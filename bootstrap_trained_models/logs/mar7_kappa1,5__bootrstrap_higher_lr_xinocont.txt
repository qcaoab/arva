Starting at: 
07-03-23_17:29

 numpy seed:  3  


 pytorch seed:  3  

Key parameters-------
paths: 256000
iterations: 30000
batchsize: 1000
remove neg:  False
w constaint activation:  yy_fix_jan29


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
               CPI  CPI_nom_ret  ...  VWD_real_ret  EWD_real_ret
date                             ...                            
192512  100.000000          NaN  ...           NaN           NaN
192601  100.000000     0.000000  ...      0.000561      0.023174
192602  100.000000     0.000000  ...     -0.033046     -0.053510
192603   99.441303    -0.005587  ...     -0.058743     -0.091750
192604  100.000000     0.005618  ...      0.031235      0.027204

[5 rows x 12 columns]
                CPI  CPI_nom_ret  ...  VWD_real_ret  EWD_real_ret
date                              ...                            
202008  1452.055956     0.003153  ...      0.065084      0.035618
202009  1454.078149     0.001393  ...     -0.036399     -0.028709
202010  1454.681696     0.000415  ...     -0.020584      0.000169
202011  1453.793232    -0.000611  ...      0.124393      0.175130
202012  1455.162018     0.000942  ...      0.044065      0.071843

[5 rows x 12 columns]


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_nom_ret', 'VWD_nom_ret']
############# End: defined asset  basket #################
        CPI_nom_ret  B10_nom_ret  VWD_nom_ret
date                                         
192601     0.000000     0.004350     0.000561
192602     0.000000     0.004338    -0.033046
192603    -0.005587     0.004327    -0.064002
192604     0.005618     0.004316     0.037029
192605    -0.005587     0.004304     0.012095
        CPI_nom_ret  B10_nom_ret  VWD_nom_ret
date                                         
202008     0.003153    -0.014709     0.068443
202009     0.001393     0.002560    -0.035057
202010     0.000415    -0.017311    -0.020178
202011    -0.000611     0.004016     0.123706
202012     0.000942    -0.004965     0.045048
Indices constructed with column names:
Index(['date_for_plt', 'CPI_nom_ret_ind', 'B10_nom_ret_ind',
       'VWD_nom_ret_ind'],
      dtype='object')
############# Updated: defined asset basket #################
timeseries_basket['data_df_mean'] = 
B10_real_ret    0.001986
VWD_real_ret    0.006974
dtype: float64


timeseries_basket['data_df_stdev'] = 
B10_real_ret    0.018939
VWD_real_ret    0.053569
dtype: float64


timeseries_basket['data_df_corr'] = 
              B10_real_ret  VWD_real_ret
B10_real_ret      1.000000      0.075353
VWD_real_ret      0.075353      1.000000


timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names', 'data_df', 'data_df_mean', 'data_df_stdev', 'data_df_corr'])
############# End: updated: defined asset basket #################
-----------------------------------------------
Dates to be REMOVED due to missing values (should be at *start* only due to trading signals):
Int64Index([], dtype='int64')
-----------------------------------------------
Dates from available data for bootstrapping:
Start: 192601
End: 202012
-----------------------------------------------
0.0% of bootstrap sample done.
5.0% of bootstrap sample done.
10.0% of bootstrap sample done.
15.0% of bootstrap sample done.
20.0% of bootstrap sample done.
25.0% of bootstrap sample done.
30.0% of bootstrap sample done.
35.0% of bootstrap sample done.
40.0% of bootstrap sample done.
45.0% of bootstrap sample done.
50.0% of bootstrap sample done.
55.00000000000001% of bootstrap sample done.
60.0% of bootstrap sample done.
65.0% of bootstrap sample done.
70.0% of bootstrap sample done.
75.0% of bootstrap sample done.
80.0% of bootstrap sample done.
85.0% of bootstrap sample done.
90.0% of bootstrap sample done.
95.0% of bootstrap sample done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 3000, 'itbound_SGD_algorithms': 30000, 'nit_IterateAveragingStart': 27000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-50.9297,  -5.9420],
        [ -1.7255,   1.3905],
        [  3.7139,  -7.8873],
        [ -7.4670,   0.2655],
        [  8.4435,  -3.0162],
        [  7.9581,  -1.6778],
        [  3.1246,  -6.9585],
        [  8.4106,  -1.7614],
        [ -1.5985,  -9.6379],
        [ -2.0548,  -8.0285]])), ('0.model.hidden_layer_1.bias', tensor([-6.2712, -4.1437, -7.6755,  6.2098, -7.2871, -7.4819, -7.1801, -7.6235,
        -8.8481,  4.0023])), ('0.model.hidden_layer_2.weight', tensor([[-7.5009e+00,  2.9710e-02, -8.6132e+00,  5.8686e+00, -7.1350e+00,
         -5.1520e+00, -5.9775e+00, -6.1079e+00, -1.0144e+01,  1.4545e+00],
        [-2.2658e-01, -1.3114e-02, -2.6116e-01, -1.2896e+00, -8.1760e-01,
         -8.2522e-01, -1.9060e-01, -9.0164e-01, -3.7311e-01, -1.3226e+00],
        [ 1.4941e-01,  1.3061e-01,  3.4243e-01,  1.6116e+00,  7.4953e-01,
          7.5921e-01,  2.7485e-01,  8.4538e-01,  3.8867e-01,  1.5197e+00],
        [ 5.1744e+00, -7.0773e-03,  6.8692e+00, -5.6608e+00,  2.5813e+00,
          4.4830e+00,  3.9490e+00,  5.5505e+00,  1.0545e+01, -2.3507e+00],
        [ 1.6504e-01,  1.6146e-01,  3.6303e-01,  1.7892e+00,  8.7581e-01,
          8.9393e-01,  2.8995e-01,  9.9763e-01,  4.1747e-01,  1.6463e+00],
        [-2.2658e-01, -1.3094e-02, -2.6116e-01, -1.2896e+00, -8.1759e-01,
         -8.2522e-01, -1.9060e-01, -9.0163e-01, -3.7310e-01, -1.3226e+00],
        [ 5.6345e+00,  3.6632e-03,  6.9509e+00, -5.8149e+00,  2.8071e+00,
          4.5795e+00,  4.1896e+00,  5.7371e+00,  1.0332e+01, -2.3794e+00],
        [-1.6654e-01, -4.5534e-02, -2.4374e-01, -1.3200e+00, -6.9691e-01,
         -7.5275e-01, -1.8873e-01, -8.3527e-01, -2.7800e-01, -1.1533e+00],
        [-2.2658e-01, -1.3092e-02, -2.6116e-01, -1.2896e+00, -8.1759e-01,
         -8.2522e-01, -1.9060e-01, -9.0163e-01, -3.7310e-01, -1.3226e+00],
        [ 7.1348e+00,  1.4043e-04,  8.6696e+00, -6.0253e+00,  4.7576e+00,
          6.6144e+00,  5.6130e+00,  8.3716e+00,  1.2163e+01, -2.5671e+00]])), ('0.model.hidden_layer_2.bias', tensor([ 3.9115, -2.2606,  2.9195, -4.6776,  3.3467, -2.2606, -4.5697, -2.1203,
        -2.2606, -5.2327])), ('0.model.output_layer_3.weight', tensor([[ 1.1572e+01,  2.9992e-05,  1.3625e+00, -5.3331e+00,  2.7921e+00,
          3.1545e-05, -5.5228e+00,  2.3086e-02,  3.1332e-05, -1.1389e+01]])), ('1.model.hidden_layer_1.weight', tensor([[ 9.3250,  1.8624],
        [ 1.4828, 11.8763],
        [-8.8804, -1.4306],
        [-1.3222,  5.9039],
        [-9.7003, -2.3791],
        [ 1.4315, 10.9659],
        [-9.3064, -2.2845],
        [-9.4249, -2.6613],
        [-7.8264, -2.0303],
        [10.0325,  2.0808]])), ('1.model.hidden_layer_1.bias', tensor([-5.6715,  0.1399,  3.5777,  7.8902, -0.8408, 10.4495, -0.9158, -2.5554,
        -2.5425, -1.7098])), ('1.model.hidden_layer_2.weight', tensor([[-3.7857e+00, -7.6265e-01, -1.2175e+00, -9.9848e-01,  8.2126e-02,
          1.1707e+00,  6.2102e-02,  7.1536e-01,  2.6350e-01, -2.3603e+00],
        [ 1.6546e+00, -7.7288e+00, -1.6173e+01, -3.3834e+00, -1.9251e+00,
          2.0549e+00, -2.0346e+00, -6.0004e-01, -8.1098e-01, -8.8455e-01],
        [-8.9200e-01, -1.7579e+00, -5.7711e+00, -2.9845e+00, -8.1152e-01,
          1.1909e-01, -8.0154e-01, -5.0823e-01, -4.0452e-01, -2.2386e+00],
        [-4.3154e+00, -1.0375e+00, -2.6168e-01, -1.4448e+00,  2.1023e-01,
          2.4403e+00,  2.9077e-01,  2.2374e+00,  1.7615e+00, -2.4911e+00],
        [-7.8690e-01, -2.3625e+00, -8.4962e+00, -3.4761e+00, -1.4453e+00,
          9.8360e-02, -1.4223e+00, -8.3024e-01, -6.9220e-01, -1.5169e+00],
        [-1.9955e+00, -2.4879e+00, -8.9177e-01, -6.4246e-01,  7.9730e-01,
          1.5856e+00,  8.3291e-01,  1.2564e+00,  1.1061e+00, -2.5417e+00],
        [-4.9526e+00, -2.3823e-01, -1.2195e+00, -1.2948e+00,  4.8790e-01,
          2.0114e+00,  4.7466e-01,  1.2986e+00,  7.5162e-01, -1.9830e+00],
        [-3.3573e+00, -3.7362e-02,  4.2474e+00, -4.5449e+00,  6.2896e+00,
         -2.9380e+01,  5.8144e+00,  5.3684e+00,  4.3663e+00, -4.7801e+00],
        [-5.0636e+00,  2.9411e-02,  2.5767e+00, -9.1340e+00,  4.9585e+00,
         -8.6763e+00,  4.7043e+00,  5.3597e+00,  4.3483e+00, -7.8079e+00],
        [ 5.5387e+00, -5.8388e-03, -9.0129e+00,  2.3398e+00, -2.3698e+00,
          3.2145e+01, -2.5487e+00,  4.5909e-01, -1.8235e+00,  1.4785e+00]])), ('1.model.hidden_layer_2.bias', tensor([-4.6124, -2.5821, -3.4484, -3.8514, -3.0332, -4.2928, -4.1645, -0.6284,
        -3.7622, -1.1467])), ('1.model.output_layer_3.weight', tensor([[  1.4086,   3.6613,   1.7299,   2.2806,   2.4271,   1.5500,   2.1151,
          -8.0988,  16.4122,   0.0895],
        [ -1.4862,  -3.6049,  -1.6576,  -2.2842,  -2.4529,  -1.5338,  -1.9840,
           8.1202, -16.2242,  -0.2425]]))])
loaded xi:  51.40288
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1518.318040318632
W_T_median: 1157.8841391994329
W_T_pctile_5: -114.48374804507138
W_T_CVAR_5_pct: -279.1514474953861
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1561.096398013243
Current xi:  [60.095287]
objective value function right now is: -1561.096398013243
4.0% of gradient descent iterations done. Method = Adam
Current xi:  [69.38662]
objective value function right now is: -1560.316489105488
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1565.7580120449945
Current xi:  [77.71711]
objective value function right now is: -1565.7580120449945
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -1568.2184311400563
Current xi:  [86.24791]
objective value function right now is: -1568.2184311400563
10.0% of gradient descent iterations done. Method = Adam
Current xi:  [93.76457]
objective value function right now is: -1565.0914025653346
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [100.20836]
objective value function right now is: -1567.9599913463094
14.000000000000002% of gradient descent iterations done. Method = Adam
new min fval:  -1569.5975290674446
Current xi:  [106.16978]
objective value function right now is: -1569.5975290674446
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [109.82313]
objective value function right now is: -1564.27489188839
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -1573.336610255289
Current xi:  [113.95651]
objective value function right now is: -1573.336610255289
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [118.51041]
objective value function right now is: -1571.6207189764702
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [121.60019]
objective value function right now is: -1572.0871064462124
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [124.260284]
objective value function right now is: -1566.4486500816322
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [126.02627]
objective value function right now is: -1571.9104190892185
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [127.79736]
objective value function right now is: -1569.8844285339947
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [129.52109]
objective value function right now is: -1570.682915193289
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [130.38469]
objective value function right now is: -1572.5129658419085
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [130.74747]
objective value function right now is: -1549.1402204506812
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [132.19466]
objective value function right now is: -1572.8325503784936
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [133.15417]
objective value function right now is: -1572.7248646937721
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [133.25763]
objective value function right now is: -1568.0566942530231
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [133.31645]
objective value function right now is: -1566.5321306148219
44.0% of gradient descent iterations done. Method = Adam
new min fval:  -1575.764855117969
Current xi:  [132.59636]
objective value function right now is: -1575.764855117969
46.0% of gradient descent iterations done. Method = Adam
new min fval:  -1575.9392043958846
Current xi:  [133.63794]
objective value function right now is: -1575.9392043958846
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [133.98991]
objective value function right now is: -1574.9188142755777
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [133.37811]
objective value function right now is: -1568.7722817329638
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [133.98004]
objective value function right now is: -1573.956745760212
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [135.08713]
objective value function right now is: -1575.0890494556556
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [134.96547]
objective value function right now is: -1573.1838290389155
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [135.06989]
objective value function right now is: -1575.593570942301
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [135.48895]
objective value function right now is: -1574.4344150708462
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [135.52844]
objective value function right now is: -1573.3027628340558
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [136.29486]
objective value function right now is: -1574.7943816297552
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [135.95871]
objective value function right now is: -1565.9133084917216
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [135.85097]
objective value function right now is: -1574.388368508893
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [135.93202]
objective value function right now is: -1564.080680897071
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -1577.1308887686473
Current xi:  [136.12914]
objective value function right now is: -1577.1308887686473
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -1577.9539210274334
Current xi:  [136.44606]
objective value function right now is: -1577.9539210274334
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [136.54742]
objective value function right now is: -1576.44823216608
78.0% of gradient descent iterations done. Method = Adam
new min fval:  -1578.146612254567
Current xi:  [136.46753]
objective value function right now is: -1578.146612254567
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [136.44882]
objective value function right now is: -1577.7521411539806
82.0% of gradient descent iterations done. Method = Adam
new min fval:  -1578.2622481127573
Current xi:  [136.84358]
objective value function right now is: -1578.2622481127573
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [136.89088]
objective value function right now is: -1577.1483377557875
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [136.89867]
objective value function right now is: -1576.1621407479909
88.0% of gradient descent iterations done. Method = Adam
new min fval:  -1578.5438759573178
Current xi:  [136.97185]
objective value function right now is: -1578.5438759573178
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [136.91658]
objective value function right now is: -1578.180184028381
new min fval from sgd:  -1578.5654291971898
new min fval from sgd:  -1578.5891429923427
new min fval from sgd:  -1578.6028714806837
new min fval from sgd:  -1578.6086734211915
new min fval from sgd:  -1578.6685661254041
new min fval from sgd:  -1578.693642862715
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [136.78218]
objective value function right now is: -1577.6807358270864
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [136.78818]
objective value function right now is: -1578.2301531838154
new min fval from sgd:  -1578.6972928571856
new min fval from sgd:  -1578.7079082770078
new min fval from sgd:  -1578.7114852304198
new min fval from sgd:  -1578.7615733082112
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [136.75455]
objective value function right now is: -1578.1790635495518
new min fval from sgd:  -1578.796427668454
new min fval from sgd:  -1578.8005948708058
new min fval from sgd:  -1578.8079114037268
new min fval from sgd:  -1578.8216618307479
new min fval from sgd:  -1578.825261533793
new min fval from sgd:  -1578.8337446403114
new min fval from sgd:  -1578.843195396744
new min fval from sgd:  -1578.8517508834475
new min fval from sgd:  -1578.8605838262345
new min fval from sgd:  -1578.867211637931
new min fval from sgd:  -1578.8733195249429
new min fval from sgd:  -1578.879011909236
new min fval from sgd:  -1578.8873408316394
new min fval from sgd:  -1578.8959018573682
new min fval from sgd:  -1578.902057024905
new min fval from sgd:  -1578.9026214984328
new min fval from sgd:  -1578.9030058906803
new min fval from sgd:  -1578.923369761868
new min fval from sgd:  -1578.9288026879353
new min fval from sgd:  -1578.9305121688417
new min fval from sgd:  -1578.9310012333144
new min fval from sgd:  -1578.9340474239775
new min fval from sgd:  -1578.9351074832746
new min fval from sgd:  -1578.940263780704
new min fval from sgd:  -1578.9427256432282
new min fval from sgd:  -1578.9461418099058
new min fval from sgd:  -1578.9495947089176
new min fval from sgd:  -1578.9519995494713
new min fval from sgd:  -1578.959874851869
new min fval from sgd:  -1578.9619884987308
new min fval from sgd:  -1578.964749587341
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [136.9673]
objective value function right now is: -1578.9161372593533
new min fval from sgd:  -1578.970598561315
new min fval from sgd:  -1578.9788098228582
new min fval from sgd:  -1578.9908563953543
new min fval from sgd:  -1578.9928438572852
new min fval from sgd:  -1579.0036439300989
new min fval from sgd:  -1579.0104799574144
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [137.01537]
objective value function right now is: -1578.8477344083688
min fval:  -1579.0104799574144
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-50.8770,  -6.9131],
        [ -1.0773,   0.5241],
        [  6.4291,  -9.3704],
        [-11.1947,   0.3528],
        [ 12.1664,  -2.0625],
        [ 11.4374,  -1.6208],
        [  8.8241,  -7.8340],
        [ 12.4826,  -1.5587],
        [ -3.6302, -11.4153],
        [ -2.0000,  -8.5175]])), ('0.model.hidden_layer_1.bias', tensor([ -7.2069,  -2.6956,  -9.0979,   9.1799, -10.1538, -10.4683,  -8.3108,
        -10.3855,  -9.8811,   8.5012])), ('0.model.hidden_layer_2.weight', tensor([[ -9.2866,  -0.0664, -10.9937,   6.3616,  -8.6453,  -4.8795,  -7.7905,
          -7.4796, -12.5313,   1.6014],
        [ -0.0308,  -0.0162,  -0.1695,  -0.6386,  -0.2181,  -0.1229,  -0.1559,
          -0.3158,  -0.1536,  -0.7489],
        [ -0.0308,  -0.0162,  -0.1695,  -0.6386,  -0.2181,  -0.1229,  -0.1559,
          -0.3158,  -0.1536,  -0.7489],
        [ -0.0308,  -0.0162,  -0.1695,  -0.6386,  -0.2181,  -0.1229,  -0.1559,
          -0.3158,  -0.1536,  -0.7489],
        [ -0.0954,   0.0403,   0.1178,   0.8666,   0.2899,   0.1854,   0.1113,
           0.3319,   0.1249,   1.1575],
        [ -0.0308,  -0.0162,  -0.1695,  -0.6386,  -0.2181,  -0.1229,  -0.1559,
          -0.3158,  -0.1536,  -0.7489],
        [ -0.0307,  -0.0161,  -0.1692,  -0.6508,  -0.2198,  -0.1244,  -0.1570,
          -0.3172,  -0.1499,  -0.7364],
        [ -0.0308,  -0.0162,  -0.1695,  -0.6386,  -0.2181,  -0.1229,  -0.1559,
          -0.3158,  -0.1536,  -0.7489],
        [ -0.0308,  -0.0162,  -0.1695,  -0.6386,  -0.2181,  -0.1229,  -0.1559,
          -0.3158,  -0.1536,  -0.7489],
        [  9.6373,  -0.0549,  11.2327,  -6.8464,   5.6433,   6.2875,   7.1477,
           9.6273,  14.2518,  -3.2216]])), ('0.model.hidden_layer_2.bias', tensor([ 4.4279, -1.1825, -1.1825, -1.1825,  1.7972, -1.1825, -1.2163, -1.1825,
        -1.1825, -6.0032])), ('0.model.output_layer_3.weight', tensor([[ 1.3699e+01, -1.6208e-02, -1.6208e-02, -1.6208e-02,  8.2031e-01,
         -1.6208e-02, -1.6046e-02, -1.6208e-02, -1.6208e-02, -1.6746e+01]])), ('1.model.hidden_layer_1.weight', tensor([[ 12.2106,   0.8786],
        [ -1.2600,   7.1965],
        [-12.2299,  -0.3314],
        [  9.5402,   9.0034],
        [-11.9286,  -3.8746],
        [  3.0678,  13.6185],
        [-12.2129,  -3.6896],
        [ -1.8706,   0.5083],
        [ -9.6404,   2.4544],
        [ 13.3977,   1.8106]])), ('1.model.hidden_layer_1.bias', tensor([-10.2276,   2.1185,   9.1438,   8.3221,  -1.3532,  11.6582,  -3.6320,
         -4.0769,   1.5434,  -6.5967])), ('1.model.hidden_layer_2.weight', tensor([[-3.2432e-01,  1.3314e-01, -1.3996e+00, -1.9525e+00, -2.5291e-01,
         -8.1709e-01, -7.0419e-02, -3.5919e-02,  1.1494e-01, -1.6105e+00],
        [ 2.1056e+00, -6.0069e+00, -1.7334e+01,  5.2396e-01, -2.9211e-01,
         -6.1192e-01, -1.2530e-02, -7.4283e-02,  1.9250e-01, -4.0219e-01],
        [-3.2466e-01,  1.3315e-01, -1.3997e+00, -1.9524e+00, -2.5297e-01,
         -8.1681e-01, -7.0404e-02, -3.5901e-02,  1.1501e-01, -1.6108e+00],
        [-5.8698e+00,  4.7791e+00,  2.0479e+00, -8.8958e-02,  2.4635e+00,
          1.3203e+00,  2.0335e+00,  4.4963e-01, -1.0341e+01, -2.6765e+00],
        [ 1.1156e+00,  4.4520e+00, -7.4392e+00, -1.9356e+00,  2.7012e-03,
          2.8815e-01, -1.2750e-02,  6.0772e-02, -5.3109e+00, -1.8341e+00],
        [ 3.6160e+00, -7.2384e+00, -1.2866e+00,  2.1601e-01,  3.3569e+00,
          3.2772e+00,  6.7262e+00, -3.4474e-02,  3.1439e+00, -2.1150e+00],
        [ 1.0035e+00, -2.8491e+00, -3.7776e+00, -8.2642e-01,  7.3314e-01,
          2.2291e+00,  1.1570e-01, -4.0435e-02,  6.8479e-01, -1.9113e+00],
        [-6.8841e+00, -4.7004e-01,  2.6391e+00, -2.8629e+00,  6.3488e+00,
         -2.6155e+01,  4.6669e+00,  6.5800e-02,  1.4264e-01, -2.0947e+00],
        [-1.4184e+00, -6.4572e-01,  2.8803e+00, -1.4509e+01,  8.8005e+00,
         -1.6749e+01,  6.4053e+00,  7.0129e-01, -3.2198e+00, -1.4504e+01],
        [ 2.6233e+00,  4.5259e-01, -6.5230e+00,  5.7506e+00, -4.8129e+00,
          2.8872e+01,  2.4882e+00,  1.4563e-01,  2.5043e+00,  7.7609e-01]])), ('1.model.hidden_layer_2.bias', tensor([-4.0285, -2.9444, -4.0284, -6.0982, -4.2455, -6.2109, -5.4372, -2.7450,
        -7.1300, -2.5366])), ('1.model.output_layer_3.weight', tensor([[ -0.2478,   4.3722,  -0.2476,   1.5048,  -2.3572,   1.7692,   1.9871,
          -7.7607,  16.0216,   0.1485],
        [  0.2477,  -4.3291,   0.2477,  -1.5068,   2.3565,  -1.7589,  -1.9763,
           7.7811, -15.9689,  -0.3013]]))])
xi:  [136.99971]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 773.9774720086862
W_T_median: 429.9986276194028
W_T_pctile_5: 137.05527436315316
W_T_CVAR_5_pct: -3.8545588203859427
Average q (qsum/M+1):  51.097479051159276
Optimal xi:  [136.99971]
Observed VAR:  429.9986276194028
Expected(across Rb) median(across samples) p_equity:  0.35101265062888465
obj fun:  tensor(-1579.0105, dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/testing_pyt_decum/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/testing_pyt_decum/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.5
-----------------------------------------------
