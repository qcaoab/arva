Starting at: 
30-06-23_19:39

 numpy seed:  2  


 pytorch seed:  2  

Key parameters-------
paths: 256000
iterations: 20000
batchsize: 1000
remove neg:  False
w constaint activation:  yy_fix_jan29


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor4
timeseries_basket['basket_desc'] = Factor4 portfolio for paper: Basic, size, value, vol, mom
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'B10_real_ret', 'VWD_real_ret', 'Size_Lo30_real_ret', 'Value_Hi30_real_ret', 'Vol_Lo20_real_ret', 'Mom_Hi30_real_ret']
############# End: defined asset  basket #################
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
192601                  0.0                NaN  ...     0.000561     0.023174
192602                  0.0                NaN  ...    -0.033046    -0.053510
192603                  0.0                NaN  ...    -0.064002    -0.096824
192604                  0.0                NaN  ...     0.037029     0.032975
192605                  0.0                NaN  ...     0.012095     0.001035

[5 rows x 16 columns]
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
202208                  NaN            -0.0020  ...    -0.036240    -0.011556
202209                  NaN            -0.0955  ...    -0.091324    -0.099903
202210                  NaN             0.0883  ...     0.077403     0.049863
202211                  NaN            -0.0076  ...     0.052365     0.028123
202212                  NaN            -0.0457  ...    -0.057116    -0.047241

[5 rows x 16 columns]


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor4
timeseries_basket['basket_desc'] = Factor4 portfolio for paper: Basic, size, value, vol, mom
timeseries_basket['basket_columns'] = 
['T30_nom_ret', 'B10_nom_ret', 'VWD_nom_ret', 'Size_Lo30_nom_ret', 'Value_Hi30_nom_ret', 'Vol_Lo20_nom_ret', 'Mom_Hi30_nom_ret']
############# End: defined asset  basket #################
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
192607                    0.0014              0.0154  ...     0.005383     0.031411
192608                    0.0319              0.0561  ...     0.005363     0.028647
192609                   -0.0173             -0.0071  ...     0.005343     0.005787
192610                   -0.0294             -0.0355  ...     0.005323    -0.028996
192611                   -0.0038              0.0294  ...     0.005303     0.028554

[5 rows x 8 columns]
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
202208                   -0.0020             -0.0164  ...    -0.043289    -0.036240
202209                   -0.0955             -0.0871  ...    -0.050056    -0.091324
202210                    0.0883              0.1486  ...    -0.014968     0.077403
202211                   -0.0076              0.0462  ...     0.040789     0.052365
202212                   -0.0457             -0.0499  ...    -0.018566    -0.057116

[5 rows x 8 columns]
Indices constructed with column names:
Index(['date_for_plt', 'Size_Lo30_nom_ret_ind', 'Value_Hi30_nom_ret_ind',
       'Mom_Hi30_nom_ret_ind', 'Vol_Lo20_nom_ret_ind', 'CPI_nom_ret_ind',
       'T30_nom_ret_ind', 'B10_nom_ret_ind', 'VWD_nom_ret_ind'],
      dtype='object')
############# Updated: defined asset basket #################
timeseries_basket['data_df_mean'] = 
T30_real_ret           0.000229
B10_real_ret           0.001637
VWD_real_ret           0.006759
Size_Lo30_real_ret     0.009939
Value_Hi30_real_ret    0.010052
Vol_Lo20_real_ret      0.003529
Mom_Hi30_real_ret      0.011386
dtype: float64


timeseries_basket['data_df_stdev'] = 
T30_real_ret           0.005227
B10_real_ret           0.019258
VWD_real_ret           0.053610
Size_Lo30_real_ret     0.082598
Value_Hi30_real_ret    0.072063
Vol_Lo20_real_ret      0.030737
Mom_Hi30_real_ret      0.061421
dtype: float64


timeseries_basket['data_df_corr'] = 
                     T30_real_ret  ...  Mom_Hi30_real_ret
T30_real_ret             1.000000  ...           0.055142
B10_real_ret             0.351722  ...           0.066570
VWD_real_ret             0.068448  ...           0.936115
Size_Lo30_real_ret       0.014412  ...           0.903222
Value_Hi30_real_ret      0.018239  ...           0.869469
Vol_Lo20_real_ret        0.081282  ...           0.482682
Mom_Hi30_real_ret        0.055142  ...           1.000000

[7 rows x 7 columns]


timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names', 'data_df', 'data_df_mean', 'data_df_stdev', 'data_df_corr'])
############# End: updated: defined asset basket #################
-----------------------------------------------
Dates to be REMOVED due to missing values (should be at *start* only due to trading signals):
Int64Index([], dtype='int64')
-----------------------------------------------
Dates from available data for bootstrapping:
Start: 192607
End: 202212
-----------------------------------------------
Bootstrap block size: 6
-----------------------------------------------
Dates USED bootstrapping:
Start: 192607
End: 202212
-----------------------------------------------
0.0% of bootstrap sample done.
5.0% of bootstrap sample done.
10.0% of bootstrap sample done.
15.0% of bootstrap sample done.
20.0% of bootstrap sample done.
25.0% of bootstrap sample done.
30.0% of bootstrap sample done.
35.0% of bootstrap sample done.
40.0% of bootstrap sample done.
45.0% of bootstrap sample done.
50.0% of bootstrap sample done.
55.00000000000001% of bootstrap sample done.
60.0% of bootstrap sample done.
65.0% of bootstrap sample done.
70.0% of bootstrap sample done.
75.0% of bootstrap sample done.
80.0% of bootstrap sample done.
85.0% of bootstrap sample done.
90.0% of bootstrap sample done.
95.0% of bootstrap sample done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      15  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      15  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 15)     True          15  
2     (15, 15)     True          15  
3      (15, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       7       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      15  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      15  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       7              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 15)     True          15  
2     (15, 15)     True          15  
3      (15, 7)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        7              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 7)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 200, 'itbound_SGD_algorithms': 20000, 'nit_IterateAveragingStart': 18000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        7              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 7)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714
 0.14285714]
W_T_mean: 1077.9285299380313
W_T_median: 745.5221097686745
W_T_pctile_5: -298.78519316905175
W_T_CVAR_5_pct: -432.03091502971404
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1605.7485603831794
Current xi:  [106.49768]
objective value function right now is: -1605.7485603831794
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1628.2093546294536
Current xi:  [106.48568]
objective value function right now is: -1628.2093546294536
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1652.0976314948512
Current xi:  [110.80287]
objective value function right now is: -1652.0976314948512
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -1656.2773149713753
Current xi:  [116.15987]
objective value function right now is: -1656.2773149713753
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1665.3431475697628
Current xi:  [121.65946]
objective value function right now is: -1665.3431475697628
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [127.96422]
objective value function right now is: -1660.503833661676
14.000000000000002% of gradient descent iterations done. Method = Adam
new min fval:  -1678.6324158768425
Current xi:  [138.5353]
objective value function right now is: -1678.6324158768425
16.0% of gradient descent iterations done. Method = Adam
new min fval:  -1681.3715677078417
Current xi:  [149.50064]
objective value function right now is: -1681.3715677078417
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [158.73378]
objective value function right now is: -1679.4293730587567
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [167.3265]
objective value function right now is: -1681.2825696010266
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -1691.3814919301617
Current xi:  [175.07455]
objective value function right now is: -1691.3814919301617
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [182.56874]
objective value function right now is: -1691.0109863413295
26.0% of gradient descent iterations done. Method = Adam
new min fval:  -1695.339386419106
Current xi:  [189.15607]
objective value function right now is: -1695.339386419106
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [195.09596]
objective value function right now is: -1685.2164540264625
30.0% of gradient descent iterations done. Method = Adam
new min fval:  -1697.122232142908
Current xi:  [200.57086]
objective value function right now is: -1697.122232142908
32.0% of gradient descent iterations done. Method = Adam
new min fval:  -1700.2153761858401
Current xi:  [206.01315]
objective value function right now is: -1700.2153761858401
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [210.64221]
objective value function right now is: -1697.394317829057
36.0% of gradient descent iterations done. Method = Adam
new min fval:  -1701.3207014328152
Current xi:  [215.07628]
objective value function right now is: -1701.3207014328152
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [218.73734]
objective value function right now is: -1696.2739453231593
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [222.71855]
objective value function right now is: -1698.4298583069467
42.0% of gradient descent iterations done. Method = Adam
new min fval:  -1704.0371735863241
Current xi:  [225.85698]
objective value function right now is: -1704.0371735863241
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [228.73094]
objective value function right now is: -1702.214318207221
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [231.08832]
objective value function right now is: -1700.7953680269536
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [233.64891]
objective value function right now is: -1698.2419757331782
50.0% of gradient descent iterations done. Method = Adam
new min fval:  -1704.6609484340481
Current xi:  [235.53226]
objective value function right now is: -1704.6609484340481
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [238.55913]
objective value function right now is: -1700.2962379160574
54.0% of gradient descent iterations done. Method = Adam
new min fval:  -1706.366161648326
Current xi:  [239.7893]
objective value function right now is: -1706.366161648326
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [241.59106]
objective value function right now is: -1704.523517632885
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [243.47739]
objective value function right now is: -1706.0130955641328
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [245.30598]
objective value function right now is: -1697.9459945925125
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [245.92883]
objective value function right now is: -1704.0580500630988
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [246.36185]
objective value function right now is: -1706.3307028280426
66.0% of gradient descent iterations done. Method = Adam
new min fval:  -1707.5754192854988
Current xi:  [247.9659]
objective value function right now is: -1707.5754192854988
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [248.20766]
objective value function right now is: -1705.2145527848984
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [249.40967]
objective value function right now is: -1705.4509396799003
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -1708.3711090329443
Current xi:  [249.65544]
objective value function right now is: -1708.3711090329443
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -1709.4803447718114
Current xi:  [249.92563]
objective value function right now is: -1709.4803447718114
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [249.92203]
objective value function right now is: -1708.9604900532643
78.0% of gradient descent iterations done. Method = Adam
new min fval:  -1709.51194871365
Current xi:  [250.22488]
objective value function right now is: -1709.51194871365
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [250.25372]
objective value function right now is: -1709.3428375142666
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [250.4814]
objective value function right now is: -1705.4431641684823
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [250.90407]
objective value function right now is: -1709.4045051134447
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [251.19853]
objective value function right now is: -1709.229048616869
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [251.35225]
objective value function right now is: -1708.9576997106249
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [251.72559]
objective value function right now is: -1708.4518137744276
92.0% of gradient descent iterations done. Method = Adam
new min fval:  -1709.8594493659252
Current xi:  [251.98347]
objective value function right now is: -1709.8594493659252
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [252.20384]
objective value function right now is: -1709.5091671618495
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [252.14455]
objective value function right now is: -1708.7585516032925
98.0% of gradient descent iterations done. Method = Adam
new min fval:  -1709.9979213768204
Current xi:  [252.29402]
objective value function right now is: -1709.9979213768204
new min fval from sgd:  -1710.0092701755568
new min fval from sgd:  -1710.0295597805489
new min fval from sgd:  -1710.036444926414
new min fval from sgd:  -1710.0380816269321
new min fval from sgd:  -1710.0401977070958
new min fval from sgd:  -1710.0547749371474
new min fval from sgd:  -1710.065294370624
new min fval from sgd:  -1710.074624049212
new min fval from sgd:  -1710.0786089660332
new min fval from sgd:  -1710.0843910036795
new min fval from sgd:  -1710.0939024456413
new min fval from sgd:  -1710.1005168903798
new min fval from sgd:  -1710.1101058478496
new min fval from sgd:  -1710.124119628832
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [252.32828]
objective value function right now is: -1709.8888715960338
min fval:  -1710.124119628832
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[  7.9287,   2.0632],
        [ -4.2085,   5.4092],
        [  3.4641,  -7.3639],
        [ -6.4276,   6.7413],
        [ -0.7628,   0.8481],
        [  8.1276,   1.9069],
        [ -0.7678,   0.8486],
        [ -0.7631,   0.8474],
        [-35.5533,  -5.7987],
        [  4.2463,  -6.9030],
        [ -4.8116,   5.2366],
        [  7.3418,   0.2870],
        [  6.8126,  10.7274],
        [ -6.7246,   7.2526],
        [  3.9507,  -6.8848]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-7.2949,  1.8964, -4.9735,  1.1587, -2.9902, -7.4417, -2.9978, -2.9878,
        -4.5653, -4.6291,  0.4848, -6.9987,  3.1108,  2.6271, -4.6894],
       device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ 2.5937e-01,  7.6802e-01,  4.6805e-01,  2.1183e-01,  6.6630e-02,
          2.5708e-01,  6.5654e-02,  6.6341e-02,  1.5950e-01,  5.0365e-01,
          2.2534e-01,  2.0498e-01,  8.5492e-01,  5.6975e-01,  4.8542e-01],
        [ 8.7366e+00, -2.4868e+00,  4.2273e+00, -3.4258e+00, -6.3119e-04,
          9.1444e+00, -2.6530e-02, -4.3690e-02,  8.5823e+00,  4.9662e+00,
         -1.6096e+00,  5.6152e+00, -1.2482e+01, -4.9710e+00,  4.5207e+00],
        [ 2.6391e-01,  7.9195e-01,  4.7985e-01,  2.1826e-01,  6.8751e-02,
          2.6153e-01,  6.7722e-02,  6.8444e-02,  1.6667e-01,  5.1462e-01,
          2.3270e-01,  2.0788e-01,  8.6580e-01,  5.8725e-01,  4.9635e-01],
        [ 8.7737e+00, -2.0754e+00,  4.5360e+00, -2.9523e+00,  2.5205e-03,
          9.3071e+00,  2.9829e-02,  1.0110e-02,  8.8050e+00,  4.7311e+00,
         -1.4886e+00,  5.5295e+00, -1.2343e+01, -4.6614e+00,  4.3015e+00],
        [ 2.6227e-01,  7.8331e-01,  4.7559e-01,  2.1593e-01,  6.7984e-02,
          2.5992e-01,  6.6974e-02,  6.7683e-02,  1.6408e-01,  5.1067e-01,
          2.3004e-01,  2.0684e-01,  8.6189e-01,  5.8093e-01,  4.9241e-01],
        [ 5.2857e+00, -2.0665e+00,  2.9978e+00, -1.3869e+00,  7.7671e-02,
          5.7938e+00,  9.1286e-02,  8.4142e-02,  4.4418e+00,  2.6412e+00,
         -9.9597e-01,  3.1639e+00, -9.2757e+00, -2.9821e+00,  2.4499e+00],
        [ 8.4288e+00, -2.1207e+00,  4.1034e+00, -2.7215e+00, -3.4155e-03,
          9.0543e+00, -6.3123e-03, -5.7035e-04,  8.5203e+00,  4.3756e+00,
         -1.4824e+00,  4.9948e+00, -1.1911e+01, -4.4706e+00,  4.0202e+00],
        [-7.5512e-02, -1.8661e-01, -2.2805e-01, -3.9726e-02, -1.9458e-02,
         -7.8049e-02, -1.9322e-02, -1.9517e-02, -3.8057e-02, -2.9838e-01,
         -4.4984e-02, -7.1325e-02, -3.2599e-01, -1.2431e-01, -2.6888e-01],
        [ 6.4063e+00, -2.0062e+00,  3.4004e+00, -1.5571e+00,  8.1525e-02,
          7.0036e+00,  8.4920e-02,  9.7565e-02,  6.0531e+00,  3.2259e+00,
         -1.2492e+00,  3.9313e+00, -1.0231e+01, -3.2093e+00,  2.6316e+00],
        [-7.5512e-02, -1.8661e-01, -2.2805e-01, -3.9726e-02, -1.9458e-02,
         -7.8049e-02, -1.9322e-02, -1.9517e-02, -3.8057e-02, -2.9838e-01,
         -4.4984e-02, -7.1325e-02, -3.2599e-01, -1.2431e-01, -2.6888e-01],
        [-7.5512e-02, -1.8661e-01, -2.2805e-01, -3.9726e-02, -1.9458e-02,
         -7.8049e-02, -1.9322e-02, -1.9517e-02, -3.8057e-02, -2.9838e-01,
         -4.4984e-02, -7.1325e-02, -3.2599e-01, -1.2431e-01, -2.6888e-01],
        [ 2.5172e-01,  7.2845e-01,  4.4827e-01,  2.0117e-01,  6.3122e-02,
          2.4960e-01,  6.2230e-02,  6.2861e-02,  1.4767e-01,  4.8516e-01,
          2.1314e-01,  2.0004e-01,  8.3656e-01,  5.4082e-01,  4.6701e-01],
        [ 8.2729e+00, -2.3834e+00,  3.9059e+00, -2.2709e+00,  1.6263e-03,
          9.0769e+00, -2.7247e-03,  3.7118e-02,  7.7910e+00,  3.8361e+00,
         -1.2877e+00,  4.7910e+00, -1.1787e+01, -3.8111e+00,  3.5705e+00],
        [ 5.3811e-01, -1.8573e+00,  1.8385e+00, -5.5314e-01, -6.3903e-02,
          6.4875e-01, -5.9730e-02, -6.2669e-02,  9.2535e-01,  1.7514e+00,
         -6.3445e-01,  5.2494e-01, -6.2600e+00, -2.0117e+00,  1.3550e+00],
        [-7.5512e-02, -1.8661e-01, -2.2805e-01, -3.9726e-02, -1.9458e-02,
         -7.8049e-02, -1.9322e-02, -1.9517e-02, -3.8057e-02, -2.9838e-01,
         -4.4984e-02, -7.1325e-02, -3.2599e-01, -1.2431e-01, -2.6888e-01]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([ 3.5002, -1.0182,  3.5889, -1.3824,  3.5567, -1.5826, -1.2748, -1.2180,
        -1.4565, -1.2180, -1.2180,  3.3546, -1.2283, -2.0481, -1.2180],
       device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 4.1538e+00, -8.8490e+00,  4.7415e+00, -9.0444e+00,  4.5195e+00,
         -3.6875e+00, -7.9849e+00,  4.8636e-04, -4.7686e+00,  4.8636e-04,
          4.8634e-04,  3.3409e+00, -7.0229e+00, -1.8467e+00,  4.8638e-04]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  4.3156,   8.9918],
        [ -5.8985,  -2.2190],
        [  3.2016,   9.9208],
        [  2.9432,   9.2786],
        [  4.3048,   3.0284],
        [ -1.7982,   0.4124],
        [  3.2244,   9.2508],
        [ -3.3276,  12.0510],
        [-12.3166,  -4.6423],
        [  4.0798,   9.3873],
        [ -8.0688,  -3.4837],
        [ -9.5157,  -1.3614],
        [ -1.1307,   4.8348],
        [  3.0871,   2.1935],
        [  9.4210,   3.2196]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ 5.0479, -4.6920,  3.4510,  4.1711, -5.4303, -4.2078,  4.2262,  5.1697,
        -1.6869,  5.2114, -4.2296,  4.9716, -1.9582, -5.0853, -3.3280],
       device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-8.1721e-01,  3.8568e-03, -1.1891e-01, -2.1757e-01, -2.7673e-02,
          5.1389e-03, -2.5681e-01, -1.0153e-01, -5.0247e-02, -6.7753e-01,
         -6.3358e-04, -1.6932e+00, -1.3381e-02, -2.0965e-02, -1.4286e+00],
        [ 3.0814e+00,  9.9328e-02,  1.6273e-01,  2.5507e+00, -1.6998e-01,
          3.0255e-02,  2.3543e+00,  7.6274e-02,  6.2471e-01,  4.6591e+00,
          1.7279e-01,  9.8650e+00,  1.5097e-02, -1.8306e-01, -3.6775e+00],
        [ 5.6811e-01,  3.2605e-02,  2.5064e+00,  2.1510e+00,  1.8706e+00,
         -8.3216e-02,  1.9125e+00, -3.7152e+00,  5.6109e-02,  1.6957e+00,
          4.3825e-02, -2.2663e+01, -3.7353e+00,  9.0700e-01,  2.4774e-02],
        [-8.1721e-01,  3.8569e-03, -1.1891e-01, -2.1757e-01, -2.7673e-02,
          5.1389e-03, -2.5682e-01, -1.0154e-01, -5.0245e-02, -6.7754e-01,
         -6.3301e-04, -1.6932e+00, -1.3381e-02, -2.0965e-02, -1.4286e+00],
        [-8.1722e-01,  3.8569e-03, -1.1892e-01, -2.1758e-01, -2.7673e-02,
          5.1388e-03, -2.5682e-01, -1.0154e-01, -5.0245e-02, -6.7755e-01,
         -6.3300e-04, -1.6932e+00, -1.3382e-02, -2.0965e-02, -1.4286e+00],
        [ 4.5194e+00, -2.2955e-01,  6.7696e+00,  5.7156e+00, -4.0693e-01,
          2.5202e-01,  5.1181e+00,  1.2984e+01,  2.3404e+00,  6.6261e+00,
         -1.2032e+00, -7.4015e+00,  8.8927e-01, -3.7924e-01,  2.8923e+00],
        [ 7.4438e-01, -3.3059e-02,  3.7440e-01,  3.5071e-01,  1.8474e-01,
          2.0357e-03,  3.7407e-01,  2.8242e-01, -8.1943e-02,  7.3344e-01,
         -3.9545e-02,  2.5699e+00,  4.9284e-02,  6.3224e-02,  1.2744e+00],
        [ 9.5792e-01,  1.5700e-02,  2.1424e-01,  4.1510e-01,  9.0747e-01,
         -2.8627e-02,  4.4901e-01,  1.5339e+00,  1.2880e-01,  1.1209e+00,
          3.2630e-02,  6.5192e+00,  5.1779e-01,  1.8665e-01, -2.1772e+00],
        [ 6.1618e+00, -2.5555e+00,  6.1856e+00,  5.3683e+00,  3.6445e-01,
         -3.5457e-01,  5.3769e+00,  1.1420e+00, -7.1179e+00,  7.8888e+00,
         -4.0678e+00, -5.5610e+00, -1.1207e-02,  2.3970e-01,  5.8051e+00],
        [-1.7400e+01,  1.4918e+00, -2.2066e+00, -1.2290e+01, -3.6081e-01,
          3.8937e-02, -1.2856e+01,  1.3413e+00,  1.3946e+01, -2.0587e+01,
          3.3651e+00, -1.8347e+00,  7.3017e-02, -4.0337e-01, -6.7256e-01],
        [-8.1721e-01,  3.8567e-03, -1.1891e-01, -2.1757e-01, -2.7672e-02,
          5.1388e-03, -2.5681e-01, -1.0153e-01, -5.0247e-02, -6.7753e-01,
         -6.3377e-04, -1.6932e+00, -1.3381e-02, -2.0965e-02, -1.4286e+00],
        [ 2.8210e-01, -9.8144e-02,  8.3023e-01,  4.9512e-01,  1.6776e+00,
         -3.3362e-02,  7.9740e-02,  5.0724e+00,  6.6429e-01,  1.5002e+00,
         -1.0913e-01,  8.9709e+00,  1.3305e+00,  1.0865e+00, -4.0992e+00],
        [-7.4756e+00,  8.8657e-01, -5.2825e+00, -6.1902e+00, -1.7069e-01,
         -1.6632e-01, -6.6018e+00, -1.0200e+00,  6.9933e+00, -8.9037e+00,
          1.8915e+00,  6.7836e+00,  5.9875e-02, -1.9772e-01, -8.0914e+00],
        [ 3.6340e+00, -5.3063e-02, -5.3229e+00,  5.4519e-01,  1.8187e+00,
          2.0345e-01,  8.1450e-01, -1.0608e+01, -4.4249e+00,  4.9034e+00,
         -3.3735e-01, -3.2956e+00,  3.7528e+00,  2.3566e+00, -1.3139e+00],
        [-1.7315e+01,  1.7127e+00, -7.4107e-01, -7.5486e+00, -3.6611e-03,
          1.8092e-01, -9.0241e+00,  1.9470e+00,  9.0828e+00, -1.7649e+01,
          3.1869e+00,  2.2073e+00,  1.3486e-01,  3.2087e-02, -4.0201e+00]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-3.4047,  0.3455, -3.5436, -3.4046, -3.4046, -5.3062,  3.1657,  1.6483,
        -0.3628,  0.0288, -3.4047, -0.3721, -1.6179, -0.5656, -1.6191],
       device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-1.4838e-02, -2.1076e+00, -8.5151e-02, -1.4839e-02, -1.4839e-02,
         -1.4571e-01, -2.7190e+00, -2.4714e+00, -2.2837e+00, -1.0204e-01,
         -1.4838e-02, -1.5289e+00, -1.4428e-01, -6.4493e-01, -2.5430e-02],
        [ 5.1809e-02, -4.2821e-01, -1.9861e+00,  6.0003e-02,  6.1891e-02,
          2.5531e+00, -4.6421e-01, -5.3405e-01,  2.3394e+00,  6.6352e+00,
          4.9233e-02, -3.6156e-01, -3.8893e+00,  9.9838e-01,  8.4151e+00],
        [-3.7906e-02,  1.1473e+00,  2.2780e+00, -2.9710e-02, -2.7824e-02,
         -3.0617e+00,  8.9207e-01,  6.8418e-01, -3.1783e+00, -7.0044e+00,
         -4.0482e-02,  8.2801e-01,  4.6972e+00, -5.4419e-01, -9.1351e+00],
        [ 2.8150e-01,  1.8676e+00,  8.8273e+00,  2.8151e-01,  2.8152e-01,
         -1.0194e+01,  2.9998e+00,  1.4848e+00, -1.9043e-01, -5.3265e+00,
          2.8149e-01, -6.9608e-01,  2.4232e+00,  9.0133e+00, -1.1961e+01],
        [ 2.0795e-01,  2.1774e+00,  7.3047e-02,  2.0795e-01,  2.0795e-01,
          2.3137e-01,  3.6448e+00,  3.2135e+00,  3.3168e+00, -8.3010e+00,
          2.0795e-01,  1.7574e+00, -1.7883e+00,  1.2456e+00, -9.8268e+00],
        [-2.0951e-01, -2.0338e+00, -1.4563e-04, -2.0952e-01, -2.0953e-01,
          4.1587e+00, -6.0310e-02, -6.4713e-01,  1.7960e+01,  2.1318e+00,
         -2.0951e-01, -1.1676e+00, -1.0024e+01,  4.9295e+00, -6.0999e-01],
        [ 1.8439e-01,  2.2088e+00,  7.8949e-02,  1.8439e-01,  1.8439e-01,
          2.5179e-01,  3.8869e+00,  3.3497e+00,  3.5096e+00, -8.7018e+00,
          1.8438e-01,  1.7443e+00, -1.9735e+00,  1.2925e+00, -1.0351e+01]],
       device='cuda:0'))])
xi:  [252.34897]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 1067.6808179884756
W_T_median: 704.1620254234715
W_T_pctile_5: 252.21827743324835
W_T_CVAR_5_pct: 95.70712889157319
Average q (qsum/M+1):  52.07807380922379
Optimal xi:  [252.34897]
Expected(across Rb) median(across samples) p_equity:  0.6489320655663808
obj fun:  tensor(-1710.1241, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: Paper_FactorInv_Factor4
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
