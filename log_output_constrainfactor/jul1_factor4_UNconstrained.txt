Starting at: 
01-07-23_16:46

 numpy seed:  2  


 pytorch seed:  2  

Key parameters-------
paths: 256000
iterations: 20000
batchsize: 1000
remove neg:  False
w constaint activation:  yy_fix_jan29


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor4
timeseries_basket['basket_desc'] = Factor4 portfolio for paper: Basic, size, value, vol, mom
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'B10_real_ret', 'VWD_real_ret', 'Size_Lo30_real_ret', 'Value_Hi30_real_ret', 'Vol_Lo20_real_ret', 'Mom_Hi30_real_ret']
############# End: defined asset  basket #################
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
192601                  0.0                NaN  ...     0.000561     0.023174
192602                  0.0                NaN  ...    -0.033046    -0.053510
192603                  0.0                NaN  ...    -0.064002    -0.096824
192604                  0.0                NaN  ...     0.037029     0.032975
192605                  0.0                NaN  ...     0.012095     0.001035

[5 rows x 16 columns]
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
202208                  NaN            -0.0020  ...    -0.036240    -0.011556
202209                  NaN            -0.0955  ...    -0.091324    -0.099903
202210                  NaN             0.0883  ...     0.077403     0.049863
202211                  NaN            -0.0076  ...     0.052365     0.028123
202212                  NaN            -0.0457  ...    -0.057116    -0.047241

[5 rows x 16 columns]


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor4
timeseries_basket['basket_desc'] = Factor4 portfolio for paper: Basic, size, value, vol, mom
timeseries_basket['basket_columns'] = 
['T30_nom_ret', 'B10_nom_ret', 'VWD_nom_ret', 'Size_Lo30_nom_ret', 'Value_Hi30_nom_ret', 'Vol_Lo20_nom_ret', 'Mom_Hi30_nom_ret']
############# End: defined asset  basket #################
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
192607                    0.0014              0.0154  ...     0.005383     0.031411
192608                    0.0319              0.0561  ...     0.005363     0.028647
192609                   -0.0173             -0.0071  ...     0.005343     0.005787
192610                   -0.0294             -0.0355  ...     0.005323    -0.028996
192611                   -0.0038              0.0294  ...     0.005303     0.028554

[5 rows x 8 columns]
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
202208                   -0.0020             -0.0164  ...    -0.043289    -0.036240
202209                   -0.0955             -0.0871  ...    -0.050056    -0.091324
202210                    0.0883              0.1486  ...    -0.014968     0.077403
202211                   -0.0076              0.0462  ...     0.040789     0.052365
202212                   -0.0457             -0.0499  ...    -0.018566    -0.057116

[5 rows x 8 columns]
Indices constructed with column names:
Index(['date_for_plt', 'Size_Lo30_nom_ret_ind', 'Value_Hi30_nom_ret_ind',
       'Mom_Hi30_nom_ret_ind', 'Vol_Lo20_nom_ret_ind', 'CPI_nom_ret_ind',
       'T30_nom_ret_ind', 'B10_nom_ret_ind', 'VWD_nom_ret_ind'],
      dtype='object')
############# Updated: defined asset basket #################
timeseries_basket['data_df_mean'] = 
T30_real_ret           0.000229
B10_real_ret           0.001637
VWD_real_ret           0.006759
Size_Lo30_real_ret     0.009939
Value_Hi30_real_ret    0.010052
Vol_Lo20_real_ret      0.003529
Mom_Hi30_real_ret      0.011386
dtype: float64


timeseries_basket['data_df_stdev'] = 
T30_real_ret           0.005227
B10_real_ret           0.019258
VWD_real_ret           0.053610
Size_Lo30_real_ret     0.082598
Value_Hi30_real_ret    0.072063
Vol_Lo20_real_ret      0.030737
Mom_Hi30_real_ret      0.061421
dtype: float64


timeseries_basket['data_df_corr'] = 
                     T30_real_ret  ...  Mom_Hi30_real_ret
T30_real_ret             1.000000  ...           0.055142
B10_real_ret             0.351722  ...           0.066570
VWD_real_ret             0.068448  ...           0.936115
Size_Lo30_real_ret       0.014412  ...           0.903222
Value_Hi30_real_ret      0.018239  ...           0.869469
Vol_Lo20_real_ret        0.081282  ...           0.482682
Mom_Hi30_real_ret        0.055142  ...           1.000000

[7 rows x 7 columns]


timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names', 'data_df', 'data_df_mean', 'data_df_stdev', 'data_df_corr'])
############# End: updated: defined asset basket #################
-----------------------------------------------
Dates to be REMOVED due to missing values (should be at *start* only due to trading signals):
Int64Index([], dtype='int64')
-----------------------------------------------
Dates from available data for bootstrapping:
Start: 192607
End: 202212
-----------------------------------------------
Bootstrap block size: 6
-----------------------------------------------
Dates USED bootstrapping:
Start: 192607
End: 202212
-----------------------------------------------
0.0% of bootstrap sample done.
5.0% of bootstrap sample done.
10.0% of bootstrap sample done.
15.0% of bootstrap sample done.
20.0% of bootstrap sample done.
25.0% of bootstrap sample done.
30.0% of bootstrap sample done.
35.0% of bootstrap sample done.
40.0% of bootstrap sample done.
45.0% of bootstrap sample done.
50.0% of bootstrap sample done.
55.00000000000001% of bootstrap sample done.
60.0% of bootstrap sample done.
65.0% of bootstrap sample done.
70.0% of bootstrap sample done.
75.0% of bootstrap sample done.
80.0% of bootstrap sample done.
85.0% of bootstrap sample done.
90.0% of bootstrap sample done.
95.0% of bootstrap sample done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      15  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      15  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 15)     True          15  
2     (15, 15)     True          15  
3      (15, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       7       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      15  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      15  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       7              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 15)     True          15  
2     (15, 15)     True          15  
3      (15, 7)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        7              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 7)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 200, 'itbound_SGD_algorithms': 20000, 'nit_IterateAveragingStart': 18000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        7              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 7)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714
 0.14285714]
W_T_mean: 1077.9285299380313
W_T_median: 745.5221097686745
W_T_pctile_5: -298.78519316905175
W_T_CVAR_5_pct: -432.03091502971404
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1617.5952286365516
Current xi:  [106.131035]
objective value function right now is: -1617.5952286365516
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1622.921462178706
Current xi:  [106.742455]
objective value function right now is: -1622.921462178706
6.0% of gradient descent iterations done. Method = Adam
Current xi:  [105.401924]
objective value function right now is: -1617.5925572286965
8.0% of gradient descent iterations done. Method = Adam
Current xi:  [102.15509]
objective value function right now is: -1621.7635436277046
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1628.118479581192
Current xi:  [99.34384]
objective value function right now is: -1628.118479581192
12.0% of gradient descent iterations done. Method = Adam
new min fval:  -1647.7083824317501
Current xi:  [104.63009]
objective value function right now is: -1647.7083824317501
14.000000000000002% of gradient descent iterations done. Method = Adam
new min fval:  -1648.5060422730485
Current xi:  [110.405914]
objective value function right now is: -1648.5060422730485
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [115.86121]
objective value function right now is: -1647.7305460036039
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [120.02157]
objective value function right now is: -1646.437823218446
20.0% of gradient descent iterations done. Method = Adam
new min fval:  -1649.9859727736223
Current xi:  [123.962494]
objective value function right now is: -1649.9859727736223
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [126.96161]
objective value function right now is: -1649.013064684907
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [129.43948]
objective value function right now is: -1646.8893331112927
26.0% of gradient descent iterations done. Method = Adam
new min fval:  -1650.1975568086725
Current xi:  [132.09402]
objective value function right now is: -1650.1975568086725
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [133.88948]
objective value function right now is: -1649.87851908409
30.0% of gradient descent iterations done. Method = Adam
new min fval:  -1651.011936716254
Current xi:  [135.6315]
objective value function right now is: -1651.011936716254
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [137.04315]
objective value function right now is: -1650.163822651953
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [138.12776]
objective value function right now is: -1650.4971448091017
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [139.589]
objective value function right now is: -1649.8734923658603
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [140.83002]
objective value function right now is: -1650.6188870706605
40.0% of gradient descent iterations done. Method = Adam
new min fval:  -1651.3203839144915
Current xi:  [140.89792]
objective value function right now is: -1651.3203839144915
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [141.38403]
objective value function right now is: -1651.0946052117533
44.0% of gradient descent iterations done. Method = Adam
new min fval:  -1651.353714107366
Current xi:  [141.78624]
objective value function right now is: -1651.353714107366
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [141.73734]
objective value function right now is: -1651.0931839302225
48.0% of gradient descent iterations done. Method = Adam
new min fval:  -1651.5532975146311
Current xi:  [142.11726]
objective value function right now is: -1651.5532975146311
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [142.5185]
objective value function right now is: -1650.5039980705694
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [143.31387]
objective value function right now is: -1650.4450483390515
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [142.6607]
objective value function right now is: -1649.472235595196
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [142.8815]
objective value function right now is: -1650.8965499606281
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [142.69598]
objective value function right now is: -1649.5685283237972
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [143.31349]
objective value function right now is: -1651.1561906075244
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [143.18866]
objective value function right now is: -1651.4068378794175
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [142.91673]
objective value function right now is: -1648.3509843072036
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [142.97375]
objective value function right now is: -1651.0384961251523
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [142.17503]
objective value function right now is: -1650.7454468972212
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [142.87068]
objective value function right now is: -1651.0190504980926
72.0% of gradient descent iterations done. Method = Adam
Current xi:  [142.7194]
objective value function right now is: -1651.529807949279
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -1651.7377756797332
Current xi:  [142.57332]
objective value function right now is: -1651.7377756797332
76.0% of gradient descent iterations done. Method = Adam
new min fval:  -1652.0366818262446
Current xi:  [142.5024]
objective value function right now is: -1652.0366818262446
78.0% of gradient descent iterations done. Method = Adam
new min fval:  -1653.0542814294108
Current xi:  [142.51439]
objective value function right now is: -1653.0542814294108
80.0% of gradient descent iterations done. Method = Adam
new min fval:  -1653.3363987337732
Current xi:  [142.4279]
objective value function right now is: -1653.3363987337732
82.0% of gradient descent iterations done. Method = Adam
new min fval:  -1653.6378839815636
Current xi:  [142.3919]
objective value function right now is: -1653.6378839815636
84.0% of gradient descent iterations done. Method = Adam
new min fval:  -1653.8317951789852
Current xi:  [142.45267]
objective value function right now is: -1653.8317951789852
86.0% of gradient descent iterations done. Method = Adam
new min fval:  -1653.8869493298262
Current xi:  [142.54779]
objective value function right now is: -1653.8869493298262
88.0% of gradient descent iterations done. Method = Adam
new min fval:  -1654.6703372321313
Current xi:  [142.59923]
objective value function right now is: -1654.6703372321313
90.0% of gradient descent iterations done. Method = Adam
new min fval:  -1655.630511174905
Current xi:  [143.00143]
objective value function right now is: -1655.630511174905
92.0% of gradient descent iterations done. Method = Adam
new min fval:  -1656.0593097530686
Current xi:  [143.22774]
objective value function right now is: -1656.0593097530686
94.0% of gradient descent iterations done. Method = Adam
new min fval:  -1656.6468478626964
Current xi:  [143.53064]
objective value function right now is: -1656.6468478626964
96.0% of gradient descent iterations done. Method = Adam
new min fval:  -1656.8424949392722
Current xi:  [143.80537]
objective value function right now is: -1656.8424949392722
98.0% of gradient descent iterations done. Method = Adam
new min fval:  -1657.1118538770113
Current xi:  [144.01976]
objective value function right now is: -1657.1118538770113
new min fval from sgd:  -1657.113276322218
new min fval from sgd:  -1657.121357887819
new min fval from sgd:  -1657.1394351902595
new min fval from sgd:  -1657.1418946424283
new min fval from sgd:  -1657.1435601503356
new min fval from sgd:  -1657.1525335027043
new min fval from sgd:  -1657.1571098246263
new min fval from sgd:  -1657.165695754239
new min fval from sgd:  -1657.1710898732524
new min fval from sgd:  -1657.1772512925775
new min fval from sgd:  -1657.1813096478434
new min fval from sgd:  -1657.1896886784634
new min fval from sgd:  -1657.1961072634913
new min fval from sgd:  -1657.1961369343476
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [144.09412]
objective value function right now is: -1657.1727843964575
min fval:  -1657.1961369343476
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[  7.4729,   1.7453],
        [ -4.0352,   4.9570],
        [  3.4786,  -6.8112],
        [ -5.8919,   6.0459],
        [ -6.0107, -10.2294],
        [  7.4567,   1.6325],
        [ -2.0674,   2.5868],
        [ -1.8480,   2.3674],
        [  8.3598,   1.5939],
        [  3.4995,  -6.7810],
        [ -4.3636,   4.7682],
        [  6.7391,   1.8018],
        [ 39.3007,   3.5830],
        [ -5.4621,   6.2035],
        [  3.4393,  -6.7299]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-7.1890,  1.5537, -5.1272,  2.0099, -4.4775, -7.2174, -2.2912, -2.5448,
        -7.5265, -5.0841,  0.7874, -7.0034,  4.0248,  3.4407, -5.0484],
       device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-6.0256e-02, -4.9655e-02, -2.2033e-01, -3.4954e-02, -2.8041e-01,
         -5.9274e-02, -1.3825e-02, -1.2907e-02, -7.7706e-02, -2.2450e-01,
         -3.2170e-02, -4.7454e-02, -5.9906e-01, -9.9304e-02, -2.2306e-01],
        [ 4.9596e+00, -2.4052e+00,  3.1272e+00, -4.0441e+00,  1.0535e+01,
          4.5049e+00, -1.0993e-01, -1.5109e-01,  9.9800e+00,  4.0781e+00,
         -1.4880e+00,  3.8688e+00, -1.0665e+01, -5.5171e+00,  3.6826e+00],
        [ 3.6331e-01,  1.3144e-01,  5.9610e-01,  4.6746e-02,  6.8781e-01,
          3.5299e-01,  1.1077e-02,  9.0784e-03,  4.5707e-01,  6.1073e-01,
          5.3102e-02,  2.7366e-01,  2.1762e+00,  2.5897e-01,  6.0685e-01],
        [ 4.9807e+00, -1.9806e+00,  3.5023e+00, -3.5938e+00,  1.0600e+01,
          4.6018e+00, -5.0505e-01, -6.2551e-01,  1.0729e+01,  3.9747e+00,
         -1.4796e+00,  3.7307e+00, -1.0512e+01, -5.1809e+00,  3.5873e+00],
        [ 3.6040e-01,  1.3050e-01,  5.9269e-01,  4.6627e-02,  6.8258e-01,
          3.5019e-01,  1.0996e-02,  9.0056e-03,  4.5337e-01,  6.0720e-01,
          5.2934e-02,  2.7158e-01,  2.1621e+00,  2.5681e-01,  6.0335e-01],
        [ 1.7618e+00, -1.0400e+00,  2.1834e+00, -1.0117e+00,  5.9407e+00,
          1.6420e+00, -6.1748e-03, -1.0354e-02,  5.0978e+00,  2.3504e+00,
         -5.4292e-01,  9.6847e-01, -8.1386e+00, -2.3029e+00,  2.1531e+00],
        [ 4.5908e+00, -1.9326e+00,  3.2877e+00, -3.1843e+00,  1.0264e+01,
          4.2698e+00, -7.4679e-01, -8.3222e-01,  1.1702e+01,  3.9528e+00,
         -1.5838e+00,  3.1620e+00, -1.0441e+01, -4.8341e+00,  3.5469e+00],
        [-6.0256e-02, -4.9654e-02, -2.2033e-01, -3.4954e-02, -2.8041e-01,
         -5.9274e-02, -1.3826e-02, -1.2907e-02, -7.7706e-02, -2.2450e-01,
         -3.2170e-02, -4.7454e-02, -5.9906e-01, -9.9304e-02, -2.2306e-01],
        [ 3.4686e+00, -1.5585e+00,  2.8534e+00, -1.8404e+00,  7.6108e+00,
          3.2618e+00, -6.3697e-01, -6.1934e-01,  9.4511e+00,  3.2220e+00,
         -1.2929e+00,  2.4554e+00, -9.0436e+00, -3.2157e+00,  2.5949e+00],
        [-6.0256e-02, -4.9654e-02, -2.2033e-01, -3.4954e-02, -2.8041e-01,
         -5.9274e-02, -1.3826e-02, -1.2907e-02, -7.7706e-02, -2.2450e-01,
         -3.2170e-02, -4.7454e-02, -5.9906e-01, -9.9304e-02, -2.2306e-01],
        [-6.0256e-02, -4.9654e-02, -2.2033e-01, -3.4954e-02, -2.8041e-01,
         -5.9274e-02, -1.3826e-02, -1.2907e-02, -7.7706e-02, -2.2450e-01,
         -3.2170e-02, -4.7454e-02, -5.9906e-01, -9.9304e-02, -2.2306e-01],
        [-6.0256e-02, -4.9654e-02, -2.2033e-01, -3.4954e-02, -2.8041e-01,
         -5.9274e-02, -1.3826e-02, -1.2907e-02, -7.7706e-02, -2.2450e-01,
         -3.2170e-02, -4.7454e-02, -5.9906e-01, -9.9304e-02, -2.2306e-01],
        [ 4.3684e+00, -2.2722e+00,  3.1420e+00, -2.8083e+00,  9.0227e+00,
          4.2341e+00, -8.1114e-01, -7.9335e-01,  1.1178e+01,  3.4646e+00,
         -1.6169e+00,  2.9090e+00, -1.0035e+01, -4.1280e+00,  3.2680e+00],
        [-6.0641e-03, -1.0699e-01,  2.6007e-01, -4.8441e-02,  2.1146e+00,
         -6.7778e-03,  3.2553e-04,  6.0469e-04, -9.8209e-03,  3.4967e-01,
         -2.2923e-02, -2.9858e-03, -4.4307e+00, -5.1995e-01,  2.2750e-01],
        [-6.0256e-02, -4.9654e-02, -2.2033e-01, -3.4954e-02, -2.8041e-01,
         -5.9274e-02, -1.3826e-02, -1.2907e-02, -7.7706e-02, -2.2450e-01,
         -3.2170e-02, -4.7454e-02, -5.9906e-01, -9.9304e-02, -2.2306e-01]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.6535, -1.1904,  2.2427, -1.6121,  2.2278, -1.5475, -1.6272, -0.6535,
        -1.6095, -0.6535, -0.6535, -0.6535, -1.5261, -1.3817, -0.6535],
       device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-1.1914e-03, -7.9506e+00,  7.9438e+00, -8.3744e+00,  7.6070e+00,
         -2.8792e+00, -8.3438e+00, -1.1914e-03, -4.6277e+00, -1.1915e-03,
         -1.1914e-03, -1.1915e-03, -6.5392e+00, -7.4470e-01, -1.1915e-03]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[-4.5033e+00, -4.8359e+00],
        [-4.4452e+00, -4.7949e+00],
        [-2.1843e+00, -5.3358e+00],
        [-4.2145e+00, -4.7817e+00],
        [-8.5954e+00,  1.4437e-04],
        [-4.4791e+00, -4.8254e+00],
        [-4.2079e+00, -4.7407e+00],
        [-5.6724e+00,  2.6333e-01],
        [-1.7952e+00, -3.2850e+00],
        [-4.3486e+00, -4.8019e+00],
        [-4.5466e+00, -4.8636e+00],
        [-4.5561e+00, -4.8836e+00],
        [-4.0709e+00, -4.7810e+00],
        [-4.2035e+00, -4.7742e+00],
        [-6.9834e+00,  8.2163e-01]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-3.6123, -3.6133, -4.0466, -3.7282,  0.3033, -3.6186, -3.7028, -0.3354,
         0.2342, -3.6759, -3.6090, -3.6211, -3.7875, -3.7281,  0.6451],
       device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 2.4965,  2.3739,  0.6187,  1.9353, -4.5178,  2.4446,  1.9121, -3.1287,
         -2.6143,  2.1299,  2.5920,  2.6030,  1.7437,  1.9272, -5.1817],
        [ 1.4103,  1.3045, -0.1323,  0.9098, -3.8145,  1.3641,  0.8962, -2.3826,
         -2.0008,  1.0724,  1.4941,  1.5005,  0.7502,  0.9072, -3.8781],
        [ 2.6990,  2.5746,  0.8004,  2.1359, -4.6931,  2.6471,  2.1096, -3.3486,
         -2.7518,  2.3346,  2.7954,  2.8077,  1.9421,  2.1276, -5.4580],
        [ 0.7509,  0.6739, -0.4194,  0.3568, -3.1898,  0.7175,  0.3491, -1.8701,
         -1.3151,  0.4807,  0.8117,  0.8139,  0.2396,  0.3640, -2.7854],
        [ 2.3795,  2.2584,  0.5254,  1.8187, -4.4297,  2.3279,  1.7978, -3.0111,
         -2.5193,  2.0087,  2.4742,  2.4844,  1.6312,  1.8129, -5.0330],
        [-0.1844, -0.2268, -1.6273, -0.5917, -2.0359, -0.2177, -0.5431, -0.6257,
         -0.3851, -0.4382, -0.1428, -0.1661, -0.7197, -0.5903, -2.3813],
        [ 1.5130,  1.4067, -0.0587,  1.0095, -3.8907,  1.4666,  0.9956, -2.4264,
         -2.0189,  1.1735,  1.5972,  1.6036,  0.8475,  1.0065, -4.0205],
        [ 1.5666,  1.4580, -0.0362,  1.0559, -3.9187,  1.5195,  1.0404, -2.4496,
         -2.0428,  1.2236,  1.6522,  1.6594,  0.8914,  1.0528, -4.0702],
        [-0.2990, -0.3250, -1.3788, -0.6145, -2.4318, -0.3282, -0.5524, -0.5421,
          0.0311, -0.4700, -0.2650, -0.2974, -0.7095, -0.6180, -1.8687],
        [ 0.9691,  0.9259,  1.5043,  0.7930,  1.5340,  0.9537,  0.7673,  0.0330,
          0.1067,  0.8163,  1.0013,  1.0084,  0.8010,  0.8125,  1.6742],
        [ 3.2432,  3.1133,  1.3772,  2.6680, -5.2828,  3.1897,  2.6359, -4.0821,
         -3.1396,  2.8670,  3.3435,  3.3581,  2.4735,  2.6596, -6.3299],
        [ 1.1428,  1.0447, -0.2754,  0.6740, -3.5631,  1.0996,  0.6629, -2.1803,
         -1.7721,  0.8227,  1.2209,  1.2257,  0.5270,  0.6726, -3.4604],
        [ 1.3879,  1.2818, -0.1547,  0.8879, -3.7812,  1.3418,  0.8731, -2.3368,
         -1.9240,  1.0505,  1.4717,  1.4785,  0.7290,  0.8856, -3.8155],
        [ 2.7645,  2.6383,  0.8571,  2.1935, -4.7529,  2.7116,  2.1673, -3.4304,
         -2.8194,  2.3926,  2.8625,  2.8749,  1.9982,  2.1849, -5.5583],
        [ 2.4505,  2.3303,  0.5863,  1.8998, -4.4796,  2.4004,  1.8756, -3.0855,
         -2.5854,  2.0950,  2.5436,  2.5550,  1.7112,  1.8936, -5.1152]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-3.1427, -2.3029, -3.3787, -1.8834, -3.0395,  0.4362, -2.4290, -2.4806,
         0.7162, -0.6277, -4.0765, -2.1793, -2.3773, -3.4270, -3.1080],
       device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-2.7532e-01,  1.0323e-02, -4.1166e-01,  1.3674e-01, -2.1071e-01,
         -1.9055e-01,  1.1973e-02,  6.7846e-03, -4.8396e-01,  1.2881e+00,
         -1.1155e+00,  6.2375e-02,  3.9630e-02, -4.7324e-01, -2.5044e-01],
        [ 1.6472e+00,  1.3747e+00,  1.7611e+00,  1.3797e+00,  1.6065e+00,
          1.3565e+00,  1.3902e+00,  1.3430e+00,  1.9979e+00,  2.3050e-01,
          2.3933e+00,  1.3327e+00,  1.3164e+00,  1.8221e+00,  1.5983e+00],
        [-2.1781e+00, -2.1164e+00, -2.1902e+00, -2.6564e+00, -2.2232e+00,
         -2.5282e+00, -2.2386e+00, -2.2463e+00, -3.0074e+00, -5.6420e+00,
         -2.0168e+00, -2.2720e+00, -2.2859e+00, -2.1300e+00, -2.1798e+00],
        [ 1.8499e+00,  7.7549e-01,  2.2487e+00,  4.2764e-01,  1.6684e+00,
          1.7478e+00,  8.4140e-01,  8.5192e-01,  1.7963e+00, -2.0965e+00,
          3.9002e+00,  6.1056e-01,  7.2841e-01,  2.3957e+00,  1.7734e+00],
        [ 8.1340e-01,  6.1760e-01,  8.4759e-01,  8.6609e-01,  7.8748e-01,
          5.0867e+00,  6.0479e-01,  5.9986e-01,  6.6763e+00,  7.8953e+00,
          9.2452e-01,  6.3879e-01,  5.9194e-01,  8.5915e-01,  8.0295e-01],
        [ 6.9350e-01,  5.6630e-01,  7.1427e-01,  8.1075e-01,  6.7584e-01,
          4.7857e+00,  5.4967e-01,  5.4321e-01,  6.2064e+00,  7.4462e+00,
          7.5793e-01,  5.9316e-01,  5.4217e-01,  7.2183e-01,  6.8618e-01],
        [ 7.8664e-01,  6.2655e-01,  8.1334e-01,  8.9587e-01,  7.6486e-01,
          5.3272e+00,  6.1015e-01,  6.0365e-01,  7.0048e+00,  8.4909e+00,
          8.7020e-01,  6.5485e-01,  6.0086e-01,  8.2263e-01,  7.7772e-01]],
       device='cuda:0'))])
xi:  [144.09317]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 984.5050246772579
W_T_median: 537.236582260723
W_T_pctile_5: 144.14537365196452
W_T_CVAR_5_pct: 26.782198178102394
Average q (qsum/M+1):  52.594057144657256
Optimal xi:  [144.09317]
Expected(across Rb) median(across samples) p_equity:  0.5035675058762232
obj fun:  tensor(-1657.1961, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: Paper_FactorInv_Factor4
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
