/home/marcchen/Documents/constrain_factor/researchcode/exp_config_json_files/multi_portfolio_TEST2_EFs_OOD_test.json
Starting at: 
12-08-23_20:48

 numpy seed:  2  


 pytorch seed:  2  

Key parameters-------
paths: 256000
iterations: 10
batchsize: 10
remove neg:  False
w constaint activation:  yy_fix_jan29


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
192601                  0.0                NaN  ...     0.000561     0.023174
192602                  0.0                NaN  ...    -0.033046    -0.053510
192603                  0.0                NaN  ...    -0.064002    -0.096824
192604                  0.0                NaN  ...     0.037029     0.032975
192605                  0.0                NaN  ...     0.012095     0.001035

[5 rows x 16 columns]
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
202208                  NaN            -0.0020  ...    -0.036240    -0.011556
202209                  NaN            -0.0955  ...    -0.091324    -0.099903
202210                  NaN             0.0883  ...     0.077403     0.049863
202211                  NaN            -0.0076  ...     0.052365     0.028123
202212                  NaN            -0.0457  ...    -0.057116    -0.047241

[5 rows x 16 columns]


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_nom_ret', 'VWD_nom_ret']
############# End: defined asset  basket #################
               CPI_nom_ret  B10_nom_ret  VWD_nom_ret
My identifier                                       
192607           -0.011299     0.005383     0.031411
192608           -0.005714     0.005363     0.028647
192609            0.005747     0.005343     0.005787
192610            0.005714     0.005323    -0.028996
192611            0.005682     0.005303     0.028554
               CPI_nom_ret  B10_nom_ret  VWD_nom_ret
My identifier                                       
202208           -0.000354    -0.043289    -0.036240
202209            0.002151    -0.050056    -0.091324
202210            0.004056    -0.014968     0.077403
202211           -0.001010     0.040789     0.052365
202212           -0.003070    -0.018566    -0.057116
Indices constructed with column names:
Index(['date_for_plt', 'CPI_nom_ret_ind', 'B10_nom_ret_ind',
       'VWD_nom_ret_ind'],
      dtype='object')
############# Updated: defined asset basket #################
timeseries_basket['data_df_mean'] = 
B10_real_ret    0.001637
VWD_real_ret    0.006759
dtype: float64


timeseries_basket['data_df_stdev'] = 
B10_real_ret    0.019258
VWD_real_ret    0.053610
dtype: float64


timeseries_basket['data_df_corr'] = 
              B10_real_ret  VWD_real_ret
B10_real_ret      1.000000      0.090987
VWD_real_ret      0.090987      1.000000


timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names', 'data_df', 'data_df_mean', 'data_df_stdev', 'data_df_corr'])
############# End: updated: defined asset basket #################
-----------------------------------------------
Dates to be REMOVED due to missing values (should be at *start* only due to trading signals):
Int64Index([], dtype='int64')
-----------------------------------------------
Dates from available data for bootstrapping:
Start: 192607
End: 202212
-----------------------------------------------
Bootstrap block size: 6
-----------------------------------------------
Dates USED bootstrapping:
Start: 199201
End: 202212
-----------------------------------------------
0.0% of bootstrap sample done.
5.0% of bootstrap sample done.
10.0% of bootstrap sample done.
15.0% of bootstrap sample done.
20.0% of bootstrap sample done.
25.0% of bootstrap sample done.
30.0% of bootstrap sample done.
35.0% of bootstrap sample done.
40.0% of bootstrap sample done.
45.0% of bootstrap sample done.
50.0% of bootstrap sample done.
55.00000000000001% of bootstrap sample done.
60.0% of bootstrap sample done.
65.0% of bootstrap sample done.
70.0% of bootstrap sample done.
75.0% of bootstrap sample done.
80.0% of bootstrap sample done.
85.0% of bootstrap sample done.
90.0% of bootstrap sample done.
95.0% of bootstrap sample done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 0, 'itbound_SGD_algorithms': 10, 'nit_IterateAveragingStart': 9, 'batchsize': 10, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.0, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[  8.3291,   2.5980],
        [-10.9143,   3.1158],
        [ -0.5507,   5.5431],
        [ -0.4369,   1.2990],
        [ -0.4368,   1.2989],
        [ 10.3673,   0.1053],
        [-11.5174,  -0.9996],
        [ -8.0726,   3.2617],
        [ -2.7845,   5.0630],
        [-11.6111,  -2.4033]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-4.6538, 11.1410,  9.6888, -0.6066, -0.6064, -9.0740,  7.4315,  9.2687,
         6.6586,  6.1055], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-4.9340e-03, -3.1754e-02, -4.9736e-02, -3.7896e-03, -3.7906e-03,
         -1.8412e-01, -2.5657e-01, -2.3966e-02, -5.8865e-03, -4.6493e-01],
        [-4.9340e-03, -3.1754e-02, -4.9736e-02, -3.7896e-03, -3.7906e-03,
         -1.8412e-01, -2.5657e-01, -2.3966e-02, -5.8865e-03, -4.6493e-01],
        [-2.2149e+00, -1.1376e+01, -4.9074e+00,  7.7220e-02,  8.0244e-02,
         -8.2611e+00,  5.1733e+00, -6.0865e+00, -1.5785e+00,  2.6575e+00],
        [-8.8113e-03,  3.6279e-02, -3.0679e-02, -8.3831e-04, -8.4062e-04,
         -2.0593e-01, -3.8407e-01,  2.8128e-02,  2.6723e-02, -6.5987e-01],
        [-4.9340e-03, -3.1754e-02, -4.9736e-02, -3.7896e-03, -3.7906e-03,
         -1.8412e-01, -2.5657e-01, -2.3966e-02, -5.8865e-03, -4.6493e-01],
        [-4.9340e-03, -3.1754e-02, -4.9736e-02, -3.7896e-03, -3.7906e-03,
         -1.8412e-01, -2.5657e-01, -2.3966e-02, -5.8865e-03, -4.6493e-01],
        [ 1.0884e+00,  1.2496e+00,  3.3881e+00,  2.4735e-01,  2.4744e-01,
          4.6153e+00, -3.3253e+00,  1.2051e+00,  1.1673e+00, -2.0030e+00],
        [ 1.0840e+00,  7.6239e+00,  2.9677e+00, -7.0166e-02, -6.6195e-02,
          4.9384e+00, -3.3243e+00,  3.7749e+00,  5.6802e-01, -1.5313e+00],
        [-4.9340e-03, -3.1754e-02, -4.9736e-02, -3.7896e-03, -3.7906e-03,
         -1.8412e-01, -2.5657e-01, -2.3966e-02, -5.8865e-03, -4.6493e-01],
        [-4.9340e-03, -3.1754e-02, -4.9736e-02, -3.7896e-03, -3.7906e-03,
         -1.8412e-01, -2.5657e-01, -2.3966e-02, -5.8865e-03, -4.6493e-01]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.5763, -0.5763,  0.4856, -0.7874, -0.5763, -0.5763,  0.0523, -0.3634,
        -0.5763, -0.5763], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ -0.0179,  -0.0179, -12.2065,   0.0803,  -0.0179,  -0.0179,   5.7268,
           9.0119,  -0.0179,  -0.0179]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  2.6510,   0.5979],
        [-19.9968,  -4.2400],
        [  6.4777,  -8.5174],
        [ -9.2885,   0.5769],
        [ -5.2933,  -9.2161],
        [  1.2250,   3.2564],
        [ -4.9727,  -8.2752],
        [-14.7304,  -8.7815],
        [ -7.6193,  -8.7379],
        [ 11.2951,   0.7806]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ 3.9507,  1.7668, -6.7286,  6.6624, -6.2252,  9.5741, -1.7535, -2.9705,
        -9.3956, -8.6394], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-1.2539e+00, -5.0783e-01, -7.5870e-01, -6.3318e-01, -5.1906e-01,
         -1.2551e+00, -5.9917e-01, -5.1099e-01, -5.1013e-01, -6.5063e-01],
        [-1.2539e+00, -5.0783e-01, -7.5870e-01, -6.3318e-01, -5.1906e-01,
         -1.2551e+00, -5.9917e-01, -5.1099e-01, -5.1013e-01, -6.5063e-01],
        [ 1.0546e+00,  1.3900e-01, -1.8596e-02, -9.4333e+00,  2.5528e+00,
         -6.7410e-01,  6.6261e+00, -9.9898e-01, -1.0245e+00, -4.1148e-01],
        [-2.2891e+00,  1.9794e+00,  2.5814e+00, -2.0292e+00, -7.4826e-02,
         -5.5142e+00,  2.5230e+00, -3.2179e-01, -2.6244e+00, -3.4882e+00],
        [-1.2539e+00, -5.0783e-01, -7.5870e-01, -6.3318e-01, -5.1906e-01,
         -1.2551e+00, -5.9917e-01, -5.1099e-01, -5.1013e-01, -6.5063e-01],
        [-6.8317e+00,  8.9282e+00, -4.7597e+00,  2.2703e+00,  2.2955e-02,
          3.7282e+00, -4.4660e+00,  2.7073e+00,  9.5292e+00, -1.0563e+00],
        [-1.1642e+00, -9.0362e+00,  3.5402e+00, -2.7558e+00,  3.3685e+00,
          8.0518e-01,  1.6032e-01,  1.2301e+01, -1.1420e+01, -1.0720e+01],
        [-2.6715e+00,  2.6582e+00,  9.0334e-01, -1.5554e+00,  1.9235e-01,
         -3.8641e+00,  4.9046e-01, -4.9865e-02,  4.9874e-01, -2.0604e+00],
        [-2.6527e+00,  3.0702e+00,  1.0535e+00, -1.9015e+00,  2.4950e-01,
         -4.8953e+00,  8.0484e-01,  4.2303e-02,  2.2215e-01, -2.2828e+00],
        [-4.5574e+00,  2.2389e+00, -4.2595e+00,  4.2975e+00, -1.7121e+00,
          4.3587e-03,  1.8559e+00, -1.5239e+00,  8.4788e+00,  1.2389e+00]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-1.8016, -1.8016,  1.6147,  2.1199, -1.8016, -4.4295, -4.0668,  0.6076,
         0.8080,  0.7418], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ 4.7473e-03,  4.7481e-03, -2.4154e-01, -2.7771e+00,  4.7474e-03,
          4.4321e+00, -7.8538e+00, -7.6842e-01, -1.6523e+00,  1.0302e+00],
        [-4.7442e-03, -4.7434e-03,  3.7042e-01,  2.7719e+00, -4.7441e-03,
         -4.3528e+00,  7.9120e+00,  7.8944e-01,  1.9649e+00, -1.1766e+00]],
       device='cuda:0'))])
loaded xi:  -579.3133
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 928.0406076148151
W_T_median: 802.9397371901745
W_T_pctile_5: -89.8203597709638
W_T_CVAR_5_pct: -242.54788524615043
-----------------------------------------------
new min fval from sgd:  -1753.1240016572272
min fval:  -1753.1240016572272
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 192.2707120633999
W_T_median: 99.62739463347214
W_T_pctile_5: -519.5328941022418
W_T_CVAR_5_pct: -620.0212757607634
Average q (qsum/M+1):  57.57315555695565
Optimal xi:  [-579.3133]
Expected(across Rb) median(across samples) p_equity:  0.3495291453194416
obj fun:  tensor(-1753.1240, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.05
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-0.5906,  1.1402],
        [-0.4646,  1.3674],
        [-0.4645,  1.3675],
        [-4.7194,  6.5969],
        [ 9.3994,  5.8082],
        [-2.4023,  5.1090],
        [ 5.0249, -5.9394],
        [ 4.6763, -6.0849],
        [-0.4651,  1.3654],
        [-3.4212,  5.9183]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-1.0202, -0.3923, -0.3921,  9.0984,  0.2720,  4.5587, -8.5056, -8.4395,
        -0.4094,  6.9428], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-1.6370e-02, -2.2554e-02, -2.2556e-02, -4.6004e-02, -6.8282e-02,
         -5.0222e-03, -3.7125e-01, -3.8052e-01, -2.2286e-02, -1.6750e-02],
        [ 1.3788e-01,  1.7011e-01,  1.6990e-01, -4.1686e+00, -6.6768e+00,
         -5.0473e-01,  1.9242e+00,  2.0444e+00,  1.7045e-01, -1.7101e+00],
        [-1.6370e-02, -2.2554e-02, -2.2556e-02, -4.6004e-02, -6.8282e-02,
         -5.0222e-03, -3.7125e-01, -3.8052e-01, -2.2286e-02, -1.6750e-02],
        [-1.6370e-02, -2.2554e-02, -2.2556e-02, -4.6004e-02, -6.8282e-02,
         -5.0222e-03, -3.7125e-01, -3.8052e-01, -2.2286e-02, -1.6750e-02],
        [ 1.2943e-01,  1.7090e-01,  1.7089e-01, -2.9485e+00, -4.8113e+00,
         -1.9197e-01,  1.3001e+00,  1.5542e+00,  1.6990e-01, -1.0071e+00],
        [ 1.3772e-01,  1.8027e-01,  1.8026e-01, -3.1204e+00, -5.0727e+00,
         -2.1977e-01,  1.4245e+00,  1.5912e+00,  1.7944e-01, -1.0954e+00],
        [ 7.3878e-01,  1.1727e+00,  1.1727e+00,  7.6141e+00, -5.5191e-01,
          2.1442e+00, -3.0615e+00, -3.2007e+00,  1.1575e+00,  4.2224e+00],
        [ 1.3013e-01,  1.6123e-01,  1.6098e-01, -4.3167e+00, -6.7971e+00,
         -5.4510e-01,  1.7674e+00,  2.1538e+00,  1.6167e-01, -1.7903e+00],
        [-3.9700e-01, -5.9459e-01, -5.9498e-01,  7.8406e+00,  9.1614e+00,
          1.2183e+00, -4.0018e+00, -3.5711e+00, -5.8294e-01,  3.6100e+00],
        [-1.6370e-02, -2.2554e-02, -2.2556e-02, -4.6006e-02, -6.8283e-02,
         -5.0219e-03, -3.7127e-01, -3.8054e-01, -2.2286e-02, -1.6750e-02]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.5269, -1.0287, -0.5269, -0.5269, -1.1328, -1.0980,  2.1840, -0.9143,
         0.9753, -0.5269], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 7.6037e-03, -4.5540e+00,  7.6038e-03,  7.6038e-03, -2.9527e+00,
         -3.1414e+00,  5.8156e+00, -4.6906e+00,  9.0797e+00,  7.6043e-03]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -9.2351,   1.2901],
        [ 11.4166,   7.0197],
        [  8.0824,  10.0747],
        [ -4.4740,  12.3592],
        [  9.4918,  -0.3888],
        [ 13.7282,  -1.1878],
        [-11.9599,  -1.2071],
        [ -1.5266,   8.1732],
        [ -3.2559,  -0.6451],
        [-13.6630,  -2.9513]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ 6.0749,  5.9292, 10.1918,  9.4573, -9.8402, -6.9670,  6.9883,  7.2792,
        -4.2315,  0.7100], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[  4.0976, -11.3669,  -7.5908,  -2.7081,  -4.1743,  -5.3898,   4.1525,
          -5.0175,   4.6680,   9.1984],
        [  1.5140,  -0.4624,   4.6455, -14.2474,  -2.2942,  -5.1231,   1.1181,
          -5.3619,   6.9438,   6.0044],
        [  2.5183,  -0.1568,   0.6007,  -5.0887,  -3.1092,  -1.0994,  -0.4825,
          -0.4158,  -0.2532,  -2.9750],
        [  5.2276,  -5.8393,  -6.3071,   3.9687,  -4.6886,  -3.3679,   1.3050,
          -1.9598,  -3.4409,   4.1182],
        [ -0.0807,  -1.0119,  -0.5902,  -0.1541,  -0.6134,  -1.7325,  -0.6027,
          -0.1840,  -0.1409,  -0.1505],
        [  0.5422,  -4.9282, -14.0385,  -1.2102,  -5.7751,  -2.6010,   6.4240,
           2.0494,   1.1494,   9.2318],
        [ -9.6918,  -0.1644,  -0.2586,  -0.7706,  -0.3209,  -1.4650,   4.1419,
           2.1803,  -0.3032,   0.3917],
        [  1.8077,  -2.6123,  -0.7823,   9.1331,  -7.0373,  -3.6259,  -2.7457,
           0.1268,  -0.1077,   2.6287],
        [ -0.0807,  -1.0122,  -0.5901,  -0.1541,  -0.6134,  -1.7311,  -0.6026,
          -0.1840,  -0.1409,  -0.1506],
        [ -0.0807,  -1.0119,  -0.5902,  -0.1541,  -0.6134,  -1.7322,  -0.6026,
          -0.1840,  -0.1409,  -0.1505]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-1.2425, -1.7795, -1.5169, -1.1066, -1.7523, -0.6360, -0.1135, -3.3491,
        -1.7536, -1.7526], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ 7.4527, -3.8996, -2.4345,  6.2850, -0.0236, -3.2394, -0.3515,  0.8180,
         -0.0235, -0.0235],
        [-7.3384,  3.8299,  2.4341, -6.2854,  0.0235,  3.4898,  0.3792, -1.0005,
          0.0236,  0.0236]], device='cuda:0'))])
loaded xi:  -378.32812
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 928.0406076148151
W_T_median: 802.9397371901745
W_T_pctile_5: -89.8203597709638
W_T_CVAR_5_pct: -242.54788524615043
-----------------------------------------------
new min fval from sgd:  -1690.924546506857
min fval:  -1690.924546506857
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 182.86291081173044
W_T_median: 74.49254824373664
W_T_pctile_5: -338.2877738456313
W_T_CVAR_5_pct: -390.74658346879755
Average q (qsum/M+1):  57.14488958543347
Optimal xi:  [-378.32812]
Expected(across Rb) median(across samples) p_equity:  0.3543595995288342
obj fun:  tensor(-1690.9245, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.2
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-2.1266, -9.6534],
        [-0.6908,  1.1105],
        [-0.6984,  1.1383],
        [ 5.4211, -6.2916],
        [ 9.2782, -1.2672],
        [ 0.2658, -6.6060],
        [-0.6907,  1.1101],
        [ 5.4829,  2.5801],
        [-0.6625,  1.0449],
        [-5.8168,  6.3408]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-9.0682, -1.3384, -1.3576, -7.7013, -9.6391, -7.3639, -1.3382, -4.7008,
        -1.2893,  7.5648], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-7.8969e-02,  1.5747e-02,  1.5136e-02, -6.5277e-01, -1.0118e-01,
         -8.4202e-02,  1.5755e-02, -1.9525e-02,  1.7284e-02, -1.3822e-01],
        [-7.8969e-02,  1.5747e-02,  1.5136e-02, -6.5277e-01, -1.0118e-01,
         -8.4202e-02,  1.5755e-02, -1.9525e-02,  1.7284e-02, -1.3822e-01],
        [-8.0828e+00, -3.3488e-02, -4.6688e-02, -5.3898e+00, -6.5066e+00,
         -3.0717e+00, -3.3305e-02, -2.9631e+00,  5.1241e-03,  8.8722e+00],
        [-7.8969e-02,  1.5747e-02,  1.5136e-02, -6.5277e-01, -1.0118e-01,
         -8.4202e-02,  1.5755e-02, -1.9525e-02,  1.7284e-02, -1.3822e-01],
        [-7.8969e-02,  1.5747e-02,  1.5136e-02, -6.5277e-01, -1.0118e-01,
         -8.4202e-02,  1.5755e-02, -1.9525e-02,  1.7284e-02, -1.3822e-01],
        [ 7.8920e+00, -7.9517e-02, -9.3921e-02,  3.8812e+00,  2.8668e+00,
          2.9368e+00, -7.9223e-02,  6.0597e-02, -4.4835e-02, -8.4863e+00],
        [ 7.3427e+00, -4.1262e-02, -4.8049e-02,  3.2629e+00,  2.8236e+00,
          2.7181e+00, -4.1268e-02,  1.4673e-01, -1.3906e-02, -7.8884e+00],
        [-7.8969e-02,  1.5747e-02,  1.5136e-02, -6.5277e-01, -1.0119e-01,
         -8.4202e-02,  1.5755e-02, -1.9526e-02,  1.7284e-02, -1.3822e-01],
        [-7.8969e-02,  1.5747e-02,  1.5136e-02, -6.5277e-01, -1.0118e-01,
         -8.4202e-02,  1.5755e-02, -1.9525e-02,  1.7284e-02, -1.3822e-01],
        [-7.8969e-02,  1.5747e-02,  1.5136e-02, -6.5277e-01, -1.0118e-01,
         -8.4202e-02,  1.5755e-02, -1.9525e-02,  1.7284e-02, -1.3822e-01]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.9726, -0.9726,  3.1663, -0.9726, -0.9726, -4.1908, -3.8689, -0.9726,
        -0.9726, -0.9726], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 0.0381,  0.0381, 12.9832,  0.0381,  0.0381, -6.8815, -6.6144,  0.0381,
          0.0381,  0.0381]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -2.7300,  -0.7870],
        [  9.2801,   1.1326],
        [  9.0367,  10.1016],
        [ -3.1516,  10.0784],
        [  2.3247,   0.8208],
        [-11.7507,  -1.1677],
        [-13.0906,  -2.8926],
        [ -6.9221,   8.1108],
        [-13.5360,  -3.0443],
        [ -7.0228,   0.7083]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-6.0429, -1.4217,  8.9347,  6.9009,  5.5366,  5.3312, -0.2267, 10.6779,
        -0.0942,  3.5876], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-6.3549e-01, -1.5398e+00, -7.6998e-01, -6.0599e-02, -1.5907e+00,
         -8.3249e-01, -6.4769e-01, -9.9376e-02, -6.4889e-01, -5.7241e-02],
        [ 8.3788e+00, -4.8435e+00,  1.1244e+01, -1.8043e+01, -4.9603e+00,
         -6.7051e-01,  1.6170e+00,  3.2350e+00,  2.0860e+00,  1.7554e+00],
        [-2.4183e-01, -3.8635e+00, -1.4372e+01,  1.2802e+00,  1.8432e+00,
          9.7712e+00,  5.9837e+00, -1.3836e+01,  6.1682e+00,  1.0811e+00],
        [-9.1475e-01, -1.5798e+00, -8.3977e-01,  6.6396e-01, -1.6353e+00,
         -7.9985e-01, -9.3424e-01,  8.2127e-01, -9.3739e-01, -4.6987e-01],
        [-8.0602e+00, -2.7174e+00,  2.2651e+00,  3.0439e+00,  1.1964e+00,
         -4.2148e-02,  2.7522e+00, -4.9508e+00,  2.9658e+00,  1.5106e+00],
        [ 1.7055e-01, -1.9357e+00, -1.2558e+00, -5.9936e-01,  1.4333e+00,
         -1.0935e+01,  1.5985e+00, -1.0653e+01,  1.7374e+00, -4.3156e+00],
        [-2.6879e-02, -5.8407e+00, -2.5269e+01, -6.9401e+00, -5.1455e+00,
          1.0162e+01,  1.0790e+01,  7.6856e-01,  1.1653e+01, -3.3247e+00],
        [-4.0052e+00, -3.1503e+00, -4.1078e+00,  7.7954e-01,  1.2698e-01,
          9.0391e-02,  5.7280e-03,  1.0730e+00,  2.0299e-01,  1.7726e+00],
        [-3.1028e-02, -3.2811e+00, -9.0132e-02,  3.2048e+00, -3.4615e+00,
         -1.0825e+01, -7.3573e+00,  5.3745e+00, -8.0334e+00,  1.9339e+01],
        [-1.2546e+00, -1.1291e+00, -3.3490e-01,  1.3796e+00, -1.2748e+00,
         -5.1430e-01, -1.2560e+00,  1.5910e+00, -1.2583e+00, -2.2991e+00]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-2.4704, -5.5677, -2.5239, -2.7611, -3.3938, -1.6316, -3.2730, -3.5661,
        -4.6048, -2.4416], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-0.0210, -4.2073, -4.8426, -0.2355,  2.6770,  3.8116,  8.8541,  1.1238,
          0.3888, -0.8380],
        [ 0.0098,  4.2597,  4.7261,  0.2345, -2.4912, -3.5284, -9.1335, -1.1255,
         -0.6015,  0.8376]], device='cuda:0'))])
loaded xi:  -214.05327
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 928.0406076148151
W_T_median: 802.9397371901745
W_T_pctile_5: -89.8203597709638
W_T_CVAR_5_pct: -242.54788524615043
-----------------------------------------------
new min fval from sgd:  -1623.2543033630122
min fval:  -1623.2543033630122
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 204.71171888415572
W_T_median: 59.30502629826543
W_T_pctile_5: -191.2268072563425
W_T_CVAR_5_pct: -218.76344365194572
Average q (qsum/M+1):  56.05199801537298
Optimal xi:  [-214.05327]
Expected(across Rb) median(across samples) p_equity:  0.34488107400635876
obj fun:  tensor(-1623.2543, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.5
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-11.2737,   1.7007],
        [  7.6959,   4.2054],
        [  3.8779,  -7.6092],
        [  6.0393,  -0.7980],
        [  8.1322,  -3.0392],
        [  6.6049,  -3.7852],
        [  2.1530,  -5.7798],
        [ -1.3644,  -9.8628],
        [  3.5980,  -8.0926],
        [ -1.3651,   0.6012]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ 9.3869, -8.6201, -7.2168, -8.4064, -6.5788, -6.1712, -6.6115, -8.5746,
        -7.3207, -2.4487], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-7.3577e-01, -2.7393e-01, -2.3036e-01, -9.9731e-03, -4.7064e-01,
         -2.9026e-01, -8.3096e-02, -2.0880e-01, -2.6129e-01, -1.7089e-02],
        [-7.3577e-01, -2.7393e-01, -2.3036e-01, -9.9731e-03, -4.7064e-01,
         -2.9026e-01, -8.3096e-02, -2.0880e-01, -2.6130e-01, -1.7089e-02],
        [-7.3578e-01, -2.7394e-01, -2.3037e-01, -9.9731e-03, -4.7066e-01,
         -2.9027e-01, -8.3096e-02, -2.0880e-01, -2.6130e-01, -1.7087e-02],
        [-7.3577e-01, -2.7393e-01, -2.3036e-01, -9.9731e-03, -4.7064e-01,
         -2.9026e-01, -8.3096e-02, -2.0880e-01, -2.6129e-01, -1.7089e-02],
        [-1.0324e+01,  4.8241e+00,  4.3859e+00,  1.3515e+00,  3.1793e+00,
          2.1795e+00,  2.3569e+00,  7.9397e+00,  5.0193e+00, -1.1420e-01],
        [ 9.0389e+00, -4.7819e+00, -5.4399e+00, -2.2211e+00, -4.9436e+00,
         -3.1159e+00, -2.4649e+00, -9.1474e+00, -6.2830e+00, -1.0520e-01],
        [-7.3577e-01, -2.7393e-01, -2.3036e-01, -9.9731e-03, -4.7064e-01,
         -2.9026e-01, -8.3096e-02, -2.0880e-01, -2.6129e-01, -1.7089e-02],
        [-7.3577e-01, -2.7393e-01, -2.3036e-01, -9.9731e-03, -4.7064e-01,
         -2.9026e-01, -8.3096e-02, -2.0880e-01, -2.6129e-01, -1.7089e-02],
        [-9.6513e+00,  4.2907e+00,  4.1033e+00,  1.0119e+00,  2.9200e+00,
          2.0450e+00,  2.0683e+00,  7.4801e+00,  4.7041e+00, -1.2013e-01],
        [-8.7257e+00,  3.6455e+00,  3.7203e+00,  5.4290e-01,  2.6100e+00,
          1.7815e+00,  1.8002e+00,  6.6603e+00,  4.3647e+00, -1.2229e-01]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-1.3169, -1.3169, -1.3171, -1.3169, -2.0545,  1.7691, -1.3169, -1.3169,
        -2.0951, -2.1880], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 0.0206,  0.0206,  0.0206,  0.0206, -7.7263, 13.2028,  0.0206,  0.0206,
         -6.5518, -5.1478]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  3.8228,  12.8336],
        [-13.3933,  -3.5186],
        [-10.3617,   0.2013],
        [ -6.2571,  15.3401],
        [ 12.7997,   4.0283],
        [ -7.8908,  12.0735],
        [ 11.7991,   2.8889],
        [  1.0779,  10.9936],
        [  8.1666,   8.7960],
        [-10.8444,  -1.8217]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([11.5308, -1.1118,  9.1239, 12.1809,  0.4775, 13.5917, -0.1118,  8.1238,
         7.6146,  1.7803], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 16.4445,  -1.4587, -13.9325,   0.7999,   2.2539,  12.7710,   4.5543,
           3.3750,   5.4250,  -9.0998],
        [ -0.6059,  -0.0900,  -1.2078,  -0.3471,  -1.6763,  -0.3871,  -1.7719,
          -0.4395,  -0.9491,  -0.3178],
        [  1.6752,   5.2328,  -1.8167, -16.0969,  -1.4204,   0.4261,  -1.9227,
          -2.6335,   0.9736,   1.1307],
        [  0.7216,  -0.1432,  -3.3983,  -0.9198,  -1.3730,  -0.9233,  -1.1609,
          -0.2923,  -0.9186,   0.0290],
        [  6.4699,   0.8734,  -1.8170,  -3.7577,  -3.0543,   8.5373,  -1.7796,
          -4.6219,  -0.3323,  -4.2928],
        [-14.7198,  10.3976,   6.2988,  -7.6778,  -2.8306,  -8.9073,  -4.8137,
          -7.0763,  -5.6585,   8.4990],
        [ -0.6066,  -0.0892,  -1.2012,  -0.3466,  -1.6712,  -0.3862,  -1.7563,
          -0.4385,  -0.9532,  -0.3182],
        [ -7.2569,  10.8954,   5.1379,  -1.6679,  -9.5597,   2.1443,  -9.0123,
          -2.5082, -23.5249,   8.5497],
        [  0.4047,   0.1861,  -3.2898,  -1.8702,  -1.6130,  -1.4351,  -1.8069,
           1.6671,   0.5666,   0.5384],
        [ -0.6085,  -0.0899,  -1.2019,  -0.3470,  -1.6747,  -0.3869,  -1.7694,
          -0.4384,  -0.9518,  -0.3184]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-0.1311, -1.9625, -2.0240, -2.6627, -4.3165,  0.2241, -1.9823, -1.5650,
        -2.4324, -1.9631], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[  0.5137,  -0.1205,   2.5344,   0.5210,  -4.4510,  -5.6714,  -0.1072,
          11.0627,   1.2164,  -0.1196],
        [ -0.1021,   0.1215,  -2.5333,  -0.5880,   4.3878,   5.7438,   0.1351,
         -11.0546,  -1.2174,   0.1213]], device='cuda:0'))])
loaded xi:  -112.769135
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 928.0406076148151
W_T_median: 802.9397371901745
W_T_pctile_5: -89.8203597709638
W_T_CVAR_5_pct: -242.54788524615043
-----------------------------------------------
new min fval from sgd:  -1553.1484568859535
min fval:  -1553.1484568859535
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 378.96154295876653
W_T_median: 161.60371362480146
W_T_pctile_5: -103.6276342522331
W_T_CVAR_5_pct: -126.24099505100807
Average q (qsum/M+1):  54.30732185609879
Optimal xi:  [-112.769135]
Expected(across Rb) median(across samples) p_equity:  0.3752589752276739
obj fun:  tensor(-1553.1485, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ 2.0782, -3.3748],
        [ 3.6322, -5.2499],
        [-4.7881, -4.3868],
        [-3.7356, -1.3681],
        [-2.8116,  7.1122],
        [-3.9416, -7.7328],
        [ 5.7990, -6.7866],
        [-2.3129,  7.5458],
        [-7.0882, -0.1975],
        [ 9.3054, -0.8755]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-5.7839, -5.7502,  2.8614,  1.3385,  5.6225, -6.4654, -6.0063,  5.8090,
         5.4883, -7.3852], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-6.5834e-03, -4.0416e-02, -2.7958e-01, -1.9983e-01, -6.2054e-01,
         -3.7264e-02, -1.7267e-01, -6.2414e-01, -3.6743e-01, -3.0721e-01],
        [-1.0062e+00, -2.7133e+00,  6.8169e-01,  5.2598e-01,  5.5480e+00,
         -9.1629e+00, -1.2526e+01,  5.5823e+00,  4.3679e+00, -2.1864e+01],
        [-6.5835e-03, -4.0415e-02, -2.7958e-01, -1.9983e-01, -6.2053e-01,
         -3.7264e-02, -1.7266e-01, -6.2413e-01, -3.6743e-01, -3.0721e-01],
        [-6.5835e-03, -4.0415e-02, -2.7958e-01, -1.9983e-01, -6.2053e-01,
         -3.7264e-02, -1.7266e-01, -6.2413e-01, -3.6743e-01, -3.0721e-01],
        [-6.5835e-03, -4.0415e-02, -2.7958e-01, -1.9983e-01, -6.2053e-01,
         -3.7264e-02, -1.7266e-01, -6.2413e-01, -3.6743e-01, -3.0721e-01],
        [-6.5835e-03, -4.0415e-02, -2.7958e-01, -1.9983e-01, -6.2053e-01,
         -3.7264e-02, -1.7266e-01, -6.2413e-01, -3.6743e-01, -3.0721e-01],
        [-6.5835e-03, -4.0415e-02, -2.7958e-01, -1.9983e-01, -6.2053e-01,
         -3.7264e-02, -1.7266e-01, -6.2413e-01, -3.6743e-01, -3.0721e-01],
        [-6.5835e-03, -4.0415e-02, -2.7958e-01, -1.9983e-01, -6.2053e-01,
         -3.7264e-02, -1.7266e-01, -6.2413e-01, -3.6743e-01, -3.0721e-01],
        [ 9.2725e-01,  3.0141e+00, -8.0068e-01, -9.3097e-01, -6.5384e+00,
          4.4545e+00,  6.3406e+00, -6.6441e+00, -4.7694e-01,  2.7555e+00],
        [ 1.4154e+00,  2.1595e+00, -1.1626e+00,  3.6426e-01, -4.0944e+00,
          6.0315e+00,  5.2631e+00, -4.4536e+00, -3.9567e+00,  1.5376e+01]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.8259,  1.6491, -0.8259, -0.8259, -0.8259, -0.8259, -0.8259, -0.8259,
        -1.9749, -0.5597], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 5.4276e-03,  1.5268e+01,  5.4273e-03,  5.4273e-03,  5.4273e-03,
          5.4273e-03,  5.4272e-03,  5.4273e-03, -5.9489e+00, -1.1966e+01]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  3.6371,   6.1643],
        [-15.0258,   0.6421],
        [ -1.9023,  -2.7144],
        [-12.0596,  -3.9010],
        [  6.5253,  11.7922],
        [ 11.5826,   2.7289],
        [  0.2610,   0.2073],
        [  8.6589,   5.2815],
        [ 10.3234,   5.3365],
        [  8.9687,  -0.8116]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-1.7228,  1.8686, -6.9094,  3.5802,  8.8717, -1.4242,  5.1871, 12.5432,
         1.9315, -9.5336], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 1.1057e+00,  2.9148e-01, -2.3157e+00,  2.7817e+00,  1.6443e+00,
         -2.1026e+00, -1.8128e+00, -1.4526e+00, -2.3600e-01, -4.9287e+00],
        [ 1.1772e-01, -9.8050e-01,  7.0888e-01,  2.4365e-02, -1.5246e+00,
         -5.9696e-01, -1.1054e+00, -1.4821e+00, -9.6323e-01, -7.7558e-01],
        [ 7.9240e-01,  1.8398e+01,  4.4498e-01, -4.3744e+00,  1.1626e+01,
         -3.2706e-01, -3.6420e+00,  7.5307e+00, -5.7008e-01,  1.0184e+01],
        [ 5.1801e-01, -2.4722e+00,  2.3952e+00,  8.5212e-01, -2.2792e+00,
         -8.2271e-01, -1.1242e+00, -1.1672e+00, -1.3562e+00,  1.1681e+00],
        [-9.4008e-02,  6.0348e-02,  1.1153e-01, -1.1118e-01, -6.5956e-01,
         -8.1271e-01, -1.3531e+00, -2.3847e+00, -1.1465e+00, -5.6273e-01],
        [ 7.1072e-01, -2.3643e+00,  2.1314e+00,  1.5426e+00, -1.8355e+00,
          3.3729e-01, -3.1691e-01, -4.0449e+00, -6.8567e-01,  7.0388e-01],
        [-1.7492e-01,  6.5083e+00, -8.4441e-01,  1.8478e+01, -2.8964e+01,
         -1.0505e+01,  7.6249e+00, -2.0907e+01, -1.9410e+01, -1.0448e+01],
        [ 9.7469e-01,  3.6810e+00,  1.1398e-01,  1.7192e+00,  9.1586e+00,
         -3.9237e+00, -1.7650e+00, -1.9252e+00, -2.9691e+00, -1.0113e+00],
        [ 1.3169e-01, -9.2704e-01,  7.0163e-01,  4.4098e-02, -1.5116e+00,
         -5.8148e-01, -1.2595e+00, -1.3966e+00, -9.6711e-01, -7.4675e-01],
        [-2.7950e+00, -3.8686e+00,  1.7291e+00,  4.7953e+00, -1.7112e+01,
         -4.2371e+00,  1.9759e-01,  4.9316e-01, -4.9136e+00, -8.2053e+00]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-0.6234, -1.4236, -4.4434, -1.1337, -1.4574, -0.3277, -0.0507, -1.7836,
        -1.4145,  0.1508], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[  1.4256,  -0.6388,   0.5884,  -0.9272,  -0.1871,  -1.2894,  17.2040,
          -1.2620,  -0.6271,  -6.9976],
        [ -1.3793,   0.6439,  -0.1583,   0.9271,   0.1929,   1.2903, -17.2370,
           1.2550,   0.6399,   7.0230]], device='cuda:0'))])
loaded xi:  -75.23009
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 928.0406076148151
W_T_median: 802.9397371901745
W_T_pctile_5: -89.8203597709638
W_T_CVAR_5_pct: -242.54788524615043
-----------------------------------------------
new min fval from sgd:  -1506.5717752277176
min fval:  -1506.5717752277176
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 462.6033211721568
W_T_median: 241.38705771693878
W_T_pctile_5: -71.02279613631312
W_T_CVAR_5_pct: -94.6213332250818
Average q (qsum/M+1):  53.27359107232863
Optimal xi:  [-75.23009]
Expected(across Rb) median(across samples) p_equity:  0.41597664008537927
obj fun:  tensor(-1506.5718, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.5
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[  9.9739,  -0.6840],
        [  7.6332,   1.8334],
        [ -1.5312,   0.0834],
        [-10.2613,   1.5863],
        [  8.3288,  -1.0078],
        [  0.1251, -10.2716],
        [  8.4885,  -3.6189],
        [-10.5911,   1.0354],
        [  6.8184,  -7.2119],
        [  4.2862,  -8.1014]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ -8.1794, -10.1768,  -2.7669,   6.1060,  -8.7567,  -7.9621,  -6.1695,
          7.6760,  -5.7250,  -6.3193], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ 1.1495e+00,  4.3123e-01,  7.3267e-02,  1.0564e+00,  2.9845e-01,
          1.2920e-01,  6.9860e-01,  1.6264e+00,  8.5625e-01,  2.7409e-01],
        [ 1.1878e-01,  8.0343e-02, -4.0176e-02, -9.9268e-01, -2.1860e-01,
         -2.9561e-02, -2.8495e-01, -2.0240e+00, -2.8839e-01, -7.0705e-02],
        [ 3.7927e+00,  3.5676e+00,  1.6558e-01, -4.8556e+00,  1.0427e+00,
          1.0049e+01,  1.0780e+00, -5.7267e+00,  2.9807e+00,  4.7166e+00],
        [ 3.8481e+00,  4.2869e+00,  1.6251e-01, -4.9011e+00,  1.7084e+00,
          1.0823e+01,  1.4823e+00, -6.2427e+00,  3.1302e+00,  4.6577e+00],
        [ 3.4630e+00,  3.6370e+00,  1.5290e-01, -4.2969e+00,  1.0108e+00,
          9.7981e+00,  1.0941e+00, -6.0029e+00,  3.0325e+00,  4.2357e+00],
        [ 9.3380e-01,  3.3076e-01,  6.2263e-02,  9.3091e-01,  2.5059e-01,
          1.3425e-01,  5.9738e-01,  1.4254e+00,  7.8932e-01,  2.5248e-01],
        [ 5.5567e+00,  5.7219e+00, -7.7481e-02, -6.0144e+00,  3.1917e+00,
          1.1453e+01,  3.8821e+00, -6.1218e+00,  5.6927e+00,  6.7704e+00],
        [-4.7471e-01, -1.3193e-01, -8.2143e-03, -2.9022e-01, -4.2027e-02,
         -2.5309e-02, -3.4232e-01, -5.4440e-01, -2.6131e-01, -1.1056e-01],
        [ 4.9954e+00,  5.0878e+00,  1.4877e-01, -5.5082e+00,  2.5853e+00,
          1.2077e+01,  1.7815e+00, -6.7869e+00,  3.3499e+00,  4.9632e+00],
        [ 5.1386e+00,  5.8048e+00, -1.8614e-01, -5.7305e+00,  3.0361e+00,
          1.1185e+01,  4.5993e+00, -6.6097e+00,  6.4961e+00,  6.8082e+00]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([ 3.6659, -2.3623, -2.1325, -1.9746, -2.1401,  3.1165, -2.0361, -1.4115,
        -1.6959, -1.6132], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 1.0170e+01, -6.2214e-01, -4.5206e+00, -5.0383e+00, -4.2349e+00,
          4.0593e+00, -8.3537e+00,  1.0106e-02, -6.5558e+00, -8.3793e+00]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  9.4065,   0.7940],
        [ -0.0918,  -3.3145],
        [ -2.9156,   9.3940],
        [ 13.0285,   3.6165],
        [ -1.1712,  -5.1052],
        [-13.3867,  -3.6611],
        [-16.0116,  -4.1431],
        [  8.4274,  -0.7132],
        [-10.5007,  -3.1510],
        [ -1.8095,   0.3203]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-6.4131, 10.8480,  8.3839,  0.0206, -5.8090, -0.5102, -2.9063, -9.6947,
        -3.6337, -4.4624], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-3.0473e+00,  6.8928e+00, -1.7798e+01, -4.8778e+00,  2.9915e+00,
          5.9888e+00,  4.5680e-01, -5.8322e+00, -1.5494e+00, -3.2052e-01],
        [-3.7386e+00, -7.1656e-01, -2.4054e+00, -1.7654e+00, -5.8176e-01,
          2.0614e+00, -3.9296e-02, -2.1327e+00,  3.7134e-01,  6.8371e-02],
        [-1.2159e+01,  4.2920e+00, -1.6968e+01, -1.6717e+01,  1.2420e+01,
          6.5912e+00,  1.7893e+01, -2.6485e+00,  5.2954e+00,  3.8287e-03],
        [ 1.8757e+00, -1.2342e+01,  6.1567e+00,  9.0796e-01,  1.9496e-01,
          8.8813e+00,  1.0095e+00,  1.5684e+00,  6.2401e-01,  6.0930e-01],
        [-3.7417e+00, -7.1285e-01, -2.4063e+00, -1.7621e+00, -5.7910e-01,
          2.0675e+00, -4.0370e-02, -2.1370e+00,  3.7114e-01,  6.8845e-02],
        [ 6.4618e+00,  1.1296e+00,  4.6795e+00,  7.3211e+00, -7.5796e+00,
         -5.2284e+00, -1.6269e+00,  1.6574e+00,  7.8046e-02, -1.8105e-01],
        [ 1.3290e+00, -1.3724e+01,  1.2443e+00,  5.0459e+00, -3.4319e+00,
         -1.2226e+00, -1.2751e-01,  5.6238e+00, -8.1158e-02,  2.2429e-01],
        [-3.7422e+00, -7.1221e-01, -2.4064e+00, -1.7615e+00, -5.7863e-01,
          2.0686e+00, -4.0570e-02, -2.1378e+00,  3.7110e-01,  6.8924e-02],
        [-1.4298e+00,  5.3030e+00, -1.5397e+01, -7.1645e+00,  2.0486e+00,
          3.1128e+00,  8.8480e-01, -3.5980e+00,  2.3103e+00,  4.3207e-01],
        [ 5.4904e+00, -9.9973e+00,  3.0348e+01,  1.0650e+01, -5.9009e+00,
         -1.1204e+01, -9.0735e+00,  5.2360e+00, -2.9501e+00,  1.4348e-01]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([ -3.6152,  -1.7666, -11.3061,  -0.2304,  -1.7621,   3.5953,   1.3153,
         -1.7614,  -2.3325,   5.5942], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ -1.0741,   1.6903,  14.4375,  -1.9674,   1.6923,  -2.0615,   1.9859,
           1.6942,  -4.7196,   2.4205],
        [  0.8599,  -1.6865, -14.4407,   1.7929,  -1.6933,   2.0234,  -1.6873,
          -1.6929,   4.6955,  -2.4882]], device='cuda:0'))])
loaded xi:  -34.958233
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 928.0406076148151
W_T_median: 802.9397371901745
W_T_pctile_5: -89.8203597709638
W_T_CVAR_5_pct: -242.54788524615043
-----------------------------------------------
new min fval from sgd:  -1418.6313290130067
min fval:  -1418.6313290130067
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 389.7350160636747
W_T_median: 229.05197731206815
W_T_pctile_5: -34.71041882340249
W_T_CVAR_5_pct: -63.72344618091656
Average q (qsum/M+1):  51.937476373487904
Optimal xi:  [-34.958233]
Expected(across Rb) median(across samples) p_equity:  0.31982762018839517
obj fun:  tensor(-1418.6313, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 3.0
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[  7.1171,  -6.2470],
        [  9.7375,  -0.5551],
        [  9.5808,  -0.5891],
        [-10.2315,  -9.4427],
        [  9.5257,  -0.5408],
        [  8.5288,  -0.9609],
        [  2.6896,  -7.1392],
        [  9.7577,  -0.3577],
        [  8.7013,  -5.5368],
        [  9.8662,  -0.2987]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-6.0426, -8.4579, -8.4735, -5.8819, -8.5133, -8.9230, -6.9849, -8.5341,
        -5.1190, -8.6227], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ 3.3919,  1.8488,  1.7002,  4.0138,  1.5489,  0.3324,  2.4760,  2.3707,
          3.2828,  2.6322],
        [ 5.9646,  4.6685,  4.4607,  4.8664,  4.3350,  3.1079,  4.3287,  5.1171,
          5.4129,  5.3487],
        [ 3.9233,  2.9893,  2.5263,  4.4230,  2.4455,  1.0297,  3.2532,  3.5275,
          3.6319,  3.6590],
        [ 5.0965,  4.2391,  4.0265,  4.6722,  4.1028,  2.7455,  3.5836,  4.6510,
          5.1210,  4.9541],
        [ 5.8718,  4.7964,  4.5286,  4.9279,  4.5094,  2.9151,  4.5747,  5.2663,
          5.7028,  5.3951],
        [-0.4045, -0.2552, -0.2193, -0.0455, -0.2098, -0.0537, -0.0461, -0.2818,
         -0.7233, -0.2967],
        [ 4.5269,  3.7888,  3.3962,  4.7487,  3.3692,  2.0955,  3.4653,  4.3480,
          3.9144,  4.5362],
        [ 0.7707,  0.6629,  0.6046,  0.8230,  0.5843,  0.1985,  0.3206,  0.6923,
          0.9873,  0.7110],
        [-3.9130, -2.6887, -2.2337, -3.8437, -2.5164, -0.6514, -3.4346, -2.5705,
         -2.9521, -3.0575],
        [-0.4044, -0.2552, -0.2193, -0.0455, -0.2098, -0.0537, -0.0461, -0.2818,
         -0.7233, -0.2966]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-7.9994, -9.5456, -8.4064, -8.8620, -9.7348, -1.7152, -8.6683,  4.5188,
         7.8383, -1.7157], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-2.6988, -9.1561, -3.3649, -6.3513, -9.8898,  0.0213, -4.4942,  8.6385,
          7.9110,  0.0213]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -2.5854,   7.2608],
        [  0.7076,  -1.0305],
        [  2.8758,  10.6792],
        [-18.6513,  -5.7220],
        [ 13.5824,   2.5604],
        [ -1.2448,   1.1641],
        [  1.6120,   1.6824],
        [-21.0453,  -6.3902],
        [ 12.2835,   0.9170],
        [-18.0195,  -4.8001]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-1.0996, -0.3980,  8.8017, -4.3003, -5.8281, -1.3387, -2.3030, -4.4758,
        -8.2848,  1.0982], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 1.2930e+00, -8.4142e-03,  6.1673e-01,  1.7993e+00, -1.5231e+00,
          1.1490e+00,  1.0807e+00,  1.8580e+00, -9.3759e-01,  2.0284e+00],
        [-4.5242e+00,  7.6347e-01,  2.9730e+00,  4.3361e+00, -9.1730e-01,
          1.5210e-01,  1.0987e+00,  3.6840e+00,  3.1226e-01, -4.4937e-01],
        [ 3.8435e-02,  3.2701e+00, -3.2564e+01,  1.5839e+01, -6.5999e+00,
         -5.8983e+00, -6.2292e+00,  2.4507e+01, -5.2795e+00,  4.8598e+00],
        [ 1.1853e+00, -3.7293e-01,  5.0095e-01,  1.4985e+00, -1.5172e+00,
          1.0580e+00,  9.9023e-01,  1.5701e+00, -9.3970e-01,  1.7751e+00],
        [-5.1979e-02, -1.3091e+00,  1.4794e+01,  1.4774e+01,  4.3349e+00,
          1.4117e+00, -2.8486e-01,  1.8311e+01,  5.5943e+00, -2.2853e+00],
        [-3.2382e-01,  1.7080e-01, -3.6709e+00, -9.3917e-01, -2.1358e+00,
          3.4740e-01,  4.9739e-01, -1.0424e+00, -2.0369e+00,  3.9715e-01],
        [-1.2512e+00, -3.1285e-01, -1.2887e+00, -1.9809e-01, -3.5238e-02,
         -7.4804e-01, -8.4402e-01, -2.1178e-01, -3.5362e-01, -1.3510e+00],
        [ 1.4250e+00,  5.9852e-01,  7.4816e-01,  2.1304e+00, -1.6044e+00,
          1.2434e+00,  1.1789e+00,  2.1790e+00, -1.0019e+00,  2.3028e+00],
        [-5.5574e-01,  1.0228e+00, -2.3783e+01,  3.2294e+00, -5.8856e+00,
          4.4951e-01, -4.3320e-01,  3.9346e+00, -3.1731e+00,  1.0991e+01],
        [-4.1001e-03,  2.6434e+00, -4.4745e+01, -4.9229e+00, -2.6918e+00,
         -2.0215e+00, -2.8859e+00, -7.5993e+00, -2.9496e+00, -1.3407e+00]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-6.0014, -6.6768, -7.9119, -6.0045, -4.5863, -5.1204, -5.6233, -5.9164,
        -2.4195, -2.3388], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[  0.8346,   3.9146,  16.4650,   0.6661,   0.3692,  -1.6637,  -0.7407,
           1.0223,  -7.4476,  -3.3762],
        [ -0.7603,  -3.5179, -16.4890,  -0.7313,  -0.3979,   1.5341,   0.7988,
          -0.9278,   7.2532,   2.9301]], device='cuda:0'))])
loaded xi:  -34.92381
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 928.0406076148151
W_T_median: 802.9397371901745
W_T_pctile_5: -89.8203597709638
W_T_CVAR_5_pct: -242.54788524615043
-----------------------------------------------
new min fval from sgd:  -1268.554531406869
min fval:  -1268.554531406869
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 386.8026461806521
W_T_median: 210.35874731530794
W_T_pctile_5: -34.75607916934724
W_T_CVAR_5_pct: -64.31127316124301
Average q (qsum/M+1):  51.30335260206653
Optimal xi:  [-34.92381]
Expected(across Rb) median(across samples) p_equity:  0.2731228490670522
obj fun:  tensor(-1268.5545, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 5.0
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ 8.9990, -0.3262],
        [ 9.8876, -0.4440],
        [ 9.4356, -0.5183],
        [ 9.7646, -4.6575],
        [ 8.9441, -0.4609],
        [ 0.3071, -7.9568],
        [ 8.7874, -0.5348],
        [-6.7191, -8.6281],
        [ 8.0896, -6.6798],
        [ 9.3436, -0.4676]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-8.3322, -7.9010, -7.8695, -5.6807, -8.1613, -6.3807, -8.2523, -6.3050,
        -6.0354, -7.9570], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ 0.3758,  0.6926,  0.5690,  0.8044,  0.3903,  0.5214,  0.3247,  0.5116,
          0.7126,  0.5315],
        [ 2.7444,  5.4900,  3.4247,  4.6953,  2.8366,  4.3708,  2.5155,  5.5614,
          4.7626,  3.3188],
        [ 2.9186,  5.9124,  3.6715,  4.7250,  2.8336,  4.5040,  2.7602,  5.4868,
          5.0707,  3.3905],
        [ 2.9834,  6.0099,  3.6442,  5.2626,  2.9586,  5.5675,  2.7053,  6.6458,
          5.7662,  3.5071],
        [ 2.9057,  5.9133,  3.5257,  4.7828,  2.8734,  4.5245,  2.8143,  5.4756,
          5.0249,  3.5348],
        [ 3.0205,  5.9295,  3.6933,  5.0304,  3.0448,  4.9405,  2.7271,  6.2282,
          5.5398,  3.5624],
        [ 2.9056,  6.0650,  3.6122,  5.2804,  2.9497,  5.7353,  2.7194,  6.8885,
          5.8421,  3.4720],
        [ 0.3890,  0.7511,  0.6053,  0.8280,  0.4049,  0.5395,  0.3345,  0.6620,
          0.7597,  0.5626],
        [ 0.3877,  0.7486,  0.6033,  0.8252,  0.4036,  0.5374,  0.3334,  0.6595,
          0.7571,  0.5607],
        [-0.1744, -0.3843, -0.2829, -0.4794, -0.1638, -0.2872, -0.1176, -0.2960,
         -0.4880, -0.2616]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([ 4.9646, -9.3253, -9.2669, -8.5739, -9.2580, -8.8415, -8.4978,  4.4932,
         4.4795, -2.0682], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 7.4341, -5.2359, -5.8376, -7.5516, -5.9498, -6.8216, -7.5259,  5.0033,
          4.9051, -0.0246]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 8.4683e+00, -2.0167e-01],
        [ 1.1353e+01,  2.8206e+00],
        [ 3.2721e-01,  1.1209e+01],
        [-1.0832e+01, -4.6031e+00],
        [ 1.1318e+01,  2.8317e+00],
        [-1.1295e+01, -4.5147e+00],
        [ 9.0600e+00,  5.6569e+00],
        [-9.4756e+00,  4.3600e-03],
        [-1.0676e+01, -3.2558e+00],
        [ 5.9589e+00,  8.3174e+00]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-9.1974, -0.7285,  9.6826,  0.3683, -0.7407, -3.7073,  8.4888,  7.3284,
        -0.7428,  5.7239], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-3.8248e+00, -3.7009e+00, -1.6972e+01,  9.6545e+00, -3.2806e+00,
          1.4198e+00, -6.0537e+00,  6.0587e+00,  5.5822e+00, -1.2052e+01],
        [ 2.6859e-01,  1.5936e+00,  3.1093e+01, -1.0472e+01,  1.1667e+00,
          4.3199e-02,  2.5539e+00, -4.4719e+00, -8.1149e+00,  1.4017e+00],
        [-1.6968e+00, -2.7066e+00, -9.5378e-01, -5.5234e-01, -3.2704e+00,
         -2.8383e-03, -5.7126e-01, -2.6409e+00, -7.5603e-02,  4.3110e-02],
        [ 2.3349e-01, -2.3148e+00, -1.3560e+00,  2.1443e-01, -2.7326e+00,
         -2.1235e-02, -7.6739e-01, -2.4080e+00,  1.9538e-01, -7.5645e-01],
        [ 2.9510e-01, -2.1712e+00, -7.2625e-01, -1.7381e-01, -2.1573e+00,
         -5.5465e-02, -1.8791e+00, -1.8790e+00, -9.4138e-03, -1.0685e+00],
        [-4.7655e-01, -4.2180e+00,  8.1559e-01,  1.5024e+00, -4.1929e+00,
          3.4347e+00, -2.0415e+00,  2.6442e-01,  2.0524e+00, -1.3025e+00],
        [ 3.0924e-01, -1.4373e+00,  2.4077e+00,  4.6505e-02, -1.4234e+00,
         -2.1666e+00, -8.2834e-01,  1.1130e+00, -1.9177e+00,  1.1523e+00],
        [-6.1451e-01, -3.1931e+00,  1.0854e+00,  1.7979e+00, -3.1592e+00,
          3.8853e+00, -1.6575e+00,  6.4426e-01,  2.3141e+00, -1.0119e+00],
        [-2.3635e+00, -3.2829e+00, -2.1386e+00, -1.1463e+00, -3.3565e+00,
         -5.2687e-03,  2.0511e-01, -2.6414e+00, -8.6978e-02,  8.3263e-01],
        [-9.5220e+00, -1.4338e+01, -9.6207e+00,  1.4071e+01, -1.3813e+01,
          9.6557e+00, -1.9712e+01,  7.2483e+00,  1.2334e+01, -2.4767e+01]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([ 0.1687, -2.3780, -3.8904, -3.1639, -2.9617, -3.8232, -2.7553, -3.5565,
        -4.0998, -2.6698], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ -5.3770,   0.3848,  -0.2549,   0.4640,   0.2330,   1.2895,   1.1011,
           1.1877,  -0.4883,  19.8035],
        [  5.0610,  -0.4228,   0.2550,  -0.4232,  -0.2349,  -1.2884,  -1.0997,
          -1.1954,   0.6205, -19.8532]], device='cuda:0'))])
loaded xi:  -19.891674
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 928.0406076148151
W_T_median: 802.9397371901745
W_T_pctile_5: -89.8203597709638
W_T_CVAR_5_pct: -242.54788524615043
-----------------------------------------------
new min fval from sgd:  -1029.460777641933
min fval:  -1029.460777641933
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 361.9915821760751
W_T_median: 214.34012579233408
W_T_pctile_5: -16.475066752127344
W_T_CVAR_5_pct: -51.74536717296096
Average q (qsum/M+1):  50.46403651083669
Optimal xi:  [-19.891674]
Expected(across Rb) median(across samples) p_equity:  0.24053234358628592
obj fun:  tensor(-1029.4608, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 10.0
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ 11.6314,  -0.2897],
        [ 13.2417,  -0.9717],
        [ 12.3730,  -0.5825],
        [ 11.9187,  -4.5346],
        [ 10.4544,  -1.3441],
        [  3.2864,  -9.9393],
        [  7.8609,  -1.8931],
        [ -5.4921, -10.4610],
        [ 11.6343,  -6.4624],
        [ 12.2338,  -0.4644]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-10.9866,  -9.8536, -10.3358,  -7.4637, -11.0888,  -7.6733, -10.1109,
         -7.4684,  -6.9133, -10.4773], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ 2.7863e-01,  1.0043e+00,  6.3554e-01,  7.1674e-01,  4.7085e-02,
          5.3504e-01,  4.4278e-03,  4.0172e-01,  9.6761e-01,  5.6390e-01],
        [ 7.6477e-01,  4.5708e+00,  2.2941e+00,  2.8896e+00, -1.2194e-02,
          3.9563e+00,  3.8295e-03,  4.7840e+00,  3.7086e+00,  2.0915e+00],
        [ 3.0067e+00,  7.4336e+00,  4.5036e+00,  4.7178e+00,  1.3336e+00,
          6.0289e+00,  1.3713e-01,  7.2708e+00,  5.7853e+00,  4.1883e+00],
        [ 3.6208e+00,  8.0840e+00,  4.9214e+00,  5.7345e+00,  2.5307e+00,
          7.3484e+00,  1.1371e+00,  7.5948e+00,  7.2115e+00,  4.7052e+00],
        [ 3.0697e+00,  7.4951e+00,  4.4403e+00,  4.8122e+00,  1.4361e+00,
          6.0753e+00,  1.7197e-01,  7.2914e+00,  5.7914e+00,  4.3590e+00],
        [ 3.8423e+00,  8.2761e+00,  5.2128e+00,  5.5633e+00,  2.6934e+00,
          6.0728e+00,  1.1233e+00,  7.5004e+00,  6.5408e+00,  4.9937e+00],
        [ 3.5561e+00,  8.1352e+00,  4.8944e+00,  5.7559e+00,  2.5161e+00,
          7.5124e+00,  1.1253e+00,  7.7566e+00,  7.2533e+00,  4.6754e+00],
        [ 2.5924e-01,  9.3430e-01,  5.8953e-01,  6.6339e-01,  4.4025e-02,
          4.8732e-01,  3.5796e-03,  3.6400e-01,  8.9722e-01,  5.2280e-01],
        [ 2.5821e-01,  9.3065e-01,  5.8713e-01,  6.6055e-01,  4.3864e-02,
          4.8485e-01,  3.5361e-03,  3.6209e-01,  8.9347e-01,  5.2066e-01],
        [-1.6834e-01, -5.2437e-01, -3.3995e-01, -4.8008e-01, -8.9842e-04,
         -2.3232e-01,  2.7835e-03, -8.1077e-02, -7.1713e-01, -3.1908e-01]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([  4.7617,  -9.1319, -10.1226,  -9.4424, -10.1314, -10.0463,  -9.4261,
          4.4397,   4.4230,  -2.1670], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 6.5662, -3.0873, -5.7367, -9.0906, -5.8724, -8.0791, -9.0884,  4.2112,
          4.1157,  0.0174]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  9.9768,  -1.7313],
        [ 11.0757,   5.6272],
        [ -1.9518,  12.9735],
        [-13.2575,  -3.9810],
        [  1.5680,   3.2732],
        [-16.5229,  -5.5015],
        [ 11.3249,   3.5764],
        [-12.3339,  -0.2640],
        [-13.0272,  -4.1540],
        [  7.9576,   9.2124]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-13.1025,  -2.5910,  11.1286,  -0.3701, -10.6108,  -3.0541,   7.5880,
          9.9574,  -1.8873,   6.6914], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-4.0507e+00, -2.4776e+00, -2.4870e+01,  8.8998e+00, -6.3270e-03,
          5.8997e+00, -6.3410e+00,  5.4198e+00,  1.0631e+01, -5.6814e+00],
        [ 2.6771e+00, -1.6607e-01,  2.5331e+01, -1.4496e+01,  4.0303e-02,
          7.0570e+00,  3.0493e+00, -3.8980e+00, -8.5215e+00,  2.4753e+00],
        [-4.8715e-01, -9.8232e-01, -3.5298e-01,  1.4505e-01, -2.3684e-01,
          1.5661e-02, -3.8669e+00, -2.1466e+00,  3.3752e-02, -1.8114e+00],
        [-6.4101e-01, -6.8396e-01, -5.6381e-01, -1.5424e-01, -4.9646e-02,
         -3.6681e-02, -3.5989e+00, -1.0451e+00, -6.7667e-02, -1.4801e+00],
        [-4.8355e+00, -3.9095e+00, -7.1327e+00,  1.7625e+00, -3.5288e-03,
          1.3699e+00, -2.6370e+00,  2.2759e+00,  2.3090e+00, -1.1521e+00],
        [-4.7752e-01, -8.9377e-01, -5.1736e-01, -1.4831e-01, -4.5413e-01,
         -3.1337e-02, -3.6832e+00, -1.4922e+00, -6.1384e-02, -1.4150e+00],
        [ 2.9097e+00, -1.4325e+00,  2.7689e+00,  3.9229e-01, -2.8506e+00,
          6.0070e+00, -2.7235e+00,  9.3873e-01,  1.4047e+00,  3.8985e-01],
        [-4.7811e-01, -8.9367e-01, -5.1797e-01, -1.4849e-01, -4.5423e-01,
         -3.1364e-02, -3.6641e+00, -1.4913e+00, -6.1437e-02, -1.4149e+00],
        [-4.2229e+00, -1.0010e+00,  3.2034e+00,  2.5719e-01, -4.4662e+00,
          1.5013e+00, -1.4950e+00,  5.7361e-01,  4.6709e-01,  8.4347e-01],
        [-1.2768e+01, -2.0849e+00, -4.5121e+00,  1.4111e+01,  5.5664e-03,
          1.4339e+01, -2.0286e+01,  8.5591e+00,  1.1622e+01, -4.2144e+01]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-0.1627, -1.8750, -3.8852, -4.0696, -2.9022, -3.6868, -4.6414, -3.7057,
        -4.3813, -3.6383], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ -6.3696,   0.3957,   0.1471,  -0.0970,  -3.1987,  -0.0905,   0.6639,
          -0.0907,   1.8041,  20.7586],
        [  6.0596,  -0.4337,  -0.1471,   0.1065,   3.1982,   0.0905,  -0.6626,
           0.0903,  -1.7583, -20.7978]], device='cuda:0'))])
loaded xi:  -6.4342847
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 928.0406076148151
W_T_median: 802.9397371901745
W_T_pctile_5: -89.8203597709638
W_T_CVAR_5_pct: -242.54788524615043
-----------------------------------------------
new min fval from sgd:  -894.3373274641217
min fval:  -894.3373274641217
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 365.1524204973921
W_T_median: 215.712136191748
W_T_pctile_5: 0.00010873169577543252
W_T_CVAR_5_pct: -39.60041562622977
Average q (qsum/M+1):  49.809223790322584
Optimal xi:  [-6.4342847]
Expected(across Rb) median(across samples) p_equity:  0.2150485645979643
obj fun:  tensor(-894.3373, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 15.0
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ 11.6026,  -0.0385],
        [ 13.4272,  -1.0897],
        [ 12.5133,  -0.5929],
        [ 12.2025,  -4.3618],
        [ 10.1553,  -1.3273],
        [  3.6277, -10.0658],
        [  7.2653,  -1.7152],
        [ -5.8051, -10.6109],
        [ 11.4751,  -6.2097],
        [ 12.3121,  -0.3863]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-11.3089,  -9.7025, -10.2737,  -7.2865, -11.1604,  -7.7172,  -9.8553,
         -7.6222,  -6.6806, -10.5459], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ 2.1137e-01,  9.2848e-01,  5.6036e-01,  7.5487e-01,  3.1167e-02,
          6.7372e-01,  2.3643e-02,  4.0628e-01,  1.0279e+00,  4.7454e-01],
        [ 9.3053e-01,  5.2677e+00,  2.8029e+00,  3.6603e+00, -1.4245e-02,
          4.6772e+00, -2.1817e-02,  6.1526e+00,  3.9219e+00,  2.5258e+00],
        [ 2.7424e+00,  7.4035e+00,  4.4989e+00,  5.0721e+00,  8.8049e-01,
          5.9048e+00,  5.7481e-02,  7.7585e+00,  5.4242e+00,  4.1259e+00],
        [ 3.5025e+00,  8.1420e+00,  4.9719e+00,  6.2504e+00,  2.2551e+00,
          7.3875e+00,  1.0437e+00,  7.9642e+00,  6.9441e+00,  4.7005e+00],
        [ 2.8011e+00,  7.4560e+00,  4.4260e+00,  5.1559e+00,  9.6533e-01,
          5.9454e+00,  7.5976e-02,  7.7668e+00,  5.4213e+00,  4.2945e+00],
        [ 3.6990e+00,  8.3003e+00,  5.2444e+00,  6.0669e+00,  2.2993e+00,
          5.7757e+00,  8.9717e-01,  7.8949e+00,  6.1470e+00,  4.9736e+00],
        [ 3.4650e+00,  8.2199e+00,  4.9678e+00,  6.2766e+00,  2.2665e+00,
          7.5228e+00,  1.0575e+00,  8.1175e+00,  6.9922e+00,  4.6924e+00],
        [ 1.9704e-01,  8.5737e-01,  5.1587e-01,  6.9769e-01,  2.9553e-02,
          6.1612e-01,  2.3172e-02,  3.6527e-01,  9.5597e-01,  4.3690e-01],
        [ 1.9627e-01,  8.5365e-01,  5.1354e-01,  6.9461e-01,  2.9467e-02,
          6.1310e-01,  2.3145e-02,  3.6313e-01,  9.5209e-01,  4.3493e-01],
        [-8.1591e-02, -5.1523e-01, -2.8117e-01, -7.4286e-01, -1.5860e-02,
         -3.1740e-01, -4.2405e-03, -9.9228e-02, -9.0872e-01, -2.3219e-01]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([  4.8939,  -9.7490, -10.3861,  -9.2830, -10.3885, -10.1868,  -9.2961,
          4.5637,   4.5465,  -2.4845], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 6.4632, -3.6368, -5.7664, -9.0061, -5.8887, -7.9789, -9.0702,  4.0934,
          3.9973, -0.0147]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  9.3064,  -2.3301],
        [  2.8814,   2.8181],
        [ -1.0525,  13.9248],
        [-13.8648,  -4.2382],
        [ 11.3725,   4.6418],
        [-18.5534,  -4.8556],
        [  6.8503,   3.3448],
        [-13.2014,  -0.8499],
        [-12.8850,  -4.4040],
        [  7.8974,   9.1457]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-12.9798,  -8.6654,  11.2610,  -0.7848,  -0.3500,  -4.0627,   7.6157,
          7.9000,  -2.4802,   6.7748], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-1.3512e+00, -9.2007e-02, -7.4504e-01,  1.9368e+00, -7.6229e-01,
         -1.4027e-01, -6.4734e+00,  1.5611e+00,  1.9378e+00, -2.0071e+00],
        [ 4.5286e+00,  1.8080e+00, -1.4686e+00, -1.6508e+00,  2.4050e+00,
         -2.5202e+00,  5.2349e+00, -1.6666e+00, -3.9126e+00,  2.2961e+00],
        [-1.6871e+01, -8.8356e-02, -1.3326e+01,  7.8785e+00, -1.2770e+01,
          2.6134e+01, -4.2604e+00,  1.7869e+00,  1.4167e+01, -3.1272e+01],
        [-3.0552e+00, -1.7739e+00, -2.2736e+01,  7.4459e+00, -3.7213e+00,
          3.7495e+00, -1.5877e+00,  5.1324e+00,  1.1143e+01, -1.0584e+01],
        [ 4.2410e+00,  1.9494e-01,  1.2508e+01, -1.4008e+00,  1.1575e+00,
          1.1401e+01,  3.3310e-02, -6.1971e-01, -1.0102e+01,  2.0127e+00],
        [-7.5433e-01, -6.8867e-02, -3.4704e-01, -8.9646e-02, -2.2054e+00,
          6.8109e-03, -3.4069e+00, -1.0035e+00, -3.3870e-02, -1.1832e+00],
        [-2.1416e+00, -2.5129e+00,  2.5380e+00, -1.5067e+00, -2.5470e+00,
         -1.0961e-01, -3.1477e+00,  4.9534e-01, -1.5689e+00, -4.7544e-01],
        [-8.0943e+00, -2.6080e+00,  3.1038e+00,  6.3377e-01, -8.9048e-01,
         -1.1298e+00, -2.2101e+00,  1.5198e+00,  4.5456e-01,  1.5590e+00],
        [ 1.8911e+00, -1.1370e-01, -2.5487e+00, -7.0253e+00, -1.8087e+00,
          8.6970e-03, -3.4781e+00, -9.2077e-01, -1.9457e+00,  1.3388e+00],
        [-4.4752e+00, -1.5415e-04, -1.9197e+00,  1.3039e+01, -3.6170e+00,
          4.9368e+00, -1.9765e+01,  6.4549e+00,  1.0456e+01, -1.7667e+01]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-2.6073,  0.7836, -4.4060, -1.8561,  0.0145, -3.4142, -4.9917, -3.9965,
        -4.2194, -4.0646], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ -0.0771,  -2.1022,  18.6155,  -7.4481,   2.5088,   0.0326,   0.9931,
           1.4001,  -1.7345,   8.6590],
        [ -0.1474,   2.0642, -18.6097,   7.4564,  -2.5093,  -0.0326,  -0.9919,
          -1.4066,   1.7486,  -8.6829]], device='cuda:0'))])
loaded xi:  -6.3948145
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 928.0406076148151
W_T_median: 802.9397371901745
W_T_pctile_5: -89.8203597709638
W_T_CVAR_5_pct: -242.54788524615043
-----------------------------------------------
new min fval from sgd:  -441.48519692159056
min fval:  -441.48519692159056
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 350.22979568351343
W_T_median: 208.10477355285676
W_T_pctile_5: 0.00048292426489275896
W_T_CVAR_5_pct: -39.48366015207412
Average q (qsum/M+1):  49.392845892137096
Optimal xi:  [-6.3948145]
Expected(across Rb) median(across samples) p_equity:  0.19185050061593453
obj fun:  tensor(-441.4852, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 25.0
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ 10.9154,  -0.5983],
        [ 13.6136,  -0.7034],
        [ 12.4750,  -0.4469],
        [ 13.1891,  -3.7132],
        [  9.7734,  -1.3903],
        [  4.2067,  -9.9019],
        [  6.2015,  -1.3933],
        [ -4.8473, -10.4710],
        [ 11.1649,  -6.2674],
        [ 12.2183,  -0.2917]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-11.3475,  -9.4763, -10.1918,  -7.2397, -10.9839,  -7.4858,  -9.4579,
         -7.5051,  -6.8860, -10.4707], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-1.8978e-02,  8.6224e-01,  3.9752e-01,  9.1363e-01,  2.1009e-02,
          5.3543e-01,  8.0042e-03,  5.7332e-01,  1.0872e+00,  3.1581e-01],
        [ 3.9040e-01,  5.9300e+00,  3.0022e+00,  4.4502e+00,  4.3242e-02,
          5.1986e+00, -2.9609e-02,  6.4985e+00,  4.1389e+00,  2.7041e+00],
        [ 1.7596e+00,  7.4133e+00,  4.1539e+00,  5.5476e+00,  5.6459e-01,
          6.1083e+00, -3.0439e-02,  7.3828e+00,  5.1838e+00,  3.7487e+00],
        [ 2.8951e+00,  8.2790e+00,  4.7261e+00,  6.7432e+00,  2.1513e+00,
          7.3516e+00,  8.0163e-01,  7.6641e+00,  6.7918e+00,  4.3940e+00],
        [ 1.8448e+00,  7.4725e+00,  4.0845e+00,  5.6413e+00,  6.4640e-01,
          6.1620e+00, -2.5839e-02,  7.3917e+00,  5.1785e+00,  3.9254e+00],
        [ 2.9733e+00,  8.3635e+00,  4.9218e+00,  6.5222e+00,  2.1161e+00,
          6.1808e+00,  6.0960e-01,  7.4273e+00,  6.0933e+00,  4.5929e+00],
        [ 2.8508e+00,  8.3523e+00,  4.7111e+00,  6.7561e+00,  2.1627e+00,
          7.5632e+00,  8.2044e-01,  7.8627e+00,  6.7664e+00,  4.3760e+00],
        [-2.1653e-02,  7.9061e-01,  3.5916e-01,  8.5098e-01,  2.0692e-02,
          4.8439e-01,  6.6454e-03,  5.2096e-01,  1.0177e+00,  2.8440e-01],
        [-2.1799e-02,  7.8682e-01,  3.5714e-01,  8.4757e-01,  2.0667e-02,
          4.8166e-01,  6.5764e-03,  5.1821e-01,  1.0140e+00,  2.8274e-01],
        [-2.7265e-02, -6.7636e-01, -2.4679e-01, -9.6473e-01,  9.2540e-04,
         -4.6049e-01,  8.7915e-04, -3.9080e-01, -8.7126e-01, -2.0617e-01]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([  5.1289,  -9.8758, -10.1032,  -9.1254, -10.0988,  -9.7557,  -9.1419,
          4.7851,   4.7671,  -2.7878], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 6.4020, -4.3298, -5.9381, -9.3164, -6.0680, -8.1516, -9.3756,  4.0111,
          3.9143, -0.0254]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  9.4865,  -1.4573],
        [ 11.9770,   3.7032],
        [ -1.6203,  12.6666],
        [-13.4810,  -3.8548],
        [ 11.7195,   3.6383],
        [-17.7701,  -4.5590],
        [ 12.3988,   3.7599],
        [-11.9848,  -0.1302],
        [-12.7173,  -3.9863],
        [  7.2744,   9.8430]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-12.4951,  -0.5528,  10.7395,   0.2021,  -1.6199,  -3.0895,   7.1058,
          9.3862,  -2.1188,   7.5325], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-4.4770e+00, -5.8279e+00, -1.7536e+01,  6.1870e+00, -4.9689e+00,
          3.2538e+00, -7.5786e+00,  5.2838e+00,  3.3376e+00, -3.8138e+00],
        [ 2.1895e+00,  1.5168e+00,  2.4494e+01, -5.5321e+00,  1.1059e+00,
          2.1251e+00,  1.8586e+00, -4.2269e+00, -1.3312e+01,  2.5208e+00],
        [-1.1109e+00, -3.1665e+00,  2.4849e+00,  1.3587e+00, -2.8139e+00,
          4.9614e+00, -2.4620e+00, -6.8506e-01,  2.9939e+00, -5.9635e-01],
        [-9.8457e-01, -2.8095e+00,  1.7377e+00,  7.5235e-01, -2.5107e+00,
          3.2864e+00, -2.9125e+00, -1.1490e+00,  1.8523e+00, -9.6391e-01],
        [-3.3624e+00, -1.1490e+00, -1.4323e+01,  6.1301e+00, -1.0438e+00,
          3.7013e+00, -1.7142e+00,  3.8081e+00,  7.0065e+00, -6.7106e+00],
        [-5.9908e-01, -2.2951e+00, -2.1115e-01, -3.3158e-01, -2.1633e+00,
         -4.1007e-02, -2.8520e+00, -1.5619e+00, -1.3794e-01, -1.0137e+00],
        [ 6.2490e+00, -1.7331e+00,  6.4802e+00,  1.1358e-01, -1.7421e+00,
          2.4338e+00, -2.4013e+00,  3.8091e+00, -4.9717e+00,  2.2417e+00],
        [-5.3498e+00, -6.6162e+00, -1.0462e+01,  7.8203e+00, -6.6897e+00,
          2.2445e+01, -3.4652e+00,  1.5351e+00,  1.5530e+01, -3.9043e+01],
        [-1.8678e-02, -2.4028e+00, -8.0859e-01, -3.0053e-01, -2.1696e+00,
         -1.7016e-01, -3.1389e+00,  4.0935e-02, -1.2229e-01, -1.7272e+00],
        [-6.4395e-01, -1.4445e+01, -3.2766e+00,  1.3692e+01, -1.4102e+01,
          1.2560e+01, -2.0071e+01,  7.9806e+00,  1.2544e+01, -2.8348e+01]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-1.4246, -3.0714, -2.4555, -2.9074, -1.7177, -2.8530, -4.3277, -5.2134,
        -3.1418, -3.2980], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-5.1248e+00,  3.8384e-01,  1.8929e+00,  8.2970e-01, -6.9625e+00,
         -1.0656e-02,  3.2500e-01,  1.5460e+01, -1.8395e-01,  1.8114e+01],
        [ 4.8178e+00, -4.2192e-01, -1.8929e+00, -8.2956e-01,  6.9627e+00,
          1.0669e-02, -3.2367e-01, -1.5464e+01,  1.8440e-01, -1.8154e+01]],
       device='cuda:0'))])
loaded xi:  -5.632744
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 928.0406076148151
W_T_median: 802.9397371901745
W_T_pctile_5: -89.8203597709638
W_T_CVAR_5_pct: -242.54788524615043
-----------------------------------------------
new min fval from sgd:  634.3315504422017
min fval:  634.3315504422017
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 394.3909026425461
W_T_median: 257.6739114545083
W_T_pctile_5: 0.0009032444942146612
W_T_CVAR_5_pct: -39.25018000430771
Average q (qsum/M+1):  48.875586725050404
Optimal xi:  [-5.632744]
Expected(across Rb) median(across samples) p_equity:  0.2072712391614914
obj fun:  tensor(634.3316, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 50.0
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ 0.1317, -0.2080],
        [ 0.1317, -0.2080],
        [ 0.1317, -0.2080],
        [ 0.1317, -0.2080],
        [ 0.1317, -0.2080],
        [ 0.1317, -0.2080],
        [ 0.1317, -0.2080],
        [ 0.1317, -0.2080],
        [ 0.1317, -0.2080],
        [ 0.1317, -0.2080]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([0.2273, 0.2273, 0.2273, 0.2273, 0.2273, 0.2273, 0.2273, 0.2273, 0.2273,
        0.2273], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456,
         0.2456],
        [0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456,
         0.2456],
        [0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456,
         0.2456],
        [0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456,
         0.2456],
        [0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456,
         0.2456],
        [0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456,
         0.2456],
        [0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456,
         0.2456],
        [0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456,
         0.2456],
        [0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456,
         0.2456],
        [0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456, 0.2456,
         0.2456]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([0.3952, 0.3952, 0.3952, 0.3952, 0.3952, 0.3952, 0.3952, 0.3952, 0.3952,
        0.3952], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-1.7531, -1.7531, -1.7531, -1.7531, -1.7531, -1.7531, -1.7531, -1.7531,
         -1.7531, -1.7531]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  9.8031,  -1.4721],
        [ 12.2990,   3.2974],
        [ -1.3735,  12.2829],
        [-13.3355,  -4.0686],
        [  7.8774,   7.9880],
        [-14.8823,  -4.8693],
        [  4.8363,   1.1052],
        [-11.6243,  -0.1569],
        [-12.4397,  -3.9719],
        [  7.6846,   8.9713]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-11.5264,  -4.5442,  10.2997,  -0.3833,  -4.6589,  -3.3811,   5.8163,
         10.2248,  -2.1789,   6.6976], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-3.1062e+00, -1.6432e+00, -2.0630e+01,  9.4600e+00,  2.3670e-02,
          5.0129e+00, -6.9224e+00,  7.3575e+00,  7.0023e+00, -5.6943e+00],
        [ 2.8034e+00,  1.0249e+00,  2.2526e+01, -1.3081e+01, -1.4814e-02,
          3.6276e+00,  2.7115e+00, -3.9387e+00, -1.8989e+00,  2.7781e+00],
        [-5.4933e-01, -1.1429e+00, -2.9868e-01, -1.2244e-01,  7.2203e-02,
         -3.2431e-02, -2.4612e+00, -1.3993e+00, -4.8906e-02, -9.2263e-01],
        [-5.5246e-01, -1.1461e+00, -2.9992e-01, -1.2342e-01,  7.2060e-02,
         -3.2723e-02, -2.4579e+00, -1.3968e+00, -4.9402e-02, -9.2491e-01],
        [-5.4690e-01, -1.1400e+00, -2.9758e-01, -1.2155e-01,  7.2336e-02,
         -3.2189e-02, -2.4633e+00, -1.4028e+00, -4.8493e-02, -9.2111e-01],
        [-5.3850e-01, -1.1312e+00, -2.9587e-01, -1.1937e-01,  7.2552e-02,
         -3.1636e-02, -2.4710e+00, -1.4085e+00, -4.7581e-02, -9.1539e-01],
        [ 2.8874e+00, -3.0003e+00,  6.0043e+00, -7.3770e-01,  9.1971e-01,
          4.1934e+00, -2.9448e+00,  3.0577e+00,  2.7602e+00,  1.2433e+00],
        [-5.5083e-01, -1.1445e+00, -2.9874e-01, -1.2272e-01,  7.2207e-02,
         -3.2523e-02, -2.4595e+00, -1.4004e+00, -4.9050e-02, -9.2352e-01],
        [-5.3875e-01, -1.1315e+00, -2.9596e-01, -1.1945e-01,  7.2539e-02,
         -3.1652e-02, -2.4709e+00, -1.4080e+00, -4.7609e-02, -9.1556e-01],
        [-5.7069e+00, -7.1318e-01, -5.5678e+00,  1.3053e+01, -1.0203e-02,
          1.0547e+01, -1.6362e+01,  7.7176e+00,  1.0953e+01, -2.6905e+01]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-0.8836, -2.1125, -2.4618, -2.4595, -2.4639, -2.4716, -4.8326, -2.4601,
        -2.4715, -2.8249], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ -5.8658,   0.3860,  -0.0695,  -0.0699,  -0.0690,  -0.0683,   0.6403,
          -0.0696,  -0.0683,  12.2162],
        [  5.5842,  -0.4240,   0.0695,   0.0702,   0.0690,   0.0683,  -0.6390,
           0.0696,   0.0684, -12.2215]], device='cuda:0'))])
loaded xi:  -3.5765848
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 928.0406076148151
W_T_median: 802.9397371901745
W_T_pctile_5: -89.8203597709638
W_T_CVAR_5_pct: -242.54788524615043
-----------------------------------------------
new min fval from sgd:  41.92621309032699
min fval:  41.92621309032699
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 931.8849209880442
W_T_median: 813.3035006153654
W_T_pctile_5: 95.02789229685482
W_T_CVAR_5_pct: -8.25645336675172
Average q (qsum/M+1):  35.0
Optimal xi:  [-3.5765848]
Expected(across Rb) median(across samples) p_equity:  0.1767326857894659
obj fun:  tensor(41.9262, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 999.0
-----------------------------------------------
