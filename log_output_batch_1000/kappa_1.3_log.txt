Starting at: 
2022-06-17 22:26:16
tracing parameter entered from terminal:  1.3


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2542.401157614462
gradient value of function right now is: [-1.43152018e-02 -2.13228783e-01 -2.51085671e-03 -2.39891315e-03
  1.43152018e-02  2.13228783e-01  2.51085671e-03  2.39891315e-03
  2.20182194e-01 -3.95977366e-03 -3.61742271e-02  2.38742448e-01
  5.68935731e-01  4.06893041e-05  1.34832589e-04 -3.26749532e-02
 -9.10590269e-03 -2.64047245e-03 -1.23546184e-02 -1.40679642e-02
 -9.51807330e-03 -2.70323711e-03 -1.24926937e-02 -1.42406427e-02
  8.69973050e-02  1.77198954e-03  2.61100805e-02  6.18963807e-03
 -2.65396676e-02 -4.38758243e-04 -7.53469346e-03 -1.83870783e-03
 -2.28749701e-02  1.80315162e-02 -7.47687698e-03  2.66970339e-02
  1.43566506e-01  1.67091315e-01  2.18945932e-01  4.94080722e-02
  1.43302368e-02  2.89200927e-02  3.26172273e-01  2.00695790e-02
 -7.45162874e-03 -2.03524514e-02 -2.41261155e-01 -1.09177248e-02
  2.02579474e-02  5.67083785e-02  4.31046551e-02  2.66332389e-02
  2.98413380e-03  1.72555875e-02  6.20408225e-02  4.60184274e-03
  1.25301120e-02 -7.70182293e-02  2.04325674e-01 -5.97050112e-01
 -4.36766608e-01  1.19708839e+00  3.87727308e-02 -2.52721677e-01
 -3.51356305e+00]
supnorm grad right now is: 3.51356305429668
Weights right now are: 
[-1.31718457  1.44259514 -3.11725837 -3.93545798  1.57175328 -1.55128683
  3.51619564  3.21942959  3.20028668 -2.6139166  -1.98996458 -2.67108453
  2.10556999  2.04069818  1.63349011  3.96130742  8.69384184 -3.96801606
 -1.04337792 -0.27712695  8.62073883 -4.5716225  -1.15080968  0.03317182
  1.93318753 -8.40490167 -7.43752178 -4.61010288 -0.60616186  7.92929371
  7.75440221  4.29173056 -2.12697755  6.85234613  2.20380594 -1.52908814
 -9.35536104  7.16949747  0.93451349 -5.11444426 -3.41862231 -7.30301095
  1.96623631 -7.94889867  3.42841067 11.32155212 -2.18958986  8.77256526
  0.83459476  3.55287363 -2.4967408   3.2396819   0.59297546  3.90437853
  4.44294492  1.76307643  5.02326626 -1.7410344  -1.78629209 -2.80843575
  7.57830286  2.61914315  3.82093345 -1.67431798 25.94067043]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2542.160718128822
gradient value of function right now is: [ 1.94813017e+00  1.15227602e-01 -6.21321237e-04 -8.41816026e-04
 -1.94813017e+00 -1.15227602e-01  6.21321236e-04  8.41816026e-04
  2.34995048e+00  6.05724861e-03  8.51622566e-01  2.25826312e+00
 -6.57946029e-01 -9.72480925e-06 -6.03212318e-04 -1.07275135e-02
  9.54902184e-06 -2.52127335e-03 -5.73106795e-03 -5.22870077e-03
 -7.90959151e-04 -3.21492408e-03 -7.64457155e-03 -7.41886044e-03
 -1.95982267e-02 -1.63642667e-03 -1.61148221e-02 -3.97896918e-03
  3.20054242e-03  6.41108467e-04  5.74728524e-03  1.52854805e-03
  6.86447097e-01  1.58270891e-01  4.42480936e-01  1.34452217e-01
  7.24360013e-02  6.59818701e-02  1.14750361e-01  8.25577441e-03
  1.75182414e-02  3.90942429e-02  3.38335559e-01  2.30338610e-02
 -2.51188690e-02 -9.59907949e-02 -3.77749562e-01 -3.29105183e-02
 -3.10162537e-02 -7.88568785e-02 -1.82110734e-01 -3.67670986e-02
  2.24895442e-03  4.54821670e-02  3.91136818e-02  3.50914214e-03
  7.33853651e-02 -3.70699864e-01  7.52008136e-01 -1.71459903e+00
 -4.23065213e-01  1.08731305e+00  1.60602514e-01 -7.68278262e-01
 -5.66047827e+00]
supnorm grad right now is: 5.660478273717263
Weights right now are: 
[ -1.00721913   3.05319949  -4.47888108  -5.43818158   1.26178784
  -3.16189118   4.87781835   4.7221532    3.9104524   -5.28663081
  -2.34007966  -2.58101053   2.35282417   6.45184132  -1.27863342
   7.95967959  10.34091948  -6.1330533   -0.95959196  -0.08327748
  10.26445877  -6.86549733  -1.16915685   0.1359617    2.02901367
 -17.67252686 -11.66520742  -6.80763164  -1.10356773  18.34906111
  12.76836299   7.07802452  -2.05019163   7.67786145   2.69428225
  -5.62145861 -12.47420124   9.42911999   1.25159248  -8.28995924
  -8.20658524 -12.37387242   1.858133   -12.94161661   7.46341061
  13.02533075  -1.91257512  12.73973224   3.45938294   4.0148993
  -3.67204786   4.83700117   0.27879067   6.05745822   7.97535012
   1.96039423   4.32935727  -2.4283935   -2.35829079  -3.25707287
   7.97090637   2.37304966   3.68217583  -2.26976259  26.00990909]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2541.924645099277
gradient value of function right now is: [-1.81053632e+00 -7.68324400e-02 -8.44675612e-04 -1.07096074e-03
  1.81053632e+00  7.68324400e-02  8.44675612e-04  1.07096074e-03
 -1.99658720e+00 -8.51674947e-04 -2.67749868e-01 -1.84500233e+00
  5.55443746e-01  4.25556447e-06  9.28859037e-04 -2.83659736e-03
 -6.59203696e-03 -1.31186261e-03 -5.77598869e-03 -9.36766241e-03
 -8.75821690e-03 -1.82172116e-03 -7.95961772e-03 -1.26591931e-02
  5.54550710e-02  8.11618453e-04  1.19656866e-02  1.73492427e-03
 -2.87943342e-02 -4.39664521e-04 -6.22439296e-03 -9.32541157e-04
 -4.28348127e-01 -1.57090286e-01 -3.04042864e-01 -8.35311457e-02
 -7.48944615e-02 -4.99594914e-02 -8.69310590e-02 -6.41689019e-03
 -1.69738985e-02 -6.67867969e-03 -1.66713369e-01 -2.02468655e-02
  3.40732632e-02  2.20396334e-02  2.37568697e-01  4.11573465e-02
  4.20911595e-02  4.50259695e-02  1.05168353e-01  4.88900415e-02
 -7.72590699e-03 -7.39066434e-03 -3.62803551e-02 -1.07025270e-02
 -1.79789266e-01  5.18109416e-01 -2.08061452e-01  4.01528101e-01
  4.75125718e-01 -8.98044876e-01 -3.25241665e-01  8.97669675e-01
  3.46446402e+00]
supnorm grad right now is: 3.4644640163170677
Weights right now are: 
[ -1.36005913   3.68678341  -5.77548748  -6.80002855   1.61462784
  -3.7954751    6.17442475   6.08400017   3.41612893  -8.01118849
  -3.18505653  -3.31656349   3.13123861  12.00033245 -10.72093162
  13.31416799  10.8068763   -8.26732347  -1.38674228  -0.5299219
  10.66304872  -9.06141269  -1.66434786  -0.4004112    2.81754703
 -20.91207856 -14.06869778  -7.22326378  -1.87464984  21.1241152
  15.50928167   7.08773519  -1.12726016   6.46549141   2.73003132
  -8.85403307 -14.33040698  10.7060356    1.69553877 -10.27852638
 -12.93882905 -17.30124894   1.93222889 -17.57189962   8.5743469
  12.32412696  -2.04006904  13.62478737   3.97307148   5.13906462
  -4.50232909   5.24113004   4.56666834   7.47724986  13.27741216
   7.0407532    1.95963668  -2.4375157   -1.38051052  -4.46055284
   8.22389307   2.47094445   1.56884093  -2.37334549  26.13035702]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2542.495846141402
gradient value of function right now is: [ 3.39438990e-02 -6.17926344e-02 -5.69797084e-04 -4.97569236e-04
 -3.39438990e-02  6.17926344e-02  5.69797081e-04  4.97569233e-04
  2.81905891e-01 -2.25638388e-03  6.18592876e-02  4.44552783e-01
  5.45350161e-01  3.56527554e-07  2.16376943e-04  1.01367819e-02
 -3.71465036e-03 -1.57083460e-03 -3.91829265e-03 -6.62320352e-03
 -3.38628591e-03 -1.42944493e-03 -3.54642058e-03 -5.99164802e-03
  5.96121247e-02  5.76830371e-04  1.04600602e-02  1.04497570e-03
 -4.50335017e-02 -5.17294447e-04 -8.34774127e-03 -8.90532766e-04
  1.94425755e-01  1.14100436e-01  1.68067041e-01  6.38613628e-02
 -1.24998153e-01 -1.83204875e-01 -2.14998101e-01  3.95842274e-03
 -2.72446587e-02 -6.62657687e-03 -7.74079448e-01 -2.84287914e-02
  5.92649556e-03 -1.63340427e-03  3.51524617e-01  5.89483657e-03
  3.16823378e-02  4.58496237e-02  5.29894124e-02  3.37106156e-02
  1.26116190e-03  1.28108248e-03  1.99078287e-02  1.60689470e-03
 -1.18388218e-01  7.84219241e-01 -7.95538438e-02  3.03137230e-01
 -2.28427108e-01  2.04594717e-01 -1.58793692e-01  1.06882854e+00
 -1.03713814e+00]
supnorm grad right now is: 1.0688285392029837
Weights right now are: 
[ -1.48640403   4.50867692  -6.12599933  -6.91384548   1.74097274
  -4.61736861   6.5249366    6.1978171    4.02598805 -11.42352786
  -3.63698973  -2.70991794   3.25154428  15.7748334  -12.91372555
  15.76653834  11.90902366  -8.9636331   -1.10213101  -0.09493103
  11.85018995  -9.42591368  -1.19181676   0.24220787   2.46311765
 -24.03686962 -17.01654481  -9.18440467  -1.59401761  23.90999794
  18.52145814   8.26742337  -0.68467086   8.05676808   2.85365305
  -8.92201214 -16.06289946  11.40390144   2.13331958 -14.78569978
 -17.68492239 -27.84680887   1.57497039 -22.43058517   8.23170297
  13.57873514  -2.3240548   13.09179199   3.63226614   5.10354175
  -2.8142916    4.6654677    5.99186953   4.89442276  16.67368077
   8.73259201   1.68112098  -2.28704169  -1.58363366  -3.81860555
   8.32168539   2.50647009   1.47269127  -2.28378214  25.98199485]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2543.101063095449
gradient value of function right now is: [ 8.56577524e-01 -8.34846911e-02 -2.84870943e-04 -3.23079766e-04
 -8.56577524e-01  8.34846911e-02  2.84870943e-04  3.23079766e-04
  2.55792751e-01  2.09125987e-03  2.82997108e-01  3.48839873e-01
  8.04525589e-01 -1.28545769e-05  3.93318081e-03 -2.33081610e-03
 -9.97735812e-04 -1.12939407e-03 -2.28505163e-03 -3.30244016e-03
 -1.16360945e-03 -1.32466025e-03 -2.66302278e-03 -3.85248767e-03
 -2.24869671e-03 -2.84441152e-04 -3.50988214e-03 -1.24827496e-03
  1.07793980e-02  2.76871010e-04  4.23666505e-03  1.09725670e-03
  2.68303157e-01  1.44763183e-01  1.92970468e-01  6.23363124e-02
 -8.44509530e-03  3.12443970e-03 -1.40927497e-02  7.40555002e-03
 -7.99518922e-03 -1.57744238e-03 -1.42876748e-01 -7.88940165e-03
  7.06053295e-03 -8.98598072e-03  8.32978997e-02  6.67847340e-03
  2.39437412e-03 -2.74977372e-02 -1.34844053e-03  2.08878007e-03
  2.75720260e-03  1.14479481e-02  2.57686305e-02  3.05226816e-03
 -1.90048060e-02  2.94828908e-01  2.08144373e-01 -9.20543450e-02
 -5.45172193e-01  1.15255153e+00 -1.66945796e-02  3.69054083e-01
 -5.03224852e-01]
supnorm grad right now is: 1.1525515346155757
Weights right now are: 
[ -0.89803572   4.91829284  -6.67230411  -7.59805661   1.15260443
  -5.02698453   7.07124138   6.88202823   3.99541027 -13.92379241
  -3.05518147  -2.89454039   3.53040736  20.75793714 -17.81195361
  18.56595036  12.84043543  -9.67976129  -0.95572721   0.11134574
  12.62334613 -10.20472244  -1.1477793    0.3405226    2.55283306
 -22.77634641 -19.8668283   -7.54434137  -1.3474691   21.88002553
  21.23794151   4.39244717  -1.08689827   6.46555734   1.50891034
  -8.29621725 -15.90737981  13.43089761   3.9491818  -19.58033109
 -22.44350743 -34.15904921   1.79549725 -27.1812331    9.53354298
  15.00564231  -1.69868383  14.28628653   2.14103009   4.8253442
  -2.43708136   2.94667886  10.91203765   7.67309856  19.30905601
  13.83034536   1.99167449  -2.41739092  -1.77721343  -3.80691906
   8.17055026   2.39260699   1.83641633  -2.44064312  26.18070439]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2571.389745661901
gradient value of function right now is: [-2.11649390e+00 -3.86708285e+00 -1.37442308e-05 -1.27511930e-05
  2.11649390e+00  3.86708285e+00  1.37442306e-05  1.27511928e-05
 -4.47781251e+00 -9.05207762e-02 -3.47536236e+00 -1.22119525e-01
 -7.60655921e-01 -2.48844003e-02 -7.93556269e-01 -8.07192036e-01
 -1.80356770e-04 -1.03590713e-04 -2.05602654e-04 -1.98139552e-04
 -1.61233311e-04 -8.86131628e-05 -1.80879143e-04 -1.71563818e-04
 -1.62791098e-02  4.97325937e-05 -1.41475396e-03 -1.41588958e-04
  7.22761940e-01 -4.03217180e-02  3.01848110e-01 -1.60290094e-01
  1.20869512e+00  8.07061629e-01  9.64252265e-01  6.91346163e-03
  1.33743546e+00  5.63685647e-01  8.62772723e-01 -1.43304245e-02
  1.95524967e-01  9.30827021e-02  4.71387094e+00  2.23013056e-01
 -2.65113001e-01 -1.14001941e-01 -6.26687851e+00 -3.01338156e-01
 -4.11363084e-01 -1.87500864e-01 -4.26463389e+00 -4.81887126e-01
 -2.20693446e-02 -2.18187111e-01 -3.54583612e-02 -3.98010778e-02
  1.20683322e+00 -1.52603094e+01  8.39156992e-01 -1.28510954e+01
 -2.22544991e-01  7.30115096e+00  1.85352083e+00 -2.20984549e+01
 -6.10689499e+00]
supnorm grad right now is: 22.09845488710811
Weights right now are: 
[ -2.48122336   1.40575711  -6.07087134  -6.48190029   2.73579207
  -1.5144488    6.46980861   5.7658719   -2.34522126 -11.98302468
   2.34665727   3.48073052   8.08133363  50.88658013 -24.18003643
  16.00347202  14.79461469  -8.54005944   0.41671922   1.40540106
  14.49182873  -8.84962789   0.46110211   1.86831912   1.77612609
 -21.7549129  -23.24965655  -5.54203701  -2.0882796    6.66614759
  14.05846486 -13.55226208  -5.65133098   6.88516198  -0.36028113
  -4.98111417  -9.93832172  15.11609971   8.18946444 -24.01312952
 -23.63223079 -37.79970646   2.21457457 -27.8285726   14.53791007
  23.06544597  -0.83941128  19.2537313    0.50467752   3.1123585
   0.22349464   1.05076553  11.35357214   4.2846424   23.07489917
  12.67646836   1.39315348  -1.87193651  -3.35611274  -2.61522796
   8.14592442   1.098295     0.72779419  -1.84057526  26.73038661]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -2571.2534096835775
gradient value of function right now is: [-1.75908475e+00 -3.68479254e+00  2.45724377e-03  2.59875254e-03
  1.75908475e+00  3.68479254e+00 -2.45724377e-03 -2.59875254e-03
 -4.01881605e+00  8.75330431e-01 -2.14684976e+00  2.24291364e+00
 -1.67377043e+00 -4.46647196e-02 -1.75987176e+00 -1.79204042e+00
  1.17083165e-02  2.58223690e-02  3.20050980e-02  3.20236332e-02
  1.21464939e-02  2.66107410e-02  3.30087415e-02  3.30279762e-02
  3.70466582e-02  5.35230515e-05  1.32282902e-02  2.17287868e-03
  4.66259225e+00  3.92290515e-01  1.75557522e+00  2.60453895e-01
  2.12205948e+00  1.76536801e+00  2.19020232e+00 -3.46030873e-02
  1.27568206e+00  5.50359949e-01  9.62999924e-01  5.61708585e-02
  2.10392350e-01  1.03818789e-01  5.43170246e+00  2.12536050e-01
 -2.81162264e-01 -1.85934257e-01 -6.39934550e+00 -2.86715142e-01
 -5.23548668e-01 -1.34421328e+00 -4.09416796e+00 -5.74256106e-01
  3.75100279e-02  2.47630900e-01  1.39338889e-01  4.59912973e-02
  1.86021122e+00 -1.78774001e+01  4.14213383e+00 -1.85458602e+01
 -5.11795460e+00  2.39447043e+01  2.47620270e+00 -2.22308448e+01
 -1.16304114e+01]
supnorm grad right now is: 23.94470434616732
Weights right now are: 
[ -2.7200656    1.23854447  -6.48903809  -6.8810074    2.97463431
  -1.34723616   6.88797536   6.16497901  -2.62619205  -5.83098796
   3.48035658   2.79237709   7.69219915  56.10021964 -24.5089113
  15.51843198  18.74274827  -8.16288121   1.37936495   2.35361889
  17.90625311  -8.40073556   1.38990954   2.78402254   2.26676072
 -13.68419607 -25.29653289  -9.16218761  -2.18144011   6.82247649
  11.8863661  -14.97192589  -7.35624296   7.6657528    0.22017766
  -5.36687612  -9.98017546  14.85123708   6.82602875 -21.47350175
 -27.50573775 -39.57076456   2.39310799 -31.40622755  16.46467342
  24.40705759  -0.74558117  21.06356445   1.28363592   3.92804797
  -0.37195297   2.0005559   14.2261208    6.28172064  29.2767017
  15.20542307   1.64725662  -1.91802048  -3.20600833  -2.93723122
   7.49631532   1.08710124   1.2827548   -1.95236027  27.04160805]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2570.3577519482787
gradient value of function right now is: [-7.81325612e-01  5.32372425e-01 -3.04471206e-03 -3.77034949e-03
  7.81325612e-01 -5.32372425e-01  3.04471206e-03  3.77034949e-03
 -3.20233967e+00 -2.10154432e+00 -3.65556373e+00 -5.01702212e+00
  1.19210029e+00  2.92283355e-02  1.11176844e+00  1.06156422e+00
 -2.34562715e-02 -3.83740376e-02 -4.65166975e-02 -4.65297353e-02
 -2.83754130e-02 -4.60356764e-02 -5.58720290e-02 -5.58877825e-02
 -1.20693672e-01 -2.93115862e-05 -3.75069393e-02 -8.38125401e-04
 -6.44612953e+00 -2.02917272e-01 -1.88511409e+00 -2.09116236e-01
  3.64726216e-01  4.50575424e-01  3.13774195e-01  2.88299954e-01
 -1.04182077e+00 -4.45266564e-01 -7.77843780e-01 -2.89925861e-02
 -1.15187725e-01 -2.73691125e-02 -2.86545852e+00 -1.10432957e-01
  1.77175431e-01  9.00336030e-02  3.68795371e+00  1.71097061e-01
  1.07362121e+00  1.88828374e+00  3.99460384e+00  1.07332914e+00
 -4.33869495e-02 -2.42207752e-01 -3.54074464e-02 -4.45976197e-02
 -5.77909463e-01  1.06427522e+01 -3.23941788e+00  1.05401928e+01
  1.06002155e+00 -5.58671984e+00 -8.69202325e-01  1.27249193e+01
  1.44808714e+01]
supnorm grad right now is: 14.480871399272576
Weights right now are: 
[ -2.95666441   1.39779858  -7.75921562  -8.12234049   3.21123312
  -1.50649027   8.15815289   7.40631211  -2.43292902  -5.20932497
   3.13466155   2.48097208   7.94590243  56.49418879 -24.23610169
  15.5514722   18.14860874  -9.03544531   0.52366437   1.49816375
  17.27008577  -9.26598737   0.52026283   1.91463662   1.69877949
  -9.77760501 -25.77625254 -10.30820026  -2.33869084   8.30553284
  11.66734988 -14.79328319  -7.96642011   8.72074691   1.30973264
  -3.95072551  -9.73500704  15.21313363   5.40754082 -22.58422608
 -30.4355936  -41.66274947   2.05706802 -34.36905235  17.96168443
  25.26102611  -0.38606544  22.49299726   0.77203158   4.81370184
  -0.18421007   1.38753971  18.79182343   7.38068465  33.90050559
  19.72195269   1.01847538  -1.93323536  -4.07805597  -3.20785755
   7.96333907   0.98441972   0.9095179   -1.9658177   27.11243828]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2570.9469268422417
gradient value of function right now is: [ 1.69904241e+00  7.13253198e+00 -6.50205783e-03 -9.14844298e-03
 -1.69904241e+00 -7.13253198e+00  6.50205783e-03  9.14844298e-03
  5.15437683e+00 -2.20732347e+00  2.95298623e+00 -1.86655431e+00
 -2.45092679e+00 -3.41042936e-02 -2.35551766e+00 -2.26110777e+00
 -5.45150789e-02 -9.04316692e-02 -1.02851128e-01 -1.02846011e-01
 -7.38882265e-02 -1.21476897e-01 -1.38292383e-01 -1.38285991e-01
  4.34317632e-01  1.09709330e-07 -8.20933237e-03 -4.86871825e-04
 -1.19371238e+00  1.79246447e-01  4.44171966e-01  3.07754841e-03
 -1.96100314e+00 -1.44004053e+00 -2.32820229e+00  9.13068508e-02
 -7.02418634e-01 -5.34867008e-01 -8.19182256e-01 -4.60675383e-02
 -1.78502222e-01 -4.49415142e-02 -7.84671498e+00 -1.75279001e-01
  1.37460486e-01  2.03851909e-02  7.20353833e+00  1.34629030e-01
  7.10980589e-02  1.20848571e+00 -6.56762353e-01  7.68176035e-02
 -1.40502221e-02 -1.43954991e-01 -7.26732241e-03 -1.43093121e-02
 -1.47270853e+00  1.65765390e+01 -2.14034570e+00  7.33148470e+00
  1.66587055e+00 -1.15960641e+01 -1.72985842e+00  1.88649680e+01
  6.53549773e+00]
supnorm grad right now is: 18.86496799178304
Weights right now are: 
[-2.93157821e+00  1.59263389e+00 -8.07507118e+00 -8.36928936e+00
  3.18614692e+00 -1.70132559e+00  8.47400845e+00  7.65326098e+00
 -2.21107911e+00 -4.48641563e+00  2.94153632e+00  2.90978836e+00
  8.24789665e+00  5.33585450e+01 -2.40253878e+01  1.52043270e+01
  1.82915464e+01 -9.13552325e+00  4.44260056e-01  1.41842587e+00
  1.72951583e+01 -9.35977760e+00  4.21651001e-01  1.81573189e+00
  9.18517334e-01 -8.58953636e+00 -2.81730643e+01 -1.22025092e+01
 -2.43120082e+00  1.05197198e+01  1.19412700e+01 -1.47612859e+01
 -9.74357705e+00  8.70326580e+00  1.38148329e+00 -4.90789469e+00
 -9.21156831e+00  1.56958185e+01  3.97933230e+00 -2.55057493e+01
 -3.30583677e+01 -4.51354867e+01  2.07096468e+00 -3.70610335e+01
  1.92986071e+01  2.64295025e+01 -2.22812992e-02  2.38102257e+01
  1.09784858e+00  4.63793761e+00 -4.42216213e-01  1.59692663e+00
  2.23980561e+01  6.44835626e+00  3.77615178e+01  2.34902395e+01
  1.07546149e+00 -2.06586139e+00 -4.41381660e+00 -3.38384225e+00
  8.24160452e+00  1.18136362e+00  1.02854804e+00 -2.08001101e+00
  2.69012880e+01]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2571.8994116579124
gradient value of function right now is: [ 1.24125938e-01  2.99046169e+00 -6.28428484e-03 -8.69304925e-03
 -1.24125938e-01 -2.99046169e+00  6.28428484e-03  8.69304925e-03
 -1.10743709e+00 -3.66730581e+00 -2.46800928e+00 -4.38564945e+00
 -1.08556132e+00 -6.09612782e-03 -9.74725504e-01 -8.74536224e-01
 -5.68692612e-02 -9.71067487e-02 -1.04071483e-01 -1.04053950e-01
 -7.46995706e-02 -1.26355955e-01 -1.35489196e-01 -1.35466482e-01
  5.38782985e-01 -5.81622792e-07 -2.24337892e-03 -5.49159462e-04
 -2.70806395e+00 -2.32685385e-01 -5.72304584e-01 -3.51267918e-01
 -1.06145482e+00 -9.58258013e-01 -1.68837209e+00 -5.70853166e-03
 -2.39883245e-01 -2.12089747e-01 -5.21908619e-01 -3.87978328e-02
 -9.57109924e-02 -1.49236586e-02 -5.40363848e+00 -9.75283419e-02
  7.85313340e-02  5.23028958e-02  4.50924366e+00  8.03306488e-02
  1.99776294e-01  1.27401802e+00 -5.92912277e-02  2.12335656e-01
 -4.56488960e-02 -3.11522541e-01 -9.41092600e-02 -4.90414582e-02
  4.26710203e-02  7.91315704e+00 -2.43119524e+00  5.73038877e+00
  3.49280375e+00 -1.48109044e+01 -3.48089358e-02  9.39602433e+00
  1.20420172e+01]
supnorm grad right now is: 14.81090438284069
Weights right now are: 
[ -3.07314204   1.46772537  -8.47261661  -8.62723664   3.32771075
  -1.57641706   8.87155388   7.91120826  -2.31311074  -3.88782871
   2.82780238   3.13243141   8.38602262  50.36261756 -23.99415422
  15.07177607  18.84811344  -9.23093523   0.43473201   1.40882902
  17.8106915   -9.43005549   0.43228089   1.82627387   0.75914472
  -8.89854408 -31.87684754 -13.14818659  -2.95858943   9.46228429
  11.64403402 -16.5977457  -11.17999062   8.62561887   1.69364945
  -5.11194599  -8.66682364  16.68625604   2.79564839 -26.97194648
 -35.24150748 -48.09934386   2.22528137 -39.28365072  20.41951754
  27.08365291   0.41798185  24.91863912   0.98305679   4.61653834
  -0.89123158   1.37255598  23.66759573   4.45792757  39.79642133
  24.90381497   1.43962157  -2.1420101   -4.32578283  -3.57333865
   8.78822379   1.1786421    1.34790281  -2.1372168   27.13013621]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2572.9847852284715
gradient value of function right now is: [-1.50905036e-01 -1.26695941e+00  4.32844047e-03  5.87416720e-03
  1.50905036e-01  1.26695941e+00 -4.32844047e-03 -5.87416720e-03
  1.24346992e+00  2.11204977e+00  2.40332452e+00  4.05509522e+00
 -1.16402958e+00 -2.47836521e-02 -1.26179988e+00 -1.30885670e+00
  5.52569636e-02  7.61230827e-02  8.06751543e-02  8.06577657e-02
  7.12741677e-02  9.76345596e-02  1.03516507e-01  1.03494350e-01
 -4.61915974e-01  5.53249808e-08 -9.85236357e-03  1.02162281e-05
  4.49033616e+00  2.87921330e-01  1.58300157e+00  3.15843663e-01
  1.33182285e+00  1.10733528e+00  1.46405974e+00  9.46014384e-02
  7.12166385e-01  3.39792371e-01  6.38944890e-01  1.74772372e-02
  9.71797222e-02  2.49658652e-02  3.52509211e+00  9.50734772e-02
 -1.41683557e-01 -1.00834288e-01 -3.58644088e+00 -1.39650835e-01
 -5.16073445e-01 -1.95916202e+00 -1.27172793e+00 -5.23829939e-01
  5.34885898e-02  2.46895333e-01  6.06035739e-02  5.43587214e-02
  1.26924949e+00 -1.04813582e+01  4.00893013e+00 -9.46605081e+00
 -2.77830069e+00  1.29302528e+01  1.55963387e+00 -1.20541927e+01
 -1.05767555e+01]
supnorm grad right now is: 12.930252822325004
Weights right now are: 
[ -3.19308899   1.46377708  -9.42608745  -9.52916516   3.4476577
  -1.57246877   9.82502472   8.81313677  -2.18299761  -4.03166908
   2.65879316   3.37866652   8.835821    46.16438575 -23.79714632
  14.92477741  18.74634626 -10.06938477  -0.20487643   0.76908282
  17.7663045  -10.2272745   -0.16495901   1.2289192    0.23878586
  -8.861561   -37.12091649 -10.26950721  -3.19119238  11.61201197
  12.60790015 -14.46527024 -11.49071443   9.69659534   2.76831085
  -3.63130832  -8.49358346  16.52435511   1.87895633 -32.49910731
 -36.96345664 -51.85784581   2.27387158 -40.99778876  20.81428199
  27.61180816   0.2612833   25.30732193   2.06126338   3.39447824
  -0.42329964   2.31648327  28.1364873    7.49247508  42.04273434
  29.50312806   0.83883979  -2.16950807  -3.89358593  -3.70696428
   9.24586566   1.1718542    0.78144949  -2.19046136  27.08469726]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2569.016607051138
gradient value of function right now is: [-2.24014302e-01  1.92867359e+00 -8.20788855e-03 -8.82661988e-03
  2.24014302e-01 -1.92867359e+00  8.20788855e-03  8.82661988e-03
 -3.55389377e+00 -4.19896065e+00 -4.63477925e+00 -7.21568263e+00
  3.87171927e+00  7.62067928e-02  3.90264222e+00  3.85681751e+00
 -1.47898005e-01 -1.52192296e-01 -1.70722802e-01 -1.70648494e-01
 -1.52236927e-01 -1.55871411e-01 -1.75149132e-01 -1.75073896e-01
  3.98376904e-01 -5.41384691e-07  2.20377486e-02  7.69076590e-06
 -7.96735502e+00 -3.90531562e-01 -2.72015242e+00 -2.17640701e-01
 -1.11622901e+00 -7.20569080e-01 -9.77780295e-01 -7.53846708e-02
 -3.65172381e+00 -1.37967482e+00 -2.64551861e+00 -3.03708042e-02
 -2.11096297e-01 -5.38068256e-02 -5.22160881e+00 -2.06770333e-01
  4.57894828e-01  2.02769902e-01  8.52098332e+00  4.50465847e-01
  1.44692241e+00  2.30662893e+00  5.37490555e+00  1.44738221e+00
 -5.41158773e-02 -1.53309614e-01 -1.09535966e-01 -5.45777474e-02
 -3.42925932e+00  3.08283759e+01 -6.38475356e+00  2.28858000e+01
  3.63269320e+00 -2.07689148e+01 -4.06586299e+00  3.54450872e+01
  2.66527083e+01]
supnorm grad right now is: 35.445087185672634
Weights right now are: 
[ -2.92457094   1.45557876 -10.47437685 -10.5383146    3.17913965
  -1.56427045  10.87331412   9.82228621  -2.90635881  -3.00902859
   2.44056175   3.41133752   8.96835863  45.47669345 -23.66156817
  14.41761554  18.0757688  -11.12125097  -1.17766483  -0.20373874
  17.26692458 -11.19078602  -1.0441824    0.34963898   1.02302893
  -8.86606565 -39.71280686  -6.9573785   -3.12181484  13.88518794
  12.38411438 -15.22066133 -11.52677596  11.53122281   3.51280085
  -6.79672548  -7.84244126  16.52528579   1.9741912  -41.1144659
 -38.7344873  -55.77140407   2.07108959 -42.82875411  21.44433677
  26.46851594   0.15698127  25.91419865   1.59064332   4.72663534
  -0.23063059   1.82443583  33.50215249   6.27940051  44.2557382
  34.96699626   0.2014156   -2.15363002  -4.95587957  -3.58500379
  10.21434913   0.99576995   0.13891293  -2.17276204  26.99625922]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2574.225504863864
gradient value of function right now is: [ 1.11696772e+00  1.88159491e+00  6.90907538e-03  6.98618272e-03
 -1.11696772e+00 -1.88159491e+00 -6.90907538e-03 -6.98618272e-03
  3.63910960e+00  1.24541224e+00  3.45538082e+00  1.61449173e+00
  6.96843932e-01  9.60426281e-03  6.86056562e-01  7.01135881e-01
  1.14849007e-01  1.33896158e-01  1.43086958e-01  1.43023518e-01
  1.09485761e-01  1.28191742e-01  1.36961088e-01  1.36900274e-01
 -2.44530233e-01 -7.10347059e-11 -7.17776016e-03  6.10305394e-05
 -5.29629769e-02 -1.01383997e-01 -2.07239745e-01 -9.54505630e-02
 -3.15887932e-01 -1.66016824e-01 -3.33666089e-01  1.04510409e-01
 -1.17738734e+00 -5.75220371e-01 -9.83131478e-01 -1.66240943e-02
 -6.96789163e-02 -1.79841705e-02 -2.76272539e+00 -6.84643430e-02
  1.15426649e-01  6.55875070e-02  3.84669002e+00  1.14129335e-01
 -2.22637441e-01 -2.15556526e-01  8.46999779e-02 -2.21737339e-01
 -1.65961728e-02 -4.72417149e-02 -4.48061949e-02 -1.69864418e-02
 -7.14314957e-01  8.57749000e+00 -1.04664540e+00  5.26738936e+00
  1.44290946e+00 -7.43961683e+00 -8.52591983e-01  9.78636873e+00
  2.86516777e+00]
supnorm grad right now is: 9.786368730587311
Weights right now are: 
[ -2.87815512   1.55605805  -9.85784698  -9.94746318   3.13272383
  -1.66474974  10.25678425   9.23143479  -2.69755627  -2.96980372
   2.79581881   3.57768266   9.03397308  42.77554236 -23.47532666
  14.60723352  19.14424189 -10.40607735  -0.43587193   0.53804028
  18.37631713 -10.48534113  -0.30338937   1.09041851  -0.09459692
  -8.87242297 -44.74892592  -7.12667836  -3.05279184  14.94998279
  12.64016303 -16.33356278 -12.09420991  11.77964137   3.2660116
  -4.87654448  -7.75765979  17.21920104   1.714012   -45.83300729
 -40.43829042 -59.29778687   1.6825817  -44.56451657  22.36374475
  27.01842331   0.19889895  26.81103035   1.10844638   4.33514256
  -0.39189926   1.27840183  37.15228763   4.11715135  47.03289338
  38.73370853   0.52853543  -2.30840656  -4.88215689  -3.60497896
  10.4934038    1.18138084   0.43634641  -2.32675971  27.1423477 ]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -2573.9510092441515
gradient value of function right now is: [-1.43814409e+00 -4.22519567e+00  1.82526097e-03  1.45493601e-03
  1.43814409e+00  4.22519567e+00 -1.82526097e-03 -1.45493601e-03
 -2.37238848e+00  1.44257641e+00 -1.67111805e+00  1.84823281e+00
 -5.23466184e-01 -1.15576886e-02 -5.70766344e-01 -5.77409907e-01
  3.83500228e-02  3.62975280e-02  4.07530238e-02  4.07399289e-02
  2.93075420e-02  2.76748756e-02  3.11112362e-02  3.11028846e-02
 -4.25483394e-02  9.29737430e-10 -2.08542269e-03  1.42576754e-06
  2.37444610e+00  1.25995333e-01  8.15775907e-01  1.42825323e-01
  1.07681643e+00  7.58087408e-01  1.06145954e+00  8.20549735e-02
  1.74742982e+00  7.95420931e-01  1.50741139e+00  1.29084062e-02
  1.22034207e-01  2.98450385e-02  4.76679576e+00  1.20161309e-01
 -1.94714768e-01 -8.07348863e-02 -6.39747326e+00 -1.92748601e-01
 -3.11728500e-01 -1.01490630e+00 -1.30737041e+00 -3.22529223e-01
  2.75392951e-02  1.40990072e-01  4.30342333e-02  2.90574660e-02
  1.36641756e+00 -1.59520192e+01  2.84804641e+00 -9.77687262e+00
 -1.85087831e+00  1.08083178e+01  1.59842203e+00 -1.80412242e+01
 -9.83442944e+00]
supnorm grad right now is: 18.041224201444376
Weights right now are: 
[-2.54717939e+00  1.41469529e+00 -1.11688178e+01 -1.12010811e+01
  2.80174811e+00 -1.52338698e+00  1.15677551e+01  1.04850528e+01
 -2.93138337e+00 -3.31392861e+00  2.67517530e+00  3.55053127e+00
  8.81871010e+00  4.21556802e+01 -2.34344222e+01  1.46805567e+01
  1.84240024e+01 -1.15394681e+01 -1.55673711e+00 -5.82795500e-01
  1.77731552e+01 -1.15440101e+01 -1.34256936e+00  5.12828837e-02
  3.87024797e-01 -8.87290686e+00 -4.88164969e+01 -7.34297499e+00
 -3.31408203e+00  1.39657017e+01  1.24507689e+01 -1.72396145e+01
 -1.27306640e+01  1.13816625e+01  2.82176139e+00 -6.52098814e+00
 -7.85144363e+00  1.76410956e+01  1.52835660e+00 -4.96972721e+01
 -4.13452605e+01 -6.28094851e+01  1.89950679e+00 -4.54920350e+01
  2.36345348e+01  2.76852422e+01  2.57494824e-01  2.80601639e+01
  1.50647810e+00  3.44194476e+00 -3.57685597e-01  1.63589255e+00
  3.96365759e+01  2.72730142e+00  4.96093910e+01  4.12198617e+01
  5.20579644e-01 -2.29804031e+00 -4.45961832e+00 -3.67903008e+00
  1.07709577e+01  1.17761737e+00  3.99750747e-01 -2.31809624e+00
  2.69462982e+01]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2570.255328144871
gradient value of function right now is: [-2.25133830e+00 -5.69151297e+00 -8.49697673e-04 -5.44452164e-04
  2.25133830e+00  5.69151297e+00  8.49697673e-04  5.44452164e-04
 -6.20342365e+00  2.18118557e-01 -5.38960303e+00 -5.07384737e-01
 -9.27939863e-02 -1.39131962e-02 -1.34102941e-01 -1.70104200e-01
 -1.88214947e-02 -1.76393620e-02 -1.95658731e-02 -1.95484355e-02
 -1.16535860e-02 -1.09117751e-02 -1.21093733e-02 -1.20965029e-02
  1.16809335e-02  1.79260642e-09  5.04888005e-04 -3.96142720e-08
  1.40913047e+00  2.31805266e-01  6.49875038e-01  2.22514016e-01
  1.26368391e+00  8.62287934e-01  1.26873758e+00  8.85952255e-02
  2.09785903e+00  9.49224273e-01  1.92682766e+00  7.69045897e-03
  1.51398276e-01  2.22773397e-02  6.06338151e+00  1.46227053e-01
 -2.45107307e-01 -9.06594417e-02 -7.89803987e+00 -2.38906129e-01
 -4.81398233e-02 -2.78814210e-01 -6.27711919e-01 -5.16310044e-02
  3.98245808e-02  1.00278000e-01  4.40549394e-02  4.09319900e-02
  1.61978869e+00 -1.91880214e+01  2.68847084e+00 -8.44499744e+00
 -1.91522390e+00  1.04403953e+01  1.91772817e+00 -2.13991811e+01
 -8.15708958e+00]
supnorm grad right now is: 21.399181103679176
Weights right now are: 
[ -2.9883585    1.34390981 -11.49527312 -11.58225639   3.24292721
  -1.4526015   11.89421038  10.866228    -3.09911564  -3.46516427
   2.84740734   3.28136008   8.74740272  40.44275463 -23.29104754
  14.8210081   18.64324165 -11.80136123  -1.7489794   -0.77505184
  18.0525682  -11.74524941  -1.47449665  -0.08064853   0.14228846
  -8.87535097 -52.21112981  -4.72922987  -3.29454013  14.21934387
  12.65955747 -16.99448229 -13.3160425   11.64643994   2.91558561
  -6.42717544  -7.40938551  18.214583     1.05780258 -54.03867693
 -42.14282329 -66.77234995   1.8750253  -46.33063826  23.31025509
  24.56918077   0.51842313  27.6752177    1.14469449   4.61307751
  -0.44226239   1.28882547  43.87240414   3.12850954  52.77264095
  45.48443638  -0.08520342  -2.33996262  -4.90088579  -4.04130049
  11.05814287   1.28365504  -0.18989456  -2.37167924  26.89388932]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2573.9167626308176
gradient value of function right now is: [-4.13551613e-01 -2.45253860e-01 -5.87909480e-03 -2.82070776e-03
  4.13551613e-01  2.45253860e-01  5.87909480e-03  2.82070776e-03
 -3.02386780e+00 -2.80524344e+00 -3.36371907e+00 -4.20499991e+00
  1.48840967e+00  1.84687205e-02  1.51760272e+00  1.52033158e+00
 -1.11069176e-01 -1.23400789e-01 -1.29786272e-01 -1.29747499e-01
 -5.25835109e-02 -5.83737260e-02 -6.14200770e-02 -6.14018461e-02
  3.05064274e-01 -1.97503769e-09  8.33928248e-03  1.49246037e-06
 -2.32699012e+00 -1.25334047e-01 -7.53731749e-01 -1.22151917e-01
 -3.62561403e-01 -3.51872606e-01 -4.53398465e-01 -4.73774731e-03
 -3.05354999e-01 -1.10702433e-01 -2.39236273e-01 -6.25381694e-05
 -1.68949382e-02 -9.95596194e-03 -1.11379094e+00 -1.81170058e-02
  3.76353591e-02  6.00078797e-02  1.24735470e+00  4.12270118e-02
  3.21386914e-01  1.11291106e+00  1.01211739e+00  3.52516928e-01
 -1.71419227e-02 -1.47595419e-01 -2.46887231e-02 -2.07162093e-02
 -1.26564432e-01  2.16717027e+00 -2.23502319e+00  6.27387549e+00
  1.19586255e+00 -4.70814468e+00 -1.46421927e-01  2.60146030e+00
  5.98311655e+00]
supnorm grad right now is: 6.273875486975545
Weights right now are: 
[ -2.81869413   1.46110917 -11.28854384 -11.44911769   3.07326284
  -1.56980086  11.6874811   10.73308931  -2.85223838  -3.28890217
   2.95267999   3.32806354   8.88954191  36.55028953 -23.07889293
  14.92591356  19.5283924  -11.46343075  -1.35128428  -0.37781045
  19.03228706 -11.35753231  -1.02201356   0.3714049    0.36082669
  -8.8870202  -57.31454526   2.44162423  -3.67326924  13.18633043
  12.9653938  -19.07712037 -14.47464256  10.45297764   2.50459434
  -5.21593483  -8.0738293   19.31455249   0.33642401 -57.03556269
 -43.80229928 -70.21948473   2.02944739 -48.0281817   24.86181494
  25.84392745   0.59429481  29.2113101    2.28909703   3.95133803
  -0.56699029   2.26222951  45.16378215   3.51850542  55.34827725
  46.77178307   0.53441133  -2.42501008  -5.35512229  -3.62868642
  11.43746001   1.62061531   0.29700517  -2.41399579  26.8400317 ]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2570.954404399319
gradient value of function right now is: [-1.53336760e+00 -3.19083614e+00 -8.75106769e-03 -2.36144099e-03
  1.53336760e+00  3.19083614e+00  8.75106769e-03  2.36144099e-03
 -6.13062846e+00 -2.89156212e+00 -5.93141168e+00 -5.12785054e+00
  2.63993692e+00  2.73698743e-02  2.62239629e+00  2.50884579e+00
 -1.75142104e-01 -1.84244735e-01 -1.94639827e-01 -1.94537000e-01
 -4.76268313e-02 -5.01918508e-02 -5.30273101e-02 -5.29991698e-02
  2.92400213e-01 -5.12649654e-10  5.35553017e-03 -2.25138849e-06
 -3.08848160e+00  6.82944193e-03 -8.94701459e-01  2.74765017e-02
  4.40188504e-01  3.37170773e-01  3.61241793e-01  2.88058831e-02
 -9.81245124e-01 -1.64056839e-01 -6.95406526e-01  3.44057944e-03
 -4.01826942e-02  1.20704776e-03 -1.74028576e+00 -3.80872005e-02
  1.20369074e-01  2.90076213e-02  3.80457133e+00  1.16447479e-01
  6.52063953e-01  1.34796777e+00  2.30414336e+00  6.66047053e-01
 -8.80990731e-03 -8.10670241e-02  1.54929645e-02 -9.55780506e-03
  6.48090749e-03  7.02273841e+00 -1.42900260e+00  3.52384542e+00
 -8.22775867e-01  3.16223081e+00  3.89714296e-02  7.57324535e+00
  1.10620645e+01]
supnorm grad right now is: 11.062064477493594
Weights right now are: 
[ -3.05175184   1.29183013 -11.36841763 -11.69526824   3.30632055
  -1.40052182  11.7673549   10.97923985  -2.90293504  -3.54951757
   2.92314975   3.36589381   8.85545356  34.6966791  -23.27970053
  14.53803162  19.39701733 -11.76602022  -1.60669151  -0.63378163
  19.03257595 -11.49002733  -1.11684689   0.2760434   -0.53383528
  -8.88742335 -60.60015765   4.47284317  -3.55112487  14.95653684
  13.41979444 -17.6616104  -13.35958054  12.65867936   3.43253585
  -7.11157134  -7.53780773  20.25173619   0.95128171 -61.49779867
 -44.89910388 -72.71819438   1.60697171 -49.12091913  25.61303986
  25.00250058   0.14052059  29.98098775   1.46418063   4.19418331
  -0.33159032   1.42882647  49.81021299   1.76583952  57.54713669
  51.0039874    0.57302762  -2.29507206  -5.44589616  -3.89371702
  11.44108661   1.66112247   0.41007704  -2.32605981  27.17755842]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2571.645142500391
gradient value of function right now is: [-1.61688085e+00 -4.27946473e+00 -1.08333063e-03 -2.67002011e-04
  1.61688085e+00  4.27946473e+00  1.08333063e-03  2.67002011e-04
 -5.55702204e+00 -3.33420772e-01 -4.88323362e+00 -1.47735981e+00
  3.63708757e-01  1.79712515e-02  3.44422277e-01  3.18682701e-01
 -2.19108193e-02 -2.29547322e-02 -2.42264632e-02 -2.42141037e-02
 -5.54209888e-03 -5.82783406e-03 -6.14655889e-03 -6.14311141e-03
  3.49451187e-02  5.62159237e-11  6.69088398e-04  2.79695358e-07
 -3.68045305e-01  3.02725214e-02 -1.25242605e-01  9.04746199e-02
  8.38863810e-01  5.89745595e-01  9.01273256e-01  2.08502542e-02
  1.15932669e+00  6.17896125e-01  1.13815891e+00  8.28634785e-03
  1.01592193e-01  1.60185813e-02  5.85836638e+00  1.04351736e-01
 -1.28407444e-01 -4.49646187e-02 -6.82643100e+00 -1.33800549e-01
  2.49062442e-01 -8.21720798e-02  1.86282475e+00  2.43834971e-01
  1.81158183e-02  7.77969757e-02  2.36482685e-02  2.15390656e-02
  8.66817544e-01 -1.32418165e+01  1.48713270e+00 -5.18820269e+00
 -1.36107367e+00  8.19941866e+00  1.04369876e+00 -1.53721870e+01
 -3.14056888e+00]
supnorm grad right now is: 15.372187019764565
Weights right now are: 
[-3.13216073e+00  1.27504638e+00 -1.14397432e+01 -1.19693222e+01
  3.38672944e+00 -1.38373808e+00  1.18386805e+01  1.12532938e+01
 -3.05478679e+00 -3.51580928e+00  3.16103586e+00  3.68352638e+00
  8.46269862e+00  3.83027088e+01 -2.33589851e+01  1.46300766e+01
  1.98088826e+01 -1.18299637e+01 -1.57209246e+00 -5.99018043e-01
  1.95047252e+01 -1.15450035e+01 -1.06083278e+00  3.32294414e-01
  8.35068287e-02 -8.88756391e+00 -6.45344352e+01  3.84295946e+00
 -3.75843706e+00  1.19978289e+01  1.27071770e+01 -1.87222031e+01
 -1.42323311e+01  1.15048728e+01  2.95847708e+00 -5.44201737e+00
 -7.65184302e+00  1.99644758e+01 -2.22140972e-01 -6.37869089e+01
 -4.57400550e+01 -7.56233122e+01  2.15986070e+00 -4.99570663e+01
  2.69859079e+01  2.58915610e+01  4.34424216e-01  3.13384061e+01
  2.06907708e+00  3.94733582e+00 -4.10153129e-02  2.05318086e+00
  5.14799098e+01  2.67187388e+00  5.88218932e+01  5.25829276e+01
  1.15809623e-01 -2.42173226e+00 -5.11106342e+00 -3.97473774e+00
  1.23857482e+01  1.64955135e+00 -1.29923108e-01 -2.42815918e+00
  2.69147463e+01]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2572.3309143648903
gradient value of function right now is: [ 2.30296405e+00  7.71934874e+00 -1.45757511e-02 -1.14707342e-03
 -2.30296405e+00 -7.71934874e+00  1.45757511e-02  1.14707342e-03
  4.86098616e+00 -4.69057038e+00  2.99116310e+00 -4.94791121e+00
  1.88671694e+00  2.42490670e-02  1.97970041e+00  2.02736580e+00
 -2.78264952e-01 -3.09424911e-01 -3.22869086e-01 -3.22779696e-01
 -2.27410942e-02 -2.54564359e-02 -2.65505312e-02 -2.65435145e-02
  5.81456619e-01 -6.52945410e-10  1.46149314e-02  1.88057332e-06
 -3.46744328e+00 -1.92620567e-01 -1.07189136e+00 -1.61543045e-01
 -1.64203478e+00 -1.60369126e+00 -3.06330636e+00 -1.06859766e-03
 -1.53344607e+00 -8.50662419e-01 -2.25234043e+00 -1.10339234e-03
 -1.49238894e-01 -5.57808091e-02 -1.50648817e+01 -1.62879086e-01
  1.81672441e-01  1.13024147e-01  1.49240774e+01  1.99698936e-01
  4.49293933e-01  1.77249358e+00  1.46677166e+00  5.12082251e-01
 -2.87704162e-02 -1.93595967e-01 -2.40336652e-02 -3.53885941e-02
 -2.08292357e+00  2.12984016e+01 -5.44977633e+00  1.94488172e+01
  3.70334857e+00 -1.77585890e+01 -2.61680845e+00  2.60526472e+01
  1.75932067e+01]
supnorm grad right now is: 26.052647193005335
Weights right now are: 
[-2.73407966e+00  1.51811840e+00 -1.14688879e+01 -1.19919328e+01
  2.98864837e+00 -1.62681010e+00  1.18678252e+01  1.12759044e+01
 -2.82310234e+00 -3.86698288e+00  3.17297057e+00  3.63185669e+00
  8.66710844e+00  3.65527280e+01 -2.30634385e+01  1.51225428e+01
  2.01787770e+01 -1.19210433e+01 -1.56441252e+00 -5.91491258e-01
  2.01705678e+01 -1.13227183e+01 -7.55552394e-01  6.37346252e-01
  4.24534848e-01 -8.88707986e+00 -6.81284846e+01  9.79069156e+00
 -3.82507840e+00  1.03692466e+01  1.29435933e+01 -2.02108708e+01
 -1.62202638e+01  9.60742306e+00  1.89550322e+00 -9.82713911e-01
 -8.07786064e+00  2.06169151e+01 -7.27633746e-01 -6.39572041e+01
 -4.69447627e+01 -7.86166750e+01  2.25289304e+00 -5.12012087e+01
  2.86762696e+01  2.70077056e+01  6.97692289e-01  3.30629940e+01
  2.14677193e+00  4.35972723e+00 -6.86910321e-01  2.30067817e+00
  5.00639963e+01  2.19308748e-01  6.13153814e+01  5.10430215e+01
 -1.34412119e-02 -2.51836035e+00 -5.22064858e+00 -3.69368740e+00
  1.19993733e+01  2.19209180e+00 -2.39171870e-01 -2.49790748e+00
  2.68956537e+01]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2572.4832446677365
gradient value of function right now is: [-5.11567149e-01 -1.43529643e+00 -3.40611130e-03 -7.63128857e-05
  5.11567149e-01  1.43529643e+00  3.40611130e-03  7.63128857e-05
 -1.77598301e+00  4.82246275e-01 -1.61526173e+00  3.66080526e-01
 -7.12637415e-01 -7.64118927e-03 -7.01769846e-01 -6.76214473e-01
 -5.72012637e-02 -6.86600138e-02 -7.24977801e-02 -7.24175090e-02
 -1.45310357e-03 -1.72075444e-03 -1.81533373e-03 -1.81340417e-03
  2.49957889e-01  3.72478337e-09  1.25078007e-02 -1.44157636e-04
  5.51599805e-01  8.20071769e-02  2.25879422e-01  6.65136503e-02
  1.79585103e-01  1.38456302e-01  1.77980448e-01  7.62681149e-03
  6.44255899e-01  2.59150965e-01  5.44422436e-01  1.55295799e-03
  3.51810042e-02  1.16724811e-02  2.08292123e+00  3.41944515e-02
 -6.48320579e-02 -4.45576131e-02 -3.18815980e+00 -6.36462017e-02
  1.02518231e-01  7.96681370e-02  5.49099933e-01  1.01922318e-01
  7.39203830e-03  5.98611366e-02  7.11358990e-03  7.92611325e-03
  4.29612062e-01 -5.61132221e+00  9.37260031e-01 -4.44560969e+00
 -4.77717362e-01  2.39021715e+00  4.89260379e-01 -6.16571520e+00
 -5.02919574e+00]
supnorm grad right now is: 6.16571519967887
Weights right now are: 
[-2.99483883e+00  1.26312081e+00 -1.18267689e+01 -1.22886419e+01
  3.24940754e+00 -1.37181250e+00  1.22257061e+01  1.15726136e+01
 -2.78789280e+00 -3.57666678e+00  2.98839343e+00  4.50328650e+00
  8.46742630e+00  3.31782881e+01 -2.35315585e+01  1.45852320e+01
  2.00696245e+01 -1.24249408e+01 -1.98136046e+00 -1.00871301e+00
  2.03601981e+01 -1.14356452e+01 -7.87501060e-01  6.05041282e-01
  1.73547441e+00 -8.87872229e+00 -6.91435055e+01  1.44049161e+01
 -3.49455154e+00  1.18146921e+01  1.45401915e+01 -1.87604830e+01
 -1.58940491e+01  1.05267777e+01  2.61465273e+00  4.41344328e+00
 -7.20382071e+00  2.19036918e+01 -5.09080686e-01 -6.62737882e+01
 -4.78050618e+01 -8.02162565e+01  2.19624976e+00 -5.20720841e+01
  2.96354258e+01  2.73527296e+01  6.05594762e-01  3.39015826e+01
  3.91137477e+00  6.38554456e+00  2.20854816e-01  4.02082815e+00
  5.32604910e+01  2.68367699e+00  6.19042094e+01  5.39907415e+01
 -6.38677961e-02 -2.39355699e+00 -6.11437878e+00 -3.69986636e+00
  1.26171382e+01  1.98125677e+00 -2.41626078e-01 -2.42652378e+00
  2.66218852e+01]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2568.593709890696
gradient value of function right now is: [ 1.34575480e+00 -2.18852057e-01  8.94407109e-02  1.99302463e-03
 -1.34575480e+00  2.18852057e-01 -8.94407109e-02 -1.99302463e-03
  7.84582861e+00  8.83880569e+00  8.57775160e+00  9.45736399e+00
 -1.00466621e+00 -2.47483832e-02 -1.07762555e+00 -1.08528434e+00
  1.68963356e+00  1.92317124e+00  1.95991343e+00  1.95852252e+00
  4.02958084e-02  4.61532334e-02  4.70256932e-02  4.69922875e-02
 -4.08180288e+00  1.04635245e-10 -5.80650083e-02  8.81084432e-06
  3.13082606e+00  6.98845847e-02  7.89100641e-01  5.40387323e-02
  7.09171763e-01  5.88033019e-01  8.43573233e-01  5.51610146e-02
  5.98218593e-01  2.07463832e-01  5.32089700e-01  3.47234567e-03
  4.28425794e-02  1.59991557e-02  3.60642931e+00  4.38789147e-02
 -7.79464391e-02 -5.15578859e-02 -4.45947545e+00 -8.03676206e-02
 -1.31382867e+00 -4.27175838e+00 -2.28512731e+00 -1.40202522e+00
  9.95649563e-03  9.68435343e-02  1.03979180e-02  1.13904950e-02
  1.42070018e+00 -8.07132492e+00  3.88912923e+00 -8.80763433e+00
 -8.46024935e-01  4.65837861e+00  1.62535585e+00 -9.20614798e+00
 -1.77132924e+01]
supnorm grad right now is: 17.71329235173446
Weights right now are: 
[-2.87515790e+00  1.43637416e+00 -1.12466863e+01 -1.21884652e+01
  3.12972661e+00 -1.54506585e+00  1.16456236e+01  1.14724368e+01
 -2.31832175e+00 -3.47418623e+00  3.15714783e+00  4.49821185e+00
  8.63733617e+00  3.12039745e+01 -2.34081306e+01  1.47051071e+01
  2.04978418e+01 -1.20124318e+01 -1.55001620e+00 -5.77157714e-01
  2.07603752e+01 -1.10666639e+01 -3.98564946e-01  9.94135927e-01
 -4.61054203e-01 -8.88072810e+00 -7.47300943e+01  1.18740294e+01
 -4.36102550e+00  1.37846058e+01  1.36323988e+01 -1.79926361e+01
 -1.45897486e+01  1.25919849e+01  3.03523592e+00 -2.66084841e+00
 -7.22848014e+00  2.15394165e+01 -8.30775559e-02 -6.91439591e+01
 -4.87901227e+01 -8.40405707e+01  1.67930971e+00 -5.31069443e+01
  3.04915090e+01  2.74919770e+01  4.20887806e-01  3.47844608e+01
  2.15305075e+00  4.29747903e+00 -4.21607359e-01  2.24273466e+00
  5.37321963e+01  1.40040942e+00  6.29187578e+01  5.43923392e+01
  3.30942113e-01 -2.59310234e+00 -4.94295433e+00 -3.72979029e+00
  1.26593160e+01  1.86665985e+00  1.43718235e-01 -2.59659123e+00
  2.68467571e+01]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2574.572801670939
gradient value of function right now is: [ 2.16343952e-01  4.28217520e-01 -4.82582135e-03 -4.41608515e-05
 -2.16343952e-01 -4.28217520e-01  4.82582135e-03  4.41608510e-05
  3.58452696e-01 -8.45119435e-01  1.80141973e-01 -8.83589000e-01
  5.20762736e-01  1.15314927e-02  5.24254936e-01  5.06839535e-01
 -7.04960633e-02 -9.01607487e-02 -9.37520902e-02 -9.36337853e-02
 -7.84258828e-04 -1.00646270e-03 -1.04521924e-03 -1.04391208e-03
  3.55919533e-01  4.78957593e-12  5.55620561e-03  4.54226004e-06
 -7.26779164e-01  3.08449212e-02 -1.79186660e-01  4.23083286e-02
 -1.14167488e-01 -9.78876435e-03 -2.67434734e-01 -8.08677423e-03
 -4.00287307e-01 -1.52147354e-01 -4.96310506e-01  7.44595823e-04
 -4.54270698e-02 -9.78075071e-03 -3.54448921e+00 -4.64195494e-02
  5.78812471e-02  9.68204983e-03  4.09905334e+00  5.91227362e-02
  1.85917564e-01  5.75006167e-01  7.61413324e-01  2.05204320e-01
  2.17152549e-03  2.41771625e-02  6.15110673e-03  2.64760621e-03
 -7.90317586e-01  7.71669208e+00 -4.96624364e-01  2.67691576e+00
 -3.31077326e-01  5.88964235e-01 -8.96798138e-01  8.73489075e+00
  4.04634738e+00]
supnorm grad right now is: 8.73489074926404
Weights right now are: 
[-2.75837017e+00  1.33616172e+00 -1.11590122e+01 -1.22299722e+01
  3.01293888e+00 -1.44485341e+00  1.15579495e+01  1.15139438e+01
 -2.88088256e+00 -3.39821774e+00  3.20987121e+00  3.69520097e+00
  8.57084414e+00  3.12123770e+01 -2.32303578e+01  1.49121469e+01
  2.07907542e+01 -1.20964041e+01 -1.56460707e+00 -5.91766551e-01
  2.13392794e+01 -1.08679860e+01 -1.40062936e-01  1.25249607e+00
  2.53490470e-01 -8.86660236e+00 -7.63237730e+01  1.25746417e+01
 -3.59498027e+00  1.37565291e+01  1.39408537e+01 -1.96067611e+01
 -1.55321838e+01  1.13946203e+01  2.44802565e+00 -4.11950472e+00
 -6.67664066e+00  2.25799107e+01 -1.96092663e-01 -7.04845456e+01
 -4.94502093e+01 -8.72089066e+01  2.13556057e+00 -5.37895576e+01
  3.16643405e+01  2.81809753e+01  6.29714383e-01  3.59165594e+01
  2.17325026e+00  4.15879882e+00 -2.74273748e-01  2.18228013e+00
  5.82500548e+01  2.25499268e+00  6.60549378e+01  5.87486584e+01
  7.27854558e-02 -2.45465832e+00 -5.74703857e+00 -3.71597227e+00
  1.22366553e+01  2.24100533e+00 -1.69982514e-01 -2.45940096e+00
  2.69904966e+01]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2568.847439557985
gradient value of function right now is: [ 1.04742319e+00 -1.77359811e-01  4.80086329e-02  2.71479506e-04
 -1.04742319e+00  1.77359811e-01 -4.80086329e-02 -2.71479506e-04
  6.25876773e+00  7.03701834e+00  7.06626041e+00  8.23376235e+00
 -1.96110049e+00 -5.69927564e-02 -2.05135580e+00 -2.08432522e+00
  1.01354054e+00  1.05242420e+00  1.10530389e+00  1.10459484e+00
  6.19427151e-03  6.45870538e-03  6.78400822e-03  6.77964607e-03
 -1.35436322e+00  6.95484202e-12 -3.99377274e-02 -4.35578908e-06
  5.00904413e+00  1.53253954e-01  1.33842830e+00  1.12389855e-01
  6.65586039e-01  6.22637568e-01  1.22049863e+00 -6.48632071e-03
  5.62592693e-01  2.38685403e-01  6.41735331e-01 -9.55859200e-04
  7.47141157e-02  2.79234016e-02  8.61652844e+00  7.52626976e-02
 -1.03328053e-01 -7.61338304e-02 -8.79284200e+00 -1.04648942e-01
 -1.12148285e+00 -4.26737663e+00 -3.86102365e+00 -1.16864605e+00
  1.30376754e-02  1.76326003e-01  4.88870684e-03  1.42003094e-02
  1.35862122e+00 -1.23690506e+01  4.17884523e+00 -1.26813048e+01
 -6.05503374e-01  3.95403766e+00  1.50207769e+00 -1.37666830e+01
 -1.78917130e+01]
supnorm grad right now is: 17.89171304538589
Weights right now are: 
[ -2.56405268   1.44680559 -11.56371596 -12.79462063   2.81862139
  -1.55549728  11.96265323  12.07859222  -2.55700706  -3.30513551
   3.36460986   3.88734053   8.38580651  31.490709   -23.41339174
  14.835164    20.91613675 -12.47156117  -1.83580888  -0.86126425
  21.47569411 -11.13046291  -0.34399125   1.05001789   0.38050564
  -8.86657733 -80.47429652   9.7064339   -3.63497474  13.32660641
  13.54222379 -18.98740752 -15.81793236  11.38101861   2.23293164
  -2.69933291  -7.26486161  21.87646587  -1.0402826  -72.18702223
 -50.02934605 -89.02606912   2.0068109  -54.38215459  32.41603983
  29.23496001   0.55461511  36.74258903   2.17780678   3.50186079
  -0.17478045   2.20520164  58.11779111   1.06515005  66.86149802
  58.40658032   0.4376384   -2.68246037  -5.07335481  -3.69158371
  12.71027363   2.21024484   0.31183809  -2.68671384  26.87700352]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2568.1292842747234
gradient value of function right now is: [-2.53829826e+00 -4.91135986e+00 -2.90872595e-03 -1.67753611e-05
  2.53829826e+00  4.91135986e+00  2.90872595e-03  1.67753611e-05
 -7.75450434e+00 -1.71229093e-01 -6.92800203e+00 -4.39199333e-01
 -1.29373515e+00 -2.81865646e-02 -1.33244525e+00 -1.34038377e+00
 -6.12749794e-02 -6.20404028e-02 -6.56322413e-02 -6.55448240e-02
 -4.03191194e-04 -4.12111578e-04 -4.34278360e-04 -4.33594683e-04
  6.88322247e-02 -5.60511348e-11  2.37452958e-03 -2.82532279e-04
  9.45662087e-01  7.84023581e-02  5.00443172e-01  4.57160854e-02
  9.82441214e-01  7.62775715e-01  1.31220036e+00 -9.60052216e-03
  1.61352957e+00  6.83757581e-01  1.77934539e+00  2.07744347e-03
  1.13941911e-01  4.09922460e-02  9.80083345e+00  1.18429705e-01
 -1.90570715e-01 -8.52477405e-02 -1.43014871e+01 -1.98001374e-01
 -1.11927265e-01 -3.10434565e-02 -2.23057411e+00 -1.15108341e-01
  2.01156335e-03  1.72339181e-02  1.07282548e-02  2.36309797e-03
  1.72447072e+00 -2.13835360e+01  1.85613265e+00 -1.26813728e+01
 -1.39381187e+00  6.80339408e+00  2.02215973e+00 -2.46246055e+01
 -9.20043214e+00]
supnorm grad right now is: 24.62460545023089
Weights right now are: 
[-2.96144690e+00  1.30954839e+00 -1.17167378e+01 -1.33211016e+01
  3.21601561e+00 -1.41824008e+00  1.21156750e+01  1.26050732e+01
 -2.76187303e+00 -3.45643332e+00  2.95645014e+00  3.87150998e+00
  8.57368125e+00  2.89459218e+01 -2.33287907e+01  1.48313550e+01
  2.06993400e+01 -1.28886344e+01 -2.20728460e+00 -1.23334489e+00
  2.12205468e+01 -1.15394226e+01 -7.25164535e-01  6.68475008e-01
  7.57139666e-01 -8.87939346e+00 -8.20633030e+01  1.73665886e+01
 -4.03800661e+00  1.43970643e+01  1.34571705e+01 -1.88847806e+01
 -1.52641738e+01  1.24530300e+01  2.18031041e+00 -6.70889773e+00
 -6.87314117e+00  2.25407493e+01 -3.46188045e-01 -7.46951368e+01
 -5.11508211e+01 -9.15326140e+01  1.72416601e+00 -5.55130598e+01
  3.36576640e+01  3.00888328e+01  1.18281065e-01  3.79978074e+01
  1.97346205e+00  4.77792449e+00 -6.32288758e-01  2.01909544e+00
  5.90581140e+01  6.96785046e-02  6.86861075e+01  5.93066671e+01
 -2.71174221e-01 -2.55904934e+00 -6.38049991e+00 -3.75744684e+00
  1.27361905e+01  2.47975553e+00 -4.61829961e-01 -2.55381882e+00
  2.68750328e+01]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2573.4894030574333
gradient value of function right now is: [ 6.43964923e-01  2.45415607e+00 -4.19227974e-02 -4.13923743e-05
 -6.43964923e-01 -2.45415607e+00  4.19227974e-02  4.13923743e-05
  2.04688672e-01 -3.62116573e+00 -5.56304536e-01 -4.10797619e+00
  9.83553548e-01  4.58972197e-02  1.02030862e+00  1.03264372e+00
 -9.27830659e-01 -9.23460268e-01 -9.59265243e-01 -9.58659617e-01
 -1.02076588e-03 -1.01946938e-03 -1.06012523e-03 -1.05947266e-03
  5.36471136e-01  5.30930688e-12  1.75341838e-02  5.48126266e-05
 -2.88398441e+00 -1.33329755e-01 -1.01144267e+00 -1.31842362e-01
 -7.93561606e-01 -6.46234633e-01 -1.01424755e+00 -5.49664472e-03
 -7.07466743e-01 -3.53331897e-01 -7.33725814e-01 -1.35959106e-03
 -5.19860838e-02 -2.02421407e-02 -5.10846093e+00 -5.83984102e-02
  8.67707299e-02  6.95330615e-02  6.18718331e+00  9.83333753e-02
  5.31460622e-01  1.69764599e+00  2.25524371e+00  5.93482802e-01
 -2.11667842e-02 -1.49504329e-01 -2.12968564e-02 -2.64316156e-02
 -1.04058845e+00  9.75074403e+00 -3.67445391e+00  1.18712509e+01
  1.54051720e+00 -6.84223228e+00 -1.26499767e+00  1.19846743e+01
  1.37163721e+01]
supnorm grad right now is: 13.716372105964243
Weights right now are: 
[ -2.70823396   1.22773443 -11.59284308 -13.11618845   2.96280267
  -1.33642612  11.99178035  12.40016001  -2.5834901   -3.49113779
   3.12428501   4.11078656   8.56186139  27.29422049 -23.35975195
  14.77117205  20.89953744 -12.94821308  -2.22118282  -1.24793315
  21.79031889 -11.11332123  -0.27138708   1.12136055   0.2968399
  -8.09062342 -85.75770868  21.80150841  -4.40845233  13.99667068
  13.59820484 -19.00370835 -15.51791581  12.50138276   2.1637958
  -3.58773114  -6.98831647  22.24900367  -0.83239512 -77.44560766
 -51.6224332  -94.69311866   1.9656339  -56.00411595  35.2932827
  30.79189974   0.53928266  39.69097813   2.91998775   3.60571306
  -0.27009904   2.77853781  58.52268075  -2.79457591  69.22163474
  58.67996088  -0.19880526  -2.64714917  -6.16945202  -3.99944684
  13.40793063   2.22267166  -0.42790258  -2.6108595   26.92138426]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2572.70209624096
gradient value of function right now is: [-7.72650115e-01 -1.09012621e+00 -3.82231932e-04 -9.26213782e-08
  7.72650115e-01  1.09012621e+00  3.82231933e-04  9.26214081e-08
 -9.40701670e-01  4.78183073e-01 -4.44414221e-01  1.41185487e+00
 -1.65090759e+00 -5.53186509e-02 -1.67565513e+00 -1.69068700e+00
 -7.82265206e-03 -7.93593992e-03 -8.20367241e-03 -8.19818944e-03
 -2.14362242e-06 -2.33259027e-06 -2.32790993e-06 -2.32212894e-06
  6.92479752e-03  6.94423022e-14  8.17193312e-05  4.20100967e-08
  2.64684487e+00  1.84064722e-01  1.19931003e+00  1.25636056e-01
  4.32895954e-01  4.26407531e-01  7.55962826e-01 -1.71493408e-02
  3.09716010e-01  1.50541649e-01  4.64255153e-01  1.56802932e-03
  4.78891300e-02  6.67001902e-03  4.09073928e+00  4.98879849e-02
 -6.81779917e-02 -2.80842464e-02 -4.26499974e+00 -7.23543675e-02
 -2.99087826e-01 -4.75783328e-01 -2.64382414e+00 -3.27142053e-01
  2.26454189e-02  6.87820819e-02  1.53404958e-02  2.69938599e-02
  3.58653829e-01 -7.59244897e+00  2.07564179e+00 -5.69019973e+00
 -1.55641505e+00  6.22308478e+00  4.37466286e-01 -8.67072919e+00
 -9.77493214e+00]
supnorm grad right now is: 9.77493213813441
Weights right now are: 
[ -2.86678397   1.39125997 -11.27216385 -12.92962057   3.12135268
  -1.49995166  11.67110112  12.2135921   -3.13634384  -3.68394884
   3.25188004   3.84506524   8.33961961  28.466617   -23.43255298
  14.7690311   21.30682778 -12.82249281  -2.02279105  -1.04911933
  22.48621587 -10.5565549    0.31880645   1.71180809   0.22049253
  -8.09686309 -88.22693118  21.3499049   -4.08557919  11.05327008
  13.67860375 -20.80402332 -16.37203028  11.3664837    1.56838463
  -2.13884393  -7.30356833  22.66065283  -1.5338539  -79.96538272
 -52.19215411 -98.58571567   2.35282851 -56.52062684  37.12765904
  31.70846253   0.52521357  41.4854334    2.48801151   3.84415856
  -0.37573902   2.46657756  60.74946064  -1.93335111  70.15688424
  60.76814811  -0.80370159  -2.49040278  -6.19841426  -4.33727164
  13.48262648   2.66351284  -1.0175936   -2.49081572  26.7492933 ]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2572.171642373741
gradient value of function right now is: [-3.54851852e-01  3.16116142e+00 -2.15475603e-02 -8.67607005e-06
  3.54851852e-01 -3.16116142e+00  2.15475603e-02  8.67607007e-06
 -3.27894037e+00 -6.46521678e+00 -3.96906619e+00 -6.68960455e+00
  2.54305040e-01  4.94595785e-02  2.92314471e-01  2.72236339e-01
 -3.61741844e-01 -4.37454855e-01 -4.47490456e-01 -4.46648364e-01
 -1.75224757e-04 -2.14905674e-04 -2.19711724e-04 -2.19297934e-04
  1.17271676e+00 -1.37770716e-12  1.76305062e-02 -1.62157809e-05
 -4.03354653e+00 -1.78517295e-01 -1.28185497e+00 -2.63731335e-01
 -1.03865622e+00 -6.93331911e-01 -9.73836522e-01 -1.79090565e-01
 -1.72750296e+00 -6.82183187e-01 -1.55570537e+00 -7.02651205e-03
 -7.45334729e-02 -2.31248768e-02 -4.00112455e+00 -7.19377720e-02
  1.73345841e-01  1.23781262e-01  6.97679125e+00  1.68974620e-01
  8.12283217e-01  2.76735459e+00 -6.16249880e-02  8.36854942e-01
 -4.59936496e-02 -2.32697428e-01 -4.46181358e-02 -4.71383784e-02
 -1.53055659e+00  1.49232611e+01 -5.50141284e+00  1.71291289e+01
  1.97804671e+00 -9.26598680e+00 -1.75295540e+00  1.62384289e+01
  2.11853394e+01]
supnorm grad right now is: 21.185339360291454
Weights right now are: 
[  -3.03945443    1.40699626  -11.07732953  -13.0241853     3.29402314
   -1.51568795   11.47626679   12.30815678   -3.44248556   -3.0967894
    3.35482681    3.76786342    8.32189174   26.05108081  -23.45617486
   14.79193849   21.99408858  -12.58141285   -1.68559508   -0.71103698
   23.09249333  -10.39846896    0.55554709    1.94947494    0.30299807
   -8.09749481  -91.32280365   22.56209914   -4.22446708   15.89996917
   13.91271138  -16.48797553  -14.17732451   14.15517317    2.84637621
   -4.49224307   -6.24316244   22.24494573   -0.9447431   -84.78825106
  -52.46331008 -101.63390822    1.73306151  -56.80944834   36.96127559
   29.91384688    0.49235857   41.32520302    2.53161726    3.56315718
   -0.46537719    2.54477751   63.91005557   -2.61667462   70.34489385
   63.67315173   -0.33203378   -2.57481867   -6.64857894   -4.09904018
   14.51572366    1.82005557   -0.45963505   -2.60831373   27.29648327]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -2573.5471299661135
gradient value of function right now is: [-1.54839023e+00 -3.15929392e+00  4.64099805e-03  7.19378128e-07
  1.54839023e+00  3.15929392e+00 -4.64099805e-03 -7.19377919e-07
 -2.38696308e+00  1.08281936e+00 -1.94546162e+00  1.69148501e+00
 -1.88755996e+00 -5.88058159e-02 -1.92647018e+00 -1.94967517e+00
  8.95976505e-02  9.95459294e-02  1.02987403e-01  1.02884325e-01
  1.57373625e-05  1.75171239e-05  1.81285546e-05  1.81130913e-05
 -1.17601498e-01  1.88299707e-13 -2.71524471e-03  1.42976686e-05
  2.40111366e+00  2.19230841e-01  1.11551764e+00  2.05357412e-01
  6.53963239e-01  5.34529571e-01  7.30097709e-01 -8.39615020e-03
  1.15801701e+00  4.74875312e-01  1.13254188e+00  2.39028442e-03
  6.26225303e-02  7.72693474e-03  4.03664950e+00  6.34250800e-02
 -1.33538093e-01 -3.83380216e-02 -6.81827426e+00 -1.36139429e-01
 -3.62713121e-01 -5.85449346e-01 -2.24364989e+00 -3.75686967e-01
  2.01075477e-02  7.12767538e-02  1.69001077e-02  2.21741645e-02
  1.22095194e+00 -1.37092954e+01  2.02044590e+00 -6.10944449e+00
 -1.44256768e+00  6.87143939e+00  1.44461877e+00 -1.54309893e+01
 -9.76819275e+00]
supnorm grad right now is: 15.43098934057185
Weights right now are: 
[-2.63067810e+00  1.38452866e+00 -1.11095177e+01 -1.29549380e+01
  2.88524681e+00 -1.49322035e+00  1.15084550e+01  1.22389094e+01
 -3.54592900e+00 -2.92613736e+00  3.18933998e+00  3.63526446e+00
  8.24166633e+00  2.82306208e+01 -2.33141401e+01  1.50099614e+01
  2.21638858e+01 -1.28797866e+01 -1.79702697e+00 -8.20599103e-01
  2.32640600e+01 -1.03739435e+01  6.83215296e-01  2.07843385e+00
  7.28255074e-01 -8.25632585e+00 -9.31950860e+01  2.51754006e+01
 -3.76924873e+00  1.46383412e+01  1.30564199e+01 -1.77477936e+01
 -1.48665817e+01  1.36032790e+01  1.74057251e+00 -6.91980370e+00
 -6.85216033e+00  2.23607708e+01 -6.92420003e-01 -8.74657553e+01
 -5.33696683e+01 -1.06438962e+02  1.63235256e+00 -5.77437922e+01
  3.86534272e+01  3.13067975e+01  5.02863745e-02  4.30521405e+01
  1.95555267e+00  3.76586356e+00 -5.60880408e-01  2.06412662e+00
  6.43804890e+01 -4.89800663e+00  7.27897674e+01  6.39650027e+01
 -3.43680233e-01 -2.49781138e+00 -6.68009105e+00 -4.53148825e+00
  1.40580590e+01  2.30713422e+00 -4.95743799e-01 -2.50866110e+00
  2.69108841e+01]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -2571.670350241424
gradient value of function right now is: [-1.70456714e+00 -2.00482309e+00 -2.37225535e-03 -3.43597285e-07
  1.70456714e+00  2.00482309e+00  2.37225535e-03  3.43597300e-07
 -4.43317522e+00 -1.39621396e+00 -3.77149053e+00 -1.78362637e+00
 -8.62656357e-01 -2.08683020e-02 -9.12452400e-01 -9.39696243e-01
 -4.51617799e-02 -4.81055882e-02 -5.01223199e-02 -5.00575910e-02
 -7.76361318e-06 -8.34075712e-06 -8.70228261e-06 -8.68896259e-06
  6.12035862e-02 -5.37984714e-16  9.22128815e-04  3.89147369e-07
 -2.20372468e-01  1.06518084e-01  1.56692443e-01  6.13746249e-02
  7.49152010e-01  6.44769674e-01  1.12866871e+00 -1.62369718e-02
  4.81010219e-01  2.19374672e-01  7.03715137e-01  7.80536274e-04
  5.99921292e-02  6.87208580e-03  5.82612977e+00  6.04903799e-02
 -7.63068662e-02 -1.31362721e-02 -6.62539934e+00 -7.70475902e-02
  1.66634744e-01  3.71209476e-01 -6.74427475e-01  1.74090858e-01
  1.37030620e-03 -6.40922699e-03  7.80338395e-03  1.47475145e-03
  8.76593604e-01 -1.06875658e+01  7.58798921e-02 -1.67454223e+00
 -1.03362320e+00  4.71939643e+00  1.00375398e+00 -1.18627223e+01
 -7.38910593e-01]
supnorm grad right now is: 11.862722279965787
Weights right now are: 
[  -2.91931844    1.45918995  -10.89475587  -13.01997624    3.17388715
   -1.56788164   11.29369313   12.30394764   -3.2034824    -3.64050225
    3.28394197    3.3674738     8.02206867   26.34359264  -23.3081995
   15.29770971   22.10164214  -13.12179591   -1.97769106   -1.00003734
   23.05258827  -10.47103002    0.56719958    1.9631805     0.14162246
   -8.24039437  -95.47234645   26.23059583   -4.02200043   12.854297
   13.10644799  -19.41971638  -15.29380896   12.93134759    1.55673146
   -4.8303528    -6.58139293   21.90616405   -1.5417088   -89.76416883
  -53.76015762 -110.08501035    1.95329822  -58.13963429   39.63910795
   33.85547506    0.50887444   44.08016417    2.66421356    3.19923226
   -0.45047231    2.72244503   65.22393075   -4.93129662   75.26450412
   64.62304078   -0.66673399   -2.63693286   -6.97668009   -4.55279254
   14.04748547    2.6582966    -0.83765476   -2.64889974   27.07399574]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2568.2261171456043
gradient value of function right now is: [-1.38092345e-01  2.64994755e-01 -2.00456964e-02 -1.22837673e-05
  1.38092345e-01 -2.64994755e-01  2.00456964e-02  1.22837672e-05
 -2.65814808e+00 -3.56600050e+00 -2.70453362e+00 -4.95734943e+00
  3.20191947e+00  1.61430348e-01  3.22293547e+00  3.17179728e+00
 -3.55551959e-01 -4.01671520e-01 -4.11172020e-01 -4.10847961e-01
 -2.72756615e-04 -3.10717315e-04 -3.18124625e-04 -3.17877609e-04
  9.04791184e-01 -2.75110644e-14  1.58005999e-02  3.95955580e-06
 -5.51237199e+00 -3.42907861e-01 -2.16369614e+00 -9.51538816e-02
 -2.88385138e-01 -1.96935539e-01 -3.12610720e-01  1.13939453e-01
 -2.17132996e+00 -7.75732316e-01 -1.66502593e+00 -9.21193014e-03
 -1.26935281e-01 -4.81722345e-03 -5.88168378e+00 -1.35287540e-01
  2.25743715e-01  1.32477247e-02  8.91528259e+00  2.43315475e-01
  1.12965983e+00  1.19637966e+00  6.43252432e+00  1.22180261e+00
 -7.30104808e-03  1.35333096e-02 -2.89995934e-02 -8.28867246e-03
 -3.91499911e+00  3.03645731e+01 -1.12320263e+00  3.36244049e+00
  1.50145048e+00 -8.38442022e+00 -4.59077604e+00  3.53844391e+01
  2.26889177e+01]
supnorm grad right now is: 35.384439136797866
Weights right now are: 
[-2.81972131e+00  1.13315057e+00 -1.08167304e+01 -1.32981705e+01
  3.07429002e+00 -1.24184226e+00  1.12156676e+01  1.25821418e+01
 -3.11640311e+00 -2.96211103e+00  2.85983274e+00  4.39309202e+00
  7.97623635e+00  2.58770375e+01 -2.35694588e+01  1.51043454e+01
  2.23213027e+01 -1.31736620e+01 -1.98325105e+00 -1.00491436e+00
  2.28294352e+01 -1.08556611e+01  2.03720039e-01  1.59966745e+00
  9.48280065e-02 -8.23100161e+00 -9.70373802e+01  3.09876375e+01
 -4.35927389e+00  1.11611619e+01  1.43639112e+01 -1.74263197e+01
 -1.38025255e+01  1.39260161e+01  2.06235890e+00  3.22608927e+00
 -7.14034306e+00  2.17699330e+01 -1.09373587e+00 -9.07256028e+01
 -5.39609393e+01 -1.14304415e+02  2.04290721e+00 -5.83566835e+01
  4.16019099e+01  3.71022156e+01  4.76144833e-01  4.61233552e+01
  3.89790429e+00  3.79270654e+00  2.92988738e-01  3.88095506e+00
  6.41343344e+01 -7.79325499e+00  7.69246617e+01  6.33589921e+01
 -5.68104978e-01 -2.50228745e+00 -7.07153597e+00 -5.19023284e+00
  1.45167880e+01  1.78065164e+00 -8.11100171e-01 -2.48735219e+00
  2.71520473e+01]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2573.8364218121355
gradient value of function right now is: [ 2.61075693e-01 -1.70216841e+00 -9.38720080e-03 -2.42763153e-06
 -2.61075693e-01  1.70216841e+00  9.38720080e-03  2.42763152e-06
 -4.29433885e-01 -9.59152900e-02 -8.39506070e-01 -2.05949582e-01
  8.20782424e-01  1.49418652e-02  8.82497250e-01  9.12814931e-01
 -1.83969841e-01 -1.93837418e-01 -1.98480385e-01 -1.97975098e-01
 -5.91179030e-05 -6.29564413e-05 -6.42365707e-05 -6.40704959e-05
  2.61951363e-01  7.12342542e-18  5.35076359e-03 -1.23258781e-07
  1.45158381e-01  1.48892141e-02  5.83334326e-02  6.97973642e-02
 -5.17871275e-01 -5.23843971e-01 -6.09349959e-01  1.27433770e-02
  3.64691837e-01  1.56359991e-01  3.57729415e-01 -2.90788224e-03
  4.84299445e-03  7.28178031e-04 -3.21181448e-01  4.78385893e-03
 -2.08766756e-02 -5.05110100e-03 -6.50086598e-01 -2.11368570e-02
  1.34943552e-01  1.99039097e-01  4.61415082e-01  1.42310284e-01
  9.42870486e-03  5.91261017e-02 -9.91646211e-03  1.17146292e-02
 -4.72571893e-01 -6.95393750e-01  8.04625345e-01 -1.78903107e+00
  7.66727903e-01 -4.25918850e+00 -5.54202439e-01 -6.88622010e-01
  2.08177344e+00]
supnorm grad right now is: 4.259188498389203
Weights right now are: 
[-2.82688573e+00  1.32876386e+00 -1.12070350e+01 -1.35915948e+01
  3.08145444e+00 -1.43745555e+00  1.16059723e+01  1.28755661e+01
 -2.74489763e+00 -3.12352926e+00  2.89076052e+00  3.95000997e+00
  8.18523174e+00  2.06780257e+01 -2.33885666e+01  1.54296395e+01
  2.20503932e+01 -1.37551268e+01 -2.48632175e+00 -1.50654548e+00
  2.27573434e+01 -1.12157998e+01 -8.14638675e-02  1.31588180e+00
 -7.05037333e-02 -8.23146241e+00 -1.01660508e+02  2.87192639e+01
 -4.28946815e+00  1.36731541e+01  1.48689192e+01 -1.65609733e+01
 -1.48537781e+01  1.31628082e+01  1.50252457e+00 -9.87231199e-01
 -5.97774471e+00  2.24698684e+01 -1.51177948e+00 -9.08368315e+01
 -5.49183561e+01 -1.17232636e+02  1.77671062e+00 -5.92823965e+01
  4.25519507e+01  3.94724700e+01  4.29555271e-01  4.70538596e+01
  2.80704147e+00  3.06878290e+00 -2.65844747e-01  3.06547487e+00
  6.55800402e+01 -5.51690033e+00  7.83703812e+01  6.44164378e+01
 -6.19847325e-01 -2.60835945e+00 -7.22032927e+00 -4.98612627e+00
  1.49517162e+01  1.86903489e+00 -9.01137123e-01 -2.63344410e+00
  2.70757609e+01]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2572.07713891796
gradient value of function right now is: [-1.69954433e+00 -3.46559487e+00  3.80515100e-03  1.59905472e-06
  1.69954433e+00  3.46559487e+00 -3.80515100e-03 -1.59905500e-06
 -3.65295134e+00  1.18890238e+00 -2.46569396e+00  1.57434784e+00
 -1.21137940e+00 -4.55385361e-02 -1.26878877e+00 -1.29137236e+00
  7.61810857e-02  8.07751941e-02  8.22600796e-02  8.22009416e-02
  3.91395409e-05  4.14800688e-05  4.24328098e-05  4.24093765e-05
 -8.92739494e-02  1.70300998e-18 -2.07484897e-03  1.93769673e-07
  2.12733107e+00  1.70359417e-01  9.78620528e-01  1.11647009e-01
  8.41236654e-01  8.66241881e-01  1.59374468e+00 -1.47429505e-02
  8.63669322e-01  5.38934827e-01  1.43636908e+00  1.04544267e-03
  9.65221667e-02  5.26983758e-03  9.60658385e+00  1.12335781e-01
 -1.36462965e-01 -1.28530022e-02 -1.23216261e+01 -1.59372618e-01
 -2.48074962e-01 -5.44457253e-01 -3.06492354e-01 -3.06713276e-01
  1.68830474e-02  5.14092035e-02  1.14547910e-02  2.33321342e-02
  1.56679193e+00 -1.91035407e+01  1.48204355e+00 -4.11373078e+00
 -1.83263232e+00  8.44715868e+00  2.08418990e+00 -2.43475977e+01
 -1.21707676e+01]
supnorm grad right now is: 24.347597692550448
Weights right now are: 
[-2.91650241e+00  1.40393079e+00 -1.10505667e+01 -1.36227980e+01
  3.17107112e+00 -1.51262248e+00  1.14495040e+01  1.29067694e+01
 -2.64945988e+00 -3.48962273e+00  2.80435093e+00  3.85035171e+00
  7.97945260e+00  2.11390345e+01 -2.35046614e+01  1.54310123e+01
  2.25532235e+01 -1.36624101e+01 -2.29693060e+00 -1.31689311e+00
  2.30847396e+01 -1.12446554e+01 -2.83470370e-02  1.36906023e+00
  3.06910585e-01 -8.24976761e+00 -1.04689682e+02  3.18543732e+01
 -4.77670548e+00  9.39204322e+00  1.37830633e+01 -2.13023811e+01
 -1.58311561e+01  1.17206533e+01  4.45039812e-01 -1.46646220e+00
 -7.02902715e+00  2.16884041e+01 -2.38667277e+00 -8.96246299e+01
 -5.49265831e+01 -1.21658150e+02  2.28184832e+00 -5.94124658e+01
  4.48409827e+01  4.32945553e+01  3.26019923e-01  4.95370317e+01
  2.48771438e+00  3.18012375e+00 -3.97194460e-01  2.67564032e+00
  6.52673195e+01 -6.52481735e+00  8.09666017e+01  6.35836434e+01
 -6.38355434e-01 -2.66285981e+00 -7.41316041e+00 -5.24873030e+00
  1.43449887e+01  2.73422975e+00 -9.32609400e-01 -2.60665891e+00
  2.68601510e+01]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2570.0279370266444
gradient value of function right now is: [-1.90475858e+00 -4.54873204e+00  2.26294766e-03  1.03299304e-07
  1.90475858e+00  4.54873204e+00 -2.26294766e-03 -1.03299064e-07
 -6.41534121e+00  6.62477356e-01 -5.01928985e+00  4.74528339e-01
 -3.55696112e-01 -1.05240831e-02 -4.05668335e-01 -4.09222974e-01
  4.83829714e-02  4.86668466e-02  4.94431044e-02  4.94499604e-02
  2.67675733e-06  2.64180749e-06  2.72735413e-06  2.73300742e-06
 -1.62851339e-02 -7.15834967e-10 -1.39609454e-03 -2.55147526e-03
  8.07860639e-01  4.02973846e-02  3.27043964e-01  2.00578976e-02
  1.09923876e+00  1.13599298e+00  2.08614259e+00 -1.54904600e-03
  9.72373664e-01  6.05790378e-01  1.49583215e+00  1.09301875e-03
  8.78208291e-02  6.04895954e-03  1.14667994e+01  1.11807187e-01
 -1.16732196e-01 -1.01699529e-02 -1.37376298e+01 -1.48196614e-01
 -9.48487860e-02 -2.24348147e-01  6.72808522e-02 -1.22437698e-01
  4.00656586e-03  3.47056559e-02  4.18647934e-03  5.74319300e-03
  1.82289989e+00 -1.95883623e+01  7.55453658e-01 -3.15945582e+00
 -1.42445289e+00  8.98681961e+00  2.62498321e+00 -2.72343345e+01
 -1.34741703e+01]
supnorm grad right now is: 27.234334536572767
Weights right now are: 
[-3.18433457e+00  1.35917740e+00 -1.08375989e+01 -1.35642510e+01
  3.43890328e+00 -1.46786909e+00  1.12365362e+01  1.28482223e+01
 -2.47031190e+00 -4.02432198e+00  3.02205731e+00  4.28193965e+00
  8.31239877e+00  1.94374460e+01 -2.32719768e+01  1.56791921e+01
  2.25342517e+01 -1.38018046e+01 -2.46553743e+00 -1.48241647e+00
  2.34296889e+01 -1.07763505e+01  4.13065013e-01  1.81335382e+00
  6.39962498e-01 -9.76910074e+00 -1.05958707e+02  3.40623037e+01
 -5.33527301e+00  9.09564821e+00  1.43733386e+01 -2.14049520e+01
 -1.64616052e+01  1.17978854e+01  5.35274807e-01  7.76494789e-01
 -7.03787643e+00  2.18531735e+01 -2.03394256e+00 -9.20240392e+01
 -5.64677527e+01 -1.27081789e+02  2.06198540e+00 -6.10427809e+01
  4.87180072e+01  4.69365654e+01  3.07733918e-01  5.36535987e+01
  4.12800667e+00  3.71612342e+00 -5.92345939e-01  4.40572011e+00
  6.06428745e+01 -7.96890667e+00  8.26832396e+01  5.83475125e+01
  5.76326144e-02 -2.69635351e+00 -7.95692899e+00 -5.05444964e+00
  1.41525767e+01  2.38205342e+00 -3.48723899e-01 -2.60457815e+00
  2.65543986e+01]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2569.4933256306776
gradient value of function right now is: [ 1.56835579e+00  5.41561394e+00 -3.45597765e-03 -1.73686685e-06
 -1.56835579e+00 -5.41561394e+00  3.45597765e-03  1.73686685e-06
  5.23700743e+00  1.18086149e-01  4.36878601e+00  7.03153639e-01
 -1.71120472e+00 -8.44137130e-02 -1.67276909e+00 -1.63352363e+00
 -3.65529003e-02 -5.68102499e-02 -5.77867242e-02 -5.75572583e-02
 -2.88530212e-05 -4.42060478e-05 -4.49661310e-05 -4.47909548e-05
  3.76094943e-01 -3.17352241e-13  9.17356549e-03 -7.90613091e-05
  1.24017424e+00  1.11764442e-01  6.26542919e-01  6.33292141e-02
 -4.63271239e-01 -5.13998334e-01 -1.30901056e+00 -1.90049564e-03
 -2.53075433e-01 -2.93110041e-01 -8.77714575e-01  9.77467716e-04
 -6.06500583e-02  7.17752120e-04 -6.92997133e+00 -6.29611721e-02
  8.13551722e-02 -2.93981616e-03  8.75191099e+00  8.37018941e-02
  5.44126277e-02  1.62352231e-01 -2.13180989e+00  5.43416651e-02
  1.79824737e-02  2.81907779e-02  1.31360027e-02  2.10034929e-02
 -2.13792790e+00  1.63158387e+01  3.95590317e-01 -8.23989515e-01
 -4.92849921e-01 -8.91944537e-02 -2.35226688e+00  1.83359990e+01
  6.67585690e+00]
supnorm grad right now is: 18.335998967037273
Weights right now are: 
[  -2.91442929    1.25311455   -9.82719934  -13.3034914     3.168998
   -1.36180624   10.22613661   12.58746266   -2.44241117   -3.81830113
    3.08353857    4.64625271    7.72832443   15.61703552  -23.81018355
   15.31507991   24.03456621  -12.68393618   -1.34854564   -0.3641808
   24.23715861  -10.14688346    1.02678461    2.42706647    1.79226647
   -7.31156326 -104.15432479   39.00962539   -4.42101846    6.19250033
   15.54422675  -25.58372474  -17.28784924   10.42299512    0.23699995
    1.5013854    -5.55064329   22.91950285   -1.14761119  -91.19364786
  -56.13104133 -128.51778173    2.57738407  -60.80377999   51.22813741
   47.97846145    0.33517195   56.26590685    6.64634913    4.32028844
   -0.54161997    6.97355677   62.53939682   -7.8853327    86.59423158
   59.70209421   -1.02626581   -2.53169431   -8.71846823   -5.77742497
   13.0902879     2.84233948   -1.20620589   -2.52998852   26.96307249]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2567.913066157174
gradient value of function right now is: [-1.14095895e+00 -3.13400343e+00 -1.59383146e-04 -1.24131968e-07
  1.14095895e+00  3.13400343e+00  1.59383146e-04  1.24131972e-07
 -3.35137109e+00  3.83459504e-01 -2.19615022e+00 -1.13711486e-01
  5.16004243e-01  2.33523681e-02  4.35382543e-01  3.88226450e-01
  6.18124209e-03  1.01503063e-03  1.97865905e-03  1.78500657e-03
 -8.90212818e-07 -3.71344622e-06 -3.34146989e-06 -3.37644836e-06
  8.84872833e-02 -4.98206519e-08  4.59488207e-03  6.67788002e-03
 -1.73693772e-01 -7.67891391e-03 -1.42847619e-01 -2.57109547e-03
  7.22705494e-01  6.97576415e-01  1.43359135e+00 -1.14642684e-04
  3.90055712e-01  3.15462973e-01  9.46139856e-01  4.99656707e-04
  7.45667965e-02  8.52871868e-03  9.22492039e+00  7.24925823e-02
 -1.03629937e-01 -2.83374139e-03 -1.19507215e+01 -1.00402946e-01
  1.34308484e-03  1.94597769e-01  1.27913995e+00  2.09945359e-03
 -3.07913699e-03 -6.64967571e-02 -1.98921309e-03 -3.29314707e-03
  1.24443707e+00 -1.75573255e+01 -4.64679103e-01 -1.15406332e+00
 -3.81027839e-01  2.82390893e+00  1.31307052e+00 -1.86167674e+01
 -3.19554605e+00]
supnorm grad right now is: 18.616767380755082
Weights right now are: 
[-2.68232500e+00  1.27847292e+00 -1.05168882e+01 -1.38247046e+01
  2.93689371e+00 -1.38716461e+00  1.09158254e+01  1.31086758e+01
 -2.22946511e+00 -3.78266839e+00  2.89235012e+00  4.55007761e+00
  7.99479312e+00  1.93201457e+01 -2.32709272e+01  1.61426532e+01
  2.28891473e+01 -1.36691283e+01 -2.33217258e+00 -1.29481580e+00
  2.32826600e+01 -1.10980758e+01  7.04577904e-02  1.52832088e+00
  1.02248466e+00 -7.07539827e+00 -1.06090684e+02  4.21135950e+01
 -4.50477406e+00  9.90751091e+00  1.60220094e+01 -1.95568727e+01
 -1.50756573e+01  1.17768603e+01  5.45830353e-01 -1.14642690e+00
 -4.66692617e+00  2.27211242e+01 -2.10318057e+00 -9.30196760e+01
 -5.57367222e+01 -1.31127384e+02  2.36118961e+00 -6.05053369e+01
  5.29282355e+01  5.08654365e+01  4.89533990e-01  5.81736335e+01
  3.93147614e+00  3.38084840e+00  3.24646758e-02  4.26289975e+00
  6.39425497e+01 -8.05532266e+00  8.67317907e+01  6.08307265e+01
 -4.03438349e-01 -2.65393244e+00 -1.06322320e+01 -4.61456932e+00
  1.34527813e+01  2.76702748e+00 -5.81525727e-01 -2.68285771e+00
  2.66473131e+01]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2569.8021580607247
gradient value of function right now is: [-1.75437653e+00 -5.86426957e+00  7.57664620e-03  2.44517042e-06
  1.75437653e+00  5.86426957e+00 -7.57664620e-03 -2.44517041e-06
 -5.40247773e+00  2.74397386e+00 -3.97508837e+00  2.30474999e+00
 -6.70236865e-01 -4.13568441e-02 -6.98520544e-01 -7.05324835e-01
  1.42590010e-01  1.53498918e-01  1.56040618e-01  1.55816018e-01
  6.00010366e-05  6.42584773e-05  6.54051705e-05  6.53163875e-05
 -1.75885371e-01  4.00504220e-12 -7.06119001e-03 -4.80975242e-03
  1.30040320e+00  1.79691201e-02  4.23318367e-01  4.47680671e-03
  7.84451778e-01  8.78720318e-01  1.64159788e+00 -4.99083296e-03
  9.04450614e-01  6.24480881e-01  1.63674118e+00  5.23394493e-04
  9.48337590e-02  3.63930270e-03  1.04040412e+01  1.01251722e-01
 -1.38595422e-01 -5.78298379e-03 -1.44691893e+01 -1.47633232e-01
 -2.47692092e-01 -7.88803157e-01  4.73134048e-01 -2.90388324e-01
  6.88121676e-03  8.25469551e-02  2.77213402e-03  9.37901574e-03
  2.05365853e+00 -2.36759886e+01  1.04879642e+00 -3.18507422e+00
 -1.25612485e+00  7.34785040e+00  2.50135820e+00 -2.76456414e+01
 -1.27940782e+01]
supnorm grad right now is: 27.645641426765565
Weights right now are: 
[-3.04017459e+00  1.06002876e+00 -1.01347420e+01 -1.37355577e+01
  3.29474330e+00 -1.16872045e+00  1.05336792e+01  1.30195289e+01
 -2.36726221e+00 -3.47895662e+00  2.89964368e+00  4.55562391e+00
  7.65214303e+00  1.62961579e+01 -2.36416399e+01  1.57472556e+01
  2.33773747e+01 -1.34686179e+01 -2.05132918e+00 -9.91976194e-01
  2.37158585e+01 -1.08849294e+01  3.37362525e-01  1.80912510e+00
  1.55501180e+00 -7.32551718e+00 -1.09401467e+02  3.92185663e+01
 -4.75574401e+00  4.88640829e+00  1.52283507e+01 -2.65525387e+01
 -1.63919225e+01  1.05187084e+01  1.01158238e-03  3.40235761e+00
 -6.09652667e+00  2.29776587e+01 -2.56244224e+00 -9.19306770e+01
 -5.58547529e+01 -1.29710155e+02  2.46384890e+00 -6.04686942e+01
  5.71239566e+01  5.64604091e+01  3.19629340e-01  6.24204435e+01
  4.12124137e+00  3.18770791e+00 -1.13307514e-01  4.63318754e+00
  6.09688173e+01 -6.79680762e+00  8.77139086e+01  5.76293345e+01
 -7.20720333e-01 -2.73450933e+00 -1.04377780e+01 -5.62279976e+00
  1.39702521e+01  2.60746680e+00 -1.17143417e+00 -2.73732314e+00
  2.67803941e+01]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2573.720644388005
gradient value of function right now is: [-5.82123006e-01 -1.42249728e+00  5.93506601e-04  1.59382747e-08
  5.82123006e-01  1.42249728e+00 -5.93506601e-04 -1.59382402e-08
 -1.85691822e+00  5.79754197e-01 -1.47831199e+00  5.63168769e-01
 -1.12093385e+00 -5.34694478e-02 -1.12700195e+00 -1.11792811e+00
  1.94230524e-02  1.63574794e-02  1.65127589e-02  1.65270573e-02
  8.74216119e-07  3.90864860e-07  4.24699590e-07  4.31481113e-07
  6.57625816e-02 -1.72761022e-20  1.23883322e-03 -5.46261371e-06
  1.14488964e+00  2.86074340e-02  5.43349780e-01  2.20478975e-02
  3.01197464e-01  2.73142967e-01  5.29473089e-01  1.11438543e-02
  4.41521293e-01  2.24564688e-01  6.20603254e-01  1.56219282e-03
  3.28775972e-02  1.03310496e-03  2.64647833e+00  3.23800817e-02
 -4.38997080e-02 -1.77917711e-03 -3.52655896e+00 -4.36243709e-02
 -9.77247609e-02 -9.29534966e-02 -1.30811663e+00 -1.04647997e-01
  5.44030855e-03  2.18970014e-02  4.07231910e-03  6.71862128e-03
  8.85413777e-01 -8.18898177e+00  3.40004031e-01 -9.35689246e-01
 -5.02575058e-01  2.85003963e+00  1.02616897e+00 -8.92979080e+00
 -7.03665709e+00]
supnorm grad right now is: 8.929790803622598
Weights right now are: 
[  -2.98576917    1.20595156  -10.14112002  -13.72316089    3.24033788
   -1.31464325   10.54005729   13.00713202   -2.4747906    -4.00363219
    2.80320136    4.54722869    7.49577101   15.53400554  -23.77612944
   15.72190336   23.04796364  -13.8603294    -2.38874097   -1.32800917
   23.607511    -10.83604393    0.42380926    1.89556636    0.80239965
   -7.32551312 -113.75543667   36.43844423   -5.60556835   10.94713888
   15.38742793  -22.97846591  -15.40296831   11.46511649    0.61055733
    2.82605255   -5.82424258   22.90306098   -2.87735429  -94.66511071
  -55.55367451 -126.36304616    2.23198521  -60.00583943   59.69673904
   59.94638665    0.46637447   64.96579098    4.24354651    2.83559149
   -0.53727706    4.97768066   60.54075308   -4.51891088   88.12991041
   56.78129959   -0.69481874   -2.68495376   -9.53439359   -6.03630706
   14.09126847    2.30421921   -1.11460179   -2.74364237   26.72314834]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2569.9936836683987
gradient value of function right now is: [ 4.31613568e-01  9.68371993e-01 -4.81523709e-03 -1.00158992e-06
 -4.31613568e-01 -9.68371993e-01  4.81523709e-03  1.00159045e-06
  1.43583476e+00 -3.81297067e-01  1.15455058e+00 -3.85802397e-01
  4.72642295e-01  6.23679061e-02  4.92300309e-01  5.08156204e-01
 -7.03043382e-02 -8.31113527e-02 -8.37141434e-02 -8.35388630e-02
 -2.21412040e-05 -2.64167095e-05 -2.66386884e-05 -2.65660559e-05
  2.54676783e-01  7.16660263e-09  1.34346213e-02  2.49665019e-02
 -9.66228359e-01 -9.27628095e-03 -3.86800685e-01 -5.80581294e-03
 -1.22778190e-01 -1.13914988e-01 -2.49122239e-01 -1.16125860e-04
 -2.30718123e-01 -1.36338575e-01 -2.18308554e-01  1.67879984e-04
 -1.15169374e-02 -4.63168357e-03 -1.82891949e+00 -1.37159443e-02
  1.43887651e-02  1.40500646e-02  2.59250658e+00  1.80604047e-02
  1.11506959e-01  7.63900346e-01  1.43776795e+00  1.46307606e-01
 -7.97177626e-03 -1.76305411e-01 -1.01999143e-02 -1.19136985e-02
 -4.72466022e-02  2.85295928e+00 -2.30357306e+00  7.25595121e+00
  4.04230389e-01 -7.02401957e-01 -1.51828832e-01  3.96816038e+00
  6.61832977e+00]
supnorm grad right now is: 7.255951211210589
Weights right now are: 
[  -3.08685788    1.22410254   -9.6663847   -13.65650687    3.34142659
   -1.33279423   10.06532196   12.94047795   -2.1333186    -4.01084109
    2.9139327     4.91933549    7.72973027   15.63914641  -23.63358265
   15.74622982   23.22251797  -13.78001776   -2.22000543   -1.16068129
   23.56553421  -10.97794142    0.35327708    1.8278533     0.66486703
   -7.32570335 -114.13629662   39.24070209   -4.86607537    9.00893437
   16.44752344  -22.40684955  -15.92156173   11.37918805    0.70280295
    2.21062728   -5.10467312   23.91958411   -3.1229652   -93.26889597
  -56.41654032 -131.53630905    2.1140455   -61.13223544   62.17909048
   63.69288819    0.56341237   67.70785815    3.53261757    3.96403929
    0.29161773    4.6133941    57.29667474   -9.32277142   92.28232344
   52.91736719    0.36174799   -2.71022033  -11.01202213   -4.81768132
   13.08551003    2.73090476   -0.21450874   -2.6390678    26.62458106]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2570.172144319276
gradient value of function right now is: [-7.09687991e-01  2.39512433e+00 -1.52680934e-02 -2.46068211e-06
  7.09687991e-01 -2.39512433e+00  1.52680934e-02  2.46068210e-06
 -3.50862538e+00 -6.13341602e+00 -4.39281916e+00 -7.19607766e+00
  1.36303990e+00  8.66864044e-02  1.39394039e+00  1.38733178e+00
 -2.75518481e-01 -2.84582334e-01 -2.90202572e-01 -2.89430176e-01
 -6.30771559e-05 -6.51215099e-05 -6.67224395e-05 -6.65506773e-05
  2.37714207e-01 -6.72056560e-25  4.17606159e-03 -7.16084487e-06
 -5.09796252e+00 -9.51254128e-02 -2.11840865e+00 -1.09856738e-01
 -4.75320087e-01 -4.28065508e-01 -1.08017402e+00 -1.50596026e-03
 -6.44040865e-01 -3.15945384e-01 -1.16406858e+00  3.47084641e-03
 -6.66106440e-02 -1.62722865e-03 -7.38543709e+00 -1.10236420e-01
  7.18395819e-02  1.15414485e-03  9.39678160e+00  1.16368480e-01
  9.98971216e-01  1.12064826e+00  4.48740081e+00  1.62549629e+00
 -1.52331006e-02 -4.51483651e-02  5.41773774e-05 -4.74750046e-02
 -1.49309284e+00  1.52039439e+01 -1.10243584e+00  2.21043005e+00
  6.80688184e-01 -3.36495712e+00 -3.14998037e+00  2.76484196e+01
  2.18991748e+01]
supnorm grad right now is: 27.648419567953173
Weights right now are: 
[-2.98456829e+00  1.29325803e+00 -9.63654769e+00 -1.39151412e+01
  3.23913700e+00 -1.40194972e+00  1.00354850e+01  1.31991123e+01
 -2.15387060e+00 -4.70223963e+00  2.85217354e+00  4.05157294e+00
  7.74342077e+00  1.63500434e+01 -2.34687666e+01  1.60282713e+01
  2.30562803e+01 -1.39374475e+01 -2.38180097e+00 -1.31920095e+00
  2.33874339e+01 -1.10843267e+01  2.44656306e-01  1.72506470e+00
  9.67519392e-02 -7.33443113e+00 -1.18914063e+02  3.67440765e+01
 -6.20640438e+00  5.62641825e+00  1.53719073e+01 -2.25532038e+01
 -1.54744952e+01  1.18022794e+01  3.35272796e-01  3.39568320e+00
 -5.68164250e+00  2.37259285e+01 -2.07889514e+00 -9.44470091e+01
 -5.60956365e+01 -1.35949397e+02  2.20484945e+00 -6.07383892e+01
  6.56746598e+01  7.21637180e+01  2.89156105e-01  7.12339494e+01
  2.42665208e+00  1.88156063e+00 -3.91164418e-01  4.07118189e+00
  5.41613875e+01 -1.02292049e+01  9.34918518e+01  4.96799443e+01
  1.12137744e-01 -2.77937817e+00 -9.05741643e+00 -6.97593636e+00
  1.29832079e+01  2.67649753e+00 -1.02051885e+00 -2.61159305e+00
  2.71928522e+01]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2565.681456742796
gradient value of function right now is: [ 4.50093815e+00  1.30257905e+01 -1.10966750e-02 -1.59445137e-06
 -4.50093815e+00 -1.30257905e+01  1.10966750e-02  1.59445181e-06
  1.33941590e+01 -2.99902871e+00  9.89533414e+00 -3.06041381e+00
  1.13213497e+00  9.46122194e-02  1.31534249e+00  1.41662026e+00
 -1.49759763e-01 -1.83476668e-01 -1.85145686e-01 -1.84389931e-01
 -3.43963132e-05 -4.26053326e-05 -4.29996496e-05 -4.28263058e-05
  5.94845057e-01  6.95535089e-18  1.34915966e-02  6.51427138e-03
 -2.42157226e+00 -6.54045157e-02 -9.18327368e-01 -6.27872768e-02
 -2.02143676e+00 -2.59112065e+00 -3.88924002e+00  2.16206829e-03
 -9.08277095e-01 -4.43109665e-01 -1.25443842e+00 -1.33801214e-04
 -1.20422389e-01 -1.47668738e-03 -1.91457360e+01 -1.64279796e-01
  1.27018803e-01  9.90581907e-04  2.07460684e+01  1.70745458e-01
  5.17081485e-01  1.11675438e+00  1.39794241e+00  7.51164765e-01
 -2.05025503e-02 -1.41548119e-01 -5.87421511e-03 -4.35209205e-02
 -3.02727332e+00  3.05902607e+01 -1.80784827e+00  3.37620020e+00
  3.85195395e+00 -2.07521287e+01 -5.02488819e+00  4.58693453e+01
  2.04161663e+01]
supnorm grad right now is: 45.869345293113426
Weights right now are: 
[-2.78858554e+00  1.36148988e+00 -8.99841367e+00 -1.38435986e+01
  3.04315425e+00 -1.47018157e+00  9.39735094e+00  1.31275696e+01
 -2.03904977e+00 -4.25583118e+00  2.86362654e+00  4.50594476e+00
  8.07926117e+00  1.51280961e+01 -2.32199790e+01  1.62580471e+01
  2.36834796e+01 -1.35771270e+01 -1.88625274e+00 -8.17941007e-01
  2.39622193e+01 -1.06322944e+01  8.23426884e-01  2.31069869e+00
  1.05694761e+00 -7.33670202e+00 -1.17975333e+02  3.79943816e+01
 -5.34934927e+00  4.18536766e+00  1.65155784e+01 -2.08057500e+01
 -1.62252709e+01  1.11820902e+01 -7.18945311e-01  2.17439678e+00
 -5.23558031e+00  2.39661694e+01 -1.38476712e+00 -9.60760981e+01
 -5.53029407e+01 -1.39665545e+02  2.25883786e+00 -6.01453422e+01
  6.80687402e+01  7.76470573e+01  3.68090240e-01  7.38469694e+01
  4.31611052e+00  3.46988660e+00  1.29470207e-01  5.81955784e+00
  5.46612191e+01 -1.11788976e+01  9.41760699e+01  4.87780905e+01
 -2.07330540e-01 -2.59480472e+00 -1.02960447e+01 -6.50935727e+00
  1.35238332e+01  2.56582089e+00 -1.11445913e+00 -2.55089504e+00
  2.67128942e+01]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2574.016409930096
gradient value of function right now is: [ 6.41190641e-01  1.45259845e+00 -6.46369163e-03 -3.47960361e-07
 -6.41190641e-01 -1.45259845e+00  6.46369163e-03  3.47960414e-07
  7.79011881e-01 -1.56532061e+00 -2.75491878e-02 -1.70215143e+00
 -3.30163714e-01 -1.16068077e-02 -2.77011228e-01 -2.29799445e-01
 -1.09121830e-01 -1.12483588e-01 -1.14711979e-01 -1.14557755e-01
 -8.90028795e-06 -9.24983085e-06 -9.44298004e-06 -9.43135470e-06
  1.01477042e-01 -1.10646883e-25  1.86023828e-03 -1.55831055e-05
 -1.33623934e-01 -4.59720985e-02 -2.23585941e-02 -5.00783636e-02
 -4.61750433e-01 -6.62403578e-01 -1.18580622e+00 -2.69306252e-03
  2.08057897e-01  6.54501301e-02  2.90728534e-01  1.26258675e-03
 -7.08614271e-03 -2.67556270e-04 -2.90472746e+00 -1.38180401e-02
  1.73452644e-03  2.08214603e-04  2.65081122e+00  3.99210574e-03
  8.94885244e-03  2.02433423e-01 -1.29833427e+00  7.09425286e-02
 -3.24208405e-03  3.99020879e-03 -3.97267624e-04 -1.03446076e-02
 -6.19752865e-02  1.05773196e+00 -1.27726114e-01  2.13673572e-01
  6.79972988e-01 -2.92587984e+00 -3.98878959e-01  2.12807203e+00
  1.11607163e+00]
supnorm grad right now is: 2.9258798356355364
Weights right now are: 
[  -2.85367858    1.33552311   -9.12255167  -13.92008977    3.10824729
   -1.4442148     9.52148893   13.20406073   -2.28910584   -4.29232423
    2.86700868    4.21538161    7.81525581   12.5206627   -23.26474498
   16.17975168   23.19092116  -14.13642989   -2.42013142   -1.3551521
   23.72775287  -10.974232      0.49716337    1.98509383    0.35994459
   -7.33750948 -121.35593421   35.37562      -6.57264936    8.5113
   15.59014304  -23.53003025  -16.05496489   11.94816409   -1.25705089
   -3.14066506   -6.39822655   22.89822236   -2.02765259  -99.26003547
  -54.85859497 -145.73621206    2.15122671  -59.75135405   70.42129405
   88.76166846    0.20513823   77.01376515    1.47385394    3.18348818
   -0.78386828    4.41842799   53.58226834   -9.42573968   93.53506803
   46.51015848   -0.17677608   -2.84846821   -9.44103359   -7.58195712
   14.08700965    2.74503081   -1.45566929   -2.75468393   26.83027622]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2568.440021376395
gradient value of function right now is: [-4.24820868e-02 -2.68880202e+00 -1.01115566e-01 -6.95163923e-06
  4.24820868e-02  2.68880202e+00  1.01115566e-01  6.95163937e-06
 -1.50752913e+00 -3.07315126e+00 -2.08718381e+00 -3.72770913e+00
  1.74688311e+00  1.42545421e-01  1.76560208e+00  1.69712480e+00
 -1.84809906e+00 -1.80988614e+00 -1.85860704e+00 -1.84482860e+00
 -1.88884397e-04 -1.84440285e-04 -1.90105636e-04 -1.88693344e-04
  2.16723305e-01  1.59842940e-24  6.64371590e-03  1.43463542e-04
 -3.09538448e+00  2.04467927e-03 -1.08203730e+00  2.98839800e-02
 -1.98656688e-01 -2.30565735e-01 -5.41044470e-01 -1.38093565e-03
 -6.14696905e-01 -1.16549157e-01 -5.95482515e-01  1.11358061e-03
 -6.66334631e-02 -8.65122408e-04 -4.83280537e+00 -8.02549512e-02
  4.39823950e-02  5.52528140e-05  4.82772148e+00  5.23865548e-02
  8.79304187e-01  9.70534380e-01  5.37623317e+00  1.12870601e+00
  5.41486306e-03  3.20475555e-03  5.82805163e-03  1.20427632e-02
 -1.84034574e+00  1.36246726e+01 -4.53627591e-01  1.02487534e+00
 -5.10004978e-01  1.01390791e+00 -3.51928081e+00  2.08905159e+01
  1.53864045e+01]
supnorm grad right now is: 20.890515885344374
Weights right now are: 
[-2.88318428e+00  8.14251998e-01 -9.45411356e+00 -1.40279425e+01
  3.13775299e+00 -9.22943688e-01  9.85305082e+00  1.33119134e+01
 -1.97108260e+00 -4.39130670e+00  3.04624825e+00  4.52331286e+00
  7.84536622e+00  1.20195720e+01 -2.35015302e+01  1.58859920e+01
  2.27255653e+01 -1.47786364e+01 -3.00574683e+00 -1.93658504e+00
  2.31967261e+01 -1.16486926e+01 -1.68144386e-01  1.31901903e+00
  1.96839449e-01 -7.33752522e+00 -1.21873393e+02  3.79924452e+01
 -6.01489036e+00  5.86317957e+00  1.66096884e+01 -2.26777492e+01
 -1.64549129e+01  1.20335082e+01 -9.57939568e-01  5.72321177e+00
 -4.65437759e+00  2.45759476e+01 -1.44760108e+00 -9.87538776e+01
 -5.28222739e+01 -1.42162960e+02  2.28533712e+00 -5.79461378e+01
  7.29661784e+01  9.20733265e+01  1.56567707e-01  7.96966438e+01
  1.81104666e+00  2.44918916e+00  3.85457312e-02  4.84380905e+00
  5.41600125e+01 -1.04567496e+01  9.67925532e+01  4.61423226e+01
 -9.82115422e-01 -2.63957499e+00 -1.09320475e+01 -6.75010593e+00
  1.32483623e+01  2.96676069e+00 -1.84197836e+00 -2.62494264e+00
  2.69321768e+01]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2568.614851839371
gradient value of function right now is: [-1.82805703e+00 -2.19005913e+00 -1.26256662e-03 -3.23121753e-07
  1.82805703e+00  2.19005913e+00  1.26256662e-03  3.23121766e-07
 -6.17191234e+00 -2.38592168e+00 -6.03228089e+00 -3.39564527e+00
 -5.04264491e-01 -3.03291364e-03 -4.94584203e-01 -4.98111483e-01
 -1.86133115e-02 -2.08408145e-02 -2.11372276e-02 -2.10038361e-02
 -7.71868376e-06 -8.66731799e-06 -8.82768290e-06 -8.77153412e-06
  2.73267282e-02 -3.39455663e-27  4.80343414e-04 -7.57513752e-11
 -2.18681110e+00  1.39763661e-02 -7.65322701e-01 -1.85311191e-02
  1.04363281e-01  1.01619143e-01  1.46733323e-01 -4.84826157e-03
  2.19171219e-01  1.10777222e-01  2.88621078e-01  8.08853547e-04
  8.93656714e-03 -3.63402302e-04  8.00661471e-01  7.24464385e-03
 -1.12913783e-02  1.04562412e-04 -1.00022107e+00 -1.36742505e-02
  5.59345087e-01  2.75185240e-01  6.13119180e-01  7.69214600e-01
 -5.20630035e-03 -1.49642250e-03  5.16721109e-03 -1.11219851e-02
  2.27872812e-01 -2.21213255e+00 -2.13452298e-01  5.04884985e-01
 -5.09547670e-01  2.33327900e+00 -4.82073748e-01 -6.31861716e-01
  2.88869504e+00]
supnorm grad right now is: 6.171912338715769
Weights right now are: 
[-3.11201755e+00  1.21539767e+00 -8.62858318e+00 -1.40189277e+01
  3.36658627e+00 -1.32408936e+00  9.02752045e+00  1.33028986e+01
 -2.63252407e+00 -4.55248876e+00  2.33604169e+00  4.32692642e+00
  7.42180383e+00  1.28878108e+01 -2.37281628e+01  1.57346956e+01
  2.41347932e+01 -1.40048703e+01 -2.03298892e+00 -9.58029523e-01
  2.41421565e+01 -1.11126795e+01  5.06305275e-01  1.99705107e+00
  1.19851997e+00 -7.33752522e+00 -1.25539360e+02  3.50504271e+01
 -6.24615800e+00  6.56164265e+00  1.54194071e+01 -2.32041062e+01
 -1.67613256e+01  1.21276807e+01 -1.48539417e+00 -3.32754800e-02
 -4.94153832e+00  2.34213858e+01 -2.69013209e+00 -1.03588308e+02
 -5.07176863e+01 -1.38500088e+02  2.52339891e+00 -5.56321001e+01
  7.56474205e+01  9.63131558e+01  1.59564345e-01  8.33576674e+01
  1.65445326e+00  1.61210550e+00 -4.83458401e-01  4.86625919e+00
  5.54576849e+01 -8.95672353e+00  9.37589211e+01  4.52608534e+01
 -7.37339066e-01 -2.52388273e+00 -1.02552993e+01 -7.01939503e+00
  1.43644954e+01  2.84885602e+00 -2.02764994e+00 -2.65035860e+00
  2.67959713e+01]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2569.4624228235384
gradient value of function right now is: [ 3.37953625e-01  6.85558052e+00 -1.12133875e-02 -6.72999241e-07
 -3.37953625e-01 -6.85558052e+00  1.12133875e-02  6.72999244e-07
 -6.94408132e-01 -7.30065356e+00 -1.89640416e+00 -7.45322568e+00
  2.85258836e-02  9.24221200e-02  7.61477813e-02  1.19986716e-01
 -1.65595676e-01 -1.80997012e-01 -1.83219097e-01 -1.78084193e-01
 -1.62750355e-05 -1.79546501e-05 -1.82132826e-05 -1.77016414e-05
  2.66546695e-01 -6.85058048e-24  4.30470264e-03 -5.61541964e-12
 -4.73623327e+00 -9.47341794e-03 -1.80649634e+00 -2.10040886e-02
 -6.44676415e-01 -6.08410583e-01 -1.44568398e+00 -5.45674163e-03
 -6.10051046e-01 -6.85689073e-01 -1.97008112e+00  1.79157246e-03
 -5.62775609e-02 -1.34530361e-04 -8.51189105e+00 -1.18807286e-01
  1.11533331e-01  5.22216766e-05  1.65568322e+01  1.99548588e-01
  7.21815580e-01  5.33078652e-01 -1.78508162e-01  2.05983758e+00
 -2.47744554e-03 -1.55848392e-04  2.63371186e-03 -1.89314185e-02
 -2.65289954e+00  2.24026180e+01 -1.80269053e-01  2.91970493e-01
  7.64476744e-01 -4.14903728e+00 -1.00156603e+01  5.40754425e+01
  1.91526136e+01]
supnorm grad right now is: 54.07544252078142
Weights right now are: 
[-2.94669535e+00  1.56378429e+00 -8.43895706e+00 -1.38879443e+01
  3.20126406e+00 -1.67247598e+00  8.83789432e+00  1.31719152e+01
 -2.37196407e+00 -4.38691571e+00  2.49885813e+00  4.47442092e+00
  7.73870827e+00  1.21514176e+01 -2.34878256e+01  1.59016592e+01
  2.40284244e+01 -1.42479111e+01 -2.23866855e+00 -1.13301406e+00
  2.43546850e+01 -1.09147474e+01  7.01814075e-01  2.21477131e+00
  5.74430260e-01 -7.33752526e+00 -1.28643205e+02  3.46728874e+01
 -6.73021435e+00  8.25913554e+00  1.62734939e+01 -2.25050053e+01
 -1.56922747e+01  1.34096035e+01 -6.47582033e-01 -1.46037656e+00
 -3.32588824e+00  2.41486578e+01 -3.42347677e+00 -1.05749499e+02
 -5.03540225e+01 -1.37276139e+02  2.04295472e+00 -5.51325863e+01
  7.72963793e+01  9.96426917e+01  7.87668152e-02  8.54111315e+01
  1.26930726e+00  1.46013248e+00 -4.13805720e-01  5.18353163e+00
  5.69941599e+01 -7.71542014e+00  9.49118313e+01  4.36141783e+01
 -8.35966934e-04 -2.68590379e+00 -9.59784542e+00 -8.17056713e+00
  1.42997401e+01  3.01332249e+00 -2.76739816e+00 -2.73051541e+00
  2.67813258e+01]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2571.210798184339
gradient value of function right now is: [ 5.54679226e-01  2.15234628e+00  1.80140630e-03  1.38740658e-07
 -5.54679226e-01 -2.15234628e+00 -1.80140630e-03 -1.38740647e-07
  2.83572345e+00  1.46996472e+00  2.98964388e+00  1.65924519e+00
 -1.85766989e+00 -1.32754093e-01 -1.90636423e+00 -1.86699606e+00
  3.80556056e-02  3.42498828e-02  3.51084113e-02  3.44431935e-02
  4.66620946e-06  3.55078008e-06  3.73777426e-06  3.74418395e-06
  7.00397023e-02  1.01230966e-16  1.54322248e-03  4.04926695e-04
  1.98523323e+00  1.52051699e-02  7.88744765e-01  1.48693352e-02
  1.56266122e-02  1.03462590e-01  3.16377852e-01  6.91404188e-03
  4.35587704e-01  4.45781981e-02  5.16407459e-01 -6.82096599e-04
  3.58550373e-02  1.18849666e-03  2.18408973e+00  2.88748057e-02
 -3.78389327e-02 -8.38940511e-04 -3.12025255e+00 -2.80630313e-02
 -3.74500936e-01 -9.04032175e-02 -2.36274899e+00 -4.17322915e-01
 -7.71643551e-04 -2.04398762e-02 -2.01157983e-03 -2.67545346e-03
  8.67066286e-01 -8.63104668e+00  2.27538131e-01 -9.00300408e-01
  2.25911638e-01 -1.65457612e-01  1.20031499e+00 -9.10719969e+00
 -9.11641821e+00]
supnorm grad right now is: 9.116418210691695
Weights right now are: 
[-2.99328651e+00  1.45305262e+00 -8.32789969e+00 -1.38258949e+01
  3.24785522e+00 -1.56174431e+00  8.72683696e+00  1.31098657e+01
 -2.07019619e+00 -3.94383804e+00  2.75180148e+00  5.01479444e+00
  7.55555953e+00  1.30908470e+01 -2.35490660e+01  1.59335906e+01
  2.40340087e+01 -1.43945385e+01 -2.33728569e+00 -1.23278425e+00
  2.42042536e+01 -1.11813256e+01  4.71024404e-01  1.93758283e+00
  1.28699526e+00 -7.33752565e+00 -1.25271982e+02  4.18093229e+01
 -5.60984486e+00  1.07681502e+01  1.79209538e+01 -2.04269025e+01
 -1.57036641e+01  1.29627965e+01 -1.27629418e+00  3.34517528e+00
 -2.28373459e+00  2.43391903e+01 -4.12722810e+00 -1.08943593e+02
 -4.80746988e+01 -1.33914222e+02  2.56741488e+00 -5.26607287e+01
  7.95354345e+01  9.75193016e+01 -1.31908518e-01  8.77003959e+01
  1.91006400e+00  3.17991170e+00 -1.69921252e-01  5.84588757e+00
  6.00012667e+01 -8.74378208e+00  9.67146879e+01  4.14448402e+01
  3.61121377e-01 -2.43171246e+00 -1.21818372e+01 -6.54342713e+00
  1.48635065e+01  2.66807156e+00 -1.99629509e+00 -2.81391514e+00
  2.66486987e+01]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2574.622323274716
gradient value of function right now is: [-3.84505376e-01 -1.74668386e+00  1.39510098e-03  3.02198431e-08
  3.84505376e-01  1.74668386e+00 -1.39510098e-03 -3.02188761e-08
 -1.00562239e+00  1.29305373e+00 -6.04598163e-01  1.34171485e+00
 -3.90159466e-01 -1.17218528e-02 -4.03197883e-01 -3.86644461e-01
  3.18031382e-02  2.90556021e-02  2.93205974e-02  2.99569259e-02
  1.87386280e-06  7.71854942e-07  8.15243868e-07  1.10198556e-06
  7.32174336e-02  1.05697741e-22 -1.39732136e-03 -6.98219775e-03
  5.72033722e-01  3.21250654e-02  2.34522101e-01  4.11111290e-02
  2.24494527e-01  3.12970363e-01  4.50305122e-01 -6.65115176e-03
  2.97733506e-01  1.29479954e-01  4.73134423e-01  5.06607644e-04
  1.41274667e-02  4.90807737e-04  2.02647196e+00  2.12627489e-02
 -2.93465531e-02 -7.46475660e-04 -3.31852738e+00 -4.21001002e-02
 -2.62872820e-02 -1.58884366e-01  7.43601054e-01 -9.46672039e-02
  8.85550351e-03  1.14174200e-01  5.83558731e-03  3.37788366e-02
  4.27008637e-01 -4.89399102e+00  7.38098360e-01 -1.45942090e+00
 -1.06285848e+00  4.49946455e+00  8.81167292e-01 -8.19307170e+00
 -6.35417748e+00]
supnorm grad right now is: 8.19307169592185
Weights right now are: 
[-3.03314765e+00  1.21693612e+00 -7.69556180e+00 -1.38056559e+01
  3.28771636e+00 -1.32562781e+00  8.09449906e+00  1.30896266e+01
 -2.11170997e+00 -3.98262620e+00  2.73309054e+00  4.93696695e+00
  7.34058930e+00  1.13759559e+01 -2.36323090e+01  1.59324725e+01
  2.42986541e+01 -1.41847482e+01 -2.09316916e+00 -9.88679942e-01
  2.47682154e+01 -1.08798355e+01  7.91808374e-01  2.31118082e+00
  4.97859622e-01 -7.33752526e+00 -1.28729635e+02  4.15269488e+01
 -6.44198711e+00  6.78131859e+00  1.70284688e+01 -2.26899269e+01
 -1.60223939e+01  1.22701433e+01 -1.76685246e+00  7.98789136e+00
 -3.22668025e+00  2.41596540e+01 -4.55504578e+00 -1.10027165e+02
 -4.58158694e+01 -1.36374742e+02  2.38316528e+00 -5.08291143e+01
  8.26215553e+01  1.06211311e+02 -2.19751645e-02  9.24203418e+01
  2.01837601e+00  1.77558461e+00 -4.71623509e-01  5.44807091e+00
  5.93058574e+01 -8.40215111e+00  9.79471252e+01  3.93469019e+01
 -1.27064208e-02 -2.51915956e+00 -1.12377670e+01 -7.22581123e+00
  1.43774833e+01  2.97564119e+00 -1.96962093e+00 -2.73765618e+00
  2.68380129e+01]
(65,)
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2574.8380577882376
gradient value of function right now is: [-4.83618180e-01 -2.07681376e+00  5.99973109e-03  8.57386215e-07
  4.83618180e-01  2.07681376e+00 -5.99973109e-03 -8.57386203e-07
 -1.53755037e+00  1.18905021e+00 -1.10122416e+00  1.16832342e+00
 -4.21220500e-01 -1.56159226e-02 -4.32342355e-01 -4.14284212e-01
  8.90543049e-02  9.63401096e-02  9.67949343e-02  9.43576768e-02
  2.13941601e-05  2.27761364e-05  2.29254911e-05  2.24659582e-05
 -1.20124882e-01  2.45180602e-22 -3.64723493e-03 -3.50611461e-03
  5.84487427e-01  2.60339336e-02  2.36436407e-01  3.34727809e-02
  2.41689746e-01  3.08472348e-01  4.76866823e-01 -6.90687610e-03
  3.47468369e-01  1.68734002e-01  5.73521011e-01  4.31779735e-04
  1.81596298e-02  4.03264131e-04  2.30268678e+00  2.59523786e-02
 -3.65718774e-02 -6.20544789e-04 -4.09047591e+00 -5.09298542e-02
 -6.80516382e-02 -5.52538295e-01  8.13836653e-01 -2.37389411e-01
  8.75707614e-03  1.16110570e-01  4.32442658e-03  3.66872540e-02
  5.00746756e-01 -6.47129854e+00  3.92575137e-01 -8.29134083e-01
 -8.26208659e-01  3.86620882e+00  1.37130099e+00 -1.09209879e+01
 -6.61794782e+00]
supnorm grad right now is: 10.920987941396692
Weights right now are: 
[  -3.48086386    1.12382673   -8.16902701  -13.95642474    3.73543257
   -1.23251842    8.56796427   13.24039547   -2.34236674   -3.93471398
    2.58983621    4.81082285    7.01336243   11.51191135  -23.99955963
   15.58240595   23.69194344  -14.89118465   -2.7631217    -1.5666527
   23.34558604  -12.48780774   -0.81558671    0.70873485    0.67915331
   -7.33752521 -130.59286914   42.19625572   -6.85872791   11.8550518
   19.02556323  -14.42078007  -13.33140057   16.38896768    0.32318434
    3.60115418   -3.02025004   24.3686614    -4.51618348 -112.6150595
  -45.25213067 -132.37554094    1.38915676  -47.84567275   83.25739781
  111.00651089   -0.17244085   93.13881377    1.15462862    1.36226494
    0.29710596    6.28317213   61.72498606   -8.95295585   99.3690063
   39.36880267    0.24598583   -2.47649626  -11.68832601   -7.3864088
   15.41795561    1.27415969   -2.56378429   -3.16048578   26.77571379]
(65,)
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2574.8540400734396
gradient value of function right now is: [-5.74891251e-01 -2.44974298e+00  9.54876897e-03  2.86117975e-06
  5.74891251e-01  2.44974298e+00 -9.54876897e-03 -2.86117923e-06
 -1.55043047e+00  1.77296729e+00 -9.69874839e-01  1.75109391e+00
 -4.69719583e-01 -1.91169753e-02 -4.85699333e-01 -4.68456883e-01
  1.47820685e-01  1.54457447e-01  1.55356291e-01  1.49461289e-01
  7.34080278e-05  7.60439716e-05  7.66280848e-05  7.36501474e-05
 -9.41915023e-02  3.31122357e-25 -3.54868314e-03 -3.61235417e-03
  7.71001122e-01  2.83294250e-02  3.10055394e-01  4.64409054e-02
  3.66026698e-01  4.17607588e-01  6.29720171e-01 -4.19406129e-03
  3.50213361e-01  2.08195416e-01  6.81096054e-01  6.94860552e-04
  2.78658576e-02  5.19455597e-04  2.96054173e+00  2.95448352e-02
 -5.50715621e-02 -6.38969985e-04 -5.31380473e+00 -5.57285257e-02
 -9.49940691e-02 -5.94700337e-01  9.95873374e-01 -2.93956232e-01
  7.52394835e-03  9.64714616e-02  5.23614285e-03  3.25518134e-02
  8.09412406e-01 -9.92620595e+00  4.50259506e-01 -9.90620768e-01
 -9.87083736e-01  4.64450365e+00  1.58921455e+00 -1.22409213e+01
 -7.64280201e+00]
supnorm grad right now is: 12.24092133450391
Weights right now are: 
[-3.01555855e+00  1.44313127e+00 -7.81361453e+00 -1.35947609e+01
  3.27012726e+00 -1.55182296e+00  8.21255179e+00  1.28787316e+01
 -2.53968273e+00 -3.84233456e+00  2.66086072e+00  4.35927754e+00
  7.45977578e+00  1.45797556e+01 -2.33393342e+01  1.63888013e+01
  2.41115810e+01 -1.47466917e+01 -2.44418617e+00 -1.35368662e+00
  2.39988986e+01 -1.20709757e+01 -2.50256977e-01  1.18234176e+00
  7.54744621e-01 -7.33752521e+00 -1.32493008e+02  4.25827619e+01
 -6.46848424e+00  7.64459775e+00  1.73284470e+01 -2.11354659e+01
 -1.55141475e+01  1.39140152e+01 -1.65365314e+00 -6.81571131e-01
 -1.78144198e+00  2.51442383e+01 -4.81284125e+00 -1.12059046e+02
 -4.43587844e+01 -1.32504936e+02  1.87789012e+00 -4.63629218e+01
  8.48701512e+01  1.16997590e+02 -1.02797365e-01  9.52005113e+01
 -3.39840938e-01  2.95600996e-01 -1.35998937e-01  5.44896330e+00
  6.42931648e+01 -7.28050312e+00  1.01017610e+02  3.84962470e+01
  7.69238305e-02 -2.48450920e+00 -1.13782578e+01 -7.78844538e+00
  1.43415632e+01  2.73470532e+00 -3.11647250e+00 -3.11735708e+00
  2.68232875e+01]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2574.821639185539
gradient value of function right now is: [-4.66000075e-01 -2.31774504e+00  8.42450023e-03  2.74560891e-06
  4.66000075e-01  2.31774504e+00 -8.42450023e-03 -2.74560886e-06
 -9.52454368e-01  2.09557697e+00 -3.88154903e-01  2.10902686e+00
 -4.70684207e-01 -1.86297276e-02 -4.88831968e-01 -4.73210725e-01
  1.29656176e-01  1.34415911e-01  1.35566110e-01  1.28925717e-01
  6.98765441e-05  7.21421649e-05  7.29115240e-05  6.90964412e-05
 -7.19879193e-02  6.16848753e-28 -2.85646104e-03 -3.44816692e-03
  8.74425035e-01  2.77730296e-02  3.46207387e-01  5.12583763e-02
  3.60067331e-01  4.18740621e-01  6.28629061e-01 -3.89926132e-03
  2.63176484e-01  1.94078033e-01  6.47576442e-01 -4.12546965e-04
  2.79889984e-02  4.62111199e-04  2.95459850e+00  2.63460580e-02
 -5.64577494e-02 -4.94489056e-04 -5.38685181e+00 -4.96923305e-02
 -1.08143864e-01 -5.50239524e-01  1.08434203e+00 -3.19243173e-01
  6.34112249e-03  7.17783730e-02  2.60496023e-03  2.86456417e-02
  8.56326302e-01 -1.01558607e+01  5.79222276e-01 -1.19364707e+00
 -7.70293845e-01  3.74622250e+00  1.51042027e+00 -1.09818496e+01
 -7.81091215e+00]
supnorm grad right now is: 10.98184963389478
Weights right now are: 
[-3.34603110e+00  1.33738891e+00 -8.00399537e+00 -1.33503453e+01
  3.60059981e+00 -1.44608060e+00  8.40293264e+00  1.26343160e+01
 -2.56651522e+00 -3.61587994e+00  2.85299289e+00  4.70501864e+00
  7.34520123e+00  1.19863608e+01 -2.33578395e+01  1.64808820e+01
  2.39856281e+01 -1.51377408e+01 -2.76837509e+00 -1.71582311e+00
  2.39545016e+01 -1.23218251e+01 -4.63823662e-01  9.53150703e-01
  1.49719180e+00 -7.33752521e+00 -1.33960667e+02  4.25064577e+01
 -6.33548460e+00  9.24458394e+00  1.77911510e+01 -2.04917502e+01
 -1.58884251e+01  1.38018171e+01 -1.25531191e+00  1.82619785e+00
 -1.85511774e+00  2.55693396e+01 -7.11148059e+00 -1.11763958e+02
 -4.49627041e+01 -1.23339012e+02  1.91989979e+00 -4.54964999e+01
  8.72755222e+01  1.15688224e+02  1.61589121e-01  9.80602429e+01
  1.13989832e+00  1.43069388e+00  1.26428925e-01  6.10254534e+00
  6.38380243e+01 -6.40487329e+00  1.03450944e+02  3.61705291e+01
  4.44540163e-02 -2.54773572e+00 -1.34612272e+01 -7.20729440e+00
  1.42786830e+01  2.83757705e+00 -3.39711263e+00 -3.25423286e+00
  2.69746059e+01]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2574.816962257934
gradient value of function right now is: [-5.31111121e-01 -2.29831127e+00  8.58106108e-03  2.53357663e-06
  5.31111121e-01  2.29831127e+00 -8.58106108e-03 -2.53357654e-06
 -1.23910354e+00  1.82785451e+00 -6.81679053e-01  1.81429905e+00
 -4.91913607e-01 -1.89500879e-02 -5.08280333e-01 -4.92231512e-01
  1.32495216e-01  1.36995932e-01  1.37987293e-01  1.31578286e-01
  6.46135945e-05  6.62286808e-05  6.68555015e-05  6.35189162e-05
 -6.78076110e-02  5.21864258e-27 -1.59123959e-03  3.59607012e-04
  7.53853108e-01  2.66302126e-02  3.03220289e-01  4.36175239e-02
  3.72825703e-01  4.25828789e-01  6.16718632e-01 -3.45380466e-03
  2.78270501e-01  1.90858616e-01  6.11789739e-01 -4.06047459e-05
  2.69401493e-02  5.03419601e-04  2.81538920e+00  2.37269138e-02
 -5.47589751e-02 -5.90992151e-04 -5.15408747e+00 -4.52126171e-02
 -9.30060015e-02 -4.82172020e-01  1.08298932e+00 -2.64708724e-01
  5.17919958e-03  5.10007572e-02  3.70475599e-03  2.19972181e-02
  9.13182712e-01 -1.00556196e+01  2.04690786e-01 -5.74100767e-01
 -8.51830737e-01  4.02677964e+00  1.53583121e+00 -1.03674768e+01
 -7.54121020e+00]
supnorm grad right now is: 10.367476766042303
Weights right now are: 
[-3.00744421e+00  8.95535246e-01 -7.40935372e+00 -1.31004222e+01
  3.26201292e+00 -1.00422694e+00  7.80829098e+00  1.23843927e+01
 -2.29006128e+00 -3.59085989e+00  3.12739551e+00  5.32913382e+00
  7.61541723e+00  1.30343198e+01 -2.29259450e+01  1.71072061e+01
  2.42670936e+01 -1.50110622e+01 -2.57912835e+00 -1.47860807e+00
  2.50764073e+01 -1.16020566e+01  2.72907911e-01  1.65996527e+00
  8.37252623e-01 -7.33752522e+00 -1.33768123e+02  4.41042248e+01
 -5.83890153e+00  8.43628675e+00  1.93566882e+01 -1.89833808e+01
 -1.58572441e+01  1.35231003e+01 -1.66895447e+00  2.88343604e+00
 -9.61598370e-01  2.66518914e+01 -6.86585228e+00 -1.11474155e+02
 -4.40428595e+01 -1.15996838e+02  1.93403786e+00 -4.29510779e+01
  8.89452460e+01  1.18506681e+02 -2.22988855e-01  1.00604864e+02
  1.79395830e+00  3.24575236e+00  5.11090634e-02  7.01853753e+00
  6.70889892e+01 -7.95463744e+00  1.07312760e+02  3.65209596e+01
 -3.05204017e-01 -2.60904198e+00 -1.43734923e+01 -7.33279353e+00
  1.37421232e+01  2.70568194e+00 -2.47840729e+00 -2.97928297e+00
  2.71163276e+01]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1500.5381508159278
W_T_median: 1330.2229399572464
W_T_pctile_5: 727.3270278790462
W_T_CVAR_5_pct: 624.5202042491737
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.3
F value: -2574.816962257934
-----------------------------------------------
-------------------------
