Starting at: 
2022-06-17 22:26:16
tracing parameter entered from terminal:  0.6


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1588.0768044677873
gradient value of function right now is: [ 0.2216767   0.05223578  0.05988724  0.06627589 -0.2216767  -0.05223578
 -0.05988724 -0.06627589  0.62515793  0.19016003  0.15969871  0.18199468
 -0.19172511 -0.06800169  0.22904635  0.09714965  0.01200967 -0.37066267
  0.041133    0.02710026  0.00872275 -0.44329604  0.02712699  0.018369
 -0.09774773 -0.24930295  0.22149687 -0.04456204  0.10117652  0.13197993
 -0.44524444  0.21804475 -0.02122877 -0.00867828 -0.17609002 -0.01045688
 -0.0255938  -0.03005553 -0.13162089 -0.00996     0.03728791  0.03469654
  0.28621791  0.01173816  0.19278811  0.16918475  0.5269737   0.16170363
  0.80238112  1.36283118  0.06407932  0.96623693  0.11125231  0.02360127
  0.36751284  0.08466361  0.44434072  2.44277418 -0.05889052 -0.18327236
 -0.14806495 -0.81417763  0.18235335  1.25724555  1.20148112]
supnorm grad right now is: 2.442774183528646
Weights right now are: 
[-2.23128832  0.9392273   2.52195457  2.35843301  2.48585703 -1.04791899
 -2.1230173  -3.0744614  -1.24488828  6.82876651  3.22639852  2.35577905
  4.06332182 -0.94264125 -0.61736365 -0.08095023  5.87509681  2.72918732
  4.28091803  3.19459606  5.98957414  2.81624352  5.41762414  4.42418005
  3.9166931   3.91617556 -2.37761054  7.85553512 -3.04237347 -0.17348042
  2.49945368 -0.9269787   1.56493545  0.5343247   3.29965367 11.33502603
  2.25398853  2.26317465  2.95220306 10.0315845   5.70802017 -0.36122948
 -0.1356013   5.21239508  5.15170582  1.46237325 -1.76273901  3.44299532
 -3.96160687  3.36837796  5.76213567 -1.11468389  9.71367012  7.20542719
 -3.97189021  9.1693578   3.17084246 -1.26397392 -0.58151333 -2.69530007
  3.7482357   2.05662785  2.58134956 -1.6626554  30.60031506]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.9189586841633
gradient value of function right now is: [-7.33068506e-01 -7.01609920e-01 -7.81887847e-02 -9.64027525e-03
  7.33068506e-01  7.01609920e-01  7.81887847e-02  9.64027525e-03
 -9.60510958e-01 -3.13512124e-01 -4.62644961e-01 -9.76516926e-02
  1.10493018e-01 -2.16555727e-01  3.84404690e-01  6.05264790e-02
  2.89322409e-02 -3.59725968e-01  3.85895246e-01  4.34848442e-02
  1.52731799e-02 -3.93597278e-01  3.12995239e-01  3.46194529e-02
 -1.19942839e-02 -1.62071407e-01 -4.85921955e-01 -2.08573163e-03
  8.40644889e-01  2.78414269e+00  1.42862913e+00  1.32433833e+00
 -2.38458231e-01 -1.07356293e+00  2.67379524e-02 -3.83924664e-02
 -2.93775892e-02 -1.50765328e-01 -3.08915829e-02 -4.54815384e-03
  1.21704113e-01  3.69430215e-01  7.16245788e-01  1.00554353e-01
  1.25318199e-01  2.12279498e-01 -3.75511528e-01  1.37513711e-01
 -1.07746770e+00 -1.28154026e+00 -2.52436792e-01 -1.22420136e+00
  4.45669948e-01  1.01601549e+00  3.05112993e+00  3.46656636e-01
 -1.61644272e+00  5.33719106e+00 -2.51017770e+00  1.06305689e+01
  1.22954271e+00 -4.27230891e+00 -1.09980095e+00  5.09534226e+00
  7.12352667e+00]
supnorm grad right now is: 10.630568856295508
Weights right now are: 
[-2.23453501  1.09698353  3.16176542  3.12633856  2.48910372 -1.20567522
 -2.76282815 -3.84236694 -2.18779965 10.08520852  3.69823891 -0.65494373
  5.07143684  4.66911138 -0.96218362 -1.49918416  6.32886825  6.36428069
  4.74541377  2.71498767  7.33530113  6.79819033  6.17896941  4.67654151
  7.82836626  7.02231467 -1.53304027 17.33788169 -2.17077124  3.4977404
  2.47889821 -6.84924131  4.60301629 -0.19089362  4.5139451  21.94548326
  5.34520169  3.2221247   6.27962117 21.62240294  9.42666835  0.67491532
  1.12271816  8.21493335  5.77119609  0.10181987 -4.56034217  3.28971915
 -4.55524042  3.99190207  5.96639177 -1.97032066 13.43247575 10.61481376
 -4.19981349 13.91197121  3.64800578 -1.79383535 -1.25303751 -1.91296326
  5.95801621  0.96149351  2.97231218 -2.15523791 30.5600303 ]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.1210664897267
gradient value of function right now is: [ 4.11164846e-01  1.13285357e+00 -1.26648038e-02 -5.90506144e-02
 -4.11164846e-01 -1.13285357e+00  1.26648038e-02  5.90506144e-02
  4.93809805e-01  3.14375842e-01  4.16328032e-01  1.57372317e-01
 -7.26038399e-02 -4.13993106e-01 -1.22172076e+00 -1.35032263e-01
 -7.56680970e-03  1.45974347e-01 -3.30317498e-01 -2.01125514e-02
 -4.67453976e-03  2.01939915e-01 -2.74811401e-01 -1.50389377e-02
  1.04186454e-02  1.19530376e-01  2.66089533e-01  5.03895197e-05
 -1.52372998e-01 -1.88202096e+00 -4.63340071e-01 -1.15181154e+00
  1.23139690e-01  9.22249191e-01 -9.62446677e-03  1.37323048e-02
  7.71675457e-03  2.85622438e-02  1.02001071e-01  1.49394492e-04
 -7.53083827e-02 -2.49887330e-01 -4.95543966e-01 -6.95567353e-02
 -2.27837696e-01 -2.39034257e+00  2.81242770e-01 -4.08531349e-01
  4.39055357e-01  2.15633836e-01  9.28722719e-03  4.72759873e-01
 -4.48874725e-01 -7.55320206e-01 -3.30656823e+00 -3.38707022e-01
  1.62805497e+00 -6.46063225e+00  2.00233900e+00 -8.67185125e+00
 -1.02159927e+00  4.48264174e+00  1.59705878e+00 -5.77101816e+00
 -6.05246345e+00]
supnorm grad right now is: 8.671851246178093
Weights right now are: 
[-2.19817199  1.60704101  2.86605738  2.70051825  2.4527407  -1.7157327
 -2.46712011 -3.41654664 -3.05188543 10.14381756  4.85203841 -6.23016128
  5.72680279  5.45056418  0.18400592 -2.62498614  8.24138491  7.13860308
  5.5769831   4.8509381   9.93368314  7.41669845  6.46202442  6.85930934
 11.06227521 10.9523025  -0.77506322 28.26431481 -2.12976785  3.42822521
  2.27037772 -7.31893865  7.3074051   0.25234731  8.9819995  26.02315719
  7.09596796  7.43985726  6.69554576 33.3377424  12.12972803  1.51847087
  0.88263655 11.86805336  6.27727433  0.12732965 -4.98707994  3.4591659
 -4.35729824  5.15078168  9.1238121  -1.81000624 14.89485317 11.57585762
 -4.16138015 16.64581876  4.10432291 -1.95645186 -1.67372634 -2.25908467
  5.73880529  1.03115684  2.84850837 -2.42250986 30.65416371]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.0333797364985
gradient value of function right now is: [-2.95828061e-01  1.14627679e+00 -1.16503712e-02 -5.47451442e-02
  2.95828061e-01 -1.14627679e+00  1.16503712e-02  5.47451442e-02
 -8.92359342e-01 -5.01376773e-01  4.69437872e-02 -3.04576626e-01
 -7.92331263e-02 -1.17396090e+00 -2.24386771e+00 -1.03933268e-01
 -2.77072731e-03  5.01289505e-02 -3.19447764e-01 -5.50214477e-03
 -1.81048335e-03  1.02048210e-01 -2.53380925e-01 -3.66691315e-03
  3.86663214e-03  1.03585179e-01 -2.57240534e-01  3.43526123e-06
 -1.03711730e-01 -8.53769459e-01  5.85856846e-01 -1.15670722e+00
  2.35132292e-01  1.35938181e+00  2.17608607e-01  7.31774273e-03
 -6.15188533e-04 -2.02408002e-02 -2.93166770e-01  8.36471624e-07
 -6.40744305e-02 -6.83447962e-01 -4.16350802e-01 -1.04494492e-01
 -2.67666473e-01 -4.84816179e+00  3.06962012e-01 -7.86193891e-01
 -1.03992839e+00 -2.06424261e+00 -1.64345819e-01 -1.33675727e+00
 -3.39469988e-01 -6.22553922e-01 -2.87633975e+00 -3.09611254e-01
  1.20505225e+00 -7.16001897e+00  3.00018412e+00 -7.31490882e+00
 -4.24442883e-01  5.30802957e+00  2.98164737e+00 -6.82207708e+00
 -7.35576125e+00]
supnorm grad right now is: 7.355761254134114
Weights right now are: 
[-3.35476437e+00  2.45018735e+00  2.64449443e+00  2.27003611e+00
  3.60933308e+00 -2.55887904e+00 -2.24555716e+00 -2.98606449e+00
 -4.12616944e+00  1.13521310e+01  5.73963914e+00 -8.31613153e+00
  6.58303167e+00  5.37629113e+00  1.35478967e+00 -2.66480630e+00
  7.64725307e+00  7.50971191e+00  6.28680484e+00  2.35012020e+00
  8.63062793e+00  7.83114416e+00  7.10505117e+00  4.72079247e+00
  1.82868171e+01  1.61470257e+01 -2.08083370e+00  3.43676237e+01
 -2.88982773e+00  3.46231254e+00  3.45435830e+00 -7.07250799e+00
  1.04689538e+01 -6.76827802e-03  1.11800794e+01  2.96698320e+01
  5.10591601e+00  1.47109279e+01  8.50806948e+00  3.87039169e+01
  1.48775179e+01  1.29978011e+00  1.15433741e+00  1.55976677e+01
  6.56133851e+00  2.61090738e-01 -5.24445964e+00  3.64885163e+00
 -6.15562680e+00  6.14445948e+00  1.20570728e+01 -1.84797029e+00
  1.48032203e+01  1.26085478e+01 -4.31848702e+00  1.92241289e+01
  4.42289237e+00 -2.06348784e+00 -1.77715464e+00 -2.40332075e+00
  6.77072713e+00  1.13548653e+00  2.74970472e+00 -2.37207339e+00
  3.05799034e+01]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.610164523782
gradient value of function right now is: [ 6.80565839e-02 -7.38624546e-01 -9.66751641e-02 -6.08126479e-02
 -6.80565839e-02  7.38624546e-01  9.66751641e-02  6.08126479e-02
  4.28413030e-01  3.47678343e-01  1.94906896e-01  3.58801999e-01
 -9.95234306e-03  6.95691187e-01  1.72305042e+00  1.90669435e-02
  1.97083380e-04  3.26101030e-02  1.45494144e-01  1.36765216e-03
  1.71615081e-04  1.05569166e-02  8.38340532e-02  7.52845928e-04
 -7.11201128e-04 -1.72349770e-02  2.07929769e-02 -1.77711328e-07
 -1.73656094e-01 -4.41357765e-01 -1.91164901e-01  4.60533216e-01
 -1.01759538e-01 -9.87057821e-01 -7.65536326e-02 -6.26185066e-03
  2.08530598e-03  2.88424914e-02  7.64822430e-02  1.99409341e-06
  5.03037634e-02  2.76339927e-01  2.71340078e-01  6.43240378e-02
  7.80112702e-02  1.81721798e+00 -3.90737878e-02  2.63845558e-01
  1.95310167e-01  4.72721050e-01  1.09720720e-01  2.30087170e-01
  1.49463081e-01  1.84613187e-01  1.23402759e+00  1.05467503e-01
 -7.96210320e-01  3.00001847e+00 -1.04474935e+00  3.37379400e+00
  3.16760663e-01 -3.05163739e+00 -1.38553963e+00  3.29520212e+00
 -9.89598993e-01]
supnorm grad right now is: 3.3737940034633738
Weights right now are: 
[-3.26064631  3.22419585  2.34959433  1.78396037  3.51521502 -3.33288754
 -1.95065706 -2.49998875 -3.74030886 12.20750785  6.20376659 -9.4205337
  6.87672334  5.70648704  1.87910331 -3.46527377  8.42271965  8.16127226
  6.704114   -2.70934596  9.39875814  8.65178733  8.00408586 -0.86719306
 28.16254162 21.95510559 -1.1057697  35.3434058  -2.96056524  3.68703313
  3.84057544 -7.38289353 12.5059165  -0.46392544 13.86007041 29.99209661
 -3.89618432 18.11320721 10.23977917 38.7859494  14.93384674  1.55665819
  1.08672259 16.6229032   6.76099614  0.62717881 -5.22022375  4.13961665
 -6.62070287  7.20062497 13.5817618  -1.25721765 15.09516515 14.7022524
 -4.20356175 22.09919447  4.19278905 -1.98580618 -2.01469615 -2.42122947
  5.97902211  0.62808669  2.32290303 -2.51520016 30.32753921]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.7894527540282
gradient value of function right now is: [-2.24976628e-01 -9.04982650e-01 -8.64621456e-02 -2.31591340e-02
  2.24976628e-01  9.04982650e-01  8.64621456e-02  2.31591340e-02
 -3.01944307e-01 -1.91994453e-01 -1.39416336e-01 -2.00541247e-02
  8.35941365e-03  1.14105830e+00  2.55566368e+00  2.08821417e-02
  1.43118276e-04  1.38968012e-02  9.99616970e-02  3.92508481e-04
  2.56291421e-05 -2.00178730e-02  3.06778020e-02  1.00511351e-04
 -2.48224472e-04 -1.27023219e-02 -1.26155459e-01 -3.43468205e-08
  2.39497400e-01 -1.50346044e+00  4.17962322e-01  1.19504124e-01
 -1.61358747e-01 -1.37224638e+00  4.20421911e-03 -5.78454399e-03
  8.66755794e-04  1.85115362e-02 -1.14344468e-01 -4.31655909e-06
  5.57297794e-02  8.28985330e-01  2.23177638e-01  9.11092855e-02
  1.30217377e-01  3.06683691e+00  8.25942563e-02  3.79949219e-01
 -4.42731681e-01 -3.56060180e-01 -4.23444874e-02 -5.33967732e-01
  1.73424915e-02  1.77709452e-01  9.30527222e-02  1.87758342e-02
 -9.67267228e-01 -2.83847781e-01 -2.15440591e+00  3.00433351e+00
  4.14371636e-01  2.92294462e-01 -2.01303538e+00  1.28268060e+00
  1.30386883e+01]
supnorm grad right now is: 13.038688313283627
Weights right now are: 
[ -3.23467198   4.08418529   1.96208722   1.44784676   3.48924069
  -4.19287698  -1.56314995  -2.16387515  -3.82741962  12.62501954
   6.57732729 -10.44483585   9.65108772   6.11368798   2.19561879
  -3.01341927  12.26094004   9.58234125   7.82960461  -5.15912111
  13.96453265  10.41751591  11.81047892  -3.78185808  36.8274894
  24.14309731  -0.99885206  35.40257217  -3.1315269    3.85872536
   4.30469056  -7.43341502  14.79895643  -0.58279191  17.09850407
  30.38063911 -10.69482355  20.42302097  11.02254533  38.31626609
  14.12065905   2.41141829   0.21128343  16.37428404   5.97979247
   0.49028312  -5.12204263   4.0800641   -8.01447796   7.81613381
  13.88400172  -1.38001968  14.35147396  15.14029828  -4.56021269
  23.7215714    4.77317973  -1.80644408  -1.92879467  -2.46515081
   6.53378897   1.0631776    2.54044876  -2.74926396  30.67142262]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.8926568808447
gradient value of function right now is: [ 8.58748031e-02  6.35247636e-01 -4.57785717e-02 -6.33345868e-02
 -8.58748031e-02 -6.35247636e-01  4.57785717e-02  6.33345868e-02
  7.77031872e-02 -1.59188572e-02  7.57288433e-02 -7.92747466e-02
 -1.87559985e-02 -8.87832927e-01 -2.69328496e+00 -5.04253994e-02
 -1.18388417e-05  3.12993386e-02 -2.00992645e-02 -1.47525138e-05
 -3.13744024e-06  5.01876670e-02 -9.66092072e-03  4.70326512e-05
  1.06920326e-04  1.83724163e-02  6.75992261e-02  1.91844039e-08
 -5.62589974e-01  7.79505266e-01 -3.96070410e-01  1.75765002e-03
  9.34974629e-02  1.23343940e+00 -8.31537620e-03  8.72329348e-03
 -8.35252351e-04 -3.15509654e-02  7.39807316e-02  2.42163450e-05
 -6.28494575e-02 -6.92638445e-01 -1.79389388e-01 -8.06758484e-02
 -1.89421025e-01 -1.68407592e+00 -2.69829072e-01 -3.00288647e-01
  2.33139589e-01  2.43790298e-01  2.52570318e-02  2.44838757e-01
  4.49208525e-02 -1.76096556e-01  3.73057046e-01 -4.68596807e-03
  8.32927540e-01 -3.32786953e-02  1.86322477e+00 -2.67930031e+00
 -3.35383285e-01 -7.73385349e-01  1.58471107e+00 -1.14186909e+00
 -1.11055708e+01]
supnorm grad right now is: 11.105570771300316
Weights right now are: 
[ -3.35376078   4.71287194   1.48890798   1.53682498   3.60832949
  -4.82156363  -1.08997071  -2.25285337  -3.91231174  12.97271111
   6.24343    -11.40586757  11.12126408   5.82901098   2.27549798
  -3.89811261  14.32020276  12.06535023  11.60236788  -6.96050328
  15.85702296  12.87891297  17.79620329  -5.65144941  46.86840015
  27.59760233  -0.61706028  35.42904665  -3.76893791   4.1817385
   4.5844558   -7.17809754  17.13182492  -0.62962794  19.18588773
  31.59155827 -13.55692443  19.5603489   12.37353211  41.54952214
  14.23340126   2.63033379   0.09043968  17.87410947   6.26106228
   0.57462636  -5.17129371   4.5922356   -8.55558      9.15129532
  14.08848587  -0.72940336  13.77032321  15.78474666  -4.45576886
  25.62400489   4.82645595  -1.72264536  -1.94124904  -2.58392837
   6.39313979   0.65231955   2.58963308  -2.84776047  30.42439886]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.7186689685634
gradient value of function right now is: [ 2.15242964e-01  1.91569415e+00  1.39718054e-01  1.21932274e-01
 -2.15242964e-01 -1.91569415e+00 -1.39718054e-01 -1.21932274e-01
 -4.24683258e-01 -6.13264667e-02  1.93634695e-01 -2.89763892e-01
 -2.31279450e-02 -2.43856477e+00 -4.95600802e+00 -6.29446069e-02
  6.65628404e-08 -5.03311317e-02 -1.69933907e-02 -4.71681903e-05
  1.56322121e-07 -7.61082060e-02 -1.75542119e-02 -6.74804177e-05
  5.91547306e-05  3.13135002e-02 -4.52969493e-02  6.83676088e-09
  7.98278218e-01  3.72196873e+00  3.76158957e-01 -6.05100132e-02
  1.41923150e-01  2.46807971e+00  5.83409343e-02  2.29676345e-02
 -7.09299116e-04 -2.40445646e-02 -9.63941819e-02 -1.61682619e-05
 -8.32278913e-02 -3.24301596e-01 -2.55828735e-01 -7.52470297e-02
 -5.42146627e-01 -4.47854606e+00 -8.19819996e-01 -8.60775029e-01
 -3.75990704e-01 -8.88123297e-01 -1.95331891e-01 -4.73602847e-01
 -1.29226446e-01 -1.53270402e-02 -7.29673096e-01 -5.23086848e-02
  9.83850630e-01 -3.64415079e+00  1.17206726e+00 -2.20009832e+00
 -3.00289843e-01  2.14335718e+00  1.87981675e+00 -2.27598828e+00
 -1.34790735e+01]
supnorm grad right now is: 13.479073482398695
Weights right now are: 
[ -3.48965301   4.95078398   1.78034309   2.27677697   3.74422172
  -5.05947567  -1.38140582  -2.99280535  -3.90284752  13.28901591
   6.3618065  -11.89110018  13.14343765   5.9212727    2.45127713
  -3.5496297   17.80915695  14.92228462  17.11583548  -7.74486446
  18.89321037  14.74368956  22.02813382  -6.57866936  56.49995518
  28.92607105  -0.87721767  35.43642988  -4.25081253   4.38757592
   5.72748103  -6.95382019  18.80562728  -0.54362629  23.32360254
  31.71246908 -15.17014294  20.53867061  11.79450133  45.35136484
  14.00255697   3.19183702   0.14965412  18.46912174   6.14206418
   0.448258    -5.08491032   4.10466848  -9.30211909   9.6159382
  14.24817399  -0.92783454  13.15056875  16.99608963  -4.47395783
  27.24408001   4.71168004  -1.76477022  -2.23760967  -2.69369256
   7.14080614   1.0338882    2.769811    -2.96893646  30.54505014]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1595.5245491871583
gradient value of function right now is: [ 5.34670151e-01  2.29568878e+00  5.54407820e-02  4.94899899e-02
 -5.34670151e-01 -2.29568878e+00 -5.54407820e-02 -4.94899899e-02
  4.43060393e-01  6.38141728e-01  8.44631945e-01  3.79027961e-01
 -1.40445585e-02 -2.63901119e+00 -7.28929146e+00 -3.38543627e-02
 -1.32778657e-07 -8.11855750e-03 -7.64052022e-03 -5.07498449e-06
 -1.34297398e-07 -1.31378214e-02 -1.23539697e-02 -1.07120168e-05
  1.80626623e-05  2.63370311e-02  2.24563526e-02  2.51071552e-09
  4.03555798e-01  3.56820757e+00  4.62925952e-02 -6.05627153e-01
  1.96344386e-01  3.86490990e+00  2.28523548e-03  1.88017489e-02
 -1.31958451e-04  1.08889152e-03  4.63099580e-02 -2.51376928e-06
 -1.67636882e-01 -1.13418281e+00 -6.26832655e-01 -1.43584239e-01
 -7.84557190e-01 -7.50653066e+00 -5.82340624e-01 -1.41338218e+00
  1.02475262e-01 -1.37966949e-01 -7.77776143e-02  1.51974995e-01
 -3.24503961e-01 -2.35041862e-01 -1.79000837e+00 -1.15299157e-01
  2.16701685e+00 -4.80403615e+00  2.03487852e+00 -6.05779624e+00
 -8.72568689e-01  3.48371800e+00  3.36770290e+00 -4.89475776e+00
 -2.55420942e+01]
supnorm grad right now is: 25.542094155382387
Weights right now are: 
[ -2.94332341   5.08952122   1.34046195   1.88953462   3.19789212
  -5.19821291  -0.94152468  -2.605563    -3.700991    14.00000831
   6.46183425 -12.13253085  15.3664626    5.97351174   2.52481258
  -2.72476181  18.00169249  17.4348645   20.83607901  -9.35904158
  19.10249186  16.29764274  24.0228786   -8.25016713  63.00583951
  30.08927094  -0.89988568  35.43969953  -4.67298517   4.51228035
   6.07349038  -7.12359074  20.82678304  -0.32437984  23.94698146
  31.86613469 -16.23342734  22.94980865  13.80898151  47.91661278
  14.22239202   3.28193914   0.07519724  19.99475053   5.91840074
   0.1890855   -4.97074494   3.83079244 -10.40316714  10.56668853
  15.74904569  -1.01362859  11.88680522  17.71880809  -4.85914174
  28.33669311   4.99262882  -1.7584357   -2.34231707  -2.67212392
   7.11563853   0.82581584   2.86670907  -3.0587769   30.46144055]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.8951146494842
gradient value of function right now is: [ 2.75543451e-01  4.13305294e-01 -1.80284381e-02 -3.15362216e-02
 -2.75543451e-01 -4.13305294e-01  1.80284381e-02  3.15362216e-02
  5.18290720e-01  4.92878808e-01  6.14974160e-01  4.53574938e-01
 -6.90912348e-03 -5.41798140e-02 -2.72519502e+00 -1.72911907e-02
 -2.56470648e-07  2.34026786e-02 -4.38375483e-03  2.58716467e-06
 -2.42621757e-07  5.67967215e-02 -7.91872349e-03  6.53632450e-06
  2.58785390e-06  1.36944479e-02  2.50818925e-02  3.40824701e-11
 -1.22112729e+00 -1.44666309e+00 -2.61972610e-01 -7.67896975e-01
  1.41904055e-01  1.66572188e+00 -9.51803437e-03  9.40470578e-03
  5.40343799e-05  8.99486023e-03  4.29624002e-02  4.06174856e-06
 -2.06635295e-01 -1.82473953e+00 -1.15689476e+00 -1.38431993e-01
 -1.86434393e-01 -3.44039134e+00  7.44277589e-01 -6.60595721e-01
  1.95840956e-01  3.25467122e-01  8.06767420e-02  2.33213235e-01
 -2.37039936e-01 -4.27960162e-01 -1.52676483e+00 -8.46425232e-02
  1.90850047e+00 -3.67886344e+00  3.41031189e+00 -9.33909889e+00
 -6.84359795e-01  1.69316237e+00  2.72385983e+00 -4.16167939e+00
 -1.44426248e+01]
supnorm grad right now is: 14.442624802519425
Weights right now are: 
[-2.96712104e+00  5.06843921e+00  2.24911274e+00  2.83683283e+00
  3.22168976e+00 -5.17713090e+00 -1.85017547e+00 -3.55286122e+00
 -3.72000952e+00  1.41903962e+01  6.38027392e+00 -1.27092511e+01
  1.67042089e+01  6.31725473e+00  2.74913509e+00 -3.13210762e+00
  1.83201295e+01  1.93706162e+01  2.39631483e+01 -9.20534799e+00
  1.94139151e+01  1.75387540e+01  2.42402054e+01 -7.87910844e+00
  6.77743697e+01  3.26419201e+01 -1.02448736e+00  3.54403945e+01
 -5.14140294e+00  4.26342068e+00  6.45285371e+00 -6.92884718e+00
  2.25193090e+01 -5.62854976e-01  2.79716225e+01  2.91069965e+01
 -1.58656980e+01  2.30959885e+01  1.39833704e+01  4.90236320e+01
  1.35036677e+01  3.34957073e+00  8.56799579e-02  2.00992347e+01
  5.50743571e+00  4.40764489e-02 -4.36704623e+00  4.12299997e+00
 -1.05401697e+01  1.12421375e+01  1.58069152e+01 -6.94995774e-01
  1.15881156e+01  1.92684676e+01 -4.29546161e+00  3.06713229e+01
  4.83613766e+00 -1.76048852e+00 -2.26449402e+00 -2.66479610e+00
  6.26465167e+00  8.22706149e-01  3.01946758e+00 -3.11134534e+00
  3.05491281e+01]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.3753476952338
gradient value of function right now is: [ 3.68097092e-01  1.37689375e+00  1.68008098e-02  2.74779569e-02
 -3.68097092e-01 -1.37689375e+00 -1.68008098e-02 -2.74779569e-02
  3.28467540e-01  4.49591184e-01  4.57652784e-01  2.16525363e-01
 -6.27719833e-03 -1.81158747e+00 -3.71360019e+00 -2.34512210e-02
 -2.37384399e-07 -4.26355046e-03 -2.03195745e-03 -3.09610479e-06
 -3.77096688e-07 -1.78216676e-02 -7.94178393e-03 -1.40614906e-05
  3.28314999e-06  9.91508808e-03  3.40150223e-02  1.41802968e-10
  1.75772173e-01  3.16377594e+00 -1.24943737e-01  1.72771140e-01
  1.24545453e-01  2.12215093e+00 -3.07558299e-03  1.04809705e-02
 -2.08436131e-04 -8.24729101e-03  5.47143955e-02 -2.50794848e-06
 -5.45058530e-02 -8.35317091e-01 -4.77561458e-02 -6.36923369e-02
 -3.70068776e-01 -4.03210879e+00 -5.39518504e-01 -5.10289856e-01
  1.38032660e-01  3.89803839e-02 -1.81698792e-02  1.66087858e-01
  6.76080646e-02 -2.21717529e-03  4.77649765e-01  1.53946241e-02
  1.17861467e+00  3.37539725e-01  1.69756856e+00 -1.31315944e+00
 -2.82219524e-01 -4.03437171e-01  2.01026594e+00 -2.72701610e-01
 -1.48897175e+01]
supnorm grad right now is: 14.889717495572532
Weights right now are: 
[ -3.08244      5.08400588   1.44234578   2.50663958   3.33700871
  -5.19269757  -1.04340852  -3.22266796  -3.43271396  14.46861908
   6.0556152  -13.07228923  16.59676511   6.18483171   2.73442187
  -3.98688131  18.44600604  21.61062532  28.39964587  -9.55157899
  19.55273454  18.48993068  25.23898775  -8.74947095  68.61627168
  33.86098847  -0.71143224  35.44053058  -5.05975508   4.45265015
   6.45206494  -7.00941353  23.48433644  -0.41372954  29.61267395
  28.05680496 -19.39588637  21.69520796  15.88276692  50.016673
  13.79934015   3.81824948   0.34140745  21.40353236   5.65435763
   0.10090111  -4.4073729    4.91802859 -11.34881245  11.70649471
  16.02569773  -0.7395863   10.97129553  20.61124394  -4.08113233
  32.2564112    4.18125855  -1.66203114  -2.16535968  -2.74344641
   6.48772212   0.89832021   2.88842613  -2.92851873  30.42782003]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1590.9550455730641
gradient value of function right now is: [-1.36463902e+00 -4.83237028e+00 -9.80713247e-02 -2.07244361e-01
  1.36463902e+00  4.83237028e+00  9.80713247e-02  2.07244361e-01
 -5.62660726e-01 -1.22573741e+00 -1.97420806e+00 -5.89925512e-01
  1.35696328e-02  4.12622334e+00  1.24406206e+01  5.79811377e-02
 -2.23259531e-08  8.60709414e-03  3.51165909e-03  8.36086936e-07
 -8.32308067e-08  9.98292289e-02  5.62405214e-02  1.57528538e-05
 -6.17318610e-06 -3.06366286e-02  1.53276401e-03 -3.03889541e-10
 -3.57985976e-01 -7.21282384e+00 -1.99464545e-02  1.16450107e-01
 -3.37927632e-01 -7.76031204e+00 -1.24243671e-02 -1.08407056e-01
  1.14531670e-04  6.78635341e-04 -8.78728181e-03 -7.40568874e-06
  3.93877648e-01  1.79525491e+00  1.50822830e+00  2.49855697e-01
  1.24872988e+00  8.49572637e+00  2.16849413e+00  1.75611531e+00
  5.24553913e-02  2.10226610e-01  1.00189316e-01  4.79245254e-02
  4.04473289e-01  3.22336249e-01  1.92633888e+00  1.36201692e-01
 -3.07735815e+00  8.48553465e+00 -3.23446387e+00  8.88619392e+00
  1.55758976e+00 -4.87410619e+00 -5.11080813e+00  8.15415711e+00
  4.34229050e+01]
supnorm grad right now is: 43.4229049591645
Weights right now are: 
[ -3.24865483   4.5712995    0.79820415   3.02185603   3.50322355
  -4.67999119  -0.39926688  -3.73788441  -3.66809888  14.50062979
   6.17276653 -13.21750502  18.35774162   6.36323774   2.81073281
  -4.07829643  18.59047848  23.94719927  35.07005839  -9.64522778
  19.82960761  18.22814678  25.77766602  -7.92083433  69.76739077
  34.18759713  -1.58458909  35.44061096  -5.59610567   4.37031269
   8.13696478  -7.36916599  23.85048002  -0.53748377  32.04707481
  28.57485947 -19.28421446  21.26069729  14.90455018  52.36868153
  13.70835166   4.02221202   0.10822987  22.51760008   5.81364398
   0.12816541  -4.12744139   5.10072787 -11.62508403  12.56599231
  15.68172681  -0.29500279  10.49069018  21.75238849  -4.23067354
  33.6920004    4.98681101  -1.62128516  -2.34917106  -2.76047467
   6.39819174   1.17661356   2.96016682  -3.16113693  30.74508697]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.7670640360227
gradient value of function right now is: [-9.98988536e-01 -1.79663530e+00 -2.38166770e-02 -8.87691902e-02
  9.98988536e-01  1.79663530e+00  2.38166770e-02  8.87691902e-02
 -1.08805434e+00 -1.35578171e+00 -1.77093403e+00 -1.11023565e+00
 -1.28874308e-03  1.00291383e+00  4.60914077e+00 -4.06560462e-04
  7.19724206e-08 -7.89481119e-03 -2.71183676e-03 -2.13455910e-07
 -1.83081766e-07  2.95646589e-02  2.76951426e-02  3.48820474e-06
 -1.81239907e-07 -6.36440473e-03  5.62781738e-03 -5.91341539e-12
  1.30574437e-01 -1.45223191e+00  1.38012606e-02  3.59884941e-01
 -1.38306095e-01 -2.99467267e+00  2.53563893e-03 -2.16511662e-02
 -4.72122437e-06 -2.44966550e-02 -2.02631294e-02 -1.79050580e-06
  1.93647010e-01  9.12867748e-01  8.47094882e-01  1.16186586e-01
  5.52758163e-01  3.73196497e+00  2.73253660e-01  9.93290017e-01
 -1.58753967e-02  9.66400954e-03  2.53601579e-02 -5.16375574e-02
  1.99553954e-01  1.92764570e-01  1.14732327e+00  6.41848024e-02
 -1.53935193e+00  2.79053582e+00 -1.90858294e+00  5.86929896e+00
  7.14159214e-01 -2.00600364e+00 -2.19931692e+00  3.97573334e+00
  1.51700711e+01]
supnorm grad right now is: 15.170071064906145
Weights right now are: 
[-3.04286699e+00  4.61682473e+00 -2.22217977e+00  3.68413430e+00
  3.29743570e+00 -4.72551642e+00  2.62111704e+00 -4.40016268e+00
 -3.92687488e+00  1.42947309e+01  5.96352374e+00 -1.41634993e+01
  1.77808330e+01  6.66787373e+00  2.91462988e+00 -3.97268163e+00
  1.85137544e+01  3.52875829e+01  3.51872692e+01 -9.68691009e+00
  2.01570561e+01  1.77662976e+01  2.62858008e+01 -7.73324101e+00
  7.01013024e+01  3.62908939e+01 -1.32827740e+00  3.54406469e+01
 -5.68209043e+00  4.68594460e+00  7.45521398e+00 -7.30698557e+00
  2.44163749e+01 -3.13217699e-01  3.52142881e+01  3.02666429e+01
 -2.02807125e+01  2.38047652e+01  1.62111136e+01  5.40465510e+01
  1.34823968e+01  4.29915078e+00  1.38742137e-01  2.37281165e+01
  5.07589756e+00  1.87110264e-02 -4.38270981e+00  4.63868899e+00
 -1.19502425e+01  1.28519360e+01  1.62418952e+01 -4.64417044e-01
  9.45024175e+00  2.27926051e+01 -4.07635481e+00  3.49225003e+01
  4.67431404e+00 -1.82874710e+00 -2.42594153e+00 -2.77696053e+00
  6.06914864e+00  7.24289241e-01  2.74547165e+00 -3.22885270e+00
  3.05905957e+01]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.3534266895215
gradient value of function right now is: [-8.87743788e-01 -2.25852952e+00 -1.61046857e-02 -1.50733751e-01
  8.87743788e-01  2.25852952e+00  1.61046857e-02  1.50733751e-01
 -7.02584442e-01 -1.04519254e+00 -1.01618710e+00 -6.68882193e-01
 -6.92342166e-04  2.06630619e+00  4.07488096e+00  1.71944874e-04
  1.26902263e-07 -1.29792888e-02 -3.24180527e-03 -3.79516636e-07
 -3.57575802e-08  1.56431782e-01  2.18476518e-02  1.75630223e-05
 -1.66181780e-07 -2.85730047e-03 -8.72699051e-03 -3.35213358e-11
 -9.11203891e-01 -4.99933396e+00 -4.87154656e-02 -3.70440050e-01
 -1.12089453e-01 -2.66144050e+00  2.59864021e-03 -2.58456767e-02
  6.37654262e-05 -1.11171639e-02 -3.70877821e-02  1.64181875e-06
  7.03416137e-03  7.36173832e-02 -2.97492330e-01  3.12152860e-02
  7.85011408e-01  2.76149962e+00  1.84621054e+00  7.16893493e-01
 -7.28023975e-02  2.22021707e-02  1.05637557e-01 -1.27227587e-01
 -4.96649067e-02 -1.25849196e-01 -4.18800067e-01 -1.27097842e-02
 -4.79976475e-01 -3.33725985e-01  3.09816937e-01 -2.46970941e+00
  3.72241032e-01 -6.82886636e-01 -5.84120925e-01  1.06901767e-01
  1.57603843e+01]
supnorm grad right now is: 15.76038426341975
Weights right now are: 
[-2.82595600e+00  4.58456280e+00 -4.22331308e+00  4.20069030e+00
  3.08052471e+00 -4.69325449e+00  4.62225035e+00 -4.91671868e+00
 -3.80758775e+00  1.42090455e+01  6.55553800e+00 -1.42457490e+01
  1.90517116e+01  6.24455503e+00  2.77861255e+00 -3.76652676e+00
  1.80144730e+01  4.10760386e+01  3.12642689e+01 -9.69472034e+00
  2.04394739e+01  1.97056047e+01  2.79617932e+01 -7.47270411e+00
  7.04200990e+01  3.66912836e+01 -1.52557806e+00  3.54406719e+01
 -5.85022129e+00  4.59814237e+00  7.00170832e+00 -7.27481360e+00
  2.46583758e+01 -4.63019135e-01  3.94468136e+01  3.22797533e+01
 -2.19987909e+01  2.35910288e+01  1.56748109e+01  5.49666024e+01
  1.30860672e+01  4.40523421e+00 -3.64603606e-01  2.50381009e+01
  5.43526903e+00  5.35724016e-02 -3.93222671e+00  4.52151425e+00
 -1.24817350e+01  1.30466621e+01  1.64828334e+01 -8.30688743e-01
  8.43196268e+00  2.33994546e+01 -3.99172659e+00  3.60496647e+01
  5.09277894e+00 -1.71458238e+00 -2.22849023e+00 -2.79346629e+00
  6.96195835e+00  8.30586088e-01  2.97194549e+00 -3.28857172e+00
  3.07310156e+01]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1593.5025078772164
gradient value of function right now is: [-1.45609785e-01 -1.92705127e+00  5.49983982e-03 -8.64174934e-02
  1.45609785e-01  1.92705127e+00 -5.49983982e-03  8.64174934e-02
  3.55955505e-01  1.50536526e-02  9.80585154e-02  2.94105012e-01
  1.11016265e-03  3.03323729e+00  2.07610843e+00  6.57022532e-03
  5.58336675e-07 -5.63458880e-04  7.96069141e-04 -2.69541839e-07
 -4.39866881e-08  1.85841392e-01 -1.33549326e-03  3.03506291e-05
 -1.62229082e-06 -2.55442243e-03  1.58930941e-02 -3.48574457e-11
 -2.67020130e+00 -8.39368190e+00 -4.05363208e-01 -1.77764432e+00
 -1.42958227e-02 -1.20456548e+00 -1.00850475e-02 -2.45711249e-03
  1.83038657e-04  5.20988779e-03  2.76211291e-02  9.06120331e-06
 -3.13157701e-01 -1.06433750e+00 -2.50935784e+00 -1.23004131e-01
  5.61961830e-01  2.26120454e+00  2.83378710e+00  4.01812799e-01
  1.79057421e-01  4.66295304e-01  1.81639197e-01  2.14949747e-01
 -4.62336790e-01 -6.05756471e-01 -3.37219681e+00 -1.57506173e-01
  9.98904338e-01 -5.40618382e+00  3.63643097e+00 -1.56437735e+01
 -4.79802439e-01  2.44115687e+00  1.24096699e+00 -8.97290681e+00
 -8.42480651e-01]
supnorm grad right now is: 15.64377348367102
Weights right now are: 
[ -2.7292723    4.24451371  -7.71570238   4.94387435   2.98384101
  -4.3532054    8.11463965  -5.65990273  -3.43847769  14.69799919
   6.55674549 -14.11147651  21.67458866   6.40426129   3.17640939
  -2.8556338   16.51629732  43.74442661  30.57795197  -9.76082779
  20.55292534  20.0076614   27.24635164  -6.54146447  70.71856079
  37.21272285  -2.17824651  35.44068265  -6.03055928   4.90564279
   7.55792926  -6.8018059   25.12774791  -0.34785131  39.02776338
  38.12846795 -21.78974633  24.96683473  17.03152623  56.61991027
  13.33857126   4.19091794  -0.21229829  26.29036104   5.80452239
   0.52536289  -4.25018663   4.77472626 -12.99677809  13.46129738
  17.398123    -1.0139204    7.79462899  23.97061318  -3.65162674
  37.37720764   4.82826556  -1.82920453  -2.56331611  -2.90537884
   6.37239183   0.75687124   2.40323551  -3.19767517  30.38632509]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1596.8585728373382
gradient value of function right now is: [-1.78817179e-02 -2.08727883e+00 -1.14261146e-02 -5.35505612e-03
  1.78817179e-02  2.08727883e+00  1.14261146e-02  5.35505612e-03
  4.92688799e-01  4.21443050e-01 -1.04995500e-01  4.18242074e-01
  5.97919992e-03  8.04489106e-01  8.49495468e+00  2.50291304e-02
  2.12001534e-06 -7.60472971e-03 -6.56855321e-03 -2.12243293e-07
 -6.57570800e-08 -4.78142210e-02  2.10924979e-02 -5.02785241e-06
 -3.63897749e-07 -1.28749465e-02  1.80062372e-02 -1.38821536e-11
  1.38485327e+00 -3.93414774e-02  1.60512075e-01  1.15027425e+00
 -1.65226115e-01 -5.43330572e+00 -1.48762736e-02 -1.32725274e-02
 -6.96713776e-05  1.06941422e-02  3.56825003e-02 -4.86640403e-06
  4.91033504e-01  1.94469318e+00  2.25864207e+00  2.15654034e-01
  3.81454131e-01  6.84261002e+00 -6.49859185e-01  1.00097309e+00
  2.46871414e-01  2.06564733e-01 -1.38426306e-03  2.93724885e-01
  5.06645761e-01  4.29200264e-01  2.71662801e+00  1.24980924e-01
 -2.11085732e+00  8.99804015e+00 -3.38622939e+00  1.23997690e+01
  1.41066006e+00 -5.40153345e+00 -4.76112760e+00  8.92906150e+00
  2.90022069e+01]
supnorm grad right now is: 29.002206851952884
Weights right now are: 
[-2.21535663e+00  4.35544635e+00 -8.26379807e+00  4.98733352e+00
  2.46992534e+00 -4.46413804e+00  8.66273534e+00 -5.70336190e+00
 -3.37041643e+00  1.48011076e+01  6.97786469e+00 -1.41001190e+01
  2.34598023e+01  6.25262720e+00  2.96459660e+00 -2.69845770e+00
  1.52524799e+01  4.49918751e+01  3.10090993e+01 -9.76966173e+00
  2.06360504e+01  2.18245538e+01  2.67285235e+01 -5.83844126e+00
  7.09464373e+01  3.76037662e+01 -2.20653324e+00  3.54406945e+01
 -5.91735233e+00  4.97209515e+00  8.52134074e+00 -6.91562507e+00
  2.57331331e+01 -2.15204388e-01  4.15869619e+01  3.49652108e+01
 -1.99345575e+01  2.44969398e+01  1.66508818e+01  5.81900170e+01
  1.27893075e+01  4.15884318e+00 -7.22109241e-01  2.69011008e+01
  4.72338420e+00 -3.75990190e-02 -3.66068619e+00  4.72492863e+00
 -1.30046392e+01  1.38266703e+01  1.91584091e+01 -8.97615998e-01
  7.13227660e+00  2.51459375e+01 -3.55019985e+00  3.84699069e+01
  4.97662352e+00 -1.64911428e+00 -2.52032708e+00 -2.90063588e+00
  6.49961603e+00  7.33904537e-01  2.96980035e+00 -3.30607297e+00
  3.07194595e+01]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.7361984868235
gradient value of function right now is: [ 7.07888887e-01  5.48429721e-01  2.65761773e-02  6.48874660e-02
 -7.07888887e-01 -5.48429721e-01 -2.65761773e-02 -6.48874660e-02
  7.12408544e-01  6.18272684e-01  6.39775171e-01  5.34311739e-01
  1.75844133e-03  3.81464166e-01 -1.64122217e+00  7.34185577e-03
  1.51432038e-04  1.84903150e-02  1.02992615e-02 -1.66923510e-07
 -1.73537316e-06 -9.52872350e-03 -1.93957636e-02  1.91434611e-05
 -1.80132641e-07 -2.50182417e-03  5.65073739e-02  1.41835164e-12
 -9.50104554e-01 -1.27797618e+00 -2.43649024e-01 -3.22854329e-01
  7.08570065e-02  1.34453118e+00 -1.32661471e-02  6.43415687e-03
  1.83744901e-04  8.74361043e-03  6.58455123e-02  4.62871625e-06
 -1.54054090e-01 -1.08387457e+00 -9.58129584e-01 -8.51178409e-02
 -1.56201764e-01 -2.68295467e-01  7.15438263e-02 -1.61464964e-01
  2.86829547e-01  4.36828384e-01  5.14521386e-02  3.42798926e-01
 -1.04266599e-01 -1.54204576e-01 -8.01283424e-01 -3.44384088e-02
  8.71749567e-01 -1.27836541e+00  2.02663695e+00 -5.54647128e+00
 -4.46659143e-01  9.33986913e-01  9.27272606e-01 -3.28194540e+00
 -8.25073103e+00]
supnorm grad right now is: 8.250731032073437
Weights right now are: 
[ -2.08593179   4.55656222  -8.36598037   5.34020331   2.3405005
  -4.66525391   8.76491764  -6.05623169  -3.25285032  14.6953879
   7.1503991  -14.48809154  23.52276185   6.75079418   2.87040808
  -2.65217237  13.5719608   46.5294565   31.35041401  -9.76517627
  20.64892779  22.6871203   28.98630642  -6.3725268   71.00408993
  37.91271509  -0.80139712  35.44069857  -6.19453627   5.10629687
   7.79212557  -7.18270875  25.73383857  -0.18694007  42.84522374
  37.54500495 -19.00702886  24.30266917  18.6149103   59.92557162
  12.9503852    3.86526787  -0.38034599  27.77110352   4.53674657
   0.40229691  -3.83597004   5.10169993 -13.94458635  14.29853723
  19.66903359  -1.06201989   6.24383111  26.25090628  -3.35973301
  39.55657215   4.62628168  -1.92303129  -2.53343818  -2.85126172
   6.18045168   0.99654296   2.80138056  -3.31251923  30.56544671]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.291586939497
gradient value of function right now is: [ 2.19767248e-01 -1.59251138e-01  1.04206891e-02 -2.26199287e-03
 -2.19767248e-01  1.59251138e-01 -1.04206891e-02  2.26199287e-03
  4.47715459e-01  2.72765981e-01  2.14853703e-01  2.42335090e-01
 -2.23579499e-03  4.63116230e-01 -1.03605183e+00 -8.87772212e-03
  6.65121589e-03  6.76655357e-03  2.32361608e-03  4.09044100e-05
 -4.66332432e-07  4.34457915e-02 -3.71931800e-03  5.00883660e-06
  4.11826902e-08  4.66196892e-03  6.46330384e-02  5.68675696e-13
 -7.68144216e-01 -2.09376306e+00 -3.15595169e-01 -6.49140440e-01
 -1.19470707e-04  5.23170461e-01 -1.03491171e-02  3.86190376e-03
  5.18321948e-05  1.27110806e-03  7.49700004e-02  2.75126778e-06
 -1.56583207e-01 -2.93859116e-01 -7.81926517e-01 -3.93436299e-02
 -1.95892805e-02 -9.69548661e-01  7.96443947e-01 -2.73413049e-01
  3.02792904e-01  3.79249034e-01  4.92994652e-02  3.16843006e-01
 -3.41560820e-01 -2.57588877e-01 -1.56054441e+00 -7.63908290e-02
  7.14003343e-01 -2.55736469e+00  1.57950511e+00 -7.25729447e+00
 -4.51126830e-01  1.19127729e+00  1.06722745e+00 -4.10088147e+00
 -6.26987123e+00]
supnorm grad right now is: 7.2572944670999195
Weights right now are: 
[ -2.12335121   4.20961804  -8.50547448   5.9637503    2.37791992
  -4.31830973   8.90441174  -6.67977869  -3.572377    14.39721497
   6.5177104  -15.02530434  23.40512436   6.60437091   2.84934444
  -3.47871734  -2.60055093  49.00450707  30.21617836  -8.99060845
  20.78396059  23.07160533  30.10404791  -6.30917324  71.15571599
  40.13356398  -0.43495844  35.44070543  -6.26084993   5.28334629
   6.73984598  -8.01020949  25.43736008   0.10831222  44.17832332
  39.88312975 -21.28206636  23.97607316  18.75078514  60.56518239
  13.18632192   4.62939076  -0.25911341  29.06955568   3.65847041
   0.18720351  -3.77327693   5.10803549 -14.19620322  15.06570608
  18.07370265  -0.88189201   5.3242605   26.43870917  -3.73455394
  40.05868135   4.96870987  -1.52891147  -2.66538096  -3.04349741
   6.10879262   0.54510357   2.71606756  -3.33258859  30.58014413]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.9542749117584
gradient value of function right now is: [ 5.38186426e-02  3.47527249e-01  1.21778011e-02  4.90409144e-02
 -5.38186426e-02 -3.47527249e-01 -1.21778011e-02 -4.90409144e-02
 -1.89525531e-01 -1.52783733e-01 -2.50900449e-01 -2.19345749e-01
  1.14297629e-03 -5.15739247e-01  6.81360321e-01  5.89686001e-03
  1.46256277e-03  8.66575357e-03  4.20324783e-03  1.29272824e-05
 -5.58496116e-09 -4.71298082e-02 -6.87835401e-03 -5.44675356e-06
 -7.42987607e-08 -5.11701289e-03  5.32228594e-03  1.48067459e-12
  7.60032252e-01  1.53948403e+00  8.18995321e-02  4.29155398e-01
 -8.99568710e-03 -2.95420190e-01 -7.96373058e-04  4.20229819e-03
 -6.80729029e-05 -6.93775427e-03  6.08966801e-03 -4.55336070e-06
  8.73960584e-02  5.42438950e-01  6.00054485e-01  3.05754399e-02
 -7.94819153e-03  1.17742689e+00 -8.20395835e-01  2.84678689e-01
  4.42004477e-02 -2.14601640e-02 -4.81505039e-02  5.70338502e-02
  1.36273768e-01  1.61490214e-01  8.91189047e-01  3.03321889e-02
 -4.34886519e-01  1.47986387e+00 -1.52741522e+00  4.89637709e+00
  2.93718096e-01 -9.34763340e-01 -1.01451721e+00  1.87816435e+00
  1.56610659e+00]
supnorm grad right now is: 4.896377092189148
Weights right now are: 
[ -1.79683492   4.1875358   -8.17779896   5.25537377   2.05140363
  -4.29622749   8.57673623  -5.97140216  -4.30586128  14.32071148
   6.94969474 -14.88561863  24.57511283   6.35708989   2.91831459
  -3.50636967  -0.94554354  49.27460375  32.78695616  -5.47991363
  20.8077775   24.55605178  31.12942952  -9.76226389  71.34990634
  40.34300452  -3.36092091  35.44071017  -6.10770868   5.51732902
   8.38583941  -7.89415988  26.70787409   0.18093553  42.91618037
  38.71842065 -19.12339297  23.94001485  17.78302611  66.67165982
  12.96114384   4.5765332   -0.30083489  29.34647446   4.36741353
   0.31372031  -3.25598089   5.17874708 -15.06542227  15.58194775
  17.4787398   -1.11493429   4.9097471   26.91651197  -3.42839987
  40.99465997   4.96701211  -1.64088368  -2.73800277  -2.95089794
   6.66114011   0.86535122   2.98779257  -3.25487536  30.50173257]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.66827543424
gradient value of function right now is: [ 9.74207584e-01  1.20042932e+00  2.80879430e-02  7.06745932e-02
 -9.74207584e-01 -1.20042932e+00 -2.80879430e-02 -7.06745932e-02
  5.57458597e-01  5.94266157e-01  6.01348665e-01  5.04091246e-01
 -1.68047228e-03 -5.03637694e-01 -2.02221865e+00 -1.01103759e-02
  8.40129611e-03  1.54863962e-02  9.16822514e-03  2.46729277e-05
 -6.82661166e-09 -2.71487130e-02 -2.05414769e-02 -1.51006803e-05
  3.34883292e-08  7.21657360e-03  1.50993837e-02  3.37985195e-13
 -3.97483370e-02  4.82661838e-01 -5.13197410e-02 -3.27546041e-01
  9.37967365e-02  1.49144619e+00 -6.93586637e-03  5.02262623e-03
 -2.44725914e-05  7.62748908e-03  3.15826401e-02 -7.68339687e-06
 -1.23473651e-01 -6.68418691e-01 -6.57156299e-01 -7.10197999e-02
 -2.26451131e-01 -2.77501886e+00  2.44783011e-01 -5.90299492e-01
  2.39684286e-01  2.67072347e-01  6.06088152e-03  2.98742857e-01
 -1.75430259e-01 -1.21141437e-01 -1.11509474e+00 -4.97906795e-02
  9.03594753e-01 -5.18894827e-01  1.28242297e+00 -4.57034933e+00
 -3.40582236e-01  8.03137549e-01  1.65233056e+00 -3.51498669e+00
 -1.36347523e+01]
supnorm grad right now is: 13.63475227427203
Weights right now are: 
[-1.21806153e+00  3.85791455e+00 -7.62669262e+00  5.08360473e+00
  1.47263024e+00 -3.96660624e+00  8.02562989e+00 -5.79963311e+00
 -4.30156703e+00  1.46151840e+01  7.44125035e+00 -1.45384378e+01
  2.68378812e+01  6.37833522e+00  3.02885224e+00 -4.20162358e+00
  5.35565677e-01  5.02149640e+01  3.42031397e+01 -1.33129090e+00
  2.08099058e+01  2.52135664e+01  3.19171884e+01 -1.03158626e+01
  7.15440658e+01  4.15498459e+01 -4.50304009e+00  3.54407140e+01
 -6.20025339e+00  5.70544349e+00  8.48979643e+00 -8.26310469e+00
  2.66471334e+01  1.88884703e-02  4.44681186e+01  3.98584330e+01
 -2.35659782e+01  2.29874157e+01  1.72639674e+01  6.85103667e+01
  1.28197552e+01  4.12738603e+00 -4.12685759e-01  2.97354719e+01
  4.51239272e+00  5.49154524e-02 -3.40058621e+00  4.63115842e+00
 -1.54692763e+01  1.61794476e+01  1.79169580e+01 -1.31183838e+00
  4.74110074e+00  2.70803690e+01 -3.48014302e+00  4.19294339e+01
  5.26876850e+00 -1.74511736e+00 -2.58868442e+00 -2.92016611e+00
  7.10420993e+00  9.39466842e-01  2.77153142e+00 -3.29004116e+00
  3.05471864e+01]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1592.9423925328047
gradient value of function right now is: [ 9.07075107e-01  3.12892678e+00  2.40756310e-02  1.47903569e-01
 -9.07075107e-01 -3.12892678e+00 -2.40756310e-02 -1.47903569e-01
  1.74996454e-01  3.80338604e-01  3.86772039e-01  1.75734948e-01
  8.90698163e-04 -2.20295727e+00 -4.50788444e+00 -2.00769963e-03
 -1.69242904e-03  2.29185648e-02  6.65212705e-03 -6.65964649e-05
  3.13686055e-10 -1.42028796e-01 -1.51629842e-02 -6.84755584e-05
  7.23716109e-08 -6.33002588e-04  1.92266767e-04  2.44740065e-12
  1.33828101e+00  5.95523747e+00  1.30642243e-01  8.83558906e-01
  7.72314812e-02  2.69994210e+00  2.95438273e-04  4.82524665e-03
 -4.15514163e-04 -1.42210999e-03  3.24838540e-03 -1.55039780e-05
  1.40843121e-01  6.92247038e-02  1.13983594e+00  9.02393983e-03
 -1.03495035e+00 -4.77393032e+00 -2.83322748e+00 -8.02359789e-01
  1.54390031e-02 -9.57492887e-02 -7.93734900e-02  4.12324473e-02
  3.32849140e-01  3.04382467e-01  2.10032762e+00  8.21290708e-02
  4.62634403e-01  1.95329952e+00 -1.25816415e+00  8.44321763e+00
 -2.50548214e-01 -4.40323802e-01  8.11288722e-01  3.75119949e+00
 -5.34225063e+00]
supnorm grad right now is: 8.44321763409541
Weights right now are: 
[-1.41229316e+00  4.11077368e+00 -7.59659923e+00  5.31840519e+00
  1.66686187e+00 -4.21946537e+00  7.99553650e+00 -6.03443358e+00
 -4.55434454e+00  1.46139797e+01  7.77343928e+00 -1.45131248e+01
  2.72191897e+01  6.24699187e+00  2.59096485e+00 -3.48121821e+00
 -3.92591673e+00  5.15384616e+01  3.42830140e+01 -2.94724299e+00
  2.08107929e+01  2.64732827e+01  3.34537814e+01 -7.53872884e+00
  7.16202752e+01  4.16324503e+01 -6.57796114e+00  3.54407151e+01
 -6.49956619e+00  5.97973727e+00  9.33562137e+00 -8.17515316e+00
  2.69036098e+01  4.14598266e-01  4.40600977e+01  3.98048165e+01
 -2.12877942e+01  2.31045540e+01  1.65494634e+01  7.24499995e+01
  1.26519488e+01  4.20068396e+00  1.26487190e-01  2.96998260e+01
  4.18205463e+00  1.62308885e-03 -3.37168801e+00  4.70337153e+00
 -1.59218434e+01  1.67791622e+01  1.94427258e+01 -1.36439047e+00
  4.07494554e+00  2.83420718e+01 -3.32208095e+00  4.29772485e+01
  4.55505791e+00 -1.80486247e+00 -2.50455006e+00 -3.02379113e+00
  6.80306847e+00  7.42444374e-01  3.22283879e+00 -3.33363036e+00
  3.06762418e+01]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.8230116204477
gradient value of function right now is: [-1.13187636e+00 -1.44956431e+00 -6.40151070e-03  4.17124301e-03
  1.13187636e+00  1.44956431e+00  6.40151070e-03 -4.17124301e-03
 -7.67145941e-01 -8.07147781e-01 -9.96271009e-01 -7.52430817e-01
  2.19135320e-03  5.15193867e-01  3.91597853e+00  1.88932182e-02
 -1.55755554e-03 -2.19089337e-03 -4.97692694e-03 -4.83828271e-05
  1.62653856e-09 -2.23612268e-02  1.29892857e-02  3.56734387e-05
 -2.51465847e-07 -1.24876873e-02 -1.04202887e-02 -1.67090415e-12
  3.64330533e-01 -3.82647308e-02  1.55247509e-02  5.37697165e-01
 -9.57987151e-02 -2.49648507e+00  6.27562787e-03 -4.75978075e-03
  2.71588096e-04 -1.03158636e-02 -2.46812621e-02 -1.04580830e-07
  2.17590070e-01  7.53278291e-01  1.40304067e+00  1.30612624e-01
  6.86160687e-01  4.45608663e+00 -4.66186488e-01  1.02202773e+00
 -1.93946926e-01 -2.23787550e-01 -9.37827102e-03 -2.35135407e-01
  2.09132856e-01  2.26000192e-01  1.73283149e+00  9.14493406e-02
 -1.80885556e+00  1.67358204e+00 -1.96372407e+00  7.91513345e+00
  6.87303912e-01 -1.37978378e+00 -2.84828051e+00  6.87861264e+00
  1.93351966e+01]
supnorm grad right now is: 19.335196621099172
Weights right now are: 
[-1.53292636e+00  3.80143343e+00 -6.46832766e+00  5.04751446e+00
  1.78749507e+00 -3.91012512e+00  6.86726493e+00 -5.76354285e+00
 -5.10831804e+00  1.40499847e+01  7.37105053e+00 -1.53010533e+01
  2.85237617e+01  6.58432191e+00  3.10091838e+00 -3.75188590e+00
 -3.95077849e+00  5.26524802e+01  3.50026963e+01  5.67831558e-02
  2.08106034e+01  2.71292748e+01  3.57720583e+01 -1.05152598e+01
  7.17497807e+01  4.27798527e+01 -4.88127168e+00  3.54407215e+01
 -6.68635076e+00  6.05683307e+00  8.68654948e+00 -8.35608693e+00
  2.65551166e+01  1.65057452e-01  4.77586211e+01  4.12630049e+01
 -2.26882289e+01  2.39251662e+01  1.59549178e+01  7.49081000e+01
  1.29923620e+01  4.06909649e+00 -7.26883238e-02  3.06781304e+01
  4.10043223e+00  3.96591508e-01 -2.81139002e+00  4.62587091e+00
 -1.60438340e+01  1.74000670e+01  1.99828778e+01 -1.31605984e+00
  3.80654186e+00  2.82121640e+01 -3.28048685e+00  4.35695531e+01
  4.02512055e+00 -2.16133865e+00 -2.77849784e+00 -2.98432652e+00
  5.90318860e+00  6.76751565e-01  2.97337226e+00 -3.11327525e+00
  3.06639764e+01]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.3013969693732
gradient value of function right now is: [ 1.00710495e+00  1.07252159e+00  1.42755093e-02  7.20048496e-02
 -1.00710495e+00 -1.07252159e+00 -1.42755093e-02 -7.20048496e-02
  3.49680279e-01  4.26232817e-01  3.22517527e-01  3.23473790e-01
 -2.45006472e-03 -1.13767713e+00 -4.12196516e-01 -2.04349180e-02
  2.48695021e-03  7.99182583e-03  3.18395420e-03  8.22024268e-05
 -5.40351945e-09 -6.99463489e-02 -7.46701878e-03 -1.91937636e-04
  8.90873762e-09  7.92833721e-03  1.06346823e-02  7.09528085e-13
  1.16974007e+00  3.00254029e+00  1.14341056e-01  5.22846807e-01
  3.27326216e-04  2.14768504e-01 -3.52948394e-03  6.46593852e-03
 -3.55728311e-03 -6.64755612e-03  1.81018273e-02 -1.13724756e-04
  1.18784705e-01  9.49803931e-01  6.78589533e-01  3.34519097e-02
 -8.46327161e-01 -4.79239530e-01 -1.96606260e+00 -6.88566365e-01
  1.26409778e-01  2.80068327e-02 -4.63220670e-02  1.54319701e-01
  1.87210932e-01  2.19078749e-01  9.74856902e-01  3.87539969e-02
 -2.96387695e-02  1.97797185e+00 -2.01238909e+00  6.92246269e+00
 -8.41086185e-03 -1.48136062e+00 -5.91933062e-01  2.45044450e+00
 -3.99580076e+00]
supnorm grad right now is: 6.922462693147046
Weights right now are: 
[-8.27786090e-01  3.71690137e+00 -5.33266340e+00  4.98762672e+00
  1.08235480e+00 -3.82559306e+00  5.73160067e+00 -5.70365510e+00
 -5.03797915e+00  1.43810119e+01  7.15384111e+00 -1.52662301e+01
  2.61045512e+01  6.31175815e+00  2.78046150e+00 -5.37829134e+00
 -5.12393410e+00  5.33102415e+01  3.49955586e+01 -1.23834983e+00
  2.08110473e+01  2.76240405e+01  3.73765592e+01 -1.76404910e+01
  7.18596302e+01  4.53412288e+01 -4.78708424e+00  3.54407238e+01
 -6.73432002e+00  6.35861587e+00  8.82856321e+00 -8.77020539e+00
  2.67262373e+01  5.41397950e-01  4.61621557e+01  3.97421223e+01
 -2.39523282e+01  2.28684746e+01  1.88394686e+01  8.28545906e+01
  1.32883561e+01  4.61431060e+00 -4.00752593e-02  3.11808720e+01
  3.30910845e+00  3.11053448e-01 -2.79142187e+00  4.40548027e+00
 -1.70727016e+01  1.75243114e+01  2.05987826e+01 -1.88117119e+00
  2.93793373e+00  2.86230604e+01 -3.42895475e+00  4.44711705e+01
  5.29663274e+00 -1.69115749e+00 -2.97319738e+00 -2.98943024e+00
  6.53022422e+00  3.35891564e-01  3.12330513e+00 -3.43879578e+00
  3.05866260e+01]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.1685684179224
gradient value of function right now is: [-3.06647411e-01 -1.93542290e+00 -3.99096346e-02 -1.34117353e-01
  3.06647411e-01  1.93542290e+00  3.99096346e-02  1.34117353e-01
  3.57959127e-01  2.90318550e-01  1.72376429e-01  3.51078089e-01
  1.93241571e-03  7.84982348e-01  2.75631237e+00  1.57826957e-02
 -3.82123756e-03 -2.08013813e-02 -7.58638483e-03 -3.49603146e-05
  4.59296157e-10  6.14441203e-02  1.56103358e-02  1.64663294e-05
 -7.11213467e-08 -2.45227489e-03  1.76176890e-03 -6.37924818e-13
 -2.23252425e-01 -1.67975661e+00 -2.47935122e-02 -6.04344679e-02
 -7.47139097e-02 -1.84895288e+00 -6.50279792e-03 -7.89968367e-03
  1.45419892e-04  1.48515472e-02  1.14580841e-02  7.87310436e-07
  6.98011246e-02  3.07361564e-01  1.72750355e-01  5.13729731e-02
  3.64272728e-01  2.48990755e+00  9.83857386e-01  3.35466671e-01
  5.93094151e-02  9.62193512e-02  3.27084650e-02  7.02486649e-02
  1.07662614e-02  6.96703062e-04  4.98982405e-03  6.32482352e-03
 -5.94984336e-01  1.35214097e+00 -3.94846307e-01  4.66870456e-01
  3.47457823e-01 -1.31969880e+00 -1.29092716e+00  1.71730834e+00
  8.04269564e+00]
supnorm grad right now is: 8.042695635761564
Weights right now are: 
[ -1.26065944   3.47858919  -5.69663158   4.31143      1.51522815
  -3.58728088   6.09556885  -5.02745838  -4.97044141  14.8493196
   7.77535385 -14.90483943  27.83408754   6.57356375   3.06962483
  -4.36331645  -4.583809    55.44222836  37.88201603  -0.88038358
  20.81197859  28.95897151  38.50986675 -17.18801781  71.99570346
  45.79987973  -4.93357787  35.44072453  -6.77385398   6.45202284
   8.34568703  -8.84154105  26.25651597   0.30250631  46.73485609
  40.95644714 -22.57581355  24.77230674  19.70203079  86.68596342
  13.47565957   4.12511538  -0.31478186  31.70428657   3.69433393
   0.34180964  -2.6411513    4.92489737 -17.49951553  17.99271691
  20.29663814  -2.0805979    3.63058484  29.1534547   -3.26524801
  45.71524569   4.10527204  -2.11928288  -2.95850541  -3.09883881
   6.14768279   0.75607274   2.9998026   -3.16759096  30.58867708]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1595.4269071906
gradient value of function right now is: [-9.28404947e-01 -3.51702052e+00 -5.54045257e-02 -1.58329299e-01
  9.28404947e-01  3.51702052e+00  5.54045257e-02  1.58329299e-01
  2.48143418e-02 -1.08844776e-01 -2.78221689e-01  2.99815065e-02
  5.55230614e-03  1.93032931e+00  6.18968611e+00  6.14123073e-02
 -2.76113192e-03 -2.51365472e-02 -1.17316457e-02 -3.05766866e-05
  7.33224212e-10  5.88777366e-02  2.45663022e-02  1.53689734e-04
 -3.77604515e-07 -1.52408030e-02 -4.08217009e-03 -1.14276370e-12
 -5.39772705e-01 -3.24440015e+00 -5.80147576e-02  9.00771150e-02
 -1.41663724e-01 -3.86041794e+00 -2.05598137e-03 -1.25753038e-02
  3.85013752e-03  4.12340125e-02 -5.62095316e-03  8.41155826e-05
  1.56084518e-01  5.72919732e-01  6.01597243e-01  1.11375904e-01
  6.13904993e-01  7.69080798e+00  9.27385641e-01  1.26477328e+00
 -2.20966025e-02  5.21039543e-02  3.65664889e-02 -1.95070800e-02
  1.48265651e-01  6.43804110e-02  7.85525177e-01  5.18536410e-02
 -9.16785407e-01  2.24207547e+00 -1.01130342e+00  2.85988466e+00
  6.56297389e-01 -1.51448288e+00 -3.84593064e+00  4.76891447e+00
  2.94617802e+01]
supnorm grad right now is: 29.46178017070481
Weights right now are: 
[ -1.32470144   3.57142544  -6.3402577    4.27183304   1.57927015
  -3.68011713   6.73919497  -4.98786142  -5.49709681  14.48420346
   7.97872812 -15.18157289  29.57103041   6.73157645   3.10438352
  -5.25863092  -4.51973436  56.78965531  39.75249864  -0.93291314
  20.81267168  28.70699544  38.25269739 -21.81854878  72.13173053
  45.97088575  -6.4887546   35.44072597  -7.49912911   6.51108568
   7.28931372  -9.23992147  26.52220258   0.28964643  50.45114604
  40.47056719 -24.28517113  22.62536991  17.82356476  92.24266497
  13.50630627   4.15388524  -0.41574216  31.87427631   3.66121712
   0.46773546  -2.64390516   5.01664452 -17.98427937  18.53643247
  19.48038089  -2.18608144   3.35976286  29.44359292  -3.36069803
  46.4583236    5.53992785  -1.82036879  -2.89209895  -3.19333188
   6.94278029   0.88993574   2.80254908  -3.32752515  30.7808865 ]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.865726076172
gradient value of function right now is: [-9.73057680e-01 -2.44273786e+00 -8.79254170e-02 -1.64566232e-01
  9.73057680e-01  2.44273786e+00  8.79254170e-02  1.64566232e-01
 -2.08488707e-02 -7.53166240e-02 -1.47054776e-01  3.86594023e-02
  1.81818108e-03  9.73796558e-01  3.60722697e+00  2.70219756e-02
 -6.03322958e-03 -2.55225430e-02 -2.08266108e-02 -8.36084221e-05
  2.13172734e-09  4.66426545e-02  3.05438180e-02  2.00961965e-04
 -4.75400665e-08 -3.25834309e-03 -1.38266136e-02 -7.89987037e-14
 -1.24490530e-01 -1.06189023e+00  2.42517567e-02  4.03447606e-01
 -1.01507953e-01 -2.45668897e+00  2.74312483e-03 -7.93999206e-03
  3.35217949e-03  2.82512438e-02 -2.33068005e-02  3.84099570e-05
  1.95363862e-01  3.13760230e-01  1.11074863e+00  1.05290673e-01
  1.88955603e-01  4.78162566e+00 -5.69622064e-01  6.17729129e-01
 -1.94082256e-01 -1.89428707e-01 -8.53936141e-04 -2.46882699e-01
  2.50636255e-01  1.69876265e-01  1.62454210e+00  8.90386733e-02
 -7.64627803e-01  1.48214767e+00 -1.12737863e+00  5.82219938e+00
  5.43546493e-01 -1.14760616e+00 -2.70496950e+00  6.55829113e+00
  2.29312502e+01]
supnorm grad right now is: 22.931250196615736
Weights right now are: 
[ -1.38119038   3.59395985  -6.28010509   4.6394399    1.63575909
  -3.70265154   6.67904236  -5.35546828  -5.62202861  14.57324853
   8.39927193 -15.14641581  30.13647547   6.83124116   3.25109246
  -5.40159007  -4.7242748   58.44201583  37.55774776  -1.80279345
  20.81269602  29.12759549  40.8934398  -21.97107508  72.18104893
  48.43297355  -6.73871701  35.44072671  -7.19102001   6.60604117
   8.04189055  -8.85119722  26.42108387   0.54204334  52.0162335
  40.62332701 -24.56301278  23.80132582  18.25243023  94.1130763
  12.92980334   4.03598627  -0.54999498  32.12546117   3.25670833
   0.30564772  -2.83161287   4.88931056 -19.09552057  18.49932239
  18.57734888  -2.87396799   3.17857129  29.72777423  -3.27967034
  47.15113931   5.64465985  -1.84921682  -2.80054487  -3.12009178
   7.86212556   0.98379843   2.86419802  -3.22705382  30.77028784]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.4992228703109
gradient value of function right now is: [ 9.34888843e-01 -2.54367606e-01  9.88633059e-03  6.02354934e-02
 -9.34888843e-01  2.54367606e-01 -9.88633059e-03 -6.02354934e-02
  4.14567655e-01  4.60899166e-01  3.27220677e-01  3.86513364e-01
  1.43416917e-03 -1.73496210e-01  2.38501550e+00  2.77805262e-02
 -2.53598093e-04  5.99668680e-03  1.06611820e-03  4.44121106e-06
 -5.74557272e-09 -4.16373430e-02 -1.88752627e-03  5.87185171e-04
 -6.16363898e-07 -9.71054305e-04  1.24550649e-02 -1.58073337e-13
  1.03794830e+00  1.42822194e+00  2.87513713e-01  9.43670394e-01
 -3.14514287e-02 -1.16883834e+00 -3.23454485e-03  2.93556826e-04
  5.09189824e-03  3.36834372e-02  1.59164052e-02  1.63851200e-05
  1.90812378e-01  5.49691628e-01  1.00043353e+00  6.81843117e-02
 -3.37035177e-01  3.70733788e+00 -1.71424764e+00  5.36762173e-02
  1.14457094e-01  5.40834091e-02 -6.60222916e-02  1.51098166e-01
  3.16662240e-01  2.29164253e-01  1.74029117e+00  8.42191701e-02
 -7.03387324e-01  3.98727923e+00 -1.66217501e+00  6.61784110e+00
  7.14669333e-01 -3.40310313e+00 -2.23191888e+00  6.30654148e+00
 -1.10713348e+00]
supnorm grad right now is: 6.617841103105851
Weights right now are: 
[-8.74957065e-01  3.28353658e+00 -5.32561063e+00  4.50141971e+00
  1.12952578e+00 -3.39222827e+00  5.72454790e+00 -5.21744810e+00
 -5.80554943e+00  1.41996660e+01  8.43423829e+00 -1.53908140e+01
  3.22918651e+01  6.54738749e+00  2.98888222e+00 -4.25993305e+00
 -4.36160543e+00  6.06501299e+01  3.97695795e+01  8.81312948e-02
  2.08115545e+01  3.02466157e+01  4.09617658e+01 -1.95771377e+01
  7.24105890e+01  4.64079675e+01 -3.89523601e+00  3.54407275e+01
 -6.49709298e+00  7.09425146e+00  8.09257537e+00 -8.43926741e+00
  2.52961434e+01  3.30135249e-01  5.47378339e+01  4.14192640e+01
 -2.54553158e+01  2.33399736e+01  1.90360305e+01  9.56159775e+01
  1.34403119e+01  4.04886875e+00 -4.77795156e-01  3.26674143e+01
  3.09354848e+00  6.29977287e-01 -2.64687026e+00  4.89534339e+00
 -1.86861438e+01  1.92590397e+01  1.91627453e+01 -2.54783325e+00
  3.66644943e+00  3.05978602e+01 -2.97933886e+00  4.78782845e+01
  4.74164731e+00 -1.75096573e+00 -3.10850028e+00 -3.24991799e+00
  7.41586958e+00  4.99002443e-01  3.03402857e+00 -3.10068604e+00
  3.03197204e+01]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -1593.135725306251
gradient value of function right now is: [ 1.47397858e+00  1.34125885e+00  8.76763033e-02  3.02722966e-01
 -1.47397858e+00 -1.34125885e+00 -8.76763033e-02 -3.02722966e-01
  2.32448937e-01  3.23847835e-01  1.93118975e-01  2.10597948e-01
  3.66273382e-04 -8.48480958e-01  4.07791992e-01 -2.12782726e-03
  5.47641708e-03  2.62661283e-02  4.82305822e-03  6.17861923e-05
 -8.62483236e-09 -1.60195290e-01 -1.26267361e-02 -6.37818670e-04
 -7.40712985e-09  1.54573000e-03  1.33484921e-02  4.24564121e-14
  1.73165348e+00  4.09473785e+00  5.76092672e-02  7.64705389e-01
  1.43749738e-02 -2.46385615e-02 -1.80883908e-03  5.41665782e-03
 -7.09006321e-03 -4.74067078e-03  1.27012662e-02 -1.80906021e-04
  1.62615593e-01  1.24824633e+00  1.64326689e+00  1.08213730e-01
 -7.10871687e-01  8.64877280e-01 -3.17488100e+00 -4.95154960e-01
  1.57908341e-01  1.07667456e-01 -4.29075162e-02  1.78667688e-01
  1.88130752e-01  2.73712501e-01  1.82618254e+00  9.15171129e-02
 -2.75314695e-01  2.69581967e+00 -2.83982335e+00  1.02852064e+01
 -2.42778197e-01 -4.51095656e-01 -2.27788570e+00  7.49789618e+00
  4.12800408e-01]
supnorm grad right now is: 10.285206416820612
Weights right now are: 
[ -0.63335774   3.5286157   -4.23999558   4.82458907   0.88792645
  -3.63730739   4.63893285  -5.54061746  -5.83545124  14.0898329
   8.75611562 -15.40142787  32.33800834   6.95907867   2.85251436
  -4.45245715  -4.60805672  61.47529402  41.16267818   1.22148512
  20.81168817  30.46985528  41.28158768 -19.08207315  72.55983065
  47.47139289  -3.23974769  35.44072839  -7.02133989   7.24182401
   7.55653806  -8.61012202  25.82572617   0.59978672  57.55965013
  40.92510471 -25.93651075  23.16239486  18.60282215  98.88478712
  13.32631117   4.13823025  -0.42896071  34.26267585   2.85141057
   0.34953952  -2.72838958   4.77014411 -18.95941751  20.11855388
  19.69002683  -2.5518573    3.07579041  30.58885372  -3.22348389
  48.27154456   5.2375537   -2.041139    -3.01903907  -3.07398737
   6.91763441   0.66545825   3.13322409  -2.978782    30.52152542]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.9085399196515
gradient value of function right now is: [-1.20327933e+00 -1.03388147e+00 -5.89776316e-03 -6.52616267e-02
  1.20327933e+00  1.03388147e+00  5.89776316e-03  6.52616267e-02
 -6.10239197e-01 -6.71532186e-01 -7.38744703e-01 -6.31565126e-01
 -2.08938991e-03  1.39200002e-01  1.46836941e+00 -2.20033941e-02
  5.92495048e-05 -5.02224810e-03 -1.16447589e-03 -7.89706005e-06
  4.84799034e-10  3.60273482e-02  7.50048445e-03 -3.28251791e-04
 -5.81573813e-09 -2.39913540e-03 -2.47207375e-03 -3.27881908e-13
  3.50407175e-01 -9.35849930e-01  1.25721847e-01 -2.72312528e-01
 -5.95011117e-02 -8.77105778e-01  1.25944679e-03 -1.27414273e-03
 -6.67932320e-03 -3.13800845e-02 -5.87704842e-03 -2.09792447e-04
 -4.77364176e-02  6.33853317e-01 -3.36318103e-01  5.07646182e-03
  5.64119633e-01  2.47898277e+00  1.56420618e+00  5.77146323e-01
 -6.66780598e-02 -1.46067159e-01 -3.18530124e-02 -8.42871494e-02
 -2.23343015e-01 -4.31299750e-02 -1.30834804e+00 -5.51624647e-02
 -3.65875308e-01 -1.08288384e+00 -1.25060962e+00 -9.40418524e-01
  2.92646908e-01  3.03327021e-01 -6.05624527e-01 -2.56495980e+00
  7.56535711e+00]
supnorm grad right now is: 7.565357109947892
Weights right now are: 
[ -1.21862285   3.39454604  -4.60887687   4.46211027   1.47319156
  -3.50323773   5.00781414  -5.17813865  -6.56802667  13.5911294
   8.77018205 -15.49776407  30.63455532   6.64184995   2.82473315
  -5.92863926  -2.0351663   64.03886983  41.77962028   5.12418161
  20.812649    31.20474505  40.04920898 -19.83707987  72.75540312
  49.21134404  -5.38480773  35.44072919  -6.70106735   7.35419362
   8.21989519  -8.70621034  25.36112969   0.41196273  60.47849054
  37.6621749  -23.96720472  22.05354275  16.76755824 106.20958122
  13.53458492   4.59867837  -0.50747683  35.03793308   3.47377024
   0.73181569  -2.16003679   5.03555184 -18.90515272  20.42006031
  18.24387229  -2.51964452   3.42322353  31.56629204  -3.42340316
  48.51342808   5.3462804   -1.77275168  -3.13508712  -3.17132359
   7.44608563   0.80223568   3.25042848  -3.35320511  30.60683109]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.2436785377563
gradient value of function right now is: [-4.69349485e-02  2.00045997e+00  3.07959341e-03  8.54921521e-02
  4.69349485e-02 -2.00045997e+00 -3.07959341e-03 -8.54921521e-02
 -2.07681039e-01 -9.84804552e-02 -3.05857208e-03 -1.43871469e-01
 -1.91985916e-03 -9.01477691e-01 -2.70109324e+00 -2.91709021e-02
 -9.58530667e-02  3.67021793e-03  5.47373343e-03  2.22595221e-05
  3.06470120e-08 -4.80463820e-02 -1.10346853e-02 -3.40398753e-04
  1.27238970e-07  4.90445480e-03 -2.19865295e-02  3.05539831e-13
  5.03912831e-01  1.95769671e+00  1.74225963e-01 -4.15440681e-02
  7.09474969e-02  1.52591910e+00  7.82347554e-03  2.63006832e-03
 -2.30688397e-03 -2.04891767e-02 -2.04997283e-02 -4.18582701e-05
 -2.56720566e-02 -8.01987775e-02 -1.01980924e-01 -2.52343357e-02
 -2.39730033e-01 -3.89411086e+00 -6.82200005e-01 -4.59565332e-01
 -3.56357858e-01 -4.77030461e-01 -5.43758958e-02 -4.07910742e-01
 -1.16726340e-02  1.46398846e-02 -2.00496681e-01 -6.65281965e-03
  5.96794674e-03 -2.00169455e+00  4.25926508e-01 -3.34150947e-02
 -1.32593111e-01  1.08466772e+00  1.36405957e+00 -1.24507146e+00
 -6.97991792e+00]
supnorm grad right now is: 6.979917924127878
Weights right now are: 
[ -0.83311044   3.53242614  -5.82302678   3.84315985   1.08767915
  -3.64111783   6.22196405  -4.55918823  -6.35142756  13.88209545
   8.13849954 -15.73844123  33.06229801   6.71914677   2.92446071
  -4.46693051   0.27519032  66.01785297  40.41520264   4.94363733
  20.81090535  31.91082306  40.25323858 -18.17275713  72.92081439
  48.46736703  -2.40457797  35.4407306   -6.40456078   7.47440615
   6.05963712  -8.06580995  25.08175566   0.45510151  59.31567992
  33.4011195  -23.96651878  23.30913018  23.92632183 108.67534731
  13.58690802   4.76887571  -0.65181209  35.63045194   3.4089323
   0.6156662   -2.01347518   4.75671584 -20.00196323  19.5594317
  19.55710129  -3.81238409   4.08391958  32.2601477   -3.04351147
  49.62100003   4.42398261  -2.46421953  -2.60459333  -3.16575681
   7.41242735   1.34620575   2.88469072  -3.04756768  30.47006242]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.6192210052213
gradient value of function right now is: [-7.38284613e-01 -1.61676035e+00 -6.67025836e-02 -2.44490948e-01
  7.38284613e-01  1.61676035e+00  6.67025836e-02  2.44490948e-01
  1.07313494e-01  2.23258481e-02  4.82369300e-02  1.05814205e-01
  1.62528898e-03  5.92122316e-01  1.06113906e+00  1.91012869e-02
 -2.95571018e-03 -3.08120029e-02 -1.14034479e-02 -9.64008674e-06
  5.44258298e-10  8.27478063e-02  1.83721828e-02  1.31091041e-04
 -3.14936094e-08 -3.71024027e-03  7.82472378e-04  4.42597715e-14
 -3.46131548e-01 -1.29268488e+00 -1.36728839e-02 -8.60391562e-02
 -5.65020887e-02 -6.25487437e-01 -7.63756950e-04 -4.96812637e-03
  4.97127498e-04  1.02253163e-02  1.05262692e-03  6.00969675e-07
 -9.37151793e-03  9.00360963e-02 -1.57013984e-01  4.43930273e-03
  1.27396277e-01  2.07119626e+00  4.92208135e-01  1.84387475e-01
 -2.15037744e-03  1.09789367e-02  8.40514938e-03  1.01059292e-03
 -1.02232305e-02 -2.33103549e-02 -1.15386704e-01 -2.12688745e-03
 -1.20919117e-01 -2.03019417e-02 -9.10884681e-02 -7.07583227e-01
  2.00258310e-01 -3.50378070e-01 -6.21022566e-01 -1.33842913e-01
  7.04426175e+00]
supnorm grad right now is: 7.044261752006491
Weights right now are: 
[ -1.07077073   3.45071976  -6.71122791   3.66456368   1.32533944
  -3.55941145   7.11016518  -4.38059206  -6.38403316  14.35981041
   8.7822186  -15.00239108  33.07965814   6.90490242   2.78025156
  -3.63181924  -0.79957826  67.9440153   39.78799761   4.40370746
  20.81029304  32.93374873  40.02088602 -16.22905618  73.01769798
  48.79658431  -4.045947    35.44073103  -6.88638326   7.09150574
   7.648323    -7.79993052  24.5725099    0.41203103  58.14963199
  30.27260039 -24.87655397  23.32504822  24.62291091 110.51605374
  13.28290431   4.46217357  -0.7630389   35.50891556   3.23787874
   0.53651013  -2.33073823   4.7247721  -19.50890794  20.32972915
  22.21561364  -3.16520019   4.06707555  33.06400392  -3.06977507
  50.5556477    4.63712364  -1.85387232  -2.87775586  -3.20888784
   6.54321077   0.78491937   3.0434161   -3.5210343   30.64185652]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.630362377964
gradient value of function right now is: [-5.30259859e-01  5.86572352e-01 -4.29836427e-03 -4.85406291e-02
  5.30259859e-01 -5.86572352e-01  4.29836427e-03  4.85406291e-02
 -2.03166252e-01 -1.95018138e-01 -8.44609411e-02 -1.55063468e-01
 -4.49767707e-04 -3.34434856e-01 -2.06839633e+00 -2.12421805e-02
 -1.72283032e-02 -3.97820262e-03  6.19483085e-05  1.20259643e-06
  9.39445074e-10  3.11082165e-02 -3.32440503e-04 -8.83593890e-05
  6.50765813e-08  7.75079438e-04 -1.32853857e-02  2.70061171e-13
 -2.13224110e-01 -1.79160629e-01  7.20790784e-02 -2.98862809e-01
  1.93699681e-02  9.21213920e-01  4.42104719e-03  1.33663835e-04
 -1.00146017e-03 -2.00427254e-02 -1.56966913e-02 -1.28277447e-05
 -1.01164919e-01 -1.70351224e-01 -7.42960663e-01 -4.65860196e-02
 -9.02551347e-03 -2.34960700e+00  8.44876924e-01 -1.77421029e-01
 -1.59785426e-01 -2.13635794e-01 -1.46451562e-02 -1.86958736e-01
 -9.96671855e-02 -7.76008814e-02 -7.91966630e-01 -3.85026762e-02
  1.96903607e-01 -2.13073085e+00  7.35719074e-01 -3.26462374e+00
  4.28050842e-03  6.32261057e-01  1.34459025e+00 -3.52812879e+00
 -3.62362769e+00]
supnorm grad right now is: 3.6236276890423884
Weights right now are: 
[ -1.10132326   3.44721935  -5.80338488   4.15158546   1.35589197
  -3.55591104   6.20232215  -4.86761385  -6.757123    14.27079022
   8.65207677 -14.97414999  33.53322152   6.34547935   2.71378526
  -4.7525621    0.49259346  68.85296095  39.48118251   5.66237262
  20.81014418  32.7328656   40.379363   -18.13237769  73.07930835
  48.99371244  -5.57220851  35.44073138  -7.19787409   7.37202192
   7.28336895  -7.90353702  24.88035432   0.24900019  58.60046677
  26.94033677 -23.51185269  22.22372531  25.18192164 119.39713757
  13.86057784   4.46520029  -0.79369697  37.35751113   3.21842932
   0.486886    -2.29896794   5.35944929 -19.99746769  20.51847468
  22.15484803  -3.5191878    3.39339935  33.14878572  -3.06623002
  50.70775675   4.39781492  -2.25000571  -2.95487719  -3.4043112
   7.2026862    0.67677027   2.78853141  -3.4222375   30.58415544]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1600.0026079850818
gradient value of function right now is: [-4.98502781e-02 -9.72124636e-02  5.46683482e-03  1.80825052e-02
  4.98502781e-02  9.72124636e-02 -5.46683482e-03 -1.80825052e-02
 -6.62399040e-02 -6.17160978e-02 -6.77648370e-02 -6.49119695e-02
  6.10178717e-05  5.80420698e-02  4.46193753e-01  6.75966667e-03
  1.76803540e-03  1.75782660e-03  1.03047799e-03 -2.93175135e-06
 -2.71107372e-11 -4.96737866e-03 -1.59421887e-03  1.47600098e-04
 -1.22335479e-08 -3.08212529e-04  1.63292890e-04  7.32959393e-14
 -1.25996713e-01  1.38370637e-01 -5.60286920e-02  3.30958702e-01
 -3.92653484e-03 -2.14945851e-01  5.73031671e-04  1.24727343e-03
  2.11540304e-03  8.03788974e-03 -1.38384277e-03  4.05412153e-05
  7.57818686e-02 -3.85201993e-02  5.09999160e-01  1.42291945e-02
 -1.16776698e-01  1.09666038e+00 -9.39328900e-01  4.21654851e-02
  6.17057578e-03  2.49043175e-02  4.29615772e-03  6.52175776e-03
  1.80917975e-01  4.28072342e-02  1.15896862e+00  4.13968625e-02
  1.30303850e-03  9.65888567e-01  1.21709034e-01  1.44134973e+00
  6.09843482e-02 -5.30719909e-01 -3.68854813e-01  2.58638871e+00
  3.40792391e+00]
supnorm grad right now is: 3.4079239099889898
Weights right now are: 
[ -1.27371679   3.61320237  -5.18985247   4.2843072    1.5282855
  -3.72189406   5.58878974  -5.00033559  -7.17247325  14.22388849
   8.9843116  -15.18390648  34.36977605   6.63851189   3.12345311
  -4.72874315  -1.8782594   69.93043437  42.14340292   5.94666639
  20.81009504  32.76422863  37.9635611  -19.34608815  73.22736699
  50.2749458   -4.54574161  35.44073231  -7.32590968   7.3063183
   5.68540609  -8.07506805  25.42919843   0.65851854  63.23927825
  29.53373665 -24.91657946  22.60826922  23.3775167  121.7538346
  13.25113363   4.44666403  -0.69682149  38.15285992   3.7076743
   0.626066    -2.36387247   4.36342486 -20.07063316  21.44383912
  21.11261322  -3.2998709    2.84960994  33.28016537  -2.89095752
  51.32537799   5.57916712  -1.6704571   -3.01373975  -3.38587669
   7.2653211    0.9120433    2.94094655  -3.30725826  30.60053858]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.0934529546073
gradient value of function right now is: [ 7.04847795e-01  1.63975252e+00  6.06476288e-03  4.48312475e-02
 -7.04847795e-01 -1.63975252e+00 -6.06476288e-03 -4.48312475e-02
  1.96015743e-01  2.92871538e-01  2.74890009e-01  2.05287582e-01
 -1.20350057e-03 -9.75801241e-01 -1.91557810e+00 -1.60570456e-02
 -2.97299718e-03  1.74156309e-03  2.87526395e-03  4.48237219e-06
 -6.91918825e-11 -2.80227677e-02 -7.55500534e-03 -1.27775694e-04
  1.79204945e-09  5.53883365e-03  8.73871775e-04  1.87814131e-14
  7.95917602e-01  2.30342295e+00  1.25225704e-01  4.13301527e-01
  3.60415197e-02  1.23085475e+00 -2.25378234e-04  2.09224782e-03
 -1.56173473e-03 -6.81207278e-03  8.40940630e-04 -3.06352172e-05
  7.00425544e-02  1.16545014e-01  6.30449338e-01  1.52076696e-02
 -5.11971611e-01 -2.94237645e+00 -1.30288666e+00 -6.39306316e-01
  1.44500403e-02 -3.98178795e-02 -2.84401521e-02  2.66172160e-02
  1.10761065e-01  9.53416300e-02  8.55564170e-01  3.32521413e-02
  2.75650305e-01  1.00596694e+00 -3.93080335e-01  2.85582985e+00
  1.87098482e-01 -1.03671627e+00  6.33575143e-01  2.46216489e+00
 -7.56870265e+00]
supnorm grad right now is: 7.568702645423849
Weights right now are: 
[ -0.97880144   3.51941049  -5.38961219   3.89853333   1.23337015
  -3.62810218   5.78854946  -4.61456172  -7.10874108  14.38978853
   9.28777915 -14.85139469  31.44709315   6.51292191   3.1035307
  -5.82315642  -1.06440988  72.19819042  43.36332811   5.92775196
  20.81016682  33.784527    38.71826528 -18.79151116  73.2710251
  52.86105922  -5.76643667  35.44073249  -6.87981374   7.3344309
   8.47107635  -7.66727448  23.85951768   0.81221408  62.61674232
  33.58426893 -24.63306615  23.46054737  24.66523476 120.74444915
  12.64403795   4.77321855  -1.13582315  38.38255045   3.47200933
   0.17903897  -2.4459641    4.86189956 -20.20356169  21.71582634
  22.19690248  -3.12279458   2.08605321  34.13440424  -3.02747303
  51.76614709   4.92970185  -1.92517298  -2.67397813  -3.28280904
   7.79037694   0.89484447   3.10573195  -3.24640045  30.52956556]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.3733857946484
gradient value of function right now is: [-1.46801700e+00 -1.47452796e+00 -2.89504642e-02 -9.81912717e-02
  1.46801700e+00  1.47452796e+00  2.89504642e-02  9.81912717e-02
 -7.11618979e-01 -6.63198715e-01 -1.00286202e+00 -7.16784670e-01
  5.80116989e-04 -5.92268806e-01  3.39488590e+00  8.10536715e-03
 -3.07773348e-03 -1.08274161e-02 -7.50827013e-03 -1.72273785e-05
  2.66928606e-10  5.67955532e-03  2.88458641e-02 -8.03364854e-05
 -4.96360990e-09 -1.22015820e-02 -8.39021431e-03 -1.64058075e-14
  1.74141677e+00  1.73633751e+00  2.78428332e-01  8.00950697e-01
 -1.55742725e-01 -2.32770135e+00  3.38593583e-03 -5.38823263e-03
 -3.27362704e-03 -1.62869677e-02 -1.22612217e-02 -7.48697878e-05
  2.77816067e-01  1.48333548e+00  1.83045251e+00  1.43547191e-01
  3.77930464e-01  4.14512665e+00 -1.41527302e+00  9.98681531e-01
 -1.44613128e-01 -2.82502900e-01 -5.75926045e-02 -1.85095556e-01
  1.78394899e-01  2.67812046e-01  1.40054290e+00  6.34905639e-02
 -1.30333596e+00  1.67092212e+00 -2.81571344e+00  1.14850406e+01
  9.44217187e-01 -3.09650092e+00 -3.05045567e+00  7.75437008e+00
  1.68918047e+01]
supnorm grad right now is: 16.891804706699805
Weights right now are: 
[ -1.35179245   3.44865534  -5.43557638   4.44893972   1.60636116
  -3.55734703   5.83451365  -5.16496811  -7.70053376  14.12904814
   8.99002663 -15.21043079  36.06465907   6.69355578   3.06770379
  -4.92770009  -1.65487675  73.62058621  40.5519436    6.57559692
  20.81018684  32.80500987  38.39694816 -16.30827365  73.29693165
  51.22084983  -6.65752147  35.44073272  -6.70154443   7.56847511
   8.80959626  -7.87456847  24.21737034   0.57579328  63.80388809
  32.41373336 -23.61000001  23.33997595  25.39252009 124.74171769
  12.30839127   4.07334584  -1.05297586  38.66127673   3.00275629
   0.27741786  -2.27024354   4.84850132 -20.76239106  21.65856902
  23.91307782  -3.59526345   1.39048997  35.47117977  -3.27264272
  52.12631191   5.02676066  -2.2146994   -3.18214369  -2.97823563
   7.49850603   0.37284959   2.96760316  -3.38441446  30.56512863]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.8871480893395
gradient value of function right now is: [-7.28901240e-01 -4.51760145e-02 -3.95183043e-02 -1.06176271e-01
  7.28901240e-01  4.51760145e-02  3.95183043e-02  1.06176271e-01
 -1.04722644e-01 -1.25867249e-01 -3.95612540e-02 -8.03328890e-02
 -1.51039151e-03  9.25297901e-02 -1.50811126e+00 -1.74001462e-02
 -1.01840875e-02 -9.09787134e-03 -4.44769753e-03 -1.04899601e-05
  3.06614029e-09  3.52645601e-02  5.10518724e-03  2.31646337e-04
  2.58860111e-08  6.08266525e-03 -7.73411068e-03  6.45817129e-15
 -7.95540338e-01 -8.63700101e-01 -2.56567225e-02 -2.97121594e-01
  6.96409274e-03  7.38674306e-01  1.30434402e-03 -7.90301962e-04
  3.47686118e-03 -3.51626462e-04 -4.84810417e-03  6.40662706e-05
 -5.64605554e-02 -4.73903870e-01 -8.17311280e-01 -3.67641334e-02
 -8.83204888e-02 -2.72754946e+00  7.71386503e-01 -3.38281129e-01
 -1.40650979e-01 -1.36999155e-01  7.38409064e-03 -1.59599446e-01
 -4.09949315e-02 -8.75964021e-02 -6.28407416e-01 -2.06695595e-02
  3.65616691e-01 -1.27129518e+00  1.52892057e+00 -4.10874282e+00
 -1.76088432e-01  8.47678977e-01  1.85742838e+00 -2.43956476e+00
 -9.43932247e+00]
supnorm grad right now is: 9.439322471088923
Weights right now are: 
[ -0.77097521   3.16229885  -5.64306627   3.87232502   1.02554392
  -3.27099054   6.04200354  -4.5883534   -7.8484603   13.95684335
   8.95287225 -15.47763756  38.32836582   6.96043038   3.12105962
  -4.19246976  -3.07948681  73.87101853  39.26081159   7.2214403
  20.81023324  33.73870597  40.23097262 -18.48671217  73.32541816
  50.93733517  -4.21838941  35.44073285  -7.20791296   7.37145447
   9.22855251  -7.67105928  23.654146     0.61673261  66.05730274
  30.19434164 -25.22015511  22.54228295  26.46136137 128.52752786
  12.77164631   4.36104963  -0.82669085  39.40575103   3.53616532
   0.43254205  -2.35669771   4.97448795 -21.15653374  22.16092046
  24.55279716  -3.71904271   1.5450754   34.94212297  -2.78143018
  52.65278132   4.28628703  -2.25686893  -3.08265152  -3.2830885
   6.57351002   1.17056255   2.89630091  -3.10552064  30.32026723]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.3051501262082
gradient value of function right now is: [ 1.85056116e-01 -1.79419363e-02  8.89801067e-03 -1.26817531e-02
 -1.85056116e-01  1.79419363e-02 -8.89801067e-03  1.26817531e-02
  1.13481839e-01  7.19159109e-02  1.31210940e-01  1.01025182e-01
 -3.37884954e-04  4.61488025e-01 -1.22969953e+00 -4.02140298e-03
 -5.65552098e-03  9.77040532e-04  1.97864385e-03 -7.21395590e-07
 -2.26018484e-09  2.24294915e-02 -3.39365057e-03  1.00417390e-04
  2.42777175e-08  2.60493503e-03  4.89562371e-03  8.29652860e-15
 -1.08302819e+00 -1.99025895e+00 -5.17146346e-02 -7.02214449e-01
  3.11216765e-02  7.44139562e-01 -7.98699113e-04  4.38321944e-03
  6.02259979e-03  6.27260105e-03  4.62565939e-03  1.09806567e-04
 -2.06382205e-01 -6.44682674e-01 -1.88520890e+00 -9.25948945e-02
  1.46408458e-01 -2.04669664e+00  2.19863759e+00 -1.20848801e-01
 -7.36579279e-03  2.10740368e-02  1.31978212e-02 -3.63861300e-03
 -2.21709953e-01 -1.90827914e-01 -2.04170518e+00 -8.63432483e-02
  6.69654306e-01 -2.02628739e+00  2.07723092e+00 -7.83694069e+00
 -3.70290773e-01  1.89626706e+00  1.96375035e+00 -7.41798478e+00
 -3.61540541e+00]
supnorm grad right now is: 7.836940685733893
Weights right now are: 
[ -0.65926805   3.37194137  -4.14826222   3.71965075   0.91383676
  -3.48063306   4.54719949  -4.43567914  -7.54646364  14.05191932
   9.26044601 -15.36866132  34.97540903   6.78178794   2.99776807
  -4.68683094  -2.86220198  75.52451228  38.86565022   8.45220883
  20.80962404  35.28098434  41.52563546 -17.84244641  73.35907643
  52.44493129  -2.92367422  35.44073293  -7.20004935   7.10045123
   8.15690229  -7.57615967  23.40906615   0.63381371  66.95748053
  28.89736117 -24.48844767  22.03298389  27.72734646 133.15518002
  13.04792585   4.04690664  -1.02493949  40.00243477   3.38229262
   0.57783513  -2.13405186   5.04608153 -21.2242483   22.80375814
  25.3902933   -3.64517171   1.5821078   35.26286696  -3.15790493
  52.43506148   4.3041979   -2.09459757  -3.08121729  -3.38861962
   6.65252795   1.15087253   3.09532988  -3.19537394  30.66451258]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1593.7511230629102
gradient value of function right now is: [-5.58886095e-01 -3.37496107e+00 -7.60632163e-03 -1.43668488e-01
  5.58886095e-01  3.37496107e+00  7.60632163e-03  1.43668488e-01
  4.97539004e-01  3.06684721e-01  4.44180487e-01  5.23973034e-01
  7.80172675e-04  2.16488813e+00  3.49892013e+00  2.95886526e-02
 -3.44353710e-03 -5.03748090e-03 -1.35131729e-03 -3.11586735e-06
  1.90295405e-10  9.64646744e-02  7.67774124e-03  1.17517976e-04
 -2.98751512e-08  2.34336312e-03 -2.35661815e-03 -1.53079628e-13
 -2.09031052e+00 -6.02929796e+00 -5.59085044e-02 -1.02725683e+00
 -7.48529974e-02 -2.36821669e+00 -1.77733914e-03 -4.60403007e-03
  2.80939557e-03  3.70491839e-02  1.79282848e-05  4.97517105e-05
 -3.52982513e-01 -4.16309242e-01 -3.31465486e+00 -1.04636193e-01
  8.90114032e-01  3.74512657e+00  5.63840141e+00  4.40492662e-01
  2.46880378e-02  7.84253570e-02  2.48719639e-02  4.34462983e-02
 -3.62267699e-01 -2.87626854e-01 -2.94112476e+00 -1.17786630e-01
  2.50860932e-01 -1.73529830e+00  2.03582596e+00 -1.18955903e+01
 -9.84566732e-02  1.54761911e+00  4.03073770e-01 -9.76494833e+00
  7.35985778e+00]
supnorm grad right now is: 11.895590260614904
Weights right now are: 
[ -1.2227712    3.35120662  -4.89614926   4.11789976   1.47733991
  -3.45989831   5.29508653  -4.83392814  -7.51924348  14.37350698
  10.39180214 -14.65354399  37.91684905   6.77120961   3.34718637
  -5.10236848  -1.93149648  77.5775165   41.05637348   9.57608905
  20.81003516  34.50548041  39.15605924 -17.67713205  73.37906876
  52.54392615  -6.00150139  35.44073301  -7.37335103   7.27835431
   8.50487555  -7.5247748   24.47332425   0.29103141  69.26930608
  33.37095219 -20.51177996  22.04162089  25.78300059 141.29023709
  12.45717776   4.48412517  -1.45398241  40.15869982   3.88010076
   0.62128529  -2.11559807   4.42393611 -21.21692     23.39205689
  25.87468042  -3.50815479   1.666163    36.4155351   -3.02800285
  52.85031977   4.84179306  -1.94830218  -3.11026508  -3.28023935
   6.63975016   1.06280534   2.811172    -3.28318429  30.57563808]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.5257694535258
gradient value of function right now is: [ 9.56226654e-01  3.60027722e-01  1.91770644e-02  1.77188329e-02
 -9.56226654e-01 -3.60027722e-01 -1.91770644e-02 -1.77188329e-02
  6.96835987e-01  7.12030739e-01  7.91193342e-01  7.21696050e-01
 -1.34488237e-03  1.03752071e-01 -1.08685212e+00 -2.19680577e-02
  7.02734098e-05  3.88134629e-03  3.61729687e-03  5.68336739e-06
 -1.88063998e-10  2.06712950e-02 -1.11161480e-02  4.29135214e-05
  3.21924921e-08  1.29441765e-02  3.73445335e-03 -1.51277439e-14
 -4.75125698e-01 -1.30136858e+00 -1.08992716e-02 -8.15168199e-01
  6.13763154e-02  7.40637646e-01 -2.79148264e-03  5.06101691e-03
  1.71916434e-04  8.38137651e-03  5.59424695e-03 -9.08282616e-06
 -3.22964859e-01 -4.51130541e-01 -1.84609179e+00 -7.27677774e-02
  1.42558488e-01 -2.42413055e+00  2.63838920e+00 -6.80944790e-01
  8.94441773e-02  1.24177385e-01  4.34966331e-03  1.30082347e-01
 -4.80110407e-01 -1.98881988e-01 -2.82748260e+00 -8.23963293e-02
  9.58450097e-01 -1.62417367e+00  1.41982312e+00 -9.10295814e+00
 -3.25389565e-01  1.83047693e+00  1.59730210e+00 -6.80199860e+00
 -1.71941963e+01]
supnorm grad right now is: 17.194196323094115
Weights right now are: 
[ -1.0409649    3.33028852  -4.65922729   4.15922973   1.29553361
  -3.43898021   5.05816456  -4.87525812  -7.73473619  14.1959419
  10.1506373  -14.84957495  38.06622494   7.12715934   3.39501821
  -4.00419307  -2.27273746  77.82636627  41.15957527  10.80879071
  20.81008257  33.86039699  38.69115146 -23.26074088  73.41517255
  51.97994285  -5.33637584  35.44073313  -6.67318142   7.78214173
   8.53995495  -8.05168849  24.61191833   0.6135999   71.12178449
  29.35720886 -22.8264571   21.17018096  26.35624318 143.23649758
  12.47049669   4.32930239  -1.14154478  40.4498301    3.65554143
   0.69227052  -2.06165546   4.60875215 -22.00090016  23.09615837
  25.29377576  -3.9985779    1.54058937  37.31144179  -2.93864479
  53.27663997   5.01260159  -1.57804286  -3.20323804  -3.11768205
   7.26282279   1.12422014   2.81594319  -3.44394693  30.21674185]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.9756719414036
gradient value of function right now is: [-2.24804315e-02 -1.45182844e+00 -4.13656679e-02 -2.99732698e-02
  2.24804315e-02  1.45182844e+00  4.13656679e-02  2.99732698e-02
  8.61151186e-03  1.16314116e-01 -1.82453631e-01  1.14272587e-02
  8.66832224e-04 -1.65323968e-01  3.93002942e+00  1.85102255e-02
  2.78477091e-03 -9.49027164e-03 -9.61830536e-03  6.01989586e-06
 -1.35679627e-10 -4.56863463e-02  1.82695708e-02 -6.90920857e-04
 -1.14839255e-09 -2.22693044e-03  1.31804496e-03 -7.84976393e-15
  1.31676511e+00  1.63267013e+00  6.85075449e-02  5.61506977e-01
 -9.33525606e-02 -2.98655659e+00 -4.16019580e-04 -4.83482771e-03
 -3.85284597e-03  6.43336815e-03  3.76541269e-05 -4.21008245e-05
  3.12536583e-01  1.38285323e+00  1.60953432e+00  1.42251153e-01
 -2.35037126e-02  4.30278265e+00 -1.60228288e+00  4.64424748e-01
  4.49429391e-02  9.38921853e-03 -1.31105968e-02  4.81836262e-02
  2.40703533e-01  1.85704423e-01  1.42237974e+00  7.02300635e-02
 -1.01017220e+00  2.97834887e+00 -2.90846327e+00  9.07942891e+00
  5.44215450e-01 -2.01753544e+00 -3.47654448e+00  8.23350837e+00
  1.96761647e+01]
supnorm grad right now is: 19.676164688147097
Weights right now are: 
[ -1.11923143   3.41680698  -6.14748669   3.93423884   1.37380014
  -3.52549867   6.54642396  -4.65026722  -8.25659987  13.92961032
  10.17323157 -15.18554515  40.3640825    7.37301357   3.35627422
  -3.30201949  -3.43929196  79.21834748  40.6068103   11.15166436
  20.81017972  34.27965293  38.65141353 -24.2039778   73.45887198
  52.49065332  -5.21643385  35.44073324  -7.0034867    7.54908891
   7.90278194  -7.953491    24.37713846   0.89306152  71.0053271
  31.82472415 -22.21846133  21.20028234  28.17674453 146.45315272
  12.24810252   4.48642802  -1.29196155  41.20662855   3.06944763
   0.26293595  -2.25308532   4.48880848 -21.90138966  24.33716024
  27.03265657  -3.55122372   0.89997775  36.55297607  -3.15454917
  53.16450305   5.02658271  -1.84030914  -3.24632051  -3.40646048
   7.24377101   0.73414134   2.9763165   -3.35279065  30.72191616]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1596.9402563411697
gradient value of function right now is: [-6.51026194e-01 -1.94302469e+00 -1.39069105e-02 -4.12490544e-02
  6.51026194e-01  1.94302469e+00  1.39069105e-02  4.12490544e-02
 -2.95347072e-01 -3.32876739e-01 -4.65864570e-01 -3.33716786e-01
  3.96094036e-03  7.26441806e-01  4.62828541e+00  1.58332530e-01
  1.49380715e-03 -2.94687441e-03 -3.47895610e-03 -2.07010484e-05
 -3.39302431e-10  1.26241772e-02  1.37948209e-02  1.85961036e-03
 -1.91253288e-06 -2.20108615e-02  1.72071800e-03 -5.54728615e-13
  1.00237102e+00 -1.35854189e-01  3.75113387e-01  1.09828648e+00
 -1.02870296e-01 -2.52983075e+00 -1.48304402e-03 -4.88318309e-03
  1.32830349e-02  9.72252594e-02  1.15663511e-03  1.00899115e-04
  2.54990979e-01  4.54544877e-01  1.49409712e+00  1.20542892e-01
  4.93292606e-01  8.50788110e+00 -1.23630316e+00  1.37630499e+00
  4.63536527e-02  2.75885629e-03 -2.09984813e-02  4.24147651e-02
  2.75656611e-01  1.91332730e-01  1.80486237e+00  9.90983207e-02
 -1.43361517e+00  2.66918075e+00 -2.59825046e+00  8.43329876e+00
  1.29989849e+00 -4.97935591e+00 -4.53748213e+00  1.04823040e+01
  1.43909080e+01]
supnorm grad right now is: 14.39090796132841
Weights right now are: 
[ -1.13945792   3.34472768  -5.96315718   4.24794382   1.39402663
  -3.45341937   6.36209445  -4.9639722   -8.34573961  13.81986051
  10.34728073 -15.18480967  42.87105709   7.225381     3.34237796
  -4.11811458  -5.45873888  79.64691534  41.32072581  12.12373534
  20.80949915  34.47760197  37.33100894 -23.47464561  73.48610795
  51.81793036  -5.21930018  35.44073332  -6.66705818   7.695455
   9.02858912  -8.00730684  23.1447517    0.82707295  73.7697136
  34.57071411 -20.67213876  20.25176008  25.10622445 148.83782251
  12.03276271   3.98383571  -1.26824377  41.66354878   3.46135724
   0.9563154   -2.32230621   4.80563278 -22.31322792  24.43689202
  28.95974964  -3.75806162   1.28119238  37.70465514  -2.90352071
  53.64800224   4.52102502  -1.96225404  -3.01902132  -3.31056872
   7.3170318    0.443707     2.68028276  -3.03182528  30.3211664 ]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.471312552662
gradient value of function right now is: [ 1.64742507e-01  6.79953848e-01  1.06148188e-02 -2.12848734e-02
 -1.64742507e-01 -6.79953848e-01 -1.06148188e-02  2.12848734e-02
  2.93667004e-01  2.52990516e-01  3.81851952e-01  3.07620534e-01
 -8.98026063e-04 -3.00526541e-02 -2.53860546e+00 -4.68426032e-02
 -1.21192980e-03  1.31290158e-03  2.61180930e-03 -7.39776730e-06
  2.72839659e-11  3.35465550e-02 -6.24530397e-03  1.50677191e-04
  5.67731012e-08  7.07048287e-03 -2.45678674e-04 -1.03487295e-14
 -8.20254806e-01 -1.09206926e+00 -1.46452817e-02 -6.26736202e-01
  4.85722589e-02  1.40792272e+00 -8.77427548e-04  2.10255080e-03
  6.67428437e-04 -3.20723361e-02  7.98312325e-04  1.64013172e-05
 -3.03280717e-01 -6.09841655e-01 -1.99736765e+00 -1.02913433e-01
  2.32380901e-01 -4.10314265e+00  2.50207934e+00 -4.72383923e-01
  9.55350115e-03  3.09241205e-02  2.34874186e-03  2.54909374e-02
 -3.42519290e-01 -1.74028130e-01 -2.21073063e+00 -8.69590996e-02
  8.39120779e-01 -1.77384214e+00  1.78783675e+00 -7.71422849e+00
 -4.63275479e-01  2.13306725e+00  2.71536661e+00 -7.80656041e+00
 -9.84062308e+00]
supnorm grad right now is: 9.840623084442129
Weights right now are: 
[ -1.20531512   3.41256582  -5.72987921   4.3099399    1.45988383
  -3.52125751   6.12881648  -5.02596828  -7.92755317  13.91537323
  10.73639094 -14.87456919  42.35851286   6.86575261   3.01865203
  -5.04358637  -8.24279264  80.72172244  39.82795663  11.57797511
  20.80959458  35.32745191  36.21999247 -19.94424936  73.5389059
  51.78224537  -7.59127456  35.4407336   -7.02951131   7.66376352
   9.3527914   -8.30048254  22.41842757   0.82336882  73.11570842
  37.57142909 -18.52602707  19.10401195  25.87468655 150.57640698
  11.72816572   4.07228542  -1.65773553  42.05717358   3.68913637
   0.54424528  -2.03818908   5.13937634 -23.27495739  24.46545687
  30.20614044  -4.11386616   1.17324385  37.97848101  -2.99266937
  53.64366957   5.64477354  -1.60436642  -3.2094911   -3.43432267
   7.01378267   1.23943232   3.18903797  -3.30376149  30.62453042]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.6275986454798
gradient value of function right now is: [-3.91814322e-02  3.37041059e-01 -2.99234718e-02 -1.39024871e-01
  3.91814322e-02 -3.37041059e-01  2.99234718e-02  1.39024871e-01
  2.95102671e-01  2.86091661e-01  3.37150581e-01  3.06944618e-01
 -7.66062672e-04 -4.15196743e-01 -1.90507699e+00 -2.48931554e-02
  5.45687799e-04 -7.77331988e-03 -2.75699850e-03 -2.66737695e-05
 -3.12933987e-10  4.72764748e-02  9.70117157e-03  1.00096107e-03
  1.13739969e-08  7.14017063e-03  2.00105710e-03  2.77685238e-14
 -6.74283062e-02  4.46997692e-01  3.85629624e-02  2.23165461e-01
 -6.93996866e-03  9.26239887e-01 -1.27518939e-03 -1.88040782e-03
  4.76307759e-03 -4.78330942e-03  2.35500511e-03  3.22763938e-05
  2.55404874e-02 -3.19946922e-01  2.31874378e-01 -1.19834304e-02
 -4.02198951e-01 -2.61044673e+00 -5.77469816e-01 -6.56208906e-01
  6.41401579e-02  6.83001047e-02  6.05074021e-04  7.65272099e-02
  9.80239901e-02  3.45611979e-02  5.46860366e-01  1.90888958e-02
  4.21330163e-01  8.45442120e-01  3.31401472e-01  7.62533040e-01
  1.41695596e-01 -1.10631762e+00  1.13082308e+00  9.54368000e-01
 -8.76346721e+00]
supnorm grad right now is: 8.763467214718112
Weights right now are: 
[ -1.26518954   3.32932529  -4.62250163   3.70639088   1.51975825
  -3.43801698   5.0214389   -4.42241926  -8.1268876   13.63975573
  10.9644184  -15.07094695  40.42519191   7.04336625   3.01476967
  -4.5223439   -6.07885438  81.08281394  37.95263077  13.56314831
  20.80954352  35.91326766  34.91409798 -20.79665604  73.51717441
  52.50855124  -3.98115659  35.44073391  -6.74206952   7.8890196
   9.27409417  -7.6821495   22.70040689   0.76543046  78.95629641
  33.96476436 -18.56806443  19.59981894  23.61885736 150.0790957
  11.48138571   4.04139753  -1.34423165  42.18409624   3.30085099
   0.47466945  -2.22617621   4.6028765  -22.49459536  25.54276221
  30.54588416  -3.43677367   1.77628837  39.23428835  -3.01447151
  54.04999815   5.38629753  -1.56082627  -3.13071607  -3.4023963
   7.49153202   0.84223243   3.2404138   -3.30159773  30.59079723]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.0987339446654
gradient value of function right now is: [ 8.42885855e-01 -1.12928935e+00 -3.66677797e-02  8.87269927e-02
 -8.42885855e-01  1.12928935e+00  3.66677797e-02 -8.87269927e-02
  3.80902189e-01  5.82027308e-01  3.08608021e-01  4.18149370e-01
  6.86711801e-04  1.02566475e-01  5.21958859e+00  4.75390727e-02
  1.36395835e-04  1.12355030e-03 -6.20189565e-03  3.19167401e-06
 -2.94913863e-10 -8.11820444e-02  1.07224226e-02 -3.66138271e-04
 -4.98193333e-08  6.84936340e-03  1.07679184e-03 -2.14330387e-16
  1.46568448e+00  1.71566561e+00  2.51365660e-02  9.89542330e-01
 -9.48366176e-02 -3.34074940e+00 -8.63843271e-04 -1.39040674e-03
 -3.26578418e-03  5.41538360e-02  1.26154585e-03 -6.94076467e-05
  3.57207431e-01  1.56603020e+00  2.20562215e+00  1.69725521e-01
 -7.93510110e-01  8.45067511e+00 -3.26021292e+00 -3.70027023e-02
  4.58726800e-02  4.17421680e-02 -1.01592157e-02  6.10616154e-02
  4.20334574e-01  2.23568380e-01  2.54834555e+00  1.20991880e-01
 -7.37857934e-01  3.92697078e+00 -3.65930361e+00  1.10655967e+01
  5.50517153e-01 -2.50510296e+00 -5.50555037e+00  1.24270928e+01
  1.49915175e+01]
supnorm grad right now is: 14.991517454330003
Weights right now are: 
[ -1.26007142   3.54526514  -4.74587444   3.82692666   1.51464013
  -3.65395683   5.14481171  -4.54295504  -8.49512026  13.81771686
  11.10718859 -15.17917958  42.14281106   6.96675247   3.4239689
  -4.01988311  -9.61767968  82.325299    36.05923411  11.38331219
  20.80969141  34.7614863   34.58824947 -24.24793499  73.57765511
  52.93370939  -4.00229777  35.44073586  -6.89749303   7.78786945
   9.14232154  -7.80574352  23.52065084   0.76953818  81.99947188
  32.05767206 -20.09042963  20.27700018  19.9168196  152.66362571
  11.5662794    3.96314276  -1.31044747  42.74314864   2.31990293
   0.60070514  -2.38197591   4.21371561 -23.47504053  25.59237777
  31.5220629   -4.1100642    0.79439931  38.57125349  -3.30935051
  53.88494946   5.41987813  -1.62809841  -3.55410192  -3.57428725
   6.47302041   0.86506562   2.89450581  -3.13280222  30.54368307]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.4620388292326
gradient value of function right now is: [-1.91251897e-02 -4.64200691e-01  2.42392083e-02  1.08150644e-01
  1.91251897e-02  4.64200691e-01 -2.42392083e-02 -1.08150644e-01
 -1.48972948e-01 -1.17673133e-01 -1.98960895e-01 -1.63350769e-01
  3.24742698e-03  3.28992700e-01  2.44098856e+00  8.76806037e-02
 -2.24642203e-03  5.06216241e-03  3.19786241e-03 -3.18193319e-05
  4.01696452e-09 -3.95268523e-02 -4.80190648e-03  5.33035349e-04
 -5.54123268e-07 -1.48955309e-02 -2.48396717e-03 -1.85960695e-14
  6.51927200e-01  3.75894644e-01  1.45258944e-02  3.16383575e-01
 -3.24336675e-02 -1.08679025e+00  5.98692336e-04  4.35154880e-03
 -1.69597324e-03  5.95068191e-02 -1.99770204e-03 -1.28517915e-04
  1.07934199e-01  5.68214126e-01  1.02420859e+00  6.34802225e-02
  1.80491097e-01  4.95093292e+00 -1.30229128e+00  6.57006350e-01
 -7.02280742e-02 -8.97747145e-02 -7.51592271e-03 -8.04763839e-02
  9.45042874e-02  9.45484348e-02  8.75181362e-01  3.93195346e-02
 -6.57177457e-01  4.88308237e-01 -1.63690974e+00  4.60611183e+00
  2.84399535e-01 -5.40147085e-01 -2.66380807e+00  4.15581655e+00
  1.45271117e+01]
supnorm grad right now is: 14.527111687175585
Weights right now are: 
[ -1.14207531   3.4466019   -4.30339216   4.33152379   1.39664402
  -3.55529359   4.70232943  -5.04755217  -8.58291352  13.79213891
  11.36294489 -15.11018002  42.97849023   7.14350249   3.0946558
  -4.85854915  -6.38579139  83.71939698  36.99030053  11.85021256
  20.81592591  34.02198777  33.49317901 -22.85480709  73.64069903
  52.01240748  -3.47325603  35.44073618  -7.21463411   8.01707082
   8.50754469  -7.92198154  22.58786025   0.82873106  88.41333106
  29.76742609 -19.68965813  19.40190416  15.98659446 152.38721202
  12.30819686   3.76633378  -1.25305908  43.27406819   3.46476474
   0.79661292  -2.02472325   5.3517424  -23.20469245  25.97880297
  29.75017062  -3.97604803   1.5547521   39.35537131  -3.21299912
  54.39814937   5.16934542  -2.08973495  -3.38272351  -3.47389711
   7.10065431   1.04084363   3.09041167  -3.20978703  30.63033498]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1600.2883795841526
gradient value of function right now is: [-5.62169351e-02  2.77286348e-01  1.08498463e-02  1.27546370e-02
  5.62169351e-02 -2.77286348e-01 -1.08498463e-02 -1.27546370e-02
  1.27467066e-02  1.59371795e-02  3.46488194e-02  1.49262301e-02
  1.29877575e-04 -1.02195407e-01 -4.80889907e-01 -1.02786224e-02
 -2.74051476e-03  1.13103503e-03  2.72612687e-03 -4.45379936e-05
  1.66624684e-09  4.15840861e-03 -4.90711646e-03  2.33507787e-04
  4.42293549e-08  2.62525118e-04 -2.31061141e-03  6.66076164e-14
 -9.68532467e-02 -3.76022104e-02 -4.41104063e-03 -5.46728204e-02
  1.32306151e-02  2.79260949e-01  4.01792098e-04  2.05590948e-03
  1.69803856e-03 -5.84828610e-03 -1.11135444e-03  4.96485146e-06
 -2.38230972e-02 -9.55940811e-02 -1.82150816e-01 -1.40479954e-02
  1.15936597e-02 -6.97954253e-01  1.26666691e-01 -4.29206753e-02
 -7.08234926e-02 -8.00985353e-02 -3.60068260e-03 -7.82103829e-02
 -1.18549467e-02 -1.44539909e-02 -1.15635933e-01 -6.01582214e-03
  6.77736890e-02 -5.54242852e-01  2.82413335e-01 -8.38070932e-01
 -1.92371300e-02  3.60260521e-01  4.67901591e-01 -8.30529869e-01
 -2.58019085e+00]
supnorm grad right now is: 2.580190850727397
Weights right now are: 
[ -0.87752717   3.17366729  -4.53104558   3.46375449   1.13209588
  -3.28235898   4.92998285  -4.17978287  -8.83079941  13.7521198
  11.37887245 -15.32279114  41.72556531   6.96824808   2.95754736
  -4.27690038  -7.79810019  85.27962948  34.45888969   9.56109839
  20.81553425  35.93042669  33.5660965  -22.57844962  73.76479205
  51.92154861  -4.06047537  35.44073645  -7.40781049   7.90183442
   7.47670054  -8.12196605  21.72803046   0.80373845  91.18025567
  27.92103431 -20.43278491  19.06650047  14.76424497 150.93173487
  12.20199719   3.8566759   -1.30302749  43.53837693   2.7159021
   0.72704053  -1.99158947   4.76072546 -23.81582053  26.1207985
  30.06290603  -4.34722239   2.11910048  39.98842472  -2.78766394
  54.82887248   5.0368467   -2.11732247  -3.40390984  -3.46342142
   6.83400719   1.34998573   2.87845807  -3.35570894  30.65185432]
(65,)
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1600.310135199866
gradient value of function right now is: [-6.79840436e-02  2.29007854e-01  1.10855158e-02  1.14140238e-02
  6.79840436e-02 -2.29007854e-01 -1.10855158e-02 -1.14140238e-02
  9.13828079e-03  1.25802470e-02  3.30333059e-02  1.35129147e-02
 -8.79045192e-05 -7.13058178e-02 -4.50281450e-01 -9.19132156e-03
 -2.14491955e-03  1.27972632e-03  2.40334599e-03 -3.00883650e-05
  1.10308008e-09  5.35940729e-03 -4.35214080e-03  2.84202738e-04
  2.63695758e-08  1.40017342e-03 -1.84713315e-03  4.55357882e-14
 -1.31590157e-01 -1.18517860e-01 -6.19755615e-03 -6.64824682e-02
  1.26432281e-02  2.62830912e-01  4.29089878e-04  1.96153196e-03
  2.56660076e-03 -2.08050806e-03 -9.38015140e-04  1.62301222e-05
 -2.65921014e-02 -1.02785269e-01 -1.99133490e-01 -1.51201722e-02
 -1.62722176e-02 -6.68663690e-01  1.47259800e-01 -8.57711295e-02
 -6.15514935e-02 -7.12660659e-02 -4.67390404e-03 -6.92592231e-02
 -1.56665335e-02 -1.74340826e-02 -1.38553883e-01 -7.40049972e-03
  8.41399253e-02 -5.54595578e-01  3.30804141e-01 -1.00069588e+00
 -1.19788920e-02  3.56735328e-01  4.85067219e-01 -9.61522397e-01
 -2.81090046e+00]
supnorm grad right now is: 2.8109004598549125
Weights right now are: 
[ -0.95374037   3.34629016  -5.59119439   4.22922556   1.20830908
  -3.45498185   5.99013165  -4.94525394  -8.88766054  13.6029959
  11.40853063 -15.44045045  35.48416731   7.15299329   3.15417426
  -5.64406359  -7.6175649   86.43602596  34.23191361   8.92120878
  20.8156883   34.89988776  33.65437395 -22.034659    73.83380361
  55.18049     -3.73293011  35.44073651  -7.08226365   8.44743333
   6.51048917  -8.04833504  21.24361515   0.7404302   93.93550936
  32.13917601 -18.23361696  20.21842386  14.75934676 152.16074016
  12.00626518   3.91462946  -1.15173792  44.09955439   2.78945688
   0.52007854  -2.00600859   4.98698068 -23.23022534  27.19774984
  28.22455679  -3.63199621   0.82552836  39.72066594  -3.42946206
  54.12053034   4.68317262  -1.63659228  -3.39311265  -3.71058882
   6.60530638   0.25011361   2.80102848  -3.26441868  30.45693511]
(65,)
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1600.2660479195745
gradient value of function right now is: [-9.76295140e-02  2.08301857e-01  1.28487372e-02  1.35923812e-02
  9.76295140e-02 -2.08301857e-01 -1.28487372e-02 -1.35923812e-02
  7.16791493e-03  7.99820807e-03  3.24375570e-02  1.19536227e-02
 -1.76511116e-04 -4.00588978e-02 -4.42211060e-01 -8.49296240e-03
 -2.40651102e-03  1.42913542e-03  2.57428381e-03 -2.95508463e-05
  1.36847285e-09  5.82476246e-03 -4.61696588e-03  3.15406867e-04
  2.33864541e-08  1.69061792e-03 -2.00800546e-03  3.14536877e-14
 -1.78179915e-01 -2.01850772e-01 -1.10267962e-02 -8.65985275e-02
  1.41893085e-02  2.63797979e-01  4.28875374e-04  1.95981919e-03
  3.14214533e-03 -4.80630617e-04 -9.23213039e-04  2.18484544e-05
 -2.97153984e-02 -1.27008735e-01 -2.47245211e-01 -1.81966662e-02
 -9.92350380e-03 -6.61389854e-01  2.11486317e-01 -8.83121162e-02
 -6.27871234e-02 -7.23199326e-02 -3.20543883e-03 -7.21744344e-02
 -1.96152170e-02 -2.14655353e-02 -1.88196102e-01 -9.46823968e-03
  5.88383432e-02 -6.74939232e-01  3.79277600e-01 -1.17525108e+00
 -2.85580378e-02  3.59809067e-01  5.32259275e-01 -1.18708543e+00
 -2.91429718e+00]
supnorm grad right now is: 2.914297183301681
Weights right now are: 
[ -0.32450457   2.93000115  -3.92315823   3.09153122   0.57907328
  -3.03869284   4.3220955   -3.80755961  -9.30173978  13.23566465
  11.2905778  -15.76287527  41.17506488   6.79020151   2.90551799
  -3.67835874  -7.80367567  86.42361712  33.46263853   6.10150111
  20.81295215  36.21008192  35.65854048 -24.22276958  74.01194502
  51.35540062  -4.00306608  35.44073666  -7.01893998   8.63590727
   7.43143269  -7.37993074  20.88687649   0.84989933 100.17555563
  30.56554088 -19.4155057   19.33758363  14.96422227 156.02622675
  11.99052808   3.95427267  -0.86580432  44.19274359   3.18560755
   0.86524136  -1.75708186   5.63153209 -25.08593183  25.66727202
  27.96160129  -5.50443229   1.02995898  40.78884023  -2.97522167
  54.31339352   5.2008196   -2.58360047  -3.26921991  -3.4893196
   8.27077782   1.28520632   3.0150438   -3.0880424   30.36542964]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1600.2665151322844
gradient value of function right now is: [-1.08941512e-01  2.12648761e-01  1.38273134e-02  1.25566166e-02
  1.08941512e-01 -2.12648761e-01 -1.38273134e-02 -1.25566166e-02
  9.88815631e-03  1.09200252e-02  3.45871437e-02  1.45285366e-02
 -8.99750758e-05 -4.33838393e-02 -4.54717305e-01 -7.73760372e-03
 -2.17857948e-03  1.30700629e-03  2.48337453e-03 -3.79902975e-05
  1.91389542e-09  6.31958027e-03 -4.38873655e-03  3.07191461e-04
  2.53081566e-08  1.40679583e-03 -1.92917244e-03  3.62930806e-14
 -1.68726162e-01 -2.03032294e-01 -9.33493452e-03 -9.82734131e-02
  1.33607858e-02  2.69216045e-01  4.43492999e-04  2.04344878e-03
  2.83553779e-03 -7.56849340e-04 -8.78030794e-04  1.85039811e-05
 -3.23392119e-02 -1.11406475e-01 -2.80269079e-01 -1.91529599e-02
 -4.46374248e-03 -6.66054973e-01  2.59885076e-01 -8.65431466e-02
 -6.39929980e-02 -7.49696954e-02 -3.96428664e-03 -7.38939882e-02
 -2.45375787e-02 -2.25717200e-02 -2.36166530e-01 -1.15094862e-02
  5.59651126e-02 -6.97405164e-01  3.56652776e-01 -1.21415177e+00
 -3.06023394e-02  4.08505904e-01  5.27850392e-01 -1.35091442e+00
 -3.00790947e+00]
supnorm grad right now is: 3.007909467967049
Weights right now are: 
[ -1.52368383   3.26043092  -4.06403465   3.94718951   1.77825254
  -3.36912261   4.46297192  -4.66321789  -9.09898538  13.24217183
  12.02800654 -15.5608249   36.79230375   7.40817423   3.20004777
  -5.22385006  -5.35555268  89.37358584  33.69860541   6.11742616
  20.83021143  35.20073286  31.7578899  -22.78740492  74.21697785
  53.66541508  -1.8403482   35.44073786  -7.61504722   8.50076534
   6.97893022  -7.23872455  22.46579213   1.04592183 108.65139701
  30.23014655 -18.68587645  19.69836264   8.26786081 156.28208513
  11.03899194   4.00561112  -1.22522688  44.58450522   2.517556
   0.57066259  -1.8841953    6.01052966 -23.86610096  27.20104147
  28.39317688  -4.32368287   0.82113577  41.66236443  -3.0853318
  54.90028079   6.04510008  -1.3907337   -3.19949911  -3.5876368
   7.88927801   1.12033338   3.08001719  -3.30079353  30.59038136]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1600.3294912012589
gradient value of function right now is: [-7.60374049e-02  1.93585564e-01  1.34091674e-02  1.14461162e-02
  7.60374049e-02 -1.93585564e-01 -1.34091674e-02 -1.14461162e-02
  5.12695802e-03  5.72207949e-03  2.78738899e-02  9.20873070e-03
 -1.19748788e-04 -3.99772868e-02 -4.17883931e-01 -6.78649131e-03
 -8.32071929e-04  1.32737565e-03  2.33482264e-03 -2.05253597e-05
  1.50703652e-09  6.31935250e-03 -4.26479084e-03  3.07786502e-04
  1.86571211e-08  1.39115802e-03 -9.56904444e-04  2.89876822e-14
 -1.60653514e-01 -1.87262027e-01 -1.35759406e-02 -8.30353405e-02
  1.24263401e-02  2.50532397e-01  3.51397734e-04  1.94300293e-03
  2.87226666e-03 -8.77663324e-05 -6.91857157e-04  1.93364962e-05
 -2.95573573e-02 -1.08550215e-01 -2.40740713e-01 -1.73381675e-02
 -4.30145669e-03 -6.22204719e-01  2.13437710e-01 -8.28518486e-02
 -4.00261292e-02 -4.64069764e-02 -3.48715488e-03 -4.60543170e-02
 -2.06976248e-02 -1.96191149e-02 -1.88300181e-01 -9.49299023e-03
  8.55032318e-02 -4.94650756e-01  3.35808101e-01 -1.09370818e+00
 -2.75994163e-02  3.68646018e-01  4.99296492e-01 -1.16963958e+00
 -2.80736104e+00]
supnorm grad right now is: 2.8073610355967555
Weights right now are: 
[-1.13430216e+00  3.35662884e+00 -3.82636231e+00  3.57066291e+00
  1.38887087e+00 -3.46532053e+00  4.22529958e+00 -4.28669130e+00
 -9.01333824e+00  1.34806028e+01  1.23738551e+01 -1.54347543e+01
  3.47578408e+01  7.21093083e+00  3.54371522e+00 -5.81150399e+00
 -7.22324271e+00  9.00634264e+01  3.38999357e+01  5.17026407e+00
  2.08368629e+01  3.60099092e+01  3.25657939e+01 -2.53529887e+01
  7.42557299e+01  5.50143498e+01 -3.84884662e+00  3.54407379e+01
 -7.71144751e+00  8.18705834e+00  6.96384934e+00 -7.56429206e+00
  2.18111094e+01  1.01176641e+00  1.10413552e+02  3.14889581e+01
 -1.93016949e+01  1.96794510e+01  8.28111396e+00  1.62753269e+02
  9.65551841e+00  4.42767973e+00 -1.51716043e+00  4.47689594e+01
  2.04016839e+00  7.02009905e-01 -2.00110421e+00  5.98489288e+00
 -2.45160838e+01  2.74378497e+01  3.02046242e+01 -4.51113597e+00
  9.96745164e-02  4.13501805e+01 -3.13393602e+00  5.45300917e+01
  5.69983350e+00 -1.87300903e+00 -3.39591794e+00 -3.46955844e+00
  7.47206102e+00  8.92715853e-01  3.05829333e+00 -3.09138184e+00
  3.04499828e+01]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1180.9082026163483
W_T_median: 1080.093488726384
W_T_pctile_5: 932.441042615035
W_T_CVAR_5_pct: 891.8070799098795
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.6
F value: -1600.3294912012589
-----------------------------------------------
