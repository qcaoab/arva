Starting at: 
2022-06-17 22:26:16
tracing parameter entered from terminal:  1.2


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2392.7103012326133
gradient value of function right now is: [ 1.74561691e+00 -3.40058246e-01  3.05424071e-02  3.07055812e-02
 -1.74561691e+00  3.40058246e-01 -3.05424071e-02 -3.07055812e-02
  1.42583105e+00  2.73080853e-01  1.24891601e+00  5.28681364e-01
  1.04964455e+00 -4.68637906e-04 -1.27871680e-02 -1.71408061e-03
  6.59131736e-02  5.39945665e-02  8.47745207e-02  6.51295526e-02
  6.71543108e-02  5.57353713e-02  8.68026853e-02  6.70058379e-02
 -6.30407665e-02 -3.30118622e-02 -4.60338961e-01 -1.80632294e-02
  1.21323374e-02  3.78517028e-04  7.71034315e-02  2.80081475e-03
  2.30357902e-02  1.96962011e-02  7.04271450e-01  3.63961489e-02
  1.37596425e-02  2.71798673e-03  2.45228387e-01  1.10213378e-02
  2.00130977e-02  2.17286761e-01  2.14077306e-02  2.56609459e-01
 -3.84831991e-02 -4.11800213e-02 -2.10927833e-01 -4.12337312e-01
 -8.12615587e-02 -5.26631126e-01 -2.27892325e-01 -1.22000570e+00
 -1.51076898e-04  1.00880153e-03  4.23142591e-03  2.96568796e-02
  1.05562970e-01 -3.46674433e-01  1.01296347e+00 -1.42803137e+00
 -2.17832644e-01  5.16907115e-01 -1.79458051e-01  2.42646164e-02
 -5.52381341e+00]
supnorm grad right now is: 5.523813409963517
Weights right now are: 
[-1.27013834  1.77560038 -2.40703126 -3.03171245  1.52470705 -1.88429207
  2.80596853  2.31568407  3.23963251 -1.3317606  -3.18640053 -1.93163989
  1.99185937  2.16157978  8.48663482  5.23558449  8.47013352 -0.68766167
 -0.30648743 -0.65322968  8.5159918  -1.19959452 -0.37022397 -0.20391182
  3.99609936 -1.34432224 -3.47568241 -1.6753451  -1.59017996  7.88772931
  5.71844449  2.51690533 -3.7529606  10.73829974 -0.96178677 -2.23097497
 -2.27598555  9.17187417  2.82443461  1.16445513 -1.39364774 -1.38387571
  5.10675136  4.66132598  8.79574866 16.30314271 -4.06772136  2.25989677
  3.70950352  4.84024248 -0.35013233 -1.35009301  1.87669833  6.48777977
  3.80972704  1.43775702  5.52026584 -1.08356848 -1.98705169 -2.51460761
  7.054691    2.72255629 -0.33259799  7.75675644 26.25565201]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2408.793133972463
gradient value of function right now is: [ 2.10923265e+00  1.29400111e-01  2.75032168e-01  2.76994028e-01
 -2.10923265e+00 -1.29400111e-01 -2.75032168e-01 -2.76994028e-01
  5.11530934e-01  9.88513194e-02  2.85984229e-01  1.28790745e-01
  2.03856714e-01 -1.96204610e-03 -3.63108772e-01 -8.35977533e-03
  7.02364913e-02  1.24529939e-02  8.84176911e-02  1.41434885e-02
  7.35966092e-02  1.31451597e-02  9.30115987e-02  1.49179183e-02
 -1.29968490e-02 -6.34968157e-01 -3.60788823e+00 -1.54320428e-02
  4.53266538e-03  1.15291632e-05  2.29776193e-02  9.75038281e-03
  9.13507820e-04  3.41860607e-02  2.35614478e+00  1.08723751e-02
  2.75176821e-03  3.34059209e-04  5.70110001e-02  1.14170802e-02
  6.51405648e-03  5.50882939e-02  4.62885285e-03  4.41518300e-02
 -3.60823832e-01 -4.12557380e-01 -3.73063930e+00 -4.69667753e+00
 -1.08337806e-01 -2.33212501e-01 -1.97704909e-01 -5.75927886e-01
 -2.79719957e-03 -2.98500517e-03  1.23358036e-02  4.12821107e-02
  1.39903140e+00 -9.07754601e+00  2.80891119e+00 -1.55874893e+01
 -1.34884433e+00  6.95721580e+00 -9.36883304e-02 -1.04518761e-02
 -3.62621419e+00]
supnorm grad right now is: 15.587489281467935
Weights right now are: 
[-1.04647396  7.38598731 -1.81174503 -2.46008735  1.30104267 -7.494679
  2.2106823   1.74405896  4.20510951 -4.47710571 -2.03612712 -3.50408109
  6.72009063  0.02747341  8.38424148  3.52089352 15.69497825 -3.16728695
  2.10363354 -1.56658862 15.63849197 -3.58130181  2.03674377 -1.06077573
  4.43752776 -7.60003025  2.62919136 -0.20921863 -3.91781617 18.41668575
 10.35041043  2.60716001 -5.97030898 20.37521542  2.48413626 -5.9943121
 -3.57613312 19.58931087  7.29447612 -0.8246373  -5.98494123 -0.26970879
  2.55197313  7.03301559 16.60431066 23.17639357 -5.21010925  2.77900109
  5.63942485  6.53434914 -2.24209003 -2.12369235 12.82627267  3.61512347
 12.58962582 -0.03337765  2.74139179 -1.05709735 -1.55246228 -1.61084187
  6.62327254  1.95983939 -1.35731657  9.27209527 26.98835469]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2421.3664499812867
gradient value of function right now is: [-4.48927012e+00 -1.51108473e+00 -1.49643511e-01 -1.54566995e-01
  4.48927012e+00  1.51108473e+00  1.49643511e-01  1.54566995e-01
 -1.83218543e+00 -5.31142834e-02 -9.28982611e-01 -7.47251446e-02
  3.57522461e+00  1.69726570e-03  7.18211139e-01  3.43403544e-03
 -6.00569792e-02  1.10527786e-03 -2.44968672e-02  1.05626912e-03
 -6.37965821e-02  1.14345016e-03 -2.63803248e-02  1.09162265e-03
 -3.90646013e-03 -3.26141303e+00 -1.70590613e+01  4.01522291e-02
  6.21547860e-04  4.22187035e-07 -2.81851442e-02  1.38526509e-03
 -7.66194449e-04 -4.29400283e-02 -1.14890477e+00 -2.58998764e-02
  4.63091252e-04 -6.82031769e-06 -2.16430471e-02  2.09814447e-03
  1.66020498e-03  6.81540227e-03  4.61173671e-03  7.80942935e-03
 -7.60014530e-01 -4.52604197e-01 -1.24617103e+01 -1.73987162e+01
  5.42820519e-01  5.26344613e-01  3.25137403e+00  5.33694053e+00
  3.37764176e-03  2.50840289e-02  3.45998764e-03  2.49798785e-01
  2.09196244e+00 -2.44132943e+01  1.60471949e+00 -1.87712824e+01
 -3.04314993e+00  2.00633733e+01 -2.23676110e-03 -3.43346131e-03
 -8.84423802e-02]
supnorm grad right now is: 24.413294278970707
Weights right now are: 
[-2.45226244  8.56525998 -1.2160521  -1.81709219  2.70683115 -8.67395167
  1.61498937  1.10106381 -2.65673253 -5.41816895  4.51107094 -2.48562418
  6.1229552  -0.94120725  7.63796233  2.56798203 22.61382638 -6.82426567
  6.77403202 -4.55397124 22.43706111 -7.21619245  6.65299863 -4.02657635
  5.00965097 -7.11710157  2.94509879 -6.44730816 -5.16901653 18.81617233
 15.97522626 -1.79254395 -4.69467011 28.08185773  1.53141322  0.19321234
 -4.4895874  22.29356599 12.31660593 -5.530244   -4.48439101  1.54009436
  1.03321048  8.88211283 20.75346168 27.47033501 -3.71645231  2.37539944
  3.58131904  7.3221077  -2.79033943 -0.96769642 18.43160342  3.18465617
 11.93088759  0.83659136  1.71335531 -1.51165641 -0.78441256 -2.06765424
  5.84796015  1.33925526  3.4012876  13.67114862 27.2126763 ]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.1209225285975
gradient value of function right now is: [-2.79791464e-01  2.25943931e-02 -4.75127183e-02 -4.83839591e-02
  2.79791464e-01 -2.25943931e-02  4.75127183e-02  4.83839591e-02
 -1.15393868e+00 -7.12136736e-01 -3.10672305e+00 -9.57708141e-01
 -1.02101514e+00  6.16939133e-04  1.99864972e+00  5.01575100e-03
 -1.38568999e-02 -3.16951737e-03 -2.50517019e-02 -3.05360920e-03
 -1.35135563e-02 -2.98249517e-03 -2.46590802e-02 -2.87410063e-03
  9.10468259e-03  2.61071853e+00  5.65433478e+00 -1.34713465e-01
 -2.95207186e-03 -3.73035163e-06 -3.74923653e-02 -1.22257045e-02
  8.24778990e-03 -1.19678128e-01 -1.84479769e+00  6.02340309e-02
 -1.87515623e-03 -3.18545448e-04 -4.97956842e-02 -8.38310842e-03
 -1.70242933e-02 -5.41976639e-02 -4.62139872e-03 -8.43804919e-03
  3.79752440e-01  3.00973106e-01  1.08328979e+01  1.76041493e+01
  2.59113836e-01  6.44036327e-01 -5.67746393e-01  3.12021531e+00
 -3.98159619e-02 -1.74623510e-01 -7.26522432e-02 -1.04926930e+00
 -2.02544265e+00  1.73082004e+01 -4.90021996e+00  2.19555136e+01
  5.16693029e+00 -2.41430989e+01  7.40841658e-02 -5.28595404e-03
  9.80749871e+00]
supnorm grad right now is: 24.14309886487238
Weights right now are: 
[-2.61190364  8.43114455 -1.5288893  -2.02591128  2.86647235 -8.53983624
  1.92782657  1.30988289 -3.02445865 -1.71623986  5.41328442 -0.73854763
  5.94573359  6.03342996  6.42285373 11.2249828  31.45504128 -8.14357594
  8.91410856 -6.00589492 31.20963122 -8.4996916   8.90724079 -5.44052363
  3.83155227 -7.5579232   3.40023067 -6.37981597 -7.68707583 19.72200202
 19.32756131 -3.67826636  4.43480152 29.86198381  0.32130746  2.14141021
 -5.60080618 34.17385665 11.78073109 -7.39657196 -2.95106804  0.947707
  4.0920448  13.20199459 24.79537096 32.63439925 -3.261122    2.15035001
  5.50245954  8.77724592 -3.17663838 -0.62017695 17.84923095  0.43723934
 16.24952777  1.6151251   2.1326644  -1.71290765 -0.82903201 -2.21900149
  6.10863565  1.24734816  3.07238175 15.39790184 27.14081488]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2424.5810582266686
gradient value of function right now is: [-2.55203754e-01  1.18281972e-01 -1.63911585e-02 -1.59689607e-02
  2.55203754e-01 -1.18281972e-01  1.63911585e-02  1.59689607e-02
 -8.83514064e-01 -6.21228736e-01 -1.78213470e+00 -8.90979518e-01
 -3.97111875e-01  2.53648133e-05  9.39716924e-01  3.60993789e-03
 -4.22033870e-03 -8.86634893e-04 -1.74222279e-02 -6.98618429e-04
 -3.75618229e-03 -7.83134460e-04 -1.53598278e-02 -6.16935141e-04
  8.89688069e-04  2.08577088e-01  1.89064724e+00  1.41423371e-01
 -2.17989693e-03 -2.84108570e-08 -1.97206087e-02 -7.14955978e-03
  6.17093293e-03  1.47221833e-02 -7.91254135e-01  2.69107701e-02
 -9.44348851e-04  1.38454853e-04 -4.33956886e-02  1.64993373e-04
 -1.99042049e-02 -3.06606623e-02 -7.75361867e-03 -5.21145121e-03
  1.60553279e-01  1.06094705e-01  1.69920733e+00  1.45764332e+00
  2.13911776e-01  2.61675658e-01  4.62192947e-01 -8.18731769e-01
 -1.49152819e-02 -4.84389443e-02  6.63369143e-02  9.10811246e-01
 -4.52944334e-01  7.58699259e+00 -8.38471963e-01  6.21418903e+00
 -2.39222627e+00  6.26250028e+00  3.58086057e-02 -2.89711728e-03
  6.14561558e+00]
supnorm grad right now is: 7.586992592757415
Weights right now are: 
[-2.68358324  8.24788533 -1.94844847 -2.32342823  2.93815195 -8.35657702
  2.34738574  1.60739985 -2.96022288 -1.74689208  5.60133294 -0.30426595
  5.7579755  14.50880543  6.21337187 18.81482039 42.47312488 -7.99311039
  8.30613477 -6.03164797 42.41573795 -8.36648422  8.42147039 -5.48507783
  4.43580043 -7.88684899  3.51230615 -7.64784309 -7.18531498 19.84160557
 25.19490442 -1.64783286  6.45838538 31.97970791  0.14154897  3.79185205
 -2.59231881 45.31476621  9.12738528 -0.97742025 -2.16633214  1.13651535
  4.39619142 14.94073794 28.52349858 37.115418   -3.26161904  1.99423855
  7.65017716 10.22407489 -3.04056512 -0.82701945 16.40871354 -0.86847845
 20.92433064  1.3457788   2.0650145  -1.74758476 -0.53795546 -2.20082427
  6.28273958  1.46395706  3.64367819 14.04593653 27.42010016]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2423.4071343228607
gradient value of function right now is: [-1.49751997e+00 -7.68549479e-01  1.73963050e-02  1.70964978e-02
  1.49751997e+00  7.68549479e-01 -1.73963050e-02 -1.70964978e-02
  2.78187554e-01  5.60433417e-01  2.23323624e+00  8.09997743e-01
  2.12353222e+00 -9.42632386e-06 -1.56210154e+00 -1.74791438e-02
  6.13618815e-03  4.60607799e-03  1.80214600e-02  3.21576602e-03
  5.73008518e-03  4.43008367e-03  1.66806934e-02  3.09040384e-03
 -3.11759415e-03 -3.59857799e+00 -1.14033320e+01  1.33991734e-01
  1.49527933e-02  1.54348980e-07  4.99114864e-03  7.28206379e-03
 -3.63191683e-02  5.05899221e-02  7.87247161e-01 -1.22517744e-01
  9.63594446e-03  2.35939607e-03  2.18425368e-01  1.10004058e-02
  1.02220081e-01  1.65655216e-01  2.86771366e-02  1.87646545e-02
 -4.52054916e-01 -3.77779374e-01 -1.55230653e+01 -2.28471503e+01
 -1.21315168e-01 -2.67560024e-01  1.21578688e+00 -8.71155166e-01
  5.15135286e-02  1.63641264e-01  7.92576725e-02  1.33699165e+00
  2.37435398e+00 -2.41667131e+01  4.33645037e+00 -2.90428475e+01
 -5.90894395e+00  2.85207863e+01 -1.40417191e-01  5.85008534e-02
 -1.29629664e+01]
supnorm grad right now is: 29.042847469014053
Weights right now are: 
[-2.80934518  7.53432272 -2.81003398 -3.20604701  3.06391389 -7.64301441
  3.20897125  2.49001862 -2.81733753 -1.18939444  5.89592129 -0.44726512
  5.53450303 18.25646923  5.49455568 21.66241527 51.78857256 -8.11110591
  8.00629893 -5.67379009 51.88539124 -8.51469024  8.0908185  -5.17876197
  4.54081706 -7.84979943  3.53987544 -9.08484254 -5.18014896 19.90255424
 29.04868871  4.86238053  6.8985511  34.64683725  0.38199237  3.59533785
 -0.9818364  53.08079627  7.86961991  2.41549779 -1.80769824  1.37951968
  5.74244857 14.91337086 31.85540233 40.76211202 -3.15102732  2.09068554
  8.84880344 11.60821712 -3.35279474 -0.69995092 16.36423631 -0.96427186
 24.66257666  1.00183464  1.88188621 -1.90443541 -0.43016758 -2.26293221
  6.72630745  1.38501487  6.19712988  8.7602245  27.16921817]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -2419.7145337620873
gradient value of function right now is: [ 1.85480304e-01 -1.03114901e-01  2.89488907e-02  2.86399057e-02
 -1.85480304e-01  1.03114901e-01 -2.89488907e-02 -2.86399057e-02
  2.28318235e+00  5.16674666e-01  4.74244031e+00  1.47038018e+00
  1.29269540e+00 -2.89862732e-06 -3.17015554e+00 -5.22910845e-02
  1.06538918e-02  3.47382696e-04  3.62871595e-02  4.08144620e-04
  1.02337076e-02  3.45611449e-04  3.47548588e-02  3.99979525e-04
  1.77112565e-03 -3.51796798e+00 -8.11862384e+00  4.61822810e-01
  3.45459125e-03  6.58146901e-08  1.30808159e-02  1.40601170e-02
 -1.00018733e-02  6.18527725e-02  4.07285578e-01 -4.55589535e-01
  1.52887033e-03  7.05772616e-03  7.63436727e-01  4.18012263e-02
  1.37048384e-02  3.60255200e-02  2.48918008e-03  2.41794346e-02
 -4.53641150e-01 -3.03843862e-01 -1.58660695e+01 -2.30753563e+01
 -3.61153076e-01 -7.13357545e-01 -6.49780084e-02 -7.32629426e+00
  1.27274532e-01  4.74298727e-01  1.60341525e-01  4.71396046e+00
  2.50870522e+00 -2.67495262e+01  6.31240050e+00 -2.94585344e+01
 -9.30271790e+00  3.46636667e+01 -3.33037374e-01  1.99351396e-01
 -1.88300390e+01]
supnorm grad right now is: 34.66366666357662
Weights right now are: 
[-2.91979136  7.239379   -3.23964657 -3.69447047  3.17436007 -7.34807069
  3.63858384  2.97844209 -2.54524832 -1.70264001  6.13127413 -0.5476743
  5.39447653 19.90494294  5.19475321 23.44100956 60.64849135 -8.95487769
  7.46036028 -6.44230433 60.72776756 -9.37651807  7.49604147 -5.96210578
  4.84394719 -8.0139275   3.52354014 -9.05138749 -6.51366786 19.89339156
 36.7293566  10.34892306  8.09625125 36.87196837  0.46240562  3.51261042
 -2.33520146 61.71570345  6.88135491  4.58514227 -4.86514013 -0.10065571
  2.05912049 14.4813634  35.30268694 43.96321353 -3.07985558  2.00228027
  8.12348663 12.33173263 -3.72440391 -0.83895271 16.34322488  0.31690972
 27.58824575  1.18976533  2.0732097  -1.94450959 -0.33280737 -2.44465773
  6.84358668  1.51291514  5.25914473  9.69375699 27.29013985]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2424.5913236076153
gradient value of function right now is: [ 8.65321106e-01  8.50443562e-01  3.68430502e-03  3.64136355e-03
 -8.65321106e-01 -8.50443562e-01 -3.68430502e-03 -3.64136355e-03
 -8.34794966e-01 -3.65838935e-01 -1.16243757e+00 -8.60188450e-01
 -1.11848318e+00  1.14497981e-06 -4.90956221e-01  6.77517370e-03
  9.73492714e-04 -7.12714111e-04  6.21699953e-03 -4.99794690e-04
  9.46397755e-04 -6.88518078e-04  6.03934295e-03 -4.82790972e-04
 -2.02992931e-03  1.19224908e+00  5.88028441e+00 -2.13778015e-02
 -2.73200180e-03 -6.93524106e-09 -4.04422518e-03 -5.50541311e-03
  1.24354515e-02  7.95275561e-03  1.40103223e+00  1.40243259e-01
 -4.05266253e-03 -3.39339511e-04 -6.66518363e-02 -1.56623146e-02
 -3.08730441e-02 -6.33569658e-02 -1.22932137e-02 -4.26377750e-02
  1.96088418e-01  1.80637381e-01  6.75704427e+00  7.54520245e+00
  1.50314440e-02  1.42591672e-01 -8.49746736e-01  2.22956043e-01
 -4.33744945e-02 -1.99448060e-01 -5.45326491e-03 -4.15702611e-01
 -1.09526631e+00  1.32003430e+01 -2.90722764e+00  1.66525138e+01
  6.47235253e-01 -4.60228662e+00  2.62315901e-01 -1.76674990e-01
  5.70321826e+00]
supnorm grad right now is: 16.65251382253284
Weights right now are: 
[-2.81439927  7.54848342 -3.3604332  -3.86073636  3.06896798 -7.65717511
  3.75937047  3.14470798 -2.7686354  -1.00919519  6.19728123 -0.83618693
  5.50183748 20.08726175  5.14669341 23.1546663  69.93160393 -7.76976001
  9.64074395 -5.1029043  70.0382948  -8.14544897  9.6719281  -4.58255042
  3.10960593 -8.31620798  3.59466379 -8.86190197 -7.84275811 19.89089916
 42.37872254 12.77091402 10.75543497 38.5194274   0.43118208  4.14810595
 -2.00497159 67.79908883  7.17700417  5.82415498 -5.52673649  0.12236313
 -0.48208662 12.64710223 38.73890531 47.81293787 -3.10348536  1.95526258
  6.95859781 12.65624501 -3.57302434 -0.55844899 14.41084654 -0.27841689
 29.48638744  1.52931116  1.85429493 -1.8833596  -0.89248657 -2.22606271
  7.06239412  1.53023354  6.02711407  8.45608991 27.24735706]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2419.3870915947105
gradient value of function right now is: [ 6.44382701e+00  3.91589914e+00  1.65289688e-02  1.64882781e-02
 -6.44382701e+00 -3.91589914e+00 -1.65289688e-02 -1.64882781e-02
 -5.57126959e-01 -7.67261436e-01 -2.81773533e+00 -1.78559388e+00
 -6.41326463e+00  7.74664544e-07 -4.34967868e-01  1.92381470e-02
  1.18855271e-02 -7.26487515e-04  4.16974987e-02 -4.22888413e-04
  1.18370481e-02 -7.36048373e-04  4.15387577e-02 -4.31735366e-04
 -6.86956202e-05  8.22082944e+00  2.95230129e+01 -3.59241618e-01
 -6.04280167e-03 -1.62751285e-08 -6.49782582e-03 -2.75563922e-02
  2.26286073e-02  3.27770468e-02  2.55034913e+00  6.52411735e-01
 -5.90363951e-03 -2.68609882e-03 -2.47806007e-01 -8.99063636e-02
 -4.14840892e-02 -1.22413560e-01 -2.74765233e-02 -1.03713298e-01
  4.83974364e-01  3.89825672e-01  3.02268056e+01  4.86764592e+01
  1.40626283e-02  3.14384888e-01 -4.64069918e+00 -5.31421484e+00
 -1.42950003e-01 -7.57765722e-01 -7.85167571e-02 -4.60216582e+00
 -3.30039833e+00  3.63335295e+01 -7.70788664e+00  4.15091350e+01
  1.09981159e+01 -5.24248755e+01  4.41883423e-01 -1.31770552e-01
  1.79516212e+01]
supnorm grad right now is: 52.42487554721005
Weights right now are: 
[ -2.58464003   7.48792558  -7.703252    -8.25136647   2.83920874
  -7.59661727   8.10218927   7.53533809  -2.44969602  -1.17704898
   6.65584908  -1.07803688   5.40548247  20.16472324   5.10747946
  25.22189132  74.68913441 -10.3102906    7.69457734  -7.49959364
  74.72954984 -10.72941789   7.69612541  -7.03398633   5.74032915
  -8.19922529   3.81542592  -9.40786982  -6.55348386  19.89064898
  47.18174205  13.3824952    9.87148004  40.59936319   0.37565001
   4.31323226  -3.19875647  74.23965569   6.50941649   6.33939794
  -7.61963321   0.37361536  -3.33613266  11.29261247  41.533599
  50.18557106  -3.09382722   2.14004104   7.22876101  14.14586577
  -3.72117066  -0.54859212  13.96578147   0.68125519  30.71957039
   1.34966519   2.00665286  -1.99584533  -0.84998447  -2.46262172
   7.2427452    1.53608125   3.54914946  10.76777353  27.2860492 ]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2426.083593762821
gradient value of function right now is: [-9.34086474e-01 -3.82012284e-01  4.30645591e-04  4.29171116e-04
  9.34086474e-01  3.82012284e-01 -4.30645591e-04 -4.29171116e-04
 -7.34778921e-01 -1.44049026e-01 -5.42040814e-01 -2.32011581e-01
  5.72530250e-01  4.62922025e-08  1.56292864e-01  6.34698277e-03
 -1.67274184e-04 -2.42035201e-04  1.93144852e-03 -1.78954192e-04
 -1.70427755e-04 -2.63665047e-04  1.92534992e-03 -1.95012115e-04
 -1.40448078e-03 -4.96401268e-01 -2.71916003e+00 -4.07791673e-02
 -2.81361718e-03 -3.16092943e-10 -7.75006022e-04 -2.59028298e-03
  7.46675359e-03 -2.22887370e-03  2.82071913e-01  7.25343451e-02
 -2.28350999e-03 -8.83952141e-04 -8.79627779e-02 -8.59484890e-03
 -1.98829991e-02 -3.82288677e-02 -9.53793378e-03 -3.01352572e-02
 -3.13054775e-02 -3.24483059e-02 -1.76744023e+00 -3.10698891e+00
  3.35343622e-02  7.78435383e-02  5.25799235e-01  1.72877948e+00
 -1.39285215e-02 -7.26295078e-02 -9.75273990e-03 -5.44037792e-01
  3.13487607e-01 -2.11532934e+00 -1.18361110e-01 -1.67262167e+00
 -3.37151025e-01  3.36071998e+00  1.01868418e-01 -6.31755627e-02
  8.12911505e-01]
supnorm grad right now is: 3.360719976929109
Weights right now are: 
[ -2.77022885   7.29437659 -10.06115318 -10.61520836   3.02479757
  -7.40306828  10.46009044   9.89917998  -2.37553397  -1.46387553
   6.44444463  -1.08442676   5.37597187  20.1359797    5.69203181
  24.95440818  79.49692597  -9.97118448   8.58738142  -6.91186505
  79.53970718 -10.42243919   8.58915534  -6.48429164   5.30471833
  -8.286863     3.55116089 -10.22095658  -4.6820803   19.89111982
  54.53054563  14.90054881  11.30373937  42.10768692   0.46751385
   4.42298914  -1.304513    78.74488203   6.93610059   7.10141105
  -6.14331824   0.55602425  -1.37159712  11.06039135  44.40554177
  53.01446974  -3.12486308   2.13888508   6.44229071  14.53898668
  -3.25169065  -0.58681153  12.87268685   1.02565491  32.73778523
   1.30190629   1.81228202  -2.05085258  -0.95709871  -2.37477462
   7.42518762   1.59032959   6.16894056   8.9641824   27.18240976]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2421.491130247607
gradient value of function right now is: [ 1.73498156e+00  1.14039056e-01  4.41922853e-03  4.42702536e-03
 -1.73498156e+00 -1.14039056e-01 -4.41922853e-03 -4.42702536e-03
  4.08605502e+00  1.17130217e+00  5.36826617e+00  2.78616863e+00
  5.66663011e-01 -2.07131700e-07 -1.65934018e+00 -2.77847074e-02
  5.97596540e-03  4.89039462e-04  1.14243929e-02  3.41325311e-04
  6.00744476e-03  5.70361737e-04  1.14552145e-02  3.96027400e-04
  4.66124919e-03 -2.23600778e+00 -4.22468813e+00  2.96745067e-01
  8.58369869e-03  5.31455125e-09  1.09171824e-02  2.71875002e-02
 -2.49279752e-02  5.90148292e-02 -5.43124121e-01 -4.23687400e-01
  6.50222106e-03  4.35751432e-03  5.11422299e-01  6.84151633e-02
  4.43754534e-02  1.10487373e-01  3.14190244e-03  5.22783885e-02
 -2.46558141e-01 -1.74216810e-01 -1.18743271e+01 -1.55747553e+01
 -3.01773562e-01 -6.71781434e-01  1.47935321e-01 -7.95998473e+00
  9.89485194e-02  3.42363132e-01  8.23853191e-02  3.55181086e+00
  2.33748770e+00 -2.01473510e+01  6.54916416e+00 -2.39396782e+01
 -6.28730872e+00  2.34341703e+01 -4.72871575e-01  1.70554815e-01
 -1.87645803e+01]
supnorm grad right now is: 23.939678153624403
Weights right now are: 
[ -2.70524906   7.30905457 -12.18859663 -12.76100755   2.95981777
  -7.41774626  12.5875339   12.04497916  -2.19875206  -1.7808397
   6.45067698  -1.29577478   5.26829833  20.1516348    5.68181334
  25.42607335  82.63492046 -10.51728029   8.81944633  -7.34230954
  82.62723562 -11.0015083    8.8164074   -6.9523958    6.69902565
  -8.19714651   3.62036075 -10.7505007   -4.7307295   19.89152518
  62.28379628  16.43545513   9.28950406  45.61315148  -0.20540528
   3.77758142  -0.22122011  87.21345587   6.61489055   7.1078432
  -4.50958038   1.61253077   0.37815528  13.57291333  47.04432599
  55.61155142  -3.05685656   2.06611482   7.42892948  14.90410326
  -3.62269024  -0.52505678  12.49555388   1.4971984   32.53072463
   1.88643245   1.49254999  -2.06989244  -0.61356248  -2.50635965
   7.51114286   1.70075848   3.98984049   9.34141646  27.22551915]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2423.0643046659497
gradient value of function right now is: [-3.10096981e+00 -1.10223531e+00 -2.27011353e-03 -2.27009173e-03
  3.10096981e+00  1.10223531e+00  2.27011353e-03  2.27009173e-03
 -3.40182146e+00 -9.60749602e-01 -3.63689891e+00 -1.83264698e+00
  1.40780334e+00  1.93995775e-07  1.70537679e+00  2.97203183e-02
 -4.88445302e-03 -5.10659735e-04 -8.26580753e-03 -3.29745627e-04
 -4.89811657e-03 -6.68693910e-04 -8.22932062e-03 -4.23196710e-04
 -5.57448560e-03 -1.64963524e-01 -4.69134305e+00 -1.51564466e-01
 -8.93438412e-03 -4.94028275e-09 -7.04333105e-03 -1.15835129e-02
  2.55248687e-02 -4.23995126e-02 -1.77611640e-01  2.01858098e-01
 -7.16759989e-03 -4.30104427e-03 -4.69860975e-01 -3.15409554e-02
 -6.08016436e-02 -1.22144717e-01 -1.91035010e-02 -7.59231386e-02
  7.75669789e-02  4.67683298e-02  2.52177270e+00  4.88339601e-01
  2.61004387e-01  4.25602940e-01  1.77208489e+00  8.78040070e+00
 -4.35551422e-02 -1.68898523e-01 -5.72018296e-02 -1.70990737e+00
 -6.53271037e-01  7.60437379e+00 -2.29253755e+00  1.06280103e+01
  2.47566841e+00 -7.86250288e+00  5.18819215e-01 -3.81435292e-01
  1.48315519e+01]
supnorm grad right now is: 14.831551878972835
Weights right now are: 
[-2.84842835e+00  7.19627499e+00 -1.50357783e+01 -1.55805983e+01
  3.10299706e+00 -7.30496668e+00  1.54347156e+01  1.48645699e+01
 -2.24434921e+00 -1.78800184e+00  6.62610673e+00 -1.27972521e+00
  5.31266073e+00  2.02252480e+01  5.41014415e+00  2.49173071e+01
  8.61293894e+01 -8.74786239e+00  7.61073379e+00 -4.81100852e+00
  8.61549148e+01 -9.30035010e+00  7.62035668e+00 -4.49024659e+00
  6.06662123e+00 -8.38051588e+00  3.49689483e+00 -1.06855392e+01
 -5.58136853e+00  1.98914337e+01  6.63726794e+01  1.99750756e+01
  1.09616099e+01  4.64519514e+01  3.31912253e-01  4.31302605e+00
 -8.56830279e-02  9.33477801e+01  6.97783737e+00  7.40026234e+00
 -5.02205503e+00  9.81081679e-01 -8.17970181e-01  1.37603562e+01
  4.98760824e+01  5.80888638e+01 -3.06999170e+00  2.11746912e+00
  7.73026691e+00  1.65503655e+01 -3.02029041e+00 -4.44637182e-01
  1.26562720e+01  1.63011405e+00  3.37525577e+01  1.64685453e+00
  1.54219317e+00 -2.12378239e+00 -8.86174109e-01 -2.51305367e+00
  7.68998681e+00  1.64733767e+00  4.92565044e+00  5.90408358e+00
  2.73966778e+01]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2424.506491965891
gradient value of function right now is: [ 1.41443020e+00  2.54009256e-01  3.75412943e-03  3.75858560e-03
 -1.41443020e+00 -2.54009256e-01 -3.75412943e-03 -3.75858560e-03
  2.49963326e+00  8.01089141e-01  2.69628907e+00  1.55551670e+00
 -2.42464538e-01 -4.10002969e-07 -1.26626960e+00 -1.63688247e-02
  6.06080158e-03 -3.22890668e-04  2.10859372e-02 -1.50396524e-04
  6.05669394e-03 -4.74272783e-04  2.11749262e-02 -2.40541532e-04
  9.78237266e-03 -3.39756198e-02  1.96852828e-01  7.76772089e-02
  2.35934903e-03  1.74403215e-10  3.65997156e-03  2.69343261e-03
 -2.32850931e-02  1.60238533e-02  6.14172433e-01 -1.98522406e-01
  1.59594974e-03  9.18044522e-04  2.35935336e-01  1.60396946e-02
  5.95692115e-02  8.53704615e-02  2.95236123e-02  1.03861109e-01
 -4.77670145e-02 -3.39040583e-02 -8.96074904e-01 -1.33410367e+00
 -1.86686777e-01 -2.55570734e-01 -6.93207245e-01 -1.89150170e+00
  6.51835088e-02  1.72198839e-01  1.27633110e-02  1.03568986e+00
  1.33875128e-01 -3.70896440e+00  1.19699493e+00 -5.35608876e+00
 -4.52884304e-01  1.55483512e+00 -6.63131480e-01  6.50018635e-01
 -7.31433963e+00]
supnorm grad right now is: 7.314339627622097
Weights right now are: 
[ -2.68156687   7.31091433 -16.28761861 -16.87107209   2.93613558
  -7.41960602  16.68655588  16.1550437   -2.17294685  -1.04881688
   6.98105703  -0.79993696   5.2885643   20.10868307   5.52614993
  23.14196732  89.38304084  -9.07303465   7.50880302  -4.57823969
  89.343957    -9.67703917   7.50398758  -4.29226784   4.85171146
  -8.38363167   3.54218157  -9.98497919  -7.15259807  19.8914074
  75.40602828  22.79478968  11.03629859  49.70807551   0.45466288
   4.96853085  -0.93571373  98.99292271   7.46365127   9.83639312
  -6.09597241   1.57513295  -3.8140152   14.15530856  53.06612193
  61.49584475  -2.97145115   2.15338161   6.14254145  15.44666228
  -3.43781155  -0.51622419  12.18161255   1.90691214  35.91436781
   1.68146342   1.39801512  -2.20126486  -0.51713942  -2.57674816
   7.87117068   1.55060393   4.651989     5.04616452  27.28251376]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.164267579863
gradient value of function right now is: [-1.45902193e+00 -6.79057339e-01 -4.65108727e-03 -4.64348505e-03
  1.45902193e+00  6.79057339e-01  4.65108727e-03  4.64348505e-03
 -1.86744070e+00 -6.47623176e-01 -2.51843342e+00 -1.07801077e+00
  2.38571842e-01  3.44565974e-07  1.55844661e+00  1.44396698e-02
 -1.13850272e-02 -1.21934596e-03 -1.83255290e-02 -5.17794326e-04
 -1.14099473e-02 -1.91352207e-03 -1.82143492e-02 -8.02412437e-04
  1.39554211e-03  1.26715086e+00  1.70456232e+00 -2.13107824e-01
 -1.24046205e-02 -5.28568523e-10 -2.61441549e-03 -6.62231359e-03
  3.18782034e-02 -3.74777804e-02 -6.37244609e-01  1.90218013e-01
 -1.44855947e-02 -1.49073663e-03 -2.19003012e-01 -2.51294843e-02
 -7.27723512e-02 -1.50998016e-01 -1.52783190e-02 -7.85718658e-02
  1.41710209e-01  1.06677788e-01  8.10234774e+00  9.50762912e+00
  1.24377369e-01  2.36188202e-01 -7.68668968e-02  5.40226509e+00
 -4.46217675e-02 -1.55181261e-01 -6.70169799e-02 -2.35314948e+00
 -1.33680884e+00  1.42171747e+01 -2.30068205e+00  1.57692618e+01
  4.28410730e+00 -1.69171542e+01  6.82180294e-01 -4.88043737e-01
  1.18977045e+01]
supnorm grad right now is: 16.91715419359996
Weights right now are: 
[ -2.77202101   6.88603276 -20.11881883 -20.65609533   3.02658972
  -6.99472445  20.5177561   19.94006695  -2.17669799  -1.44317298
   6.95084398  -1.47223645   5.51207402  20.06100627   5.89960187
  23.52648334  90.18753345  -7.03395086   8.7188122   -1.62680049
  90.28475291  -7.67097374   8.71962431  -1.383784     3.67732395
  -8.31373802   3.50507717 -10.58320039  -4.13715375  19.89143423
  78.0333374   22.2385699   11.16140715  52.32605413   0.39485281
   4.95494211   1.00625762 104.07240167   7.88908812  10.41507267
  -6.09719017   1.79879207  -3.92198825  14.93530426  55.81894954
  63.9725952   -2.92547451   2.18199394   7.99708747  17.57778103
  -3.34343778  -0.5839509   12.13377829   3.16919385  37.37017249
   1.52153479   1.39376993  -2.18002781  -0.72160002  -2.51067607
   7.85776525   1.54868562   4.43048562   5.0372683   27.29282539]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2422.868181737114
gradient value of function right now is: [-2.23155902e+00 -1.09090836e+00  1.55659209e-04  1.81625880e-04
  2.23155902e+00  1.09090836e+00 -1.55659209e-04 -1.81625880e-04
 -5.46675561e-01  2.65899059e-01  7.14097341e-01  7.72924545e-02
  1.94932058e+00 -2.21521169e-06 -7.22431054e-01 -8.09548867e-03
  2.97378236e-04  1.59714505e-03  2.57784519e-03  7.54311913e-04
  4.23153387e-04  2.14581959e-03  2.79723331e-03  1.01491233e-03
  1.53206283e-02 -2.23927828e+00 -9.94848569e+00  1.44518332e-01
  9.81164498e-03  3.09451379e-12 -2.32243564e-04  1.82307049e-03
 -7.04666479e-02  1.07651763e-03  1.22913287e-01 -1.01283255e-01
  2.07473329e-02  7.58568187e-04  1.02844477e-01  1.64141918e-02
  5.33879023e-02  1.16173751e-01  5.47700099e-03  3.16063107e-02
 -1.60929918e-01 -1.60922236e-01 -9.64990370e+00 -1.59705126e+01
  2.54549874e-02 -3.14391637e-02  1.97116169e+00  1.51311835e+00
  3.68980165e-02  1.24741322e-01  3.21179002e-02  1.41555156e+00
  1.82339944e+00 -1.61771141e+01  2.93908887e+00 -2.00685339e+01
 -3.93933751e+00  1.76115506e+01 -4.42457641e-01  2.41943438e-01
 -7.23830770e+00]
supnorm grad right now is: 20.068533918098026
Weights right now are: 
[ -2.81965369   7.26076807 -22.35961747 -23.02193212   3.0742224
  -7.36945976  22.75855474  22.30590373  -2.9425026   -0.36505503
   6.26170761  -1.61614233   5.40878629  19.20738563   5.56613955
  23.0478063   92.15531988 -11.27540719   8.57587602  -5.21415128
  91.97393116 -11.95283623   8.5564182   -4.99375896  10.44900346
  -8.70091465   3.3248726   -9.54053638  -1.83712629  19.89141374
  88.69087406  24.35014789   7.41102946  51.61065925   0.82126961
   5.47538085   4.77125755 112.82203616   7.9544215   11.2947486
  -6.24997704   1.65170924  -4.04297431  17.36399324  58.52142395
  66.44644239  -3.08933326   2.15531085   5.63362286  16.71143812
  -2.83110307  -0.72530154  10.88238467   2.97783988  37.91759105
   1.93267839   1.45299926  -2.17960627  -0.5545755   -2.40510858
   7.7947496    1.61129747   3.96865942   4.88218566  27.21563675]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2422.4175094088478
gradient value of function right now is: [-4.59743839e+00 -1.74666393e+00 -2.04594216e-03 -2.01501862e-03
  4.59743839e+00  1.74666393e+00  2.04594216e-03  2.01501862e-03
 -4.17816305e+00 -7.94105705e-01 -3.81503625e+00 -1.79456418e+00
  2.16938692e+00  2.33414513e-07  1.42077101e+00  2.96686192e-02
 -6.54813415e-03  4.27427075e-04 -6.93091772e-03  1.27718984e-04
 -6.39901981e-03  5.63751447e-04 -6.73312686e-03  1.76281861e-04
 -2.07676202e-02 -5.89583925e-01 -8.53868877e+00 -2.43354541e-01
 -8.29612064e-03 -1.28504495e-10 -4.17321100e-03 -8.39387699e-03
  3.09743311e-02 -2.86717237e-02  6.92902990e-01  2.68220078e-01
 -9.17116827e-03 -3.33207086e-03 -5.27240403e-01 -4.23288309e-02
 -2.16154890e-02 -6.87720917e-02 -3.31208927e-03 -2.12182672e-02
  7.88405876e-03 -1.03063549e-02  1.07840249e-01 -2.90581704e+00
  2.38324495e-01  4.62621867e-01  2.16340816e+00  1.10378301e+01
 -4.34722693e-02 -2.05331711e-01 -6.33795659e-02 -2.35100589e+00
  6.39152916e-02  1.50664933e+00 -1.46937395e+00  5.45297399e+00
  2.68204886e+00 -7.30150594e+00  6.02884046e-01 -6.54144216e-01
  1.14660190e+01]
supnorm grad right now is: 11.466018963409265
Weights right now are: 
[-2.96796508e+00  7.07245328e+00 -2.38620813e+01 -2.42444624e+01
  3.22253379e+00 -7.18114497e+00  2.42610185e+01  2.35284340e+01
 -2.57356001e+00 -1.77329957e+00  6.68403654e+00 -1.67142243e+00
  5.51313097e+00  2.48113732e+01  5.62967651e+00  2.57764334e+01
  9.54426864e+01 -8.39348720e+00  7.69380044e+00 -2.24623251e+00
  9.55409955e+01 -9.06345487e+00  7.77596495e+00 -2.03635908e+00
  6.12004125e+00 -8.47821949e+00  3.45327108e+00 -9.67999116e+00
 -9.99548089e-02  1.98914157e+01  9.56145553e+01  2.36663213e+01
  1.01135083e+01  5.48446973e+01  7.99289188e-01  4.66357236e+00
  4.15606241e+00  1.21357863e+02  6.96247975e+00  1.09650993e+01
 -4.75885995e+00  3.22789789e+00 -2.11763797e+00  1.87722887e+01
  6.10910968e+01  6.86079109e+01 -3.10805855e+00  2.28101278e+00
  5.76970580e+00  1.69972376e+01 -2.92510897e+00 -5.16977561e-01
  1.05816040e+01  3.73697309e+00  3.67447889e+01  1.80112916e+00
  1.71460976e+00 -2.27247514e+00 -7.76261441e-01 -2.49189190e+00
  8.25423021e+00  1.65068018e+00  4.52067916e+00  4.48580862e+00
  2.72917084e+01]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2422.591662778793
gradient value of function right now is: [-3.91142742e+00 -1.60084195e+00 -3.83474181e-03 -3.80497206e-03
  3.91142742e+00  1.60084195e+00  3.83474181e-03  3.80497206e-03
 -3.02683897e+00 -5.43863573e-01 -2.72850135e+00 -1.22698561e+00
  1.93882619e+00  1.33393580e-06  1.41671354e+00  1.66316588e-02
 -1.29588678e-02 -5.49104696e-04 -2.02793267e-02 -2.97853145e-04
 -1.27960964e-02 -6.08320746e-04 -1.99721380e-02 -3.25297568e-04
 -5.25195988e-03 -9.59439502e-01 -7.26741543e+00 -1.51907190e-01
 -8.11533823e-03 -8.45306749e-12 -2.32339885e-03 -2.70628709e-03
  2.48924047e-02 -2.95652947e-02 -4.39033830e-01  1.68820311e-01
 -1.02520390e-02 -1.26234095e-03 -3.41536376e-01 -2.61820703e-02
 -4.48360888e-02 -7.55488518e-02 -1.47883495e-02 -4.74471516e-02
  1.89441878e-02  1.29730447e-03 -1.05964762e+00 -5.17268918e+00
  2.01040672e-01  3.11011347e-01  1.87487109e+00  7.17623977e+00
 -4.29113260e-02 -1.33566951e-01 -3.99926596e-02 -1.53234935e+00
  2.25942599e-01  1.77639707e+00 -5.14494827e-01  3.11182133e+00
  5.84893948e-01  4.54834514e-01  5.34044602e-01 -5.48284929e-01
  9.11989938e+00]
supnorm grad right now is: 9.11989938437393
Weights right now are: 
[ -2.89566386   7.01621971 -28.05913779 -28.46848329   3.15023257
  -7.1249114   28.45807506  27.75245491  -2.51104867  -1.31147002
   6.83480754  -2.01962651   5.67479857  26.29152655   6.02577538
  25.97478033  95.53482892  -7.73810157   9.28420459  -1.210311
  95.63875586  -8.22272104   9.30810944  -0.77199988   8.08678898
  -8.66504824   3.4117597   -9.56935903  -0.67102479  19.89141048
 101.56104971  25.71706924  11.38628128  56.81106377   0.71483867
   5.34788422   3.77768959 127.5057612    7.34995667  10.63664707
  -7.22961184   1.29358515  -5.89382888  17.52135569  63.90673851
  71.29427902  -3.14471585   2.10632916   6.04466618  17.10204176
  -2.9735187   -0.62713646   9.89341534   3.71137607  38.35540804
   1.44892993   1.33852582  -2.26312491  -0.49679874  -2.45829566
   7.98906199   1.69249996   4.5327073    4.47563955  27.30243528]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2423.079795291236
gradient value of function right now is: [ 1.19457483e+00  5.67419025e-02  1.83367914e-03  1.83766947e-03
 -1.19457483e+00 -5.67419025e-02 -1.83367914e-03 -1.83766947e-03
  2.59067658e+00  1.05684774e+00  3.22264495e+00  1.73662118e+00
  6.38125757e-01 -1.82187638e-07 -1.37715098e+00 -2.05687519e-02
  5.98105611e-03  4.76854624e-03  1.03714848e-02  1.57669235e-03
  5.96904586e-03  5.16656410e-03  1.02215660e-02  1.70431517e-03
  9.30595283e-03 -2.05138830e+00 -4.78548009e+00  2.81473047e-01
  5.57435877e-02  3.79204729e-11  1.10387023e-03  8.22784973e-03
 -1.14028051e-01  2.94773845e-02  2.24355219e-01 -3.91274416e-01
  7.57465882e-02  2.43484874e-03  4.40575960e-01  8.17539260e-02
  1.43415899e-01  3.75392995e-01  2.02463675e-02  9.41773097e-02
 -1.62316753e-01 -1.70484339e-01 -1.17786867e+01 -1.49413788e+01
 -8.68510379e-02 -2.91418991e-01  7.53815606e-01 -4.35827427e+00
  3.82017098e-02  2.58056189e-01  5.99520241e-02  2.38858450e+00
  2.05492955e+00 -1.81127693e+01  4.03565329e+00 -2.56770238e+01
 -4.91276728e+00  1.94078619e+01 -1.52570353e+00  1.48345373e+00
 -1.53107016e+01]
supnorm grad right now is: 25.677023802106557
Weights right now are: 
[ -2.61579252   7.23121518 -28.58338316 -28.95740665   2.87036123
  -7.33990687  28.98232043  28.24137826  -2.13162689  -0.92298401
   7.18237155  -2.17707781   5.56274403  31.40730586   5.95979648
  27.33383371  98.75018337  -5.1055418    9.42455988   1.33413221
  98.88327096  -5.50847527   9.43817677   1.844366     7.21187369
  -8.46321547   3.48704347  -9.49617301   0.85354816  19.89141124
 106.96243656  24.1608856   11.68745399  60.29332744   0.68926369
   4.11221242   5.12794807 131.62837259   6.86784738   9.64946267
  -5.23666211   2.25716038  -5.31732108  17.78214457  66.4782261
  73.19410029  -3.07062687   2.20732747   5.6338161   18.08548761
  -2.67934635  -0.81701848   9.35541241   4.50116533  37.56616074
   1.92614046   1.67237455  -2.34142676  -1.15980401  -2.59536129
   8.30554748   1.89930661   4.82579814   4.18551736  27.22941708]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.2108107737436
gradient value of function right now is: [-7.55362937e-01 -1.07254212e-01  1.12566709e-03  1.11505803e-03
  7.55362937e-01  1.07254212e-01 -1.12566709e-03 -1.11505803e-03
 -1.28702291e+00 -2.93183146e-01 -9.51110017e-01 -6.45983569e-01
  1.43001472e-01  1.39389986e-05 -3.70250229e-01  1.89506725e-03
  3.57295520e-03 -8.97531320e-04  1.02347918e-02 -1.77020054e-04
  3.51774330e-03 -9.52094409e-04  1.01047722e-02 -1.88876425e-04
  3.23937650e-03  5.54723965e-01 -4.42990942e-01 -2.29476295e-01
 -9.24643085e-03 -7.73027343e-12 -1.00602878e-03 -1.53886307e-03
  2.88419856e-02  3.87790008e-04  1.26533761e+00  1.67140312e-01
 -8.63162753e-03 -3.69033601e-04 -3.95971276e-02 -2.26300594e-02
 -2.84803628e-02 -6.37800863e-02 -3.17868703e-03 -1.93142338e-02
  1.45746137e-03 -3.67874845e-03  2.75204469e+00  3.07446499e+00
  2.87751239e-02  9.91401973e-02 -6.20531948e-01  3.07570571e+00
 -2.85717234e-02 -1.04138133e-01 -5.18071940e-02 -1.98485424e+00
  1.15512603e-02  8.09220241e-01 -3.96610223e-01  1.76239913e+00
  2.75149873e+00 -9.26322000e+00  4.82838023e-01 -6.01457939e-01
  6.58114275e-01]
supnorm grad right now is: 9.26321999758337
Weights right now are: 
[ -2.77818166   7.25625062 -32.56636112 -32.93812528   3.03275037
  -7.36494231  32.96529839  32.2220969   -2.52818112  -1.1828631
   6.83065548  -2.24137574   5.56455784  34.3102599    5.74225654
  24.54992949  98.0091321   -4.90950915  10.01260438   1.62432522
  98.11357307  -5.33200665  10.01486966   2.1189453    8.43156736
  -8.44513236   3.45993628  -9.0887559    2.92788241  19.89141148
 115.66487518  24.24587938   9.38415799  61.62931093   0.98115366
   4.26175149   8.49625554 139.25540366   8.1450941   10.86824494
  -6.93768818   1.35638327  -5.56394788  18.38746198  68.85886823
  75.19972677  -2.89942804   2.35885171   5.29266015  18.26867457
  -2.84932652  -0.50784012  10.60441834   5.42319049  38.07002008
   1.53084836   1.20431648  -2.38790837  -0.83143105  -2.5754795
   8.51632601   1.65951186   5.15453664   4.25437065  26.99100596]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2424.8589247529144
gradient value of function right now is: [ 2.42522136e+00  1.08973538e+00  3.35136658e-04  3.33987178e-04
 -2.42522136e+00 -1.08973538e+00 -3.35136658e-04 -3.33987178e-04
  4.79837985e-01 -2.03943220e-01 -5.37107131e-01 -5.55686890e-01
 -2.32333012e+00 -1.81817304e-07 -3.96599899e-01  1.78549352e-04
  9.78566485e-04  3.01877465e-05  3.82225804e-03  1.48762721e-05
  9.71839008e-04  3.46567597e-05  3.78310912e-03  1.61534548e-05
 -8.09987145e-03  2.21207001e+00  1.03685110e+01  4.24153335e-02
 -2.24256186e-03 -1.67928227e-11 -8.01331933e-04 -3.48182131e-03
  1.86100118e-02 -4.82098944e-04  4.96003972e-01  6.40326636e-02
 -5.41174440e-03  2.81121123e-05 -1.30792765e-02 -2.09525253e-02
 -2.37988115e-03 -2.33771730e-02  5.02568744e-04 -6.63881471e-03
  5.80362186e-02  8.79608522e-02  8.17619681e+00  1.49963537e+01
 -1.01259028e-02  1.41554637e-02 -2.27492577e+00 -4.78842129e+00
 -9.31453867e-03 -5.95347893e-02  3.01899296e-03  5.18181268e-01
 -8.79541996e-01  8.00884951e+00 -2.18674626e+00  1.30276314e+01
  2.50546862e+00 -1.37421193e+01  1.66422471e-01 -2.70824394e-02
  1.95755988e+00]
supnorm grad right now is: 14.99635366993326
Weights right now are: 
[ -2.74740252   7.18486017 -31.720362   -32.0857776    3.00197123
  -7.29355186  32.11929927  31.36974921  -2.3819821   -0.94497618
   7.44361767  -2.18418766   5.48894108  37.79519523   5.45309332
  26.19396589 101.93872182  -4.48453054   9.73603978   2.27320523
 102.00947387  -4.93370498   9.73860301   2.74006585   6.85332439
  -8.52050776   3.44015305  -9.51844981   2.86269968  19.89141261
 119.90793334  22.82788821   9.76324554  64.82615428   0.6014759
   4.66686176   8.58188775 148.50010934   8.94015427  10.81327461
  -6.73175968   3.08168564  -8.98830503  17.86237616  71.87843371
  77.6970715   -2.92695      2.27411019   7.1430987   19.24906758
  -2.40758456  -0.82681497   9.74091868   5.34800838  39.34682643
   1.99014778   2.05215083  -2.41257758  -1.09951276  -2.63106504
   8.40497966   1.57596505   4.73887069   4.37663234  27.15479441]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2411.6062500685534
gradient value of function right now is: [ 2.53912793e+00  3.67930678e-01  1.38329439e-03  1.37063919e-03
 -2.53912793e+00 -3.67930678e-01 -1.38329439e-03 -1.37063919e-03
  5.36872496e+00  2.44786318e+00  6.50250750e+00  4.30900148e+00
  2.75377449e-01 -8.14773242e-06 -2.22802730e+00 -2.56809246e-02
  5.79190167e-03  2.88544453e-03  1.23525039e-02  2.34399313e-03
  5.70099688e-03  2.80730502e-03  1.21670480e-02  2.27805984e-03
  3.82193695e-02 -2.05311651e+00 -3.21617413e+00  3.86410125e-01
  4.81608333e-02  9.44458062e-12  3.62151314e-03  5.89390611e-03
 -3.91177562e-01  2.95136338e-02  4.56221460e-01 -4.97600926e-01
  8.50997056e-02  1.30372277e-03  5.41472699e-01  8.01459080e-02
  4.81030240e-01  6.69773483e-01  6.34304857e-02  3.13994568e-01
 -1.28938053e-01 -1.61352634e-01 -1.21827947e+01 -1.48931543e+01
 -3.06678458e-01 -4.81332589e-01  1.38523367e-01 -6.43755266e+00
  1.75575116e-01  3.49240671e-01  5.58594615e-02  3.48866725e+00
  2.21625940e+00 -1.66475623e+01  4.28149774e+00 -2.71581953e+01
 -4.43166939e+00  1.70035346e+01 -4.56340194e+00  3.83090979e+00
 -2.77664215e+01]
supnorm grad right now is: 27.766421462560032
Weights right now are: 
[ -2.48378208   6.90242716 -35.76375186 -36.07605223   2.73835079
  -7.01111885  36.16268913  35.36002384  -1.84880881  -0.86495191
   7.89198506  -1.57308916   5.63492839  42.79950744   5.96740585
  29.24605761 101.7618342   -2.36658119   8.27939628   1.5552194
 101.85612994  -2.81940191   8.2836842    2.25282532  10.92481928
  -8.29256321   3.28058721  -9.47583677   5.40952807  19.89141368
 127.28135956  20.91946278   8.86989701  70.93982973   0.48437745
   4.38513263   6.84474661 151.55673987   7.86180153   5.25127613
  -6.65535037   1.91868517  -4.98191235  20.407024    74.10393201
  80.06519328  -2.79666382   2.15917208   7.40066499  18.8727812
  -2.58490186  -1.05298306  11.76762095   7.0838041   37.03370756
   2.14041933   0.44641591  -2.60727719  -0.37798789  -2.56193476
   9.23510973   2.14454688   5.26000766   4.50224843  27.02371036]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.458683261414
gradient value of function right now is: [ 8.76097995e-01  4.22163882e-01 -5.31688460e-04 -5.29696141e-04
 -8.76097995e-01 -4.22163882e-01  5.31688460e-04  5.29696141e-04
 -2.97368759e-01 -6.34062443e-01 -9.27934277e-01 -1.05813152e+00
 -1.24582962e+00  4.97288321e-04 -1.08426611e-01 -5.40838419e-04
 -2.33033995e-03 -3.65982987e-04 -5.61934064e-04 -3.57474602e-04
 -2.31088499e-03 -3.62206656e-04 -5.57873078e-04 -3.53789546e-04
  2.11137411e-02  1.10093446e+00  6.20812776e+00  1.44654158e-01
 -2.02769875e-02 -3.74074192e-12 -2.08043587e-03 -3.29158030e-03
  4.94712422e-02 -3.13965376e-03 -2.65963534e-01 -5.27518533e-03
 -1.94675278e-02  1.27852249e-04  1.58043671e-03 -7.44737929e-03
 -5.25848611e-02 -9.79704117e-02 -6.79885372e-03 -2.42432506e-02
  3.98683694e-02  5.67155396e-02  4.63100047e+00  7.50954119e+00
  4.87865322e-02  5.70566412e-02 -5.73568950e-01 -2.78397150e+00
 -3.30325440e-03 -3.41409791e-04  2.06073442e-02  1.43427629e+00
 -8.78930483e-01  5.92633856e+00 -1.43460285e+00  8.63616102e+00
  2.30042476e-01 -3.13932382e+00  7.87308444e-02  1.78355858e-01
  4.04340784e+00]
supnorm grad right now is: 8.636161017550926
Weights right now are: 
[-2.78537735e+00  7.01898659e+00 -3.54501191e+01 -3.58295836e+01
  3.03994607e+00 -7.12767828e+00  3.58490563e+01  3.51135553e+01
 -2.63318386e+00 -1.78763696e+00  7.26569460e+00 -2.12703410e+00
  5.65283517e+00  4.12321420e+01  5.91993094e+00  2.84177188e+01
  1.04935650e+02  6.44649283e-01  8.71927700e+00  5.77112238e+00
  1.04972435e+02  1.57826332e-01  8.71546565e+00  6.43187394e+00
  7.54250349e+00 -8.27510632e+00  3.31520268e+00 -9.35614690e+00
  8.13209811e+00  1.98914135e+01  1.32469150e+02  2.26111443e+01
  9.58996410e+00  7.11705479e+01  6.39643169e-01  4.98665907e+00
  8.26516681e+00  1.59139485e+02  8.34207831e+00  6.00647417e+00
 -7.07356480e+00  2.08470195e+00 -9.67856339e+00  1.96114614e+01
  7.69282096e+01  8.23296354e+01 -2.80126727e+00  2.36850139e+00
  8.44451241e+00  1.96385656e+01 -2.75633208e+00 -9.81191940e-01
  1.01482894e+01  6.43251978e+00  3.88236223e+01  2.11159477e+00
  1.12014985e+00 -2.48057942e+00 -6.04765676e-01 -2.53190299e+00
  9.05398253e+00  1.89604941e+00  4.90392560e+00  4.61338865e+00
  2.72849620e+01]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2422.325180413522
gradient value of function right now is: [ 1.99620416e+00  5.35320056e-01  1.70823484e-03  1.70515205e-03
 -1.99620416e+00 -5.35320056e-01 -1.70823484e-03 -1.70515205e-03
  2.80041986e+00  9.83052763e-01  2.96508928e+00  1.81338252e+00
 -3.75461922e-01 -1.66429710e-06 -9.59898836e-01 -7.34174975e-03
  7.57552981e-03  1.57947025e-04  7.79258353e-03  1.50301680e-04
  7.53029110e-03  1.52340561e-04  7.74386766e-03  1.44746306e-04
  3.72717663e-02 -8.31046597e-01 -2.61273050e-01  3.07837737e-01
  2.39409051e-02  8.49125667e-12  2.09930970e-03  3.05875469e-03
 -1.64726578e-01  1.97182961e-02 -1.54810632e-02 -3.00801160e-01
  3.93796962e-02  2.40629694e-04  1.70169193e-01  3.88244507e-02
  9.43160623e-02  1.27996227e-01  2.08410051e-02  8.24696027e-02
 -8.57550820e-02 -7.82443346e-02 -6.92995462e+00 -6.20534830e+00
 -1.76793706e-01 -2.58048506e-01 -2.07079254e-01 -4.82792764e+00
  9.78363361e-02  1.84795162e-01  6.14937217e-02  2.60936136e+00
  5.94637618e-01 -1.14055620e+01  1.72691169e+00 -1.38454370e+01
 -2.79063481e+00  9.39909475e+00 -1.65513045e+00  2.13272388e+00
 -1.21478434e+01]
supnorm grad right now is: 13.84543700615824
Weights right now are: 
[-2.53436095e+00  7.27463030e+00 -4.13223417e+01 -4.17101893e+01
  2.78892966e+00 -7.38332199e+00  4.17212790e+01  4.09941609e+01
 -2.11732375e+00 -1.22471006e+00  7.74239292e+00 -1.78252821e+00
  5.78610268e+00  4.70497474e+01  6.01032698e+00  2.94817958e+01
  1.02485311e+02 -4.49677896e-02  7.74417423e+00  3.38512474e+00
  1.02513024e+02 -5.06741758e-01  7.74602404e+00  4.08471316e+00
  1.22083918e+01 -8.43009772e+00  3.49789779e+00 -9.30098076e+00
  6.11175669e+00  1.98914144e+01  1.36759647e+02  1.92482135e+01
  8.07496459e+00  7.30230676e+01  9.40375720e-02  4.66911649e+00
  7.32172634e+00  1.66517203e+02  8.77122120e+00  6.99298683e+00
 -7.15781956e+00  1.36743411e+00 -9.39198698e+00  2.03961645e+01
  7.93482296e+01  8.44999477e+01 -3.04176633e+00  2.28801524e+00
  9.30000657e+00  2.01567274e+01 -2.91394216e+00 -1.02838185e+00
  1.22785376e+01  8.10061371e+00  4.09039751e+01  1.44921365e+00
  5.62469141e-02 -2.60196307e+00 -8.88078745e-01 -2.69730515e+00
  8.72095391e+00  1.98199675e+00  5.84837667e+00  4.25368659e+00
  2.71374962e+01]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2426.28575401091
gradient value of function right now is: [-5.44184556e-01 -5.30997397e-01  1.56049253e-04  1.48591843e-04
  5.44184556e-01  5.30997397e-01 -1.56049253e-04 -1.48591843e-04
  5.77533851e-01  3.71243705e-01  9.09152175e-01  6.73349054e-01
  7.24504082e-01 -9.34919033e-10 -2.72798583e-01 -1.45312289e-03
  2.91858758e-04  1.14870465e-03  1.75429515e-03  1.60453823e-03
  2.79112985e-04  1.02381587e-03  1.74454751e-03  1.43041382e-03
 -6.01763912e-03 -5.03054261e-01 -3.44167173e+00  3.42234798e-02
  4.03803410e-03  1.87002172e-12  6.39006492e-04  1.44112698e-03
 -1.14801708e-02 -2.03010906e-03  1.40977561e-01 -8.34484771e-02
  4.86321088e-03  6.94093742e-06  4.98527870e-02  1.32537563e-02
  3.85023310e-02  6.42495155e-02  8.30514837e-03  2.19127275e-02
 -1.99378597e-02 -2.24476653e-02 -1.68126609e+00 -3.51170740e+00
 -3.96458374e-02 -6.71573743e-02  3.54090688e-01  1.54529031e+00
  1.40667060e-02  6.44931438e-02  2.46628872e-03  3.64934608e-01
  3.02014532e-01 -2.59482301e+00  4.10434228e-01 -3.58232366e+00
 -5.65301327e-01  3.01429516e+00 -3.10284098e-01  3.67972805e-01
 -3.84962556e+00]
supnorm grad right now is: 3.849625557624459
Weights right now are: 
[ -2.89538235   7.32768831 -39.82636337 -40.25270276   3.14995106
  -7.43638001  40.22530064  39.53667437  -2.27769012  -1.36567701
   7.99780492  -2.1368405    5.73090983  48.95132095   5.79494218
  30.14723649 107.08523078   3.67296393  10.92033227   6.93369227
 107.09921896   3.21486319  10.91857283   7.65411404   7.89106141
  -8.38197658   3.28423904  -8.2496175    2.70548421  19.89140982
 142.94830053  17.23584371  10.89724412  76.20635313   0.68998189
   5.59038903   1.81262068 167.61142937   9.09500934   5.72314977
  -5.62119835   2.87088981 -10.67032928  20.57391657  82.11140866
  86.5725002   -2.89435218   2.27667464   7.15718311  19.38991142
  -2.52014687  -0.73708753  12.39391769   7.29959992  40.72265566
   1.74643219   1.24119974  -2.44904756  -1.10811719  -2.63460813
   9.02158794   1.89010616   5.36458938   4.1587095   27.16935583]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2422.23785131091
gradient value of function right now is: [ 2.16409749e+00  2.08249892e+00  6.23139302e-05  6.95226126e-05
 -2.16409749e+00 -2.08249892e+00 -6.23139302e-05 -6.95226126e-05
 -2.17758980e+00 -1.09920993e+00 -3.42176259e+00 -2.15717694e+00
 -3.51337948e+00  4.25136997e-07  1.14244246e+00  1.06120403e-02
  4.69984002e-04 -1.14356249e-03 -2.34951988e-03 -1.95874267e-03
  4.83708081e-04 -1.07425142e-03 -2.35401565e-03 -1.84056212e-03
 -8.22525947e-02  5.12014304e+00  1.93371418e+01 -1.02739910e+00
 -6.49290002e-02 -4.31024493e-12 -1.79581741e-03 -8.31994328e-03
  2.38154366e-01 -8.48931995e-03  6.38926345e-01  7.11165638e-01
 -1.23135598e-01 -9.29580177e-04 -2.58575822e-01 -1.08903402e-01
 -1.84478974e-01 -5.31358694e-01 -6.47261546e-03 -8.69488967e-02
  1.51225489e-01  1.41928139e-01  2.06468135e+01  3.48138010e+01
  9.68278281e-02  3.37855815e-01 -4.01510987e+00 -1.73349969e-01
 -1.21104582e-01 -5.46194969e-01 -1.40232351e-01 -7.02135985e+00
 -2.25161738e+00  2.26473832e+01 -2.51528576e+00  2.64356169e+01
  1.10329754e+01 -4.58725366e+01  3.46142263e+00 -4.29561520e+00
  2.25057497e+01]
supnorm grad right now is: 45.87253664054079
Weights right now are: 
[ -2.84103379   7.51488427 -40.49814463 -40.98577837   3.09560251
  -7.62357596  40.89708189  40.26974999  -2.4558005   -1.30177028
   7.64265618  -2.1614279    5.56737052  49.14540511   6.3134081
  30.96430033 109.10104281   6.15810398   8.62053703   9.81735796
 109.09730734   5.62122005   8.61107867  10.45030674   7.27747022
  -8.36657814   3.41243342  -7.48636453   4.07982886  19.89140955
 149.66329199  19.60595699  10.48982709  79.1397593    0.40024187
   5.94404363   2.8270652  173.38024061   8.50908465   6.69333796
  -5.71084535   3.2181132  -10.11489766  22.55098391  84.84307909
  88.51134316  -2.87787397   2.34186388   6.12033258  19.21445282
  -2.98661223  -0.69924175  12.26433186   7.27438615  41.78933611
   1.51046457   1.58559765  -2.51778772  -0.91493588  -2.79160398
   9.21775813   1.74063389   5.17657064   3.62156112  27.37467886]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.2519799091087
gradient value of function right now is: [ 5.24079751e-01  2.30231218e-01  6.86488066e-05  7.11457399e-05
 -5.24079751e-01 -2.30231218e-01 -6.86488066e-05 -7.11457399e-05
  2.32707313e-01  1.62259862e-01 -1.50347662e-01  1.52007325e-01
 -3.44478944e-01  3.13218537e-05 -2.08601547e-02  8.93061670e-03
  3.68800825e-04 -3.47443759e-04  2.41882098e-03 -5.93145513e-04
  3.76010302e-04 -3.38015246e-04  2.43079065e-03 -5.76955421e-04
  2.48490327e-02  3.57600640e-01  1.91365565e+00  6.22674538e-02
  2.21848317e-03  7.82434733e-14  2.37269457e-04  6.07024193e-04
 -1.69254943e-02  1.03153815e-03  8.19354303e-01  1.09855813e-02
  7.11367964e-03 -1.31900806e-04 -1.62330610e-01  1.94709465e-04
 -2.70428263e-02 -5.13649087e-02 -3.43448133e-03 -5.74128115e-03
  5.14919170e-02  4.52131711e-02  3.60870294e+00  2.38374891e+00
  1.42631665e-02  3.07935635e-02 -3.22534529e-01  7.87337702e-01
  2.68174116e-03  8.34103822e-03  8.83035160e-03  3.36547282e-01
 -6.83900138e-01  8.28020988e+00 -7.97837775e-01  8.01073267e+00
 -6.13742014e-01  1.12136639e+00  5.79751720e-02  9.31807906e-03
  5.74319360e-01]
supnorm grad right now is: 8.280209876368794
Weights right now are: 
[ -2.76332566   7.28782305 -43.02200887 -43.53322932   3.01789437
  -7.39651474  43.42094614  42.81720094  -2.3177119   -1.12775735
   7.5985226   -2.06313294   5.7862282   50.47165101   6.12226055
  31.57573519 110.23624239   4.25206923   7.682935     8.55666789
 110.22220868   3.72797158   7.67627239   9.19721877   9.99812269
  -8.63229563   3.28522691  -7.32022739   8.79425278  19.89140928
 157.50833731  20.62600963   8.48080463  79.62064535   1.18695705
   5.25137389   7.15438789 178.81973004   7.62979655   7.32309058
  -7.96941244   2.00616531 -13.21843077  21.72546527  87.5300936
  90.87513164  -2.9308445    2.25030725   6.17284918  19.34612058
  -2.37502491  -0.75843627  12.52569184   7.43343184  42.59160445
   1.6556261    1.10225063  -2.37926297  -0.65492913  -2.56441981
   8.9203446    1.91033884   5.65135484   4.36364439  27.09865324]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2418.2314875837183
gradient value of function right now is: [ 7.37220606e+00  4.54393982e+00  1.14463522e-03  1.16165574e-03
 -7.37220606e+00 -4.54393982e+00 -1.14463522e-03 -1.16165574e-03
  2.68202876e-01 -4.82077079e-01 -2.43583735e+00 -1.57835756e+00
 -6.90668198e+00  2.22693904e-04 -3.41489240e-01  1.65463325e-02
  5.64782078e-03 -5.56071749e-04  2.00191047e-02 -2.71004720e-03
  5.71785647e-03 -5.30723038e-04  2.01062884e-02 -2.58678751e-03
 -5.76528818e-03  7.37390043e+00  3.42460472e+01 -7.82802392e-01
 -1.39797301e-02 -6.37360351e-14 -1.04928759e-03 -1.07837669e-03
  2.07383192e-01  6.46678001e-03  2.57104810e+00  6.19802253e-01
 -1.22585794e-01 -4.15879063e-04 -2.62599343e-01 -1.02688075e-01
 -1.87712777e-01 -2.37241000e-01 -1.62303808e-02 -1.26833173e-01
  2.01573555e-01  2.04730058e-01  2.84882732e+01  4.98717759e+01
  1.22306929e-01  1.81577635e-01 -7.12062409e+00 -1.12772440e+01
 -1.76956290e-01 -2.55716876e-01 -5.83328923e-02 -3.84253822e+00
 -3.33689080e+00  3.27360215e+01 -4.86548264e+00  3.64539160e+01
  1.09575337e+01 -5.34362056e+01  3.92111736e+00 -4.67778008e+00
  2.59853351e+01]
supnorm grad right now is: 53.43620559069947
Weights right now are: 
[ -2.75755781   7.39004381 -47.05874    -47.65375247   3.01212652
  -7.4987355   47.45767727  46.93772408  -2.34077945  -0.84304903
   7.55495722  -2.49906989   5.77448016  53.55006747   5.33437823
  30.19680482 108.37087629   5.81554643   7.82221586   9.87795046
 108.3290816    5.26973646   7.8208062   10.49623843   8.83369297
  -8.47547073   3.48001291  -6.82494721   8.36862484  19.89140929
 166.01241966  22.05207962   9.84181491  80.13465962   0.89875102
   4.60383537   5.44080192 184.54544939   8.23993478   6.92606764
  -7.16829035   1.290468   -10.63827395  23.63658469  89.63398023
  92.79537175  -2.96997729   2.38520571   7.0604661   19.59692813
  -2.42053368  -0.87098638  12.38755506   7.75186179  43.02540238
   1.59317876   0.2587429   -2.6664971   -0.3097758   -2.71739724
   9.10569758   1.73057258   5.8146941    3.74589879  27.48344805]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -2421.18896719044
gradient value of function right now is: [ 1.60274717e+00  6.65093484e-02  6.98035082e-04  6.93621481e-04
 -1.60274717e+00 -6.65093484e-02 -6.98035082e-04 -6.93621481e-04
  3.91212893e+00  1.27518447e+00  4.54089537e+00  2.80510464e+00
  4.02608713e-01 -8.72218136e-05 -1.50006053e+00 -1.60990924e-02
  3.65234271e-03  2.53090103e-04  6.37167724e-03  1.44253957e-03
  3.65321385e-03  2.39761177e-04  6.39399648e-03  1.36800068e-03
  3.59212980e-02 -1.77131002e+00 -3.70776891e+00  4.37348914e-01
  9.76390630e-03  1.36714943e-13  7.98940124e-04  1.94112453e-03
 -2.17853680e-01  1.79250683e-02 -1.34884837e-01 -5.75670518e-01
  6.91115190e-02  8.40777481e-04  3.87763850e-01  9.07153845e-02
  1.73772086e-01  3.31680858e-01  4.24151716e-02  1.58332621e-01
 -9.07940330e-02 -1.09787172e-01 -1.04476346e+01 -1.31742748e+01
 -1.51360058e-01 -3.17436797e-01  5.72514031e-01 -4.73941787e+00
  9.07976327e-02  3.01493659e-01  6.34396459e-02  2.96367470e+00
  1.70078082e+00 -1.49139068e+01  2.98864272e+00 -2.23037132e+01
 -4.95663431e+00  1.86838972e+01 -2.63910424e+00  2.83278836e+00
 -2.10312755e+01]
supnorm grad right now is: 22.30371317435032
Weights right now are: 
[ -2.63078487   7.2729095  -47.82025157 -48.49806105   2.88535359
  -7.38160119  48.21918884  47.78203267  -2.13330533  -0.44335817
   7.55408687  -1.93928038   6.00040292  52.93872255   5.88459227
  31.08580901 109.40122107   8.77353945   8.37393367  12.56273349
 109.33208109   8.2093987    8.37169583  13.15485021   8.67810008
  -8.51484269   3.30189847  -7.51633553   8.97997611  19.89140926
 173.67537289  22.47566312   8.659056    81.8172177    0.46986623
   3.725887     4.86829995 189.42116407   7.90335385   6.05955715
  -8.02875717   1.35814163 -13.27256447  22.87024858  92.46089895
  95.24494506  -3.02455432   2.33083109   7.6764124   19.91562244
  -2.49443221  -0.81168899  10.91121085   7.37658572  42.67438907
   1.62785038   0.9959981   -2.60757287  -0.69455205  -2.65512279
   8.93994766   2.05338289   5.73343093   4.36413733  26.9633345 ]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.815522311225
gradient value of function right now is: [-9.74220073e-01 -5.49401198e-01  5.18283555e-04  5.15505596e-04
  9.74220073e-01  5.49401198e-01 -5.18283555e-04 -5.15505596e-04
 -3.93725551e-02  1.90249054e-01  7.91973128e-01  3.60894429e-01
  1.10051958e+00 -6.32997491e-05 -5.40211346e-01 -5.22725015e-03
  2.69018515e-03  1.26287565e-04  4.97703968e-03  8.29429370e-04
  2.69077042e-03  1.18823007e-04  4.97770998e-03  7.81663834e-04
  2.49283393e-02 -1.49059832e+00 -6.70318047e+00  7.04386059e-02
  9.59182823e-03  6.80119287e-15 -1.38911239e-05  1.03723649e-03
 -1.43227803e-01  7.46768453e-03  2.75031459e-01 -6.62708297e-02
  5.00586969e-02  2.12069340e-04  1.06984047e-01  1.46546391e-02
  7.31036157e-02  1.15831487e-01  3.56604157e-03  2.62072459e-02
 -7.70249254e-02 -8.59820353e-02 -7.96241194e+00 -1.08686585e+01
 -2.41410938e-02 -4.50873538e-02  9.23380199e-01  4.09028225e-01
  1.99848052e-02  4.18333962e-02  1.28133349e-02  4.51863955e-01
  1.27732389e+00 -1.26212118e+01  1.59135233e+00 -1.51758999e+01
 -1.89616848e+00  1.02224986e+01 -4.77790034e-01  2.92050652e-01
 -7.34645474e+00]
supnorm grad right now is: 15.175899851910684
Weights right now are: 
[ -2.70378619   7.29861564 -50.16959126 -50.87423998   2.9583549
  -7.40730733  50.56852852  50.1582116   -2.65451899  -0.86002315
   7.20186569  -2.37050736   6.02425739  53.48413823   5.8415057
  32.08193354 110.28826823   9.8394089    7.89199649  12.60219741
 110.24776812   9.33824493   7.87666528  13.25267587   9.97035218
  -8.53629143   3.33405644  -7.20004523  11.29549899  19.89140927
 179.89102547  25.12483463   7.27139468  82.2374889    0.61003152
   4.60814092   5.92462957 195.64739532   7.95569938   5.92586822
  -6.22697535   1.68921545 -13.33979607  24.6457773   94.67615056
  97.1014      -3.00429489   2.35762379   8.16689088  20.61233183
  -2.79569123  -0.71388202  10.05227969   6.76427264  43.32525102
   1.59577163   0.60773759  -2.63971179  -0.54903052  -2.67166541
   9.08131522   1.86282047   5.17612952   3.82198456  27.1529137 ]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2420.9350829041678
gradient value of function right now is: [ 3.79369378e-01  5.72198137e-01 -8.09202461e-04 -7.97849291e-04
 -3.79369378e-01 -5.72198137e-01  8.09202461e-04  7.97849291e-04
 -2.26145386e+00 -1.32817337e+00 -5.01760817e+00 -2.65884586e+00
 -1.46359249e+00  1.15217341e-05  3.35358648e+00  2.33010948e-02
 -4.18592813e-03 -9.86097475e-04 -8.17989533e-03 -3.04569822e-03
 -4.18219820e-03 -9.27299784e-04 -8.21852509e-03 -2.86576624e-03
 -1.17384955e-02  2.42315255e+00  9.14773620e+00 -1.39482006e-01
 -4.65770878e-02 -1.12811627e-14 -3.99154412e-03 -6.30740153e-03
  1.77237032e-01 -4.07168514e-02 -2.45771015e+00  1.83312075e-01
 -5.50529166e-02 -1.06973139e-03 -5.73656210e-01 -4.30539543e-02
 -1.97225381e-01 -2.52127788e-01 -1.16902041e-02 -7.05542950e-02
  1.93480552e-01  1.95489933e-01  1.51093983e+01  2.01581724e+01
  3.51728483e-01  4.25073457e-01 -9.70890806e-01  2.99773642e+00
 -3.84790542e-02 -5.74007295e-02 -2.04542977e-02 -8.43229018e-01
 -5.02994841e+00  3.50057820e+01 -6.88632585e+00  4.02968320e+01
  3.87157302e+00 -1.89276297e+01  1.32041447e+00 -1.04698716e+00
  2.56795871e+01]
supnorm grad right now is: 40.29683197519716
Weights right now are: 
[-2.68890732e+00  6.89810837e+00 -4.83523490e+01 -4.90496449e+01
  2.94347603e+00 -7.00680006e+00  4.87512862e+01  4.83336165e+01
 -2.11513618e+00 -2.35345554e+00  7.40543530e+00 -2.18455442e+00
  6.00080351e+00  5.57356599e+01  5.73451394e+00  3.33674833e+01
  1.14956875e+02  1.32887348e+01  8.17640390e+00  1.39164558e+01
  1.14969031e+02  1.27724615e+01  8.14615002e+00  1.45238068e+01
  9.52156639e+00 -8.37667778e+00  3.15856006e+00 -6.73038341e+00
  7.25467982e+00  1.98914093e+01  1.88298454e+02  2.53540550e+01
  9.04343917e+00  8.44688814e+01  3.02811617e-01  3.66406424e+00
  4.29637342e+00  2.01777446e+02  7.92874153e+00  5.31813997e+00
 -5.11332729e+00  1.89741265e+00 -1.45609637e+01  2.49768629e+01
  9.74063789e+01  9.98131018e+01 -2.95921650e+00  2.33920158e+00
  8.25334924e+00  1.98544836e+01 -2.33068691e+00 -8.32173542e-01
  1.06048655e+01  8.08920028e+00  4.28185638e+01  1.79855287e+00
  1.50363315e-01 -2.51821061e+00 -4.75309551e-01 -2.59239075e+00
  9.51935922e+00  2.04330912e+00  5.34260767e+00  3.90628909e+00
  2.73378453e+01]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.8220942322682
gradient value of function right now is: [ 9.43993348e-01  4.95699284e-01 -4.05035692e-04 -3.94484181e-04
 -9.43993348e-01 -4.95699284e-01  4.05035692e-04  3.94484181e-04
 -5.46312447e-01 -2.73974719e-01 -1.63241524e+00 -8.15575181e-01
 -1.11432605e+00  4.01643405e-05  9.50456447e-01  8.35527180e-03
 -1.92916915e-03 -4.98556613e-04 -4.97802824e-03 -2.30081977e-03
 -1.92172522e-03 -4.69760401e-04 -5.00327979e-03 -2.16951720e-03
  1.01769651e-02  1.71437640e+00  6.65960597e+00 -1.65626288e-01
 -7.71635137e-03 -1.52458826e-14 -5.07021903e-04 -1.88463823e-03
  8.17155406e-02 -7.89512640e-03 -2.92016390e-01  1.72072448e-01
 -1.25694226e-02 -2.94019067e-04 -1.74262126e-01 -2.92530881e-02
 -1.01251012e-01 -2.01399281e-01 -4.96160568e-03 -3.70934529e-02
  7.20399217e-02  8.22055862e-02  8.36128266e+00  1.20671407e+01
  6.72099788e-02  1.29989567e-01 -1.22172294e+00  5.05037813e-01
 -3.64014910e-02 -1.01691010e-01 -2.32556848e-02 -1.19200036e+00
 -1.83126320e+00  1.32713968e+01 -2.71573523e+00  1.71026728e+01
  2.77493581e+00 -1.21190738e+01  8.33018411e-01 -6.90007522e-01
  1.07323207e+01]
supnorm grad right now is: 17.102672774765846
Weights right now are: 
[ -2.59159803   7.05105299 -49.75274687 -50.6820195    2.84616674
  -7.15974468  50.15168413  49.96599112  -2.3117528   -1.2446198
   7.43996072  -1.76777486   6.04061046  56.21561436   5.68279467
  31.31240126 114.63358388  16.28473218   5.8258407   16.31669853
 114.60037712  15.77869913   5.82428505  16.93224362   8.53975718
  -8.27857352   3.28952999  -7.0370598    7.77636915  19.89140927
 192.81686846  26.19166406   8.70226791  88.07159985   0.51658252
   4.14014534   4.20772814 203.73569693   8.68861418   4.08767288
  -6.28758147   1.1528127  -15.60964132  23.89051981 100.06577168
 101.91751615  -2.85678994   2.28019112   8.89956948  20.90154307
  -2.46209222  -0.8615145   10.42437091   7.39567479  42.88257524
   1.53093116   0.68687379  -2.62191033  -0.89551741  -2.74650607
   9.28490049   1.95001305   5.37798056   4.35214923  27.31035608]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2423.754818264736
gradient value of function right now is: [-4.57863041e-01 -1.02492534e+00  1.27720454e-03  1.22365680e-03
  4.57863041e-01  1.02492534e+00 -1.27720454e-03 -1.22365680e-03
  2.08216776e+00  1.57984549e+00  2.93777053e+00  2.68910384e+00
  1.63415723e+00 -1.60455100e-03 -4.62785343e-01 -1.77933469e-02
  4.69745637e-03  1.19296587e-03  5.24730705e-03  1.09753652e-02
  4.56078996e-03  1.14551157e-03  5.15008121e-03  1.05425063e-02
 -2.18942766e-01 -1.46955509e+00 -8.86779029e+00 -4.33243017e-02
  4.01073558e-02  1.03145283e-14  7.35315891e-04  3.55137042e-03
 -3.83220847e-01  4.99913447e-03  3.59753817e-01 -1.43728024e-01
  1.30707108e-01  1.25801720e-04  9.42782582e-02  2.91995990e-02
  5.27674545e-01  1.30289600e+00  3.70945932e-02  1.33864527e-01
 -6.06011668e-02 -7.97497230e-02 -6.99895046e+00 -1.07590801e+01
 -3.90634176e-02 -6.86331986e-02  1.67033632e+00  3.11027462e+00
  4.38184960e-02  1.32841694e-01 -2.11202988e-03 -4.32259306e-01
  2.75107006e+00 -1.07382255e+01  9.19214098e-01 -1.44991418e+01
 -1.15146695e+00  8.19886122e+00 -1.35776249e+00  4.16573245e-01
 -1.16228044e+01]
supnorm grad right now is: 14.499141750976214
Weights right now are: 
[ -2.70988149   7.1352499  -50.67632212 -51.74153382   2.9644502
  -7.24394159  51.07525938  51.02550544  -2.36595805  -0.65129535
   7.55293483  -1.41562486   6.15362977  54.96288598   5.98948952
  31.32619924 115.33363054  18.12335321   8.37728461  19.06128663
 115.25659368  17.62319019   8.3608669   19.66517438   7.68547642
  -8.26772162   3.31105869  -7.31554894  10.32472584  19.89140927
 198.78518167  23.44835097   7.97467563  88.51572342   1.0224467
   3.86125744   5.10465429 209.58787896   8.27564947   5.94477952
  -5.70479399   2.09117188 -16.10670501  24.37249899 102.58797428
 104.04841134  -2.95395997   2.48413729   8.08264521  20.72238091
  -2.15689178  -0.83281872  10.11973565   7.33255774  44.41577449
   1.40016724   1.36071729  -2.64162454  -0.57149689  -2.71251979
   9.27878346   1.85302907   5.37648966   4.30997373  27.04629119]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2423.526059202074
gradient value of function right now is: [-8.17719503e-01 -5.78628760e-01  8.11896851e-04  8.11037125e-04
  8.17719503e-01  5.78628760e-01 -8.11896851e-04 -8.11037125e-04
  1.01398146e+00  1.55247674e-01  2.28651051e+00  7.15868215e-01
  1.14529031e+00 -1.91129365e-05 -1.35841005e+00 -1.06294407e-02
  4.15284602e-03  7.75003492e-05  9.94668430e-03  7.05190951e-04
  4.20524299e-03  7.28544968e-05  1.00911130e-02  6.64231555e-04
  8.50685821e-03 -2.15532133e+00 -8.08431634e+00  3.03267239e-01
  3.45456066e-03  1.90230816e-15  1.87102649e-04  8.80207321e-04
 -5.03129613e-02  5.27672384e-03 -2.61906552e-01 -3.45959978e-01
  2.05847331e-02  2.98303099e-04  2.74915188e-01  5.37709372e-02
  4.17213767e-02  5.76769393e-02  4.70761290e-03  2.23454639e-02
 -9.55287630e-02 -1.06985707e-01 -1.10499811e+01 -1.51004469e+01
 -1.45697953e-01 -2.16034645e-01  1.17360334e+00 -1.59665893e+00
  7.03105365e-02  1.25911022e-01  3.17981205e-02  1.95228381e+00
  1.48240069e+00 -1.80331789e+01  2.97660735e+00 -2.35507492e+01
 -3.40727566e+00  1.55277074e+01 -1.10629497e+00  1.56223173e+00
 -1.54777628e+01]
supnorm grad right now is: 23.55074916378777
Weights right now are: 
[-2.78669172e+00  7.19438579e+00 -5.23810905e+01 -5.35308824e+01
  3.04126043e+00 -7.30307748e+00  5.27800278e+01  5.28148540e+01
 -2.66331753e+00 -9.31245014e-01  7.31543093e+00 -2.53603921e+00
  6.39051310e+00  5.56561861e+01  5.66999109e+00  3.30227359e+01
  1.15414156e+02  2.00994327e+01  7.90861748e+00  2.03775150e+01
  1.15356396e+02  1.96269066e+01  7.90391416e+00  2.09869777e+01
  8.11234026e+00 -8.43182214e+00  3.41914066e+00 -7.21201050e+00
  8.59332511e+00  1.98914093e+01  2.06136563e+02  1.63361911e+01
  8.55293438e+00  9.12514299e+01  5.92508264e-01  2.88217354e+00
  3.92177025e+00  2.15454241e+02  9.24571051e+00  3.83835677e+00
 -5.66390513e+00  1.22578611e+00 -1.34856360e+01  2.52468737e+01
  1.04691165e+02  1.05883300e+02 -2.99931914e+00  2.26380591e+00
  8.01747631e+00  2.04408878e+01 -2.67328334e+00 -7.18592045e-01
  9.77832102e+00  7.76529031e+00  4.46031947e+01  1.78689961e+00
  4.86338836e-03 -2.67895401e+00 -7.38774047e-01 -2.67090063e+00
  9.23106147e+00  1.89741331e+00  6.41962502e+00  4.56615255e+00
  2.69415980e+01]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2419.5219639680126
gradient value of function right now is: [ 6.15742646e+00  3.23958979e+00  2.14330454e-03  2.17757921e-03
 -6.15742646e+00 -3.23958979e+00 -2.14330454e-03 -2.17757921e-03
  2.33370790e+00  4.82414800e-01  9.59741042e-01  2.83689019e-01
 -4.59539323e+00  4.54092929e-05 -1.68086858e+00 -7.28348717e-03
  1.12116434e-02 -1.70232201e-04  3.35587899e-02 -4.51306263e-03
  1.14377677e-02 -1.58096375e-04  3.41089537e-02 -4.19869262e-03
  4.23807614e-02  3.66260346e+00  2.12237663e+01  3.25415577e-01
  4.85242918e-04 -6.70591277e-16  1.32260445e-04 -3.83775775e-04
  1.01119450e-01  1.70465004e-02  2.39017358e+00  1.92491128e-01
  7.65581857e-03  5.79888424e-04  2.01135934e-01 -3.57372607e-02
 -1.14369686e-01 -2.37569645e-01  1.06291300e-02 -7.70998908e-03
  6.52425113e-02  9.02186602e-02  1.40224128e+01  2.30470211e+01
 -8.21410484e-02 -1.15510846e-01 -3.47867050e+00 -1.07553464e+01
 -2.68498492e-02 -6.79134699e-02  3.90958734e-02  2.07016863e+00
 -1.68812302e+00  1.29339640e+01 -1.52607842e+00  1.61092726e+01
  2.57846982e+00 -1.68127774e+01  3.30600535e-01  1.73332258e-01
  3.32702550e+00]
supnorm grad right now is: 23.04702107668078
Weights right now are: 
[ -2.60799629   7.46854449 -51.71888903 -52.94109144   2.862565
  -7.57723618  52.11782629  52.22506305  -2.22198872  -0.69974504
   7.60699607  -2.11548273   6.08518404  55.79855177   5.76929197
  35.39033447 117.94506015  23.77654968   7.60566456  22.12262273
 117.9044466   23.37859115   7.60089972  22.81522658   7.07538955
  -8.35336457   3.52586576  -7.11461067   9.36461704  19.89140927
 215.21607226  17.20168155   7.81649078  91.57823392   0.88380642
   3.17834216   3.38580769 222.14886471   7.66047653   3.42997804
  -5.18555951   1.470063   -13.45187861  25.87316102 107.23528072
 107.91803044  -3.03035651   2.50735844   7.05543711  20.1085952
  -2.43047674  -1.05142944   9.53329791   7.01316752  44.68970928
   1.58029581   0.76805648  -2.74755002  -0.54210986  -2.75534
   9.27453193   2.04642559   6.26318664   4.67273255  27.35988948]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2422.206974344294
gradient value of function right now is: [-3.85981823e+00 -1.35862839e+00 -3.78542125e-04 -3.73617819e-04
  3.85981823e+00  1.35862839e+00  3.78542125e-04  3.73617819e-04
 -3.42019649e+00 -4.70025900e-01 -3.55179929e+00 -1.48834640e+00
  1.70901338e+00  3.29453262e-05  1.99203748e+00  1.32686522e-02
 -2.27992829e-03 -4.58991440e-05 -4.01479889e-03 -9.84043120e-04
 -2.30776106e-03 -4.29989322e-05 -4.08808239e-03 -9.24479578e-04
 -1.34670674e-02 -2.72985090e-01 -8.41513851e+00 -3.68711193e-01
 -8.15917859e-03 -1.37818171e-16 -1.00798637e-03 -1.61942781e-03
  8.85172208e-02 -2.51132396e-02 -6.64184391e-01  3.80224927e-01
 -3.96860152e-02 -6.91204237e-04 -4.05242299e-01 -6.48448910e-02
 -5.15145930e-02 -8.35955433e-02 -3.76427723e-03 -2.17220565e-02
  3.47734431e-02  3.62504598e-02  2.23150150e+00  1.34701055e-01
  2.14901069e-01  3.29756896e-01  2.08512702e+00  8.32476344e+00
 -7.97609356e-02 -1.80753852e-01 -4.96669086e-02 -2.14911342e+00
 -3.85705320e-01  6.72933356e+00 -1.42932266e+00  1.09122701e+01
  1.97719302e+00 -5.81985432e+00  1.19185050e+00 -1.85374574e+00
  1.19773975e+01]
supnorm grad right now is: 11.977397522777986
Weights right now are: 
[ -2.84665533   7.3344786  -51.60521682 -52.86852748   3.10122404
  -7.44317029  52.00415408  52.1524991   -2.59746889  -1.33331035
   7.2389717   -2.50215626   6.23392995  54.64613958   6.4052422
  35.46698976 120.39398306  27.72967309   7.30518085  21.91839545
 120.33519891  27.38767971   7.28684102  22.69368826   7.49942275
  -8.50137858   3.14322844  -6.60780303  10.20475078  19.89140927
 222.94248583  15.33577674   7.93024183  92.94556729   0.64283154
   4.13094492   4.14165525 229.28960919   8.02820739   4.41359106
  -5.78368892   0.82851424 -13.62432701  27.29397535 109.90051325
 110.09999269  -2.86049314   2.33126648   6.30721503  19.15070781
  -2.19414398  -0.82595193   8.16486407   7.21932485  44.19476648
   1.43290672   0.55711496  -2.61693462  -0.62366844  -2.61941399
   9.49330024   1.95072318   6.02121311   3.90048819  27.13301044]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.017604810019
gradient value of function right now is: [-2.15675627e+00 -1.00644561e+00  6.97224752e-05  5.62419536e-05
  2.15675627e+00  1.00644561e+00 -6.97224752e-05 -5.62419536e-05
 -1.49191931e+00 -3.31346354e-01 -6.84991552e-01 -5.38737082e-01
  1.17883075e+00 -2.47510866e-05  9.46931506e-02 -3.53943961e-04
 -6.80343808e-04  1.93442365e-04  3.84046378e-04  1.86337248e-03
 -7.18795093e-04  1.80770279e-04  3.89267967e-04  1.74621488e-03
 -4.52929177e-02 -7.28359926e-01 -6.33958106e+00 -2.65453690e-01
 -1.34631788e-02 -1.07742896e-14 -5.05228195e-04 -1.99359878e-03
  3.57995930e-02 -3.28720900e-04  1.94113880e-01  2.26088731e-01
 -6.17625690e-02 -1.23915848e-04 -8.22645883e-03 -3.76957891e-02
 -2.13640052e-03 -2.25527579e-02 -2.69953613e-06 -1.93079538e-02
 -3.30592712e-02 -5.10174322e-02 -3.97280778e+00 -5.26472009e+00
  2.42658227e-02  6.96001271e-02  8.92235049e-01  2.88563226e+00
 -1.22568639e-02 -9.50096553e-02 -2.95194440e-02 -1.49905104e+00
  6.13972195e-01 -6.13796726e+00  1.12681014e+00 -8.98097215e+00
  8.65500573e-01  6.48645774e-02  5.95877801e-01 -8.62579304e-01
  1.66401373e+00]
supnorm grad right now is: 8.980972154454447
Weights right now are: 
[ -3.03691968   7.15670068 -51.48454927 -52.95450327   3.29148839
  -7.26539237  51.88348653  52.23847488  -2.26258598  -1.74198565
   7.68633608  -2.47941393   6.30324188  54.01620342   5.43781515
  35.9240065  120.50391091  31.51461338   7.53362131  26.07582215
 120.32674513  31.1350397    7.48882496  26.83482614   5.46354816
  -8.54498128   3.36023553  -6.35642186   5.30987816  19.89140927
 226.88961829  15.80917762   9.24688601  91.23684442   0.34620251
   3.73348625   2.41791165 237.66562931   7.50758796   4.09836685
  -6.78360292   1.70055526 -18.32158231  23.58591796 112.01777963
 111.73466363  -3.00160864   2.47274634   8.37095664  20.97207044
  -2.43729335  -0.82019296   9.26246804   7.45518339  44.33596142
   1.09347862   1.75829487  -2.72928972  -1.05455553  -2.77968701
   9.26536058   1.86660085   6.37546184   4.31511392  27.21873011]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.7392233033215
gradient value of function right now is: [ 6.39118026e-02  1.60948457e-01  4.33577562e-05  4.64709687e-05
 -6.39118026e-02 -1.60948457e-01 -4.33577562e-05 -4.64709687e-05
 -4.71857663e-01 -1.38572368e-01 -4.49301747e-01 -3.27181005e-01
 -1.38648175e-01 -1.70474128e-05 -2.58962348e-01  2.04309646e-03
  2.79728713e-04 -1.55701773e-05  1.83058449e-03 -3.29396811e-04
  2.90930463e-04 -1.49055354e-05  1.88550967e-03 -3.13090914e-04
  6.08228840e-03  4.65994211e-02  8.32284749e-01 -4.17076598e-02
 -1.14314281e-03 -3.33340243e-15 -2.38272646e-04 -4.93506890e-04
  3.40984764e-03  3.26966302e-03  7.03865031e-01  1.05758783e-01
  2.89178280e-02  1.31727825e-06 -4.91064114e-02 -1.42668327e-02
 -2.18314438e-02 -3.73453107e-02 -4.94675426e-04 -8.50513347e-03
  1.77149826e-02  1.21766808e-02  1.26836574e+00  1.16950668e-01
  1.25264356e-02  3.90812879e-02 -1.92717383e-01  1.94029365e-01
 -6.15491041e-03 -3.26248201e-02  2.32678536e-03 -1.17126238e-01
 -1.06434373e-01  3.60453526e+00 -9.44465250e-03  2.62783586e+00
 -8.11860789e-01  3.25812497e+00  3.29370298e-01 -3.69242356e-01
  1.70874745e+00]
supnorm grad right now is: 3.6045352620215745
Weights right now are: 
[ -2.82913205   7.29878931 -52.07915853 -53.54540007   3.08370076
  -7.407481    52.47809579  52.82937169  -2.28107043  -1.24862671
   7.69784262  -2.2969717    6.14682405  55.2995871    5.27428154
  35.94153495 122.03664641  32.00634943   8.25777025  24.95152778
 121.90026399  31.69134085   8.24183153  25.77567559   6.78246606
  -8.53246716   3.30669415  -5.45393093   8.7247576   19.89140927
 231.8948036   12.61440927   6.68478475  93.95311163   0.58419425
   3.29640877   3.75177271 244.3031215    7.67988322   5.03450049
  -7.27827603   2.34260833 -14.60424385  25.95470667 114.54402357
 113.28904856  -2.93852516   2.37675618   7.82025863  21.17469648
  -2.2343718   -0.75487393  10.5206397    8.6448037   44.09178118
   1.13854484   1.35386195  -2.61636878  -1.13813709  -2.82314222
   9.06389259   2.09608901   6.16585695   3.51670334  27.33778333]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.8820516482174
gradient value of function right now is: [-1.58374273e+00 -8.38150428e-01 -6.79674885e-05 -6.13212282e-05
  1.58374273e+00  8.38150428e-01  6.79674885e-05  6.13212282e-05
 -4.28692853e-01  2.18760257e-02  1.79716203e-01  9.09261387e-02
  1.09800153e+00  2.20686278e-05 -4.16020136e-02 -4.48855933e-04
 -2.56171584e-04 -6.27466298e-05  4.96203355e-04 -8.85267188e-04
 -2.51277790e-04 -5.80920149e-05  5.21918735e-04 -8.21334742e-04
  1.76895409e-03 -6.82635713e-01 -5.39448915e+00 -1.10393223e-01
 -2.07294221e-03 -4.35803307e-15  8.23195441e-05  4.99681593e-05
  5.21366969e-02  7.64245708e-04  2.52186982e-03  5.87212727e-02
 -1.53576664e-02 -1.44397858e-05  2.43937290e-02 -9.42519748e-03
 -3.37699940e-02 -6.17517851e-02 -7.85550410e-03 -1.89699324e-02
 -1.56241145e-02 -2.35285375e-02 -1.99940926e+00 -4.95532664e+00
 -9.14814952e-03 -5.46385091e-03  8.02042300e-01  3.05118707e+00
 -4.88377276e-03 -2.05542303e-02 -6.56999061e-03 -3.73945596e-01
  6.36120429e-01 -3.22337412e+00  1.18772179e+00 -4.81296860e+00
 -5.71693819e-01  3.59151676e+00  5.43600874e-01 -1.01335518e+00
 -1.23626333e+00]
supnorm grad right now is: 5.394489152377826
Weights right now are: 
[ -2.70698627   6.96726904 -51.86696183 -53.4029552    2.96155498
  -7.07596073  52.2658991   52.68692681  -2.14158452  -1.18786976
   8.05840742  -2.56492947   6.22738633  55.82973794   5.23117653
  35.77333727 124.41351745  35.42425833   7.00045142  25.33360828
 124.25076129  35.11382917   6.98963141  26.21699812   6.82550264
  -8.31217951   3.33301736  -5.15478278   8.03650518  19.89140927
 233.23725137  12.96844597   7.04503294  98.85362689   0.29332003
   3.65333935   3.43088756 250.03380904   8.66154837   3.41942448
  -8.72408085   0.59056341 -17.38890568  24.73375065 117.11443445
 115.38747179  -2.88846965   2.3917241    9.78097711  23.27556725
  -2.60339201  -0.74076934  10.13582778   7.45154866  43.63493916
   1.50824438   0.89790338  -2.63503038  -0.92986851  -2.82380973
   9.50895269   2.04163943   6.22839777   3.54835251  27.15474758]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2420.27279178497
gradient value of function right now is: [-1.09464503e+00  4.66822480e-01 -1.79881693e-03 -1.80032951e-03
  1.09464503e+00 -4.66822480e-01  1.79881693e-03  1.80032951e-03
 -4.29329402e+00 -1.14322276e+00 -6.29951430e+00 -3.24208095e+00
 -6.65597059e-01  4.40079175e-04  2.85559714e+00  2.41106664e-02
 -8.91449940e-03 -5.95746294e-04 -1.83225683e-02 -2.18759294e-03
 -9.16740182e-03 -5.74201431e-04 -1.88864916e-02 -2.11042398e-03
 -2.17257740e-02  2.44058596e+00  7.99876138e+00 -6.34025510e-01
 -2.35364297e-02 -2.62965185e-15 -1.84575311e-03 -3.69943227e-03
  3.05719406e-01 -2.24015389e-02 -1.20867448e-01  6.06663639e-01
 -9.98989716e-02 -8.00789414e-04 -6.28512850e-01 -1.18318132e-01
 -1.30696568e-01 -2.13670203e-01 -3.77406436e-02 -9.58188888e-02
  1.55563640e-01  1.42931583e-01  1.57262757e+01  1.91941940e+01
  3.34285061e-01  4.91593519e-01 -1.78821761e+00  7.81717912e+00
 -9.51223064e-02 -1.98046100e-01 -5.45654801e-02 -2.67491944e+00
 -4.23362528e+00  3.49737475e+01 -6.71101289e+00  3.86692575e+01
  5.49068910e+00 -2.37553523e+01  1.68178076e+00 -1.94534443e+00
  2.86067341e+01]
supnorm grad right now is: 38.66925752549058
Weights right now are: 
[ -2.95749868   7.24757681 -53.98579983 -55.72410938   3.21206739
  -7.3562685   54.38473709  55.00808099  -2.70662842  -1.24111794
   7.45244513  -2.5503197    6.42681897  58.18963913   5.78977666
  34.57766322 122.73863269  37.49507239   7.50651483  26.8041716
 122.53521045  37.21237449   7.49697546  27.74199465   7.0198871
  -8.49267026   3.42224991  -4.2204807    6.86928964  19.89140927
 242.59460785  16.62980692   6.27244133  98.35218721   0.70879067
   3.63889947   4.55107682 254.11134273   8.83565183   4.93381199
  -8.62777686   0.64190872 -17.78609199  24.31088893 119.75981451
 117.62171976  -2.95927967   2.36132611   8.58044493  22.4494966
  -2.44000266  -0.59356678  12.04712002   8.72316158  44.58335716
   1.29109884   0.61519483  -2.5524664   -0.6576363   -2.72400893
   9.35289768   1.90829858   6.07978838   4.41990879  27.28747321]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2407.0886592320026
gradient value of function right now is: [ 5.15093551e+00  3.89574042e+00 -2.19853035e-03 -2.18364125e-03
 -5.15093551e+00 -3.89574042e+00  2.19853035e-03  2.18364125e-03
 -2.47312586e+00 -5.80592265e-01 -5.94411395e+00 -2.24310179e+00
 -4.58332730e+00  1.16005651e-03  3.85840443e+00  2.44709610e-02
 -8.17735777e-03 -1.10927877e-03 -4.19910774e-02 -3.96137748e-03
 -8.33329789e-03 -1.08385727e-03 -4.31782278e-02 -3.87151828e-03
  3.43141593e-02  6.63238293e+00  3.16910541e+01 -1.89777286e+00
 -1.21692922e-02 -1.38544753e-15 -8.77120499e-04 -2.46757102e-03
  4.95992182e-01 -2.73173366e-02 -1.29640580e+00  1.43590706e+00
 -1.83190498e-01 -5.34665294e-04 -4.68309944e-01 -1.88446940e-01
 -2.43776111e-01 -3.35395110e-01 -1.33712882e-02 -1.30913390e-01
  2.14127714e-01  1.86060079e-01  3.08953672e+01  4.79151221e+01
  2.84697154e-01  3.70323880e-01 -5.05873155e+00  1.14101539e+00
 -2.54080520e-01 -3.68610642e-01 -1.31581346e-01 -7.56664014e+00
 -5.74013895e+00  5.11237501e+01 -6.97531000e+00  4.91278029e+01
  1.31663901e+01 -5.94103844e+01  3.84014594e+00 -4.86485380e+00
  3.80663927e+01]
supnorm grad right now is: 59.41038438784494
Weights right now are: 
[ -2.69177562   7.05898338 -55.65133694 -57.44065017   2.94634433
  -7.16767507  56.05027421  56.72462179  -2.38759275  -0.88215688
   7.69387559  -2.33759101   6.55263491  56.52169945   6.15248983
  35.09439157 123.71895373  39.18670373   8.07268828  27.20463551
 123.57223073  38.90422366   8.06176541  28.13853555   7.52554295
  -8.28383395   3.33410555  -4.43072418   6.73606991  19.89140927
 249.09152071  16.50298208   6.39070353 100.04575359   0.54588029
   3.67433997   5.27185767 259.38843654   9.5258103    4.12782099
  -8.52159516   0.46638408 -16.36924277  25.36074802 122.16912187
 119.6156566   -2.90132349   2.57972354   9.94121259  23.13376004
  -2.97885806  -0.72949231  12.67268543   8.7999757   44.76942774
   0.96815884   0.43396039  -2.50851665  -0.30590178  -2.65593649
   9.67064879   1.86778405   6.68011304   4.32750493  27.11979089]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2422.9828188570723
gradient value of function right now is: [-1.98162910e+00 -1.34051085e+00  2.61628303e-04  2.57883021e-04
  1.98162910e+00  1.34051085e+00 -2.61628303e-04 -2.57883021e-04
  1.14502203e+00  6.65296350e-01  2.51289025e+00  1.50995312e+00
  1.87844525e+00 -1.66754750e-04 -1.00889145e+00 -6.44639518e-03
  8.67310778e-04  5.19508671e-04  3.24030394e-03  8.99014131e-04
  8.88014336e-04  5.06383058e-04  3.35215803e-03  8.76500215e-04
  3.62327391e-02 -2.37087391e+00 -1.23277299e+01  1.84524546e-01
  3.77044944e-03  7.37948582e-16  5.07984193e-04  1.61401399e-03
 -2.22069791e-01  2.64244975e-03  2.80979378e-02 -4.73163743e-01
  6.76261501e-02  9.50318631e-05  2.07511179e-01  7.61139372e-02
  1.22786604e-01  1.75106249e-01  1.23679377e-02  5.62722353e-02
 -8.72893551e-02 -1.03292557e-01 -1.23364278e+01 -1.62060129e+01
 -1.18416691e-01 -1.74203656e-01  1.28275484e+00  6.70090583e-01
  6.06886816e-02  1.15679040e-01  1.82313144e-02  6.49863910e-01
  1.96822415e+00 -1.91464724e+01  2.97918348e+00 -2.40257628e+01
 -2.81661945e+00  1.40626900e+01 -1.12916709e+00  1.13524534e+00
 -1.38640216e+01]
supnorm grad right now is: 24.025762849638085
Weights right now are: 
[-2.86632426e+00  6.77516975e+00 -5.42464092e+01 -5.61137531e+01
  3.12089297e+00 -6.88386144e+00  5.46453465e+01  5.53977248e+01
 -2.41806128e+00 -1.01984113e+00  8.05539722e+00 -2.56685951e+00
  6.76223483e+00  5.50886864e+01  5.51329023e+00  3.64130869e+01
  1.25429969e+02  4.17560376e+01  8.36355352e+00  2.89951224e+01
  1.25271663e+02  4.14545747e+01  8.32971488e+00  2.99163152e+01
  7.06037562e+00 -8.18185889e+00  3.23554592e+00 -5.15350532e+00
  5.28142487e+00  1.98914093e+01  2.58820919e+02  1.42681999e+01
  6.37383138e+00  1.04285701e+02  5.29151223e-01  2.64505957e+00
  4.32700839e+00  2.65974041e+02  9.17979824e+00  3.16880714e+00
 -5.96860098e+00  1.36886472e+00 -1.59773518e+01  2.69170523e+01
  1.24160787e+02  1.21465959e+02 -3.01908668e+00  2.48863403e+00
  1.01883921e+01  2.28563973e+01 -2.55336642e+00 -9.61969046e-01
  1.20397881e+01  9.27698994e+00  4.42691058e+01  9.70123506e-01
  1.12422356e-01 -2.85339857e+00 -7.70903467e-01 -2.82896071e+00
  9.77157010e+00  2.12714791e+00  6.57027284e+00  3.96474036e+00
  2.71456865e+01]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2424.191957458452
gradient value of function right now is: [-2.71012924e+00 -1.70659066e+00 -2.46320893e-04 -2.51071219e-04
  2.71012924e+00  1.70659066e+00  2.46320893e-04  2.51071219e-04
 -6.54597651e-02  1.17069658e-02  5.40585134e-01  4.05387068e-01
  1.92553042e+00 -3.82115029e-05  6.59075999e-01 -1.19549948e-03
 -1.86257639e-03  3.61699592e-05 -4.44241117e-03  6.42867983e-05
 -1.94352059e-03  3.57290472e-05 -4.64973087e-03  6.34711836e-05
  6.35961332e-03 -1.54930495e+00 -1.19183866e+01  1.43200740e-01
  2.27659241e-03  1.73804181e-15  1.79407163e-04  1.34745704e-03
 -2.68378871e-02 -1.05384234e-02 -1.63825840e+00 -2.72869452e-01
  7.18331486e-03  9.46881831e-06  4.73424148e-02  3.02281785e-02
  8.15037290e-03  1.74111565e-02  3.19408225e-03  1.21468737e-02
 -4.06288390e-02 -4.67558330e-02 -7.13724633e+00 -9.78082261e+00
 -1.04552339e-02 -4.34775755e-02  2.32952770e+00  3.04098262e+00
  2.95169467e-02  8.05712446e-02  1.25118485e-02  6.33462649e-01
  9.01854188e-01 -9.09170511e+00  1.36369050e+00 -1.05991904e+01
 -1.84517668e+00  8.62293754e+00 -5.57441162e-01  7.07757381e-01
 -3.91419860e+00]
supnorm grad right now is: 11.918386592562953
Weights right now are: 
[ -2.8093297    6.98254215 -55.40431965 -57.37701691   3.06389841
  -7.09123384  55.80325692  56.66098852  -2.56008819  -1.57347923
   7.85941041  -1.98120778   6.88997264  56.57489774   5.96236627
  35.74910854 125.50574356  42.67649565   5.77315578  30.50298388
 125.32173658  42.34227794   5.74231808  31.39854287   6.69682181
  -8.17060097   3.16446399  -4.94650157   5.55873026  19.89140927
 260.52133324  13.42255684   6.82496353 103.40294409   0.27512296
   3.06202318   4.66479823 267.16852922  10.97653415   2.457417
  -5.97422391   0.52346667 -18.22421329  26.25791416 126.715247
 123.42825836  -3.00374977   2.68170236  10.15409547  23.29217627
  -2.4102091   -0.83202352  11.15015723   8.66798287  45.49950709
   1.42996811   0.68110312  -2.77131328  -0.80058259  -2.844677
   9.61985694   2.12858983   6.31218517   4.10591652  27.22029609]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2423.5049738576176
gradient value of function right now is: [-1.95524341e+00 -6.79443889e-01  8.28541110e-05  8.32715134e-05
  1.95524341e+00  6.79443889e-01 -8.28541110e-05 -8.32715134e-05
 -1.27768963e+00 -3.25000475e-01 -5.09362615e-01 -6.24076557e-01
  1.01778211e+00 -2.74768083e-05 -5.07558899e-01 -3.06937757e-04
  3.55669522e-04 -2.63968074e-05  2.90380170e-03  6.20305894e-06
  3.65174844e-04 -2.72948112e-05  3.00617877e-03  5.03073155e-06
  1.13377221e-03 -1.18023720e+00 -6.63949960e+00  5.20002442e-02
  2.12670719e-03 -3.82018817e-18 -3.57218503e-04  1.64224084e-04
 -4.65661000e-03  5.78176297e-04  8.18229377e-01  9.26073275e-03
  4.02482340e-03  6.91862963e-05 -1.22507643e-03 -1.33141134e-03
 -9.78979775e-03 -8.32157793e-03 -2.93462071e-03 -4.14352749e-03
 -3.73019200e-02 -4.12151359e-02 -4.90661920e+00 -8.39625416e+00
  2.66257808e-02  3.03596613e-02  9.97817815e-01  1.78329308e+00
 -8.58250131e-04 -1.14293597e-03  8.21227743e-03  2.65741586e-01
  1.20342050e+00 -8.78857407e+00  1.31551018e+00 -9.44459233e+00
 -2.02134690e+00  9.32194177e+00 -9.42245991e-03 -9.35279059e-04
 -4.07459078e+00]
supnorm grad right now is: 9.44459233395124
Weights right now are: 
[-2.87476286e+00  7.29359292e+00 -5.44108849e+01 -5.64003611e+01
  3.12933157e+00 -7.40228461e+00  5.48098222e+01  5.56843328e+01
 -2.86983055e+00 -1.31440146e+00  7.60788537e+00 -2.37268506e+00
  6.85557556e+00  5.85733982e+01  5.86699320e+00  4.00170525e+01
  1.28009391e+02  4.35849402e+01  6.96845656e+00  3.15316570e+01
  1.27845763e+02  4.32421574e+01  6.96802801e+00  3.24281654e+01
  7.77209621e+00 -8.44574914e+00  3.21213243e+00 -5.78221826e+00
  5.36486017e+00  1.98914093e+01  2.64294527e+02  1.36741362e+01
  6.29929333e+00  1.06112540e+02  1.36214800e+00  3.32614332e+00
  5.28340218e+00  2.71466644e+02  8.94143472e+00  1.49106496e+00
 -5.98486837e+00 -2.38615635e-01 -1.79266317e+01  2.65065593e+01
  1.29507216e+02  1.25724670e+02 -3.15103309e+00  2.41204971e+00
  1.04371222e+01  2.39337150e+01 -2.61032679e+00 -8.19549283e-01
  1.03019277e+01  7.90396785e+00  4.71158185e+01  1.65731952e+00
  4.04822741e-01 -2.59187258e+00 -6.92988975e-01 -2.69050074e+00
  9.67761644e+00  2.12046484e+00  6.20859973e+00  4.01444659e+00
  2.70844164e+01]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2424.2950912123015
gradient value of function right now is: [-7.41867638e-01 -2.74298568e-01  5.48402539e-04  5.50914125e-04
  7.41867638e-01  2.74298568e-01 -5.48402539e-04 -5.50914125e-04
  4.47614568e-01  4.32937548e-01  1.36591596e+00  8.13239823e-01
  9.43753614e-01 -3.12029475e-04 -9.58685732e-01 -3.53427373e-03
  2.97748935e-03  3.13910788e-04  7.39998494e-03  4.07524208e-04
  3.07930990e-03  3.14010778e-04  7.66441672e-03  4.07678937e-04
  1.70432737e-02 -1.64146084e+00 -6.48884478e+00  3.04474771e-02
  5.79227251e-03  5.80673386e-15  2.74726819e-04  1.13312390e-03
 -1.27899331e-01  7.19690649e-03  9.17373527e-01 -1.01723655e-01
  3.70339358e-02  7.46525190e-05  8.88252876e-02  2.24207380e-02
  3.64839507e-02  8.98866152e-02  9.97818318e-03  3.46248898e-02
 -5.93676335e-02 -6.44852096e-02 -7.96901916e+00 -1.18333434e+01
 -5.59593909e-02 -9.47859162e-02  7.70708839e-01  6.50688106e-01
  1.42112509e-02  4.09464734e-02  1.15887658e-02  1.40160666e-01
  1.67309323e+00 -1.39207903e+01  2.46010026e+00 -1.62550252e+01
 -2.46159358e+00  1.18111071e+01 -3.61258963e-01  2.48622651e-01
 -9.31069066e+00]
supnorm grad right now is: 16.255025246293417
Weights right now are: 
[-2.61868513e+00  7.47552373e+00 -5.65584625e+01 -5.86375616e+01
  2.87325384e+00 -7.58421542e+00  5.69573998e+01  5.79215332e+01
 -2.49169919e+00 -8.98294060e-01  8.08555001e+00 -2.30933215e+00
  6.92631601e+00  5.79202550e+01  5.48832494e+00  3.96963567e+01
  1.26986796e+02  4.40320521e+01  6.08249515e+00  3.30760129e+01
  1.26824737e+02  4.36751790e+01  6.07630306e+00  3.39650485e+01
  6.95822691e+00 -8.50125348e+00  3.39471045e+00 -5.33236049e+00
  5.50804537e+00  1.98914093e+01  2.67018467e+02  8.32332601e+00
  6.27987076e+00  1.07274519e+02  7.12573101e-01  3.13480572e+00
  5.22321124e+00  2.74922517e+02  1.03549933e+01  2.72577356e+00
 -7.10251078e+00  1.84266222e-02 -1.78042688e+01  2.55718814e+01
  1.31594870e+02  1.27214463e+02 -2.99103060e+00  2.28735072e+00
  1.11785491e+01  2.53331550e+01 -2.46484537e+00 -8.07999855e-01
  1.10545566e+01  9.32999680e+00  4.58736194e+01  1.32045113e+00
  8.17673014e-01 -2.71581963e+00 -1.12896635e+00 -2.90485093e+00
  9.56025258e+00  2.07659640e+00  7.11394323e+00  3.72871203e+00
  2.72154216e+01]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2423.5021028900514
gradient value of function right now is: [-1.17795898e+00 -8.26167703e-01  6.31942384e-04  6.33373543e-04
  1.17795898e+00  8.26167703e-01 -6.31942384e-04 -6.33373543e-04
  1.37862607e+00  8.62317708e-01  2.79770696e+00  1.69795301e+00
  1.74842148e+00 -5.55921214e-04 -1.29392141e+00 -7.61124319e-03
  2.87622424e-03  1.08604818e-03  7.46665298e-03  8.04073585e-04
  2.97602237e-03  1.10455087e-03  7.73062125e-03  8.17794788e-04
  3.13887016e-02 -2.44958683e+00 -1.14591842e+01  2.06380234e-01
  2.20472149e-02  1.23699875e-14  6.73841387e-04  7.89524261e-03
 -4.26231218e-01  5.11367436e-03  4.45883099e-01 -4.40873399e-01
  8.85048924e-02  1.94943693e-04  2.35102097e-01  8.28246115e-02
  1.06162860e-01  3.17267918e-01  6.60770209e-02  1.15597072e-01
 -8.34755848e-02 -9.28598368e-02 -1.15686332e+01 -1.78523359e+01
 -7.96100769e-02 -1.78337497e-01  1.17007810e+00  9.42491357e-01
  3.93418498e-02  1.82742821e-01  1.39399110e-02  1.12575483e+00
  2.23059919e+00 -1.96297670e+01  3.03146860e+00 -2.35308953e+01
 -2.95430011e+00  1.53422982e+01 -1.06550551e+00  9.99750935e-01
 -1.39307059e+01]
supnorm grad right now is: 23.530895310817606
Weights right now are: 
[ -2.78555407   7.34365118 -55.48123271 -57.61718628   3.04012278
  -7.45234287  55.88016998  56.90115789  -2.30970716  -1.19396687
   7.88313325  -2.21157338   6.90088928  59.67367194   5.51878537
  41.36420481 128.05738426  45.78761626   6.15716012  35.8331354
 127.90947903  45.42644519   6.14989979  36.72561868   6.75463777
  -8.54653094   3.29354009  -5.09192614   4.98392107  19.89140927
 274.68466554  13.01642586   5.19436447 107.1535703    0.9364011
   3.31562344   5.52899304 277.18752556   9.22195627   2.34265369
  -8.061085     0.48054502 -19.27039936  24.00717974 134.19133837
 129.26290793  -2.95850186   2.31047164  10.5455388   25.34534045
  -2.52675315  -0.96871638  11.0877733    9.0919714   46.13008951
   1.15948074   1.31580259  -2.76506057  -1.06380162  -2.95057817
   9.66867909   1.9548989    6.43518497   4.88691107  27.15113181]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2426.6399510708543
gradient value of function right now is: [-2.74471547e-01 -2.42064206e-01 -4.47021243e-06 -3.38536937e-06
  2.74471547e-01  2.42064206e-01  4.47021243e-06  3.38536938e-06
  1.70053749e-01 -3.66787235e-02  3.13324627e-01  1.01428802e-01
  2.44127580e-01  5.27001952e-05 -1.88719709e-01 -9.11685629e-04
  1.42927852e-04 -3.44569907e-04  3.15564884e-04 -2.59759645e-04
  1.47983726e-04 -3.49439479e-04  3.30299222e-04 -2.63445972e-04
  1.52446844e-02 -3.74622767e-01 -1.77123789e+00  9.75341806e-02
  1.76017714e-02  2.81498428e-15  2.55240372e-05  6.05079435e-04
 -1.21335872e-02  1.42259902e-03 -3.34673120e-02 -7.85129594e-02
  1.43950424e-02  1.60734323e-05  3.14532793e-02  1.20816530e-02
 -2.07773256e-02 -3.52224107e-02 -3.41837385e-03 -2.74920246e-03
 -1.31396834e-02 -1.27038728e-02 -1.94105660e+00 -2.77215934e+00
 -1.42625141e-02 -3.27488950e-02  2.65385135e-01 -2.26418818e-01
  7.60792909e-03  2.82003836e-02  9.46019019e-03  4.00746361e-01
  2.53597459e-01 -3.03243956e+00  4.33474652e-01 -3.43621506e+00
 -8.89257200e-01  3.97189885e+00 -1.56909907e-01  3.20314348e-01
 -2.47145696e+00]
supnorm grad right now is: 3.971898854103117
Weights right now are: 
[ -2.80479031   7.37724272 -58.02057757 -60.2151813    3.05935902
  -7.48593441  58.41951483  59.49915291  -2.29218433  -1.72801805
   7.88320955  -1.92755253   6.83730733  59.7601042    5.26342607
  37.44258691 126.81243933  46.2148053    4.4504409   36.41104884
 126.69020047  45.81872722   4.4308221   37.29571522   8.0811772
  -8.50035134   3.33746894  -4.58240081   4.81298087  19.89140927
 280.90694454  11.36493276   4.99601893 106.33509271   0.53029377
   2.53966636   5.26040327 279.98020882  11.10873685   4.58438117
  -6.14845483   0.83951106 -14.15413954  27.28563693 136.49154559
 131.19256838  -3.01286778   2.46466352  11.17599687  25.49885641
  -2.29487167  -0.93496914  13.19797512  11.17105422  47.13055453
   1.25862448   0.40708451  -2.77742925  -1.30970158  -2.93313035
   9.52924625   2.01056212   7.0325483    4.03064093  27.11645392]
(65,)
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2426.6035984560203
gradient value of function right now is: [-2.73265578e-01 -2.17201897e-01  1.22716832e-05  1.31847462e-05
  2.73265578e-01  2.17201897e-01 -1.22716833e-05 -1.31847462e-05
  1.14948322e-01 -3.80475889e-02  2.55632700e-01  8.35337540e-02
  2.16210414e-01  6.31597875e-05 -1.82265380e-01 -7.87837475e-04
  1.82518090e-04 -2.57801375e-04  3.28958581e-04 -2.02229016e-04
  1.89084292e-04 -2.61890089e-04  3.41623105e-04 -2.05438910e-04
  1.15750071e-02 -3.46195053e-01 -1.59555664e+00  8.54142895e-02
  9.19687095e-03  2.47760638e-15  3.53361320e-05  4.67655077e-04
  3.36057329e-03  1.50361706e-03  9.23804389e-03 -4.57212421e-02
  6.78920243e-03  1.73313363e-05  2.40643664e-02  7.82869806e-03
 -1.72637727e-02 -3.27174296e-02 -6.25526841e-04 -2.03371938e-04
 -1.23077104e-02 -1.11635679e-02 -1.75743398e+00 -2.57554822e+00
 -1.19084917e-02 -2.69244980e-02  2.68852708e-01 -1.64894317e-01
  5.67783405e-03  1.86715232e-02  8.88249028e-03  3.18813576e-01
  2.15762650e-01 -2.84975433e+00  3.97306293e-01 -3.05597071e+00
 -8.27632802e-01  3.68820146e+00 -1.13416141e-01  2.74140976e-01
 -2.37109691e+00]
supnorm grad right now is: 3.6882014622105896
Weights right now are: 
[-2.46035939e+00  7.39462623e+00 -5.95125761e+01 -6.17723579e+01
  2.71492811e+00 -7.50331792e+00  5.99115133e+01  6.10563296e+01
 -2.61218511e+00 -1.30647157e+00  7.57077753e+00 -1.77042844e+00
  6.86243149e+00  5.84510431e+01  4.98901900e+00  3.74491911e+01
  1.25027897e+02  4.83966463e+01  5.37404850e+00  3.95575089e+01
  1.24895642e+02  4.79775094e+01  5.36255733e+00  4.04250356e+01
  6.48290583e+00 -8.60004485e+00  3.51470243e+00 -4.16096156e+00
  4.93350575e+00  1.98914093e+01  2.84601765e+02  1.12521991e+01
  4.98661303e+00  1.06730566e+02  3.37270974e-01  3.03957204e+00
  4.92961616e+00  2.86721818e+02  9.49748696e+00  4.19886450e+00
 -6.90271455e+00  1.58166192e-01 -1.67473528e+01  2.36027650e+01
  1.38992946e+02  1.32835333e+02 -2.95152690e+00  2.24747547e+00
  1.15233959e+01  2.65605693e+01 -2.81297489e+00 -1.07651755e+00
  1.40570291e+01  1.11406717e+01  4.71502256e+01  5.46962512e-01
  6.27551720e-01 -2.71528437e+00 -9.77192990e-01 -3.06455262e+00
  9.47531326e+00  2.02479511e+00  7.50744866e+00  3.84185217e+00
  2.70180745e+01]
(65,)
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2426.553394743306
gradient value of function right now is: [-3.25320315e-01 -2.46262208e-01  1.65705369e-05  1.74225286e-05
  3.25320315e-01  2.46262208e-01 -1.65705369e-05 -1.74225286e-05
  1.31906441e-01 -9.45131869e-04  3.01040748e-01  1.30735143e-01
  2.72833102e-01  5.30485474e-05 -1.90617029e-01 -9.16563076e-04
  1.81702729e-04 -2.13063593e-04  6.47680108e-04 -1.76819928e-04
  1.88113749e-04 -2.16624214e-04  6.71860970e-04 -1.79785462e-04
  1.27412573e-02 -4.05350474e-01 -1.91013370e+00  8.70272285e-02
  8.92783899e-03  2.05528023e-15  5.85512999e-05  5.46688416e-04
 -4.01568690e-03  1.38600715e-03  7.02898369e-03 -5.77467071e-02
  8.26613587e-03  2.49432418e-05  2.74211514e-02  9.61363695e-03
 -1.36431765e-02 -2.48885019e-02  1.20415974e-03  3.16550856e-03
 -1.25581704e-02 -1.18832369e-02 -1.93136738e+00 -2.96655918e+00
 -1.29659118e-02 -2.79820565e-02  3.04644140e-01 -1.80659947e-02
  6.54344703e-03  2.09990774e-02  9.07390436e-03  3.04356607e-01
  2.36597406e-01 -2.95269605e+00  4.29865569e-01 -3.26476673e+00
 -9.33796786e-01  4.11657578e+00 -1.36382265e-01  2.85656675e-01
 -2.46792620e+00]
supnorm grad right now is: 4.116575777567876
Weights right now are: 
[-2.68925029e+00  7.17501807e+00 -5.87495757e+01 -6.10097557e+01
  2.94381900e+00 -7.28370976e+00  5.91485130e+01  6.02937273e+01
 -2.58229649e+00 -1.56725735e+00  7.97367618e+00 -2.24307690e+00
  6.79531607e+00  5.85014262e+01  5.15237303e+00  3.93641426e+01
  1.29253488e+02  4.89258909e+01  5.36845892e+00  4.04953191e+01
  1.29136499e+02  4.84903010e+01  5.34785753e+00  4.13507028e+01
  6.82468529e+00 -8.31604702e+00  3.29884175e+00 -3.85385551e+00
  5.97307945e+00  1.98914093e+01  2.86237948e+02  1.42768451e+01
  5.56746866e+00  1.09044414e+02  5.24656489e-01  3.98700558e+00
  6.16083034e+00  2.90016580e+02  8.85513640e+00  1.34426872e+00
 -6.39960613e+00 -5.33172037e-02 -1.67852568e+01  2.34107998e+01
  1.41240348e+02  1.35092040e+02 -2.67376871e+00  2.35938928e+00
  1.08813681e+01  2.64823640e+01 -2.45210552e+00 -9.74708953e-01
  1.41821171e+01  9.42541382e+00  4.67640847e+01  6.45039527e-01
  3.40483298e-01 -2.74973671e+00 -1.18220382e+00 -2.87622119e+00
  9.73724596e+00  1.87460526e+00  6.95762370e+00  4.01882369e+00
  2.69283400e+01]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2426.54949510691
gradient value of function right now is: [-3.00009000e-01 -2.37690073e-01 -1.38604467e-05 -1.28209505e-05
  3.00009000e-01  2.37690073e-01  1.38604467e-05  1.28209505e-05
  1.31645147e-01 -1.56003300e-02  2.92861629e-01  1.13845632e-01
  2.45232027e-01  7.64664264e-05 -2.02701031e-01 -1.04122649e-03
  9.54247423e-05 -2.68867834e-04  5.14239448e-04 -2.46495885e-04
  9.95217358e-05 -2.73246198e-04  5.34343315e-04 -2.50526744e-04
  1.58022600e-02 -3.72105065e-01 -1.73648695e+00  9.56875558e-02
  1.16900262e-02  9.40780895e-16  4.14979723e-05  4.25875492e-04
 -7.64302043e-04  1.39117882e-03  5.55318544e-03 -5.47460779e-02
  1.04495766e-02  3.06367814e-05  3.27005062e-02  9.30247046e-03
 -2.23701303e-02 -3.68542933e-02  2.61486143e-05  5.44498314e-04
 -1.12451894e-02 -1.07757531e-02 -1.74792217e+00 -2.74400959e+00
 -1.41347919e-02 -2.83033930e-02  2.73389701e-01 -1.05054896e-01
  6.54886982e-03  1.86555870e-02  9.26112087e-03  3.24011460e-01
  2.19479364e-01 -2.67880535e+00  4.45340054e-01 -3.07895368e+00
 -9.32293572e-01  4.01890134e+00 -1.21313314e-01  2.95102388e-01
 -2.46996483e+00]
supnorm grad right now is: 4.018901335412409
Weights right now are: 
[-2.68594918e+00  7.60553619e+00 -5.90932049e+01 -6.13703403e+01
  2.94051789e+00 -7.71422788e+00  5.94921422e+01  6.06543119e+01
 -2.62337414e+00 -1.69516887e+00  8.06118364e+00 -2.46849752e+00
  6.73025271e+00  6.00189249e+01  5.63671873e+00  4.31438650e+01
  1.30164828e+02  4.93377451e+01  3.60737131e+00  4.12895021e+01
  1.30073138e+02  4.88869553e+01  3.60317340e+00  4.21394274e+01
  7.23688347e+00 -8.34203863e+00  3.44684329e+00 -3.53530767e+00
  6.37467501e+00  1.98914093e+01  2.92157220e+02  1.21216378e+01
  6.33383858e+00  1.10776633e+02  4.43230165e-01  3.39647057e+00
  4.98690771e+00  2.95275361e+02  8.76933649e+00  9.43664388e-01
 -5.27299883e+00  1.58188396e-01 -1.56196597e+01  2.40578852e+01
  1.43436008e+02  1.37216334e+02 -2.90675397e+00  2.39751689e+00
  1.08249414e+01  2.54458004e+01 -2.46389483e+00 -9.60295009e-01
  1.30676741e+01  9.23016383e+00  4.65206300e+01  1.16919767e+00
  5.69576124e-01 -2.81323161e+00 -4.96708434e-01 -2.89419544e+00
  9.78349281e+00  2.08675919e+00  7.12345753e+00  3.82426404e+00
  2.71045557e+01]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2426.555511095703
gradient value of function right now is: [-3.60913840e-01 -2.56692661e-01 -6.47942833e-07  4.72613205e-07
  3.60913840e-01  2.56692661e-01  6.47942837e-07 -4.72613201e-07
  8.71656266e-02 -9.78087176e-03  2.87713258e-01  1.20637855e-01
  2.85241440e-01  5.62787705e-05 -2.04266921e-01 -1.03561541e-03
  1.42529771e-04 -2.11248504e-04  5.13066624e-04 -2.29284032e-04
  1.48183917e-04 -2.13874163e-04  5.33461592e-04 -2.32161253e-04
  1.34554518e-02 -4.05307436e-01 -1.97401310e+00  7.64054688e-02
  9.82702803e-03  5.27589340e-16  4.74776478e-05  3.79685051e-04
 -3.21540791e-03  1.65185218e-03  4.09158462e-02 -3.33101354e-02
  1.05090842e-02  2.85118493e-05  3.29515284e-02  7.10860851e-03
 -1.74299835e-02 -3.00042426e-02  1.32418924e-03  2.01157859e-03
 -1.22236183e-02 -1.25290679e-02 -1.91360125e+00 -2.99676925e+00
 -1.41261274e-02 -2.69416306e-02  3.07627807e-01 -4.69563485e-03
  5.18820336e-03  1.35541898e-02  8.59765981e-03  2.58810386e-01
  2.84441570e-01 -2.96135928e+00  5.34868568e-01 -3.49377112e+00
 -9.38487745e-01  4.17730747e+00 -7.73719190e-02  2.00087401e-01
 -2.49911335e+00]
supnorm grad right now is: 4.177307465950343
Weights right now are: 
[-2.84298317e+00  7.32244266e+00 -6.10257856e+01 -6.33255291e+01
  3.09755188e+00 -7.43113435e+00  6.14247229e+01  6.26095008e+01
 -2.58547122e+00 -1.53604097e+00  7.81431096e+00 -2.73807404e+00
  7.04745654e+00  6.14528772e+01  5.79342726e+00  4.52628644e+01
  1.27962204e+02  4.95924041e+01  6.57927877e+00  4.01079973e+01
  1.27918754e+02  4.91509290e+01  6.59279639e+00  4.09863775e+01
  9.34640911e+00 -8.36792665e+00  3.21530284e+00 -3.74601363e+00
  5.65394239e+00  1.98914093e+01  2.97919920e+02  1.30664950e+01
  5.57811994e+00  1.11146328e+02  3.99921799e-01  2.90361835e+00
  5.36496056e+00  2.99555645e+02  8.72281733e+00  2.74119363e+00
 -6.46186950e+00 -1.35418953e-01 -1.79295591e+01  2.20965884e+01
  1.45673389e+02  1.38818107e+02 -2.93004786e+00  2.39315000e+00
  1.06539219e+01  2.55420135e+01 -2.52564247e+00 -8.08974919e-01
  1.41305549e+01  1.09377424e+01  4.51543879e+01  4.05237542e-01
  5.29716103e-02 -2.77609785e+00 -6.97366243e-01 -2.89460375e+00
  9.47708415e+00  2.12889133e+00  7.13686285e+00  3.87861083e+00
  2.73948287e+01]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1488.2492748037903
W_T_median: 1296.1013043627186
W_T_pctile_5: 741.6571019358539
W_T_CVAR_5_pct: 640.6964544558854
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.2
F value: -2426.555511095703
-----------------------------------------------
7434e+01  3.04326811e+01
  1.29694120e+01 -1.03983333e+00 -9.90180510e+00  4.22376967e+01
  6.91331568e+01  2.25030512e+00  3.10004963e+01  3.80399481e+00
  6.86302709e+01  2.55658339e-01  4.50174468e+01  1.42927296e+02
  7.82335409e+01 -5.22114474e+00  5.09438758e+00  1.03000404e+00
  1.13752054e+02  5.49376940e-01  1.97269200e+00  7.58984026e+01
 -5.20049110e-01  5.52725461e+00  2.89011454e+00 -5.83409166e+00
  1.40101136e+00 -2.61249058e+00  1.29830158e+01  6.17005048e+00
 -1.36902389e+01 -4.16111213e+00 -6.95476561e-01 -2.71471346e+00
  2.71814019e+01]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.263970286001
gradient value of function right now is: [ 9.31689186e-02 -1.15073331e-03 -9.58834867e-02 -1.17717774e-03
 -9.31689186e-02  1.15073331e-03  9.58834867e-02  1.17717774e-03
  2.59700987e-02  1.69763240e-01  1.52988070e-01  3.97826685e-01
  1.13054837e-12  2.65814444e-08  3.82745226e-09 -3.15778444e-03
 -1.51023825e-07  3.23207218e-02  7.03721810e-01 -6.10150717e-03
  1.36603018e-12  3.73849512e-08  5.20962711e-09 -4.43390856e-03
 -2.29899556e-17  6.61074994e-05  3.92909090e-05  8.15211687e-04
 -3.37874587e-02 -7.00575835e-01 -8.43552874e-02  1.66498231e-02
  1.47292079e-02 -1.01538849e-01  7.05003300e-03 -2.10996720e-02
  6.76498389e-04  1.23663249e-01 -7.11558006e-04  6.59955972e-02
 -3.85183072e-03 -7.62212310e-01 -9.59652994e-03 -6.38029901e-03
 -2.42512703e-03 -1.75186616e-01 -2.28457710e-01 -5.62229089e-03
 -9.78915488e-03 -1.48952083e+00  1.24405976e-01 -1.19731788e-02
 -4.53947082e-02  1.91764332e-01  1.12002872e-01 -6.85648424e-02
  3.09844440e-01 -2.45685064e+00 -2.10740625e-01  4.60754556e-01
  3.40651198e-01 -1.70272858e+00  2.61364504e-01 -3.30427481e+00
 -2.67574609e+00]
supnorm grad right now is: 3.3042748139155274
Weights right now are: 
[-5.40172500e+00 -1.68628760e+01  6.89249015e+00 -2.36225801e+01
  4.66742628e+00  1.68196283e+01 -6.39817320e+00  2.20866918e+01
 -5.03581728e-01 -6.17182537e+00  7.25934742e+00  3.83797488e+00
  4.81858368e+01  9.65865441e+01  5.11515998e+01  3.67569020e+01
  8.23608142e-01  2.17098676e+01  1.48268804e+00  1.52347475e+01
  4.70331681e+01  1.05163710e+02  5.96562528e+01  3.63397015e+01
  4.04653201e+01  2.89452938e+02 -3.44830181e+01  1.01469061e+02
 -1.90289270e+01  6.04403439e+00 -1.99454667e+01  3.06188446e+01
  1.28727468e+01 -1.05388653e+00 -9.43504563e+00  4.29161028e+01
  7.53158316e+01  1.94076525e+00  3.14654844e+01  3.95461949e+00
  6.91801464e+01  9.19826814e-02  4.68453024e+01  1.45158357e+02
  7.86822632e+01 -5.34700903e+00  5.26796938e+00  1.12381696e+00
  1.16181886e+02  5.79996725e-01  1.60410801e+00  7.67731876e+01
 -1.52597150e-01  4.88700805e+00  3.07565641e+00 -6.09434519e+00
  1.23898566e+00 -2.59421505e+00  1.29408999e+01  6.33971625e+00
 -1.33915017e+01 -4.01554982e+00 -9.54403200e-01 -2.88873250e+00
  2.72359285e+01]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.2766627742944
gradient value of function right now is: [ 8.75568549e-02 -1.15794329e-03 -9.30039152e-02 -1.18792224e-03
 -8.75568549e-02  1.15794329e-03  9.30039152e-02  1.18792224e-03
  2.64287041e-02  1.60014656e-01  1.45374803e-01  3.81201137e-01
  1.00644784e-12  2.17333079e-08  3.21519752e-09 -3.14721212e-03
 -1.37990371e-07  3.15760201e-02  6.97205445e-01 -7.19142339e-03
  1.22563486e-12  3.07215171e-08  4.39546451e-09 -4.42496323e-03
 -1.99814416e-17  6.63474550e-05  4.17749788e-05  8.09213880e-04
 -3.58558036e-02 -6.92022120e-01 -8.26080596e-02  1.56432608e-02
  1.69338208e-02 -8.69824629e-02  9.86063350e-03 -2.03336308e-02
  7.26113273e-04  1.33815673e-01 -9.69366191e-04  7.25214231e-02
 -4.17024046e-03 -8.24492934e-01 -1.02295790e-02 -6.72822821e-03
 -2.64024415e-03 -1.77369788e-01 -2.24217982e-01 -5.82165414e-03
 -9.58515475e-03 -1.43922247e+00  1.32195641e-01 -1.13196435e-02
 -4.73367002e-02  1.87350455e-01  9.68289941e-02 -7.34822753e-02
  3.14917726e-01 -2.49441903e+00 -2.04601791e-01  4.48918386e-01
  3.42556341e-01 -1.73798245e+00  2.51468456e-01 -3.31799446e+00
 -2.56036649e+00]
supnorm grad right now is: 3.3179944563813213
Weights right now are: 
[-5.13947995e+00 -1.52719130e+01  7.47457116e+00 -2.20051667e+01
  4.40518123e+00  1.52286653e+01 -6.98025421e+00  2.04692784e+01
 -2.06552579e+00 -5.39780430e+00  7.75857839e+00  4.17154432e+00
  4.81858364e+01  9.66354378e+01  5.11537527e+01  3.90321846e+01
  6.78188170e-01  2.08320068e+01  1.44119331e+00  1.47307583e+01
  4.70331676e+01  1.05236750e+02  5.96596127e+01  3.85573593e+01
  4.04653201e+01  2.92904483e+02 -3.55191428e+01  1.01957857e+02
 -2.00248025e+01  6.24903148e+00 -2.02062174e+01  3.24217319e+01
  1.17891663e+01 -1.11987358e+00 -1.01216660e+01  4.24741956e+01
  7.55456005e+01  2.02624443e+00  3.10339959e+01  3.55979033e+00
  7.10290929e+01  7.18500425e-02  4.53323063e+01  1.48118931e+02
  7.91143022e+01 -5.36529691e+00  4.86637107e+00  9.79556019e-01
  1.17697051e+02  5.53611391e-01  2.10276134e+00  7.68472423e+01
  1.03029306e+00  5.17786029e+00  3.24325128e+00 -5.89809294e+00
  1.38881460e+00 -2.60251662e+00  1.31800571e+01  5.78592797e+00
 -1.41133153e+01 -3.93285317e+00 -1.57442570e+00 -2.77173287e+00
  2.67727962e+01]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1486.4042453672557
W_T_median: 1294.1660642431611
W_T_pctile_5: 740.6786082633973
W_T_CVAR_5_pct: 641.6327552275663
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.2
F value: -2425.2766627742944
-----------------------------------------------
