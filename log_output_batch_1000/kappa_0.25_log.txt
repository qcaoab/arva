Starting at: 
2022-06-17 22:26:16
tracing parameter entered from terminal:  0.25


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.1582714360068
gradient value of function right now is: [-0.02429953 -0.8313539   0.38322636  0.15357138  0.02429953  0.8313539
 -0.38322636 -0.15357138 -0.22463383  0.08861725  0.08347705 -0.02316164
  0.2345526  -0.09375701 -0.09128409  0.0382677  -1.5221048   0.37694793
  0.37706087 -0.25715342 -0.88516571  0.22770202  0.22381556 -0.14537166
 -0.02533156  0.08945333  1.43408645 -0.02372942 -0.38850874 -0.01759761
 -0.18018583 -0.09715358 -0.96816115 -0.04145257 -0.42445811 -0.24840377
  0.30224292 -0.03019851 -0.7707876   0.08718751 -0.11579356 -0.49390349
 -1.52947489 -0.12127802  0.06453996  0.27439657  0.56820947  0.06989964
  0.26909048  1.28293255  3.71771218  0.2882397  -0.06447971 -0.36193454
 -1.26768642 -0.06791113  1.20364559 -2.94810777  1.2622368  -3.85756537
 -0.51781383  1.29218966  1.10898407 -2.70868854 -9.38619115]
supnorm grad right now is: 9.38619114813767
Weights right now are: 
[ 1.3260949  -0.63202118  2.32506536  1.45769685 -1.07152619  0.52332949
 -1.92612809 -2.17372524  4.54143141  3.68262972  3.75285744 -1.17926951
  3.82947923 -2.31194609 -1.58788395 -0.99720409  2.23432632  0.53028669
  2.98687022 -5.23968315  3.03529336  1.10287887  3.95787772 -3.32242398
  6.38745344 -3.55230264 -0.3868044   7.91910393 -1.59349277  4.1671948
  6.09126912 -3.73815159 -1.63504699  6.52944618  6.53808234 -4.54032826
  2.76495777  2.46938513  3.3612505   2.95486398  8.50325785  5.44928662
 -2.16142552  7.9389637  -5.97937636  2.30604859  4.1723677  -3.87432611
 -8.38320662  0.54912108  1.60823292 -6.89950143 10.39753919 10.66374504
 -1.78732346 10.59988431  2.07465969 -2.57382175 -2.45160372 -1.90536202
 -1.74700299  1.76537854  1.79171737 -2.59837648 31.0159167 ]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1206.1425149683
gradient value of function right now is: [ 1.05894966e-01  1.10708135e-02  1.66003086e+00  5.65203940e-01
 -1.05894966e-01 -1.10708135e-02 -1.66003086e+00 -5.65203940e-01
 -2.02205568e-01 -8.71096373e-03 -1.64630661e-02 -4.54960922e-02
  1.38912105e-01  1.55245157e-02 -7.13449065e-02  9.03728031e-02
 -2.87603377e+00 -1.67459824e-01 -3.52899460e-01 -7.11332013e-01
 -1.02197333e+00 -5.35088566e-02 -1.36351071e-01 -2.35157436e-01
  1.90370994e-01  1.12532424e-01  2.82211465e+00  1.29220251e-02
  4.81084636e-03 -7.15779886e-06  5.07750147e-02 -6.10490273e-02
  1.63929489e-01  2.49702308e-03  3.12823653e-01 -1.11191192e-01
 -3.28691898e-01 -2.21033785e-02 -1.07769900e+00  3.66338290e-02
 -7.14685710e-02 -4.51084634e-02 -2.16614554e-01 -7.19478647e-02
  9.20633831e-02  2.47291695e-01  3.24065479e-01  9.38703236e-02
  1.09749245e-01 -1.26582229e-01  4.38955992e-01  1.10018937e-01
 -6.17302535e-02 -1.49236905e-01 -9.51114826e-01 -6.10711779e-02
  4.72535732e-01 -1.87484561e+00 -8.32177046e-02 -1.63465883e+00
 -1.85218275e-01  6.62811261e-01  4.12398856e-01 -1.70429487e+00
 -1.83268947e+01]
supnorm grad right now is: 18.326894741492943
Weights right now are: 
[  1.84651661  -1.74313684   2.82402048   1.70645749  -1.59194789
   1.63444515  -2.42508321  -2.42248588   6.4889522    6.24994758
   7.66833217  -0.20280407   8.69757055  -3.52998029   1.07281035
   2.46220234   2.34805548   1.13944189   1.95242297  -4.30478522
   3.81484692   2.09286636   5.45297446  -1.36004878   7.52083641
  -4.29347967  -0.35876612   8.38994587   1.35141932   7.43972305
   9.4257271   -6.90056904  -1.7813292    7.36801377   6.72293999
  -6.55593093   2.83353052   2.42220359   3.90303627   2.23525866
  14.65090094   4.10461328  -1.93076147  13.85448243  -5.9123087
   1.01695058   6.12657503  -3.66702724 -10.29160347   0.40118533
   1.59824027  -8.69480565   9.45178421  13.81507966  -1.76273266
   9.8636038    2.56648588  -2.63464336  -3.70441792  -2.10413924
  -1.93838057   1.70230233   2.44308455  -2.65831321  30.95483695]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.8321415678583
gradient value of function right now is: [-6.80171984e-02 -1.68027254e-01 -5.88629329e-02 -8.90558372e-02
  6.80171984e-02  1.68027254e-01  5.88629329e-02  8.90558372e-02
 -8.24381697e-03  1.70313625e-03  6.29545831e-02  1.24218553e-02
 -6.30350891e-02  9.32754144e-02  4.08686495e-02 -4.84423154e-02
 -1.36906108e+00 -5.13218307e-02  3.91270725e-01 -2.65018761e-02
 -2.33526588e-01  4.03198108e-03  1.90752358e-01  1.72276727e-02
  5.15269881e-02  1.04407265e-01  1.61373313e+00  6.15840440e-03
  2.15428665e-01  5.98261698e-04  6.09171918e-02  1.40786939e-01
 -6.96843238e-01 -8.12527011e-03 -7.31893649e-01 -1.26572836e-01
  1.88884547e-01 -7.41055569e-03 -1.98927938e-03  1.82553843e-02
 -1.30381989e-01 -4.81721109e-01 -1.95622211e+00 -1.32735257e-01
  7.74367182e-02  2.65720995e-01  3.48471894e-01  8.13195353e-02
  1.47698375e-01  6.10668367e-01  1.89327743e+00  1.50848082e-01
 -4.84610564e-02 -1.27186608e-01 -2.85665463e-01 -4.86461283e-02
  7.76433691e-01 -3.32647126e+00  4.15215382e-01 -2.18208225e+00
 -4.00251754e-01  1.31931415e+00  7.11319398e-01 -3.07771377e+00
 -2.69965969e+00]
supnorm grad right now is: 3.326471259453904
Weights right now are: 
[  1.97572416  -2.33456915   3.18147901   1.69008826  -1.72115545
   2.22587746  -2.78254174  -2.40611665   9.16216704   8.29458382
   9.51956726   3.14664341  12.73123615  -5.42810116   2.92827296
   4.80820827   2.42688772   1.32125693   2.36279347  -3.88760649
   4.89271359   2.78413989   6.4388252    1.27381096   6.51221502
  -4.21580867  -0.10740866   8.25847835   2.39992182  10.49934367
  11.88213431  -9.27861094  -3.18988212   7.9848001    6.91483749
  -9.20477979   3.56378176   5.03584982   4.02713149   1.02659571
  15.80157215   3.4019005   -1.91139238  15.04213672  -5.45172426
  -1.66280478   7.24096268  -2.95919239 -11.40497848   0.11059497
   1.79313696  -9.73101918  10.49794095  16.88586412  -1.68081199
  11.041343     2.85699988  -2.75237161  -4.26134527  -2.45512621
  -2.35415225   1.39109238   2.5681553   -2.79063158  31.10737211]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.7889504709378
gradient value of function right now is: [-3.42930978e-02 -2.61311982e-03 -2.43168006e-01 -1.00143381e-01
  3.42930978e-02  2.61311982e-03  2.43168006e-01  1.00143381e-01
  3.17388655e-03  4.93315762e-04  1.09173844e-02  3.94805947e-03
 -5.03379442e-02  1.26912595e-01  3.78792370e-01 -2.62218652e-02
 -7.42728066e-01 -8.12282560e-03  1.19190705e-01  2.58369428e-01
 -4.95727246e-02  5.25057118e-03  8.58456606e-02  2.94440432e-02
 -9.48491280e-03  8.22110690e-02  1.11193738e+00  1.03984722e-03
  3.11301909e-01  3.03280233e-04  7.85381843e-02  1.54654063e-01
 -4.22222087e-01 -7.23088555e-03 -4.78105883e-01  1.32259897e-03
  1.37605411e-01 -2.28821079e-04  1.38864965e-01 -3.37922396e-02
 -7.89112042e-02 -4.52965220e-01 -1.43641570e+00 -8.35358828e-02
  6.09230598e-02  1.84900015e-01  2.50276312e-01  6.37454739e-02
  6.50020012e-02  7.86920163e-01  9.84555336e-01  7.22393347e-02
  1.75384562e-02  6.66109977e-02  9.67808511e-01  1.75797991e-02
  5.46598031e-01 -1.28955950e+00  7.94513631e-02  9.46232207e-01
 -3.42330022e-01  4.85155330e-01  5.14779660e-01 -1.20942109e+00
  4.64139720e+00]
supnorm grad right now is: 4.64139719724242
Weights right now are: 
[  1.16874767  -3.05003525   3.65169154   1.47540678  -0.91417896
   2.94134356  -3.25275427  -2.19143516  12.85700119  12.14387979
  11.82358607   8.06495889  16.83007289  -5.96713891   3.79653838
   6.52637123   2.48598984   1.65502602   2.82023797  -3.22993726
   6.3035861    4.05992861   7.10128803   4.64136905   7.82220516
  -4.21360456  -0.04254237  10.64983862   1.77037735  12.67985107
  12.53018083 -10.56966239  -3.53991122  10.2433866    7.65654267
 -10.35491003   4.32684404   5.77521082   4.14446169   0.03298044
  16.20712758   3.23051826  -1.67485448  15.58033944  -6.16835244
  -1.84075862   7.62857562  -2.98957359 -12.00516043   0.13585762
   2.00699018 -10.1231208   10.34656167  20.46047292  -1.28461679
  11.28528814   2.94305765  -2.9397299   -4.06604147  -2.57505768
  -2.01354958   1.32139095   2.59118297  -2.95967196  31.14745812]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.2072268893637
gradient value of function right now is: [-2.04432731e-03 -7.38255968e-03  8.21868535e-01  1.24440804e-02
  2.04432731e-03  7.38255968e-03 -8.21868535e-01 -1.24440804e-02
 -3.67445687e-05 -1.73614228e-05  6.75293078e-07  4.65544308e-04
  1.66227079e-03 -2.48658936e-02 -6.06715488e-02  5.99361823e-04
 -2.27745276e+00 -3.55912465e-02 -2.27645778e-01 -4.23694648e-01
 -2.01882371e-02 -3.53895901e-04 -3.51856158e-03 -2.98173435e-03
  8.43513520e-02  1.16003323e-01  1.66493997e+00 -9.08767346e-04
 -3.33662046e-02  4.56205712e-04  5.71525269e-03 -2.48860500e-02
  1.12789761e-01  5.43302170e-03  1.88703171e-01 -5.94272914e-03
 -7.11422902e-02 -1.72684603e-02 -4.22492406e-01  6.28827617e-03
 -1.17769018e-02 -3.33270550e-02  4.32711687e-02 -1.37689702e-02
  7.10520970e-02  3.24885410e-01  3.66430565e-01  7.97913956e-02
  6.72548888e-03 -2.59483463e-01 -3.14150960e-01  6.91829876e-03
 -3.58859158e-03 -3.05214469e-02 -2.53118303e-01 -4.21026998e-03
  2.34336630e-01 -2.10764115e-01  1.10683600e-01 -5.72831748e-01
 -2.07308467e-01  1.90307961e-01  1.76189733e-01 -1.45268021e-01
 -9.11388627e+00]
supnorm grad right now is: 9.113886270890099
Weights right now are: 
[ 2.59613148e+00 -3.38403468e+00  4.02972969e+00  1.11597088e+00
 -2.34156276e+00  3.27534299e+00 -3.63079243e+00 -1.83199926e+00
  1.57213381e+01  1.68578989e+01  1.52567522e+01  1.11017174e+01
  2.15579569e+01 -6.46712955e+00  4.38900159e+00  8.66314856e+00
  2.58179542e+00  2.36863664e+00  3.39537909e+00 -3.00184950e+00
  9.04358812e+00  6.45735097e+00  9.01923755e+00  8.56142916e+00
  8.36035541e+00 -4.52508189e+00  2.85565309e-02  1.19217031e+01
  1.55404171e+00  1.62097214e+01  1.34442071e+01 -1.17139783e+01
 -3.85036331e+00  1.24186170e+01  8.20680217e+00 -1.28412413e+01
  4.84559513e+00  6.48589717e+00  3.87079892e+00  5.85506526e-01
  1.67720368e+01  3.27649381e+00 -9.77181730e-01  1.62535497e+01
 -6.99342412e+00 -2.17551305e+00  7.41324472e+00 -2.63600676e+00
 -1.33057096e+01 -3.10989119e-01  2.07727157e+00 -1.12868532e+01
  1.03087818e+01  2.31669848e+01 -1.30037362e+00  1.17001973e+01
  3.16400545e+00 -2.74252804e+00 -4.05432861e+00 -2.94515887e+00
 -2.32617959e+00  1.05016266e+00  2.69391097e+00 -2.82027877e+00
  3.10421019e+01]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.3290423237818
gradient value of function right now is: [-9.09528861e-03  2.60335113e-02 -4.41885695e-01 -1.64497358e-02
  9.09528861e-03 -2.60335113e-02  4.41885695e-01  1.64497358e-02
  1.16697585e-02  7.96768964e-05  1.84136243e-03  4.97091452e-03
 -5.00835217e-03  5.65497057e-02  1.31934002e-01  2.48831754e-03
  8.21796924e-01 -3.71162518e-02 -1.64611962e-01  1.18489597e-01
  6.22080206e-03  1.12618437e-06  2.94068596e-04  2.14623791e-03
 -6.70687697e-02  7.12027314e-03 -1.07354458e+00 -9.65619637e-03
  1.01196054e-01  6.95562651e-04  6.05429241e-02  5.12864810e-02
  4.74973053e-02  7.11755547e-04  1.94260004e-02 -4.05643822e-04
 -4.05072629e-02  4.93861157e-03  2.48693002e-01 -1.24219028e-02
  4.63232042e-02  3.80018457e-01  6.48775093e-01  5.45928096e-02
  1.75667989e-02 -6.99438222e-02 -7.52211632e-02  1.44734810e-02
 -1.31428042e-02 -7.46483057e-01 -1.06288260e+00 -2.21750575e-02
  1.86698968e-02  3.38051707e-02  4.65881037e-01  1.77853671e-02
 -3.67662656e-01  6.19096170e-01 -3.45191225e-01  1.23166106e+00
  2.51833442e-01 -3.38438568e-01 -5.06470997e-01  7.02253156e-01
  1.12643182e+01]
supnorm grad right now is: 11.264318154613061
Weights right now are: 
[  5.09595639  -3.47115261   3.8728939    0.8309075   -4.84138768
   3.36246092  -3.47395663  -1.54693588  18.71188652  20.37761497
  16.73388792  11.64401146  24.79675718  -6.39497172   4.83355042
  10.50562041   2.89993303   2.68632867   3.71756711  -2.71433063
  14.33818456  10.83099847  11.88923697  13.54768496   8.93793562
  -4.33722371   0.09204485  14.47427554   1.25160844  16.5006989
  13.46199851 -12.47520377  -3.89313005  12.65636539   8.62055742
 -14.59049022   5.33302142   8.7307482    3.75468597   1.07980955
  16.05544283   2.8717853   -0.70795136  15.76314401  -6.55110203
  -2.53984302   7.88348875  -1.06566329 -14.11608357  -0.69222505
   2.02878354 -11.94001948   9.06241935  26.23566969  -0.95632597
  11.1118536    3.39471766  -2.99867956  -3.7705786   -2.84653004
  -2.07993985   0.99616401   2.6774366   -3.08711774  31.18651986]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -1206.3980546365005
gradient value of function right now is: [-1.69685410e-02 -1.77203657e-01  9.36323983e-01 -1.76851374e-02
  1.69685410e-02  1.77203657e-01 -9.36323983e-01  1.76851374e-02
  7.16312586e-04  1.32498040e-03  2.27353853e-02  7.70518119e-03
 -2.61162446e-02 -8.39503694e-02 -3.56701082e-01 -4.99323043e-02
 -3.18276109e+00  5.78806347e-02  7.04668346e-01 -4.97303153e-01
  1.30778064e-04  2.22733165e-04  3.74095474e-03  1.23211457e-03
  2.55726474e-01  1.80180100e-01  3.62464199e+00  2.45928278e-02
 -1.92927647e-01 -1.24061017e-03 -1.37947142e-01 -7.34348655e-02
 -2.83795855e-01 -1.74760963e-03 -2.88414283e-01 -6.81939290e-02
  1.62327885e-01 -1.94737942e-02 -4.46743948e-01  5.60445298e-02
 -1.55498721e-01 -8.66260079e-01 -2.67770728e+00 -1.51801678e-01
  1.23808288e-01  5.52839494e-01  6.93140884e-01  1.34595570e-01
  1.09856097e-01  2.23833064e-01  2.27713552e+00  9.88259272e-02
 -8.24739142e-02 -1.65441826e-01 -1.64598246e+00 -7.30783003e-02
  9.84156242e-01 -4.07275047e+00  1.00575810e+00 -5.36637784e+00
 -6.97692452e-01  2.21742146e+00  7.99331453e-01 -3.54657121e+00
 -2.20999303e+01]
supnorm grad right now is: 22.099930301525355
Weights right now are: 
[  5.13855464  -3.52614405   3.85346742   0.42235565  -4.88398592
   3.41745236  -3.45453015  -1.13838403  21.78666591  23.06474565
  18.0192968   12.62698208  27.65108002  -6.80564361   5.22281543
  11.92045524   2.79728541   2.99726369   3.08188535  -2.50370945
  20.28869171  15.57640937  16.194678    18.67533594   9.9190578
  -4.60325637   0.37919277  13.78192217   1.07712325  17.61085069
  13.22764754 -14.09020716  -3.76511713  14.54527359   9.01527596
 -15.86297221   6.17307536   9.18183669   3.42374386   0.85114987
  15.78848503   2.92988624  -0.62792356  15.59163568  -7.62826602
  -2.5777691    7.92966596  -1.11569728 -15.43847491  -0.56755641
   2.22118521 -13.0843601    8.48221564  28.25790613  -0.9305919
  11.0836608    3.60669234  -2.91358123  -4.38500949  -3.08361969
  -2.31466346   0.88478248   3.13007334  -3.09622218  31.01321259]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1206.6600071836158
gradient value of function right now is: [ 5.62200723e-02  3.39409018e-01  1.40900595e+00  3.93995200e-02
 -5.62200723e-02 -3.39409018e-01 -1.40900595e+00 -3.93995200e-02
 -2.65250205e-02 -2.32876809e-03 -4.79545417e-02 -1.84475357e-02
  4.61932874e-02  1.27073253e-01  6.52464201e-01  6.32911668e-02
 -5.71693314e-01 -1.89260045e-01 -1.73657031e+00  5.41877344e-02
 -4.44165264e-03 -4.14841881e-04 -8.76341835e-03 -3.27159648e-03
 -1.06123777e-01  1.08899203e-01  9.72159177e-01 -1.51104258e-02
  4.46950132e-01  3.22114800e-03  3.17287692e-01  9.88045060e-02
  7.65361149e-01  8.07636876e-03  8.06836328e-01  8.17928249e-02
 -3.22819363e-01  2.20411010e-03 -1.12262055e-01 -4.16964837e-02
  6.46070794e-02  1.11877357e+00  3.32876065e+00  5.38960424e-02
  8.57291194e-02  8.36854923e-02  2.11244961e-02  8.74802617e-02
 -1.80638960e-01 -1.50609906e+00 -5.95321641e+00 -1.47589630e-01
  8.33677509e-02  1.88296827e-01  1.99099529e+00  6.53195179e-02
 -8.00513093e-01  4.36290288e+00 -1.79231705e+00  7.72216233e+00
  7.99559884e-01 -3.40342455e+00 -7.48436590e-01  3.45183558e+00
  1.75780387e+01]
supnorm grad right now is: 17.578038734041453
Weights right now are: 
[  5.45500301  -3.6411522    3.82262862   0.95281975  -5.2004343
   3.53246051  -3.42369135  -1.66884813  22.64172205  25.35817556
  19.14937805  13.94130721  31.64261043  -6.97471947   5.66848394
  13.40394422   2.61093569   3.77722869   3.21341287  -2.24708386
  23.9838635   19.51226046  19.65558249  23.09462441  10.39438559
  -4.02180613   0.26109832  15.80932875   0.81290644  19.0141419
  13.39362402 -14.6482357   -3.99669881  15.17566916   9.26943061
 -17.89378609   7.11103389  10.61378655   3.50952204   0.21896745
  14.87596147   3.15648542  -0.56627295  14.71478197  -7.09958067
  -2.79047065   8.20414154  -0.12386419 -17.07524771  -0.74590408
   2.14152989 -14.71553233   7.15128734  30.11137466  -0.53467926
  10.20768497   3.74597865  -3.01413164  -4.57420624  -3.12289708
  -2.03898609   0.74075956   3.42609556  -3.29698891  31.15766818]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.7744036606616
gradient value of function right now is: [ 3.67298644e-02  1.43319186e-01  9.26433580e-01  1.51182303e-02
 -3.67298644e-02 -1.43319186e-01 -9.26433580e-01 -1.51182303e-02
 -1.50170900e-02 -1.05170777e-03 -2.01857367e-02 -8.65503828e-03
  3.09944032e-02  5.74356936e-02  3.10071855e-01  2.93690219e-02
 -6.15007577e-02 -1.15157978e-01 -1.05037356e+00 -1.12633538e-01
 -4.15865683e-04 -2.98221461e-05 -6.57703385e-04 -2.72656279e-04
 -1.68864547e-02  4.25934264e-02 -1.72470082e-01 -8.56919689e-03
  2.24716652e-01  2.15144422e-03  2.00909123e-01  6.07612210e-02
  4.56433630e-01  6.13104599e-03  5.59509036e-01  2.67194917e-02
 -2.23158947e-01  9.05340878e-04 -3.40681835e-02 -1.88844180e-02
  4.86587155e-02  7.19698218e-01  2.10569382e+00  3.96241032e-02
  3.41160819e-02 -4.72590778e-02 -5.47659487e-02  3.20157181e-02
 -1.03648534e-01 -1.70063960e+00 -4.28448822e+00 -8.40706905e-02
  3.76458860e-02  7.20850981e-02  9.59738799e-01  2.83361417e-02
 -1.01924998e+00  2.33449997e+00 -1.34503272e+00  3.87114742e+00
  8.49632121e-01 -1.77101616e+00 -8.26140540e-01  1.82099925e+00
  1.33831712e+01]
supnorm grad right now is: 13.383171202261108
Weights right now are: 
[ 4.47591997e+00 -4.38498187e+00  3.78707683e+00 -8.90115485e-03
 -4.22135126e+00  4.27629018e+00 -3.38813957e+00 -7.07127228e-01
  2.49663205e+01  2.58511530e+01  2.04104625e+01  1.59619847e+01
  3.52142701e+01 -7.56739783e+00  6.08632394e+00  1.49307414e+01
  2.62479306e+00  3.99054211e+00  3.36540010e+00 -2.44925708e+00
  3.03004836e+01  2.37572210e+01  2.51492045e+01  2.99524520e+01
  1.05149167e+01 -4.24037065e+00  1.37857171e-01  1.69020894e+01
  1.61984101e+00  1.90518166e+01  1.31167299e+01 -1.58732031e+01
 -4.72237942e+00  1.55213872e+01  9.99002212e+00 -1.90957209e+01
  7.85560679e+00  1.22067555e+01  3.47445552e+00  3.69129675e-01
  1.50373397e+01  3.20297706e+00 -4.04440857e-01  1.48052921e+01
 -8.36421292e+00 -2.43490435e+00  8.26926462e+00 -1.15826520e+00
 -1.88496411e+01 -8.06180988e-01  2.13376795e+00 -1.66922492e+01
  6.15810622e+00  3.15648577e+01 -3.82221866e-01  9.58493258e+00
  3.42972269e+00 -2.99493698e+00 -4.04607550e+00 -3.36381822e+00
 -1.96773239e+00  6.83775921e-01  3.38425362e+00 -3.28068301e+00
  3.11570450e+01]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1206.9462894079325
gradient value of function right now is: [ 1.42343819e-02  2.14430967e-03  1.81933748e+00  2.73332956e-03
 -1.42343819e-02 -2.14430967e-03 -1.81933748e+00 -2.73332956e-03
 -1.13035299e-02 -3.30284730e-04 -7.46740083e-03 -8.00018293e-03
 -1.24369010e-03 -2.46837900e-02 -6.00732197e-02 -2.41118649e-04
 -3.09920505e+00  5.17918356e-02  4.68888026e-01 -8.94507090e-01
 -5.87000761e-04 -2.52950505e-05 -5.05874653e-04 -4.91640520e-04
  3.19195799e-01  1.02557113e-01  3.50916657e+00  4.09175780e-03
 -1.19669563e-01  3.64226326e-04 -1.79358857e-02 -8.82692744e-03
 -2.61115371e-01  1.92968335e-03  6.04569387e-02  1.69316450e-02
 -6.43678548e-02 -1.99950684e-02 -1.09518777e+00 -7.17211206e-03
 -1.07733302e-01 -1.62979820e+00 -2.72963266e+00 -8.48911597e-02
  7.53145182e-02  3.61459494e-01  4.17428294e-01  6.84772475e-02
 -1.19465171e-03  3.43358730e-01  1.36534612e+00 -2.22603470e-03
  1.25307399e-02  5.29497591e-03  8.41939776e-02  8.99530105e-03
  9.53557588e-01 -9.00907322e-01  9.53119077e-01 -1.21228665e+00
 -6.02831727e-01  6.48325847e-01  6.07863487e-01 -5.56027799e-01
 -4.66335724e+00]
supnorm grad right now is: 4.663357235106169
Weights right now are: 
[ 6.12079998e+00 -3.35982835e+00  3.69473180e+00  1.58184886e+00
 -5.86623127e+00  3.25113665e+00 -3.29579453e+00 -2.29787724e+00
  2.56841867e+01  2.63580174e+01  1.96184418e+01  1.55425828e+01
  3.80588216e+01 -8.20859540e+00  6.51430876e+00  1.68845935e+01
  2.76585838e+00  4.16164227e+00  3.45390959e+00 -2.74014618e+00
  3.28928550e+01  2.68771486e+01  2.84861796e+01  3.29167391e+01
  1.08546783e+01 -4.04051174e+00  2.28858830e-01  1.62262235e+01
  1.60803583e+00  1.90111609e+01  1.27692226e+01 -1.74039626e+01
 -5.00083520e+00  1.69508710e+01  1.00247909e+01 -2.09493589e+01
  8.27686209e+00  1.23492653e+01  2.69195910e+00 -2.16572170e-02
  1.55923579e+01  2.22307976e+00 -2.63091389e-01  1.52980249e+01
 -8.18205129e+00 -2.61733977e+00  8.91696754e+00 -8.58666463e-01
 -2.00543426e+01 -6.71977103e-01  2.41169682e+00 -1.80505362e+01
  5.26731036e+00  3.29160451e+01 -4.19003832e-01  8.91263519e+00
  3.55707415e+00 -2.92628017e+00 -4.39895890e+00 -3.37054449e+00
 -2.09758992e+00  9.26355680e-01  3.72374215e+00 -3.27871143e+00
  3.11205408e+01]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1205.9519951991222
gradient value of function right now is: [ 3.87731682e-03  5.34844612e-02  2.60327555e+00 -7.03331329e-04
 -3.87731682e-03 -5.34844612e-02 -2.60327555e+00  7.03331329e-04
 -9.01038218e-03 -4.80051153e-05 -9.48742580e-05 -2.47308653e-03
  3.23019637e-03  9.49704904e-02  1.86566602e-01  5.67957555e-03
 -3.19688829e+00 -7.59443349e-02 -5.02679401e-01 -7.97119078e-01
 -3.83968361e-05  3.06427498e-06  5.48717441e-05  1.87797346e-05
  3.67454990e-01  1.20108649e-01  3.72098045e+00  8.03333380e-04
  1.49087385e-01  1.09576830e-03  1.33077045e-01  5.37888209e-02
  1.89106445e-01  3.13109307e-03  2.86763591e-01  9.61410064e-03
 -2.31676845e-01 -2.29161993e-02 -1.18478320e+00 -1.57727010e-02
 -9.37145859e-02 -9.99357908e-01 -1.07582191e+00 -7.24502624e-02
  8.35579203e-02  4.69668467e-01  4.96536519e-01  7.38659149e-02
 -1.56423421e-02 -6.51217588e-01 -1.70248143e+00 -7.80087100e-03
  1.36456110e-02  3.07361367e-02  6.97034173e-01  7.71597706e-03
  5.08833280e-01 -1.57580169e-01 -1.67880600e-01  1.30200876e+00
 -2.12334007e-01 -3.32945835e-01  2.92933199e-01 -1.12130178e-01
 -8.65085847e+00]
supnorm grad right now is: 8.650858468891016
Weights right now are: 
[ 4.90502859e+00 -3.26076353e+00  3.56942688e+00  3.16354684e-01
 -4.65045988e+00  3.15207184e+00 -3.17048962e+00 -1.03238307e+00
  2.92924124e+01  2.71069082e+01  2.03777881e+01  1.80299035e+01
  4.12763942e+01 -7.89050509e+00  6.89537535e+00  1.82508182e+01
  2.65072659e+00  3.63983493e+00  3.38668660e+00 -3.04093585e+00
  4.55302882e+01  3.08568539e+01  3.59170491e+01  4.40645399e+01
  1.12460681e+01 -4.23614631e+00  2.36722976e-01  1.60186629e+01
  1.66851460e+00  1.92717960e+01  1.24382267e+01 -1.80195384e+01
 -4.82749020e+00  1.80395196e+01  1.01981637e+01 -2.25407425e+01
  8.97486329e+00  1.43895049e+01  2.67539659e+00 -3.66394295e-01
  1.44971937e+01  2.21595172e+00  3.25031912e-02  1.40257503e+01
 -8.13327039e+00 -3.12800537e+00  9.08041059e+00 -9.58673160e-02
 -2.15283125e+01 -1.03499452e+00  2.11046413e+00 -1.98698893e+01
  4.53968869e+00  3.37066217e+01  1.92883768e-01  8.53086489e+00
  3.70603560e+00 -3.06379238e+00 -4.73865888e+00 -3.35642227e+00
 -1.94197530e+00  6.87473605e-01  3.92662580e+00 -3.49847451e+00
  3.10351153e+01]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1205.3670000878978
gradient value of function right now is: [-2.56421452e-02 -1.07309260e-01 -3.02703940e+00 -2.28437579e-03
  2.56421452e-02  1.07309260e-01  3.02703940e+00  2.28437579e-03
  1.41260328e-02  3.87337387e-04  2.93654985e-03  8.81082711e-03
 -1.72756103e-03 -2.18928187e-01 -4.10598350e-01 -2.14947326e-02
  4.74387203e+00  6.69375656e-03  1.66055835e-02  9.73408537e-01
  3.59004428e-04  1.85106469e-05  1.23137340e-04  2.76924621e-04
 -4.39051701e-01 -8.29975484e-02 -6.61662897e+00 -1.14010969e-02
 -2.05972824e-01 -1.83869275e-03 -3.56470146e-01 -2.02627925e-01
  1.42744256e-01 -1.00665610e-03 -6.69412037e-02 -2.86070498e-02
  1.77761618e-01  1.78592048e-02  1.63455619e+00  9.44449714e-02
  1.85701408e-01  1.63373734e+00  3.01903909e+00  1.45932624e-01
 -5.49185658e-02 -4.10052340e-01 -4.75923755e-01 -4.81827727e-02
  4.24191008e-02 -5.17362304e-01  1.25563625e-01  2.80893256e-02
 -9.74185255e-02 -9.23766204e-02 -2.52552744e+00 -6.61827394e-02
 -1.20774400e+00 -2.60531890e-01 -5.45464911e-01 -2.18314952e+00
  5.54083302e-01  4.96776002e-01 -7.74842589e-01 -4.54347557e-01
  1.29332633e+01]
supnorm grad right now is: 12.933263284497285
Weights right now are: 
[  4.5596994   -3.53267474   3.41575502   1.14332288  -4.30513068
   3.42398305  -3.01681775  -1.85935127  29.97972279  29.46457898
  22.22518377  19.2396861   44.40152281  -9.08559851   6.31088282
  20.25285081   2.9759467    4.40740676   3.86168977  -2.70701141
  47.27562417  36.09166785  43.13344614  47.51198366  11.47246676
  -4.32858937   0.05996254  14.89230915   1.38717606  15.82195474
  11.32093697 -19.88455167  -5.26340637  17.41924281  10.49675805
 -24.19327163   9.52081537  18.23212534   2.86398078  -1.39702241
  14.71448108   2.48308704   0.40049866  14.08274037  -7.94419001
  -3.11944171   9.51710453   0.72542549 -23.23642703  -0.95097914
   2.30579851 -22.12130939   3.97267548  33.63370835  -0.06821189
   8.48760971   3.65626962  -3.00166851  -4.93236518  -3.82410843
  -1.96419073   0.67578481   3.86713752  -3.35694638  31.18817202]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.213442765545
gradient value of function right now is: [ 9.00626991e-02  2.35821057e-01  1.53154349e+00  1.13605933e-02
 -9.00626991e-02 -2.35821057e-01 -1.53154349e+00 -1.13605933e-02
 -2.70478147e-02 -5.02504913e-03 -3.43765417e-02 -1.86366015e-02
  2.97639847e-02  4.53769646e-02  2.19503547e-01  2.90981361e-02
 -8.21159564e-01 -1.22066248e-01 -5.91098777e-01 -2.18975533e-01
 -1.32661773e-03 -2.08841702e-04 -1.46935884e-03 -1.00663224e-03
 -1.30318771e-04  4.22382479e-02  9.35081096e-01 -5.65301848e-03
  2.58139879e-01  1.99710375e-03  3.55282707e-01  3.59072414e-02
  3.41169875e-01  3.77322763e-03  6.34507338e-01  3.61441795e-02
 -1.73759591e-01 -3.60932781e-03 -3.09884068e-01 -1.42443658e-02
  2.16333881e-02  4.17548952e-01  1.68760047e+00  1.04087899e-02
  3.54543950e-02  6.12980406e-02  6.95468045e-02  3.13591462e-02
 -1.15684206e-01 -1.31647199e+00 -3.73246653e+00 -7.84749550e-02
  4.88721278e-02  8.08336628e-02  9.75776162e-01  3.40389772e-02
 -8.19686878e-01  2.91652089e+00 -9.36249798e-01  3.50712396e+00
  6.51508897e-01 -1.59549393e+00 -5.42637439e-01  2.08687169e+00
  1.13776714e+01]
supnorm grad right now is: 11.377671353685171
Weights right now are: 
[  5.07583278  -3.39845795   3.37064526   1.64260698  -4.82126407
   3.28976626  -2.97170799  -2.35863536  31.33917355  31.02133127
  22.43613875  19.54484224  46.48641227  -8.69078447   6.25506718
  21.6654956    2.86810751   4.44390498   3.5131689   -2.9367515
  50.45234898  39.09668848  46.44564818  49.29040642  12.40949002
  -4.17966262   0.32358611  15.83329796   0.79213654  12.14737924
  10.83535344 -20.74811622  -5.35967111  15.57199692  10.12226666
 -25.00721959  10.15828845  19.58179028   2.76572256  -1.51457231
  14.53171176   1.79671504   0.34345495  13.91787068  -8.04075221
  -3.82944503  10.44219954   0.73842844 -24.56990837  -0.82800872
   2.14140648 -23.72888429   3.52593283  34.93513661   0.68502611
   8.0312722    3.46274754  -3.1609784   -4.80040433  -3.74368729
  -1.61679808   0.33758646   3.86815177  -3.50383674  31.15700956]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.2729335037968
gradient value of function right now is: [-4.05910250e-02  1.26775361e-02 -9.04807948e-01 -4.57133707e-03
  4.05910250e-02 -1.26775361e-02  9.04807948e-01  4.57133707e-03
  1.79299430e-02  4.18797796e-04  2.51675005e-03  1.09908298e-02
 -4.48313286e-03 -3.17511315e-02  2.62395543e-02  2.26609710e-03
  5.03946116e-01 -4.00201258e-02 -3.62285167e-01  2.36846336e-01
  9.35434480e-04  2.92066513e-05  2.44052820e-04  6.90782406e-04
 -2.31494884e-01 -3.50245730e-03 -1.02873974e+00 -2.94751801e-02
  1.91738768e-02  2.04769939e-04  3.96690314e-02 -1.39506435e-03
  6.72634332e-02 -1.83589938e-04  4.55402694e-03  2.53477034e-02
 -8.61348911e-03  3.76256838e-04  1.15803932e-01 -2.60046944e-02
  9.70754920e-02  5.73499538e-01  1.81928892e+00  7.41333772e-02
 -4.02395055e-04  3.69687013e-03 -1.18665238e-02 -1.13464148e-03
 -3.11509693e-03  1.40804671e-01 -1.69159429e-01 -1.86097821e-03
  4.20419790e-02  4.00953362e-02  4.56029613e-01  3.16693565e-02
 -1.93154671e-01  1.36170623e+00 -3.36911432e-01  1.48283025e+00
 -1.12035045e-01  2.22296392e-01 -1.68335416e-01  1.12983217e+00
  9.06782444e+00]
supnorm grad right now is: 9.067824442498614
Weights right now are: 
[ 4.28036672e+00 -2.89626365e+00  3.15821213e+00  1.86250601e+00
 -4.02579801e+00  2.78757196e+00 -2.75927486e+00 -2.57853440e+00
  3.47342809e+01  3.36609350e+01  2.32140058e+01  2.19096228e+01
  4.77668313e+01 -9.93255587e+00  6.53709361e+00  2.36076229e+01
  3.03178928e+00  3.21305979e+00  3.00073264e+00 -2.61882910e+00
  5.39881486e+01  4.27803691e+01  4.85015987e+01  5.13912608e+01
  1.29296912e+01 -4.41444900e+00  2.76637439e-01  1.43427547e+01
  1.23728321e+00  7.78304658e+00  1.06631177e+01 -2.28745420e+01
 -6.52845815e+00  1.38254125e+01  9.55634023e+00 -2.61760146e+01
  1.01709567e+01  2.26321719e+01  2.53974722e+00 -3.05052227e+00
  1.43324277e+01  1.75914095e+00  7.28133383e-01  1.38663777e+01
 -8.91961779e+00 -4.07893810e+00  1.08574772e+01 -4.84533839e-02
 -2.65122736e+01 -8.89853703e-01  2.18002529e+00 -2.60453766e+01
  4.41211218e+00  3.53363946e+01  7.41496385e-01  9.01101894e+00
  3.89270254e+00 -3.10447632e+00 -4.33581017e+00 -3.98119486e+00
 -1.85377539e+00  5.61966761e-02  4.14044656e+00 -3.40727221e+00
  3.11636892e+01]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1206.433649791745
gradient value of function right now is: [-1.35026833e-01 -4.34427020e-01 -1.87933323e+00 -1.87896451e-02
  1.35026833e-01  4.34427020e-01  1.87933323e+00  1.87896451e-02
  2.34518069e-02  4.19648438e-03  4.59222847e-02  1.32318041e-02
 -1.78048513e-02 -1.75461869e-01 -4.43051812e-01 -2.16534127e-02
  1.51421867e+00  4.20489142e-02  3.56878344e-01  1.29538025e-01
  4.79266150e-04  5.63828454e-05  5.64126704e-04  2.66081211e-04
 -1.00612511e-01 -1.36163222e-01 -2.54098772e+00  1.46205365e-02
 -3.14478308e-01 -1.68037437e-02 -5.86900010e-01 -1.94780743e-01
 -1.21620032e-01 -1.81160702e-02 -6.04531784e-01 -1.03409033e-01
  9.20392648e-02  1.13010011e-02  4.26709530e-01  5.62924229e-02
  2.74209818e-02  5.86337195e-01  3.51147073e-01  2.34673784e-02
 -9.90356990e-02 -2.40827001e-01 -2.83068666e-01 -9.04824995e-02
  9.55858699e-02 -1.75328163e-01  1.07165908e+00  7.30713104e-02
 -1.37973486e-01 -1.81472285e-01 -2.45483763e+00 -1.03730089e-01
 -5.82964689e-02 -3.20842693e+00  7.66796656e-01 -6.12391488e+00
  3.80431327e-01 -3.57538584e-01  1.20242579e-01 -2.94227305e+00
  5.90994624e+00]
supnorm grad right now is: 6.123914878762596
Weights right now are: 
[  4.38782333  -2.55960088   3.07189794   0.25509726  -4.13325462
   2.45090919  -2.67296067  -0.97112564  37.84734473  34.62779256
  22.82435649  20.83337612  49.51276702 -10.40908661   6.88880102
  25.84419976   2.99531317   3.23340905   2.99068972  -2.22757033
  60.93875155  47.3065001   54.45095294  54.23955222  12.75634647
  -4.39916546   0.31752221  15.65162607   0.9697718    3.39170949
  10.16045887 -24.32897232  -7.70974405  11.73339544   9.18962635
 -25.81493492  10.88281535  24.54451073   2.73898833  -3.65336107
  14.54206164   1.45239492   1.1335635   13.91075396  -9.51529031
  -4.74827653  11.61902461  -0.74370055 -28.19758951  -1.04003989
   1.88261212 -28.08643389   5.54479548  36.39912364   1.03530736
  10.09322155   3.5316113   -3.33713017  -3.52278895  -4.07343129
  -1.54559178  -0.73642502   3.95450185  -3.58875082  31.20317497]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.1889451769468
gradient value of function right now is: [-7.53241842e-02 -2.63452134e-01 -1.13826875e+00 -1.20209288e-02
  7.53241842e-02  2.63452134e-01  1.13826875e+00  1.20209288e-02
  2.01569863e-02  1.69113961e-03  2.38682344e-02  5.31645299e-03
 -1.47229165e-02 -9.72983743e-02 -2.83404140e-01 -7.81845155e-03
  6.42194938e-01  3.77450839e-02  6.06026522e-01 -5.04117818e-02
  6.22449074e-04  2.59683516e-05  2.79890018e-04  1.63730776e-04
 -3.34184831e-02 -1.59497264e-01 -1.55711516e+00 -1.31992938e-02
 -2.35947838e-01 -3.91884534e-02 -3.92492399e-01 -1.04538267e-01
 -3.25564161e-01 -4.19545502e-02 -6.42542819e-01 -5.49306034e-02
  3.19153238e-02  1.00719154e-02  5.15078956e-03  1.48599526e-02
  4.68763280e-02 -8.67939120e-01 -9.20983551e-01  4.68926702e-02
 -9.05416890e-02  1.46477879e-01 -2.63987605e-02 -8.57110424e-02
  4.90736107e-02  2.74881367e-01  1.12519552e+00  3.93300513e-02
 -3.75430117e-02 -8.27623198e-02 -7.40423578e-01 -2.95524147e-02
  5.56977652e-01 -9.66431158e-01  1.23144305e+00 -3.50176129e+00
 -4.31162638e-01 -7.30699121e-01  4.16932724e-01 -1.07350120e+00
  4.69109602e+00]
supnorm grad right now is: 4.691096020441833
Weights right now are: 
[  4.33814888  -2.335081     2.944794     0.45234902  -4.08358017
   2.22638931  -2.54585673  -1.1683774   41.03216021  34.4887103
  22.120913    21.40929166  49.75663182 -10.62861726   7.52848722
  28.54312327   3.03700086   6.14637875   3.72791991  -3.43521976
  65.57562903  50.30545245  58.5258706   55.60351379  12.17697756
  -3.33219765   0.30622601  17.82133455   0.62048049  -0.24962474
   9.92215285 -25.31482893  -9.38543616  10.12076718   8.60016155
 -24.98245541  10.38782353  27.33928937   1.89361696  -5.16835637
  14.56306592   0.67966228   1.4399291   13.9966807   -9.43022676
  -5.20609022  12.61015889  -0.77856679 -30.16764124  -0.65750662
   1.81266483 -30.40157747   6.23778166  37.17435783   1.76219391
  10.55656033   3.54146448  -3.43049749  -3.38865613  -4.09088323
  -1.16000704  -1.33641083   3.90173235  -3.59439225  31.1916496 ]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.3444280886185
gradient value of function right now is: [ 8.19668209e-02  1.50336773e-01 -2.65664691e-01  1.08784709e-02
 -8.19668209e-02 -1.50336773e-01  2.65664691e-01 -1.08784709e-02
 -5.98264164e-03 -1.82667927e-03 -2.84068342e-02 -4.14490680e-04
 -3.02208477e-04  1.08114604e-02  4.37965545e-02 -6.87823991e-04
  3.77416148e-01  6.34331924e-03  1.79412986e-01 -1.80135964e-02
 -1.20880214e-03 -1.72759117e-04 -2.48146880e-03 -1.19555529e-04
  4.07285454e-02 -6.66147659e-02 -6.72426345e-01  3.79398934e-03
  3.79331732e-02  1.31344434e-02  1.05617578e-01  2.45691103e-02
 -2.57940743e-02  3.11719787e-02  2.13213944e-01  5.71500881e-02
  8.46075457e-03  2.43407983e-03 -1.51325102e-02 -7.33965365e-04
  5.84671259e-02 -1.24928350e+00 -8.56385210e-01  5.74052050e-02
 -4.21837652e-02  6.55505354e-02 -7.43897301e-02 -4.01824186e-02
 -2.67521610e-02  9.60748518e-01  6.83985563e-01 -2.54952515e-02
  4.03240399e-02  8.55381068e-02  4.20214441e-01  3.50762918e-02
  2.81131135e-01  1.99601107e+00  1.36013230e-01  2.46153513e+00
 -2.60676279e-01 -3.77470903e-01  1.31817111e-01  1.80214711e+00
  8.56636870e+00]
supnorm grad right now is: 8.566368702445615
Weights right now are: 
[  4.88814996  -2.55512769   3.16266931   2.9388409   -4.63358125
   2.44643599  -2.76373204  -3.65486928  41.86205102  35.56099863
  21.25663563  19.95157446  52.1432108  -11.16260933   7.67490576
  31.18669862   3.33227525   6.69049147   4.38424238  -3.2840048
  69.79324941  53.75969     62.81998867  54.67353919  12.39714918
  -2.86353178   0.36523649  18.14977181   0.56472605  -1.77964012
   9.43208957 -26.80461449 -10.99188231   7.9261173    8.36014329
 -23.19287864  11.22104513  31.90641893   2.50693353  -4.96140921
  14.82020457   0.58389061   1.48184999  14.65030947  -9.18145877
  -5.7330914   13.35439028  -0.56211364 -32.37861006  -0.67619169
   1.40957859 -32.70742234   6.85188607  38.09421345   1.73432377
  10.9615213    3.65227642  -3.57314088  -4.46383417  -3.70657682
  -1.62729502  -1.41418834   4.10888418  -3.68876461  31.1765492 ]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.4155298311427
gradient value of function right now is: [-1.61306683e-01 -3.94700850e-01 -5.99713254e-01 -8.31534472e-03
  1.61306683e-01  3.94700850e-01  5.99713254e-01  8.31534472e-03
  2.14894293e-02  1.28649856e-03  8.96607054e-02  2.94133129e-03
 -2.78410676e-02  3.09699329e-04 -1.95756557e-01 -4.07668165e-03
 -1.09859708e+00  1.79540455e-02  1.05422467e+00 -6.16395890e-02
  1.09478729e-03  4.66408778e-05  3.14588477e-03  1.37062313e-04
  9.60443313e-02  1.97816744e-01  2.56866105e+00  7.16713752e-03
 -5.78521299e-02 -5.32070485e-03 -1.34449156e-01 -8.69804495e-03
 -8.00881263e-01 -1.04703558e-01 -2.11005953e+00 -1.35667989e-01
  1.66215114e-02 -4.24976544e-03 -1.92159736e-01  2.83525351e-03
 -1.63701951e-01 -1.14926507e+00 -2.55589759e+00 -1.42665665e-01
  1.42318741e-01  4.06021314e-01  4.92849136e-01  1.33367885e-01
  7.87476012e-02  6.31585206e-01  1.71480711e+00  6.81036705e-02
 -6.49793927e-02 -1.46818508e-01 -7.97854238e-01 -5.78690627e-02
  1.27006652e+00 -4.64813072e+00  1.32912044e+00 -5.97448209e+00
 -1.10227181e-01 -9.95741604e-01  9.07324278e-01 -4.16962420e+00
 -1.66849486e+01]
supnorm grad right now is: 16.684948619522558
Weights right now are: 
[  4.1757749   -2.44687381   3.05746857   3.6155343   -3.92120619
   2.33818212  -2.6585313   -4.33156268  45.17414605  36.24510445
  21.28834726  24.51381467  52.77135536 -11.19530487   8.97435616
  31.06803815   3.40513699   7.70316928   3.57890719  -3.5788657
  70.16225325  58.59448006  65.87784731  53.85992365  12.07961681
  -2.48552694   0.55986971  16.9226113    1.01910175  -0.41860723
  10.43981293 -26.68210682 -11.39825901   6.43658209   8.11207286
 -22.84249206  13.01459139  37.83669195   2.16424891  -2.70184352
  13.55630806   0.34128721   2.03018388  13.48419734  -8.29438275
  -6.23415971  14.17238604   0.28462133 -34.89007969  -0.66807549
   1.03542061 -35.1569162    9.0753222   39.28485701   1.65851631
  12.76147782   3.43064334  -3.7271951   -3.46689984  -3.74307681
  -1.4610467   -1.40021032   3.76641088  -3.81854349  31.04852184]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1206.8360876974941
gradient value of function right now is: [ 2.75563322e-01  4.81969935e-01  4.12382488e-01  2.55531271e-02
 -2.75563322e-01 -4.81969935e-01 -4.12382488e-01 -2.55531271e-02
 -6.63390700e-02 -1.69456352e-03 -1.47831181e-01 -3.32379626e-04
  4.18504745e-02  4.50321959e-02  2.52177586e-01  2.01648208e-04
  1.26201494e+00 -9.42972629e-03 -7.36767856e-01  1.00845633e-01
 -4.70125279e-03 -4.96260444e-05 -4.04548913e-03 -2.31511871e-05
  1.76844253e-01  1.45293475e-02 -2.14820298e+00  1.64452788e-02
  1.08102174e-01  4.28168332e-02  1.95168879e-01  4.48538377e-02
  1.05424623e+00  3.25734473e-01  2.46831699e+00  9.57776412e-02
  1.59015143e-02  7.84721275e-03  4.13053167e-01 -5.63395698e-06
  1.16073773e-01  2.39845081e+00  2.41508089e+00  9.19599725e-02
 -2.67185554e-02 -7.97446911e-01 -7.51658529e-01 -1.71875112e-02
 -8.46376249e-02 -1.12396333e+00 -1.72728880e+00 -6.78790349e-02
  3.91995707e-02  1.07159894e-01  4.30425947e-01  3.22063198e-02
 -1.97003656e+00  4.38587997e+00 -1.99061102e+00  6.03079230e+00
  1.82394320e+00 -2.09145880e+00 -1.40722397e+00  3.48798571e+00
  4.52850170e+00]
supnorm grad right now is: 6.0307922953663615
Weights right now are: 
[ 5.32288020e+00 -2.63853529e+00  3.18294014e+00  2.80551528e+00
 -5.06831149e+00  2.52984360e+00 -2.78400287e+00 -3.52154366e+00
  4.67098420e+01  3.64318991e+01  1.95767953e+01  2.50778123e+01
  5.52597357e+01 -1.12908929e+01  9.31069946e+00  3.20966196e+01
  3.35261115e+00  9.32284103e+00  3.93244021e+00 -4.40270569e+00
  7.31487664e+01  6.36302749e+01  6.71286042e+01  5.39545766e+01
  1.22982719e+01 -2.85191375e+00  4.69986573e-01  1.67187224e+01
  1.22469316e+00 -2.83088186e-01  1.07594575e+01 -2.69056295e+01
 -1.17365909e+01  5.20673210e+00  8.49255933e+00 -2.23151665e+01
  1.48878520e+01  4.33783818e+01  2.21535577e+00 -1.39921063e+00
  1.35386495e+01  4.96589953e-01  1.93560223e+00  1.38280762e+01
 -8.74486158e+00 -6.66287682e+00  1.42923606e+01  6.34852897e-02
 -3.73435846e+01 -7.94047934e-01  9.72825925e-01 -3.75335380e+01
  1.10515769e+01  3.95584616e+01  1.62945278e+00  1.44556680e+01
  3.06537167e+00 -3.66204917e+00 -4.44593812e+00 -3.76683462e+00
 -1.45540516e+00 -1.75583023e+00  3.33075153e+00 -3.82463605e+00
  3.10014090e+01]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.7177487310737
gradient value of function right now is: [ 7.98394424e-02  1.22806237e-01  1.95301445e+00  1.24516094e-02
 -7.98394424e-02 -1.22806237e-01 -1.95301445e+00 -1.24516094e-02
 -2.61838349e-02 -5.64452362e-04 -2.25324966e-02 -1.84067775e-04
  1.50997616e-02 -6.97521830e-03  5.70659320e-02  9.04927489e-05
 -1.30402723e+00 -1.14451860e-02 -3.95426694e-01 -4.96937891e-02
 -1.58880888e-03 -9.17597289e-06 -3.93398545e-04 -6.75884574e-06
  3.13595516e-01  2.48758544e-01  3.28211504e+00  5.36192835e-03
  3.86394016e-02  1.22755702e-02  8.49182686e-02  6.17093641e-03
  2.45641410e-01  6.39420749e-02  4.93549797e-01  2.45198132e-02
 -1.32507629e-02 -5.62862445e-03 -2.26816393e-01 -2.90482314e-06
 -9.50340303e-02 -6.91573001e-01 -6.23899646e-01 -8.07967324e-02
  9.11652120e-02  4.44147626e-01  3.84384005e-01  7.93881858e-02
 -2.06964226e-02 -2.60175751e-01 -4.58274159e-01 -1.67655609e-02
  5.77489525e-03  2.63641794e-02  9.63398870e-02  4.82934106e-03
  3.71406872e-01  9.90490342e-02 -4.83726492e-02  9.22900982e-01
 -5.15923212e-01 -3.69896201e-02  1.12531813e-01  1.33866881e-01
 -7.17613871e+00]
supnorm grad right now is: 7.176138712608779
Weights right now are: 
[  4.69223792  -2.74916238   3.1627579    1.23631095  -4.43766921
   2.64047069  -2.76382063  -1.95233933  50.19674818  37.50957164
  18.88002929  29.9133482   55.97904241 -11.70719894   9.57155825
  30.53761431   3.27943612   8.23309422   3.19773251  -5.26034794
  76.27789484  68.92458932  72.00436162  57.02796195  11.54868147
  -3.12405998   0.63960388  15.98296372   0.87790585  -1.36662079
  10.45830641 -27.89580161 -11.41694136   5.75435312   8.81554875
 -20.94334791  17.44504932  48.34524188   1.82753062   2.84736609
  13.41464061   0.17350114   2.19209228  13.86779711  -9.68419454
  -6.68125077  14.59849068  -0.51298379 -39.01393999  -0.44185567
   1.07035952 -39.33267233  13.06350249  40.62882981   2.12355757
  16.18938581   3.25558235  -3.87169958  -3.57296523  -3.90588523
  -1.47859237  -1.948424     3.68151679  -3.97456469  31.07067768]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.7401410677828
gradient value of function right now is: [ 3.16041745e-02  6.66115661e-02  2.11212315e+00 -1.63336367e-04
 -3.16041745e-02 -6.66115661e-02 -2.11212315e+00  1.63336367e-04
 -2.28892509e-02 -1.87876808e-04 -1.37705243e-02 -1.07805830e-03
  1.55653578e-02  1.88213371e-02  8.59531296e-02  7.89721744e-04
 -1.24118025e+00 -7.05424346e-03 -3.78297967e-01 -4.83006937e-02
 -5.29704521e-04  2.05272723e-06  1.88648406e-04 -2.36207506e-05
  3.19948469e-01  1.51734971e-01  3.09328537e+00 -1.80115774e-03
  5.68651903e-02  1.54207746e-02  1.08623045e-01  2.91171139e-02
  1.93657918e-01  2.09899278e-02  4.66434596e-01  1.31529230e-02
 -2.82753007e-02 -6.56273184e-03 -2.47344190e-01 -3.84354247e-05
 -9.23296704e-02 -1.09780950e+00 -9.37799225e-01 -7.50074006e-02
  4.98622433e-02  3.98449582e-01  3.76846206e-01  4.10822693e-02
 -1.49262469e-02 -5.29596514e-01 -7.22332667e-01 -1.19046498e-02
  7.74131500e-03  1.63342249e-02  1.46420074e-01  7.80366431e-03
  3.61455081e-01  2.45612113e-02  3.84680034e-02  6.61389550e-01
 -5.58288412e-01  6.69585559e-01  1.68956396e-01  1.12970463e-01
 -2.76421655e+00]
supnorm grad right now is: 3.0932853737503443
Weights right now are: 
[  4.74234449  -3.17340198   3.26760125   1.42312004  -4.48777578
   3.06471029  -2.86866398  -2.13914842  51.15423876  38.39317494
  19.3046145   27.95764867  56.49944644 -11.85737924   9.28705145
  32.64916923   3.30532407   9.77031255   3.52081474  -5.9852492
  79.91550574  69.90840633  72.65486705  56.49305638  12.31121993
  -2.73279416   0.54535115  16.63523291   1.0268029   -0.59957064
  10.74776554 -27.9281687  -12.13137345   3.78069382   8.37093897
 -20.42204573  15.58108924  55.29939534   1.90302685   6.93593416
  13.73993226   0.08715095   1.93309592  14.70462301  -9.35014173
  -7.40939352  14.62390337   0.14779418 -40.99704048  -0.88584889
   0.75487447 -41.2970622   14.8510412   41.37940117   2.28656213
  17.46863407   3.24866131  -3.89549996  -4.02557118  -4.03030264
  -1.7530391   -1.61166404   3.87404532  -3.84357086  31.04965264]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.560218137313
gradient value of function right now is: [ 6.11140396e-03  8.38144578e-02 -1.32100939e+00 -4.64324664e-03
 -6.11140396e-03 -8.38144578e-02  1.32100939e+00  4.64324664e-03
  1.36642878e-02 -3.65085413e-04 -2.80752183e-02  1.27085758e-04
 -4.97175150e-03  3.98241662e-02  1.09176165e-01 -6.63060873e-05
  1.90428527e+00 -3.81684786e-03 -8.23907213e-02  1.71409814e-02
  1.14496301e-03 -1.60654908e-06 -8.58531193e-05  5.84012272e-06
 -2.69575765e-01 -3.85290230e-01 -4.19138191e+00 -1.84080818e-02
  6.26153215e-02  2.03606913e-02  1.36259688e-01  4.85601102e-02
  6.18212207e-02  3.03999821e-02  2.79142442e-01  6.13891728e-02
  4.65213070e-03  3.54208470e-03  9.75577959e-02  2.06281449e-05
  1.45429613e-01  3.88745788e-01  8.76755806e-01  1.36150905e-01
 -1.78584209e-01 -6.40567285e-01 -6.29658459e-01 -1.58457497e-01
 -1.46931035e-02  1.07005832e-01  2.79304600e-02 -1.54332670e-02
  4.41904883e-02  4.47631995e-02  4.42128721e-01  4.49953222e-02
 -1.05440434e+00  2.64069740e+00 -3.41830046e-01  1.87606249e+00
  1.07688060e+00  3.83968349e-01 -5.51113423e-01  2.75936107e+00
  2.71671501e+00]
supnorm grad right now is: 4.191381905138088
Weights right now are: 
[  4.95118039  -2.92597887   3.09575876   2.14016519  -4.69661168
   2.81728718  -2.69682149  -2.85619357  53.09066493  40.08442734
  19.35586597  31.20759517  58.48853703 -12.01225504  10.35601833
  31.80560826   3.39231607  11.57557784   3.27199409  -5.97381553
  84.26270695  71.8977877   72.80915111  58.04122565  11.39657633
  -3.10587199   0.41963305  16.74913838   1.29132431   0.63218819
  11.00946572 -28.18628248 -12.31346496   4.37447789   8.45984314
 -20.06846166  18.47212169  58.82678125   2.21174805  11.65187668
  13.79736289   0.09734953   2.07925322  14.95793072  -9.89789458
  -7.66114335  15.07368727  -0.70273694 -43.48610303  -0.68806303
   1.27620272 -43.68787137  16.25841825  41.95024601   2.02655425
  18.65419406   3.0981758   -3.67445804  -3.65069524  -4.2572592
  -1.23093812  -1.5363058    3.54242085  -3.61761678  31.02508825]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.0815534589722
gradient value of function right now is: [ 4.24900143e-02  7.04420761e-02  1.25256523e+00  4.18773143e-03
 -4.24900143e-02 -7.04420761e-02 -1.25256523e+00 -4.18773143e-03
 -7.49869752e-03 -3.73917175e-04 -2.12726275e-02  7.66701098e-05
  3.60783542e-03 -8.75776649e-03  2.66570771e-02 -5.49510927e-05
 -1.30922912e+00 -2.33405678e-03 -1.10517144e-01 -3.27218585e-02
 -5.13599381e-04 -3.66106584e-06 -2.40188844e-04 -1.09942758e-06
  1.08239042e-01  2.03620768e-01  2.78215932e+00  6.53513327e-03
  9.90096254e-03  5.85256770e-03  3.91845271e-02  4.57709626e-03
  9.37744627e-02  2.76699764e-02  2.38144955e-01  3.75809342e-02
 -3.82524501e-03 -3.87224214e-03 -1.98474461e-01 -9.39491484e-06
 -4.95732555e-02 -2.97893300e-01 -2.99008835e-01 -4.49689728e-02
  9.80090069e-02  2.96958470e-01  2.91078031e-01  8.88036076e-02
 -8.69822650e-03  2.26912172e-01  1.55475789e-01 -9.78529337e-03
  1.17876124e-02  1.79779714e-02  1.20418704e-01  1.22973437e-02
  3.81361693e-01  3.37803692e-01  1.71027287e-01  4.99909499e-01
 -4.65507475e-01  4.06196389e-01  1.61839615e-01  4.60667516e-01
 -1.10313129e+01]
supnorm grad right now is: 11.031312859118968
Weights right now are: 
[  5.47382791  -2.77997374   3.11068998   1.60636922  -5.2192592
   2.67128205  -2.71175271  -2.32239761  53.85279337  41.22201055
  17.97269414  28.36511732  61.07712401 -13.29355059  10.15961513
  35.60863363   2.94042955  10.78268602   3.2634743   -6.00372719
  87.56385015  72.73273081  73.89321327  58.08207609  10.89157567
  -2.35127046   0.69977121  15.72980883   1.16511562  -0.99118917
  10.73489859 -29.1683481  -12.10661232   3.98265462   8.78715677
 -19.26211006  18.69795934  63.77007922   2.39903068  14.44595117
  13.06168968   0.31728616   2.01849575  14.59336432  -9.61629133
  -7.37675539  15.59510866  -0.30208987 -45.86045895  -0.36066101
   0.9395681  -45.99686501  16.90228727  43.07579826   2.21791376
  18.84765464   3.3219918   -3.89819467  -3.68974243  -4.08990919
  -1.90739187  -1.69621003   3.83745759  -3.81767976  31.01713884]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.1653627192886
gradient value of function right now is: [-4.94393391e-02 -5.84737024e-02 -1.97168184e-01 -2.73630484e-03
  4.94393391e-02  5.84737024e-02  1.97168184e-01  2.73630484e-03
  1.58301788e-02  1.78623074e-04  2.23880631e-02 -3.78901742e-06
 -6.01590979e-03 -3.99351576e-04 -2.74947449e-02  4.15188678e-06
 -6.31475293e-01  1.80664505e-03  1.41772318e-01  1.23038514e-02
  1.88298713e-04  8.68616520e-07  1.46821658e-04  3.78802020e-08
 -1.48627037e-01  1.22834447e-01 -1.76117651e-02 -1.05409754e-02
 -7.19529625e-04 -1.08835739e-03 -1.04500641e-02  1.05603738e-03
 -1.28507300e-01 -9.51762062e-02 -3.57892333e-01 -7.24434492e-02
  2.89837079e-03  7.61072395e-04  7.73975770e-02 -5.19725637e-08
 -7.86982420e-03  5.76131015e-01  4.89666659e-01 -1.29380523e-02
  5.88673464e-02  7.90464916e-02  1.10652380e-01  5.41008875e-02
  1.28250309e-02 -3.24674607e-01 -2.50302260e-01  1.34216191e-02
 -1.67137598e-02 -3.31080197e-02 -1.59667845e-01 -1.62822863e-02
 -7.19605488e-02 -1.07276075e+00 -4.18847287e-02 -1.22980346e+00
 -2.37477666e-01  2.87358740e-01 -8.90683564e-02 -1.07464232e+00
  2.71883198e+00]
supnorm grad right now is: 2.718831979762795
Weights right now are: 
[  6.29379975  -3.02563421   3.04757273   0.6436762   -6.03923104
   2.91694252  -2.64863546  -1.35970459  54.84783469  43.50349952
  17.18361615  29.91360847  64.09269023 -13.46479781  10.29406658
  33.68160237   2.43129694  11.64865464   4.16314233  -6.43566559
  93.84387015  73.44667883  74.66822146  58.29583869  10.32853713
  -2.91666148   0.4579417   15.55053282   1.71493369  -1.07617416
  11.07652722 -29.33008341 -12.71912325   4.02864176   8.53245748
 -19.90248467  18.64971629  68.72961294   2.64345231  16.10900946
  13.75608719   0.3937043    1.93387568  16.03083545 -10.61437854
  -8.22444381  15.43666269  -1.07887035 -47.77272581  -0.8872934
   0.57060437 -47.55277713  17.6861997   43.91953903   2.37835256
  19.15532565   2.97179891  -4.1570169   -4.42429436  -4.07904883
  -2.21073737  -2.11539313   3.54913214  -4.13866027  31.1589646 ]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.3975560232568
gradient value of function right now is: [ 6.81556470e-02  1.29399657e-01 -6.41004993e-01  1.01362084e-03
 -6.81556470e-02 -1.29399657e-01  6.41004993e-01 -1.01362084e-03
 -1.01736113e-02 -6.47831382e-04 -6.77682833e-02 -8.09364727e-06
  8.85428180e-03  1.47989397e-02  8.77698720e-02  2.86698555e-06
  1.51129498e+00 -1.56131381e-03 -1.03582196e-01  1.27309061e-02
 -4.43502684e-05 -4.07392726e-06 -3.94894377e-04  7.47414567e-08
 -8.46362311e-02 -2.87170551e-01 -3.19355166e+00  5.74427769e-03
  4.92048199e-02  1.83175978e-02  9.83262669e-02  2.37142420e-02
  2.87284929e-01  9.23804326e-02  8.51086964e-01  6.04634455e-02
 -4.47079887e-04  1.55157795e-03  9.47274420e-02  3.58786923e-07
  1.27604736e-01  3.47119581e-01  7.91941967e-01  1.16134634e-01
 -1.34292436e-01 -3.93363044e-01 -4.44312329e-01 -1.20719068e-01
 -2.81418361e-02 -1.18839491e-01 -3.00611510e-01 -2.63348263e-02
  2.21877888e-02  4.97067260e-02  2.47876245e-01  2.18252203e-02
 -9.19761129e-01  2.90438780e+00 -4.68122823e-01  2.28006034e+00
  5.69739190e-01 -4.52981312e-01 -6.44135201e-01  2.81395786e+00
  2.34272839e+01]
supnorm grad right now is: 23.427283888660245
Weights right now are: 
[  6.5497542   -3.14820314   3.14666996   2.8659367   -6.29518549
   3.03951145  -2.74773269  -3.58196508  55.39696492  44.96949049
  18.87496791  33.05846224  65.80928454 -13.04681611  10.99164853
  31.01692293   3.4252429   15.72489201   3.90267714  -7.04489917
  98.27596307  73.80447681  77.13982074  58.302344    11.02599558
  -2.932118     0.46462886  15.20684142   1.58387158  -0.57627322
  10.63836435 -29.75818611 -12.86081401   3.85708821   8.57868942
 -18.98836798  19.839596    74.44179907   2.30432091  17.02050069
  14.92814926   0.16915746   1.76223837  18.13017919 -10.4676434
  -8.05357484  15.8380341   -0.44284333 -49.94140385  -0.67919094
   1.13498063 -49.33529098  19.70071184  44.31099508   1.99226467
  20.60415911   3.16811322  -4.19600428  -4.69632785  -4.26278346
  -2.1577155   -2.01674847   3.79775279  -4.15375123  31.26134514]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.0968753147897
gradient value of function right now is: [ 2.61824766e-02  1.26240286e-01 -1.09361325e+00 -1.58110325e-03
 -2.61824766e-02 -1.26240286e-01  1.09361325e+00  1.58110325e-03
  1.24639864e-02 -3.47693245e-04 -5.90230752e-02  2.86397659e-05
 -3.12848215e-04  5.50766916e-02  1.62635486e-01 -9.94265519e-06
  1.01466292e+00 -7.01411856e-03 -7.00859540e-01  3.72829104e-02
  2.88134052e-04 -3.54033613e-07 -4.35820919e-05  1.74623473e-07
 -4.00061650e-01 -1.35972392e-01 -2.96779396e+00 -1.85046648e-03
  1.09946848e-01  4.29657250e-02  1.74619265e-01  5.79692276e-02
  5.25583727e-01  1.47813568e-01  1.07805973e+00  1.03005527e-01
  1.46048594e-02  2.43751957e-03  2.46635144e-01 -1.84813962e-07
  1.18220971e-01  1.77339948e+00  2.26030579e+00  1.00546564e-01
 -4.42336782e-02 -3.49599468e-01 -3.82045004e-01 -4.07134814e-02
 -2.57848214e-02 -9.89122052e-02 -5.18403588e-01 -2.27413317e-02
  3.14538484e-02  8.23782843e-02  4.28854031e-01  2.77734743e-02
 -7.79629720e-01  3.28055597e+00 -9.58874615e-01  4.36698719e+00
 -1.27273075e-02  8.92101692e-01 -6.69810113e-01  3.00785907e+00
  9.98241147e+00]
supnorm grad right now is: 9.982411474808012
Weights right now are: 
[  6.27577019  -3.0043307    3.04472698   1.36178779  -6.02120148
   2.89563901  -2.64578971  -2.07781617  58.71706908  46.61674856
  18.92328518  36.49164319  65.47586021 -12.58489321  10.90875385
  27.00387044   3.28551595  15.08187241   3.32954625  -7.18842174
 102.71508547  75.53400512  79.48705945  58.54410293  10.57527214
  -3.0567838    0.61076363  16.37109198   2.06249747   0.47013232
  11.19714909 -29.52456644 -12.44876042   3.57477702   8.70109298
 -18.5267749   18.88495086  78.57223147   2.36196839  18.68232282
  13.90074432   0.17401841   2.22304322  17.17754511 -10.41224502
  -8.11894717  16.20689844  -0.57133522 -51.97057001  -0.93505892
   0.91639648 -51.54030692  20.64632514  46.27363      2.36932954
  21.16737244   3.45311159  -4.047759    -4.15505267  -4.00219978
  -1.75987451  -1.92592083   3.75784257  -4.14312436  31.08265502]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.0044681263919
gradient value of function right now is: [-3.87328724e-03  3.90329873e-02  6.74738395e-01 -1.40748806e-03
  3.87328724e-03 -3.90329873e-02 -6.74738395e-01  1.40748806e-03
  1.06236893e-02 -3.26821021e-04 -2.24600335e-02  1.07424805e-04
 -3.29147649e-03  8.20690330e-04  6.00785551e-02 -4.75682749e-05
 -8.76900467e-01 -8.72360179e-03 -4.96068098e-01 -2.62171277e-03
  9.82868456e-06  3.36258691e-08  4.77937852e-06  3.01968036e-08
 -9.73267841e-02  1.64577429e-01  1.16225771e+00 -3.10954119e-03
  6.32313586e-02  1.70987027e-02  1.18643187e-01  2.22860352e-02
  2.48689767e-01  5.22332245e-02  4.62444047e-01  5.41345115e-02
  1.28161870e-03 -1.52412874e-03 -2.33101578e-02 -2.67387106e-06
  7.60073716e-03  1.98188633e-01  5.76443950e-01  6.01540831e-03
  8.06249018e-02  1.97471084e-01  1.64365887e-01  7.29852754e-02
 -1.16771281e-02 -6.75618474e-02 -3.05188355e-01 -1.10579917e-02
  1.57964013e-02  4.27873844e-02  2.44961059e-01  1.48734085e-02
  9.58524085e-03  1.20641078e+00 -2.20005339e-01  1.94297797e+00
 -5.20296918e-01  8.58581631e-01 -1.19553772e-01  1.18385626e+00
  2.59275828e+00]
supnorm grad right now is: 2.592758284688062
Weights right now are: 
[ 6.45717572e+00 -3.20330072e+00  2.98951999e+00 -2.54675505e-01
 -6.20260701e+00  3.09460903e+00 -2.59058272e+00 -4.61352878e-01
  6.06255125e+01  4.69376539e+01  1.85152737e+01  3.95483984e+01
  6.68268402e+01 -1.33416568e+01  1.05639886e+01  2.45083366e+01
  2.91985108e+00  1.40111452e+01  2.94364123e+00 -7.59501279e+00
  1.13019885e+02  7.56321714e+01  8.31618687e+01  5.86252639e+01
  1.02782256e+01 -2.32921622e+00  6.42615211e-01  1.55638681e+01
  1.83110942e+00 -7.81831829e-01  1.08062040e+01 -3.05269763e+01
 -1.24246091e+01  4.41224128e+00  8.89630907e+00 -1.83048389e+01
  1.81031018e+01  8.37727312e+01  2.36175964e+00  1.98406471e+01
  1.41170847e+01 -3.92369856e-02  2.02740937e+00  1.75714927e+01
 -9.86481239e+00 -8.33157270e+00  1.66693293e+01 -1.65700468e-01
 -5.38297922e+01 -8.72471529e-01  1.01584130e+00 -5.35086083e+01
  2.09441551e+01  4.76305969e+01  2.82120130e+00  2.14107475e+01
  3.16559183e+00 -4.24541332e+00 -3.72643976e+00 -4.13238627e+00
 -1.93274629e+00 -1.94717531e+00  3.71329840e+00 -4.25274756e+00
  3.10985264e+01]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.9782046374414
gradient value of function right now is: [ 8.20188567e-02  1.45027533e-01  6.56583836e-01  1.84789081e-03
 -8.20188567e-02 -1.45027533e-01 -6.56583836e-01 -1.84789081e-03
 -2.40763263e-02 -3.80002432e-04 -7.35612075e-02 -4.35416719e-06
  1.19062161e-02  2.34504519e-02  1.12753427e-01  1.90139285e-06
  3.38610912e-01 -5.53017733e-03 -6.96106560e-01  2.28870228e-02
  1.46258921e-04  4.19420629e-07  8.39167528e-05  1.21734001e-08
  1.97931290e-01  2.10190482e-02 -2.14708984e-01  1.07608038e-02
  7.43647863e-02  3.15532928e-02  1.13452155e-01  3.24887711e-02
  6.72917653e-01  1.82986294e-01  1.27016699e+00  7.24247532e-02
  1.05933725e-02  1.80584295e-03  1.82905377e-01 -1.17721622e-08
  1.23557744e-02  6.84415305e-01  8.97022417e-01  6.50824709e-03
 -4.25262941e-02 -2.88918344e-01 -3.16906494e-01 -3.52852246e-02
 -2.69423206e-02 -4.60489573e-01 -8.81913347e-01 -2.28912324e-02
  1.29827765e-02  5.32843874e-02  2.37806597e-01  1.16426251e-02
 -6.45792520e-01  1.81627755e+00 -8.28134141e-01  3.18392137e+00
  3.89362823e-01 -5.60780558e-02 -3.99906466e-01  1.54304116e+00
 -2.44219940e-01]
supnorm grad right now is: 3.183921369179462
Weights right now are: 
[ 7.03717588e+00 -2.81313455e+00  3.04988362e+00 -1.61474355e+00
 -6.78260717e+00  2.70444286e+00 -2.65094635e+00  8.98715169e-01
  6.07892770e+01  4.84236823e+01  1.81580090e+01  4.09456520e+01
  6.95222096e+01 -1.32345874e+01  1.09063326e+01  2.30645699e+01
  3.24363094e+00  1.36041035e+01  3.22647486e+00 -8.45213148e+00
  1.19305554e+02  7.57595999e+01  8.98789804e+01  5.86507435e+01
  1.07860600e+01 -2.59047961e+00  4.50999001e-01  1.60894660e+01
  2.70168783e+00 -1.01887890e+00  1.15015981e+01 -3.01011479e+01
 -1.19789060e+01  4.80532538e+00  9.15518252e+00 -1.95969304e+01
  1.82644295e+01  8.86942668e+01  1.94065759e+00  2.25699137e+01
  1.39881313e+01 -1.55213008e-01  2.15428262e+00  1.79930935e+01
 -1.00246208e+01 -8.91673525e+00  1.64250347e+01 -7.55916075e-02
 -5.55565409e+01 -8.27481358e-01  6.54679885e-01 -5.52824341e+01
  2.12312016e+01  4.87813140e+01  3.35490263e+00  2.13974557e+01
  3.28813463e+00 -4.34599247e+00 -4.23604138e+00 -4.05241892e+00
 -1.95324253e+00 -2.13566934e+00  3.89587752e+00 -4.38905210e+00
  3.10023187e+01]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.4675677736445
gradient value of function right now is: [-6.21774137e-02 -7.94246346e-02 -8.10507489e-01 -5.41507010e-04
  6.21774137e-02  7.94246346e-02  8.10507489e-01  5.41507010e-04
  1.83688155e-02  1.53631130e-04  4.26843031e-02  2.36437775e-04
 -9.98715492e-03  1.08330541e-02 -2.15510424e-02 -9.55700994e-05
 -2.70690135e-01  2.90936203e-04  1.59020265e-01  6.51433557e-03
 -4.01691588e-06 -9.33814458e-08 -2.26348151e-05objective value function right now is: -1205.7286517920847
gradient value of function right now is: [-1.12065245e-01 -3.34909993e-02 -1.51358571e+00 -9.11437189e-03
  1.12065245e-01  3.34909993e-02  1.51358571e+00  9.11437189e-03
  5.32008413e-18 -8.32818259e-04 -5.24827189e-03 -1.88469114e-02
 -1.07295664e-22  2.18161333e-05  2.57879197e-03  9.50452480e-03
 -1.28273849e-03  4.98616359e-01  1.19003780e-01 -4.70431808e-02
 -1.01762973e-26 -1.74176083e-06 -5.60926753e-04 -1.48434504e-03
 -6.87988669e-05  1.47116291e-04  1.18720534e-19  3.08991641e-02
 -2.41201698e-03 -1.11382028e+00 -4.64037991e-01 -6.56401514e-01
  7.71129055e-02  4.25470981e-01  9.70244631e-02  2.77328193e-01
  9.88076621e-02 -4.85365402e-02 -1.18444372e-01  4.52487199e-01
 -1.46842181e-02 -6.28201823e-03 -3.10682229e-02  2.86792035e-04
 -8.81121963e-02  6.94919105e-02 -1.23815335e-01 -2.42023939e-02
 -5.52904381e-02 -1.78718860e+00 -7.89986573e-02 -7.61087114e-03
  5.07710757e-02  1.68738025e+00  6.57962242e-02  8.80006716e-03
  1.07102854e+00 -4.57360069e+00 -9.69805246e-01  5.18098472e+00
  1.77366126e+00 -7.37133448e+00  1.00075305e-01 -6.43264896e-01
 -6.73815690e+00]
supnorm grad right now is: 7.371334478025394
Weights right now are: 
[-2.74828379e+00  4.19869220e+00  2.32214308e+00 -3.59151055e+00
  2.01398507e+00 -4.24193994e+00 -1.82782613e+00  2.05562223e+00
 -5.42754187e+01  8.85246957e+00  7.72685027e+01  4.81837106e+01
  3.42671154e+00  8.42872791e+01  1.33009695e+02  6.76219315e+01
  2.65890124e+01  6.62382573e+00 -7.31829622e+00  1.90549344e+00
  2.81412833e+00  8.49505924e+01  1.25818288e+02  1.12082027e+02
  4.73631689e+01  1.00335979e+02  2.86255256e+01  2.34233746e+00
  1.21344688e+01 -1.30371291e+00 -4.67301194e+00  1.07046107e+01
  3.30989355e+00 -3.64056742e+00  2.56846248e+01  5.39652840e+00
  3.0760.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.172340399682
gradient value of function right now is: [-3.31197201e-02 -1.37688153e-01  1.18602850e+00  8.22400038e-05
  3.31197201e-02  1.37688153e-01 -1.18602850e+00 -8.22400038e-05
 -2.05195041e-02  9.11498980e-04  5.53323701e-02 -9.10969769e-06
  6.47787637e-03 -4.96961316e-02 -1.65455773e-01  3.86162222e-06
  2.16811898e-01  8.92983745e-03  4.40055429e-03  2.39107736e-03
  1.13433950e-04 -1.37022438e-06 -9.49124033e-05 objective value function right now is: -1204.9624084129919
gradient value of function right now is: [ 5.14467396e-02  1.62302022e-02  3.60876944e+00  3.24022667e-03
 -5.14467396e-02 -1.62302022e-02 -3.60876944e+00 -3.24022667e-03
  3.17684026e-18  1.69599213e-05  1.74972153e-03  8.17543563e-03
 -9.43842403e-24 -3.18160919e-06 -1.07306343e-03 -5.79281792e-03
 -3.10852052e-04 -1.04288167e-01 -3.31567435e-01 -1.85360531e+00
  1.90123274e-27  2.34689608e-07  1.73151776e-04  5.60042246e-04
 -5.37019923e-06  2.25002006e-04  4.01177263e-19  7.94869446e-03
  1.33874609e-03  2.25252391e-01  9.74303830e-02  1.79795963e-01
 -7.28946087e-02 -8.87610109e-01 -4.81196601e-02 -1.55658557e+00
  1.89574290e-01  7.37672950e-01  9.18836913e-02  1.96636719e+00
 -3.05294306e-02 -4.75689097e-03 -6.34670602e-02 -2.55164637e-03
 -3.09542215e-01 -1.54221360e+00 -5.36950165e-01 -6.27392542e-02
  2.47853734e-02  6.72108263e-01  4.69216446e-02  2.65025181e-03
  4.34773427e-02  2.70930171e-01  8.16658597e-02  5.75264287e-03
  1.97164250e-01  5.65143025e-01  2.01800877e-01 -5.41571025e-01
 -9.09594019e-02  1.58814954e+00  5.26286214e-02 -9.38201336e-02
 -7.99723349e+00]
supnorm grad right now is: 7.9972334945594525
Weights right now are: 
[ -2.30272763   4.29050042   2.7548134   -3.42915923   1.56842891
  -4.33374815  -2.26049645   1.89327091 -54.27541875   6.67917791
  78.97753733  51.11268058   3.42671154  85.31218199 133.61487209
  68.23578389  27.60181639   5.96299687  -7.44356383   2.05127419
   2.81412833  84.91535433 127.7238796  113.79690768  50.96041709
 103.5240181   28.62552564   1.73717432  11.04491494  -0.6262.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.8686589892177
gradient value of function right now is: [-1.17384294e-01 -1.89156741e-01 -9.74534264e-01 -2.60302356e-03
  1.17384294e-01  1.89156741e-01  9.74534264e-01  2.60302356e-03
  2.63130570e-02  1.73869888e-04  7.47370365e-02  1.56803434e-06
 -2.01659506e-02 -2.01239570e-02 -1.48438893e-01 -1.38603672e-05
 -3.35012668e-01  2.60020982e-03  9.50909292e-01 -3.24514464e-03
 -2.33397341e-04 -5.61057109e-07 -1.97948762e-04 -3objective value function right now is: -1206.9849825592964
gradient value of function right now is: [-3.62472282e-02 -1.24636288e-02  9.98341619e-01 -3.32897963e-03
  3.62472282e-02  1.24636288e-02 -9.98341619e-01  3.32897963e-03
  9.88666616e-19  2.80827937e-05 -1.33539890e-03 -4.90829580e-03
 -1.05288747e-22 -5.47733620e-07  8.93905552e-04  3.15357778e-03
  5.42738041e-03 -1.32765444e-01 -8.79459623e-02 -9.59410166e-01
 -9.26006587e-27 -7.09976481e-08 -1.95197198e-04 -5.14382409e-04
 -3.13852550e-04 -6.92642246e-04  5.31662535e-18 -1.39276326e-01
  2.10110194e-03  2.90954619e-01  1.48278784e-01  2.29768716e-01
  2.13915214e-02 -2.28520163e-01 -2.56136489e-02 -3.69353863e-01
  6.66498522e-02  3.43846631e-01  1.10272121e-01  8.13135080e-01
 -1.17161260e-02 -5.52627518e-03 -2.85652949e-02  2.63569459e-03
 -6.63006510e-02 -6.68121277e-01 -1.07365117e-01 -2.36308959e-03
  1.87130388e-02  5.99999477e-01  2.94062106e-02  2.82985894e-03
  4.46849563e-03 -2.12979819e-01  4.45668103e-03  1.86357592e-03
 -1.32796297e-01  1.09061093e+00  4.88637158e-01 -1.54453202e+00
 -5.42092190e-01  2.11836163e+00 -3.50804300e-03  3.22011932e-02
  1.40513332e+00]
supnorm grad right now is: 2.118361631179881
Weights right now are: 
[ -2.43287561   3.8324594    2.49564901  -3.48576094   1.69857689
  -3.87570714  -2.00133206   1.94987262 -54.27541875   1.91356598
  80.92124494  52.25418093   3.42671154  86.47840472 133.49278389
  70.0751518   27.41982943   6.18931496  -7.96389388   1.83240379
   2.81412833  84.86434953 129.27001582 115.01911027  52.17721501
 101.53239526  28.62552564   2.00527145  12.67749901  -0.564.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.1682501634857
gradient value of function right now is: [-1.19444438e-01 -1.55943247e-01  1.22931935e+00 -1.99925808e-03
  1.19444438e-01  1.55943247e-01 -1.22931935e+00  1.99925808e-03
  1.43589871e-02  1.38946831e-04  5.25721557e-02  1.64862991e-05
 -1.45692787e-02  6.14361052e-05 -5.28589382e-02 -1.73151795e-05
 -1.33342861e+00 -2.01333024e-03 -3.72984197e-02 -6.89106165e-02
 -6.27844837e-05 -2.69220535e-07 -9.65812274e-05 objective value function right now is: -1205.7131654154841
gradient value of function right now is: [ 6.98134181e-03  2.39029604e-03 -3.28880202e+00  4.30712514e-04
 -6.98134181e-03 -2.39029604e-03  3.28880202e+00 -4.30712514e-04
  6.09626919e-21  1.15647284e-04  2.15915218e-04  1.04038728e-03
  4.36277247e-25  2.54444376e-07 -1.60987456e-04 -7.42282973e-04
  2.64341958e-03 -1.73403527e-01  1.96481889e-01  3.49792266e+00
 -4.87070171e-29  6.05476174e-09  8.50158981e-06  3.38886459e-05
 -2.16866071e-04 -1.06931039e-03 -4.15083069e-20 -7.20854067e-02
 -1.00828293e-03  3.98307348e-01  1.52333060e-01  2.66270499e-01
  1.40786468e-02  5.17808008e-01 -2.11102632e-02  1.25697596e+00
 -2.73838233e-01 -8.31082567e-01  3.19982212e-02 -3.50836130e+00
  8.74592093e-02  1.40583455e-02  1.24998576e-01  1.89059097e-03
  6.36968497e-01  1.42920077e+00  7.89851280e-01  1.35000307e-01
  2.09226664e-02  8.79989946e-01  2.20450356e-02  6.69504031e-03
 -8.47700357e-02 -1.20104762e+00 -1.03217310e-01 -1.62257150e-02
 -1.34153617e+00  3.73003777e+00  8.88983367e-02 -2.84941979e+00
 -1.34464561e+00  4.87991861e+00 -1.35512903e-01  9.52623735e-01
  1.17981485e+01]
supnorm grad right now is: 11.798148522396882
Weights right now are: 
[-2.44671025e+00  4.05349372e+00  2.52616671e+00 -1.86855792e+00
  1.71241152e+00 -4.09674146e+00 -2.03184976e+00  3.32669594e-01
 -5.42754187e+01 -6.47300687e-01  8.17045034e+01  5.41541059e+01
  3.42671154e+00  8.68216094e+01  1.34640646e+02  7.14821491e+01
  2.74466444e+01  6.30102021e+00 -7.89484992e+00  2.10853918e+00
  2.81412833e+00  8.48818324e+01  1.32660640e+02  1.17987635e+02
 66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.938590638389
gradient value of function right now is: [ 1.90756189e-02  8.37063328e-02  4.53735127e-01 -4.06802210e-04
 -1.90756189e-02 -8.37063328e-02 -4.53735127e-01  4.06802210e-04
  5.55971283e-03 -1.10261727e-04 -3.48120995e-02  7.87576577e-05
 -6.32236518e-04  3.95523831e-02  1.16812643e-01 -3.45887415e-05
 -4.64759349e-01 -5.13219469e-03 -5.57652624e-01 -2.23189872e-03
 -4.04856745e-05 -2.49797254e-08 -1.52201585e-05 -2.21919301e-08
 -8.77611789e-02  4.65301593e-02  9.21176443e-01 -5.26326568e-04
  9.42108544e-02  4.24106955e-02  1.37381056e-01  5.24774046e-66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1204.5689335979218
gradient value of function right now is: [ 4.56725091e-02  1.91627034e-02  3.46938591e+00  5.93069804e-03
 -4.56725091e-02 -1.91627034e-02 -3.46938591e+00 -5.93069804e-03
  1.87078028e-20 -4.09265807e-04  1.44302425e-03  4.84709726e-03
 -3.47702271e-22 -1.68719157e-05 -1.03906853e-03 -3.98263239e-03
 -3.49943029e-03 -6.53440604e-02 -2.30160845e-01 -1.59377989e+00
  9.91771639e-26  7.29892474e-07  1.65311513e-04  4.53968671e-04
  1.12122125e-04  5.14963298e-04  1.05187218e-21  9.16119173e-02
  3.67635601e-03  1.79015783e-01  9.54481115e-02  1.87810102e-01
 -2.70541070e-02 -7.09313744e-01 -3.14761731e-02 -1.18440066e+00
  8.02617615e-02  4.80186475e-01  1.17603631e-01  1.28628307e+00
 -2.00066212e-02 -3.96385813e-03 -2.72628520e-02 -2.95014308e-03
 -2.66913092e-01 -9.37495872e-01 -3.45964741e-01 -7.75131931e-02
  1.83009153e-02  3.11191347e-01  2.86423699e-02  1.84167943e-03
  4.19187922e-02  3.94172561e-01  5.74229202e-02  8.05845840e-03
 -3.21323304e-02  3.17153215e-01  2.69056007e-01 -2.33711518e-01
 -3.46922584e-01  1.00526512e+00  6.35895398e-02 -2.63161748e-01
 -1.21441244e+00]
supnorm grad right now is: 3.46938590726871
Weights right now are: 
[-2.19219087e+00  3.68873889e+00  2.66747273e+00 -2.51288861e+00
  1.45789215e+00 -3.73198663e+00 -2.17315578e+00  9.77000285e-01
 -5.42754187e+01 -3.97098310e+00  8.31155833e+01  5.7002121868.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.0759236759827
gradient value of function right now is: [-1.13256425e-02 -9.67787167e-02  1.30238614e+00  8.48658741e-04
  1.13256425e-02  9.67787167e-02 -1.30238614e+00 -8.48658741e-04
 -1.16615442e-02  5.66073601e-04  4.01672302e-02 -3.89962538e-05
  1.61384844e-03 -5.34857652e-02 -1.46792765e-01  1.69306789e-05
 -1.13485731e+00  6.34359453e-03  8.54026492e-02 -1.81115646e-02
  2.98372659e-05  4.19034835e-09  4.04962184e-06  7.03533121e-09
  3.51990373e-01  1.85729208e-01  3.02533783e+00  1.25407338e-02
 -1.56687144e-01 -7.88669452e-02 -2.62479816e-01 -8.47706245e-02
 -9.99316408e-02 -9.13300875e-02 -2.69670929e-01 -6.88618603e-02
 -1.21869182e-02 -1.43696749e-03 -1.48162618e-01 -4.22662823e-08
 -8.87492837e-02 -5.94856346e-01 -8.44376539e-01 -7.69088928e-02
  68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1206.4248867558085
gradient value of function right now is: [-1.53108417e-02 -6.17000445e-03 -6.63663274e-01 -1.41067417e-03
  1.53108417e-02  6.17000445e-03  6.63663274e-01  1.41067417e-03
  5.63549640e-19 -1.15995239e-04 -5.47299852e-04 -2.17880745e-03
 -4.42799676e-24 -1.28889597e-06  3.17099640e-04  1.28633758e-03
  2.24458413e-03  3.65059678e-01  1.31984161e-01 -2.02253069e-01
 -5.97281660e-28 -7.78132571e-09 -4.64122364e-05 -1.74450046e-04
 -7.28642837e-05 -3.34834391e-04  7.40314552e-21 -5.97300578e-02
  6.47880833e-04 -7.85791548e-01 -2.99392083e-01 -5.12558669e-01
  1.05292414e-02  4.08916266e-01  6.97224884e-02  2.84311605e-01
  5.73791577e-02 -1.04646124e-01 -8.34501469e-02  4.14541982e-01
 -1.46409552e-02 -2.91016468e-03 -2.44725865e-02  3.33513144e-04
 -4.03823878e-02  5.83267151e-01 -6.08041252e-02 -1.78940236e-03
 -5.78109947e-02 -1.77763534e+00 -7.20855109e-02 -1.09435612e-02
  3.06776111e-02  1.09044119e+00  3.66799464e-02  6.47706940e-03
  6.22539614e-01 -4.69150891e+00 -4.54573080e-01  3.99363830e+00
  8.29746721e-01 -6.73852078e+00  7.43179307e-02 -7.43253362e-01
 -3.99396253e+00]
supnorm grad right now is: 6.738520778642885
Weights right 70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1206.3160371452527
gradient value of function right now is: [ 1.30269294e-01  2.37364988e-01 -5.61456582e-01  2.00936768e-04
 -1.30269294e-01 -2.37364988e-01  5.61456582e-01 -2.00936768e-04
 -7.28337902e-03 -4.92908973e-04 -1.23809744e-01  3.04540940e-05
  1.27460119e-02  6.07377643e-02  2.14821236e-01 -2.82780808e-06
  1.32995559e+00 -7.90846464e-03 -1.09311269e+00  3.13459973e-02
 -4.29046673e-05  3.68633483e-07  8.27559584e-05 -4.14582422e-08
 -3.09334281e-01 -1.87635580e-01 -3.66305983e+00  7.47724239e-03
  1.31555775e-01  4.61430086e-02  2.06018918e-01  6.60766584e-02
  1.02038516e+00  2.05772780e-01  2.03616649e+00  1.63390122e-01
  1.61059218e-02  2.38593198e-03  2.85379753e-01 -3.49364607e-07
  1.32749915e-01  2.05443465e+00  3.07660484e+00  1.01260106e-01
 -9.63243852e-02 -5.21140835e-01 -5.69873554e-01 -7.50299370e-02
 -3.96155592e-02 -2.91670987e-01 -1.17532669e+00 -3.55653162e-02
  2.98198022e-02  8.68400625e-02  5.44856133e-01  2.79345279e-02
 -1.51670.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1205.5615474152746
gradient value of function right now is: [ 6.67774037e-03  2.50975411e-03 -4.23728936e+00  2.72951314e-04
 -6.67774037e-03 -2.50975411e-03  4.23728936e+00 -2.72951314e-04
  6.17418961e-23 -1.59306363e-06  1.54759425e-04  1.18699761e-03
  1.12167427e-26 -3.19653007e-07 -1.04181708e-04 -7.32476767e-04
  9.22839961e-04  2.52685296e-02  3.07058568e-01  3.65879224e+00
 -1.10891066e-31  7.06341864e-09  1.80071768e-06  1.03957048e-05
 -8.01127634e-05 -6.33372449e-04 -2.93826349e-20 -2.75452517e-02
 -1.95781332e-03 -8.46430913e-02  3.15720965e-03 -1.12265497e-01
  8.53019035e-03  9.02486609e-01  3.95696754e-02  1.47730245e+00
 -1.72664724e-01 -1.20763332e+00 -7.51455045e-02 -3.58323237e+00
  3.59345462e-02  6.96166110e-03  6.14194763e-02  1.88706454e-03
  5.51098931e-01  2.39994189e+00  7.44516351e-01  1.26382499e-01
 -2.57276788e-02 -4.41520631e-01 -3.75813389e-02 -3.32201882e-03
 -8.59253274e-02 -1.03298240e+00 -1.19518859e-01 -1.43403511e-02
 -4.63172.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.7794666699288
gradient value of function right now is: [-1.24816059e-01 -1.09306455e-01 -2.04982370e+00 -4.51831620e-04
  1.24816059e-01  1.09306455e-01  2.04982370e+00  4.51831620e-04
  3.51169206e-02  1.11693360e-04  7.63405557e-02  1.60330365e-04
 -1.79377064e-02  1.26609438e-01  7.12952210e-02 -7.14837668e-05
  6.28286809e-01  1.14047293e-03  7.89130979e-01  1.23739499e-02
 -1.52680077e-05 -1.66099903e-08 -1.16794589e-05 -2.07507796e-08
 -4.28825479e-01 -1.16120974e-01 -2.20870272e+00 -1.39216036e-02
  5.92633087e-02  2.96803501e-02  6.56154237e-02  4.87541349e-02
 -8.00386736e-01 -1.13146466e-01 -1.66130133e+00 -7.98289434e-02
  6.39247216e-03  9.76895783e-04  1.12152399e-01  2.92904443e-07
  4.38399239e-03 -1.07335189e-01 -6.70231517e-01  2.13109836e-03
 -5.14778200e-02 -1.70306035e-01 -1.33398099e-01 -4.38634701e-02
  3.11288718e-02  5.93962894e-01  1.24285137e+00  2.54936011e-02
 -9.84407283e-03 -2.53243354e-02 -9.77708911e-02 -8.88960504e-03
  3.91117295e-01 -2.32115362e+00  3.39556032e-01 -1.59064571e+00
  3.07973431e-01 -2.77658217e-01  3.75015524e-01 -1.97525364e+00
 -7.43434514e+00]
supnorm grad right now is: 7.43434514040732
Weights right n72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1206.9168482073258
gradient value of function right now is: [ 2.03075749e-03  1.11508251e-03 -1.11661515e+00  2.45116130e-04
 -2.03075749e-03 -1.11508251e-03  1.11661515e+00 -2.45116130e-04
  2.81976648e-22 -5.67311705e-05  6.50797359e-05 -4.68660219e-05
  3.76002435e-27 -7.47698474e-07 -7.40391829e-05 -1.45562764e-04
  3.18787159e-03  1.37676607e-01  8.91759367e-02  4.71115288e-01
 -4.57484530e-32  1.01734498e-08  3.07343972e-06  8.48416604e-06
 -1.08977283e-04 -6.32576545e-04 -1.97673023e-23 -8.81516356e-02
  1.35311559e-03 -2.98701075e-01 -9.96406188e-02 -1.93236154e-01
  1.57717155e-02  2.86728572e-01  3.33063259e-02  3.20948587e-01
 -1.53264288e-01 -1.78829527e-01 -1.15310990e-02 -5.18582857e-01
  1.34231846e-02  1.56705654e-04  3.07123388e-02  1.42421724e-03
  74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.202999152419
gradient value of function right now is: [-1.98889031e-02 -6.85835083e-02  2.54753860e-01 -1.01493284e-04
  1.98889031e-02  6.85835083e-02 -2.54753860e-01  1.01493284e-04
 -9.79083985e-04  2.51017266e-04  2.04255753e-02 -1.73091676e-05
 -1.04043022e-03 -5.74228394e-02 -1.24358442e-01  1.53143801e-05
 -4.59531110e-01  4.72070937e-03  9.51292542e-02  2.07436513e-03
  2.80526312e-06 -1.12196268e-07 -8.74294666e-06 -1.39548278e-09
  8.01081138e-02  1.34327746e-01  9.63428793e-01  1.12716882e-02
 -1.32552505e-01 -5.65671415e-02 -2.11673130e-01 -7.76484815e-02
 -3.67449965e-02 -5.43343302e-02 -1.29421403e-01 -5.48218962e-02
 -9.25287413e-04  1.40495963e-04  2.67768311e-02 -6.73985298e-07
 -2.32895394e-02  2.48588639e-01  1.97042909e-01 -2.53458626e-02
  4.07637053e-02  6.73164984e-02  9.41658014e-02  3.44598077e-02
  7.02908333e-03 -1.55146944e-01 -1.86340591e-01  8.19869710e-03
 -1.91534747e-02 -3.82955674e-02 -3.00559547e-01 -1.99952219e-02
  1.27796358e-01 -1.31196490e+00  3.37893011e-01 -2.26891005e+00
 -6.61609354e-02 -5.97040303e-01  1.13094620e-01 -1.50493332e+00
 -1.07890079e+01]
supnorm grad right now is: 10.789007881334825
Weights right now are: 
[ 6.30865288e+00 -3.85571339e+00  3.05410293e+00 -1.42238632e+00
 -6.05408417e+00  3.74702170e+00 -2.65516566e+00  7.06357933e-01
  6.99489403e+01  6.47651375e+01  2.02090436e+01  5.03425666e74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.257189165633
gradient value of function right now is: [ 9.20121544e-03  3.03395151e-03  6.20991144e-01  2.61532426e-04
 -9.20121544e-03 -3.03395151e-03 -6.20991144e-01 -2.61532426e-04
  2.71737070e-25 -5.98499908e-06  3.50419896e-04  1.32770610e-03
 -4.47539129e-29 -4.30431066e-07 -2.06936851e-04 -8.30795973e-04
 -2.59432842e-03  8.15501262e-02 -3.56672111e-02 -2.04509881e-01
  3.38726973e-34  9.21112027e-09  8.10461131e-06  2.66930948e-05
  1.68784459e-05  2.59880195e-04  6.20386816e-23  7.05593712e-02
  7.24637831e-04 -1.58250306e-01 -7.20298000e-02 -8.72532455e-02
 -3.02016897e-02 -1.07777146e-01  6.39683415e-03 -2.25305774e-01
  2.62936176e-02  6.36579026e-02 -5.70452214e-03  1.83535889e-01
  1.54513562e-04 -8.30584293e-04  1.09726456e-03 -1.89922201e-04
 -76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.1233761142894
gradient value of function right now is: [-1.91381784e-02 -7.77922379e-02 -8.52527049e-01  1.95150092e-04
  1.91381784e-02  7.77922379e-02  8.52527049e-01 -1.95150092e-04
  3.37124674e-03  2.38003772e-04  2.83391487e-02  4.68254524e-05
 -1.20225354e-03 -5.88442308e-02 -1.29337655e-01 -2.87480238e-07
  5.15223489e-02  5.37437272e-03  2.72527514e-01  6.00378953e-03
  6.44510056e-05 -1.93285903e-08  1.02238505e-05 -1.11851808e-07
 -1.17025676e-01  1.85403528e-02 -4.91552692e-01  7.23424184e-03
 -1.15803377e-01 -5.14405764e-02 -1.86002846e-01 -6.73794363e-02
 -1.68308029e-01 -1.05930969e-01 -4.29965396e-01 -9.51809459e-02
  1.03041962e-02  9.74000798e-05  5.32096377e-02 -1.75687243e-07
  3.18276131e-03  5.39201518e-01  5.82157846e-01  1.36146853e-04
  2.00384661e-02  5.21670456e-02  6.18193855e-02  1.52836230e-02
  1.27810968e-02 -8.54436464e-02 -5.78250689e-02  1.15844059e-02
 -2.55969071e-02 -4.56409126e-02 -3.27587679e-01 -2.27451747e-02
  1.22887914e-01 -1.67169072e+00  3.29764774e-01 -2.65212831e+00
 -2.36161398e-01 -6.15444617e-01  1.46906672e-02 -1.54339715e+00
 -6.00080697e+00]
supnorm grad right now is: 6.000806974882652
Weights right now are: 
[  6.95858363  -3.07932974   2.80983807  -6.5775192   -6.70401492
   2.97063805  -2.4109008    5.86149082  71.10957289  66.17593051
  19.49197676  52.69587766  89.16539869 -12.85198345  10.76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.1437982538016
gradient value of function right now is: [ 7.96178382e-03  3.30925645e-03 -5.90871160e-01  3.77715103e-04
 -7.96178382e-03 -3.30925645e-03  5.90871160e-01 -3.77715103e-04
  2.37530805e-25  2.17926811e-05  2.63740318e-04  9.54139704e-04
  4.36528549e-28 -8.49979274e-07 -2.17431783e-04 -8.69780170e-04
 -2.79917991e-03 -6.28162656e-02  7.72322248e-02  1.63117863e-02
 -3.38013241e-32  1.50241219e-08  8.26924552e-06  2.82134298e-05
 -6.29443806e-05  2.95434381e-04 -5.70061839e-25  7.71802702e-02
 -5.64748621e-04  1.42394659e-01  4.01534272e-02  8.80304612e-78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.1110341338365
gradient value of function right now is: [-3.94237707e-02  1.86056734e-02 -8.69396164e-01 -9.18973452e-04
  3.94237707e-02 -1.86056734e-02  8.69396164e-01  9.18973452e-04
  2.03262825e-02 -9.56373727e-05 -1.82754559e-02  1.07271284e-04
 -3.89019709e-03  3.35500100e-03  6.90902860e-02 -1.66527237e-05
  5.82971390e-01 -6.14667033e-03 -9.21859419e-01  3.09722955e-02
 -3.73892005e-04 -5.08900857e-07 -1.61182943e-04 -2.04859318e-07
 -4.66394652e-01 -1.09186524e-01 -2.36366563e+00 -2.16747836e-02
  7.36560175e-02  2.42858657e-02  1.25684753e-01  2.90960539e-02
  4.60310297e-01  7.60046872e-02  7.97623718e-01  7.18483910e-02
  3.00343908e-02  1.57210183e-03  3.07280749e-01 -5.35740356e-06
  6.90554732e-02  9.42896183e-01  1.91622852e+00  5.15571749e-02
 -3.90741565e-02 -2.31491012e-01 -2.83211559e-01 -3.27894491e-02
 -1.19840591e-02 -1.82194788e-01 -7.19832458e-01 -9.19904807e-03
  1.79438519e-02  4.16310269e-02  2.78057828e-01  1.49696229e-02
 -5.84768672e-01  2.14738860e+00 -7.24755896e-01  2.71649188e+00
 -4.63627572e-01  1.85848390e+00 -4.25488884e-01  1.93819520e+00
  1.11746195e+01]
supnorm grad right now is: 11.174619464641044
Weights right now are: 
[  6.09550817  -3.51245258   2.95888257  -7.34469723  -5.84093946
   3.40376088  -2.5599453    6.62866885  72.83933721  66.33279767
  19.62388758  50.29814336  90.69900567 -14.1655874   10.79500354
   9.02753825   3.48339166  21.95614296   2.73188472 -10.82120338
 151.50466768  76.47027865 157.07039702  58.45400323   9.92547368
  -2.95091466   0.56745928  11.76878756   4.34472645  -1.02178.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1206.8789077831007
gradient value of function right now is: [-7.28425046e-03 -2.31740210e-03  3.90526383e-01 -1.28216156e-04
  7.28425046e-03  2.31740210e-03 -3.90526383e-01  1.28216156e-04
  1.99880126e-24  1.80261775e-05 -3.17953851e-04 -1.62081510e-03
 -2.82153980e-29  1.05227422e-07  1.60477781e-04  8.59818465e-04
  6.59240276e-04 -1.21917046e-01 -6.58391631e-02 -7.8979280.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.5951495650054
gradient value of function right now is: [-8.17632737e-02 -1.16093914e-01  3.50053621e-03 -4.25680297e-04
  8.17632737e-02  1.16093914e-01 -3.50053621e-03  4.25680297e-04
  1.32216550e-02  1.44243430e-04  5.53598927e-02  4.59442889e-06
 -9.53983146e-03 -7.65160315e-03 -7.40985968e-02 -4.12943936e-06
 -6.44198798e-01  1.91049328e-03  4.93892667e-01 -2.36501592e-02
 -1.92886536e-04 -5.34902121e-07 -2.11059688e-04 -2.79219052e-08
  2.34453308e-02  7.65417018e-02  1.35898490e+00 -3.52785357e-04
 -2.35439781e-02 -8.09286709e-03 -4.23168169e-02 -7.96651679e-03
 -4.81314852e-01 -1.23193181e-01 -1.02790236e+00 -7.54270641e-02
 -1.23779977e-02 -1.18261230e-03 -2.43912693e-01 -3.02368056e-09
 -4.60562342e-02 -5.27056192e-01 -9.16678349e-01 -4.26629967e-02
  4.76578646e-02  2.62124208e-01  2.76800933e-01  4.14163338e-02
  1.72222983e-02  1.76586685e-01  4.64908796e-01  1.62764143e-02
 -1.45984877e-02 -3.03492007e-02 -1.70268619e-01 -1.43808333e-02
  5.73418292e-01 -2.09596595e+00  4.03964855e-01 -2.05009996e+00
 -1.73834787e-01 -5.06557053e-01  4.45300889e-01 -2.20269139e+00
 -7.30370398e+00]
supnorm grad right now is: 7.303703981358425
Weights right now are: 
[  6.16148184  -3.61424185   2.93069391 -12.41468664  -5.90691313
   3.50555016  -2.53175664  11.69865826  73.03011073  70.75358289
  20.14120208  46.84218888  93.03857615 -13.23313462  11.46361503
   8.88937329   3.39836926  24.18410597   3.41795963 -10.86948518
 142.7953723   76.6165838  162.84582418  58.3933096   10.36715494
  -2.75289782   0.64258397  13.06410833   4.59667864  -0.17896025
  11.25707038 -33.12157537 -13.11595111   3.4421147    9.28155713
 -19.58716161  17.13565565 126.12239098   2.40466581  31.93783678
  14.76891179  -0.38562817   2.26659333  22.76833047  -9.80180580.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1206.2967873076514
gradient value of function right now is: [ 4.27066454e-03  1.89779686e-03  5.94784951e-02  3.82042420e-04
 -4.27066454e-03 -1.89779686e-03 -5.94784951e-02 -3.82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.1844641422485
gradient value of function right now is: [ 5.52792917e-02  8.31228723e-02  1.62428031e+00 -4.40336133e-04
 -5.52792917e-02 -8.31228723e-02 -1.62428031e+00  4.40336133e-04
 -1.12335552e-02 -9.49447073e-05 -3.63897496e-02 -1.06717209e-04
  4.37525004e-03  1.61756611e-02  6.62565420e-02  1.85683754e-05
 -8.09766841e-01 -1.81923566e-03 -1.96168883e-01 -9.49330827e-03
 -1.23867854e-04 -1.63734284e-07 -4.72596155e-05  1.28534400e-06
  2.59268635e-01  7.45752950e-02  2.46065946e+00 -1.18519034e-03
  4.78474640e-02  2.64119273e-02  8.78032155e-02  3.17267471e-02
  2.05491969e-01  7.92121053e-02  5.53068155e-01  7.13823487e-02
 -8.89519483e-03 -1.19902415e-03 -9.68506020e-02  3.15258132e-08
 -2.92619485e-02 -9.40203465e-01 -8.99907448e-01 -1.90404207e-02
  3.33431455e-02  2.22610127e-01  1.96600797e-01  2.69862034e-02
 -1.14149363e-02 -8.41142636e-02 -1.38933867e-01 -1.02448915e-02
  1.92347048e-02  1.96779321e-02  1.77574297e-01  1.78828034e-02
  2.29842179e-01  1.45435236e+00  5.88897289e-02  1.11720766e+00
 -5.78577931e-02  3.10093720e-01  1.92166498e-01  1.38467333e+00
 -9.17101265e+00]
supnorm grad right now is: 9.171012651022455
Weights right now are: 
[  6.25240586  -3.39579754   2.91691203 -10.77320051  -5.99783715
   3.28710585  -2.51797476  10.05717212  73.7519672   69.47094206
  20.15064511  42.1872283   94.89858226 -13.60499747  11.62751799
  10.27448701   3.58155611  23.03312826   2.91479444 -11.01936313
 140.19305216  76.95794998 171.49777206  58.3017516   10.08467784
  -3.10633219   0.74123739  12.6576036    4.8000055    0.6622498
  11.76223331 -33.24822915 -12.9197555    3.70703992   9.27595886
 -18.24281716  17.92327795 129.24052389   2.39280964  32.76632569
  13.56422136  -0.62469423   2.31218488  21.97148671  -9.90130674
 -12.24725715  19.78254923  -0.42552582 -78.86239694  -1.20964783
   0.7902616  -79.10737692  30.02724791  61.55294005   4.08003828
  28.37491779   3.67035629  -4.16615766  -3.84833089  -4.7693575582.0% of gradient descent iterations done. Method = Adam
objective value f84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.1203459876454
gradient value of function right now is: [-1.10301946e-01 -1.41233624e-01 -7.13772885e-01 -8.46607247e-04
  1.10301946e-01  1.41233624e-01  7.13772885e-01  8.46607247e-04
  2.27131534e-02  8.53198996e-05  6.52605566e-02 -3.47002983e-06
 -1.44593560e-02 -3.61037607e-02 -1.07699853e-01 -2.31057818e-07
 -2.23868388e-02  1.05581053e-03  7.55985402e-01  7.10060624e-04
 -4.38881324e-04 -3.89845739e-07 -2.20298446e-04  1.11903018e-08
 -8.26388373e-02 -8.64317700e-02 -7.38816480e-02 -1.42054606e-02
 -5.65201205e-02 -2.26485676e-02 -6.83601429e-02 -2.98446017e-02
 -6.62043276e-01 -1.18368478e-01 -1.26383034e+00 -5.05667703e-02
 -9.06984995e-04 -1.02571844e-04  7.90152343e-03  7.96325477e-09
 -3.15703923e-02 -1.18156028e+00 -1.48388139e+00 -1.99885513e-02
 -1.94187304e-02  3.28891883e-02  4.95232138e-02 -1.96382402e-02
  1.96853030e-02  2.59792223e-01  6.99674018e-01  1.56961566e-02
 -5.42132065e-03 -2.42467501e-02 -1.33811455e-01 -4.46424053e-03
  7.39107933e-01 -1.72443633e+00  5.35724138e-01 -1.74875129e+00
  5.25734210e-01 -7.65168404e-01  6.49957108e-01 -1.44668901e+00
 -2.21458531e+00]
supnorm grad right now is: 2.214585305966792
Weights right now are: 
[  6.03465606  -3.39842628   2.82875292  -9.91898078  -5.78008735
   3.28973459  -2.42981565   9.2029524   75.26496484  70.62199066
  19.98431818  39.82892576  95.34321677 -13.7877024   11.40063201
  10.50634161   3.41888982  23.67627498   2.62694382 -10.44588557
 138.7764053   77.19341475 179.90266171  58.30169889   9.63377859
  -2.95682444   0.50579862  13.58509351   4.87829232   0.28341905
  11.57376811 -33.46922567 -12.57803077   4.16559726   9.27684785
 -17.79012839  19.99303189 128.74304499   3.08930712  33.66417649
  13.19571105  -0.56146947   2.23385108  21.62527965 -10.78625264
 -11.75957765  20.50285335  -1.39222631 -80.06185368  -1.12126729
   0.92993696 -80.55424054  30.10931844  62.85982241   4.6996373
  28.19829257   3.70910616  -4.53155825  -3.58440627  -4.72617916
  -1.83494414  -2.53903524   4.35994503  -4.58939172  31.14667367]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.875258542981
gradient value of function right now is: [-5.96040475e-02 -3.78238826e-02 -1.51756584e+00 -1.26790481e-03
  5.96040475e-02  3.78238826e-02  1.51756584e+00  1.26790481e-03
  2.75822371e-02 -2.32516756e-06  1.91220951e-02  8.92046696e-05
 -8.11859341e-03 -1.97969114e-02 -3.25133178e-02 -2.42083573e-05
 -5.09583132e-02  7.31729691e-04  6.07073504e-01 -1.21282607e-02
 -9.23915754e-04 -4.71726920e-07 -2.73424322e-04 -4.34665060e-07
 -5.17251661e-01 -2.16132626e-02 -1.06544145e+00 -1.52125865e-02
 -3.19599835e-02 -7.96505772e-03 -3.34717704e-02 -1.41797060e-02
 -4.32864870e-01 -2.01252102e-02 -7.83678703e-01  2.44832551e-03
 -1.35701908e-03 -6.79456770e-04 -1.36472278e-01  1.99624223e-07
  4.61294803e-02 -1.10851538e-01 -1.42833557e-01  3.69144461e-02
  6.76246556e-02  1.98695381e-01  1.60210517e-01  6.83252744e-02
  1.26917184e-02  5.15189633e-01  9.10944082e-01  9.10141947e-03
  7.91774394e-03 -3.92965372e-03 -1.90273441e-02  6.09517024e-03
  6.16915041e-01 -4.42331601e-02  5.73592836e-01 -6.38743158e-01
 -2.62152586e-01 -1.26712317e-01  3.37022102e-01  1.59141067e-01
 -4.22336258e+00]
supnorm grad right now is: 4.223362579888216
Weights right now are: 
[  6.50651071  -3.18998535   2.75816453 -11.77128316  -6.251942
   3.08129366  -2.35922726  11.05525478  76.16732381  72.051572
  18.49956588  44.42941149  97.80237708 -14.22835657  11.29044361
   6.92509038   3.53822961  26.45601883   2.76841795 -11.26706953
 136.24152118  77.32136073 182.6422021   58.16631011   9.51122352
  -2.57379213   0.61693434  13.15917256   4.87254253   0.9430899
  11.60383319 -33.44684522 -12.51173979   3.4076391    9.28237541
 -19.41018665  15.47217819 131.22479029   2.40473037  33.93297491
  13.12911671  -0.57174195   2.48250718  22.00095077  -9.31191946
 -12.06772764  20.67264003   0.4993222  -81.56590366  -1.24183094
   1.21500689 -82.30093283  29.8988503   64.15688867   4.22669657
  27.96624422   4.14851445  -4.24862581  -3.75795844  -4.79156896
  -2.10642795  -2.57472785   4.34605191  -4.54666749  31.08212253]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.8954777445708
gradient value of function right now is: [ 7.69069256e-02  9.47958302e-02  6.11121389e-01  8.16820726e-04
 -7.69069256e-02 -9.47958302e-02 -6.11121389e-01 -8.16820726e-04
 -1.67944007e-02 -8.73097682e-05 -5.80581013e-02 -3.09205107e-07
  8.19625846e-03 -1.04445818e-02  5.71479227e-02  1.05899700e-07
  8.16830739e-01 -7.02323102e-03 -1.44792148e+00  1.47105653e-02
  4.88329935e-04  1.88266376e-07  1.58066131e-04  2.47839220e-09
  1.38528578e-01 -1.76131759e-01 -1.56320013e+00  8.34677166e-03
  5.89473636e-02  2.78450507e-02  1.06126655e-01  1.95268021e-02
  7.01940913e-01  2.27790278e-01  1.25513897e+00  1.00402395e-01
  7.10581713e-03  1.68017667e-03  1.61969430e-01 -5.89834876e-10
  4.10364613e-02  8.77695579e-01  1.03159297e+00  2.80047723e-02
 -1.03949113e-01 -5.24875700e-01 -5.07069390e-01 -8.83807636e-02
 -2.08291636e-02 -2.88899798e-01 -6.05580118e-01 -1.63899116e-02
  1.65774779e-02  4.25268911e-02  1.97458448e-01  1.40456923e-02
 -1.23530768e+00  2.24678563e+00 -1.18407217e+00  3.07715911e+00
  9.76619889e-01 -6.55032041e-02 -8.21939684e-01  1.89499766e+00
  1.25732960e+01]
supnorm grad right now is: 12.573295999941056
Weights right now are: 
[  6.41824849  -3.2404777    2.95805774 -11.47327521  -6.16367978
   3.13178601  -2.55912047  10.75724682  77.00021036  74.11615959
  18.24330467  40.0378058  100.3091863  -14.37678612  10.93802803
   8.85697399   3.69330422  23.93830031   2.03651612 -11.21496269
 133.17766967  77.48036739 189.37466524  58.05526694   9.41304658
  -2.60774573   0.76911168  15.15805897   4.87056857   1.13674629
  11.97583663 -33.76483785 -12.28518496   3.87792592   9.33962519
 -19.67211171  14.61440563 134.43426872   2.4671588   34.42079146
  12.49790343  -0.57509127   2.61877137  21.33981309 -10.67709206
 -12.41923581  20.52419659  -1.27509689 -83.33558177  -0.87484654
   1.15526355 -84.43300732  29.95778257  65.47255756   4.12103951
  28.18690331   3.33430679  -4.52712379  -3.75947656  -4.86308428
  -1.77074225  -2.71360589   3.84464786  -4.63829513  31.10305567]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.3388144382047
gradient value of function right now is: [ 8.80631811e-03 -4.71205014e-02  2.08515991e+00  1.93961018e-03
 -8.80631811e-03  4.71205014e-02 -2.08515991e+00 -1.93961018e-03
 -1.23669778e-02  1.39801614e-04  2.63764727e-02 -1.90275421e-04
  2.51370021e-03 -4.42418667e-02 -8.88015880e-02  4.32109298e-05
 -1.35791015e+00  4.02247700e-03  1.47020429e-01 -1.03772281e-01
  1.41242325e-03  9.39289461e-07  3.44452057e-04  3.12935870e-06
  4.40616518e-01  1.35672264e-01  4.26487865e+00  4.98226083e-03
 -9.26928193e-02 -3.70914639e-02 -1.40131893e-01 -5.00234622e-02
 -1.03940038e-01 -7.32787453e-02 -2.64496359e-01 -6.70657072e-02
 -8.47049222e-02 -5.75305349e-03 -1.13288500e+00 -1.16801164e-06
 -7.64355998e-02 -4.49598818e-01 -7.04598780e-01 -6.43806836e-02
  8.83185076e-02  6.66469753e-01  6.74210149e-01  6.68414142e-02
  5.86809465e-03 -1.25001805e-01 -1.35940859e-01  6.07531398e-03
 -1.65658357e-02 -3.16781734e-02 -2.34435663e-01 -1.48905757e-02
  5.48500007e-01 -1.66919843e+00  1.04889189e+00 -2.51940182e+00
 -1.62700093e+00 -1.50725813e-01  3.11765508e-01 -1.78306390e+00
 -1.52457546e+01]
supnorm grad right now is: 15.245754615421777
Weights right now are: 
[  5.94780323  -3.12846597   3.03103078 -12.95485671  -5.69323452
   3.01977428  -2.63209351  12.23882833  77.57471184  79.17114969
  18.20460736  35.97909266 101.68752514 -13.45943577  11.59620734
   8.98006413   3.87022837  23.9205327    2.65353278 -11.77246262
 130.40945949  77.68152353 193.36238531  57.87269943   9.74531862
  -2.36579183   0.72542375  15.15352197   4.41048523   0.80144367
  11.21806888 -34.37328627 -12.68532468   2.79864203   9.45010425
 -18.26010034  14.07244358 139.18174597   1.97572526  36.32402803
  12.84341332  -0.34776539   2.39631058  22.04057901 -10.27339017
 -12.21781123  20.85288317  -0.67150544 -85.14141883  -0.89121585
   0.92919276 -86.45094557  29.92996508  66.58101702   4.42821517
  27.84397566   3.12578326  -4.6067983   -3.58645372  -4.74798603
  -2.15350249  -2.48292961   3.85130708  -4.64425765  31.04825788]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.8744378976548
gradient value of function right now is: [-8.61631394e-03 -7.97139782e-03  1.28781357e-01  1.47930669e-04
  8.61631394e-03  7.97139782e-03 -1.28781357e-01 -1.47930669e-04
  1.14018232e-03  6.74324180e-06  4.248090.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1206.167564217118
gradient value of function right now is: [-7.92910178e-03 -3.32338239e-03 -2.02903593e-01 -1.65953876e-04
  7.92910178e-03  3.32338239e-03  2.02903593e-01  1.65953876e-04
  1.76016273e-30  4.71774588e-05 -2.12366098e-04 -8.81397266e-04
  2.21315326e-32  4.03821133e-07  1.69023183e-04  7.85012041e-04
 -9.69580128e-04 -2.19011198e-01  3.08955312e-03 -2.60088021e-01
  2.42181798e-38  5.12842556e-10  2.90424174e-07  9.44735148e-07
 -2.34059683e-05  1.55675767e-04 -9.56070850e-29  2.79697592e-02
  4.39482504e-04  5.40023331e-01  2.28612939e-01  3.71978752e-01
  5.17972964e-02 -1.81210612e-02 -3.02162770e-02  1.74317661e-01
 -1.64007994e-01  2.18528178e-01  1.48491550e-01 -7.53157198e-02
  1.97086866e-02 -2.80261138e-04  3.33105768e-02  1.30946070e-03
 -5.37206109e-04 -8.73712128e-01  4.55057864e-02 -3.53363708e-02
  3.64329325e-02  1.11151398e+00  4.55116534e-02  6.46682863e-03
 -2.84073440e-02 -3.85825348e-01 -4.52923924e-02 -1.36829188e-03
 -8.48132434e-01  3.71091775e+00  5.52117750e-01 -3.12161451e+00
 -1.10494441e+00  5.29630501e+00 -8.14460069e-02  4.45191153e-01
  3.29713173e+00]
supnorm grad right now is: 5.296305014914258
Weights right now are: 
[ -1.73463331   2.77616909   2.4307954   -0.68436598   1.00033459
  -2.81941683  -1.93647845  -0.85152234 -54.27541875  -7.74549986
  98.17335439  81.9366336    3.42671154  91.5314448  152.92071424
  90.87711278  31.29469854   5.71574971  -9.32921874   2.18102519
   2.81412833  85.16368874 162.08787341 167.41733466  74.66131287
 132.81347282  28.62552564   2.14797299  13.48242106   1.48656842
  -5.69196268   7.82010872   3.70244645  -2.10896968  32.75052713
   5.39403684   2.84674038   7.92150922  -9.17518514  -1.74958639
   3.90594.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.8693402610552
gradient value of function right now is: [-5.91961329e-03 -6.66128105e-03  1.87073098e-01  1.77286553e-04
  5.91961329e-03  6.66128105e-03 -1.87073098e-01 -1.77286553e-04
  5.86976394e-04  7.02917004e-06  4.1155592.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.3750128390745
gradient value of function right now is: [ 8.67185276e-04  4.92601106e-04  3.86494499e-01  8.71025997e-05
 -8.67185276e-04 -4.92601106e-04 -3.86494499e-01 -8.71025997e-05
  1.44653776e-29  1.08373334e-05  2.92594684e-05 -2.25463120e-06
 -6.88492357e-32 -5.61419068e-08 -2.09058561e-05 -2.60870311e-05
  6.51199259e-04 -2.55972138e-02 -1.19216125e-02 -3.91795540e-01
  5.90951398e-39 -6.65349819e-10 -7.80672601e-07 -1.76998439e-06
 -3.79815742e-05 -1.38747246e-04  5.46177424e-28 -2.03245217e-02
  2.64048024e-04  5.71471168e-02  1.95391807e-02  4.60459168e-02
  3.51260591e-03 -4.07289997e-02 -3.23583573e-04 -1.03436491e-01
  2.77794007e-02  1.38067495e-01  1.55343278e-02  4.07838655e-01
 -1.50651120e-02 -1.05723249e-03 -2.05679197e-02 -5.83607011e-04
 -5.23215634e-02 -2.35992435e-01 -6.61623850e-02 -9.69760068e-03
  1.67190638e-03  6.10148364e-02  2.21697744e-03  4.99129388e-04
  4.63479990e-03 -5.55690639e-03  4.68245725e-03  1.78973674e-03
  3.73233114e-02  5.29897809e-02  8.68811805e-02 -1.63808105e-01
 -3.81373767e-02  1.13385329e-01  2.27886126e-02 -4.15503267e-02
 -1.55141614e+00]
supnorm grad right now is: 1.5514161355435674
Weights right now are: 
[-2.60900889e+00  2.19255678e+00  2.56274518e+00  3.55726511e-01
  1.87471017e+00 -2.23580452e+00 -2.06842822e+00 -1.89161483e+00
 -5.42754187e+01 -8.24498457e+00  9.83076401e+01  8.28184938e+01
  3.42671154e+00  9.16414873e+01  1.55458168e+02  9.33431644e+01
  3.21484140e+01  6.03794632e+00 -9.74544791e+00  2.41186523e+00
  2.81412833e+00  8.51676051e+01  1.65867234e+02  1.73940358e+02
  7.97728034e+01  1.34766594e+02  2.86255256e+01  1.66407105e+00
  1.62502916e+01  1.28102893e+00 -6.54392537e+00  6.85715759e+00
  3.56870622e+00 -2.30512905e+00  3.28543665e+01  5.54066585e+00
  2.88632343e+00  7.92413030e+00 -8.62015282e+00 -2.10738403e+00
  4.46409822e+00  8.08557294e+01 -3.57812850e+00  9.92288027e+00
  3.46642018e+00  1.19350025e-01  3.97693967e+00  9.54074644e-01
  9.64641501e+01 -3.96425353e+00  1.11794932e+02  5.56221670e+01
 -1.60732638e+01  3.19851968e+00 -9.57775310e+00 -7.23138523e+01
  2.82802235e+00 -3.96311214e+00  6.76159581e+00  9.23718682e-01
  1.71900359e+00 -3.91653481e+00  7.35727207e+00 -4.74624807e+00
  3.10951090e+01]
(65,)
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.3812145891502
gradient value of function right now is: [ 1.84802322e-03  9.75194528e-04  3.87529954e-01  1.07324709e-04
 -1.84802322e-03 -9.75194528e-04 -3.87529954e-01 -1.07324709e-04
  1.86805248e-30  1.71473321e-05  5.08153750e-05  1.53241449e-04
 -1.52888252e-32 -5.72064035e-08 -3.52613798e-05 -1.28168879e-04
  1.87637042e-04 -3.41831465e-02 -8.50730738e-03 -3.78868864e-01
  1.84064222e-38 -1.67684686e-09 -1.90342088e-06 -5.84872409e-06
 -4.19087126e-05 -3.23167846e-05  1.26919685e-28 -6.54220815e-03
  2.12554648e-04  7.57334890e-02  2.84616019e-02  5.55872650e-02
  1.21985638e-03 -2.79060553e-02 -3.63575276e-04 -7.45443411e-02
  2.09240077e-02  1.41671512e-01  2.07090064e-02  3.77360577e-01
 -6.66558077e-03 -8.93543954e-04 -1.03955740e-02  5.93962167e-04
 -5.71534608e-02 -2.51511587e-01 -7.21853152e-02 -1.36330318e-02
  2.47381162e-03  9.45585151e-02  3.06881401e-03  7.71791757e-04
  3.32214320e-03 -2.29451901e-02  2.93990149e-03  1.66516044e-03
  2.20479155e-02  1.55341857e-01  9.92879205e-02 -2.57539323e-01
 -2.77615572e-02  2.46583337e-01  1.32435645e-02 -3.09678721e-02
 -1.58429245e+00]
supnorm grad right now is: 1.5842924497170656
Weights right now are: 
[-1.88463103e+00  2.82411753e+00  2.54026169e+00  8.85625274e-01
  1.15033231e+00 -2.86736527e+00 -2.04594474e+00 -2.42151360e+00
 -5.42754187e+01 -9.93290135e+00  1.00299897e+02  8.59492258e+01
  3.42671154e+00  9.18296300e+01  1.56715826e+02  9.43743126e+01
  3.26598754e+01  6.04800367e+00 -9.71657782e+00  2.23357602e+00
  2.81412833e+00  8.51716024e+01  1.67374608e+02  1.75897664e+02
  7.96242121e+01  1.36817890e+02  2.86255256e+01  1.50023122e+00
  1.60957040e+01  1.70527232e+00 -5.73288600e+00  7.14882643e+00
  3.78998305e+00 -2.07245546e+00  3.32149939e+01  5.72947432e+00
  2.31131704e+00  7.53679918e+00 -9.13506668e+00 -1.75073965e+00
  3.02037818e+00  8.38719711e+01 -4.49312766e+00  9.56602656e+00
  3.29754455e+00 -1.65614750e-01  3.63894011e+00  1.54519013e+00
  9.80760069e+01 -3.85685178e+00  1.13354359e+02  5.72298007e+01
 -1.59912444e+01  3.45882837e+00 -8.99253134e+00 -7.31417030e+01
  2.90424773e+00 -3.72894685e+00  6.32978182e+00  8.42838657e-01
  2.07182518e+00 -3.70951411e+00  6.58373487e+00 -4.84801109e+00
  3.10052442e+01]
(65,)
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.3835360777277
gradient value of function right now is: [ 1.77407244e-03  9.27185812e-04  3.45539887e-01  1.17089656e-04
 -1.77407244e-03 -9.27185812e-04 -3.45539887e-01 -1.17089656e-04
  8.55918259e-31  1.16081319e-05  5.32242259e-05  1.07492457e-04
 -1.30556298e-32 -4.72353847e-08 -4.00032086e-05 -1.05289615e-04
  1.68959537e-04 -3.03018095e-02 -7.81328848e-03 -3.69164351e-01
  1.61648387e-38 -1.93308720e-09 -2.43136600e-06 -6.52535208e-06
 -3.86508762e-05 -3.07234470e-05  4.82380526e-29 -5.97091187e-03
  5.69575231e-05  6.88413279e-02  2.50290649e-02  4.95118887e-02
  2.54246521e-03 -2.46856737e-02 -6.00649514e-04 -6.70956826e-02
  1.69164362e-02  1.30888104e-01  1.43829408e-02  3.80868584e-01
 -5.82181978e-03 -7.80050418e-04 -1.00269521e-02  6.19547660e-04
 -6.10271174e-02 -2.49674852e-01 -7.89192820e-02 -1.49634791e-02
  2.32473898e-03  9.10243130e-02  2.91935406e-03  7.36189671e-04
  3.00022682e-03 -1.07975194e-02  2.04305260e-03  1.83632243e-03
  2.69764575e-02  1.41057274e-01  9.00268772e-02 -2.28575575e-01
 -1.89265304e-02  2.37684147e-01  1.25340247e-02 -4.83631363e-02
 -1.61877473e+00]
supnorm grad right now is: 1.6187747292497932
Weights right now are: 
[ -2.12142979   2.24467831   2.36102788  -0.76446823   1.38713107
  -2.28792605  -1.86671093  -0.77142009 -54.27541875 -10.76264348
 101.62938067  89.09372186   3.42671154  91.91080678 158.85750856
  94.78851294  31.79844005   6.504552    -9.90352872   1.95291519
   2.81412833  85.17576043 169.95627664 179.52792441  81.57387775
 139.62562695  28.62552564   2.6266563   17.93476301   1.433813
  -6.08165506   6.47037724   3.71773922  -2.01580577  34.04105882
   5.57574613   2.52099856   7.52626249  -8.69502775  -1.77368118
   3.71573443  85.04800071  -3.41353087   8.35397491   2.87526147
  -0.50288075   3.22387402   0.58205403  99.24448478  -4.25883274
 114.58359939  58.48043164 -15.18848792   3.64378551  -7.30694112
 -74.86235391   2.69179343  -4.01570585   6.3993721    0.57947006
   1.69145929  -3.92573914   8.07090674  -4.41777047  31.14317345]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.3915171578928
gradient value of function right now is: [ 1.73368164e-03  8.98842233e-04  3.22801329e-01  1.01785999e-04
 -1.73368164e-03 -8.98842233e-04 -3.22801329e-01 -1.01785999e-04
  2.29123249e-31  1.20023435e-05  5.50970127e-05  1.21293703e-04
 -4.35211738e-33 -3.18134208e-08 -3.98570447e-05 -1.10704713e-04
  2.05117326e-04 -2.90416413e-02 -8.87453448e-03 -3.44390972e-01
  4.08616729e-39 -1.35087681e-09 -2.03737570e-06 -5.60708948e-06
 -3.03956498e-05 -3.48580955e-05  1.96891443e-29 -7.05547366e-03
  6.33892797e-05  6.68804002e-02  2.41795646e-02  4.78646435e-02
  2.53393180e-03 -2.97249673e-02 -6.91959039e-04 -6.85249008e-02
  1.43060801e-02  1.20416702e-01  1.34066671e-02  3.44840165e-01
 -5.73764646e-03 -7.67957028e-04 -9.80137940e-03  4.30172619e-04
 -5.40231017e-02 -2.34627628e-01 -6.99342125e-02 -1.31669446e-02
  2.29275644e-03  8.89542051e-02  2.77379704e-03  7.83431930e-04
  3.82889599e-03  4.41932391e-03  2.92980089e-03  2.10139610e-03
  2.61632021e-02  1.34596801e-01  8.51326539e-02 -2.08439230e-01
 -1.45531889e-02  2.26010035e-01  1.53817845e-02 -6.11297374e-02
 -1.50866768e+00]
supnorm grad right now is: 1.508667681166136
Weights right now are: 
[ -2.7703388    3.43906022   2.56924029   0.23201129   2.03604008
  -3.48230796  -2.07492333  -1.76789961 -54.27541875 -10.40898424
  98.49520548  90.89412624   3.42671154  91.92792253 163.62029233
  94.85688363  32.42198649   6.06836985  -9.70150686   2.43289033
   2.81412833  85.17580648 173.59822373 182.25976289  84.17692012
 141.4757711   28.62552564   2.33483955  16.67334796   1.84197167
  -5.9373699    6.97936581   3.57846327  -1.62284332  34.05906921
   5.92028029   3.36003858   8.04303014  -8.80767587  -1.84315663
   3.22783172  87.75504936  -3.69846628   8.18762047   3.24302423
  -0.38100567   3.41691696   1.58328113 100.61284626  -4.18463354
 115.89357643  59.77739131 -15.55383175   3.40906561  -7.32495687
 -75.49756179   2.69455022  -3.95684657   6.25946984   0.7475484
   1.97647538  -3.91373779   7.64858323  -4.65536349  31.06545139]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.3943409874782
gradient value of function right now is: [ 9.02916365e-04  4.77490122e-04  3.11619505e-01  7.11084215e-05
 -9.02916365e-04 -4.77490122e-04 -3.11619505e-01 -7.11084215e-05
  1.00538853e-31  1.46610709e-05  3.39253385e-05  2.61255802e-05
 -3.23305896e-33 -2.26524211e-08 -2.29033622e-05 -3.41834955e-05
  2.05268259e-04 -2.91167447e-02 -1.00164629e-02 -3.52167274e-01
  2.67362513e-39 -1.31812688e-09 -1.70403283e-06 -4.14143213e-06
 -2.20707958e-05 -4.30040328e-05  9.21093239e-30 -7.09854328e-03
  4.91301579e-05  6.71878501e-02  2.34896523e-02  4.75175831e-02
  3.76881068e-03 -3.47213729e-02 -1.13578918e-03 -7.21772062e-02
  1.33722385e-02  1.19189416e-01  1.22605581e-02  3.52822893e-01
 -7.21612291e-03 -7.60817228e-04 -1.16107008e-02  1.58931036e-04
 -5.58285883e-02 -2.39500862e-01 -7.18668306e-02 -1.37144712e-02
  2.49811889e-03  9.46655339e-02  2.99995215e-03  8.76142570e-04
  4.05437649e-03  1.17991287e-02  3.04439999e-03  2.24669143e-03
  2.75466334e-02  1.49833244e-01  8.33605199e-02 -2.02937321e-01
 -1.49595647e-02  2.47083671e-01  1.77749640e-02 -6.44934980e-02
 -1.35880802e+00]
supnorm grad right now is: 1.3588080192994068
Weights right now are: 
[-1.64388969e+00  3.56943186e+00  2.54340008e+00  1.14621080e+00
  9.09590967e-01 -3.61267960e+00 -2.04908312e+00 -2.68209912e+00
 -5.42754187e+01 -1.00102423e+01  1.01752996e+02  9.36219034e+01
  3.42671154e+00  9.23281895e+01  1.63668736e+02  9.57171833e+01
  3.21505012e+01  6.01254760e+00 -9.81615780e+00  2.08425558e+00
  2.81412833e+00  8.52009394e+01  1.74293635e+02  1.83231751e+02
  8.57267645e+01  1.42909348e+02  2.86255256e+01  2.82925067e+00
  1.47378469e+01  1.85213763e+00 -6.29607191e+00  6.76337700e+00
  2.14118894e+00 -1.82544786e+00  3.31777606e+01  5.36754395e+00
  3.36687863e+00  8.11521204e+00 -7.99970383e+00 -1.57362991e+00
  2.35254881e+00  9.05559293e+01 -3.95937564e+00  7.30207642e+00
  3.20019858e+00  1.18492770e-02  3.05648809e+00  2.07174418e+00
  1.02177933e+02 -4.13008819e+00  1.17448899e+02  6.04526081e+01
 -1.44160297e+01  3.22723742e+00 -5.40525458e+00 -7.70083334e+01
  2.77665504e+00 -3.89083358e+00  6.60009393e+00  5.17663963e-01
  1.86368151e+00 -3.77909342e+00  7.63282952e+00 -4.61432789e+00
  3.10174863e+01]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1082.3683970775924
W_T_median: 1054.7891979678384
W_T_pctile_5: 965.0391399109144
W_T_CVAR_5_pct: 936.8066958350265
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.25
F value: -1207.3943409874782
-----------------------------------------------
