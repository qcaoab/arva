Starting at: 
2022-06-17 22:26:16
tracing parameter entered from terminal:  0.7


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1704.1510403819123
gradient value of function right now is: [ 1.13500605e+00  6.97286594e-01  1.11989813e+00  1.13176512e+00
 -1.13500605e+00 -6.97286594e-01 -1.11989813e+00 -1.13176512e+00
 -1.87521738e-01 -5.85890069e-03  8.40901516e-02 -3.76841866e-01
  5.02372192e-01  1.74051112e-01  8.46918432e-03  8.31378427e-01
  5.29896294e-02  2.83376656e-02  1.17223964e-03  7.33861420e-02
  3.64410890e-02  2.37028849e-02  9.57046140e-04  4.44704168e-02
 -2.29121782e-01  3.49759661e-02  5.53299336e-02  2.33620830e-02
 -3.24371470e-01 -9.75878180e-02 -6.11220600e-02 -5.56258333e-02
 -4.11519121e-02 -2.21886811e-02 -2.46289847e-03 -1.12131406e-02
  6.37648773e-02  1.46349445e-01  1.38143038e-01  7.14299550e-02
  4.30350221e-01 -2.55144096e-02  6.05467861e-01  1.70410674e-01
  3.40217865e-01  1.86749305e-01  5.00433633e-01  2.35652710e-01
  1.43743833e-01  4.74976895e-02  2.32962049e-01  9.35780191e-02
  5.35840298e-01  1.36422407e-01  6.65714610e-01  2.50482701e-01
  7.35246702e-03  4.29301256e-02  6.00105742e-01  1.18380560e+00
 -3.93554315e-01  2.39848239e-02  5.04052962e-01  2.41260041e+00
  2.87515846e+00]
supnorm grad right now is: 2.8751584637049357
Weights right now are: 
[-1.70752086  1.69715764  1.30398353  0.80884416  1.96208957 -1.80584933
 -0.90504626 -1.52487254  2.49032967  0.12116087 -8.9533955   2.88238066
  2.10847627  3.60262541  7.45418642  1.00344518  4.54712427  2.32303935
  4.20946808  3.43285009  4.10191129  2.31100426  4.32883235  4.24454952
  0.76704359  1.84377133 -0.41536789  4.67676113  1.77406104  4.70362801
  4.70918336  4.51948364  7.12605822  6.45504449  4.2065915   5.82428122
 -0.91912109  0.64112401 -0.18482271  5.70489545 -1.01895265  0.17795853
 -1.02411183  3.34629739  1.39988189  4.39289434 -2.31114343  4.37113878
 -0.16772938  3.47381792  0.75450566  2.42282432 -0.03252105  8.45262951
 -4.63603056  9.54056304  5.97049435  0.52670732  1.87845165 -1.42983996
  4.7296205   2.8574376   3.17155857 -0.91589578 30.26429504]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1704.1204891844063
gradient value of function right now is: [-1.13774942e+00 -4.47863574e-01 -2.77887345e-01 -2.45189574e-01
  1.13774942e+00  4.47863574e-01  2.77887345e-01  2.45189574e-01
 -1.14899415e+00 -1.09210354e+00 -5.60728444e-01 -1.94998779e+00
  7.80164044e-02  1.04314582e-01  1.20601636e-02  2.48126495e-01
  3.62294916e-03  3.32576884e-03  3.88434698e-04  7.55872829e-02
  2.81119917e-03  1.80424019e-03  2.12962367e-04  6.86290794e-02
  2.71398661e-01  2.63234422e-02  6.14840731e-02  4.85236971e-03
 -4.13420447e-01 -6.08234608e-02 -9.24249051e-05 -1.98276306e-03
 -7.48505151e-01 -3.09752020e-02 -2.02176812e-02  1.49238539e-03
  4.60378027e-01 -4.85160088e-02  2.40063761e-02 -7.05993830e-02
  2.95910030e-01  2.90198685e+00  6.88011590e-01  2.22401783e+00
  9.13591908e-02  2.09255707e-01  2.53251005e-01  2.02433581e-01
  1.07349769e-02  1.02740086e-01  2.57611981e-02  8.08436862e-02
 -3.82142865e-02  2.27055629e-02  1.95159020e-01  3.70342165e-02
 -4.99423520e-03 -2.24078324e-03 -2.67702287e-01 -6.21426900e-02
  6.22588291e-01 -2.39325808e-01 -1.23936594e+00 -1.87772460e+00
  1.04976122e+01]
supnorm grad right now is: 10.497612192284985
Weights right now are: 
[-2.27667191  1.90783016  1.32985423  0.95199898  2.53124062 -2.01652185
 -0.93091696 -1.66802737  2.56424097 -0.78415695 -9.3510931   4.16195417
  2.26096258  6.81343944 15.80273934  1.20106438  5.75562751  4.99346317
 11.49283839  5.08573714  5.73598521  5.21399389 11.3769439   6.17948763
  2.15871499  2.25346984  0.05755994  7.23205768  2.21254477  5.88923957
  4.72952259  8.17248627  7.43524163  6.36425673  3.60435155  6.51268594
 -1.59785675 -0.89166939 -2.64842399  9.42640538  0.41591313  0.61501771
 -2.93226756  3.12055813  0.14386879  5.23711089 -3.07524568  5.82010253
  0.57998297  5.4704685   1.57212869  4.09280343 -2.52816015 12.25348965
 -5.39913488 13.18280912 14.6678883   2.24321383  2.27706115 -1.52928203
  4.56814038  3.19941213  3.10491412 -0.87027437 30.202893  ]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1702.9260804997548
gradient value of function right now is: [-2.49316581e-02  2.71577402e+00 -3.91572213e-01 -6.66888053e-01
  2.49316581e-02 -2.71577402e+00  3.91572213e-01  6.66888053e-01
  2.98079270e-01  2.56337972e-01  7.93528334e-02  2.24218958e+00
 -5.20629920e-01 -2.30201973e-01 -2.82302792e-02 -7.88042413e+00
 -1.92722539e-02 -7.56580604e-03 -8.77115579e-04 -5.01995459e-01
 -6.35787067e-03 -2.10896321e-03 -2.58850576e-04 -2.49000116e-01
  8.53143078e-01  4.36706421e-01  1.89226558e-01  8.98005184e-02
  9.87842689e-01  3.20863139e-01  9.63866077e-02  2.83364683e-02
  3.87623873e-01  1.28493426e-01  7.18101877e-02  2.30345135e-02
  1.08397758e+00  8.31937726e-01  2.24765224e-01  2.65276250e-01
 -1.27408175e-01 -1.07404389e+00 -5.93935330e-01 -9.21837874e-01
 -7.40825208e-02 -4.53728197e-01 -3.43060739e-01 -3.98911359e-01
  5.10648081e-04  2.84696281e-02  6.77667281e-02  2.46938673e-02
 -1.99551520e-01 -3.58165213e-01 -7.78391836e-01 -3.37969190e-01
 -1.95587925e-02  1.57912790e-01  2.86163571e+00 -1.34331301e+00
 -1.75554472e+00  1.32218369e+00  3.17672362e+00 -1.39861156e+00
 -1.72050429e+01]
supnorm grad right now is: 17.205042913953648
Weights right now are: 
[-2.54259158  2.15136881  1.29701174  0.90499125  2.79716029 -2.2600605
 -0.89807447 -1.62101964  1.85333551 -1.25098897 -8.66556247  5.08094368
  3.53493566  7.61140317 19.93818702  1.42533967  8.42058471  6.05783291
 17.76693965  5.19316774  9.28107289  7.81234661 17.87093551  6.97984615
  3.73249507  1.64009229 -1.03711704  7.85491207  2.80791737  6.33185362
  3.38620445  8.56296192  8.51481441  4.7598005   0.7312783   2.44144616
 -1.02927647 -1.28819824 -5.5195441  10.23863702  1.73738674  0.73478472
 -4.31169863  2.45061185 -1.07396897  4.66211931 -3.88935986  6.22811986
  2.57615915  6.33452612  4.2471553   5.96987397 -2.84752733 14.5897172
 -5.86211826 15.28041408 18.79763489  2.60505192  2.7415359  -1.36501265
  4.47868831  2.84598794  3.14215182 -1.06715639 30.10938319]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1701.4858159851767
gradient value of function right now is: [-3.94714008e+00 -3.88290842e+00 -3.12634111e+00 -2.95243100e+00
  3.94714008e+00  3.88290842e+00  3.12634111e+00  2.95243100e+00
 -8.98524822e-01 -1.17439352e+00 -5.22406593e-01 -2.18699072e+00
  4.31841831e-02  5.04327474e-02  2.29632197e-03  1.80137335e+00
  6.82650834e-04  1.08163517e-03 -1.32606100e-05  1.74093389e-01
  2.18046204e-04  3.86753368e-04 -6.30317336e-06  1.27647699e-01
 -2.53704203e-02 -4.42080956e-02 -1.12218566e-02  1.20549696e-04
 -4.64564405e-01 -1.25019411e-01 -5.43344475e-02 -1.71298947e-02
 -5.19234783e-01 -1.32530462e-02 -5.58150977e-03  7.59458552e-03
 -4.40808932e-02 -4.30309012e-01  4.53973389e-02 -1.63802134e-01
  2.82045325e-03  2.69318507e+00  1.94078032e-01  2.21599535e+00
 -6.73610352e-02  7.44932662e-02 -9.41232277e-02  4.23675295e-02
 -1.93017400e-03  3.18726890e-02 -6.47810302e-02  2.01389619e-02
  2.62002895e-01  2.01789984e-01  8.86445733e-01  1.94245526e-01
  4.60220549e-02 -2.42756601e-01 -1.50419692e+00  4.06791467e-01
  1.07458434e+00 -6.10812020e-01 -2.17146720e+00 -1.09832441e+00
  1.74294505e+01]
supnorm grad right now is: 17.429450476251265
Weights right now are: 
[-2.71441462  2.32277948  1.20489741  0.80245129  2.96898333 -2.43147117
 -0.80596014 -1.51847968  0.83236911 -2.26584995 -8.27475058  5.49009774
  4.73319034  8.29296824 23.27775733  1.70479245 10.91532245  7.16129439
 21.05322732  5.77190153 13.36966983 14.10229535 19.43809142  8.32567577
  4.85981113  1.1066763  -0.91046446  9.039604    2.04849111  5.33571561
  1.61196721  6.99419839  9.50091503  4.21742688 -1.04260469  2.27428534
 -1.19469518 -1.59590311 -5.7711763  11.62409765  1.61233747  1.19883386
 -5.9921983   2.72295814 -2.0493948   5.38282036 -3.3745899   6.77874505
  3.55265769  7.0801378   3.71943394  4.79240974 -2.87657541 17.00437936
 -5.37211625 17.61306536 17.63250456  3.17650797  2.87611355 -1.51626634
  4.73902164  2.75168347  3.54992985 -1.36626617 30.30902376]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1703.2703199609377
gradient value of function right now is: [ 2.21078514e+00  3.27572940e+00  1.75675224e+00  1.48593165e+00
 -2.21078514e+00 -3.27572940e+00 -1.75675224e+00 -1.48593165e+00
  1.54744197e-01  5.36189095e-01  4.44502137e-02  2.01101046e+00
 -2.99131638e-02 -2.13583902e-01 -3.12336800e-03 -4.00439855e+00
 -4.81094864e-04 -4.75616609e-03 -6.45446637e-05 -2.96320555e-01
 -5.88244267e-05 -7.17400260e-04 -1.64423194e-05 -1.74240903e-01
  7.30244639e-02  3.11470657e-02  2.42959970e-02  6.60625779e-03
  1.62705128e+00  3.06707528e-01  1.67379914e-01  5.16116472e-02
  1.02912233e-01  1.99118936e-02  1.83031083e-02  6.68999649e-03
  5.80859049e-01  7.56529953e-01  2.48477350e-01  4.36302771e-01
 -3.49328618e-02 -8.05030337e-01 -1.74388137e-01 -6.25971756e-01
 -1.79411890e-02 -2.22845212e-01 -7.88386244e-02 -1.57592654e-01
  1.12588431e-03  4.15813465e-03  2.11447015e-01 -5.16255957e-03
 -2.35784982e-01 -2.92780069e-01 -1.07105063e+00 -2.12319220e-01
 -4.80635877e-02  2.21183574e-01  2.72106929e+00 -2.15369317e+00
 -2.16003068e+00  1.88890079e+00  2.18908609e+00 -1.56951215e+00
 -1.74578684e+01]
supnorm grad right now is: 17.457868372430262
Weights right now are: 
[-2.77049836  2.48266699  1.31867922  0.93118262  3.02506707 -2.59135868
 -0.91974195 -1.647211    0.60720331 -2.77981926 -8.30703743  5.8036702
  6.17256672  9.64149635 26.77395923  1.91689524 14.46210878  9.46910622
 26.91349982  6.33026632 18.23538736 22.02309845 22.63205588  9.19852985
  6.72215101  1.65661599 -0.11412347  8.88241497  1.78759027  6.04778815
  1.0436908   6.67447652 12.51583693  3.10409453 -2.34842728  0.45694623
 -0.73365166 -1.74099158 -7.69466664 11.45256206  1.47759036  0.55033441
 -7.43009794  2.34718422 -0.59584386  5.27141964 -3.0176464   7.80934474
  7.32050853  6.74181103  4.10079492  3.73655928 -2.95211436 19.07911823
 -5.34333396 19.01105231 18.02821034  3.5217224   2.86866664 -1.48083481
  4.42877012  2.62356448  3.86485581 -1.33011524 29.84705603]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1703.4143142182495
gradient value of function right now is: [-1.66717402e+00  6.28841042e-03 -2.18454671e+00 -2.24805097e+00
  1.66717402e+00 -6.28841042e-03  2.18454671e+00  2.24805097e+00
  1.67717149e-01  6.10404330e-01  5.96008592e-02  1.91250774e+00
 -2.00773561e-02 -3.35758153e-01 -1.46629141e-03 -7.02339501e+00
 -1.35577865e-04 -3.10628184e-03 -1.01957981e-05 -9.51078630e-02
 -6.02129225e-06 -1.98707878e-04 -8.71065349e-07 -2.51673410e-02
  7.60134783e-02  4.02192455e-02  3.34110790e-02  9.41412140e-03
  2.78655115e+00  6.28633855e-01  3.21761998e-01  9.11160805e-02
  6.91656947e-02  1.38846427e-02  1.27988446e-02  5.63909672e-03
  3.03685074e-01  4.60807292e-01  1.68464240e-01  1.33205625e-01
 -6.22004654e-02 -1.22230450e+00 -2.52546749e-01 -8.54811087e-01
 -1.57772949e-01 -4.36909360e-01 -4.67871673e-01 -2.81042550e-01
  1.07389343e-03  3.13114640e-02  9.43516468e-02  5.93548985e-03
 -1.36768372e-01 -1.99547353e-01 -3.69488726e-01 -1.18063314e-01
 -3.98868222e-02  1.80502437e-01  2.52454847e+00 -7.28571869e-01
 -1.26899522e+00  5.88789707e-01  1.92787332e+00 -1.27750142e-01
 -1.53574044e+01]
supnorm grad right now is: 15.357404418264055
Weights right now are: 
[-2.85957726e+00  2.50892389e+00  1.17917533e+00  7.80929655e-01
  3.11414597e+00 -2.61761558e+00 -7.80238065e-01 -1.49695804e+00
  9.15335259e-01 -3.49723246e+00 -7.78204915e+00  5.77034253e+00
  9.96187448e+00  1.09072276e+01  3.23637323e+01  1.61390463e+00
  1.89008033e+01  9.02092774e+00  3.12033366e+01  7.13668776e+00
  1.98723987e+01  2.81300525e+01  2.33853879e+01  9.46916900e+00
  8.72285495e+00  9.79726724e-01 -8.10323585e-01  8.68697354e+00
  2.04018602e+00  5.56688941e+00 -1.62996958e-03  7.14174027e+00
  1.67962874e+01  1.55765084e+00 -3.78869005e+00 -1.06501847e+00
 -8.93407813e-01 -1.40486302e+00 -8.85078415e+00  1.14766087e+01
  3.03876238e+00  4.05796662e-01 -7.91510047e+00  2.61587059e+00
 -1.81007370e+00  5.63579375e+00 -2.87574816e+00  8.64022179e+00
  9.14926551e+00  7.29657307e+00  4.37035238e+00  3.41164202e+00
 -3.79218547e+00  2.01777242e+01 -5.32493624e+00  1.98118989e+01
  1.72461309e+01  4.06574636e+00  2.86784087e+00 -1.45182286e+00
  4.63086057e+00  2.77299063e+00  4.31775767e+00 -1.16993239e+00
  3.00850040e+01]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -1702.6039153021225
gradient value of function right now is: [-5.01976255e+00 -5.97516932e+00 -4.91288090e+00 -4.81681629e+00
  5.01976255e+00  5.97516932e+00  4.91288090e+00  4.81681629e+00
 -1.21123373e-02  1.49793261e-01 -2.06348288e-02 -5.73416335e-01
 -1.85430459e-03 -5.62629367e-03 -3.03725627e-04  1.37999404e+00
 -5.80641938e-06  9.03756797e-04 -1.65594390e-06  2.15169943e-01
  9.76800327e-07  8.37312559e-04 -8.93849589e-07  2.09956130e-01
  3.20354134e-03  3.41453333e-03  3.58922983e-03  8.23904658e-04
 -7.48929950e-02 -7.21851977e-02  8.14763559e-02 -1.83476339e-02
 -5.72960127e-03  3.94374989e-03  3.73228475e-03  1.63043932e-03
 -7.96445659e-01 -2.60169167e-01  7.61305422e-03 -6.43085512e-02
  2.12428529e-02  4.80003223e-02  9.26972988e-03  1.21198220e-01
  2.03055617e-01  1.27624665e-02  2.60123399e-01  5.45094544e-02
 -1.19339754e-03 -6.47095541e-02 -4.25915783e-02 -3.38360522e-02
  3.19452209e-01  9.46148423e-02  6.08972753e-01  1.05822059e-01
  5.10519644e-02 -2.62987580e-01  1.93760408e-01  2.14627439e+00
  1.81269073e-01 -6.62400325e-01 -1.13800829e-01  1.95170446e+00
  4.58475173e-01]
supnorm grad right now is: 5.975169317208248
Weights right now are: 
[-2.95755493  2.53004034  1.13798704  0.66458769  3.21212364 -2.63873203
 -0.73904977 -1.38061607  1.11851425 -3.8582923  -8.87551199  5.96935534
 13.72244375 12.3508474  37.66963533  1.81648358 24.03834569 12.60661148
 32.01878396  7.51693039 20.35516211 34.93637539 23.70289939  8.30154843
 10.34613601  2.03385433  0.43721482  9.21917047  1.9939019   5.98040382
  0.07124886  7.18203842 21.24623377 -0.83540606 -4.91193819 -4.31174823
 -0.6315524  -1.15559252 -9.60937651 11.64594287  3.60614326  0.65849222
 -7.81899727  3.08332891 -0.8352045   6.0268033  -2.6778734   9.39287557
 10.83702667  7.53221515  3.83198187  1.63454589 -3.08817585 22.24857241
 -4.36852471 21.89387818 17.76298529  3.35393172  2.55802985 -1.61160031
  4.70906871  2.72031051  4.14276463 -1.26323859 29.95290336]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1704.4512104060896
gradient value of function right now is: [ 4.45862137e-01  2.11166645e+00  4.69105462e-01  4.60561492e-01
 -4.45862137e-01 -2.11166645e+00 -4.69105462e-01 -4.60561492e-01
 -1.60709209e-01 -3.77119822e-01 -5.91538452e-02  4.11987840e-01
 -7.78641100e-04 -8.17283323e-02 -5.35992663e-04 -4.18920567e+00
 -2.38075044e-06 -7.75446129e-04 -1.55819982e-05 -1.68987618e-01
 -1.27744518e-06 -6.37244546e-04 -1.63509983e-05 -1.73171761e-01
  2.26700182e-02  3.43060254e-03  3.29975339e-03  6.62321599e-04
  6.22965690e-01  3.39830925e-01  1.90359111e-01  5.88836371e-02
 -3.24556364e-02  1.04718607e-02  9.10531253e-03  7.34637482e-03
  1.44261282e+00  7.28707722e-01  2.59619718e-01  3.00291735e-01
 -7.18125521e-04  8.07957564e-01  1.12838192e-02  7.32349934e-01
 -5.25581154e-02 -1.66430372e-01 -1.91745356e-01 -1.02563021e-01
  2.56590587e-03  1.04342178e-01  2.10592646e-01  5.78901219e-02
 -2.02214321e-01 -2.19434783e-01 -7.43500617e-01 -1.43957654e-01
 -6.98287125e-02  2.75424312e-01  1.81929070e+00 -2.02833694e+00
 -1.27872041e+00  1.63416543e+00  1.14025801e+00 -2.48449241e+00
 -7.18479729e+00]
supnorm grad right now is: 7.184797291394552
Weights right now are: 
[-2.78516900e+00  2.48893043e+00  1.31489708e+00  8.42067746e-01
  3.03973771e+00 -2.59762212e+00 -9.15959809e-01 -1.55809613e+00
  1.22504821e+00 -4.13476263e+00 -9.69755143e+00  5.90167212e+00
  1.68062847e+01  1.34664200e+01  4.00635106e+01  1.90186328e+00
  2.49960154e+01  1.55774388e+01  3.31392685e+01  7.62400603e+00
  2.06903619e+01  4.22148002e+01  2.47851793e+01  7.63306575e+00
  1.27519080e+01  2.06244757e+00 -9.75309933e-03  8.07451330e+00
  1.85812053e+00  6.45429995e+00  8.62931626e-02  7.40120151e+00
  2.53609073e+01 -2.60336791e+00 -6.03879313e+00 -7.15562529e+00
 -6.63602640e-01 -7.94064181e-01 -9.92520587e+00  1.21870961e+01
  2.48944685e+00  5.47996662e-01 -8.86089977e+00  3.02533949e+00
 -1.79500051e+00  5.15135420e+00 -2.94453980e+00  9.69395881e+00
  1.39953542e+01  8.51318700e+00  4.09138237e+00  1.35645936e+00
 -4.08780890e+00  2.30720843e+01 -5.05748354e+00  2.24279654e+01
  1.88277672e+01  3.36698801e+00  3.38518968e+00 -1.91413717e+00
  4.76733077e+00  2.29233267e+00  4.59072053e+00 -1.90313746e+00
  3.01696315e+01]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1701.4098189554431
gradient value of function right now is: [ 2.97962879e+00  4.61489969e+00  2.29421458e+00  2.30425797e+00
 -2.97962879e+00 -4.61489969e+00 -2.29421458e+00 -2.30425797e+00
  1.77187278e-01  6.56161678e-01  7.07691334e-02  2.01349424e+00
 -6.88639208e-04 -1.69978542e-01 -6.85505621e-04 -6.90386436e+00
 -1.02075749e-06 -4.26635875e-04 -1.11025880e-05 -1.44100966e-01
 -4.38854504e-07 -2.75209901e-04 -1.28835783e-05 -1.59897677e-01
 -2.05835812e-02  2.52394167e-03  2.25951250e-03  6.51713570e-04
  2.07163741e+00  4.18434659e-01  2.45835059e-01  6.25728704e-02
  5.17213097e-02  1.33890341e-02  1.24256863e-02  9.34195012e-03
  1.22924791e+00  1.07130093e+00  3.95105596e-01  4.52113606e-01
 -4.89294467e-02 -1.57978127e+00 -1.82002548e-01 -1.25721376e+00
 -1.25172021e-01 -3.00122588e-01 -3.84216875e-01 -2.13331813e-01
  6.08333822e-03  9.50421761e-02  3.25956047e-01  4.87777205e-02
 -2.57198999e-01 -2.58821621e-01 -1.02823581e+00 -1.96749311e-01
 -1.28066421e-01  5.47517187e-01  2.52218166e+00 -2.37000315e+00
 -1.91467673e+00  1.80636404e+00  2.26186338e+00 -1.67864878e+00
 -2.05149087e+01]
supnorm grad right now is: 20.514908684324475
Weights right now are: 
[-2.73289882  2.73313466  1.34012636  0.87965552  2.98746753 -2.84182635
 -0.94118909 -1.5956839   2.03580676 -4.56180298 -9.44817927  6.08252023
 21.99430615 14.55917034 40.95709744  1.80598694 25.61993692 18.4519136
 38.58191571  8.55240691 20.86606342 48.669903   30.46101802  8.33213795
 14.63863965  1.45702815 -0.73136098  8.64291763  2.42045802  6.3567072
 -0.47869222  7.54740201 29.51167192 -3.91523034 -7.3839743  -9.31308613
 -1.27489732 -0.16767554 -9.89250806 12.66557665  4.78358407  0.2884209
 -8.83837269  2.82604096 -2.97853105  5.52494925 -3.08543395 10.20817447
 14.33402506  8.7134255   3.2467627   0.46699449 -4.9758419  23.99876367
 -4.91877849 23.12645415 17.58707443  3.19110139  3.2653835  -2.01762208
  5.10580323  2.63689562  4.71630264 -1.51001856 30.03139284]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1703.7656041118528
gradient value of function right now is: [-3.84211701e-01 -3.22447917e+00 -4.23581687e-01 -4.39687843e-01
  3.84211701e-01  3.22447917e+00  4.23581687e-01  4.39687843e-01
  2.25224414e-01  6.33871910e-01  8.93118921e-02 -4.04215449e-01
  7.41669332e-05  1.58950554e-01  1.92424108e-05  7.78308835e+00
  1.12530211e-07  4.88792951e-04  6.20524753e-08  1.53893801e-01
  1.15727230e-07  4.24330576e-04  8.39053809e-08  1.77442441e-01
 -3.79357381e-02 -8.19997110e-04 -8.57667251e-04 -2.02185254e-04
 -1.86217582e+00 -5.43967233e-01 -2.48515616e-01 -7.59680875e-02
  4.42431054e-02 -3.55365181e-04 -2.54651856e-04 -2.20561595e-04
 -2.23070236e+00 -9.73402383e-01 -3.06853565e-01 -3.57899270e-01
  1.74589820e-03 -1.31324768e+00  3.51234704e-02 -1.17489573e+00
  2.10049650e-01  3.76193216e-01  7.61373173e-01  2.90487540e-01
 -5.28067137e-03 -1.29335301e-01 -2.86547062e-01 -7.38697261e-02
  3.30590015e-01  2.69581151e-01  1.13302233e+00  2.14638120e-01
  1.87716104e-01 -6.90370457e-01 -2.46872629e+00  3.42314594e+00
  1.76093384e+00 -2.35149432e+00 -2.21851597e+00  4.84625694e+00
  1.46564489e+01]
supnorm grad right now is: 14.656448885018277
Weights right now are: 
[-2.74458397e+00  2.47331638e+00  1.36134706e+00  9.17551504e-01
  2.99915268e+00 -2.58200807e+00 -9.62409794e-01 -1.63357989e+00
  2.61672958e+00 -4.20330508e+00 -1.00534508e+01  5.81696101e+00
  2.63380017e+01  1.63757179e+01  4.03505574e+01  1.79986780e+00
  2.56975515e+01  2.33346739e+01  3.89946946e+01  8.36303701e+00
  2.09011451e+01  5.44661041e+01  3.09347411e+01  8.04770381e+00
  1.64993165e+01  1.91335682e+00 -1.81153825e+00  1.00058430e+01
  2.20132410e+00  6.71010283e+00 -3.80157921e-01  7.91742037e+00
  3.33898630e+01 -3.64426783e+00 -5.11484992e+00 -1.01532532e+01
 -1.38501865e+00 -3.83688094e-02 -9.95015963e+00  1.26938266e+01
  4.23221558e+00  2.04493834e-01 -8.75582155e+00  3.03939254e+00
 -2.92925642e+00  5.75294251e+00 -2.49063021e+00  1.15198120e+01
  1.34350584e+01  9.80158035e+00  3.82983459e+00 -9.12719685e-02
 -5.06773938e+00  2.48567181e+01 -4.57504862e+00  2.46729423e+01
  1.79654079e+01  3.33136636e+00  3.48795200e+00 -1.72357813e+00
  4.80014480e+00  2.61461309e+00  4.76472632e+00 -1.35002685e+00
  3.03004178e+01]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1705.1827935842734
gradient value of function right now is: [ 7.23272731e-01  7.54462353e-01  1.01508041e+00  1.01312929e+00
 -7.23272731e-01 -7.54462353e-01 -1.01508041e+00 -1.01312929e+00
 -9.89707237e-02 -4.35823138e-01 -3.73420268e-02 -9.38553189e-01
  2.32976536e-04  9.59649641e-02 -7.69976067e-05  1.06163113e+00
 -2.18707284e-08  8.72133497e-05 -2.78370661e-06  1.37672921e-02
 -1.88050005e-07  4.10188738e-05 -3.39917737e-06  1.48771729e-02
  1.68401559e-02 -7.78339469e-04 -3.71019986e-04  1.63360460e-04
 -1.22987364e+00 -2.55819871e-01 -2.15970365e-01 -9.18747142e-03
 -1.85421588e-02  1.79214686e-03  1.15981582e-03  1.32668573e-03
  2.68598693e-01  1.18764682e-02  4.80832009e-02  1.41927550e-02
  9.41188555e-03  9.11396101e-01  9.94672288e-02  6.10806191e-01
 -2.38425698e-02  2.15480098e-01  1.11670042e-01  8.44590910e-02
 -9.63512562e-04  2.05382032e-02 -7.11117768e-02  8.78969516e-03
 -3.69383995e-02  1.42393072e-02  5.74507009e-02  6.28450575e-03
  1.68992652e-03  2.71504580e-02 -9.15578855e-01 -4.74370217e-01
  6.31936112e-01 -1.91521407e-01 -1.05181551e+00 -8.59647036e-01
  8.84023442e+00]
supnorm grad right now is: 8.840234417213214
Weights right now are: 
[-2.80779909e+00  2.65561526e+00  1.32791961e+00  8.95673511e-01
  3.06236780e+00 -2.76430695e+00 -9.28982342e-01 -1.61170189e+00
  3.36331552e+00 -4.33362517e+00 -1.11831968e+01  5.76363712e+00
  2.80981558e+01  1.74069391e+01  4.26251708e+01  1.70968718e+00
  2.57272942e+01  2.61598388e+01  4.22786320e+01  8.52962297e+00
  2.09607056e+01  5.96383708e+01  3.43369934e+01  8.07500380e+00
  1.74567409e+01  1.68093862e+00 -4.22568743e+00  8.60816777e+00
  2.48691384e+00  6.64919649e+00 -1.10157884e+00  7.92434429e+00
  3.68059602e+01 -7.36993421e+00 -5.92506686e+00 -1.48645522e+01
 -1.22522624e+00  5.95917592e-02 -9.75801791e+00  1.28123992e+01
  4.16383212e+00  6.72204238e-01 -9.04235996e+00  3.49186528e+00
 -3.27666070e+00  6.19470786e+00 -2.56140934e+00  1.23995744e+01
  1.36538840e+01  1.02670910e+01  3.62863231e+00 -2.28608338e+00
 -4.51769280e+00  2.58493506e+01 -4.70366243e+00  2.56340703e+01
  1.73598447e+01  2.99310919e+00  3.06868991e+00 -1.88581509e+00
  5.08388569e+00  2.60572171e+00  4.78878608e+00 -1.54438386e+00
  3.02706880e+01]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1718.586762122354
gradient value of function right now is: [-3.51450734e-01 -2.17008259e+00  1.00040316e+00  1.03046328e+00
  3.51450734e-01  2.17008259e+00 -1.00040316e+00 -1.03046328e+00
 -2.61243458e-01 -3.82590517e+00  1.26712886e-01 -1.03791037e+01
  2.96179590e-03  3.30549235e-01 -1.26974252e-01  1.19567336e+01
  8.53208696e-07  4.50488832e-04 -4.41048196e-02  1.39776123e-01
  2.36828797e-06  8.95246013e-04 -5.69490152e-02  2.97272853e-01
  5.39866592e-02 -4.07471063e-02 -2.70074042e-02 -1.91194988e-02
 -9.15759757e+00 -2.47390501e+00 -9.92844147e-01 -5.34461031e-01
  1.17899695e+01  1.10854842e+01  6.01108383e-01  1.11417104e+01
  1.01373803e+00 -2.30819473e+00 -2.87302704e-01 -1.02568937e+00
 -3.41247761e-01  5.57098888e+00 -6.16939558e-01  1.88368769e+00
  1.16938396e+00  9.30739752e-01  7.81013088e+00  5.53812686e-01
  2.15718413e-02 -9.40831971e-02  4.62782986e-01 -8.87704886e-02
  4.91289499e+00  5.82098314e-01  1.34363325e+01  8.18352843e-01
  6.06148018e-01 -4.40920583e+00 -7.61251294e+00  1.58112847e+01
  1.14499636e+01 -2.42937307e+01 -7.57823078e+00  2.51294378e+01
  4.02856997e+01]
supnorm grad right now is: 40.28569967449315
Weights right now are: 
[ -3.30937322   3.39928815   1.62183567   1.23802511   3.56394193
  -3.50797984  -1.2228984   -1.9540535    3.72661299  -4.87626793
 -12.11615773   5.31199468  34.97116917  19.61523023  45.22954076
   2.09218627  25.89010808  34.43057427  46.97496529   9.49997528
  20.63042232  70.57388607  38.20460339   7.70804897  17.34181343
  -4.66389558 -11.0839067    3.21228892   1.86373351   4.21180159
  -3.12132394   4.85723088  34.24419315 -11.75339637  -4.77409473
 -19.9807759   -1.56405246   0.79753138 -10.47462729   4.76278767
   2.35291363   0.59673402  -8.20667859   3.0949266   -2.8327035
   6.99232054  -3.42402428  12.31205419   2.87501418  11.00350022
   3.37931464  -5.14925326  -0.84134057  29.47438823  -4.99943957
  27.45157787  16.44456058   1.75083729   1.90400144  -2.68431382
   3.9466942    1.82125404   4.73532341  -1.72434494  30.05801327]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1725.2152415961505
gradient value of function right now is: [ 9.09270659e-01  1.13663006e+00  3.00045750e-01  4.84282305e-01
 -9.09270659e-01 -1.13663006e+00 -3.00045750e-01 -4.84282305e-01
 -3.14329464e-02  2.19175844e-01  1.09729030e-02  1.13480923e+00
  2.29385298e-04  1.10318758e-02 -3.05750737e-02 -2.06259347e+00
 -2.57385999e-07 -4.54188070e-05 -4.57760879e-03 -1.05143359e-01
 -1.19225189e-06 -1.79041158e-04 -8.68195036e-03 -2.43731544e-01
 -4.40835845e-03 -1.08592243e-03 -6.52003566e-04  3.76372450e-03
  2.64552999e-01 -1.33526259e-02 -1.06068518e-01  2.17007041e-02
  2.23018157e+00  1.93934584e+00  3.20498757e-01  2.09281884e+00
  9.02258576e-01  1.07819310e+00  6.23520754e-02  6.39888771e-01
 -6.86541149e-03 -8.82071708e-02 -8.06323976e-01  5.81846848e-02
 -5.36630078e-02  6.91982257e-02  1.90197445e+00  1.62202011e-02
  3.93879880e-02 -9.11622426e-03  8.55652090e-01  2.63524359e-02
 -1.30249969e-01 -5.57647814e-03  1.47212692e+00 -1.44563731e-02
 -2.11463415e-02  2.02119247e-01 -5.06773099e-01  1.08410891e+00
  1.62565286e+00 -3.69589697e+00 -1.69136272e-01  2.81279304e-01
 -3.64034451e-01]
supnorm grad right now is: 3.695896971676667
Weights right now are: 
[ -3.23644089   4.26686333   1.4533097    1.33173138   3.4910096
  -4.37555502  -1.05437244  -2.04775977   3.83812657  -4.5473607
 -12.48351726   5.87666252  35.89121713  21.19665972  44.44108244
   2.0932763   25.91702815  41.75773503  49.53032586   9.95922171
  19.414908    80.14356382  39.4013613    7.00654467  18.07883856
  -5.00840088 -11.5118685    3.18567972   2.21418547   4.03096534
  -3.44248189   5.60132212  34.14565376 -11.722401    -2.53233585
 -20.08510065  -1.05794541  -0.16586701  -8.5388488    4.52116038
  -0.52587556   0.09238914  -7.11254844   3.9721344   -2.32540938
   6.45031801  -3.39655835  11.15722801   6.24183563   9.13249599
   2.92237921  -2.85177599  -0.90296477  33.95577367  -5.50062995
  28.60702953  18.00161463   1.54044684   2.14361185  -2.80139276
   3.52637695   1.55988511   4.83352344  -2.06970143  30.07943105]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -1724.5056840650045
gradient value of function right now is: [-8.41380877e-01 -8.27507813e-01 -3.22135934e-01 -5.05827299e-01
  8.41380877e-01  8.27507813e-01  3.22135934e-01  5.05827299e-01
  7.54692198e-02  9.47425521e-01 -1.17300806e-01  7.83750158e-01
 -3.77475067e-03 -1.76341478e-02  1.07687634e-01 -2.48839257e-02
  2.35958343e-06  2.10061671e-05  8.34278138e-03  9.60687058e-02
  5.77868699e-07  3.66228571e-05  2.35363648e-02  2.32956995e-01
  4.78502562e-02  6.90826401e-02  4.87220591e-02  4.88686820e-02
  9.47640932e-01  1.58947601e-01  1.59468906e-01  6.58511061e-02
 -7.41559475e+00 -6.61149885e+00 -1.17814095e+00 -7.22073038e+00
 -2.64095462e-01  1.07542723e+00  3.71183430e-01  1.22488439e+00
  3.77311224e-02 -1.45998197e+00  1.55465121e+00 -3.40465876e-01
 -2.06787342e-01 -1.34693922e-01 -6.04284960e+00 -7.71625039e-02
 -2.63113813e-02  9.78731402e-03  4.05279433e-01 -1.53737394e-02
 -7.67784387e-02 -1.01840336e-01 -3.94110688e+00 -8.25192853e-02
 -4.83467960e-02  2.93548034e-01  1.74950534e+00 -4.14143091e+00
 -5.86801123e+00  1.49453565e+01  1.97933243e+00 -2.89483355e+00
 -5.18357197e+00]
supnorm grad right now is: 14.945356541496515
Weights right now are: 
[-3.39702331e+00  4.41993943e+00  1.36076450e+00  1.48569835e+00
  3.65159202e+00 -4.52863112e+00 -9.61827234e-01 -2.20172673e+00
  4.88919850e+00 -4.54175433e+00 -1.15641032e+01  6.08449877e+00
  3.63442441e+01  2.28868324e+01  4.46854119e+01  2.25891349e+00
  2.62184664e+01  4.57269689e+01  5.14974224e+01  1.06710059e+01
  1.95689425e+01  8.89995608e+01  3.97606936e+01  8.26527293e+00
  1.85102075e+01 -5.72166729e+00 -1.23439236e+01  5.91490413e-01
  2.40642397e+00  4.36893681e+00 -2.59609397e+00  4.91648820e+00
  3.40554586e+01 -1.17272970e+01 -9.75822472e-01 -2.02085989e+01
 -8.57419725e-01 -5.57331355e-01 -6.87480132e+00  4.24551039e+00
 -1.89643746e+00  5.56333495e-02 -6.91951733e+00  4.56117785e+00
 -1.52376102e+00  7.18884996e+00 -3.24552034e+00  1.23560083e+01
  7.17111333e+00  9.06648747e+00  2.20530551e+00 -1.40579728e+00
 -6.82222179e-01  3.61265043e+01 -5.93737714e+00  2.88051503e+01
  1.87465442e+01  1.33016577e+00  1.80515397e+00 -2.90730951e+00
  3.40356689e+00  1.50026299e+00  5.19146828e+00 -1.95496682e+00
  3.00603896e+01]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1721.1160752709375
gradient value of function right now is: [-8.59620503e-01 -4.58119342e-01 -8.00416289e-02 -3.26150590e-01
  8.59620503e-01  4.58119342e-01  8.00416289e-02  3.26150590e-01
  5.69628689e-02  1.27893332e+00 -3.26391942e-01  3.31474893e-01
 -3.99454625e-03 -1.42683201e-01  1.62763579e-01 -2.91374499e+00
 -2.50079584e-08 -7.31438832e-06 -9.05289640e-04 -1.53221864e-02
 -8.31105622e-07  7.48495031e-05  1.51841467e-02  2.09592240e-01
  5.17451932e-02  6.67100157e-02  4.99793397e-02  4.12584115e-02
  3.67679583e+00  1.20057195e+00  7.99486187e-01  3.43661936e-01
 -1.14987520e+01 -1.02133251e+01 -1.15037534e+00 -1.10414878e+01
  5.44664515e+00  6.70658731e+00  1.20509406e+00  7.22579489e+00
  1.37610319e-01 -2.08528966e+00  4.67608737e-01 -4.87804696e-01
 -1.87146429e+00 -5.77687770e-01 -1.00762871e+01 -4.30244937e-01
  4.44593806e-02  1.41288586e-01  2.97890685e+00  6.78042657e-02
 -2.42888255e+00 -3.29894818e-01 -8.85784419e+00 -4.55206921e-01
 -4.13157893e-01  3.39193494e+00  4.27240285e+00 -1.31361640e+01
 -9.58389137e+00  2.69762425e+01  4.53324092e+00 -1.76260343e+01
 -1.45007830e+01]
supnorm grad right now is: 26.97624250320097
Weights right now are: 
[-3.78215975e+00  5.11596840e+00 -2.16505988e-01  1.18461378e+00
  4.03672846e+00 -5.22466009e+00  6.15443257e-01 -1.90064216e+00
  5.61721623e+00 -4.88873892e+00 -1.23730708e+01  6.50007195e+00
  3.57161800e+01  2.45366084e+01  4.50549167e+01  2.20940505e+00
  2.62858064e+01  4.73122488e+01  5.34038167e+01  1.39998955e+01
  1.95025131e+01  9.59549879e+01  3.65192402e+01  8.51947530e+00
  1.95912724e+01 -5.31656446e+00 -1.16542540e+01  1.02929407e-01
  2.28309585e+00  4.16389406e+00 -2.28188954e+00  3.63131469e+00
  3.38217589e+01 -1.19726480e+01 -1.36659864e+00 -2.04911345e+01
 -9.07592957e-01 -1.57261900e+00 -6.52626146e+00  4.04047929e+00
  3.64142565e-01  9.28756459e-02 -8.05419337e+00  4.47839664e+00
 -1.09274361e+00  7.23003114e+00 -3.09301779e+00  1.20845794e+01
  8.66502290e+00  9.80170081e+00  2.01303608e+00  2.11335253e+00
 -1.04649350e+00  3.73160597e+01 -6.01542153e+00  2.87506854e+01
  1.95566042e+01  1.55213520e+00  2.05831177e+00 -2.73459353e+00
  3.70290784e+00  1.66859413e+00  4.97906490e+00 -1.86862737e+00
  3.01179742e+01]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1722.2109969267174
gradient value of function right now is: [-5.51634768e-02 -1.37871632e+00 -3.37710226e-04 -3.71302951e-04
  5.51634768e-02  1.37871632e+00  3.37710226e-04  3.71302951e-04
 -1.99206580e-01 -8.20412419e-01  3.98152018e-01  1.15892950e-01
  1.77458690e-02  2.32779306e-01  1.09428199e-02  1.39278741e+01
 -2.68059571e-07 -6.22907293e-06  9.87292858e-07 -1.77735933e-03
 -4.30757286e-08 -7.13035974e-07  6.63263587e-07 -5.08898890e-04
 -3.13365436e-01 -2.91145272e-01 -2.44355354e-01 -1.71338404e-01
 -4.83009586e+00 -1.70833431e+00 -8.94522650e-01 -4.61004445e-01
  4.47494055e+00  4.09428678e+00  2.27056301e-01  4.54738188e+00
 -4.52570727e+00 -3.91283051e+00 -3.22553708e-01 -4.02629111e+00
 -1.84268380e-02  1.75349251e+00  3.55633905e-01  1.00439321e+00
  1.18265286e+00  2.61903514e-01  3.94888319e+00  1.78147131e-01
 -8.19446444e-02 -1.74611827e-01 -1.59991624e+00 -9.24571727e-02
  9.25657552e-01  9.66768460e-02  1.75157718e+00  1.21869687e-01
  2.56133468e-01 -2.08835573e+00 -5.00540679e-01  2.27866089e+00
  3.87467528e+00 -6.97657351e+00 -1.78686373e+00  2.46247319e+00
  1.53229998e+01]
supnorm grad right now is: 15.322999809750149
Weights right now are: 
[-4.14841320e+00  6.55139202e+00 -3.12943035e+00 -1.21996474e+00
  4.40298191e+00 -6.66008371e+00  3.52836762e+00  5.03936352e-01
  7.36713643e+00 -5.65002765e+00 -1.37182714e+01  7.20971656e+00
  3.67184055e+01  2.45679596e+01  4.45706581e+01  1.95828330e+00
  2.62837344e+01  4.80845282e+01  5.67845163e+01  1.20172103e+01
  1.94938262e+01  9.70492914e+01  3.41775299e+01  1.17767343e+01
  1.99579516e+01 -6.43127000e+00 -1.28845301e+01 -7.65216814e-01
  2.18349960e+00  3.42131967e+00 -1.15779003e+00  3.81888461e+00
  3.33036455e+01 -1.26950122e+01 -7.18022689e-01 -2.11988128e+01
 -7.69252156e-01 -2.92714858e+00 -8.71460571e+00  2.68216068e+00
  1.35290482e+00 -6.68272828e-02 -9.28131767e+00  4.72892235e+00
 -7.18665843e-01  5.95609919e+00 -2.50605723e+00  1.23577042e+01
  9.64033220e+00  9.17188518e+00  2.12874463e+00  1.69875444e+00
 -1.12286850e+00  3.79178328e+01 -5.73178359e+00  2.72183236e+01
  1.89921682e+01  1.45425790e+00  2.24386466e+00 -2.65400063e+00
  4.18856694e+00  1.60630425e+00  4.40092569e+00 -1.97921786e+00
  3.01798008e+01]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1719.7498064643917
gradient value of function right now is: [-8.96080138e-01 -9.62125332e-01  2.32294942e-05  9.97847264e-05
  8.96080138e-01  9.62125332e-01 -2.32294942e-05 -9.97847264e-05
 -2.34649117e-01 -1.97803949e+00 -3.01443885e-01 -4.08457033e+00
 -1.20513890e-03  3.83075332e-01 -1.01060898e-02  1.14264757e+01
  1.04762591e-08 -1.78797307e-05  2.20706748e-05 -1.21531766e-04
  3.31680387e-09 -2.14677652e-06  1.60371980e-05  2.51350038e-04
  1.55142393e-01  2.29205843e-02  1.57462849e-02  1.68740727e-02
 -1.06712328e+01 -2.57387375e+00 -3.72184840e-01 -6.09579831e-01
 -1.59485486e+00 -1.23860194e+00 -2.10381874e-01 -1.52838218e+00
  1.06813941e+00 -8.44206396e-01 -8.36351909e-02  6.01399951e-02
  6.82223423e-02  2.98730942e+00  9.21197009e-01  1.61954612e+00
  8.00816881e-01  4.60142547e-01 -2.89007501e-01  3.95756245e-01
 -1.46549407e-02 -8.12671522e-02 -4.02277318e-01 -7.11523002e-02
  1.07695186e+00  2.11264259e-01  1.92207927e+00  3.26374921e-01
  8.82024734e-02 -1.04278302e+00 -1.73102668e+00  7.56386607e+00
  5.37057826e-01  1.30779111e+00 -3.40864911e+00  8.44912824e+00
  1.96573912e+01]
supnorm grad right now is: 19.65739115629307
Weights right now are: 
[ -4.54481281   7.81871327  -5.4145844   -3.55812356   4.79938152
  -7.92740496   5.81352167   2.84209518   7.64092486  -5.73157718
 -14.40493965   7.30884853  37.68969965  25.27022329  44.10979639
   2.26352548  26.28065314  48.76320948  53.73054577  13.39639614
  19.49457146  97.09392973  35.34283236  13.28988905  20.82623065
  -7.40893343 -13.56127025  -0.96596165   2.16988105   3.1696954
  -0.64696951   2.78577212  32.70706886 -13.22210628  -0.53034437
 -21.82788669  -0.32186589  -2.91644151 -11.50881714   2.66856017
   0.70036198  -0.15298578  -8.22931004   4.99676974  -0.7891146
   6.21122237  -2.3613165   13.1261189    8.92632372  11.91755151
   3.37714253   3.23036256  -0.72508513  39.02737544  -5.34896346
  27.27548671  20.24355379   0.87762624   1.23523761  -2.7902064
   3.9403493    1.57418689   3.95243865  -1.89547249  29.99827807]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1723.4296659052375
gradient value of function right now is: [ 2.74524634e-01 -8.50744583e-02 -5.05032167e-05 -1.02118241e-04
 -2.74524634e-01  8.50744583e-02  5.05032167e-05  1.02118241e-04
 -2.93620817e-04  6.88101967e-01  3.13389288e-02  1.29439585e+00
  9.08942401e-04 -1.90548601e-01  8.45140387e-02  8.13927755e-01
 -4.81643129e-08  1.29628861e-05 -1.72295913e-05 -8.77026061e-04
 -5.55206737e-08  8.94615736e-07 -2.89091841e-05 -1.43526551e-03
 -5.99137612e-02 -2.05351773e-02 -1.65590989e-02 -2.71093036e-02
  4.63295500e+00  1.28778425e+00  3.63833260e-01  8.96037332e-02
 -3.08968888e+00 -2.41665788e+00 -1.06998864e-01 -2.62100282e+00
 -2.25569264e+00 -9.46620356e-01 -3.83659452e-02 -1.20703634e+00
  2.48354860e-02 -5.90077918e-01  5.92911030e-02 -1.34496595e-01
 -2.11139433e+00 -5.20102356e-01 -6.33314858e+00 -6.14441310e-01
 -8.02177633e-03 -4.04211539e-02 -2.97859567e-01 -6.92535825e-03
 -2.37297014e+00 -2.12804267e-01 -6.57578942e+00 -4.78795523e-01
 -2.02222632e-01  3.00863789e+00  2.15347899e+00 -1.00436586e+01
 -2.28394656e+00  1.19594932e+01  3.16763089e+00 -2.00496664e+01
 -1.09738231e+01]
supnorm grad right now is: 20.049666402680874
Weights right now are: 
[-4.48042623e+00  9.04397007e+00 -1.04392395e+01 -8.99137458e+00
  4.73499494e+00 -9.15266176e+00  1.08381768e+01  8.27534620e+00
  7.80013051e+00 -5.34397790e+00 -1.43940175e+01  7.85103827e+00
  3.76934262e+01  2.62982930e+01  4.37439486e+01  2.10812198e+00
  2.62797718e+01  4.92920307e+01  4.80646924e+01  1.25188570e+01
  1.94976092e+01  9.70091381e+01  3.54420389e+01  1.20934015e+01
  2.18757633e+01 -7.82021393e+00 -1.35336496e+01 -2.07036916e+00
  2.23025444e+00  3.16045971e+00 -4.34028852e-01  3.07745875e+00
  3.27478022e+01 -1.29833074e+01  1.09224679e+00 -2.17330964e+01
 -1.79159650e-01 -3.53666333e+00 -1.56899332e+01  2.09699614e+00
  7.52820042e-02 -6.79396898e-02 -8.19784684e+00  4.79779908e+00
 -1.31688758e+00  4.47522253e+00 -2.25731279e+00  1.24642836e+01
  9.03306296e+00  9.93210730e+00  3.45877159e+00  2.07134563e+00
 -7.63133624e-01  3.99696993e+01 -5.07194635e+00  2.68265999e+01
  2.05658746e+01  8.90489918e-01  1.58158064e+00 -3.10948843e+00
  4.26162139e+00  1.52267262e+00  3.89518363e+00 -2.06424309e+00
  3.00090751e+01]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1724.6525758826494
gradient value of function right now is: [-9.42649957e-02  2.75208540e-01  7.13291391e-04  5.63849088e-04
  9.42649957e-02 -2.75208540e-01 -7.13291391e-04 -5.63849088e-04
 -2.46896607e-02  1.02002171e-01 -2.23886315e-01 -3.28013460e-01
 -2.17659172e-03 -7.33746844e-02 -5.39151559e-03 -3.39470912e+00
  4.74390446e-07  4.49381725e-05 -3.02635600e-04  1.49124780e-02
  1.92542902e-07  2.76719148e-05 -4.70999290e-04  1.02925957e-02
  6.31050851e-02  4.16769068e-02  2.78891981e-02  2.55703544e-02
  1.70098194e+00  6.49217340e-01  1.27737901e-01  1.58893572e-01
 -2.19652837e+00 -1.88263432e+00  2.85334351e-02 -2.12250397e+00
  3.76655361e+00  3.31181138e+00  1.02156296e-01  3.65156914e+00
  6.05391804e-02 -2.47776995e-01 -1.58626807e-01  1.58620998e-01
 -6.90494595e-01 -2.50185367e-01 -1.81309792e+00 -1.26390689e-01
  2.81216997e-02 -1.36125984e-02  1.23569431e+00  3.28985569e-02
 -1.13861969e+00 -6.85458843e-02 -2.88807751e+00 -2.11218316e-01
 -1.27296622e-01  1.79850607e+00  3.23065093e-01 -2.77534821e+00
 -1.02960999e+00  6.68831686e+00  7.25154154e-01 -7.58276957e+00
 -4.42400620e+00]
supnorm grad right now is: 7.582769572455471
Weights right now are: 
[-5.03794734e+00  9.40235852e+00 -1.59439099e+01 -1.40844952e+01
  5.29251605e+00 -9.51105021e+00  1.63428472e+01  1.33684669e+01
  7.44643555e+00 -5.40408469e+00 -1.41527606e+01  7.62541983e+00
  3.81809031e+01  2.70895746e+01  4.41893233e+01  2.29026684e+00
  2.63629794e+01  4.92688569e+01  4.16309334e+01  1.10092265e+01
  1.95822401e+01  9.59853059e+01  3.53698178e+01  1.10282176e+01
  2.28878273e+01 -8.43693544e+00 -1.36401743e+01 -1.27816218e+00
  2.20117639e+00  2.81205642e+00  2.88891439e-01  3.45562399e+00
  3.26705460e+01 -1.27686774e+01  2.60177771e+00 -2.17439417e+01
 -1.39972095e-01 -3.24830981e+00 -1.80239373e+01  3.17355560e+00
 -5.31078684e-02 -4.03204809e-01 -7.67625765e+00  4.37756109e+00
 -1.57894569e+00  3.97086660e+00 -2.20278039e+00  1.20930271e+01
  9.42935443e+00  9.87497834e+00  4.55895153e+00  2.70686719e+00
 -7.90144427e-01  4.20073937e+01 -5.21654326e+00  2.65846995e+01
  2.07001589e+01  6.65576109e-01  1.05323626e+00 -3.09402473e+00
  4.05497025e+00  1.59761954e+00  4.41769167e+00 -2.00398923e+00
  2.99207435e+01]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1723.3313600407193
gradient value of function right now is: [ 5.54779068e-01  4.87544180e-01  1.26059930e-04  7.51304548e-05
 -5.54779068e-01 -4.87544180e-01 -1.26059930e-04 -7.51304548e-05
  3.55079675e-01  1.66688666e+00  2.95672483e-01  2.52723975e+00
 -2.11686483e-03 -1.52634880e-01 -1.44516029e-02 -8.60909086e+00
  4.49556253e-07  5.18684547e-05 -2.63458352e-08  4.40483547e-03
  1.52946893e-07  1.52669678e-05 -4.02612173e-06  2.24819009e-03
 -9.29932861e-02  3.91037902e-02  2.72778437e-02  2.12039607e-02
  4.48033705e+00  1.70205375e+00  4.76859369e-01  5.39032557e-01
  1.24741977e+00  8.42834254e-01  1.10384350e-01  1.00760273e+00
 -1.16039744e+00  3.81397207e-01  2.37654077e-02  1.66458996e-01
 -4.10728214e-02 -2.86173163e+00 -8.13841122e-01 -1.96598471e+00
 -1.00044412e-01 -1.21634406e-01  9.09046901e-01 -7.75627050e-02
  7.91695222e-03  4.15306484e-03  1.19292928e-02  1.38068419e-02
 -1.65170256e-01 -5.43405870e-02  4.62934094e-01 -6.11464367e-02
 -1.41273411e-03  4.18305555e-01  8.61953150e-01 -1.48899984e+00
 -5.29016588e-01 -2.27721018e+00  1.26446033e+00  3.94996026e-01
 -1.28589044e+01]
supnorm grad right now is: 12.858904370110402
Weights right now are: 
[ -4.7434809   10.19790774 -19.65895215 -17.60666471   4.99804961
 -10.30659943  20.05788942  16.89063633   8.72053096  -4.7218575
 -14.22647994   7.72151827  37.67204337  27.83013663  43.57768748
   2.09971801  26.65802544  49.08596099  40.49334681  10.91335348
  19.7919365   95.01906877  37.6232895   11.10458835  23.55785109
  -8.11392929 -12.7080871   -0.15933644   2.24575783   2.85930023
   0.87891495   3.23991919  32.4862082  -12.74122526   3.24942841
 -21.90552822  -0.51706413  -3.5287441  -21.98551424   2.81220716
   2.80068559  -0.34069653  -7.67659017   4.09320633  -1.52009368
   4.36873991  -2.2078501   13.23814209   9.53586302  10.39378432
   4.55250561   2.15820201  -0.99220692  43.68460733  -4.97245712
  26.20534042  21.16182527   0.22624491   1.07071067  -3.21769592
   4.090862     1.42140708   4.34188183  -2.06067934  29.858838  ]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1721.8718462629247
gradient value of function right now is: [ 3.14903488e-02  7.33681492e-01  2.51539740e-04  1.47432891e-04
 -3.14903488e-02 -7.33681492e-01 -2.51539740e-04 -1.47432891e-04
 -5.10796752e-02 -2.84353946e-01  7.48169529e-02  4.79041262e-01
 -3.87411614e-03 -4.40329450e-01  2.93998719e-03 -1.25547303e+01
  7.28916674e-07  2.09111318e-04  5.64164918e-05  8.98229786e-03
  3.20477054e-07  3.19852892e-05  4.69604029e-05  4.57746781e-03
  1.32972319e-01  7.36357064e-02  4.08992763e-02  3.10079478e-02
  9.41499429e+00  3.59513294e+00  5.64192107e-01  2.97678875e-01
  9.82093081e-01  8.31128962e-01 -5.93422883e-02  9.49707950e-01
  1.63741848e+00  4.53853349e-01  2.23207140e-02 -1.77883239e-01
 -2.90470917e-02 -4.99950097e-01 -4.01507871e-01  1.12903700e-01
  2.40629587e-01 -1.06081815e+00  7.43178856e-01 -2.38226710e-01
  5.02252447e-03  7.94576197e-02  1.72517490e-01  4.67942704e-02
  2.03881866e-01 -4.71111667e-02  7.43288031e-01  4.31195096e-02
  2.54686881e-02 -6.22433579e-01  1.99477542e+00 -8.97732552e-01
 -4.02111914e+00  2.35050114e+00  2.13385847e+00  2.54522944e+00
 -1.34970923e+01]
supnorm grad right now is: 13.497092317407017
Weights right now are: 
[-5.60485487e+00  1.04566979e+01 -2.28522517e+01 -2.09445913e+01
  5.85942359e+00 -1.05653896e+01  2.32511890e+01  2.02285629e+01
  8.92621491e+00 -5.15197402e+00 -1.46725944e+01  7.31815673e+00
  3.88338498e+01  2.83565999e+01  4.36031483e+01  2.20500548e+00
  2.71638602e+01  4.89613119e+01  3.93668027e+01  1.14449885e+01
  2.01519404e+01  9.32718794e+01  3.80534348e+01  1.15747743e+01
  2.24975276e+01 -9.46836904e+00 -1.32150152e+01  8.85315741e-02
  2.55949255e+00  3.43930209e+00  4.71482053e-01  3.67263574e+00
  3.24675473e+01 -1.25371204e+01  3.66044514e+00 -2.19157457e+01
 -3.16138809e-01 -3.83481069e+00 -2.43871304e+01  2.79090832e+00
  2.34852525e-01 -3.45411789e-01 -7.12227972e+00  4.19949430e+00
 -1.38021098e+00  2.72215521e+00 -2.20388081e+00  1.34857868e+01
  1.06899513e+01  1.18292742e+01  5.44943723e+00  3.17737546e+00
 -8.96061490e-01  4.51615475e+01 -4.93246590e+00  2.59064727e+01
  2.21498072e+01 -3.35570874e-01  1.06520595e+00 -3.43292605e+00
  3.71519064e+00  1.44832486e+00  4.29193440e+00 -1.95313904e+00
  2.99729976e+01]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1721.3843492888489
gradient value of function right now is: [-7.90186777e-01 -5.47432468e-01 -7.35579377e-05 -3.46138677e-05
  7.90186777e-01  5.47432468e-01  7.35579377e-05  3.46138677e-05
 -3.34746299e-01 -2.44750749e+00 -2.64822595e-01 -4.32004203e+00
 -2.99863111e-03  2.80907864e-01 -5.87123072e-03  9.66010489e+00
  2.83211578e-07 -8.75461110e-05  1.93385118e-05 -3.12894576e-03
  1.24028531e-07 -1.08513236e-05  1.43578950e-05 -1.40349485e-03
  2.52910711e-01  6.16550337e-02  3.21205601e-02  3.40238777e-02
 -9.15030337e+00 -2.26877992e+00 -1.04372966e-01 -3.14331309e-01
 -5.68802623e-01 -3.68191027e-01 -3.23988885e-02 -4.99834668e-01
  1.78467865e+00 -1.03154897e+00 -1.97407452e-02 -4.83947873e-01
  1.12076671e-01  3.87404020e+00  1.16936609e+00  2.09846099e+00
  3.69057997e-01  5.33276304e-01  5.97091049e-01  3.66717927e-01
 -5.09204527e-03  8.88607565e-03 -2.83698919e-02 -1.73389628e-02
  5.14455422e-01  1.27326539e-01  2.26678778e+00  2.80782480e-01
  5.24782995e-02 -8.91261609e-01 -1.53232638e+00  6.09385240e+00
  2.02268194e-01  7.38599322e-01 -3.44623596e+00  7.14916283e+00
  2.08165272e+01]
supnorm grad right now is: 20.816527247423437
Weights right now are: 
[-5.46980768e+00  1.09576876e+01 -2.44013586e+01 -2.24214483e+01
  5.72437639e+00 -1.10663793e+01  2.48002958e+01  2.17054200e+01
  8.63005910e+00 -5.10358035e+00 -1.45402842e+01  7.46358666e+00
  4.00983157e+01  2.92350359e+01  4.42869612e+01  2.46372251e+00
  2.72147793e+01  4.79791140e+01  3.80144326e+01  1.24333850e+01
  2.02210889e+01  9.22707810e+01  3.73277330e+01  1.26551835e+01
  2.19217485e+01 -1.08601491e+01 -1.38753281e+01  3.61940722e-01
  2.27402597e+00  2.97734489e+00  1.23265919e+00  3.51179233e+00
  3.22617932e+01 -1.24381374e+01  5.32314532e+00 -2.20791572e+01
 -3.10654732e-01 -4.06937456e+00 -2.70639618e+01  2.85134864e+00
  4.78564835e-01  8.42767588e-02 -6.83433601e+00  4.55421801e+00
 -1.44237285e+00  4.05546626e+00 -2.23595510e+00  1.40199782e+01
  1.27462811e+01  1.10519223e+01  5.91328726e+00  4.36133672e+00
 -5.99750036e-01  4.80156553e+01 -4.87375246e+00  2.60360750e+01
  2.26487275e+01 -1.91684415e-01  6.69350219e-01 -3.26805498e+00
  3.76285117e+00  1.52488677e+00  3.91153140e+00 -2.05462703e+00
  3.00513228e+01]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1724.484225259595
gradient value of function right now is: [ 4.99712901e-01  4.23770085e-01  3.36791732e-05 -9.36291225e-06
 -4.99712901e-01 -4.23770085e-01 -3.36791732e-05  9.36291225e-06
  3.69768167e-01  1.83018914e+00  1.44668244e-01  2.57418558e+00
 -8.31163657e-03 -2.49839416e-01  2.22822775e-02 -8.71043471e+00
  2.84250001e-06  1.24996107e-04 -9.10513835e-05  2.19897363e-03
  1.18326002e-06  1.78354184e-05 -6.20014966e-05 -1.01255190e-04
  4.32358928e-02  1.57716659e-01  9.54670021e-02  6.40459912e-02
  6.68795436e+00  2.16731252e+00  4.85724716e-01  2.16732376e-01
 -1.80903838e+00 -1.55733287e+00 -2.21395941e-02 -1.78656915e+00
 -1.37642946e+00  5.60767584e-01  1.95600920e-02  3.80755725e-01
 -4.27624378e-02 -3.72088908e+00 -3.80547020e-01 -1.97471916e+00
 -3.85370449e-01 -5.75816652e-01 -3.52890782e+00 -2.99345915e-01
  4.57234066e-03 -3.27381895e-02  3.47578501e-01  7.90303341e-03
 -4.44175151e-01 -8.34523864e-02 -3.06344684e+00 -1.78410014e-01
 -6.67506233e-02  1.06758147e+00  1.85872778e+00 -4.25909243e+00
 -3.89684530e+00  8.63617710e+00  2.80118631e+00 -5.85450390e+00
 -1.67251537e+01]
supnorm grad right now is: 16.725153711427968
Weights right now are: 
[-5.39604209e+00  1.13962530e+01 -2.86548789e+01 -2.64287755e+01
  5.65061080e+00 -1.15049447e+01  2.90538162e+01  2.57127471e+01
  8.87365475e+00 -4.69647741e+00 -1.41044063e+01  7.74807126e+00
  3.93826964e+01  2.93498989e+01  4.43942617e+01  2.24550289e+00
  2.76584284e+01  4.72413619e+01  3.78655736e+01  1.11906730e+01
  2.05407602e+01  9.07094261e+01  3.76118231e+01  1.15574353e+01
  2.26501681e+01 -1.08541874e+01 -1.26634583e+01 -2.04920240e-01
  2.49403558e+00  3.38868476e+00  1.86988406e+00  4.06524752e+00
  3.20724682e+01 -1.23186343e+01  7.02050687e+00 -2.22181949e+01
 -4.66614274e-01 -4.11055403e+00 -3.00275313e+01  3.22849855e+00
 -6.02145469e-02 -2.14181599e-01 -6.86257969e+00  4.08439367e+00
 -2.23727604e+00  3.80935359e+00 -2.23347383e+00  1.50931003e+01
  1.51189782e+01  1.04005889e+01  5.74946770e+00  7.71007183e-01
 -8.20392352e-01  4.96638813e+01 -4.76840985e+00  2.59446773e+01
  2.40006670e+01  3.07863498e-01  6.69323464e-01 -3.48245015e+00
  4.11447696e+00  1.46235043e+00  4.59215550e+00 -2.07489098e+00
  2.99649247e+01]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1723.1379421452023
gradient value of function right now is: [-2.40250669e-01 -7.95806298e-01 -1.24130015e-04 -7.35789476e-05
  2.40250669e-01  7.95806298e-01  1.24130015e-04  7.35789476e-05
  1.15340790e-01 -8.62305487e-01  2.72446582e-01 -1.68464884e+00
  3.29528595e-03  4.08424060e-01 -3.13577811e-02  1.60831004e+01
 -4.63388422e-07 -1.22723657e-04  5.30847021e-05 -6.98201115e-03
 -5.14003222e-08 -2.73627544e-05  4.29612654e-05 -3.83588083e-03
 -8.44859380e-02 -5.63186048e-02 -2.73452435e-02  1.40672893e-03
 -1.01918229e+01 -4.02986464e+00 -7.63336538e-01 -6.09681073e-01
  3.13142042e+00  2.44588525e+00  4.88411872e-02  2.84534497e+00
 -3.67259790e-01 -1.60107909e+00 -2.95057838e-02 -1.40305843e+00
 -1.56626141e-02  2.30135900e+00 -1.78462939e-01  2.17580929e-01
  1.19913899e-01  1.17337327e+00  4.71870836e+00  3.95406201e-01
 -9.17005635e-03  1.07768143e-01 -5.81076179e-01 -1.70702363e-02
  3.95923495e-01  1.69856297e-01  5.32873808e+00  2.92088570e-01
  6.23597074e-02 -6.09924017e-01 -4.60434433e+00  9.55174917e+00
  6.05471825e+00 -1.60691108e+01 -4.52329843e+00  1.05803392e+01
  2.25233543e+01]
supnorm grad right now is: 22.523354268099162
Weights right now are: 
[ -5.78043136  11.50174572 -30.89883624 -28.9637397    6.03500007
 -11.61043741  31.29777351  28.24771132   8.9929601   -4.8321421
 -14.13369685   7.56751142  39.32943647  29.78696732  44.91173684
   2.47573475  27.72617946  47.64351272  39.3108375   11.74798818
  20.70583279  89.59786442  39.16223415  11.87678137  22.36636885
 -11.08357266 -12.12286783   0.59128458   2.42481363   2.9896672
   1.59744195   3.17538257  32.07747472 -12.00012102   8.39141321
 -22.16162376  -0.52195563  -4.23085586 -32.21342378   3.14690824
   0.82800137   0.17555233  -6.44852941   3.51260605  -1.71014992
   3.13213471  -2.29250594  15.23626014  12.23720735  10.64378029
   6.42030271  -1.83371436  -0.83985386  51.17050225  -4.95016105
  25.55756441  23.98576152   0.27467151   0.25643742  -3.42036037
   4.19537877   1.42769164   4.09066833  -2.05504485  30.02091732]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1721.6594491167057
gradient value of function right now is: [-1.25864180e-01 -9.82281044e-01 -1.26941763e-04 -7.47307799e-05
  1.25864180e-01  9.82281044e-01  1.26941763e-04  7.47307799e-05
 -9.87124922e-02 -2.46158452e-01 -1.06880903e-01 -9.62888751e-01
  2.75181055e-04  3.01646816e-01  2.26783744e-02  1.99601843e+01
  1.00182535e-07 -6.62321270e-05 -1.39473032e-05 -7.50410860e-03
  1.09426062e-07 -1.44018554e-05 -9.06844231e-06 -4.06583276e-03
  1.74100232e-02  4.61299449e-04  4.60352994e-03  2.28990646e-02
 -7.01579311e+00 -2.97186157e+00 -4.57239635e-01 -6.56556635e-01
 -1.29192687e+00 -9.59438017e-01 -2.74063699e-02 -1.12159252e+00
 -2.73026562e+00 -1.86482510e+00 -2.87742851e-02 -1.57349127e+00
  8.11925179e-02  1.42109140e+00  1.43708542e+00  8.33061445e-01
 -4.80285391e-02  4.08555724e-01 -2.08907717e+00  2.78557713e-02
 -9.58262534e-03  1.20284324e-02 -2.66231330e-01 -2.78589480e-02
  2.35759345e-01  6.80041374e-02 -3.35869919e-03  1.22867170e-01
  7.54439074e-03 -2.08682792e-01 -1.72947910e+00  2.65073839e+00
  1.04569872e+00  5.33022867e-01 -9.56391233e-01  9.04662646e-01
  1.72585889e+01]
supnorm grad right now is: 19.96018428690252
Weights right now are: 
[-5.74960188e+00  1.17471059e+01 -3.27486038e+01 -3.07188965e+01
  6.00417059e+00 -1.18557976e+01  3.31475410e+01  3.00028682e+01
  8.67071408e+00 -4.18977886e+00 -1.51195691e+01  7.19893684e+00
  3.87109127e+01  2.96603184e+01  4.41345930e+01  2.52115489e+00
  2.80243368e+01  4.70098098e+01  3.95738525e+01  1.22262451e+01
  2.09366130e+01  8.82201757e+01  3.94795988e+01  1.25912846e+01
  2.27087968e+01 -1.08870177e+01 -1.06314268e+01  7.62291525e-01
  2.70480550e+00  2.88679253e+00  1.16270393e+00  3.23620449e+00
  3.18312495e+01 -1.19164221e+01  1.13695204e+01 -2.22749470e+01
 -8.77277168e-01 -4.49487345e+00 -3.44615820e+01  3.06526393e+00
  1.56365050e+00  3.17977276e-01 -6.18145706e+00  3.90577439e+00
 -2.13664875e+00  3.66818518e+00 -2.41320358e+00  1.61838886e+01
  1.23200668e+01  1.18392702e+01  7.07950152e+00 -3.06055600e+00
 -8.98295556e-01  5.33315323e+01 -4.99610852e+00  2.62643526e+01
  2.53816083e+01 -8.61088036e-02  7.62718994e-01 -3.57971114e+00
  4.25285291e+00  1.36590582e+00  4.75038965e+00 -2.10790367e+00
  3.01372035e+01]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1720.5240341746162
gradient value of function right now is: [-6.56060487e-02  7.20491254e-02  3.46478878e-06  3.10710576e-06
  6.56060487e-02 -7.20491254e-02 -3.46478878e-06 -3.10710576e-06
  2.86002581e-02  2.02600426e-01 -2.45586145e-01 -7.15246477e-01
 -6.09064846e-03  2.80455600e-02 -1.17386775e-02 -1.76247299e+00
  1.64631474e-07 -5.28499908e-06  7.09226907e-07  1.79722519e-04
  5.83508522e-08 -2.21912519e-07  4.21426535e-07  1.46339827e-04
  9.92654702e-02  1.15213033e-01  6.48086417e-02  4.59771230e-02
 -8.71374351e-01  7.75418333e-02  1.35628917e-01  6.97142670e-02
 -2.19941978e+00 -1.78809641e+00 -1.73042884e-02 -2.11816974e+00
  1.10169696e+00  9.64947833e-01  1.83274059e-02  1.18090306e+00
  4.71787902e-02  9.80583203e-02  1.06825608e+00  2.05663802e-01
  8.20119222e-02  3.31573255e-02 -2.10090249e+00  1.62032129e-02
  8.94860126e-05  7.01037815e-03  5.41220310e-01  6.13111650e-03
  9.69481215e-02  2.93612179e-04 -2.80058248e+00 -1.06210804e-02
  5.95703677e-03 -2.31156743e-01  1.00828753e-01 -4.14560545e-01
 -3.51004495e+00  1.10672598e+01  5.37291969e-01 -1.35815561e+00
  4.49034324e+00]
supnorm grad right now is: 11.06725984506797
Weights right now are: 
[ -6.08288287  12.46573291 -32.78549862 -30.76692732   6.33745159
 -12.5744246   33.18443589  30.05089894   9.44968259  -4.22844298
 -15.04455292   7.13314563  38.80838576  30.28370619  44.61792512
   2.38206931  28.10161023  46.831329    38.58796775  13.8160099
  21.00395565  87.94583534  38.74188298  14.32262205  22.45441193
 -11.14110393  -9.96628953   1.44531554   2.59940922   3.29954765
   1.82337123   3.57519296  31.26922317 -12.22892079  12.74253
 -22.81046208  -0.82497824  -4.36145046 -37.36910486   3.72574183
   1.09615604   0.71627095  -6.29154646   3.32684956  -1.44244424
   4.0189434   -2.48063357  17.43615741  13.55426792  12.66848135
   7.63070268  -4.70587323  -1.55761257  55.65662744  -4.67229003
  26.55575164  26.24173268  -0.18880065   0.23342365  -3.53140916
   4.47133901   1.55876188   4.50535464  -1.95044397  30.12670509]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1723.5184094511476
gradient value of function right now is: [ 6.09210058e-02 -5.79479516e-02  8.83913045e-06  5.34310682e-06
 -6.09210058e-02  5.79479516e-02 -8.83913045e-06 -5.34310682e-06
 -1.02631076e-02 -6.16358293e-02  2.32114345e-01  4.94280330e-01
 -1.79082613e-03  1.84010509e-01 -6.67723978e-02  1.82511167e+00
  5.80539066e-08 -1.47836849e-06  1.41980779e-05  4.71230484e-04
  2.21678089e-08  6.49238163e-08  7.40192717e-06  2.65569474e-04
  2.67016663e-02  3.77113071e-02  3.33240556e-02  3.48868778e-02
 -3.35163988e+00 -1.78527014e+00 -3.98832736e-01 -6.23175674e-02
  5.36407055e+00  3.92659987e+00  8.81423966e-02  4.84519412e+00
 -1.64771635e-01 -3.09869352e-01 -3.06940166e-03 -4.77649845e-01
 -1.29686381e-01  1.01221394e+00 -2.82003596e+00 -8.45591743e-02
  2.56112162e-01  6.78000680e-01  7.68540840e+00  3.07287800e-01
 -1.34535233e-04  3.63889300e-02 -3.99698451e-01  4.16698800e-05
  1.86223531e-01  6.85952774e-02  7.21030000e+00  1.80595482e-01
  3.10702766e-02 -6.67030231e-01 -2.89474605e+00  5.73326583e+00
  4.64838982e+00 -2.04099986e+01 -2.53058185e+00  1.14498478e+01
  4.51323000e+00]
supnorm grad right now is: 20.409998605353604
Weights right now are: 
[ -6.08612979  12.76342639 -33.73809838 -31.4910154    6.3406985
 -12.87211808  34.13703565  30.77498702   9.20721888  -4.39050286
 -14.60437175   7.49341455  38.375521    30.12184028  45.58767528
   2.45695072  28.17491585  45.76090896  38.00340867  13.97597032
  21.04825639  87.61759103  38.33028346  14.64442403  23.34981317
 -10.73959561  -8.96277448   2.79655443   2.64612224   2.64922561
   1.27547085   4.20959479  31.26641004 -11.80481427  15.05442899
 -22.56302704  -1.05298457  -4.95579288 -36.87358038   3.63104745
  -0.09657438   0.57445212  -6.40489313   3.44530928  -0.90074938
   3.53430918  -2.02745509  17.92269967  15.55725323  14.93791384
   9.7413212   -3.57722222  -1.73725822  57.66454287  -4.58263475
  27.01198801  29.69650588  -0.5094326    0.39179697  -3.7621798
   4.78355461   1.13742712   4.75370687  -2.1976973   29.7776376 ]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -1721.7931357948414
gradient value of function right now is: [-1.96499724e-01  3.59880721e-02  7.49499270e-06  3.59262657e-06
  1.96499724e-01 -3.59880721e-02 -7.49499270e-06 -3.59262657e-06
  3.38345971e-02 -8.02592053e-01  2.82098561e-01 -1.40925724e+00
  4.09672012e-02  3.38819601e-01 -9.59175286e-02  1.31621448e-01
 -7.34217099e-07 -3.49506320e-06  6.28280629e-06  4.52129677e-04
 -2.10467986e-07 -2.44055015e-08  2.50524003e-06  2.00786158e-04
 -8.46659558e-01 -7.52454295e-01 -5.01445885e-01 -3.50576260e-01
 -5.82206631e+00 -3.00721999e+00 -7.96466994e-01 -1.32811881e-01
  6.35977512e+00  4.60669199e+00  1.97308774e-01  5.37892514e+00
  3.16582806e+00  7.12079615e-01 -1.05537405e-03  5.98930946e-01
 -7.07556225e-02  3.55476384e+00 -5.06392827e+00  1.62328686e-01
  1.93577422e-01  1.71657421e+00  9.22067057e+00  4.48626854e-01
  7.41951967e-05  1.77067092e-02 -6.57414484e-01 -9.88313981e-04
  1.72231889e-01  1.99465845e-01  1.11399973e+01  3.65048282e-01
  4.50630654e-02 -8.12911388e-01 -7.02088194e+00  1.51408546e+01
  8.98766886e+00 -3.00668315e+01 -5.01556078e+00  1.95578788e+01
  1.66444688e+01]
supnorm grad right now is: 30.06683151645894
Weights right now are: 
[ -6.41501452  13.24809635 -34.47811408 -31.98458674   6.66958323
 -13.35678804  34.87705135  31.26855836   9.27453422  -4.11413055
 -14.49397519   7.02551033  39.06541058  30.15658412  46.49262681
   2.28383771  28.20450869  45.04268245  37.36777976  14.2239875
  21.06105835  87.42900823  37.92045095  15.10058975  22.89126944
 -11.45381888  -9.32116165   2.08606243   2.78622553   3.16775636
   2.01997095   4.08656762  30.7860191  -11.91676465  15.74078773
 -22.86291241  -0.78704358  -5.98903557 -37.12639695   3.54367488
   1.06508529   0.27139296  -5.91964929   3.3664266   -1.10751254
   3.48603499  -2.05487684  17.67388995  21.14121316  15.55540503
  11.00553876  -5.52935009  -2.624825    60.10697824  -4.48124904
  27.91087759  32.66101386  -0.4728524    0.56162324  -3.51585569
   5.27042146   1.05308794   5.26670901  -2.0342906   29.92937956]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -1724.77439488205
gradient value of function right now is: [-1.87178715e-01  2.02904216e-01  8.83244757e-06  3.40533980e-06
  1.87178715e-01 -2.02904216e-01 -8.83244757e-06 -3.40533980e-06
 -1.54403524e-01 -9.35664320e-01  2.80583997e-03 -1.10984294e+00
  3.82538709e-02 -4.99050629e-02 -6.39820530e-02 -4.32596096e+00
 -7.67538411e-07  1.09435847e-05  5.28571106e-06  5.06852807e-04
 -2.69023730e-07  7.42170725e-07  2.55679763e-06  1.81808528e-04
 -7.20061124e-01 -7.11228350e-01 -5.07252700e-01 -3.87412522e-01
  1.68110007e+00 -8.90771028e-02 -3.18524827e-01  7.85298050e-03
  3.49594538e+00  2.50259513e+00  2.63349477e-01  3.08264542e+00
  2.11056936e+00  4.04354613e-01  2.55593799e-03  2.43781041e-01
 -2.22546594e-03  2.37828263e+00 -3.19711560e+00  6.70464640e-01
  6.56563286e-02  4.01787833e-01  4.05809564e+00  7.35590431e-02
  2.68994283e-04 -3.47819677e-02 -7.21006658e-01 -1.57454959e-03
  5.02297774e-02  6.59524643e-02  5.18333370e+00  9.94350634e-02
  1.30897046e-02 -3.42485402e-01 -2.21253437e+00  4.39574986e+00
  5.45576341e+00 -1.50896644e+01 -1.46015034e+00  4.26152064e+00
  3.75827474e+00]
supnorm grad right now is: 15.08966444406201
Weights right now are: 
[ -6.46113528  13.51574693 -34.69281168 -32.12492911   6.71570399
 -13.62443862  35.09174895  31.40890073   9.27066934  -4.01458881
 -14.41510102   6.89244496  39.46212133  29.7383149   46.74283762
   2.33401168  28.23344328  44.74243753  37.08706748  14.20426117
  21.07925539  87.34717584  37.74671703  14.89193157  22.58309071
 -11.88314058  -8.80725868   2.27210778   2.91549414   3.15671746
   1.73716864   3.29251931  30.5113061  -11.71497704  16.85700557
 -22.91549934  -0.85973327  -6.10297812 -37.4047002    3.94245031
   1.93383569   0.67492846  -6.33023224   3.46091371  -1.52895959
   3.78471539  -1.6736838   17.81126905  23.91595229  16.08122067
  10.537168    -6.1824896   -2.45850701  61.40396372  -4.50564597
  27.74840334  34.36716153  -0.81510659   0.56809081  -3.80492716
   5.27972848   1.06743027   5.33290874  -2.31444466  29.92839525]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1724.8930935630246
gradient value of function right now is: [-9.87936254e-02  1.88852456e-01  1.51382377e-07 -8.33509904e-08
  9.87936254e-02 -1.88852456e-01 -1.51382377e-07  8.33509904e-08
 -9.04067142e-02 -2.91311352e-01 -2.23226167e-01 -7.63100763e-01
 -1.37618782e-02 -1.10262328e-01  6.89069354e-03 -5.03991014e+00
  1.52264759e-07  8.19389750e-07 -7.97042820e-07  1.61129576e-05
  3.61733255e-08  1.19621656e-07 -2.87579146e-07 -3.32661681e-06
  3.32772701e-01  2.47990696e-01  1.55209945e-01  1.06218303e-01
  2.00693960e+00  1.21767034e+00  2.40906779e-01  1.78379248e-01
 -2.23327598e+00 -1.43772654e+00  4.23463754e-02 -1.99941569e+00
  2.12918629e-01  8.95546188e-02  3.88950331e-03  1.03927244e-01
  7.60271613e-02  3.57054491e-01  8.23412663e-01  5.79007889e-01
 -1.22201699e-01 -3.50940823e-01 -4.20994650e+00 -2.11285928e-01
  2.30058507e-05 -1.19489612e-02  1.22864736e-02 -1.70812798e-03
 -1.19046631e-01 -5.86508106e-02 -4.05319999e+00 -1.70679251e-01
 -4.85903491e-02  8.81928240e-01  1.21211500e+00 -4.59619908e+00
 -1.86416193e+00  1.07722638e+01  8.40595850e-01 -9.68873873e+00
 -4.09086269e+00]
supnorm grad right now is: 10.772263812401464
Weights right now are: 
[ -6.89648727  13.79828091 -34.87955657 -32.22075515   7.15105598
 -13.9069726   35.27849384  31.50472676   9.04190634  -3.9379678
 -15.35421458   6.52916826  39.75931895  30.15754097  46.7386088
   2.31846754  28.23957515  44.12372154  36.92481776  14.64134964
  21.09021672  87.2773484   37.61270559  15.63604773  22.1167361
 -12.09166015  -8.12207627   3.61397128   2.61019864   3.37594179
   2.12105347   4.27627296  30.16426216 -11.66218048  16.42207354
 -23.16683616  -1.20181153  -6.88976741 -30.23341829   3.83371655
   1.53397103   0.95058462  -6.15575255   2.98436702  -2.27254681
   4.16569209  -1.61650684  17.34063263  29.85194972  16.22562834
  12.21820939  -7.94744902  -4.3894165   63.01132958  -4.76938533
  27.39947814  32.86858341  -0.9726538    0.5080119   -3.49872956
   5.40757144   1.1040891    5.22393061  -2.26318864  29.98242477]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1721.338550697921
gradient value of function right now is: [-7.17283809e-01 -2.94452706e-01 -1.38486545e-06 -3.68065201e-07
  7.17283809e-01  2.94452706e-01  1.38486545e-06  3.68065201e-07
 -3.79649229e-01 -3.37406659e+00 -8.49045735e-02 -5.19900749e+00
 -2.81000706e-03  2.07168471e-01 -1.71970994e-02  7.25372707e+00
  2.62705489e-08 -2.81155859e-06  4.26356190e-07 -8.69925257e-05
  1.26340854e-08 -1.32008772e-07  1.86318758e-07 -2.17059780e-05
  3.58674541e-01  6.62788413e-02  7.04695153e-02  7.96834221e-02
 -6.36616736e+00 -1.59036444e+00 -1.78382169e-01 -1.70238484e-01
  1.72928287e+00  1.27160355e+00  7.73037234e-02  1.70170051e+00
  2.36326810e+00 -2.85287397e-01 -6.97449754e-03 -4.34312429e-01
  1.25893391e-01  5.63750198e+00 -8.36785892e-01  1.99348274e+00
  4.17556078e-02  1.18805196e+00  2.16989627e+00  1.93912407e-01
 -3.10162646e-05  1.42165090e-02 -2.18807759e-01 -1.28965683e-04
  4.27511485e-02  6.69875890e-02  3.34474815e+00  1.06954453e-01
  4.94301301e-03 -3.46240337e-01 -3.14621014e+00  4.23347750e+00
  2.93274180e+00 -6.97655084e+00 -2.57949541e+00  1.68423243e+00
  2.43249493e+01]
supnorm grad right now is: 24.324949306262546
Weights right now are: 
[ -7.01610395  14.01994041 -34.88418004 -32.22673556   7.27067266
 -14.1286321   35.28311731  31.51070717   9.15691426  -4.16213122
 -15.12962133   6.71240585  39.94090368  30.71923614  47.66014593
   2.44532306  28.25083438  43.79965645  36.85998147  15.52811853
  21.09573681  87.25781039  37.5716861   16.33926191  22.05081805
 -12.12659053  -7.16053353   3.91425668   2.62349898   3.5401041
   1.86220453   4.45452992  29.91053193 -11.45260833  15.70640582
 -23.23080377  -0.99549434  -7.60069969 -26.26203003   4.07554261
   1.33337352   1.19649944  -6.92146683   3.09910549  -2.656951
   4.07562903  -1.31147793  16.98773483  33.34935581  19.62781916
  12.87510362  -7.58171357  -3.49729946  63.07011581  -4.91263817
  26.98605515  34.52182657  -1.52917007   0.85377069  -3.78645751
   5.38941967   1.0150526    5.93511439  -2.34024978  30.16758449]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1726.011544302644
gradient value of function right now is: [ 2.81315534e-02  1.73645657e-01  3.69391279e-06  5.01437927e-07
 -2.81315534e-02 -1.73645657e-01 -3.69391279e-06 -5.01437927e-07
  6.34206647e-03  1.00723683e-03  9.56441219e-04  3.25738940e-01
 -4.12021684e-03 -1.35030203e-01 -1.81583460e-02 -4.54837361e+00
  1.31419068e-07  1.27099992e-05  6.06611443e-07  2.27581725e-04
  5.51900749e-08  8.01275664e-07  3.20272362e-07  3.21525521e-05
  9.79874466e-02  7.66707313e-02  4.78041111e-02  3.81529123e-02
  3.46353840e+00  6.26892821e-01  2.83292975e-02  7.87503283e-02
  4.63404909e-01  3.75100673e-01  1.64530808e-01  3.47317376e-01
  1.30073751e-01  5.30641023e-02  1.23649004e-03 -1.54948233e-02
 -7.46251508e-02 -4.72398150e-01 -1.11304860e+00 -2.84400539e-01
 -4.00569975e-02 -7.92418170e-02 -4.25632407e-01 -9.80441530e-02
  1.72889739e-07 -4.69841558e-03 -1.97067363e-01 -1.77616311e-03
 -1.91676016e-02  2.31099768e-02  5.07940708e-01 -2.58722738e-03
 -1.07404182e-02  2.52234365e-01 -8.15746746e-01  1.84642151e+00
  6.78648724e-01 -1.68296900e+00  1.47978463e-01 -1.08154807e+00
 -4.76962284e+00]
supnorm grad right now is: 4.769622841630962
Weights right now are: 
[ -7.17264357  14.38264847 -35.17741117 -32.42102651   7.42721228
 -14.49134016  35.57634844  31.70499813   9.86601639  -4.27186008
 -14.74573193   6.48050107  40.32041092  30.67023672  47.28405558
   2.32780524  28.2622125   43.48816273  36.48633869  13.69225333
  21.10404844  87.19792391  37.33209274  14.19110453  22.24423443
 -12.40196777  -7.21082943   4.00553245   2.97448717   3.34222644
   2.54000812   4.60027546  29.43363911 -11.28354634  16.60861055
 -23.47424233  -1.19880309  -7.87266655 -23.81854206   3.38701769
   0.22256397   0.55665105  -6.39850227   3.05629317  -4.50164011
   4.03988385  -1.00234187  16.36437442  34.67705868  22.14680747
  13.07390608  -7.85065766  -3.24203229  64.02562109  -5.10522057
  26.89932795  36.02122742  -0.91825574   0.57298271  -3.50172449
   5.60681497   0.92241519   5.99894743  -2.27899046  29.90850222]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1723.4620342469136
gradient value of function right now is: [ 2.78734203e-01  3.60116592e-01  7.35358008e-07 -2.50726420e-07
 -2.78734203e-01 -3.60116592e-01 -7.35358008e-07  2.50726420e-07
  1.65549371e-02  1.33657537e+00 -2.68706277e-01  2.23512625e+00
 -2.31464179e-02 -3.13235425e-01  4.24843915e-02 -9.85685919e+00
  2.26810695e-07  5.27060952e-06 -3.53868477e-06  5.69689737e-05
  5.77942420e-08  2.99370582e-07 -1.55090522e-06 -1.03812863e-05
  4.49466687e-01  4.30465834e-01  2.21947463e-01  1.49409685e-01
  7.14746282e+00  2.94283516e+00  3.74099546e-01  2.69445856e-01
 -4.42724315e+00 -2.62639517e+00 -1.49300555e-01 -3.92148468e+00
 -1.26380709e+00  3.35426935e-01  1.07107913e-02  5.28124891e-01
  3.92305960e-02 -3.95888105e+00  2.61949060e+00 -4.73776516e-01
  3.47371096e-03 -1.48970772e+00 -5.51459687e+00 -2.48473289e-01
  5.74223061e-06  4.67238353e-04  4.49196223e-01  1.29685519e-03
 -2.35509458e-03 -1.63962185e-01 -7.26001707e+00 -1.71618175e-01
 -1.37584950e-03 -3.94813688e-02  6.15994998e+00 -1.18065669e+01
 -6.22255509e+00  1.83888048e+01  3.24013190e+00 -6.58702343e+00
 -2.20953330e+01]
supnorm grad right now is: 22.095332980067226
Weights right now are: 
[ -6.90030361  14.55975921 -35.23390588 -32.42166203   7.15487232
 -14.6684509   35.63284315  31.70563365   9.90440702  -4.024847
 -15.11482182   6.83713656  41.03503488  32.14150881  47.10102371
   2.45720179  28.28361275  41.82405205  36.44995726  14.93728183
  21.12291139  87.13736406  37.25702406  15.74195323  22.20998467
 -12.91656956  -6.55127071   4.21825619   2.82326567   3.53180121
   2.10123458   5.35063964  29.05508395 -11.05583723  16.93245458
 -23.6023472   -1.29315094  -7.49406597 -20.75470362   4.13723631
   1.09529385   0.62650466  -6.49814397   3.61507855  -3.08498471
   3.67525806  -0.64441019  15.09071429  36.22955538  24.46320234
  12.79792537  -9.87883514  -0.40183627  63.97149704  -4.90999378
  27.54878514  39.14546261  -2.17266779   0.70396296  -3.55157787
   5.28552727   1.04779538   5.86652699  -2.31467504  29.81609964]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1724.4976715024252
gradient value of function right now is: [ 6.31002086e-02  3.59251413e-01  1.54409512e-06  7.70364262e-07
 -6.31002086e-02 -3.59251413e-01 -1.54409512e-06 -7.70364262e-07
 -3.05011946e-02 -6.26824073e-02  1.98268872e-01  8.07217610e-01
 -5.55459877e-03 -7.67661150e-02 -4.19207158e-02 -9.72963515e+00
  4.02221971e-08  1.17952367e-06  6.72986662e-07  1.03654382e-04
  2.07634581e-08  1.91081869e-07  3.98538594e-07  4.71931431e-05
  1.19154045e-01  1.10674657e-01  6.49552685e-02  5.19037098e-02
  2.30334293e+00  8.09817721e-01  8.10666126e-02  1.79712378e-01
  3.94317232e+00  2.27104931e+00  2.28783344e-01  3.45798267e+00
  3.53540627e-01  8.77302704e-02  1.31904802e-03 -2.73255573e-02
 -2.50038409e-02  4.32814831e-01 -3.10433520e+00  4.82288483e-02
  1.89753517e-02  2.65439536e-01  3.95497294e+00  3.28081904e-02
 -6.09210878e-06 -1.06349125e-02 -4.14675359e-01 -3.22713189e-03
  1.54489946e-02  5.20727318e-02  5.00122358e+00  6.94813425e-02
  7.27465270e-03 -1.26053205e-01 -1.45004125e+00  5.06032446e+00
  1.80275358e+00 -9.70275148e+00 -5.11383721e-01  3.15002176e+00
 -2.23979546e+00]
supnorm grad right now is: 9.729635149376337
Weights right now are: 
[ -6.89022905  14.81719303 -35.32506358 -32.46934567   7.14479776
 -14.92588472  35.72400085  31.75331728  10.35125701  -3.42353229
 -15.21051786   6.75527943  41.33877427  32.55484899  47.33546947
   2.32423933  28.29425115  41.39022842  36.31932689  15.22297087
  21.12878399  87.10358627  37.18299982  15.64854156  21.76112176
 -13.06533171  -6.26779666   4.56613558   2.70715853   4.08029274
   2.6514939    5.81659013  28.87212137 -10.8496583   16.29199664
 -23.66673913  -1.1809773   -8.55657666 -16.76387487   3.36794498
   1.00957541   0.90380719  -6.89192463   3.0863506   -4.0767766
   3.73696838  -0.32447841  14.28544816  39.46359009  26.84733986
  13.322401   -13.22564072  -1.7239896   64.39178415  -5.05622806
  26.57583816  40.52726202  -1.71418829   0.78108879  -3.51431526
   5.5971163    0.87793053   5.91490792  -2.51359933  29.97101964]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1723.3624430393133
gradient value of function right now is: [ 1.45626182e-01 -8.20796486e-02 -1.70055044e-06 -1.44320363e-06
 -1.45626182e-01  8.20796486e-02  1.70055044e-06  1.44320363e-06
 -7.42358216e-02  1.32489563e-01  2.63710843e-01  1.69945561e+00
  6.93000825e-03 -8.69174266e-02  1.58258760e-02  1.95508494e+00
 -1.07071201e-07  2.39296611e-06 -6.88890553e-07 -1.12126735e-04
 -6.01103982e-08  1.73983369e-07 -3.92979068e-07 -8.53493178e-05
 -1.28715915e-01 -1.42179784e-01 -1.11538078e-01 -9.95148903e-02
  2.25293584e+00  7.28742388e-01  2.22777408e-02  2.18295980e-02
  2.70101061e+00  1.48589993e+00  1.42217076e-01  2.72259667e+00
 -1.58276753e+00 -5.45273057e-01 -5.48718925e-03 -1.07145102e+00
 -2.61800774e-02 -1.62086713e-01 -1.55318402e+00  5.78020890e-02
 -3.89932860e-03 -2.76648872e-01  1.84286421e+00 -1.07539865e-01
 -1.47645509e-05 -6.76657883e-03 -1.87619943e-01  1.20464488e-04
 -1.70459665e-03 -4.73527196e-02  1.92401660e+00 -4.16970090e-02
  8.64849252e-04  9.19362779e-03  1.13611985e+00 -3.30833742e+00
  8.19007470e-01 -5.15073384e+00  4.85332588e-01 -1.93256414e+00
 -6.94836611e+00]
supnorm grad right now is: 6.948366112016433
Weights right now are: 
[-7.08844184e+00  1.49620280e+01 -3.54631934e+01 -3.25601726e+01
  7.34301055e+00 -1.50707197e+01  3.58621306e+01  3.18441443e+01
  1.00163908e+01 -3.90648476e+00 -1.55576670e+01  7.02441304e+00
  4.18539638e+01  3.26200021e+01  4.77370619e+01  2.49820722e+00
  2.83021488e+01  4.10770575e+01  3.62375756e+01  1.47895893e+01
  2.11370459e+01  8.70692443e+01  3.71047360e+01  1.52565457e+01
  2.17808524e+01 -1.34727059e+01 -6.08438716e+00  4.87753097e+00
  2.80737097e+00  4.41901158e+00  1.88259356e+00  5.78909163e+00
  2.85298599e+01 -1.04419625e+01  1.71551006e+01 -2.37227012e+01
 -1.37736092e+00 -8.24643740e+00 -1.54650897e+01  3.14813280e+00
  1.23102092e+00  8.16954445e-01 -7.00175999e+00  2.92993106e+00
 -5.35212601e+00  3.90331087e+00  1.99043157e-02  1.31198853e+01
  4.04408019e+01  3.03980581e+01  1.29696201e+01 -1.60792029e+01
 -5.72580615e-01  6.44543792e+01 -5.09725310e+00  2.66590311e+01
  4.17915162e+01 -1.71786215e+00  9.97474595e-01 -3.62184010e+00
  5.72143520e+00  7.49668934e-01  5.98671975e+00 -2.64155698e+00
  2.98869006e+01]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1724.4412110080511
gradient value of function right now is: [ 1.41235772e-01 -4.34068068e-02 -6.25247345e-07 -4.99453009e-07
 -1.41235772e-01  4.34068068e-02  6.25247345e-07  4.99453009e-07
  1.65192148e-02  9.20517775e-01 -2.61736382e-01  9.37171825e-01
 -1.84387050e-02 -8.09938450e-02  4.46734509e-02  9.56194865e-01
  1.37963699e-07  6.86441114e-07 -7.28177054e-07 -4.14055244e-05
  5.29965268e-08  6.13364385e-08 -4.20312945e-07 -3.00016341e-05
  3.13236834e-01  3.33214040e-01  1.38127993e-01  9.62737418e-02
  1.73696073e+00  9.60420833e-01  1.03882649e-01  8.11747332e-02
 -4.02338938e+00 -2.18599717e+00 -2.61366192e-01 -3.49871973e+00
 -1.49257232e+00 -1.73905869e-01  6.06326450e-03 -2.37370268e-01
  7.39896847e-03 -1.40936152e+00  2.86684956e+00 -2.34751275e-02
 -1.73590110e-02 -6.66815537e-01 -4.93452469e+00 -1.56788377e-01
  2.68728664e-06  1.47083072e-02  5.12850206e-01  1.99802993e-03
 -2.19247131e-02 -1.56714115e-01 -6.75945544e+00 -1.50692958e-01
 -1.00890942e-02  2.11457945e-01  4.54583378e+00 -1.20069803e+01
 -4.28332890e+00  1.49722438e+01  1.60047656e+00 -6.30087630e+00
 -1.18865863e+01]
supnorm grad right now is: 14.97224380798725
Weights right now are: 
[ -6.9457133   15.21311449 -35.49787841 -32.58405239   7.20028201
 -15.32180618  35.89681568  31.86802401  10.66950642  -3.62720352
 -15.27233385   6.96481394  42.74443055  33.43751708  47.85906386
   2.5125892   28.30606824  40.8199396   36.39511489  15.41565753
  21.14115522  87.04087608  37.18657975  15.84674434  21.33944408
 -14.2129469   -6.23286742   4.73485287   2.68447852   4.02955823
   2.59719441   6.37620732  27.90182568 -10.53075827  16.99806097
 -24.13540719  -1.34901899  -8.1954308   -9.3609542    2.28106942
   0.79640126   1.16915767  -6.43941002   2.87742474  -7.43827919
   4.57768144   0.13507918  12.57687861  41.7903393   33.86175956
  13.6393046  -15.54850667  -1.92971878  65.03817644  -4.7979709
  26.92670882  39.99348018  -1.73630805   0.89701299  -3.33109073
   5.72242861   1.05411334   5.32934204  -2.51734157  29.79959496]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1723.372326830224
gradient value of function right now is: [ 1.81423567e-01  3.72294257e-01  1.47570829e-06  4.48315690e-07
 -1.81423567e-01 -3.72294257e-01 -1.47570829e-06 -4.48315690e-07
 -1.84989083e-02  8.61537385e-01 -2.25167571e-01  1.53509294e+00
 -2.55965396e-02 -3.60519184e-01  2.04660224e-02 -1.04878189e+01
  1.10201005e-07  4.34162123e-06 -3.89251004e-07  9.06569521e-05
  4.76174738e-08  4.27932904e-07 -3.14189431e-07  2.48699175e-05
  5.10905727e-01  4.45730933e-01  1.24392558e-01  6.09669032e-02
  8.15980649e+00  2.97970083e+00  1.29402560e-01  1.04487534e-01
 -2.54189651e+00 -1.44065890e+00 -3.01797061e-01 -2.17479661e+00
 -1.74074222e-01  3.12320370e-01  1.07031950e-02  3.82009017e-01
  7.01646595e-02 -3.26986885e+00  1.18066273e+00 -2.57305879e-01
 -2.29562973e-03 -1.59946989e+00 -2.52368956e+00 -2.45225402e-01
  8.02103636e-07  1.41379866e-02  4.18319045e-01  2.17015116e-03
 -4.91638198e-04 -1.23860962e-01 -4.05213023e+00 -9.11552619e-02
 -6.20813249e-03 -6.26492220e-02  6.05785616e+00 -8.88698886e+00
 -4.12779705e+00  1.17756711e+01  2.04896044e+00 -3.46435004e+00
 -1.80587471e+01]
supnorm grad right now is: 18.058747064692973
Weights right now are: 
[ -7.20883342  15.4536478  -35.53485784 -32.60873938   7.46340213
 -15.56233949  35.93379511  31.89271099  10.44395917  -4.15149839
 -15.09763754   7.17497549  42.88290116  33.74568327  49.95829408
   2.48649622  28.3060257   40.60680742  36.50714514  15.97149848
  21.14276821  87.01410214  37.24182648  16.03088127  22.04145577
 -14.19323353  -6.03905103   5.56174897   3.0069008    4.56058996
   2.78935801   6.52139459  27.03019707 -10.60622653  17.03338529
 -24.67980102  -1.11936857  -8.2419851  -10.33570794   3.41028563
   1.86196178   0.9646476   -6.77083441   3.0398137   -8.93170144
   4.1017871    0.28351264  11.59536316  42.19831405  36.04343569
  13.12953171 -16.00320187  -0.84084728  65.09595287  -4.90251028
  26.91618104  39.45548075  -3.17929395   1.08675254  -3.42211086
   6.07900343   0.99774705   6.30073215  -2.39551622  30.03174287]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1723.7136499360315
gradient value of function right now is: [ 5.03127739e-01 -6.39041764e-02 -2.91988034e-06 -1.59353488e-06
 -5.03127739e-01  6.39041764e-02  2.91988034e-06  1.59353488e-06
  7.13332181e-01  2.70768452e+00  3.67023645e-01  3.38101060e+00
 -1.02049480e-02 -3.99739134e-02  5.54786598e-02  1.46028972e+00
  1.48249643e-07  5.35238185e-06 -4.51381791e-06 -1.84141995e-04
  4.45070037e-08  5.62150960e-08 -1.74186728e-06 -8.72897788e-05
 -1.24934051e-01  2.01913192e-01  1.07007732e-01  8.86377481e-02
  1.94876915e+00  2.98381253e-01  3.34705704e-02  4.83577957e-02
 -3.89078854e+00 -1.86374260e+00 -1.81982929e-01 -3.56359237e+00
 -3.06165785e+00 -1.41098450e-01  2.20278641e-03 -2.54891220e-01
 -2.28892616e-01 -5.33845605e+00  1.69007596e+00 -3.34781210e+00
 -1.54246262e-02 -4.28618197e-01 -5.43122780e+00 -1.51670467e-01
  6.50840303e-06  1.14152879e-02  2.92365596e-01  8.86684558e-04
 -2.00782269e-02 -1.72845922e-01 -7.75777772e+00 -1.61770002e-01
  1.17516388e-02  3.06888633e-01  3.01244326e+00 -1.32125431e+01
 -3.14762076e+00  1.16637096e+01  1.61125556e+00 -4.64862146e+00
 -1.27047566e+01]
supnorm grad right now is: 13.212543069479237
Weights right now are: 
[ -7.08984826  15.48276122 -35.71393008 -32.66837549   7.34441697
 -15.59145292  36.11286735  31.95234711  10.59856365  -3.66915455
 -14.58527243   7.36272773  43.7273285   34.61862432  50.51967362
   2.57267399  28.32318502  39.56540337  36.87754689  14.88879027
  21.15158442  86.96438508  37.37141831  15.8466247   21.40865851
 -14.83118866  -5.96297149   6.51883118   2.70003437   4.19231032
   3.80138727   7.10261792  27.03577405 -10.04372733  17.21110914
 -24.41487173  -0.89484165  -8.85298368  -8.77534904   2.70554273
   0.98798886   0.45943698  -6.89286852   2.77279489  -7.07770282
   4.94922579   0.65692029  10.13958266  41.83801023  36.50860924
  13.14861625 -18.57945883   1.9518361   65.52270622  -4.53688362
  27.24498509  39.5054016   -2.16096629   0.68463325  -3.52331616
   5.79773171   1.01796921   6.60785068  -2.71576613  29.95744662]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1724.0367082341074
gradient value of function right now is: [-1.94586480e-01 -3.96160076e-02 -3.91414098e-06 -1.88939044e-07
  1.94586480e-01  3.96160076e-02  3.91414098e-06  1.88939044e-07
 -1.32744922e-01 -6.64370046e-01 -2.60164927e-01 -1.64666312e+00
 -1.03034614e-02  1.13806883e-01 -1.10186351e-03  9.02218425e-01
  1.98491793e-07 -2.19230674e-05 -9.62827638e-07 -1.99996312e-04
  4.52583349e-08 -1.53828296e-07 -2.41354819e-07 -9.80159167e-06
  2.99769253e-01  2.17644769e-01  1.56939679e-01  1.50752891e-01
 -3.38718353e+00 -9.00947975e-01  5.02987048e-03  1.08264699e-02
 -1.78798433e+00 -5.89868524e-01  1.12255714e-01 -1.53946484e+00
  9.31206018e-01 -2.43619450e-02  3.19549499e-03  5.76855107e-02
  1.46439844e-01  1.23945667e+00  1.17451975e+00  8.95819790e-01
  7.65842860e-03  2.16258931e-01 -1.93065401e+00  5.91760803e-02
  3.15238437e-06  9.08336347e-04  8.55586828e-03 -6.66796230e-05
 -6.41861454e-03 -3.61363331e-02 -3.64063039e+00 -7.08826440e-02
 -2.78256517e-03 -6.88187241e-02 -7.51830261e-01 -3.37288688e+00
 -2.33393758e-01  5.91325442e+00 -1.34421305e-01 -3.04496201e+00
  8.28154887e+00]
supnorm grad right now is: 8.281548872534332
Weights right now are: 
[ -7.46546801  15.80043758 -35.82019289 -32.7061775    7.72003672
 -15.90912927  36.21913016  31.99014912  10.39166135  -3.66689501
 -15.4520833    7.30869462  43.18493104  35.11309416  51.20541198
   2.45126998  28.33742354  38.95816442  37.02984132  14.46718401
  21.15727729  86.92239642  37.42743197  15.87492248  21.49256547
 -14.25605741  -5.66480062   6.69147468   2.43766279   4.49744849
   2.7287751    6.05263195  26.61318299  -9.91860593  17.67205134
 -24.62837212  -0.23591042 -10.18973534  -8.36543659   2.04086108
   1.09461974   0.67172938  -6.62383248   3.18672316  -6.95218542
   4.28787741   0.58815078   9.74945068  41.03207872  40.78595044
  13.50502261 -18.47694439   2.86089324  65.53200057  -4.70519029
  26.75228435  37.87371074  -2.87261065   0.76000443  -3.40871002
   5.9993917    0.90937185   6.82019116  -2.81467276  30.10811183]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1723.1941641194421
gradient value of function right now is: [-5.12226930e-01 -3.05736244e-01 -3.86690184e-06  5.70256800e-07
  5.12226930e-01  3.05736244e-01  3.86690184e-06 -5.70256800e-07
 -4.02876015e-01 -2.74955144e+00 -1.33677400e-01 -4.12552895e+00
  3.93098563e-02  3.42069379e-01 -4.92335697e-02  9.25067718e+00
 -1.42400856e-06 -2.25169333e-05  4.67117186e-06 -2.68837430e-04
 -1.96165725e-07 -7.77986377e-07  1.23161795e-06  2.98656299e-05
 -5.31237014e-01 -7.10874698e-01 -1.97768296e-01 -1.46481639e-01
 -9.43395484e+00 -3.28651905e+00 -1.54528762e-01 -2.35163969e-01
  3.43920197e+00  1.49992370e+00  1.02800721e-01  2.93811537e+00
  2.48773233e+00  5.23202633e-02 -4.51635414e-03  2.70917461e-01
  7.10412280e-02  5.40159392e+00 -1.04054561e+00  1.76312627e+00
  5.02482385e-02  1.75738724e+00  5.41432487e+00  3.55387159e-01
 -3.52085928e-06 -1.18995488e-02 -2.58899815e-01 -4.79414233e-04
  5.95829123e-02  3.19096306e-01  8.23053528e+00  2.19703223e-01
  1.75204497e-02 -3.15899894e-01 -9.13955355e+00  2.44292809e+01
  4.85417977e+00 -1.54669465e+01 -2.75506042e+00  6.76411505e+00
  2.66933732e+01]
supnorm grad right now is: 26.693373156014392
Weights right now are: 
[ -7.73829955  15.85918137 -35.94079977 -32.77051023   7.99286826
 -15.96787306  36.33973704  32.05448185  10.62536111  -3.91674554
 -15.93076524   7.23392627  43.59345624  35.97561635  51.86416221
   2.55643518  28.35744029  38.90291172  37.01762652  13.8507153
  21.16475969  86.88183754  37.40947089  15.16831665  20.92744797
 -14.46255293  -5.97753933   6.62992679   2.62818009   4.75852391
   3.89971091   6.78512573  26.39078771  -9.74811636  18.20830275
 -24.67185023  -0.83333069  -9.98912335 -10.54293927   2.01713136
   0.29673793   1.21650353  -6.81281207   2.98006642  -9.14470064
   4.94974325   0.9999671   10.00177855  41.27926503  42.6405915
  14.29735041 -20.13676213   2.39375412  65.28823594  -4.62958193
  26.15314566  35.57498542  -1.63760675   0.64307916  -3.25448336
   6.2155317    1.04753085   6.41197866  -2.53948376  29.92456974]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1722.7724790899467
gradient value of function right now is: [ 1.23859783e-01  2.76314972e-01  3.83144759e-06  3.77367650e-07
 -1.23859783e-01 -2.76314972e-01 -3.83144759e-06 -3.77367650e-07
 -9.35856213e-02  1.67144145e-01  1.53470196e-01  1.47696828e+00
 -1.45212026e-02 -1.87729062e-01 -1.28730083e-02 -8.02333055e+00
  1.94026751e-07  9.47659387e-06  8.72382557e-07  2.41909049e-04
  2.62988396e-08  2.71968872e-07  2.10735945e-07  2.22253207e-05
  3.38366576e-01  2.68574451e-01  8.57220627e-02  6.43023185e-02
  5.19154165e+00  1.43127553e+00  5.38947534e-02  1.01739347e-01
  3.04454257e+00  1.17419486e+00  1.03858803e-01  2.69472724e+00
  7.51833383e-02  7.48564641e-02 -2.35968117e-03 -1.53152294e-01
 -4.96236725e-02 -4.90143655e-01 -2.27506868e+00  1.66130365e-02
  1.01072263e-02 -2.76677922e-01  2.20463418e+00 -8.94024332e-02
 -2.69824003e-05  5.23906267e-03 -2.34042256e-01 -1.52175860e-04
  4.22069357e-02  5.07123277e-03  5.13376279e+00  7.97660760e-02
 -4.75855011e-04 -2.87867965e-02  1.36756665e+00  2.06678344e+00
  4.56413234e-01 -7.61256663e+00  8.65020853e-02  2.65400478e+00
 -1.03441267e+01]
supnorm grad right now is: 10.344126700411062
Weights right now are: 
[ -7.52602394  16.02872667 -35.95454778 -32.76287603   7.78059265
 -16.13741836  36.35348505  32.04684765  10.66139605  -3.70495575
 -15.68884558   7.25622806  43.67811164  35.77143355  52.27924527
   2.5464699   28.41587716  37.45513009  37.70643522  14.85136051
  21.17388955  86.83846565  37.56081676  16.34779186  21.29071815
 -14.46059339  -5.70158836   7.64802988   2.99078904   5.00396695
   3.6517926    7.48752528  26.15026025  -9.31983565  18.45297702
 -24.48340711  -1.10030496  -9.00981982  -7.92089246   1.98510687
   1.01096227   0.91023909  -6.87283958   3.14797287  -7.76588216
   4.94121975   1.27963954   9.00840767  40.7908662   45.13922213
  12.92295246 -21.50741778   3.23860037  65.29643662  -4.44271068
  26.80839409  37.31871204  -1.4885853    0.87067739  -3.45715223
   5.96498287   0.78710875   6.11967788  -2.5829287   29.86485672]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1723.700694121829
gradient value of function right now is: [ 4.93498151e-01  1.71643828e-01  6.24018010e-06 -1.07343830e-07
 -4.93498151e-01 -1.71643828e-01 -6.24018010e-06  1.07343830e-07
  5.84067775e-01  2.65466919e+00  2.36871842e-01  3.90612956e+00
 -2.31168445e-02 -2.04341432e-01  3.56665409e-02 -5.27496965e+00
  1.21574619e-06  3.81349227e-05 -3.34539164e-06  3.89988714e-04
  1.19111791e-07  3.86167880e-07 -5.35298725e-07 -5.91232668e-06
  1.67712546e-01  4.35534956e-01  1.51741381e-01  1.39922507e-01
  6.22070478e+00  1.86839620e+00  5.47394685e-02  1.12678916e-01
 -3.40586016e+00 -1.59038478e+00 -1.75610847e-01 -3.06990829e+00
 -3.06731239e+00 -3.15005115e-02  3.93305943e-03 -8.44009157e-02
 -5.76574653e-02 -5.90385200e+00  1.60882993e+00 -2.71749497e+00
 -8.12555193e-02 -1.42689187e+00 -4.51522415e+00 -3.04295098e-01
  2.49443915e-05  9.43622609e-03  4.08432562e-01  1.40750681e-03
 -1.11694111e-01 -2.09518891e-01 -7.80303199e+00 -2.26960658e-01
 -2.16132114e-02  7.33900411e-01  5.20295119e+00 -1.58966369e+01
 -4.07512879e+00  1.41012495e+01  2.19683580e+00 -6.23952811e+00
 -2.07895749e+01]
supnorm grad right now is: 20.789574879952173
Weights right now are: 
[ -7.81803836  16.1834745  -36.28292941 -32.82485753   8.07260707
 -16.2921662   36.68186668  32.10882914  11.83145133  -3.58343331
 -15.66348466   7.11619787  44.07126422  37.07730189  52.20930054
   2.47956764  28.42859315  34.97603368  38.07360578  13.54694793
  21.17694876  86.79255241  37.60026418  15.34307167  20.53785407
 -14.70165928  -5.82389075   8.00966768   2.74373306   4.90218383
   4.25252266   7.21514782  25.80024459  -9.27057342  18.19481813
 -24.71607426  -0.90560196 -10.11478687  -7.84994117   1.38833629
   1.82165548   0.36648161  -6.56522239   2.90589134  -8.43421273
   4.5450788    1.02942435   8.35805329  40.22161836  46.31608691
  12.67854105 -21.22360666   0.7608736   64.97968942  -4.52254198
  25.81105566  36.64656299  -1.10971495   0.59159415  -3.47305951
   6.00122997   0.94222307   6.60601487  -2.49272676  29.872658  ]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1725.3506748214681
gradient value of function right now is: [-9.84109453e-02 -2.41946442e-01  9.35108820e-07  6.70248654e-07
  9.84109453e-02  2.41946442e-01 -9.35108820e-07 -6.70248654e-07
 -1.77407456e-01 -5.70825000e-01 -1.11556429e-01 -7.34988828e-01
  3.25774598e-03  1.20267216e-01 -6.07241072e-03  7.34339298e+00
 -8.29633813e-08 -2.11827412e-08  1.94654007e-06 -7.16751388e-06
  6.49803383e-09 -1.83900733e-07  5.09322513e-07  2.69204623e-05
  3.94156129e-02 -4.47944800e-02  4.39129697e-02  5.05029032e-02
 -3.41728763e+00 -1.37988020e+00 -4.46825798e-02 -1.83026541e-01
  4.82249257e-01  1.79975660e-01 -4.60220350e-02  4.24885084e-01
 -7.68372643e-03 -1.38525986e-01 -5.01815640e-03  1.93692096e-01
  1.11211182e-01  1.31553533e+00 -7.32874653e-02  8.14035728e-01
  9.64350152e-03  2.06958418e-01  1.26602092e+00  6.96344614e-02
 -2.94937517e-07  6.64492794e-03 -4.71816219e-03  2.42115149e-04
  7.18087443e-03  9.19103743e-02  2.01576245e+00  6.59240093e-02
 -9.15903934e-03 -1.62620578e-01 -2.21532336e+00  6.25150046e+00
  8.93273851e-01 -2.13834314e+00 -4.68089340e-01  1.41093976e+00
  9.35922791e+00]
supnorm grad right now is: 9.359227906175894
Weights right now are: 
[-8.04222661e+00  1.61912056e+01 -3.62881083e+01 -3.28484137e+01
  8.29679532e+00 -1.62998973e+01  3.66870456e+01  3.21323853e+01
  1.14676871e+01 -3.90887713e+00 -1.57073635e+01  7.28277272e+00
  4.37048043e+01  3.76491309e+01  5.37259072e+01  2.72124092e+00
  2.84666717e+01  3.44133112e+01  3.81588354e+01  1.45669395e+01
  2.11827949e+01  8.67483367e+01  3.76151515e+01  1.61872719e+01
  2.07157613e+01 -1.42718520e+01 -6.37799253e+00  7.68673354e+00
  2.79004308e+00  4.69527861e+00  3.55344493e+00  5.75820225e+00
  2.58228308e+01 -8.74813466e+00  1.81656016e+01 -2.44560042e+01
 -6.02309802e-01 -1.00708275e+01 -8.57490639e+00  1.93463224e+00
  2.53827484e+00  6.28872006e-01 -7.32564720e+00  3.12299073e+00
 -6.02931547e+00  4.22168461e+00  1.37241671e+00  7.67906354e+00
  3.98154328e+01  4.93934900e+01  1.23338096e+01 -2.08707788e+01
 -2.95968035e-02  6.47340486e+01 -4.43797558e+00  2.48674332e+01
  3.89099969e+01 -2.85450627e+00  1.02324720e+00 -3.35381096e+00
  5.86599290e+00  1.23843167e+00  6.48542671e+00 -2.67794619e+00
  3.01238754e+01]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1725.307099497591
gradient value of function right now is: [-2.52090118e-01  1.13424057e-01  9.06503067e-06  2.09205640e-06
  2.52090118e-01 -1.13424057e-01 -9.06503067e-06 -2.09205640e-06
 -1.23390774e-01 -1.32911136e+00  3.06817341e-02 -2.17011734e+00
  4.27683422e-02  6.80307084e-02 -5.85387961e-02 -2.52655417e+00
 -9.75033201e-07 -2.38329546e-06  5.93373338e-06  5.36233773e-04
 -1.26693675e-07  1.09574969e-07  1.29902085e-06  1.12328700e-04
 -8.39574551e-01 -8.26251042e-01 -3.96678805e-01 -3.95571323e-01
 -1.65969220e+00 -1.01012684e+00 -7.29302418e-02  2.52152609e-02
  3.77223632e+00  1.59363544e+00  2.78156708e-01  3.07542356e+00
  3.58554432e+00  4.28413185e-01 -4.70558053e-03  8.98772487e-01
  8.48982799e-03  3.45673816e+00 -2.22938906e+00  7.01633311e-01
  2.63094195e-02  9.27985090e-01  3.90571407e+00  1.61433276e-01
 -1.48110858e-05 -3.35782695e-02 -5.84429121e-01 -3.80579681e-03
  3.71157296e-02  2.07999117e-01  7.10934777e+00  1.89984485e-01
  1.20927047e-02 -2.99198861e-01 -5.65049844e+00  1.46469757e+01
  4.73158209e+00 -1.50428136e+01 -1.55793352e+00  5.65392615e+00
  1.11478609e+01]
supnorm grad right now is: 15.042813606127295
Weights right now are: 
[ -8.18200264  16.46855627 -36.39309086 -32.87853238   8.43657135
 -16.57724796  36.79202813  32.16250399  11.32663495  -3.85493053
 -16.29918123   7.00553759  43.901898    38.95727596  53.4684484
   2.51342671  28.52635383  32.89697155  38.5300193   14.46382726
  21.18726397  86.70882567  37.65720095  16.15397129  20.64151719
 -14.31615931  -7.21726978   6.91383652   2.93606608   4.7942009
   3.75140369   6.7546099   25.50288985  -8.6835066   17.95494333
 -24.48468959  -0.92657154  -8.73222166  -7.81299291   2.04170547
   1.82550183   0.78642926  -6.88773604   2.71913185  -8.01387673
   5.44873798   1.45757789   8.01414862  39.32721657  49.2718049
  12.5216116  -22.20322652   0.27293087  64.62138273  -4.61581651
  23.44020375  38.10212694  -1.63004298   0.70649895  -3.41346501
   6.08737251   0.94261174   6.29583269  -2.46342077  29.94926535]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1724.8858778891736
gradient value of function right now is: [ 1.05490370e-01 -1.58345913e-01 -4.52073796e-06 -1.62245250e-07
 -1.05490370e-01  1.58345913e-01  4.52073796e-06  1.62245250e-07
  1.47968351e-01  8.02442508e-01 -7.48225709e-03  6.26064716e-01
 -1.14576286e-02  1.14807552e-01  8.04325690e-03  4.58909692e+00
  2.19443372e-07 -1.54100833e-05 -1.28462147e-07 -2.82870510e-04
  2.30277886e-08 -1.63429472e-07 -1.21276029e-08 -1.00104137e-05
  1.37937730e-01  2.24424212e-01  9.84177898e-02  9.65811824e-02
 -3.53932697e+00 -6.62968948e-01  2.39969206e-02 -7.07600242e-02
 -1.30449604e+00 -7.68328716e-01 -1.67499163e-01 -1.21307178e+00
 -1.43715865e+00 -1.18771191e-01  1.18539784e-03 -5.58244222e-03
  2.88740468e-02 -1.21269078e+00  1.53757624e+00 -4.76103286e-01
  2.10478542e-02  1.79582041e-01 -3.90563476e-02  1.58501838e-01
 -3.26826397e-06  1.48236672e-02  3.10557840e-01  2.19189587e-03
  1.71995698e-02 -1.17168098e-02 -1.35811023e+00  4.85691685e-02
  7.61594383e-03 -8.90965550e-02  6.10126842e-01 -4.66413232e-01
 -1.43818897e+00  3.21160229e+00  3.06295466e-01  2.50577255e+00
  3.28251382e+00]
supnorm grad right now is: 4.5890969179482575
Weights right now are: 
[ -8.25524094  16.53946465 -36.53327525 -32.89149941   8.50980965
 -16.64815634  36.93221252  32.17547103  12.11515749  -3.71919462
 -16.36909735   7.28599899  43.15797631  39.77792706  54.95851177
   2.53572905  28.58202848  31.28273174  38.88715413  14.62130201
  21.19142651  86.65785581  37.70961703  16.50445814  20.3445653
 -13.48647472  -7.03757988   7.3686493    2.67604527   5.16035447
   2.1019918    6.2421356   25.29436075  -8.67412651  17.75777593
 -24.66830576  -0.73987749 -10.20860266  -6.49319469   1.72612035
   1.50127577   0.33161057  -6.65859316   3.22731421  -7.46580588
   4.93682637   1.177328     7.78452947  39.90846405  51.74418405
  12.792057   -21.72191749   1.65867286  64.55164902  -4.54619182
  23.35537505  39.81194124  -2.06749098   0.88257419  -3.4968678
   5.91140921   1.01823671   6.45498915  -2.35384248  30.0971049 ]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1726.648420455956
gradient value of function right now is: [ 3.09908628e-02 -7.49045407e-03  2.00539243e-07 -6.81099881e-08
 -3.09908628e-02  7.49045407e-03 -2.00539243e-07  6.81099881e-08
 -3.86039495e-02  1.28941741e-01 -3.81273553e-02  3.18659649e-01
 -5.73833522e-03 -1.30583697e-02  3.92422616e-03  1.32029483e-01
  1.37285648e-07  4.24439593e-06 -3.22868794e-07  4.58820046e-06
  1.04826015e-08  1.94059107e-08 -4.26570655e-08 -4.03087266e-06
  1.32398781e-01  1.10284154e-01  5.08616746e-02  4.83047932e-02
  4.39791682e-01  1.62946478e-01  8.21175340e-03  2.69951988e-02
 -2.25550134e-01 -8.87488470e-02 -1.91594993e-02 -1.94995449e-01
 -4.42492652e-01 -4.07326487e-02 -6.31487921e-05 -8.76519287e-02
  2.19419459e-02 -1.11913815e-01  1.29629664e-01  2.33627675e-01
  3.52637094e-03 -1.54646956e-01 -3.24318442e-01 -1.90217343e-02
 -1.84909281e-06  4.35154043e-03  2.55511397e-02  1.73680582e-04
  1.13544289e-02 -8.81019362e-03 -2.50412443e-01 -2.07649219e-04
 -6.56529538e-04 -3.50423806e-02  4.01014605e-01 -3.37861071e-01
 -2.13092302e-01  7.36188416e-01  1.84020422e-01 -2.75615339e-02
 -2.08865587e+00]
supnorm grad right now is: 2.0886558725319873
Weights right now are: 
[ -8.5840747   16.52856555 -36.64591062 -32.91059403   8.83864341
 -16.63725724  37.04484789  32.19456565  11.87037084  -3.8222807
 -16.89530848   7.0124205   43.2153814   40.693395    54.76198254
   2.66769884  28.63582951  29.62691431  39.14212162  14.06553522
  21.19325828  86.62771155  37.74166332  16.33980082  20.59404328
 -13.46397905  -7.78401558   7.35242109   2.9167272    5.25115004
   1.67151264   6.29641278  25.33126376  -8.37060876  18.06816277
 -24.32787085  -0.49401598 -11.35350767  -6.09200073   1.6059objective value function right now is: -1725.778867357896
gradient value of function right now is: [-1.54684063e-04 -3.48828848e-01 -3.31466540e-01 -4.30818313e-03
  1.54684063e-04  3.48828848e-01  3.31466540e-01  4.30818313e-03
 -2.23012264e-03 -3.86676214e-03 -2.28172699e-06 -3.86683098e-03
 -4.99399744e-04  4.47055449e-01 -4.01464261e-0194.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1726.6363889956863
gradient value of function right now is: [ 3.77795840e-02 -1.10879402e-02  3.15149878e-07 -1.30088945e-07
 -3.77795840e-02  1.10879402e-02 -3.15149878e-07  1.30088945e-07
 -4.53614259e-02  1.83486583e-01 -5.70986019e-02  3.64077890e-01
 -5.17847457e-03 -1.31097756e-02  6.05154829e-03  2.30448853e-01
  2.21193662e-07  9.30454654e-06 -7.75634376e-07  3.78195298e-06
  1.34558558e-08  2.66558310e-08 -9.28984956e-08 -7.63998150e-06
  1.18025574e-01  9.88123657e-02  4.33236038e-02  4.21228266e-02
  4.84798822e-01  1.69347155e-01  8.60752516e-03  2.75009372e-02
 -4.80010383e-01 -1.66128772e-01 -2.51691334e-02 -4.09874032e-01
 -5.41937966e-01 -3.76217845e-02 -4.28325535e-05 -8.47147353e-02
  1.87292500e-02 -1.46868654e-01  1.77952261e-01  2.13650537e-01
  2.48708211e-03 -1.30559775e-01 -5.54658810e-01 -2.41763636e-02
 -1.09219460e-06  3.80739978e-03  3.32071816e-02  1.93469510e-04
  7.51767415e-03 -1.72064061e-02 -7.39582544e-01 -1.33037663e-02
 -4.60134565e-04 -3.24362495e-02  4.78701824e-01 -1.08331964e+00
 -3.80547964e-01  1.50909039e+00  2.23699316e-01 -4.70137746e-01
 -2.36616323e+00]
supnorm grad right now is: 2.366163226675535
Weights right now are: 
[ -8.28674767  16.92200635 -36.98681847 -33.02267847   8.54131638
 -17.03069804  37.38575574  32.30665008  11.79339632  -3.88791674
 -16.82098828   7.21276312  44.04808477  41.13411737  54.47978087
   2.47572722  28.79743181  27.45971981  40.32962293  14.60311049
  21.19807127  86.57782449  37.93427306  15.74289957  20.62836669
 -14.16124121  -8.37547146   7.28619503   2.92797853   5.22843836
   1.31080043   6.43976009  25.14586476  -8.00885441  17.89777157
 -24.13074229  -1.1344989  -10.89477996  -5.05388519   1.40644651
   0.71917858   0.59474685  -6.69045244   3.27155869  -6.79508547
   5.33630113   1.93481123   7.00910094  42.16860917  52.25982043
  12.13447538 -23.74671787  -0.19568041  64.90514037  -4.3462objective value function right now is: -1725.8725111402528
gradient value of function right now is: [-1.12039638e-04 -2.89252090e-01 -3.0633482996.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1726.6535796533994
gradient value of function right now is: [ 3.16784994e-02 -8.88622634e-03  4.68530576e-07 -1.28455550e-07
 -3.16784994e-02  8.88622634e-03 -4.68530576e-07  1.28455550e-07
 -5.12293099e-02  1.48693177e-01 -6.45187384e-02  3.09801043e-01
 -5.28556364e-03 -1.40432678e-02  5.78759549e-03  1.69200494e-01
  1.84244768e-07  8.54791989e-06 -5.20323817e-07  1.57261386e-05
  1.50219465e-08  3.15604657e-08 -8.68503612e-08 -7.58678520e-06
  1.28643620e-01  1.00515568e-01  4.25611744e-02  4.16807914e-02
  4.99709498e-01  1.81452034e-01  9.52550069e-03  2.98171366e-02
 -5.04465569e-01 -1.88121704e-01 -3.29993208e-02 -4.26435719e-01
 -5.10946624e-01 -3.31306006e-02  7.48913844e-05 -7.93490789e-02
  1.80674609e-02 -1.21346742e-01  2.32886657e-01  2.30244557e-01
  2.49958616e-03 -1.25023914e-01 -5.24735568e-01 -2.12309820e-02
 -1.47016579e-06  4.24313876e-03  5.13010734e-02  2.73170342e-04
  7.09131357e-03 -1.64369456e-02 -7.22839220e-01 -1.05905911e-02
 -1.98155492e-04 -3.60009332e-02  5.00655686e-01 -1.00029879e+00
 -4.22607883e-01  1.53165869e+00  1.97824974e-01 -4.25032624e-01
 -2.30292400e+00]
supnorm grad right now is: 2.3029240016468386
Weights right now are: 
[-8.30969535e+00  1.68208911e+01 -3.67473340e+01 -3.30388529e+01
  8.56426406e+00 -1.69295827e+01  3.71462713e+01  3.23228245e+01
  1.18205541e+01 -3.54025463e+00 -1.80287004e+01  7.08331933e+00
  4.40272343e+01  4.20238712e+01  5.33193769e+01  2.62473857e+00
  2.87927365e+01  2.83323384e+01  4.06229819e+01  1.58751469e+01
  2.12030021e+01  8.65425225e+01  3.80072742e+01  1.61210172e+01
  2.03958155e+01 -1.38571393e+01 -7.89672504e+00  8.02476931e+00
  2.98670581e+00  4.89934133e+00 -1.52232254e-02  6.32427326e+00
  2.47198014e+01 -8.07112228e+00  1.81668429e+01 -2.44166883e+01
 -1.30307850e+00 -1.09954758e+01 -4.23820087e+00  1.99009438e+00
  4.31476721e-01  4.92671760e-01 -6.34268766e+00  3.20177470e+00
 -5.56386674e+00  5.74030642e+00  1.54235848e+00  6.99321349e+00
  4.36977391e+01  5.53632862e+01  1.26005911e+01 -2.42281340e+01
  9.82372573e-01  98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1725.8501593636695
gradient value of function right now is: [-1.19499220e-04 -3.23202503e-01 -3.7783072598.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1726.6544974049266
gradient value of function right now is: [ 2.87824156e-02 -9.39134118e-03  7.03886169e-07 -1.32134415e-07
 -2.87824156e-02  9.39134118e-03 -7.03886169e-07  1.32134415e-07
 -5.58797407e-02  1.26939507e-01 -6.35553866e-02  2.90472779e-01
 -5.11429217e-03 -1.21651749e-02  5.94924924e-03  1.89343012e-01
  2.14812377e-07  1.09635368e-05 -6.13672768e-07  2.58291531e-05
  1.58363724e-08  3.40276607e-08 -9.23558891e-08 -7.81694732e-06
  1.28167902e-01  9.84257944e-02  4.40297333e-02  4.40084898e-02
  4.43845476e-01  1.60613001e-01  1.01905413e-02  3.24419374e-02
 -4.72047276e-01 -1.60692642e-01 -2.74506543e-02 -3.94771499e-01
 -4.86377030e-01 -3.28864594e-02 -2.65921724e-05 -7.77314120e-02
  1.68960029e-02 -5.14209109e-02  1.68348387e-01  2.49696264e-01
  2.79256162e-03 -1.12939726e-01 -5.02851377e-01 -2.03453950e-02
 -1.39185956e-06  4.10060574e-03  3.65931596e-02  2.45394160e-04
  6.54322676e-03 -1.72121712e-02 -7.01815087e-01 -1.26684982e-02
  1.96399487e-05 -3.64146531e-02  4.64966301e-01 -1.03261546e+00
 -3.87130317e-01  1.48638552e+00  1.80562859e-01 -5.11784273e-01
 -2.12130337e+00]
supnorm grad right now is: 2.1213033672420183
Weights right now are: 
[ -8.23889856  16.99444617 -38.51859974 -33.0892297    8.49346727
 -17.10313786  38.91753701  32.37320132  12.05562829  -3.49106612
 -16.66173705   7.06880955  44.87492774  42.55310743  54.88179444
   2.53869305  28.72674321  24.10108987  41.03999959  12.05334274
  21.20647472  86.43243946  38.03966536  15.66323351  20.06885941
 -14.49164286  -8.0065917    8.34869876   2.85053244   5.09714907
  -0.87887319   5.26796172  24.80414646  -7.54372161  17.95864006
 -24.00150375  -0.78421044 -10.87050983  -5.12354418   1.28198501
   1.0608618    0.43958679  -7.14561196   3.25729325  -5.38607768
   5.27107608   1.75494331   6.26326034  45.88596165  57.14890674
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1725.8514761734232
gradient value of function right now is: [-1.23881901e-04 -3.43323335e-01 -3.93586320e-0100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1726.6639567235377
gradient value of function right now is: [ 2.94506485e-02 -8.85667854e-03  1.27225948e-06 -1.34886380e-07
 -2.94506485e-02  8.85667854e-03 -1.27225948e-06  1.34886380e-07
 -5.17323774e-02  1.31166223e-01 -6.20615333e-02  2.91840878e-01
 -5.22536625e-03 -1.29449536e-02  6.68393445e-03  1.75240194e-01
  3.29863186e-07  1.74699341e-05 -9.43810199e-07  5.20712342e-05
  1.64977768e-08  3.86587708e-08 -1.01048242e-07 -8.00148657e-06
  1.31119513e-01  1.01261949e-01  4.65982048e-02  4.77346449e-02
  4.71266689e-01  1.64188927e-01  1.13805030e-02  3.42160925e-02
 -5.36308678e-01 -1.81598111e-01 -2.87523409e-02 -4.48074806e-01
 -4.93740796e-01 -3.31678300e-02  2.58436182e-05 -7.87835851e-02
  1.33677630e-02 -8.04520794e-02  1.94521569e-01  2.30378624e-01
  2.49818667e-03 -1.23626487e-01 -5.53269007e-01 -2.34104521e-02
 -1.28001922e-06  4.31442044e-03  4.43521661e-02  3.07726990e-04
  6.45897296e-03 -1.96575827e-02 -8.34308871e-01 -1.59867174e-02
  1.40633603e-04 -3.24033928e-02  5.15102185e-01 -1.21929037e+00
 -4.51649276e-01  1.72679735e+00  2.03600637e-01 -5.95199093e-01
 -2.17873182e+00]
supnorm grad right now is: 2.178731819826525
Weights right now are: 
[ -8.44808462  17.04602596 -40.06241434 -33.13835395   8.70265333
 -17.15471765  40.46135161  32.42232556  11.61928146  -3.46266985
 -17.55484234   7.08557635  44.49852332  43.70113217  55.17286605
   2.55555804  28.7640578   21.37028175  42.23942916  11.49861682
  21.21178826  86.34587444  38.08093567  15.47651971  20.24455534
 -13.93011018  -7.59949888   8.62381173   2.90055067   5.16660636
  -1.99501411   6.81710134  24.45946373  -7.63300827  17.93881688
 -24.14082947  -0.77148568 -11.61713944  -5.02860574   1.56196985
   0.74218415   0.58962622  -6.3992963    3.20638684  -4.95649069
   5.11045134   1.61623112   6.6322386   48.98368541  59.46233947
  12.13526298 -22.22245949  -1.46121949  64.2618462   -4.22576126
  20.624018    47.13762254  -1.19273234   0.66131111  -3.49405195
   5.93149203   1.12242465   6.01080448  -2.24894017  30.00321628]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1268.8912543543454
W_T_median: 1108.1743837672266
W_T_pctile_5: 898.5644332923619
W_T_CVAR_5_pct: 838.4566459436147
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.7
F value: -1726.6639567235377
-----------------------------------------------
