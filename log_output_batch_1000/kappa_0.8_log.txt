Starting at: 
2022-06-17 22:26:16
tracing parameter entered from terminal:  0.8


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient2.0% of gradient descent iterations doneobjective value function right now is: -1825.2585717489876
gradient value of function right now is: [ 3.80828483e+00  2.92133611e+00  2.29131135e+00  2.36640328e+00
 -3.80828483e+00 -2.92133611e+00 -2.29131135e+00 -2.36640328e+00
  2.24767900e+00  8.79417804e-01  3.96315217e-01  2.29003750e+00
 -7.48985320e-01 -1.72902793e-01 -4.83341313e-02 -7.52494479e-01
 -2.70839873e-01 -3.36057497e-02 -6.65498485e-03 -2.75474783e-01
 -3.17419253e-01 -4.36741810e-02 -9.49972144e-03 -3.22245418e-01
  6.74450550e-01  7.15591713e-01  2.19875418e-01  7.54804810e-01
  2.23827770e-01  7.74914586e-02  1.12625820e-01  8.97617396e-02
  8.28452011e-01  2.26708222e-02  3.71909596e-01  5.62004946e-02
  3.85652336e-01  5.13842128e-01  8.85636079e-02  5.39705705e-01
  3.71253625e-02 -1.87675536e+00  4.25695895e-02 -6.40416302e-01
 -6.01083206e-01 -3.47634762e-01 -7.19917812e-01 -1.82738152e-01
  2.21680666e-02 -8.74174856e-01  3.12331864e-02 -2.89095434e-01
 -5.05509448e-01 -3.40482504e-01 -6.04018363e-01 -1.65044950e-01
 -3.72306636e-01  5.17273368e-01  2.19972172e+00 -4.55290997e-01
 -8.86070889e-01  1.34051931e+00  2.05306669e+00  1.65340445e+00
 -8.17140691e+00]
supnorm grad right now is: 8.171406906375047
Weights right now are: 
[-2.09445761  1.67621796  1.41396082  0.95850488  2.34902632 -1.78490965
 -1.01502355 -1.67453326  2.32981869  0.2838973  -8.71755001  2.20583516
  2.02329399  3.31718629  8.78072394  1.537917    4.76719924  2.78615239
  3.65214578  3.26322922  3.75322523  2.67633277  4.34687024  3.61775023
  0.06339076  2.71683287 -0.73332263  2.14097524  2.02765872  3.13264154
  3.54801146  2.40445212  5.09941355  5.35498119  4.32019313  5.01923083
 -0.57769873  2.74153599  0.16561565  2.4988597  -2.48323982  0.36783811
 -1.07592466  3.13591543 -1.28042495  7.04549922 -3.28477328  7.60009308
  0.15155658  2.5019353   0.95456832  2.18540699 -1.26476774  5.30087948
 -2.65327545  6.40905805  4.86138809  2.48323797  1.68062388 -1.16536322
  5.02855321  3.0941782   4.00999366 -0.77560823 29.47973818]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1826.837822753341
gradient value of function right now is: [ 2.76043668e-01  8.58296600e-01  1.25641485e+00  1.18651003e+00
 -2.76043668e-01 -8.58296600e-01 -1.25641485e+00 -1.18651003e+00
 -2.23529839e+00 -1.09942460e+00 -7.12810037e-01 -2.35087163e+00
  3.09728773e-01 -1.04894648e-02 -5.01950670e-03  2.21816254e-01
  7.98715405e-02  3.83128660e-04  2.24487271e-04  6.69784927e-02
  1.32366402e-01  6.32466407e-04  3.93568983e-04  1.11106059e-01
  8.14090827e-01 -5.08448392e-02 -2.39665967e-02 -7.49901466e-02
 -8.62282460e-02  2.66603890e-04  2.11005060e-02  6.17041958e-03
 -1.46713359e+00  2.27776875e-03 -1.73575192e-02  1.28945895e-02
  6.34881851e-01 -8.06734794e-02 -5.57483632e-02 -1.10558677e-01
  3.52074800e-01  4.24347851e+00  2.09532501e-01  1.99742123e+00
  8.48568712e-02  5.89079040e-02  2.52251495e-01  3.54602273e-02
  1.97678730e-02  2.79957221e-01 -6.52499976e-02  1.07677495e-01
  2.96948244e-02 -2.16913132e-02  8.51580424e-02  8.07891721e-03
  2.56131054e-01  2.77969260e-01 -2.71583368e-01  3.19696881e-01
  4.85154537e-01 -4.94217184e-01 -2.03249131e+00 -3.13730344e+00
  4.39872532e+00]
supnorm grad right now is: 4.398725318865374
Weights right now are: 
[-3.04530895  2.11926742  1.51653306  1.06857947  3.29987766 -2.22795911
 -1.11759579 -1.78460786  3.35656445 -0.60225056 -9.55718783  2.88154187
  1.73498526  7.09703544 17.56968183  1.55641186  5.67704991  5.92201967
 10.92950572  4.85506005  4.09076618  5.84287549 12.26223693  4.54725879
  0.56432799  5.3145377  -3.82799555  1.32410738  3.06832194  7.87430782
  6.39469714  7.77302477  5.21641188 10.44427258  3.85853566  9.64840482
 -0.16829225  5.90566535 -2.65397254  1.77192538 -2.44653437  0.10357698
 -1.33778521  3.07085877 -1.83104454 14.07824335 -4.13184747 14.18406288
  0.32895864  3.77114599 -0.43498297  5.49783432 -1.03467999  8.60901264
 -3.34472592 10.65932697  5.76961952  1.35753047  0.92951622 -1.92318499
  5.20759733  2.83326727  3.4312548  -1.07181345 29.21405039]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.555557532491
gradient value of function right now is: [ 9.62304328e-01  7.00387995e-01  4.72732289e-01  6.41051931e-01
 -9.62304328e-01 -7.00387995e-01 -4.72732289e-01 -6.41051931e-01
 -1.54266940e-01 -6.01182756e-01 -1.05876594e-01 -2.31709216e+00
 -8.77016128e-02  8.22443431e-02  6.49389814e-03  1.48775062e+00
 -2.69733741e-01  1.32633926e-03  1.13142860e-04 -3.70383798e-01
 -3.18270034e-01  3.94725466e-03  3.36156056e-04 -3.72939003e-01
  4.45215656e+00  6.49458715e+00  2.79307662e+00  3.82897172e+00
 -7.20503641e-01 -1.60707729e-02 -2.99101790e-02 -9.74329501e-03
 -4.21067455e-01 -2.18412762e-03 -1.00189293e-02 -2.34617710e-03
  2.41089075e+00  9.52203203e-01  3.70915522e-01  3.96770481e-01
 -8.14141072e-02  2.07264493e+00  2.51268187e-01  8.24087337e-01
 -4.92611210e-01  9.08299380e-02 -2.28557727e-01 -1.94975208e-02
  6.95340152e+00  6.18891857e-01  1.25770189e+01  7.28091272e-01
  1.60822513e+00  1.81807986e-01  2.81605417e+00  1.84012370e-01
  2.61971983e+00 -1.15305581e+01 -2.63634750e+00  1.32351076e+01
  1.71457909e+00 -8.33969320e-01 -3.71439623e+00  1.43480974e+01
  6.81386285e+00]
supnorm grad right now is: 14.34809741190809
Weights right now are: 
[-3.54484389  2.56637132  3.0289899   2.25696474  3.79941261 -2.67506301
 -2.63005263 -2.97299312 -2.00847949  0.20749067 -5.53769367  4.1850772
  3.25757555 13.42515717 28.6826942   1.45292171  7.44213252 10.27464889
 19.61893146  6.26828983  5.77468835 10.8749971  21.82040619  5.1438197
  2.1491911   4.42084291 -8.21141892 -1.82492004  2.85955954 16.52407678
 11.24542664 14.72102147  7.15132524 18.20731324  5.49568306 12.65660197
 -1.99034234  4.44591167  0.19402814 -1.60651777 -0.08514323 -0.34319689
 -4.3001244   2.88990754 -4.36991618 17.14945469 -4.18241039 20.12478199
 -3.06703003  9.27895105  0.60659632 12.57511024 -0.73317293 15.39631551
 -1.83790899 15.94069547  7.25897007  1.59064653  0.73752175 -1.71708988
  3.42947944  2.82287027  2.75848627 -1.39587753 29.3456044 ]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1847.2991889682826
gradient value of function right now is: [-1.72069339e+00 -1.84794377e+00 -5.44723821e-01 -8.50370350e-01
  1.72069339e+00  1.84794377e+00  5.44723821e-01  8.50370350e-01
 -1.13098820e+00  7.86176633e-02 -9.42785459e-02 -2.37702732e+00
  6.15160087e-01 -4.28601320e-02 -3.79142231e-04  2.57447921e+00
  1.55415352e-01 -1.30552936e-03 -1.17049581e-05  1.02470640e+00
  2.37561394e-01 -4.42801245e-03 -4.37558282e-05  1.32615088e+00
 -9.17900121e+00 -1.05153430e+01 -4.56637023e+00 -4.14944396e+00
  4.07019150e-01  1.37976495e-03  3.98556195e-03  1.40352998e-03
 -6.43331980e-02  3.64774076e-05  1.38983997e-04  2.66296108e-05
 -1.50368519e+00 -2.41231555e-01  3.76457423e-01  1.07336044e+00
  1.94335840e-01 -1.98685464e-01 -6.29156355e-02  4.66255336e-01
  1.41299114e+00  1.19855006e-01  1.66035546e+00  1.51748790e-01
 -1.44621747e+01 -1.32312131e+00 -2.07066714e+01 -1.19922361e+00
 -3.86976417e+00 -4.05863753e-01 -5.22583776e+00 -3.63524984e-01
 -4.09891697e+00  2.22466482e+01  3.85962171e+00 -2.97943985e+01
 -1.29170660e+00 -4.71887853e-02  3.59207488e+00 -2.84701618e+01
 -1.89606468e+00]
supnorm grad right now is: 29.794398471701363
Weights right now are: 
[-4.1737334   3.2784782   3.66414501  2.63268889  4.42830211 -3.38716989
 -3.26520774 -3.34871727 -3.79657283  0.51781246 -5.21532306  4.1856373
  4.26872971 18.33562162 38.15044273  2.03310186 12.24719599 12.89288763
 28.26630384  5.4823124   7.67333062 14.41286467 31.93738281  4.55700986
  2.68637014  4.195858   -8.43976597 -2.82439544  3.64561498 29.58558197
 17.84801566 18.06981016 12.63000611 23.69924413  9.2914131  16.01952917
 -2.26096431  3.65882627  0.42246292 -2.57209103  0.60468257  0.15428197
 -5.24864504  3.26973962 -2.7039203  19.18481961 -4.70666284 22.18945606
 -3.52492374 13.29054834  0.96400338 14.90859611 -0.55758746 19.60428441
 -1.57881122 19.65368823  7.09171941  1.70226401  0.3730516  -1.83272178
  4.17730066  2.62146104  2.5179099  -1.68069459 29.31225731]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.0305933063753
gradient value of function right now is: [-3.86908525e-01  6.96983069e-01  2.98954073e-01  2.90937200e-01
  3.86908525e-01 -6.96983069e-01 -2.98954073e-01 -2.90937200e-01
 -1.51659581e+00 -1.60658963e+00 -7.54013088e-02 -2.67316600e+00
 -1.07728833e-01  3.48786312e-02  6.05304321e-06 -2.30581872e+00
 -5.53188383e-02  5.35091237e-03  7.08127956e-07 -1.43581275e+00
 -4.27740044e-02  6.72987209e-03  1.51189263e-06 -1.06238760e+00
  1.78053707e+00  4.81632392e+00  1.71250347e+00  2.23132856e+00
  2.28516953e-01 -3.04559035e-03 -2.78481915e-03 -6.53081936e-04
 -6.42179358e-02 -6.06698982e-08 -2.20962439e-07 -2.52393032e-08
  4.90676766e+00  2.28887567e+00  3.92703050e-01  3.02598250e-01
  7.75894942e-02  4.50422282e+00  4.29911101e-01  2.30878140e+00
 -1.37676956e+00 -2.23821649e-01 -2.19848372e+00 -2.28168545e-01
  5.90273271e+00  4.98688215e-01  9.19244342e+00  5.77163605e-01
  2.90185596e+00  3.10505266e-01  4.50253115e+00  3.26958142e-01
  2.57290595e+00 -1.35903363e+01 -2.33810539e+00  1.49213676e+01
  7.66417222e-01  2.09273852e+00 -4.34444726e+00  1.43950332e+01
  8.01619726e+00]
supnorm grad right now is: 14.921367591104005
Weights right now are: 
[-4.92241079  3.82632897  5.17438265  3.42251119  5.1769795  -3.93502066
 -4.77544538 -4.13853957 -4.64763761  2.33199069 -5.99404054  4.34026092
  7.25801723 22.19889617 43.98944835  2.19552722 17.33102064 16.0235359
 29.87136489  3.600949   11.44654713 17.8122853  35.47705614  3.89540856
  3.16433236  4.18152812 -8.92361505 -3.54702188  4.55804009 42.18307799
 25.95420562 22.86777968 24.77423443 24.52561008 10.20089735 16.52143883
 -2.4268527   3.71066833 -0.8518388  -4.38505415  2.54780154  0.2429914
 -5.20573971  3.14181759 -2.61535008 21.2520489  -4.8278883  23.19564188
 -4.12262645 16.16221458  1.32973414 17.04387122 -1.57798522 23.55490856
 -1.59902646 23.7486327   7.78805913  1.70015663  0.55603415 -1.88030638
  3.91349048  2.42731828  2.67577412 -1.50619387 29.31122049]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1850.449569251529
gradient value of function right now is: [-1.52571997e+00  4.04854905e-01  4.00745227e-01  2.67288162e-01
  1.52571997e+00 -4.04854905e-01 -4.00745227e-01 -2.67288162e-01
 -5.25768742e+00 -4.77294192e+00 -2.40285105e-01 -1.16447846e+01
  9.17232770e-02  4.81122303e-02  1.97745916e-07 -3.54136573e-02
 -6.08571766e-03  1.58261949e-02  1.49930426e-08 -1.24281998e+00
 -6.55586583e-03  7.01757015e-03  4.29304184e-08 -6.38147461e-01
 -2.47046779e+00  7.19082742e+00  2.16555363e+00  3.18668812e+00
  1.12651843e+00 -7.03862541e-03 -3.71175612e-03 -1.06170954e-03
 -1.26250148e-01 -2.08423651e-09 -1.75616502e-08 -6.59752582e-10
  7.94321768e+00  3.72261703e+00  7.74576112e-01  8.35613038e-01
  4.79973648e-01  9.13618875e+00  2.00927665e+00  5.77943969e+00
 -1.32866817e+00  1.31152052e-01 -1.06663167e+00  9.95516203e-03
  8.88589703e+00  7.01872592e-01  1.46724467e+01  6.81090342e-01
  5.64169246e+00  5.81551793e-01  9.86907399e+00  5.00560835e-01
  6.01458581e+00 -3.01341527e+01 -8.66874835e+00  4.08950923e+01
  6.62121968e+00 -3.67992634e+00 -1.30104524e+01  2.98474980e+01
  3.37136531e+01]
supnorm grad right now is: 40.895092251674285
Weights right now are: 
[-5.82203556  3.961713    5.18954289  2.70840862  6.07660427 -4.07040469
 -4.79060562 -3.424437   -4.81485047  3.0049467  -7.23791451  4.40647776
  9.68356432 26.2253431  44.21447385  2.40604913 20.77473968 22.64857062
 29.90125689  2.88277353 13.67216276 22.31088739 35.52692676  4.09312553
  3.32203792  4.22972039 -9.54411575 -4.3743542   4.50987008 53.46713612
 37.69761283 30.264857   35.4826127  24.52741962 10.20459029 16.52198518
 -2.86919897  4.23394807 -1.1635075  -5.63223459  1.64418265  0.63761305
 -5.36222245  3.58674574 -3.14799246 24.17464801 -4.40304231 24.81060071
 -4.60815288 18.54991697  1.62962739 18.88836403 -2.33699258 27.07800086
 -1.1372547  27.43628049  7.50568989  1.56521131  0.81576784 -1.76119388
  4.12949541  2.48224422  2.16405608 -1.68615445 29.37414578]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -1850.6407160673734
gradient value of function right now is: [-1.68614571e+00 -1.18828114e+00 -8.34913828e-01 -1.18197903e-01
  1.68614571e+00  1.18828114e+00  8.34913828e-01  1.18197903e-01
 -3.65411419e+00 -3.38121281e+00 -1.23649663e-01 -1.40099317e+01
  3.00057131e-01  5.13912184e-02  1.56543028e-08  6.81623772e+00
  1.73054159e-01  2.19281016e-02  5.42543077e-10  5.54773553e+00
  8.52064574e-03  1.48320397e-03  1.39048300e-09  2.75959943e-01
 -7.40881147e+00  3.37226872e+00  1.33795560e+00  2.41099146e+00
  6.59467185e-01 -6.31821149e-03 -3.76604208e-03 -1.01390171e-03
 -5.32292307e-02 -2.03815672e-11 -1.22763714e-10 -6.77875394e-12
  1.89706353e+00 -1.06211110e+00 -3.86294669e-02 -1.21202545e-01
  5.68239725e-01  7.45698559e+00  2.49778102e+00  4.43253657e+00
  1.17155086e+00  5.53819014e-01  3.75911436e+00  4.58309488e-01
  6.03582578e+00  7.96154168e-02  8.84677690e+00  3.36088821e-01
  3.10418167e+00  2.42661801e-02  3.71242446e+00  1.61256224e-01
  4.45869719e+00 -2.60833067e+01 -3.06168722e+00  2.15957213e+01
  9.08487375e+00 -1.00509088e+01 -8.35738540e+00  2.71252317e+01
  3.04872593e+01]
supnorm grad right now is: 30.48725927820609
Weights right now are: 
[-6.42674954  3.9479509   4.99928946  1.38465436  6.68131825 -4.05664259
 -4.60035219 -2.10068274 -4.78487206  3.45049026 -7.14447422  4.65030345
 10.42010437 29.59320811 44.22377955  2.61932432 22.94897722 28.50122482
 29.90196555  2.66149017 13.90979245 24.40494289 35.52843688  5.85617747
  3.75775621  4.16590722 -9.55004538 -4.62884483  5.09487213 61.14126537
 46.69322308 35.56992632 45.08607514 24.5274251  10.20467783 16.52198568
 -2.59073678  4.43270912 -1.64943209 -7.44992879  2.24386566  0.63152596
 -4.88752421  3.34215736 -3.41447964 26.47206955 -3.69588642 26.10901086
 -4.87045138 20.84966138  1.88913514 20.43401301 -3.08746378 29.35806963
 -0.88050453 30.19869482  7.39553204  1.50241492  0.90944442 -2.02828794
  4.11375432  2.24385356  2.42905754 -1.62190583 29.37734674]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1851.0665484995636
gradient value of function right now is: [-1.16210657e+00  5.93757590e-01  9.27390573e-01  2.19673374e-02
  1.16210657e+00 -5.93757590e-01 -9.27390573e-01 -2.19673374e-02
 -4.38999666e+00 -4.14894593e+00 -1.27043103e-01 -9.07324134e+00
 -1.75786821e-02  1.71393670e-02  3.56630869e-09 -2.78915143e+00
 -7.42602637e-02  5.64780118e-03  4.95468692e-11 -5.60837420e+00
 -7.92623593e-05  4.33203746e-05  1.02646583e-10 -1.82072157e-02
  7.23351390e-01  6.10101896e+00  1.74720511e+00  3.27257388e+00
  1.91503524e+00 -1.75170356e-03 -2.23636634e-03 -5.25117628e-04
 -4.65012368e-02 -1.84959234e-13 -2.47975411e-12 -4.91083537e-14
  7.69450177e+00  2.26948781e+00  4.01555463e-01  5.42808398e-01
 -2.45009396e-01  7.85059199e+00  4.61923046e-01  4.00426809e+00
 -9.81606130e-01 -4.10191738e-02 -1.28804824e+00 -1.08430713e-01
  6.45826305e+00  3.26296985e-01  1.15214920e+01  4.55426865e-01
  5.65154133e+00  3.81451526e-01  1.00622152e+01  4.79310690e-01
  6.16354178e+00 -3.07695418e+01 -5.79354613e+00  2.57672469e+01
  3.79499979e+00 -6.46626911e-01 -9.69722724e+00  2.77422170e+01
  2.22453371e+01]
supnorm grad right now is: 30.76954180019931
Weights right now are: 
[-6.75339568  3.92692175  5.45790894  0.44091052  7.00796439 -4.03561344
 -5.05897167 -1.1569389  -4.92090469  3.602195   -6.28089743  4.77989484
 11.61008309 31.20973494 44.22431641  3.03360728 25.04119967 35.25190509
 29.90198974  2.14008256 14.68097264 22.83405053 35.52847493  9.07509285
  4.05105007  4.04686104 -9.52270833 -5.18298384  5.50369988 65.92278341
 50.28631652 35.32801324 52.48139637 24.52742505 10.20467948 16.52198564
 -2.40350116  4.46269586 -1.64965759 -9.47332547  1.59704069  0.69688896
 -5.10707113  3.31121283 -4.24037349 29.33625755 -3.87046831 26.81541773
 -5.04843726 22.65551027  2.04101483 21.77836541 -3.32653043 31.9120282
 -0.68268182 33.07206102  7.27388801  1.56753336  0.66989459 -2.11152918
  4.31352228  2.82664609  2.48904694 -1.70453475 29.43418909]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1851.0415456027263
gradient value of function right now is: [ 6.46167474e-01  3.45706527e-01  7.87824044e-01  2.65551035e-03
 -6.46167474e-01 -3.45706527e-01 -7.87824044e-01 -2.65551035e-03
  2.18115601e+00  1.65687910e+00  1.42571969e-01  5.24716039e+00
 -4.04909354e-02 -6.36180959e-03 -9.74019237e-10 -1.94695763e+00
 -1.12595663e-01 -1.71311031e-02 -8.13492870e-13 -5.86339463e+00
 -1.50919503e-05 -7.44743394e-07 -8.83511914e-12 -3.04366192e-03
  4.31805417e+00  1.66964118e+00  5.27851094e-01  7.30869581e-01
  1.71585796e-01  1.18770776e-03 -9.26780599e-05 -9.74811709e-06
  2.50169539e-02  7.41344012e-17  1.00500272e-14  6.57220521e-18
  9.94990190e-01  1.06741071e+00  1.50094497e-01  1.33023564e-01
 -7.46743023e-01 -3.37693057e+00 -1.23823066e+00 -2.54280834e+00
 -7.45905431e-01 -1.86083830e-01 -1.55858383e+00 -1.53117575e-01
  1.77709634e+00  1.31434158e-01  3.12915842e+00  1.31926271e-01
  1.53641859e+00  1.36050057e-01  2.75322490e+00  1.30533546e-01
  1.57501193e+00 -7.30287886e+00 -2.67533285e-01  4.88353579e+00
 -1.40012140e+00  2.46458968e+00  8.38809513e-01  7.41525023e+00
 -1.14040131e+01]
supnorm grad right now is: 11.40401312968829
Weights right now are: 
[ -6.70104771   4.12718599   5.83359941   1.07530375   6.95561642
  -4.23587768  -5.43466214  -1.79133214  -4.92802225   3.73112602
  -6.82529822   5.18868564  10.76405411  30.40433122  44.2244819
   3.62662302  25.85030995  41.15982312  29.90199031   2.07632799
  14.01726966  22.39142853  35.52847873  12.91933686   4.30189735
   4.10694487  -9.47295255  -5.7492066    5.46635919  72.36470457
  59.19471651  40.71031173  59.8879362   24.52742505  10.20467968
  16.52198564  -2.82677233   4.68782309  -1.97569646 -10.67016008
   1.05997403   0.5237866   -4.77346216   3.52191388  -4.70198357
  31.48322547  -4.00289164  27.54054745  -5.21008992  23.9944039
   2.02269998  22.41738772  -3.83705612  33.88490338  -0.22530436
  34.87835103   6.93803161   1.49625886   0.81665916  -2.04104067
   4.09037853   2.69526492   2.69162404  -1.71547148  29.24483777]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.1660930926628
gradient value of function right now is: [ 2.76001529e-02 -2.50313784e-01 -6.58826255e-01 -1.26539627e-03
 -2.76001529e-02  2.50313784e-01  6.58826255e-01  1.26539627e-03
  4.04084057e-01  7.33399211e-01 -2.07316980e-02  1.58322005e-01
  2.07777726e-02 -1.62325555e-03 -5.63683028e-10  1.24678327e+00
  7.56845635e-02  2.13656430e-03 -3.38452865e-14  4.30425903e+00
  2.18369453e-05 -3.67470995e-07 -1.78918096e-12  1.86258682e-03
 -2.43133908e+00 -3.22991252e+00 -1.02679392e+00 -1.29875143e+00
 -6.32067802e-01 -3.50501469e-04  1.03480669e-04  5.68219278e-05
 -4.04134864e-03  2.42375625e-16  1.16611432e-14  5.88784154e-17
 -3.00723379e+00 -1.60251122e+00 -3.25751763e-01 -2.82502018e-01
  6.22429054e-01 -9.66567073e-01  5.52692485e-01 -1.15408227e-01
  9.00762342e-01  7.75880794e-02  1.22784930e+00  8.78753325e-02
 -4.22917915e+00 -2.67482523e-01 -6.17129353e+00 -2.76599285e-01
 -4.24274085e+00 -3.19688625e-01 -6.31435781e+00 -3.16405093e-01
 -2.83304594e+00  1.62215645e+01  3.18006293e+00 -2.04083021e+01
 -7.27764356e-01 -6.04749185e-01  3.59613754e+00 -1.93922000e+01
 -3.31876947e+00]
supnorm grad right now is: 20.40830213167438
Weights right now are: 
[ -7.04358201   4.27175008   5.95926092   1.20049734   7.29815073
  -4.38044177  -5.56032365  -1.91652572  -5.10568668   3.8898689
  -7.57965062   5.05977581   8.6977549   29.13394984  44.22460831
   4.28440109  27.13576486  45.85472554  29.90199035   2.28448462
  12.76971283  22.13698163  35.52848484  14.73366134   4.29417284
   3.95134996  -9.26567316  -6.06773434   5.40457261  76.5721088
  63.46247373  41.91261735  65.66462749  24.52742505  10.20467971
  16.52198564  -2.59901722   4.42558817  -0.78345447 -11.46151682
   1.4890416    0.8739319   -4.33678288   3.60019442  -4.48038134
  33.72781599  -3.37341276  28.92892379  -5.18829787  26.01414089
   2.0995211   23.24992102  -3.92283502  35.67623627  -0.11056787
  36.78011719   7.00369714   1.59469598   0.64384198  -2.10367289
   4.12926805   2.75742604   2.48034872  -1.89691243  29.3919455 ]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.574947689674
gradient value of function right now is: [ 3.95071047e-01  7.65184731e-02  3.70973080e-01  1.44802949e-05
 -3.95071047e-01 -7.65184731e-02 -3.70973080e-01 -1.44802949e-05
  8.07105010e-01  8.03435859e-01 -4.36344632e-02  4.09067375e+00
 -1.80771228e-02 -7.77706576e-03 -2.25479722e-10 -6.01164051e-01
 -7.63371360e-02 -1.98900027e-02 -2.41095026e-15 -3.69863063e+00
 -4.88968449e-10 -2.05768078e-09 -4.88031821e-16 -6.33256116e-06
  2.70214904e+00 -6.08412188e-01 -1.70560436e-01 -3.41167335e-01
  1.62076999e-01  2.85667755e-03  1.51789591e-03  4.26649404e-04
 -1.01630221e-02  1.14315239e-16  1.59149562e-14  2.52183397e-17
 -9.72258423e-01 -2.40032362e-01 -8.70269364e-02 -1.00706794e-01
 -3.09377721e-01 -1.42858526e+00 -1.24048164e+00 -4.58070182e-01
 -1.97296042e-01 -1.56178475e-01 -1.14065469e+00 -8.61306103e-02
 -9.77937433e-01 -3.48486968e-02 -1.36991173e+00 -5.12790950e-02
 -1.66741319e+00 -7.49516653e-02 -2.15419624e+00 -1.05512885e-01
 -1.19490543e+00  6.68018928e+00  3.16293246e+00 -1.07097473e+01
 -3.11634432e+00  3.18900157e+00  3.12330459e+00 -9.89561422e+00
 -1.32944374e+01]
supnorm grad right now is: 13.294437366009408
Weights right now are: 
[-7.13609059e+00  4.49388656e+00  6.32020487e+00  2.78470541e-01
  7.39065930e+00 -4.60257825e+00 -5.92126760e+00 -9.94498924e-01
 -5.17917573e+00  3.51848686e+00 -8.16186434e+00  5.23042448e+00
  7.26377228e+00  2.80413319e+01  4.42249242e+01  4.78103997e+00
  2.81033709e+01  5.03168462e+01  2.99019904e+01  2.26766494e+00
  1.30798733e+01  2.21358463e+01  3.55284851e+01  2.13816358e+01
  4.61341718e+00  3.78961899e+00 -9.03413842e+00 -6.85664759e+00
  4.87670526e+00  8.24141640e+01  7.28538913e+01  4.77740697e+01
  7.14955156e+01  2.45274251e+01  1.02046797e+01  1.65219856e+01
 -2.57075290e+00  4.64464423e+00 -1.25173626e+00 -1.17292792e+01
  4.84835189e-01  1.12167949e+00 -4.48504435e+00  3.82461312e+00
 -4.83950527e+00  3.60878700e+01 -3.28362546e+00  3.01645636e+01
 -5.03580437e+00  2.72433613e+01  2.31158783e+00  2.38247072e+01
 -4.31054344e+00  3.76290537e+01  5.14646275e-02  3.84178046e+01
  7.00117567e+00  1.55972423e+00  7.74255678e-01 -2.04540910e+00
  3.90100299e+00  2.94290575e+00  2.36891574e+00 -1.81227047e+00
  2.91854307e+01]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1848.9052422965626
gradient value of function right now is: [-1.55879519e+00 -3.81234683e-01 -1.23659521e+00 -4.71929295e-04
  1.55879519e+00  3.81234683e-01  1.23659521e+00  4.71929295e-04
 -4.32495161e+00 -4.17981625e+00 -1.64558479e-01 -1.14149624e+01
  2.75158202e-02  9.84145675e-03  1.89774465e-08  1.34227091e+00
  1.14102342e-01  1.99271779e-02  8.11919661e-16  7.00641598e+00
  2.10112721e-06  1.98626324e-10  2.53143547e-15  2.15862352e-04
 -4.56433628e+00  1.18191623e+00  3.52394571e-01  1.06122132e+00
  6.51803187e-01 -2.54316041e-03 -9.68240953e-04 -1.80389684e-04
 -4.03976084e-02 -1.13570870e-17 -8.04424807e-15 -1.19440619e-18
  1.43009462e+00 -8.98026814e-01 -6.84334055e-02 -3.83530856e-02
  9.30250700e-01  6.42278117e+00  2.13390611e+00  4.17408273e+00
  7.77612073e-01  2.16706830e-01  2.07211404e+00  1.71329979e-01
  6.52543965e-01 -2.22640857e-03  2.18548296e+00 -7.22701495e-03
  5.95585941e-01 -2.39269217e-02  2.33554740e+00 -2.72777816e-02
  2.98358322e+00 -1.28226011e+01 -4.15708953e+00  7.56122428e+00
  2.45641335e+00 -2.18712634e+00 -5.70033133e+00  1.76817423e+00
  2.68842409e+01]
supnorm grad right now is: 26.884240943209022
Weights right now are: 
[ -7.27057744   4.20533198   6.31634996   0.41659236   7.52514615
  -4.31402367  -5.91741269  -1.13262074  -5.19680851   3.72694668
  -7.80006971   5.21812755   5.61256953  24.03862217  44.22675617
   5.59061522  28.49624802  53.83609042  29.90199036   2.3956695
  14.85950764  22.13584034  35.52848512  26.42624704   4.43895458
   3.46100496  -9.05560903  -7.34014072   5.56549628  88.8377113
  80.10091879  50.5630631   79.1625289   24.52742505  10.20467971
  16.52198564  -2.04304605   4.39445283  -2.34605732 -13.83519366
   1.3192984    1.11685614  -4.08978891   3.64936705  -5.53597001
  37.46826382  -2.95445323  29.78977914  -5.4007807   27.75826071
   2.51947664  23.19864888  -4.49416228  39.37339765   0.12016905
  39.86104137   7.39201152   1.35602647   0.78941624  -2.16813028
   4.0059294    3.07860894   2.42349898  -1.94370544  29.45595654]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.0931832060724
gradient value of function right now is: [-3.24496620e-01  7.00584888e-02  6.51629997e-01  2.07931199e-06
  3.24496620e-01 -7.00584888e-02 -6.51629997e-01 -2.07931199e-06
 -8.95568435e-01 -1.35327481e+00  7.39346097e-03 -2.78937782e+00
  8.46680726e-03  8.28002768e-03  1.24740314e-09 -3.35696914e-01
 -5.70541900e-02  5.17182024e-03  3.64430847e-17 -4.96553194e+00
 -1.76328755e-12 -1.03258324e-14 -1.48220119e-20  7.35236475e-10
  1.54784613e+00  4.06158665e+00  6.25943755e-01  1.93396856e+00
  8.22061925e-01 -1.27250778e-03 -1.52454350e-03 -2.41542354e-04
 -3.75001245e-03 -1.35824719e-20 -2.98700725e-17 -2.37898989e-21
  4.35755615e+00  1.54202070e+00  1.39412058e-01  3.33288549e-01
 -2.71558523e-01  2.40821190e+00  2.56303211e-01  8.44988163e-01
 -6.55501083e-01 -3.54606280e-02 -1.17484026e+00 -5.24406399e-02
  2.40822115e+00  1.23183287e-01  4.47335151e+00  1.24418807e-01
  4.77024079e+00  3.11973766e-01  9.88270330e+00  2.97321824e-01
  4.71420630e+00 -2.20739956e+01 -5.05157328e+00  2.01207073e+01
  1.76085616e+00  2.31517066e-01 -4.94510344e+00  1.72559713e+01
  1.10891306e+01]
supnorm grad right now is: 22.073995556735245
Weights right now are: 
[ -7.20036453   4.48321484   6.71526891  -0.34704763   7.45493324
  -4.59190653  -6.31633164  -0.36898075  -4.77023314   3.89171854
  -8.78268575   5.22753791   6.32386112  22.02962107  44.23292718
   5.81509145  29.05166371  56.77595027  29.90199036   2.09258064
  15.01546589  22.13584091  35.52848512  29.62758298   4.25740976
   3.48508955  -8.68730955  -7.71967215   5.32501965  92.80830865
  85.02040826  50.36615444  85.47181363  24.52742505  10.20467971
  16.52198564  -2.17534423   4.66122436  -1.69996347 -13.98977493
   0.55165764   0.87444309  -4.80670864   3.34805532  -5.47885708
  39.43745015  -2.89908604  30.20274388  -5.13644067  27.71283541
   3.06344868  22.78839017  -4.86885049  41.12085462   0.35556449
  41.13832845   6.98451848   1.43817227   0.75430304  -2.18780884
   3.8796663    2.84532228   2.62745402  -1.91927747  29.38572991]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -1850.9181273986742
gradient value of function right now is: [ 5.70147652e-01 -1.00742906e-01 -1.01132691e+00 -4.19226248e-06
 -5.70147652e-01  1.00742906e-01  1.01132691e+00  4.19226248e-06
  3.45174724e+00  3.01266272e+00  2.75417526e-01  4.03674286e+00
 -2.16038290e-04 -2.57510434e-03 -1.46978271e-07  6.02134813e-01
  7.52177727e-02 -1.13007158e-03 -1.35479197e-17  8.81906384e+00
 -9.27481404e-08  6.85790528e-10  5.12297781e-14 -2.92720461e-05
 -7.77511708e-01 -9.31782528e-01  2.26708571e-02 -1.33891067e-01
 -6.78739965e-01 -8.34627718e-04 -4.82103331e-04 -5.28886468e-05
  3.80960574e-02  2.92819714e-22  3.47940851e-17  4.13641781e-23
 -3.90945270e+00 -1.96414363e+00 -1.01148869e-01 -2.14531482e-01
 -4.13816303e-01 -5.48957463e+00 -3.46689824e-01 -4.07740547e+00
  8.67129069e-01  1.38636289e-01  1.87745255e+00  1.24945406e-01
  2.03240926e-01 -1.07497552e-02 -1.28741152e-01  3.61187637e-03
 -1.25149886e+00 -1.71071733e-01 -3.69898272e+00 -1.38687117e-01
 -1.05926540e+00  3.36370906e+00  1.43934095e+00 -2.93689473e+00
  4.85621373e-01 -1.73639177e+00  2.79747714e+00  3.96791728e-01
 -7.37949441e+00]
supnorm grad right now is: 8.819063836273289
Weights right now are: 
[ -7.00619697   4.34740558   6.59809978  -7.31780343   7.26076568
  -4.45609727  -6.19916251   6.60177504  -5.06727794   4.09426478
  -7.31037739   5.41299356   3.17326149  20.82840506  44.24010563
   5.68140125  29.15615465  59.02699425  29.90199036   2.2184373
  14.94386424  22.13587102  35.52848512  23.83637365   4.37870563
   3.44743448  -8.83133365  -8.60117301   5.55383801  94.53021703
  89.709336    47.07497258  89.90864294  24.52742505  10.20467971
  16.52198564  -2.92142662   4.12846728  -2.28345603 -15.61436673
   0.90157854   0.94306317  -4.89344709   3.23853847  -5.75477489
  41.25987115  -3.04067076  30.49252151  -5.19352958  27.44990006
   3.45349984  21.68950714  -4.91030298  43.1661723    0.30501667
  42.92794226   6.49849689   1.45437296   0.62732182  -2.22461083
   4.22205893   2.92387233   3.03731944  -1.70459742  29.20401462]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1846.367638610743
gradient value of function right now is: [-4.66046530e-01 -9.46444096e-02 -8.45829548e-01 -4.57782539e-06
  4.66046530e-01  9.46444096e-02  8.45829548e-01  4.57782539e-06
 -1.94262378e+00 -1.07490566e+00 -8.85723948e-02 -4.38924373e+00
  1.33187545e-02  1.71557527e-03  3.12456989e-08  5.56388494e-01
  1.06335286e-01  1.72573303e-02  1.28401992e-19  6.99143972e+00
 -1.83650974e-07 -1.46286781e-10 -1.26957544e-15 -2.89141412e-05
 -4.91091124e+00 -3.73624033e+00 -3.86032445e-01 -1.80043089e+00
 -8.95136599e-01 -1.74617383e-03 -4.42718777e-04 -1.52218930e-05
 -1.76894273e-02  2.35301777e-20 -1.47571891e-15  3.70491870e-21
 -1.97419034e+00 -1.46815719e+00 -9.75517276e-02 -1.88418610e-01
  1.07242683e+00  1.85725118e+00  1.42213485e+00  1.72006586e+00
  1.25702394e+00  1.25301063e-01  1.69914948e+00  1.40167905e-01
 -1.99579808e+00 -8.97924241e-02 -3.13646863e+00 -1.04847512e-01
 -5.83331239e+00 -3.46607153e-01 -9.42819475e+00 -3.70822101e-01
 -4.48381102e+00  1.98912959e+01  2.84703758e+00 -1.80353467e+01
 -1.85546032e-02 -1.04083638e+00  2.22392359e+00 -1.97821841e+01
  1.03344835e+01]
supnorm grad right now is: 19.89129593817397
Weights right now are: 
[ -7.28448719   4.42729496   6.78313265  -6.75795939   7.5390559
  -4.53598665  -6.38419538   6.04193101  -5.44133266   3.94422376
  -8.04927254   5.25540005   2.40826014  22.20774452  44.25241925
   6.02315664  28.81792272  63.58586667  29.90199036   2.09815714
  19.99218822  22.13635486  35.52848511  24.31513595   4.24274164
   3.41825735  -9.13099367  -9.55695527   4.92387076  96.65257601
  93.04680081  43.74529585  94.88526522  24.52742505  10.20467972
  16.52198564  -2.47333189   4.15702699  -0.83569021 -15.4136838
   1.14181099   1.61946447  -4.46850268   3.47421225  -5.07189131
  42.96814721  -2.97948217  31.21484341  -5.5220046   27.98141531
   3.96104405  21.00703687  -5.22509987  45.20407803   0.33044414
  44.84800424   6.59255736   1.63998641   0.57172743  -2.25318985
   4.43855098   3.06186753   2.63505654  -1.91655672  29.61950132]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1850.9441061591208
gradient value of function right now is: [-1.34993781e+00 -1.57560160e-01 -1.25164665e+00 -1.68295544e-04
  1.34993781e+00  1.57560160e-01  1.25164665e+00  1.68295544e-04
 -3.57764766e+00 -3.35625770e+00 -1.21177019e-01 -1.15293317e+01
  1.59341920e-02  5.51431107e-03  1.84002842e-08  6.19892325e-01
  1.85337888e-01  3.25422300e-02  4.00830593e-19  9.03853138e+00
 -3.10817562e-06 -2.54192975e-10 -2.13959337e-16 -5.13846759e-04
 -6.32768338e+00  1.77459696e+00  1.63060780e-01  9.35750542e-01
  1.67544792e-02 -4.14333013e-03 -2.92394426e-03 -2.12636303e-04
 -2.49772155e-02 -3.82401775e-21 -1.92420117e-14 -1.22647167e-22
  2.15130364e+00 -1.30538514e-01  4.15796937e-02  9.36794772e-02
  1.11316086e+00  6.03574842e+00  2.89368887e+00  3.11099561e+00
  9.63086540e-01  2.70819900e-01  2.19170305e+00  1.79511031e-01
  1.25766058e+00  2.49204131e-02  1.75084187e+00  6.59360962e-02
  3.50129679e+00  1.49193088e-01  6.03412327e+00  1.74593755e-01
  3.47650427e+00 -1.66779732e+01 -6.36739756e+00  2.34584525e+01
  4.67686750e+00 -5.04585078e+00 -5.73042089e+00  1.60910800e+01
  3.07338888e+01]
supnorm grad right now is: 30.73388876655759
Weights right now are: 
[-7.28793395e+00  4.22383999e+00  6.54550321e+00 -4.85128907e+00
  7.54250266e+00 -4.33253168e+00 -6.14656594e+00  4.13526069e+00
 -5.31737365e+00  4.31114136e+00 -8.84653360e+00  5.08773351e+00
  2.61593636e+00  2.28095098e+01  4.42660308e+01  6.98640169e+00
  2.93995051e+01  6.47236834e+01  2.99019904e+01  2.14762462e+00
  2.21713778e+01  2.21363541e+01  3.55284851e+01  2.57837220e+01
  4.33500443e+00  3.51302985e+00 -8.92627205e+00 -1.01029856e+01
  5.15088233e+00  9.91681025e+01  1.01445318e+02  4.20990793e+01
  9.87776005e+01  2.45274251e+01  1.02046797e+01  1.65219856e+01
 -2.59364039e+00  4.43348337e+00  7.95580733e-02 -1.54660260e+01
  8.41064665e-01  1.47037723e+00 -4.22684870e+00  3.69338790e+00
 -5.40494374e+00  4.44037422e+01 -2.83341708e+00  3.11793601e+01
 -6.06574819e+00  2.55223933e+01  4.40153353e+00  1.90252277e+01
 -5.33319955e+00  4.76823774e+01  6.90180666e-01  4.68615012e+01
  6.79650367e+00  1.50942317e+00  5.90190598e-01 -2.17985843e+00
  4.50911772e+00  2.85250774e+00  3.07354090e+00 -1.85581301e+00
  2.94459615e+01]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1851.979791230693
gradient value of function right now is: [-9.90643449e-01 -9.75625307e-02 -6.55486546e-01 -1.92351002e-04
  9.90643449e-01  9.75625307e-02  6.55486546e-01  1.92351002e-04
 -3.59736941e+00 -2.90296421e+00 -1.39513325e-02 -8.54330439e+00
  2.91282622e-02  5.51184307e-03  2.35140841e-08  5.61171713e-01
  1.27845000e-01  1.01422490e-02  1.73484842e-19  5.91591887e+00
 -6.25878289e-06 -2.52517980e-09 -1.12474348e-15 -1.01012008e-03
 -5.68608209e+00 -6.92257940e-01 -1.18735327e-02 -3.75805037e-01
  4.11462959e-01 -1.40060153e-03 -1.58976355e-03 -2.72397167e-05
 -7.01057515e-03 -3.97949051e-22 -8.61473131e-13 -3.74113479e-24
  1.15946782e+00 -1.29836249e-01  2.63741132e-02  2.18032806e-02
  6.24950394e-01  3.62604725e+00  1.50410550e+00  2.46406461e+00
  6.65585628e-01  1.37977221e-01  1.48654243e+00  1.23173965e-01
  3.65571862e-01  8.36136841e-03  2.46340801e-01  2.34622681e-02
  1.23308062e+00  5.82113853e-02 -6.80456011e-01  1.02969528e-01
 -1.35563692e+00  1.65555603e+00 -1.78546218e+00  9.72085890e+00
  2.41026518e+00 -2.61596450e+00 -2.68215620e+00  9.18842537e+00
  1.54597356e+01]
supnorm grad right now is: 15.45973555427584
Weights right now are: 
[-7.36926970e+00  4.68701223e+00  6.77862825e+00 -8.78939768e+00
  7.62383841e+00 -4.79570393e+00 -6.37969098e+00  8.07336930e+00
 -5.68730747e+00  3.59284941e+00 -7.40591582e+00  5.17651547e+00
 -1.14004344e-02  2.56970562e+01  4.42776282e+01  6.11127575e+00
  2.84066038e+01  6.76788331e+01  2.99019904e+01  2.24782408e+00
  2.26138253e+01  2.21364875e+01  3.55284851e+01  2.31879748e+01
  4.38097446e+00  3.31195215e+00 -7.55880660e+00 -1.09140245e+01
  5.63294874e+00  1.03136403e+02  1.15348604e+02  4.26296710e+01
  1.04308705e+02  2.45274251e+01  1.02046803e+01  1.65219856e+01
 -2.20371133e+00  4.32614178e+00 -2.06981622e+00 -1.66890258e+01
  6.48674609e-01  1.36984551e+00 -4.33241566e+00  3.02172641e+00
 -5.71019805e+00  4.59723322e+01 -2.79084035e+00  3.16066071e+01
 -5.72502250e+00  1.98170330e+01  5.35418512e+00  1.56410544e+01
 -5.67299358e+00  4.97544523e+01  5.63462163e-01  4.82387508e+01
  6.80448110e+00  1.64724962e+00  1.17715882e+00 -2.03160021e+00
  4.36636530e+00  2.81831467e+00  2.47792334e+00 -1.79326600e+00
  2.92497492e+01]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.871282758335
gradient value of function right now is: [ 4.90914936e-01  2.14786895e-02 -6.15050991e-02  1.74615127e-05
 -4.90914936e-01 -2.14786895e-02  6.15050991e-02 -1.74615127e-05
  1.72277101e+00  1.61333510e+00 -7.65536974e-03  3.92941033e+00
 -2.43481492e-02 -5.89682234e-03 -5.51558568e-09 -1.45880839e-01
 -1.96778082e-02 -6.37911584e-03 -4.69580550e-20  6.60460664e-01
  4.93911968e-07  1.50330583e-09  3.12839445e-16  1.02612464e-04
  9.36729924e-01 -1.46612528e+00 -7.40747121e-02 -7.05548893e-01
 -2.48350096e-01  1.79994888e-04 -9.57787871e-05  1.47020197e-05
  1.42165671e-03  1.30043433e-21  2.02454561e-09  2.92315035e-23
 -2.04751105e+00 -6.00042828e-01 -1.13336802e-01 -1.32081344e-01
 -1.63943842e-01 -2.18218455e+00 -7.42866045e-01 -8.69807223e-01
  1.42203584e-01 -3.78730278e-02 -3.35747860e-01 -5.88330447e-03
 -6.69552227e-01  2.51802310e-02 -9.09829521e-01 -3.11432646e-02
 -3.52290793e+00 -1.80804829e-01 -5.61994571e+00 -1.98227365e-01
 -2.27990455e+00  1.28918965e+01  3.13642995e+00 -1.48248016e+01
 -1.92189035e+00  1.62225362e+00  3.16199566e+00 -1.29305033e+01
 -1.09004715e+01]
supnorm grad right now is: 14.824801561592029
Weights right now are: 
[-6.95533303e+00  5.02465907e+00  6.85766481e+00 -9.14689142e+00
  7.20990174e+00 -5.13335076e+00 -6.45872754e+00  8.43086304e+00
 -5.55538190e+00  4.00773011e+00 -8.32125343e+00  5.69820591e+00
 -2.45833145e-01  2.92152200e+01  4.42806249e+01  6.34306836e+00
  2.80111289e+01  7.08978356e+01  2.99019904e+01  2.41593217e+00
  2.52374277e+01  2.21364820e+01  3.55284851e+01  2.34382115e+01
  4.48809834e+00  3.57903538e+00 -5.86469888e+00 -1.13269048e+01
  5.40439022e+00  9.81890728e+01  1.21062042e+02  3.35380675e+01
  1.08442896e+02  2.45274251e+01  1.02050632e+01  1.65219856e+01
 -2.29812408e+00  4.67764937e+00 -2.40856312e+00 -1.73773381e+01
  1.76157041e-04  1.81955308e+00 -4.00906363e+00  3.36707855e+00
 -5.88954073e+00  4.79536765e+01 -2.60933667e+00  3.25170590e+01
 -6.96869140e+00  1.49678017e+01  5.91474283e+00  1.14081798e+01
 -5.92358451e+00  5.16159252e+01  7.25580416e-01  4.95592824e+01
  6.81734970e+00  1.41471881e+00  9.75542226e-01 -2.19729300e+00
  4.39162818e+00  3.26015155e+00  2.84455073e+00 -1.97186968e+00
  2.92872408e+01]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.9283940693952
gradient value of function right now is: [-8.96174816e-02 -2.01203118e-02  4.06654185e-02 -7.79051159e-06
  8.96174816e-02  2.01203118e-02 -4.06654185e-02  7.79051159e-06
  1.45368429e-01  2.45501409e-01  1.67231559e-02 -9.86061909e-01
  1.66234206e-02  1.08551483e-03 -1.66672168e-10  1.07567835e-01
  3.90010348e-02 -6.85761490e-03  5.21263075e-22 -6.88533238e-01
 -4.67865579e-07 -2.57834784e-10  1.71732345e-17 -5.70550937e-05
 -4.42321602e-01  8.96324271e-01 -1.62859696e-01  5.14340470e-01
  4.62736106e-01  4.53123358e-04  2.17979345e-03  9.44483483e-06
  8.86072239e-04 -1.26750841e-25  1.23160372e-10 -1.71689575e-25
  1.12181572e+00  6.32797179e-02  9.28491522e-02  1.57544365e-02
 -2.55511923e-01  4.17065031e-01  8.07942669e-02 -1.99579208e-01
 -2.18312667e-01  5.33389410e-03  5.38665888e-02 -1.91152852e-02
  7.67761291e-02 -1.23063743e-01 -5.09549579e-02 -3.14318262e-02
  1.27500477e+00  1.80342816e-02  3.10968466e+00  3.48568867e-02
  2.05509828e+00 -8.42057767e+00 -3.21943604e-02  2.59946740e+00
  2.62849115e+00 -2.90868438e+00 -4.00934853e-01  2.19017146e+00
  1.62819917e+00]
supnorm grad right now is: 8.420577669825686
Weights right now are: 
[ -7.20104917   4.46765748   6.88729255  -8.45008212   7.45561788
  -4.57634917  -6.48835528   7.73405373  -5.54375735   3.93565751
  -7.90678269   5.54869159   1.35019436  30.99980285  44.28144828
   7.19119938  26.97043024  74.53496247  29.90199036   2.17414815
  27.23738704  22.13662601  35.52848511  24.43478172   4.57296915
   3.5125491   -5.70995534 -11.72092105   5.01749033  98.97952261
 123.01334652  24.77107267 113.84468955  24.52742505  10.2057145
  16.52198564  -2.1343138    4.61314453  -2.63045247 -17.17332635
  -0.72073024   1.54050121  -3.78246314   3.12045407  -6.63393242
  49.78366711  -2.39446556  32.27253393  -8.20323081  14.77723274
   6.59310467  11.789144    -6.15583745  53.31504778   0.79564318
  50.55022331   6.77158762   1.27327857   0.98444769  -2.19921443
   4.96926325   2.96071321   3.24732168  -1.97794807  29.23641065]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.7525756073005
gradient value of function right now is: [ 3.70683280e-01  6.43656893e-02  6.99607119e-01  3.27152311e-04
 -3.70683280e-01 -6.43656893e-02 -6.99607119e-01 -3.27152311e-04
  7.16036711e-01  7.42278233e-01  2.45425386e-02  2.90913331e+00
 -8.45541394e-03 -9.86933892e-04 -1.69178470e-10 -2.81052835e-01
 -9.75912818e-02  1.90967205e-03 -3.80307111e-22 -5.42886620e+00
  6.75645925e-06  1.09493184e-10  4.50897327e-18  1.27586850e-03
  2.43452444e+00  2.00557736e-02  5.34039377e-02 -2.26560843e-01
 -4.70144298e-01  1.54576826e-03 -5.29843565e-04  7.73838569e-05
  2.06040823e-03  1.14268064e-24  7.97288387e-11  2.29624296e-26
  7.51566805e-01  7.68111693e-01 -6.38362478e-03  9.18205182e-02
  7.34426365e-02 -1.47581900e+00 -4.17863659e-01 -5.81442786e-01
 -5.36934557e-01 -1.44105280e-01 -1.96906573e+00 -8.62870365e-02
 -2.27021212e-02  5.66901135e-02  5.25766741e-03  1.72751151e-02
 -6.73919521e-01  4.07030723e-02  3.57526063e-01 -9.50531716e-03
 -4.94784183e-01  4.13215755e+00  1.21642804e+00 -4.81439236e+00
 -2.12774145e+00  2.70492189e+00  1.02477798e+00 -3.29824569e+00
 -7.37508691e+00]
supnorm grad right now is: 7.375086913139801
Weights right now are: 
[-7.19111798e+00  4.79994222e+00  7.02037917e+00 -8.26577717e+00
  7.44568669e+00 -4.90863391e+00 -6.62144190e+00  7.54974879e+00
 -5.80777356e+00  3.76207725e+00 -8.35066354e+00  5.62797729e+00
  2.64255494e-01  3.12959641e+01  4.42818073e+01  7.33313396e+00
  2.63650697e+01  7.74884607e+01  2.99019904e+01  2.23433992e+00
  2.83215545e+01  2.21366635e+01  3.55284851e+01  2.53888862e+01
  4.59929449e+00  3.54765629e+00 -4.16651257e+00 -1.23125951e+01
  4.78517441e+00  9.87325894e+01  1.24631896e+02  2.09459833e+01
  1.18328326e+02  2.45274251e+01  1.02088268e+01  1.65219856e+01
 -2.11082965e+00  4.90337115e+00 -4.53154779e+00 -1.82066416e+01
  8.52141508e-02  1.61349618e+00 -3.55064799e+00  2.97962447e+00
 -6.60477918e+00  5.08449805e+01 -2.34885390e+00  3.25585979e+01
 -8.60236376e+00  1.39976705e+01  7.68742478e+00  1.18836640e+01
 -6.46628433e+00  5.54386427e+01  8.70602590e-01  5.18090338e+01
  6.72129837e+00  1.36539882e+00  9.12827635e-01 -2.24317446e+00
  4.69275347e+00  3.43560400e+00  3.03659036e+00 -1.93846266e+00
  2.93150189e+01]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.3622051796194
gradient value of function right now is: [ 2.73217918e-01  3.84933287e-02  7.67666017e-01  8.95890227e-06
 -2.73217918e-01 -3.84933287e-02 -7.67666017e-01 -8.95890227e-06
  2.09341543e-01 -4.54056414e-02 -4.94169640e-02  2.89864257e+00
 -2.68960479e-02 -1.06830065e-03  8.78912631e-10 -2.67564547e-01
 -1.68759933e-01 -1.75868623e-02 -1.36617240e-20 -7.61967080e+00
  1.74813431e-07  4.72391978e-11 -1.53285754e-18  4.91777114e-05
  3.54966331e+00 -3.70898943e-01  2.13438599e-01 -3.37236819e-01
  9.63070837e-01  2.30864519e-03  4.61927937e-03  1.21133019e-04
 -9.55916113e-03  1.02632006e-22 -8.81285338e-08  6.13681227e-25
  5.95887060e-01  4.39767476e-01 -4.78172776e-02  4.15141183e-02
 -2.56280320e-01 -8.65416725e-01 -1.49997541e+00  2.65109075e-01
 -4.12666408e-01 -1.26171860e-01 -1.35827927e+00 -6.28004006e-02
 -1.78905462e-03  4.73870460e-03 -9.39755192e-02 -1.46783542e-02
 -3.41137372e-01  3.82944386e-02 -1.04207536e+00  1.47292049e-02
 -1.58698828e+00  5.46932241e+00  3.10529435e+00 -5.27815130e+00
 -2.72281460e+00  2.68280135e+00  1.39943774e+00 -2.54043284e+00
 -8.63609340e+00]
supnorm grad right now is: 8.636093403333799
Weights right now are: 
[ -7.01254908   5.04586091   7.14641349  -8.45223043   7.26711779
  -5.1545526   -6.74747622   7.73620205  -5.6342419    3.70399304
 -10.12963986   5.83090812  -1.63465218  29.86163475  44.28189493
   7.87838841  26.23406197  79.75794131  29.90199036   2.20737373
  30.03911922  22.13668995  35.52848511  26.76732253   4.97537983
   3.331864    -4.48496136 -12.10780382   5.21052035  99.15733602
 127.58749033  12.27972027 122.87140294  24.52742505  10.21320691
  16.52198564  -2.29960503   4.95505833  -5.16592069 -17.82449953
  -0.14608953   1.89187064  -3.86302466   3.76653721  -6.99915241
  52.94774153  -2.10282449  32.6016851   -9.19576708  11.45092474
   8.03520426  11.42233156  -6.34463028  57.01936767   0.66478233
  52.94819572   6.19124699   1.31297157   1.20062367  -2.1517293
   4.70821594   3.92488048   3.21971302  -2.06069192  29.35377421]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.050134335571
gradient value of function right now is: [-2.41519483e-02 -1.32032980e-02 -1.22878147e-01 -1.49711545e-05
  2.41519483e-02  1.32032980e-02  1.22878147e-01  1.49711545e-05
 -4.07290361e-01 -2.08925468e-01  1.83129191e-02  2.87036046e-02
 -2.24914939e-03 -4.64142911e-04  3.76816272e-10  4.73814603e-02
 -3.28270207e-02 -2.06250869e-03 -5.69175085e-23  1.57767216e-01
 -3.19300651e-07  7.60076496e-12 -2.39488541e-19 -8.26975224e-05
  1.91582665e-04 -1.45476265e+00  5.01726263e-02 -8.33325442e-01
  5.06834355e-02  7.88523156e-04  3.48215863e-04  4.22635443e-05
  4.50113403e-05  9.21276695e-27 -2.07137381e-10  3.41872893e-28
 -8.03241679e-01 -4.20726540e-01 -4.26487663e-02 -6.98091585e-02
  1.64174292e-01 -7.33093031e-01 -1.49352695e-01  5.20337192e-02
  8.12919330e-02 -2.22434400e-02  1.00961770e-01 -7.63478961e-03
 -1.55240256e-01  2.83024738e-02 -2.54076451e-01 -6.26995125e-03
 -2.17548221e+00 -9.40929130e-02 -4.82504080e+00 -8.68655640e-02
 -2.88980871e+00  1.20990080e+01  2.44168161e+00 -8.92141498e+00
 -9.38716888e-01  8.52124441e-01  1.62352589e+00 -6.69247538e+00
 -2.91411876e+00]
supnorm grad right now is: 12.099007990876789
Weights right now are: 
[ -7.19585697   5.5973202    6.86061195  -8.22235073   7.45042568
  -5.70601189  -6.46167468   7.50632234  -5.92758791   3.58720267
  -7.95263296   5.48395834  -0.93568228  28.57111099  44.28228739
   9.09959541  26.6330921   82.50521619  29.90199036   2.16623318
  31.46084007  22.13669325  35.52848511  27.99332757   4.85706333
   3.37221839  -4.66928623 -11.80736855   5.29088726 102.42959063
 127.06510824   8.1253051  128.20259032  24.52742505  10.2203663
  16.52198564  -2.23966139   4.78767817  -6.37336081 -18.21517203
   0.29143646   1.7239502   -3.43765204   2.89219462  -6.62609454
  54.09990452  -2.11288354  32.85595552  -9.77520336  12.67458137
   8.53601244  13.68524416  -6.31304338  58.5665512    0.78636863
  54.03249536   5.98562402   1.34029098   0.74420791  -2.32240934
   5.00880015   3.30364537   3.27880944  -1.95153995  29.37417768]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1849.9716998952888
gradient value of function right now is: [ 1.25249272e+00  2.64508010e-02  6.35014512e-01  7.32124704e-05
 -1.25249272e+00 -2.64508010e-02 -6.35014512e-01 -7.32124704e-05
  4.42357123e+00  4.46625642e+00  1.85747813e-01  9.29879847e+00
 -1.21570439e-02 -1.70236693e-03 -1.59209938e-09 -1.75803761e-01
 -1.47474371e-01 -2.71482472e-02 -3.95852239e-22 -5.97205416e+00
  1.12438850e-06  3.94990979e-10  1.09808884e-17  5.06450148e-04
  3.59408734e+00 -1.79354664e+00  9.89433724e-02 -1.05740563e+00
  6.62616560e-01  2.63574580e-03  7.54034755e-03  8.44909829e-05
  2.23091754e-02  1.00038027e-25  1.47346682e-09  8.14955418e-28
 -1.66110796e+00 -1.71326914e-01 -8.56712288e-02 -9.91846015e-02
 -8.92596351e-01 -7.81506770e+00 -1.91773337e+00 -4.16664078e+00
 -4.36095249e-01 -1.18524742e-01 -9.96627810e-01 -7.70455192e-02
 -6.83326490e-01 -3.97820610e-02 -1.01146315e+00 -7.54923753e-02
 -3.72014376e+00 -1.39856316e-01 -6.14828722e+00 -1.59327008e-01
 -3.40495132e+00  1.74779291e+01  6.20784783e+00 -1.82554675e+01
 -2.72335390e+00  2.12785134e+00  5.05723793e+00 -1.23283848e+01
 -2.75426804e+01]
supnorm grad right now is: 27.542680380259636
Weights right now are: 
[-6.75081732e+00  6.62478100e+00  7.25658342e+00 -1.17744338e+01
  7.00538603e+00 -6.73347269e+00 -6.85764615e+00  1.10584054e+01
 -5.53918130e+00  4.01757368e+00 -7.99061188e+00  5.74003083e+00
 -6.71275687e-03  3.06811109e+01  4.42831865e+01  8.87401669e+00
  2.56191125e+01  8.50891720e+01  2.99019904e+01  2.15653354e+00
  3.19044041e+01  2.21367068e+01  3.55284851e+01  2.59662369e+01
  5.19412669e+00  3.57828286e+00 -5.37185336e+00 -1.18700194e+01
  5.21942029e+00  1.04380940e+02  1.28956059e+02  4.62339476e+00
  1.32656000e+02  2.45274251e+01  1.02229214e+01  1.65219856e+01
 -2.27932427e+00  4.84209763e+00 -5.62919892e+00 -1.83190951e+01
  1.96257309e-01  1.94409173e+00 -4.22363383e+00  2.94395113e+00
 -7.11236633e+00  5.57321247e+01 -2.22035720e+00  3.35968108e+01
 -1.03526579e+01  1.19855003e+01  9.01367156e+00  1.53944977e+01
 -6.29031332e+00  6.06176247e+01  8.82861717e-01  5.51170107e+01
  6.35514458e+00  1.37510280e+00  8.68539916e-01 -2.34141990e+00
  5.12551900e+00  3.14135437e+00  3.32124565e+00 -2.01962470e+00
  2.91267810e+01]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.375246621848
gradient value of function right now is: [ 4.97514627e-01  4.01311135e-04  1.07780593e-01  7.08872067e-06
 -4.97514627e-01 -4.01311135e-04 -1.07780593e-01 -7.08872067e-06
  1.49229658e+00  1.54180941e+00 -2.78119211e-03  4.02673979e+00
 -3.40127928e-03 -6.95418967e-04 -1.84347545e-10 -9.92135159e-03
 -7.37238118e-02 -1.59308819e-02 -2.44206306e-22 -1.55970659e+00
  1.05904720e-07  6.35013923e-11  3.10535623e-19  3.91681232e-05
  1.62647863e+00 -1.41845339e+00  5.70689449e-02 -8.51986734e-01
  5.14863874e-01  7.60185523e-04  1.75892544e-03  2.44255614e-05
  8.04785849e-04  8.58290899e-26  1.27749999e-09  4.91875779e-28
 -1.78496096e+00 -6.45555788e-01 -1.08048731e-01 -1.08025355e-01
 -5.69789130e-01 -2.93442093e+00 -1.22043983e+00 -9.01839162e-01
 -4.00032578e-02 -3.84787449e-02 -1.77308178e-01 -1.82178149e-02
 -5.71589850e-01  2.67251653e-02 -8.04424361e-01 -4.64621776e-02
 -2.83764904e+00 -1.30362823e-01 -5.11035518e+00 -1.11120602e-01
 -3.28672719e+00  1.45040119e+01  4.21518295e+00 -1.41882691e+01
 -1.50080980e+00  1.15556869e+00  2.85069496e+00 -9.33390188e+00
 -1.39311866e+01]
supnorm grad right now is: 14.504011943394191
Weights right now are: 
[ -6.93897136   7.02539048   6.8333309  -10.68983089   7.19354007
  -7.13408217  -6.43439363   9.97380251  -5.63368775   3.78650747
 -10.23310551   5.7680144   -0.3158096   31.33079404  44.28331465
  10.03705917  25.37324737  85.56777804  29.90199036   2.36927499
  33.86368058  22.13672466  35.52848511  28.0977383    5.19774604
   3.45183779  -5.13271939 -11.8533257    5.57322889 105.39404753
 130.67138025  -1.516522   137.05924899  24.52742505  10.22359614
  16.52198564  -2.08909634   4.6073758   -6.16320612 -19.26146548
  -0.34956181   2.02818871  -3.973896     3.10846819  -6.33516847
  57.24584709  -2.70143734  33.95553167 -10.8673327   12.0811175
   9.34213501  15.62952308  -6.12669335  62.50494852   0.81242851
  56.07502001   6.24963767   1.52802308   0.68644232  -2.22604021
   5.20168348   3.14711294   3.2494703   -1.95601644  29.09501182]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1851.7903554052714
gradient value of function right now is: [-1.46859405e+00 -3.98321779e-03 -2.29021332e-01 -2.53611303e-04
  1.46859405e+00  3.98321779e-03  2.29021332e-01  2.53611303e-04
 -4.95536800e+00 -4.70333253e+00 -7.26559477e-02 -1.17179195e+01
  1.17150278e-02  2.47660822e-03  5.26333145e-09  3.48086805e-02
  2.18668374e-01  1.77365865e-02  2.48734940e-23  3.70096669e+00
 -5.63097065e-06 -4.35966249e-10 -1.58635072e-18 -1.53966793e-03
 -5.24690622e+00  3.21985161e+00 -1.46912009e-01  1.73431816e+00
  4.07748178e-01 -2.02797046e-03 -3.27311991e-03 -6.33949736e-05
 -1.55676619e-02 -2.83566744e-27 -2.17113510e-10 -7.29822990e-30
  4.65491892e+00  1.30900146e+00  2.09817416e-01  2.29064129e-01
  8.96819097e-01  9.36521425e+00  2.44834702e+00  3.90506155e+00
 -4.17633267e-03  1.24421874e-01  8.41809159e-01  3.86730137e-02
  1.04036725e+00 -9.26841976e-02  1.41873638e+00  6.23731614e-02
  6.54381815e+00  2.91124454e-01  1.23688503e+01  2.76881577e-01
  6.86171473e+00 -3.39746124e+01 -9.84994663e+00  3.48902994e+01
  4.96940500e+00 -4.93629770e+00 -6.65400082e+00  2.14794437e+01
  3.45454619e+01]
supnorm grad right now is: 34.89029937908446
Weights right now are: 
[ -6.88155319   7.07353224   6.88313885 -14.17678382   7.1361219
  -7.18222393  -6.48420158  13.46075544  -5.8187353    3.65792704
 -10.18564613   5.62064629  -2.11970162  27.95215663  44.28354563
   9.88187046  25.24886155  87.25358946  29.90199036   2.39765248
  34.67729121  22.13673939  35.52848511  26.20810233   4.91747466
   3.44859504  -5.37891213 -11.82445073   5.70940857 110.55398236
 133.48975103  -7.61419536 142.43594355  24.52742505  10.22431216
  16.52198564  -2.28316962   4.69639378  -5.56270527 -19.41171205
   0.17322751   1.84441853  -3.46082642   2.89452057  -7.26153258
  58.4167788   -2.40081036  32.67979865 -11.11305313  13.27588767
   9.06547888  15.43269811  -6.30465023  64.03505708   0.71859455
  56.96162123   6.24676823   1.26053134   0.62107886  -2.29062066
   5.45661957   3.16104603   3.35375213  -2.03167477  29.45513785]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1852.209133226461
gradient value of function right now is: [-1.21081060e+00  3.29830650e-03 -5.49443862e-01 -4.20886231e-04
  1.21081060e+00 -3.29830650e-03  5.49443862e-01  4.20886231e-04
 -4.45721598e+00 -3.79255084e+00 -3.33545977e-02 -1.01821981e+01
  5.28375428e-03  9.91468652e-04  4.00415098e-10 -1.00456562e-02
  1.64606488e-01  2.09536502e-02  2.61284806e-24  6.77859111e+00
 -1.63668029e-05 -2.34213533e-10 -1.82209240e-19 -2.09761576e-03
 -5.78676776e+00  7.32193680e-01 -2.38966516e-02  1.96341994e-01
 -3.28730288e-01 -2.95323052e-03 -3.27749969e-03 -8.98031985e-05
 -8.34160862e-03 -5.15130964e-28 -3.97198966e-10 -1.00080889e-30
  2.39634213e+00  5.93775408e-01  1.36978872e-01  1.52420208e-01
  1.02818716e+00  6.45069763e+00  2.48444334e+00  2.98742475e+00
  5.09295503e-01  1.48273157e-01  1.41897374e+00  9.78125344e-02
  7.26516572e-01 -4.03522290e-02  1.03236209e+00  5.39008749e-02
  3.27592415e+00  1.63580989e-01  4.16093116e+00  1.84432470e-01
  2.16883744e+00 -1.20204032e+01 -6.83267132e+00  2.38676460e+01
  2.48059920e+00 -2.32081266e+00 -4.76612148e+00  1.67883896e+01
  2.43975530e+01]
supnorm grad right now is: 24.397552955647935
Weights right now are: 
[ -6.96608343   7.9986593    6.9449781  -15.39994074   7.22065214
  -8.10735099  -6.54604083  14.68391236  -5.9910665    3.60561932
 -10.05925164   5.4846076   -0.96993282  31.28993292  44.28383856
  10.09353949  25.70665534  89.16462159  29.90199036   2.43453888
  38.25190805  22.13679833  35.52848511  26.28042881   4.77981741
   2.9190286   -4.759003   -11.85828161   5.34947855 112.91108089
 138.11973524 -10.98546783 147.18472422  24.52742505  10.22475715
  16.52198564  -2.22106089   5.42996147  -4.51363562 -17.85955247
  -0.20869861   1.88653352  -3.32118691   2.7566805   -6.34224148
  59.91980271  -2.10037297  32.84224699 -11.33174688  12.26904718
   9.74476128  14.9122235   -6.25610127  65.49690785   0.86263041
  57.95771498   6.32661978   1.42246184   0.69008126  -2.25670429
   5.13642054   3.21451458   3.14718598  -1.95612982  29.26493484]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.268297727092
gradient value of function right now is: [-7.52444903e-01  1.27355943e-02  4.00172925e-01  1.06850766e-03
  7.52444903e-01 -1.27355943e-02 -4.00172925e-01 -1.06850766e-03
 -2.90799199e+00 -2.84292190e+00 -4.60886652e-02 -5.73651070e+00
  2.27306041e-03  4.77670865e-04  5.08003237e-10 -3.43949686e-02
  3.22921013e-02  3.59321037e-03  1.16284622e-24 -2.93715350e+00
  2.06912876e-05 -2.44984776e-10 -1.05076753e-19  5.33232113e-03
 -9.41947813e-01  2.22815004e+00 -6.63044484e-02  1.19521903e+00
  6.99549744e-01 -8.53299123e-05  4.00424888e-04 -7.67297877e-06
 -9.34966410e-03 -2.97196363e-28 -4.21515788e-11 -4.13507475e-31
  3.64366927e+00  6.87553018e-01  1.03151278e-01  1.09112881e-01
  1.64861624e-01  4.84218401e+00  5.53543452e-01  2.09076714e+00
 -3.70925556e-01 -2.23107497e-02 -5.80966600e-01 -3.66195261e-02
  4.14336080e-01 -1.02570624e-01  5.38021843e-01  1.29191561e-02
  3.40897357e+00  1.08160727e-01  7.08701219e+00  1.40683896e-01
  3.69149628e+00 -1.61798711e+01 -3.21343921e+00  9.19532424e+00
  1.74332962e+00 -8.69526198e-01 -3.01635822e+00  9.00178448e+00
  1.49574531e+01]
supnorm grad right now is: 16.179871067001017
Weights right now are: 
[ -6.78400887   7.0484971    7.10358783 -16.15692311   7.03857758
  -7.15718879  -6.70465056  15.44089472  -5.72696288   3.76531304
 -10.06236925   5.54763095  -2.4223013   30.42934476  44.28387332
  11.24150158  24.53575935  91.14776944  29.90199036   2.32221183
  39.87278592  22.13682161  35.52848511  25.67390444   4.84978051
   3.5189033   -5.38450942 -11.41114234   5.44879663 113.18941289
 139.68335748 -17.61617931 151.8162781   24.52742505  10.22552291
  16.52198564  -2.13621819   4.85001866  -4.71801953 -18.80255674
  -0.68918561   2.00805248  -3.50270634   2.81061647  -6.77952173
  60.52900672  -2.42639752  31.64961518 -11.50482385  13.87702989
   9.90856915  16.4203652   -6.29185783  67.07734286   0.98580413
  58.49170565   6.35470082   1.35065744   0.71899228  -2.52481204
   5.35837816   3.36233322   3.29364448  -2.00320643  29.45774059]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.6309276135098
gradient value of function right now is: [ 1.81528203e-01  9.45575534e-03  1.97764957e-01  5.26043490e-04
 -1.81528203e-01 -9.45575534e-03 -1.97764957e-01 -5.26043490e-04
  4.01500724e-01  5.06457090e-01 -1.85148614e-02  1.19386486e+00
 -2.00038743e-04 -6.40387065e-05 -1.31557020e-11 -3.04398006e-02
 -1.59865039e-02  5.58599798e-04 -4.18242827e-25 -1.35682588e+00
  1.41934133e-05 -1.75758843e-11  5.74110265e-21  3.28268197e-03
  3.24779508e-01 -3.46365028e-01 -6.07818789e-02 -2.68431802e-01
 -2.27934254e-01  2.35581103e-04 -5.67979225e-04  9.69668282e-06
 -2.00612597e-03  3.48895327e-28  9.80120365e-11  2.00887955e-31
  1.69815795e-02  2.54316685e-01 -2.82813941e-02  2.39950653e-02
  1.79196427e-01 -5.24360906e-01  1.03600985e-01  1.56597410e-01
 -3.00849517e-01 -4.76054564e-02 -6.96482572e-01 -2.89748833e-02
 -3.09886487e-01  3.31356665e-02 -4.08063897e-01 -7.24297016e-03
 -9.07517648e-01 -1.45951096e-02 -6.86576318e-01 -3.35809692e-02
 -4.30662618e-01  4.47292123e+00  5.58772732e-01 -4.55397275e+00
 -5.15672265e-01  7.07585352e-01  6.33898190e-01 -3.74289195e+00
 -2.13802976e+00]
supnorm grad right now is: 4.553972750237402
Weights right now are: 
[ -6.50028149   7.66018168   6.92259358 -16.10851299   6.7548502
  -7.76887337  -6.52365631  15.39248461  -5.80721127   3.8577324
  -9.17803113   5.73333408  -1.80824927  35.37462025  44.28400295
  11.09231745  24.17290573  92.32931857  29.90199036   2.34152124
  43.32409764  22.1368514   35.52848511  25.96438252   5.11642899
   3.23905262  -5.45113267 -11.65691793   5.57183146 117.79721822
 144.08737494 -21.43000315 155.16021005  24.52742505  10.22685097
  16.52198564  -2.41084718   5.11576227  -3.77628584 -19.5372402
   0.28472273   2.1617208   -3.27728392   3.02164519  -6.71141508
  61.68303282  -2.54126036  31.59218737 -12.12615046  13.04296883
   9.66225374  16.35748099  -6.23730564  69.04663981   0.92003769
  59.48846446   6.53337757   1.52355888   0.68458483  -2.3726557
   5.18908989   3.33013852   3.72661143  -2.06348405  29.31630202]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.3551738323044
gradient value of function right now is: [-3.20221481e-01 -5.60457806e-03  1.61033315e-02  3.30274143e-05
  3.20221481e-01  5.60457806e-03 -1.61033315e-02 -3.30274143e-05
 -8.53325176e-01 -1.09523155e+00 -4.36490794e-02 -2.00641432e+00
  3.81644049e-03  1.88631520e-04  1.73694606e-10  4.00813292e-02
  2.26212583e-02 -2.56083176e-03  3.63282299e-24 -5.87134734e-01
 -4.39669328e-08  2.59191954e-11 -4.18824745e-21  1.11005342e-05
  3.79635961e-01  2.13801075e+00 -8.37671327e-02  1.29141403e+00
  3.99974723e-01 -1.89465729e-04  1.32862575e-03 -7.83802604e-06
 -7.04928434e-03 -3.17504657e-29 -1.47015107e-09 -5.70751450e-32
  1.10203192e+00  1.79548248e-01  7.29105023e-02  4.99033448e-02
 -1.46191130e-01  2.79761113e+00 -5.33221102e-02  1.02428368e+00
 -1.77648760e-01  5.15118581e-03 -2.14025587e-01 -7.86862912e-03
  2.12937495e-01 -1.08465630e-01  2.27729969e-01 -1.30246934e-02
  2.24214786e+00  5.89606027e-02  5.67825318e+00  2.93033157e-02
  3.24527251e+00 -1.40574854e+01 -3.15714201e+00  7.19458282e+00
  1.39049943e+00 -9.18335592e-01 -1.14227277e+00  1.43961722e+00
  5.96912664e+00]
supnorm grad right now is: 14.057485390402718
Weights right now are: 
[ -6.65478652   8.03387588   6.76339415 -17.17962444   6.90935523
  -8.14256757  -6.36445688  16.46359606  -5.82788749   3.50202651
 -10.0468379    5.85229205  -2.84806456  31.98702633  44.28404986
  11.1966923   25.86722247  94.06003261  29.90199036   2.3410967
  45.43306045  22.13698997  35.52848511  25.59892996   4.95691199
   3.1466863   -5.08279702 -10.89612679   5.36218029 116.02422476
 148.32253451 -25.45118865 158.66442998  24.52742505  10.2275148
  16.52198564  -2.25585422   5.13633685  -5.23639116 -18.57974496
  -0.36670209   2.21831519  -3.83827788   2.94574726  -6.19525022
  63.17912813  -2.43861935  31.46192258 -11.88903915  10.00455686
  10.3505672   16.62029618  -6.10534913  70.66183893   1.09304205
  59.40160009   6.69134627   1.32224555   0.77096688  -2.33123066
   5.26410301   3.13627754   3.97584962  -2.26427898  29.30647108]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1852.614796883933
gradient value of function right now is: [-8.53837159e-01  4.61178229e-03  8.20344865e-02  3.13071333e-04
  8.53837159e-01 -4.61178229e-03 -8.20344865e-02 -3.13071333e-04
 -3.67633211e+00 -3.40405517e+00 -4.43486022e-02 -6.16309139e+00
  1.72638282e-03  3.72854701e-04  4.76280175e-10 -1.94732002e-02
  4.96264868e-03  1.39221354e-02  4.78434081e-26 -1.31289795e-02
  8.20669091e-06 -6.80298048e-11 -2.24795188e-21  1.54042682e-03
 -1.58573795e+00  6.89653063e-01  3.98508214e-02  1.88517263e-01
 -3.53659107e-01 -1.53498796e-03 -2.64147255e-04 -1.17132037e-05
 -8.30205139e-03 -8.21335405e-28 -6.68196405e-10 -1.63327466e-32
  2.21500123e+00  4.52954978e-01  5.25697507e-02  7.03817905e-02
  6.65291988e-01  4.80261949e+00  1.03711909e+00  2.21670453e+00
 -1.03524645e-01  1.07593895e-03 -3.15460243e-01  2.28960690e-03
  3.53930709e-01 -3.81861217e-02  5.06733721e-01  2.17815930e-02
  1.22292089e+00  7.22949357e-02  2.42512727e+00  6.06823228e-02
  8.56342702e-01 -3.99113954e+00 -3.28803806e+00  6.23974336e+00
 -1.13753240e-01  7.75373048e-01 -2.37307892e+00  3.60138917e+00
  1.57549820e+01]
supnorm grad right now is: 15.754982046693534
Weights right now are: 
[-6.81565961e+00  8.93247055e+00  6.57193128e+00 -1.69206930e+01
  7.07022832e+00 -9.04116224e+00 -6.17299401e+00  1.62046646e+01
 -6.07637308e+00  3.43163261e+00 -9.80210183e+00  5.48081190e+00
 -1.09366173e+00  3.03208612e+01  4.42842273e+01  1.07927539e+01
  2.64187539e+01  9.56930828e+01  2.99019904e+01  2.40448029e+00
  4.70659284e+01  2.21370102e+01  3.55284851e+01  2.65528606e+01
  4.86805304e+00  2.86395208e+00 -5.11708937e+00 -1.15730946e+01
  5.19367838e+00  1.18219173e+02  1.48613579e+02 -3.10921421e+01
  1.63079153e+02  2.45274251e+01  1.02279663e+01  1.65219856e+01
 -2.30225960e+00  4.87685594e+00 -5.28243888e+00 -1.96843102e+01
 -2.21183069e-02  2.19350275e+00 -3.54926015e+00  3.17678324e+00
 -6.45393125e+00  6.37790490e+01 -2.46347356e+00  3.02570388e+01
 -1.23568528e+01  1.18311950e+01  1.07056241e+01  1.82153371e+01
 -6.09278900e+00  7.27160015e+01  9.99620265e-01  6.06706804e+01
  6.72472361e+00  1.44500291e+00  7.34116752e-01 -2.37737021e+00
  5.34356216e+00  3.76818720e+00  3.63839046e+00 -2.02785975e+00
  2.93862900e+01]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1852.1844969479848
gradient value of function right now is: [-1.80839912e+00 -8.30728961e-02 -1.00196538e+00 -2.26029967e-03
  1.80839912e+00  8.30728961e-02  1.00196538e+00  2.26029967e-03
 -5.25575209e+00 -4.80060732e+00 -5.44087823e-02 -1.22607829e+01
  6.07938384e-03  7.13803763e-04  2.59434876e-10  3.75448499e-01
  7.78039961e-02  1.08703563e-02  4.86877423e-26  5.39616783e+00
 -1.13977850e-04 -3.28310003e-10 -2.40925134e-21 -2.08632170e-02
 -3.37203364e+00  2.25724780e+00 -6.59454920e-03  1.21413440e+00
  5.82914366e-01 -2.16573887e-03  8.98406754e-04 -4.89721652e-05
 -1.07648331e-02 -7.41826162e-30 -5.21481131e-11 -9.76324849e-34
  2.18330239e+00 -4.43681020e-01  1.01098288e-01  8.41527233e-02
  2.91921782e-01  7.51956687e+00  9.92901691e-01  3.35553544e+00
  8.69396178e-01  1.37460492e-01  1.80343883e+00  1.07189463e-01
  5.12622877e-01 -2.03396447e-01  7.27639262e-01 -9.77727134e-03
  3.87961381e+00  1.18104717e-01  7.35187587e+00  1.20081113e-01
  4.38413267e+00 -2.03204273e+01 -7.26734090e+00  2.20348911e+01
  2.04735694e+00 -1.25613060e+00 -4.62978409e+00  1.24700465e+01
  2.59429151e+01]
supnorm grad right now is: 25.942915092631598
Weights right now are: 
[ -6.90710678   8.81726431   6.71489284 -19.33896811   7.16167549
  -8.925956    -6.31595557  18.62293972  -5.98256439   3.83778102
  -9.9015254    5.41861946  -1.13096836  31.80682988  44.28429652
  11.30625677  25.69851498  96.54889329  29.90199036   2.41887772
  49.32094228  22.13706112  35.52848511  25.65819601   5.09966175
   2.88317946  -5.5256895  -11.19523307   5.59350218 115.82616103
 153.55194801 -38.00566292 168.22281071  24.52742505  10.22805266
  16.52198564  -2.03818382   4.78488104  -3.35021377 -20.25253769
  -0.31669993   2.05290212  -3.95468673   2.72668593  -6.11233732
  65.92598617  -2.05647658  31.11905895 -12.64870457  12.44295653
  10.63693647  18.60954949  -5.98591148  73.82335016   1.048918
  61.4655816    6.73579184   1.4465234    0.80106403  -2.41708109
   5.36534095   3.57504337   3.12683734  -2.10118191  29.36218991]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.0280341823504
gradient value of function right now is: [ 7.33774719e-01  7.42539841e-03  5.10442932e-01  1.71837960e-04
 -7.33774719e-01 -7.42539841e-03 -5.10442932e-01 -1.71837960e-04
  2.44186088e+00  2.40344351e+00  2.08623013e-02  5.42844065e+00
 -2.25664775e-03 -3.88589228e-04 -9.69018635e-11 -4.98584570e-02
 -8.76400798e-02 -1.87493289e-02 -2.26985342e-26 -5.09592921e+00
  8.36900565e-06  1.86956271e-10  1.29769754e-21  1.51051898e-03
  2.30453995e+00 -1.06655446e+00  9.54733313e-04 -5.93390115e-01
  8.41759799e-01  9.71181382e-04  1.43072980e-03  3.27102152e-05
  4.74481830e-03  8.22215458e-30  1.10221398e-10  6.32386494e-34
 -7.16926457e-01  1.01772314e-01 -4.77989279e-02 -1.54474404e-02
 -6.38572874e-01 -3.53808663e+00 -1.37547281e+00 -1.53043730e+00
 -3.03986404e-01 -5.52990963e-02 -6.85553229e-01 -3.36327526e-02
 -4.01404545e-01  5.44839865e-02 -5.79975919e-01 -2.40891388e-02
 -1.91699781e+00 -4.81135901e-02 -3.12127673e+00 -5.40075496e-02
 -1.96475241e+00  9.73931120e+00  2.81657185e+00 -9.59601694e+00
 -1.66220411e+00  1.64237151e+00  2.23769548e+00 -5.40935897e+00
 -1.63336232e+01]
supnorm grad right now is: 16.333623202871973
Weights right now are: 
[ -6.59394608   9.26447278   7.18310336 -19.0317384    6.84851479
  -9.37316447  -6.78416609  18.31571002  -5.63375675   4.10148902
 -10.37143011   5.69043877  -0.5861359   33.84475544  44.28442073
  10.82913935  26.11292073  97.28480641  29.90199036   2.30047079
  50.69118241  22.13709031  35.52848511  25.37913085   5.10999816
   2.51184249  -5.28493035 -11.36293145   5.70950988 117.66225608
 156.8676415  -38.64699251 171.93026926  24.52742505  10.22806082
  16.52198564  -2.33374854   5.27081041  -2.76539206 -19.17777136
  -0.49944798   2.14827474  -4.25106775   3.09284169  -5.92872921
  67.79452008  -2.06801977  30.61639757 -13.02661087  12.76002615
  10.85644411  18.75724772  -5.931536    75.31884542   1.05588713
  62.26640093   6.5478631    1.51585609   0.7568827   -2.41631136
   5.47372383   3.51231863   3.31814382  -2.15886059  29.12078582]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1847.425677549389
gradient value of function right now is: [ 1.09388111e+00  9.22461040e-03  8.47057590e-01  9.57762442e-05
 -1.09388111e+00 -9.22461040e-03 -8.47057590e-01 -9.57762442e-05
  2.93816865e+00  3.31915389e+00  2.26506270e-02  8.47252419e+00
 -3.55906159e-03 -6.65771830e-04 -4.59314219e-11 -7.34638399e-02
 -2.13017357e-01 -2.58180754e-02 -7.73643087e-27 -8.74207240e+00
  6.91825457e-06  1.51897874e-09  1.81226673e-21  1.42175226e-03
  3.86253724e+00 -3.28206047e+00  5.22455982e-02 -1.90203883e+00
  8.77393349e-01  3.80655442e-03  3.07045754e-03  1.62214991e-04
  4.06803703e-03  1.21913424e-30  3.21381634e-11  7.56968224e-35
 -2.05682897e+00  1.00106359e-01 -8.43453722e-02 -3.25060121e-02
 -6.89429070e-01 -7.11038134e+00 -2.28434659e+00 -1.81132222e+00
 -4.74981818e-01 -1.24267480e-01 -1.15401502e+00 -6.15307641e-02
 -7.49728199e-01  1.39776097e-01 -1.03495576e+00 -3.91308540e-02
 -5.63569299e+00 -1.64101782e-01 -9.32838468e+00 -1.59647603e-01
 -5.30620233e+00  2.24503133e+01  8.59887777e+00 -2.69074942e+01
 -3.69913842e+00  3.34663559e+00  4.67242580e+00 -1.48222976e+01
 -2.76541389e+01]
supnorm grad right now is: 27.654138917839
Weights right now are: 
[ -6.71166423   8.38772505   7.48110096 -22.59665393   6.96623294
  -8.49641674  -7.08216369  21.88062555  -5.83759408   3.62785903
  -9.7932419    5.73841124  -1.70081815  35.11700435  44.28446008
  10.81095291  25.5284701   99.1853997   29.90199036   2.10005575
  51.74870964  22.13729324  35.52848511  22.88204803   5.05758474
   2.62781862  -4.51313586 -11.46396708   5.46831342 115.81683192
 158.73877034 -48.40923342 175.91525143  24.52742505  10.22814284
  16.52198564  -2.61973676   4.75917366  -3.48545851 -20.4065187
   0.32639187   2.11132911  -3.79899394   3.13365761  -6.11381092
  68.84330274  -2.19272713  30.26422846 -13.24767929  13.16974159
  11.73562303  20.64030735  -5.80235662  77.06754361   0.72412718
  63.18950288   6.72246969   1.74822135   0.60602566  -2.47168531
   5.36402231   3.51089138   3.89472099  -2.12127411  29.17183185]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1847.050610533119
gradient value of function right now is: [ 7.67192257e-01  5.99048769e-03  1.02037310e+00  8.33293787e-05
 -7.67192257e-01 -5.99048769e-03 -1.02037310e+00 -8.33293787e-05
  3.23618590e+00  2.69907990e+00  1.53976446e-01  5.59910736e+00
 -7.49939057e-04 -7.66379760e-05 -1.13039184e-10 -4.18323529e-02
 -1.46313280e-01 -1.52811851e-02 -8.77692934e-27 -1.07081418e+01
  2.03267567e-06  3.14506611e-10  1.10642693e-21  1.28764312e-03
  4.31754447e+00  1.74336037e+00  1.03315725e-01  8.77745721e-01
  8.07180598e-01  3.47590738e-03  9.07900367e-04  7.35301024e-05
  1.28613018e-02  3.11699981e-31  2.42035299e-11  2.45718854e-36
  8.27751419e-01  5.46290932e-01  5.92356203e-03  2.32994088e-02
 -7.36541288e-01 -4.32264339e+00 -1.53211360e+00 -2.90299881e+00
 -4.88980109e-01 -1.19022761e-01 -1.47731787e+00 -6.35905214e-02
  1.74777289e-01  3.62639741e-02  2.05217479e-01  5.50008381e-03
  1.70849703e+00  6.78822410e-02  4.16274898e+00  4.14226536e-02
  1.49375585e+00 -7.12470930e+00  1.78332470e+00  4.38433282e-01
 -1.93265221e+00  2.52853214e+00  9.49821887e-01  3.61344396e+00
 -1.73143560e+01]
supnorm grad right now is: 17.31435598033972
Weights right now are: 
[ -6.44400689   8.42200245   7.2727064  -23.62767372   6.6985756
  -8.53069414  -6.87376913  22.91164534  -5.62810477   4.14146102
  -8.65261769   5.9646907   -2.09090617  34.93421666  44.284473
  11.40914816  24.86097446  99.77826004  29.90199036   2.13768036
  54.23333819  22.13747164  35.52848511  23.31099778   5.24271855
   3.17713624  -5.21016724 -11.51499789   5.40780593 114.24598481
 161.80978118 -54.47834362 179.65712712  24.52742505  10.22837362
  16.52198564  -2.88376252   4.38446628  -2.86827326 -20.07355325
   0.50696898   2.14433725  -3.86215858   2.81925293  -5.80431062
  69.9678919   -3.26172756  30.4213796  -13.33147689  12.65753969
  11.99920503  19.88372126  -5.82201361  79.33754915   0.84862898
  64.41613035   6.97011169   1.44130779   0.69985518  -2.44234066
   5.55422354   3.8292447    3.47682628  -2.15643524  29.10324399]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1851.4901935144403
gradient value of function right now is: [ 4.85625404e-01 -1.06060282e-03 -7.47668702e-01 -2.03378589e-07
 -4.85625404e-01  1.06060282e-03  7.47668702e-01  2.03378589e-07
  2.44324798e+00  2.19501672e+00 -9.00963431e-03  3.82866746e+00
 -2.31620603e-04 -3.39510750e-05 -8.86181371e-12  1.33175219e-02
  1.36011662e-02  6.92485110e-03 -8.51696189e-28  6.77691490e+00
 -1.24977666e-08 -1.96938554e-11  3.67936068e-23 -5.54325423e-06
  5.12506194e-01 -7.18386356e-01 -9.09962844e-02 -1.26561536e-01
 -1.20082647e+00 -3.18369846e-04 -2.60519224e-03  9.57287763e-06
  6.84852566e-04  3.18169128e-30  4.28145283e-11  2.72212032e-35
 -3.36277664e+00 -1.90818986e+00 -2.56016186e-01 -1.57723886e-01
 -5.05918917e-02 -2.59026152e+00 -1.65203065e-01 -8.12700631e-01
  6.82239474e-01  4.30377323e-02  9.51613180e-01  4.43890334e-02
 -8.76593830e-01  8.51372546e-02 -1.03869965e+00 -2.14598985e-02
 -2.65442501e+00 -1.27545228e-01 -3.71731628e+00 -1.21636271e-01
 -6.97632149e-01  7.41980336e+00  2.21870063e+00 -9.86500929e+00
 -9.38737951e-01  9.35989095e-02  1.91517586e+00 -8.57100525e+00
 -9.92464891e+00]
supnorm grad right now is: 9.924648910512357
Weights right now are: 
[ -6.71545694   9.38894254   6.82025506 -22.47538645   6.97002565
  -9.49763423  -6.42131779  21.75935807  -5.62073839   3.9361191
 -10.08676212   6.04640028  -0.64832134  37.30950283  44.28448181
  11.55064953  25.99110466 100.92025318  29.90199036   2.26191927
  57.78549926  22.13751626  35.52848511  24.918206     4.93032724
   3.22097488  -4.7795215  -10.79865041   4.95249959 115.34198926
 165.35195369 -59.29365518 183.19404321  24.52742505  10.22843325
  16.52198564  -3.38848421   4.2595707   -3.54469678 -18.31201494
   0.64776528   2.34032744  -3.85592953   2.99651694  -5.01561984
  70.26200573  -2.921263    31.06111176 -14.18005879  13.56213041
  11.55528377  20.01490734  -5.53910831  81.23086768   0.9569934
  64.63505684   6.78352894   1.52098865   0.62277491  -2.49622259
   5.13570999   3.31897861   3.38110153  -2.2383756   29.14572179]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.2153473766964
gradient value of function right now is: [ 2.68360231e-01 -3.79045764e-03 -1.22191171e-01 -9.75777400e-05
 -2.68360231e-01  3.79045764e-03  1.22191171e-01  9.75777400e-05
  1.45254532e+00  1.12632723e+00  2.13198887e-02  2.18344677e+00
 -6.47101074e-05 -3.76849560e-05 -1.26613434e-11  2.38628588e-02
  4.14084990e-03 -2.24392134e-03 -6.35769757e-28  7.97730139e-01
 -6.87512130e-06  2.15682799e-10  7.73262610e-23 -1.94013111e-03
  9.99108286e-01  6.59762363e-01  4.72112539e-02  4.44055105e-01
 -7.86112486e-02  2.12070114e-04 -5.19261559e-04  1.18522219e-05
  2.23076539e-03  1.49581264e-32  4.74128182e-13  1.34586710e-37
 -7.16601422e-01 -1.95586994e-01  4.41276519e-02 -3.44083566e-02
 -2.92580519e-01 -1.32769671e+00 -3.40770993e-01 -7.44065171e-01
  1.16292266e-02  5.23864817e-03  2.51268030e-01  1.39645020e-03
  3.47473990e-01  2.05639535e-02  4.13792339e-01  1.76914449e-02
  1.25978549e+00  1.74922553e-02  1.19389809e+00  4.35084412e-02
  5.76595226e-01 -4.70146908e+00  6.41862334e-01  3.32111562e+00
  3.83896094e-01 -4.41767111e-01  3.90605523e-01  5.09525054e+00
 -5.41152125e+00]
supnorm grad right now is: 5.411521254897687
Weights right now are: 
[ -6.80721276   8.95976156   7.01688121 -28.52312368   7.06178147
  -9.06845325  -6.61794394  27.8070953   -5.7703532    4.10214504
  -9.39783817   5.84328236  -2.2438106   37.61199198  44.28448599
  11.2591751   25.06272931 102.30352997  29.90199036   2.19772285
  59.74888268  22.13760107  35.52848511  21.49129861   4.94042085
   3.24015594  -5.65683448 -11.05596516   5.57022525 114.71647911
 168.51628416 -63.54206609 187.75773673  24.52742505  10.22850004
  16.52198564  -2.75207759   4.74170934  -2.0128526  -18.53060672
   0.30731725   2.08269544  -4.03406135   2.90503593  -5.17226401
  72.02679965  -2.55970976  31.7889469  -14.26023292  14.55019169
  12.0088392   22.98986943  -5.84899714  82.77057003   0.76462793
  65.10969731   6.87773696   1.49101535   0.99259863  -2.44772771
   5.62202021   3.31558136   3.48885385  -2.01902587  29.11467426]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.3769665913467
gradient value of function right now is: [ 5.30246037e-01  9.62091346e-03  6.76051798e-01  4.89793510e-05
 -5.30246037e-01 -9.62091346e-03 -6.76051798e-01 -4.89793510e-05
  1.18063064e+00  1.19205841e+00  9.59487051e-03  4.51146314e+00
 -7.46578144e-03 -6.42339675e-04 -9.66189226e-12 -1.02714637e-01
 -1.70804869e-01 -1.70898220e-02 -9.03312364e-28 -7.01904864e+00
  3.52528086e-06  1.45818290e-09  6.94021098e-24  1.11990048e-03
  3.02675054e+00 -1.78405711e+00 -4.88156321e-02 -1.08744285e+00
  8.26492144e-01  1.40716063e-03  3.87142654e-03  2.32563815e-05
  8.23006130e-04  8.34149520e-33  6.31084683e-13  1.71449731e-38
 -7.55002882e-01  5.79708365e-02 -1.06332213e-01 -3.50388674e-02
 -7.56155275e-01 -3.48936980e+00 -1.83772539e+00 -1.18873940e+00
 -4.22269617e-01 -8.38065992e-02 -9.84138319e-01 -4.98741008e-02
 -9.48408849e-01 -4.44160339e-02 -1.22099201e+00 -5.30119186e-02
 -3.41595119e+00 -8.95504417e-02 -5.03757661e+00 -9.68604186e-02
 -2.81486210e+00  1.56092328e+01  5.29017094e+00 -1.67598687e+01
 -2.40810137e+00  2.20895276e+00  2.95095391e+00 -1.06673188e+01
 -1.61672630e+01]
supnorm grad right now is: 16.759868746999533
Weights right now are: 
[ -6.94381733   9.35306265   7.44584298 -29.26223645   7.19838604
  -9.46175434  -7.04690571  28.54620807  -6.10658418   3.80412192
 -10.03622006   5.8680888   -3.46813768  39.0760587   44.28448788
  10.20761486  25.04853436 102.69063382  29.90199036   2.08753426
  63.0554302   22.1378652   35.52848511  21.7057089    4.98607315
   3.13420612  -5.98206588 -11.1859841    6.2680518  117.09822814
 171.07502545 -69.61723637 191.08676606  24.52742505  10.22850167
  16.52198564  -2.72695351   4.53970654  -4.1340152  -17.83095375
   0.44547284   1.99199224  -3.7015953    3.01457948  -5.65625692
  72.04850852  -2.75545911  30.551613   -14.81416081  13.40241228
  12.41415562  22.19831819  -5.91724078  84.00533726   0.93908729
  64.88015996   6.49307452   1.57476266   1.06200723  -2.53112776
   5.15552947   3.14061928   3.41637171  -2.30525727  29.42231518]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1852.412348268532
gradient value of function right now is: [ 3.49546610e-01  2.06922683e-03 -2.14404795e-01  2.04610794e-04
 -3.49546610e-01 -2.06922683e-03  2.14404795e-01 -2.04610794e-04
  1.06814399e+00  1.65227029e+00  4.53346730e-02  2.08344837e+00
 -3.24924798e-04 -4.49337420e-05 -3.89186369e-13 -8.92931748e-03
  4.27218628e-02  9.50811886e-04 -8.69732842e-29  2.69825169e+00
  1.67030214e-05 -4.95029041e-10  6.52503658e-24  3.45384580e-03
 -2.13611195e+00 -3.88365776e+00 -6.37264706e-02 -2.26955414e+00
 -5.76725728e-01  3.27657372e-04 -1.47372086e-03  1.02822150e-05
  4.59653968e-03  1.16718015e-33  1.33885226e-12  1.46813028e-38
 -1.93712325e+00 -6.58373892e-01 -7.52871012e-02 -1.40405509e-01
  3.27437254e-01 -2.76647939e+00  4.33199099e-01 -1.12514024e+00
  2.82246921e-02 -2.06839898e-02  6.23855562e-02 -1.10668295e-02
 -5.51347594e-01  8.25009292e-02 -6.97179247e-01 -8.55829440e-03
 -5.39511758e+00 -1.97120073e-01 -9.37650543e+00 -1.76556880e-01
 -4.45049984e+00  2.22133109e+01  5.16708314e+00 -2.38967003e+01
 -1.89243410e-01 -1.37825334e+00  2.87990701e+00 -1.50396867e+01
 -8.05707074e+00]
supnorm grad right now is: 23.896700298466
Weights right now are: 
[ -7.14959527   8.01455117   7.44400604 -30.98005439   7.40416398
  -8.12324286  -7.04506877  30.26402601  -5.59781908   3.86824817
  -9.79043396   5.68991096  -0.73564772  42.06832625  44.28448944
  12.42379575  27.1197275  103.85145204  29.90199036   2.23901337
  65.9123461   22.13795241  35.52848511  20.61663059   4.70882059
   3.21273444  -5.13191457 -10.37714713   5.57315258 120.94952121
 174.72156669 -70.5595273  194.66650177  24.52742505  10.22850862
  16.52198564  -2.44588951   4.6715872   -5.15270839 -17.26699793
   0.49460608   2.1911032   -3.87100356   2.72499278  -5.57274589
  73.80544096  -3.13168203  30.62549091 -14.32535762  12.99619401
  12.9374005   23.10868661  -6.09428158  85.15467165   0.60091679
  64.90733737   6.58643238   1.49448422   0.73711449  -2.5687933
   5.15862822   2.74600412   3.47863891  -2.24096478  29.29188821]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.6587516764876
gradient value of function right now is: [-1.69935855e-01 -6.63244324e-03 -6.32613295e-02 -2.08307176e-04
  1.69935855e-01  6.63244324e-03  6.32613295e-02  2.08307176e-04
 -8.93680758e-01 -8.56245298e-01 -3.03033065e-02 -1.10335446e+00
  3.08485037e-04 -1.22017450e-05  6.09656591e-13  3.42498715e-02
  1.85984260e-02  3.95695335e-03  3.81326859e-29  6.09395303e-01
 -2.96125971e-05 -1.22380022e-10 -1.34022169e-25 -3.32364191e-03
 -5.73476601e-01 -1.65618057e-01  1.64416374e-02 -1.45356352e-01
 -2.47289732e-01 -2.61580197e-04 -1.21245728e-03 -1.41365956e-06
 -4.30212699e-03 -1.05513841e-32 -1.13318574e-12  1.44764860e-39
  6.61851392e-02  9.52142092e-02  1.17548300e-02  1.46456162e-02
  3.32364299e-01  1.05931773e+00  4.88921200e-01  9.17586338e-01
 -1.11776302e-01 -6.80845185e-03 -1.24546453e-01 -7.35740517e-03
  9.43298086e-02  4.86395986e-02  1.27054704e-01  1.37603779e-02
 -2.48040753e-02  6.57522175e-03 -2.70464875e-01  6.71797101e-03
 -1.72239675e-01  8.41415346e-01 -3.62604007e-01  5.53215790e-02
  4.43147082e-02  6.49599987e-02 -3.91260337e-01 -1.69174057e-01
  2.59725135e+00]
supnorm grad right now is: 2.597251353216171
Weights right now are: 
[-7.26569070e+00  1.02796955e+01  7.12306349e+00 -2.88306254e+01
  7.52025941e+00 -1.03883872e+01 -6.72412623e+00  2.81145970e+01
 -5.80890824e+00  3.78932310e+00 -1.06776071e+01  5.76113419e+00
 -8.52920087e-02  4.04033182e+01  4.42844899e+01  1.13163156e+01
  2.68328217e+01  1.05163336e+02  2.99019904e+01  2.24006119e+00
  6.91824359e+01  2.21380727e+01  3.55284851e+01  2.34495381e+01
  4.80748124e+00  3.01750009e+00 -5.26496635e+00 -1.06169336e+01
  5.76523488e+00  1.23312347e+02  1.78507175e+02 -7.72120606e+01
  1.97846519e+02  2.45274251e+01  1.02285140e+01  1.65219856e+01
 -2.57321141e+00  4.87234768e+00 -3.02848265e+00 -1.73417944e+01
  7.34896089e-01  2.14809111e+00 -3.81147855e+00  3.23050881e+00
 -5.99317058e+00  7.53441654e+01 -2.53618493e+00  2.93653056e+01
 -1.50753478e+01  1.40555115e+01  1.25379519e+01  2.21818262e+01
 -5.97508055e+00  8.62556817e+01  7.83318994e-01  6.56704261e+01
  6.47788070e+00  1.47801534e+00  7.31621529e-01 -2.47944432e+00
  5.19151950e+00  3.11689674e+00  3.70657556e+00 -2.18153353e+00
  2.92311964e+01]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.4689715314869
gradient value of function right now is: [-2.51784424e-01 -1.22983962e-03  2.02234174e-01 -1.69055684e-05
  2.51784424e-01  1.22983962e-03 -2.02234174e-01  1.69055684e-05
 -1.20461277e+00 -1.15498590e+00 -5.44339575e-02 -1.79882998e+00
  8.97680643e-04  9.74255032e-05  2.60956231e-12  7.75307883e-03
 -1.83052814e-02 -8.48016970e-04  5.13638203e-29 -2.27552490e+00
 -1.84467828e-06 -3.95773127e-11 -1.65198772e-25 -4.01788852e-04
  4.11940023e-01  1.06946957e+00  3.89957423e-02  3.92436139e-01
  3.30847270e-01 -2.00041980e-04 -2.12277302e-04 -1.21512321e-06
 -6.83256631e-03 -1.75176572e-32 -9.04447238e-12 -8.61723203e-39
  1.12282518e+00  5.89984636e-01  6.05938739e-02  1.02676733e-01
 -9.36978048e-02  2.10774849e+00 -9.21961467e-02  1.24478958e+00
 -1.88073212e-01 -4.47785648e-03 -3.56075169e-01 -3.71497764e-03
  2.97704635e-01 -8.65496268e-03  3.85782188e-01  8.11757314e-03
  1.99155132e+00  1.00203365e-01  3.78476430e+00  7.45473841e-02
  1.75603256e+00 -7.84218519e+00 -3.05889360e+00  1.09686162e+01
  6.81790923e-03  7.99485151e-01 -1.75123686e+00  5.41432542e+00
  6.25008882e+00]
supnorm grad right now is: 10.968616202673866
Weights right now are: 
[ -7.14798777   9.63001722   7.58019686 -30.71979404   7.40255648
  -9.73870891  -7.18125959  30.00376565  -5.73188207   4.04408576
 -10.54031373   5.72060114  -1.41765289  39.98027161  44.28449269
  10.75001043  26.50514188 105.71183345  29.90199036   2.21333373
  71.22143569  22.13814417  35.52848511  21.98106492   4.98987973
   2.87747354  -5.08922865 -11.0337831    5.78777436 126.67212421
 182.6954821  -77.02575343 200.2404507   24.52742505  10.22851529
  16.52198564  -2.7615764    4.80395356  -3.58528292 -18.39097224
   0.28193375   2.33431324  -3.91478809   3.1354658   -5.49512796
  76.38771416  -2.46655971  29.74434954 -15.1786235   12.79294339
  12.86928113  21.42757365  -6.37157363  87.39679291   0.91426284
  65.92499996   6.6197022    1.52535934   0.86198655  -2.41301909
   5.15126071   3.20694837   3.38672076  -2.2022495   29.33798396]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1852.6608229470755
gradient value of function right now is: [-2.28414659e-01  1.99174922e-03  5.78327899e-01  6.04961759e-05
  2.28414659e-01 -1.99174922e-03 -5.78327899e-01 -6.04961759e-05
 -4.25821382e-01 -7.97635737e-01 -4.90682754e-02 -1.71772216e+00
  1.32551225e-03  1.75504490e-04 -2.66937792e-12 -1.13456200e-02
 -1.99756455e-02 -3.74059436e-03  7.65946310e-30 -5.83378254e+00
  4.39286986e-06  1.09371135e-10  2.25694181e-26  1.21702959e-03
  1.70008331e+00  3.56118363e+00 -4.42161142e-02  1.71349305e+00
  7.51451775e-01  5.40413310e-04  1.23696453e-03  2.05824754e-06
 -4.26334403e-03 -4.21674489e-33 -1.26581665e-12 -4.37058023e-38
  2.88679587e+00  9.72369818e-01  1.21834718e-01  1.29452102e-01
 -4.29242102e-01  2.60172841e+00 -2.97737359e-01  8.41002802e-01
 -4.87004914e-01 -2.11513366e-02 -6.98647147e-01 -3.87155864e-02
  5.34423141e-01 -1.40287724e-01  6.53703056e-01  5.45244315e-03
  4.70573713e+00  1.10635589e-01  1.05968154e+01  1.62383862e-01
  4.70765634e+00 -2.43730773e+01 -2.84870590e+00  1.31719668e+01
  2.31996219e+00 -1.58732347e+00 -2.46085473e+00  1.38457532e+01
  6.93072980e+00]
supnorm grad right now is: 24.373077287342554
Weights right now are: 
[ -6.96026495   8.81776272   7.4789139  -31.77935283   7.21483366
  -8.92645441  -7.07997663  31.06332445  -5.65026896   4.15748413
  -9.03585245   6.01311539  -1.6689839   38.07713242  44.28449399
  12.1751329   27.28650628 106.42941283  29.90199036   2.2027527
  74.54738269  22.13824459  35.52848511  22.40309638   4.93981903
   2.69550072  -5.70114235 -10.96496262   6.00890476 131.30341232
 183.9182057  -77.7900729  203.58843728  24.52742505  10.22852791
  16.52198564  -2.53288005   4.48933696  -3.29317199 -19.38641781
   0.55934748   2.53534681  -4.01570515   2.85182612  -5.60023827
  76.8625046   -2.44222823  29.08768882 -15.57158872  13.52857959
  12.75066872  23.4702436   -5.94666806  88.50891687   0.98991031
  66.79506406   7.29176598   1.33899967   0.76653467  -2.66419382
   5.6466326    3.16968694   3.40329009  -2.10625261  29.2803222 ]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.4668132493455
gradient value of function right now is: [ 7.51635975e-02 -2.32743670e-04 -9.48407511e-02  1.26989189e-05
 -7.51635975e-02  2.32743670e-04  9.48407511e-02 -1.26989189e-05
  3.03945627e-01 -1.47110349e-03 -5.41027131e-02  9.61467909e-01
 -1.80239502e-04 -3.27824837e-05 -4.91002153e-13  2.86592468e-03
 -1.58803118e-02 -3.88150203e-03 -3.47596783e-30  7.09295272e-01
 -2.91109141e-07  1.74348406e-10  1.25379928e-27  2.02918510e-04
  9.79423658e-01  3.55120819e-01  6.57497042e-02  2.91918165e-01
  2.14715352e-01  2.45688366e-04 -1.87977952e-04  5.69005137e-06
 -4.13539349e-03  8.89132261e-34  2.15105656e-12  3.39336521e-38
 -7.20731689e-01 -4.91000177e-01 -1.82724635e-02 -7.59434087e-02
 -2.27989281e-01  1.38875690e-01 -5.00064137e-01  4.59115083e-01
 -1.08919484e-01 -1.45015662e-02 -1.00740650e-01 -1.27564542e-02
  1.30656584e-01  3.17979634e-02  1.36830197e-01  5.21863969e-03
 -5.46790003e-02 -2.26397277e-02 -3.65087227e-01 -1.30029944e-02
  2.04692746e-03 -3.25084129e-01  1.21459051e+00 -3.58178303e+00
 -2.76592730e-01  4.13265099e-01  3.59732136e-01 -1.82120727e+00
 -2.64671653e+00]
supnorm grad right now is: 3.5817830317275483
Weights right now are: 
[ -7.09466382   8.7676104    7.47668392 -32.36279283   7.34923253
  -8.87630209  -7.07774665  31.64676445  -5.80563127   4.09079225
  -8.21542078   6.00211139  -1.32564812  35.45668163  44.28450021
  12.34963258  26.48008181 107.38358438  29.90199036   2.39864509
  77.31685645  22.13831115  35.52848511  22.45915577   5.26155476
   2.87379338  -5.64064885 -10.51294821   6.04392283 132.09192437
 189.06648656 -81.61936107 206.83745661  24.52742505  10.22857378
  16.52198564  -2.89901275   4.30738702  -2.96487933 -18.39801228
   0.72028976   2.56919503  -4.23319155   3.05629608  -5.63968413
  78.03683446  -3.13979409  28.40168948 -15.57235147  13.69435789
  13.05196735  23.83825364  -5.57523331  90.11861406   0.88374922
  67.67133264   6.87208758   1.61146535   0.82353402  -2.5733342
   5.51403444   3.35777714   3.70641677  -2.19277572  29.25415264]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.9499573220182
gradient value of function right now is: [ 1.31105075e-01 -1.07603105e-02 -3.23206671e-01 -5.68092834e-04
 -1.31105075e-01  1.07603105e-02  3.23206671e-01  5.68092834e-04
  7.59637001e-01  6.96348372e-01 -2.00940154e-02  1.18907348e+00
 -3.72268700e-04 -2.46075366e-05 -4.15348218e-12  4.57618846e-02
  5.40549031e-02  6.06295795e-03 -2.06034697e-30  3.47332944e+00
 -7.93207877e-05 -2.18455755e-10  7.59332813e-28 -9.14622743e-03
 -1.02849842e+00 -9.47123529e-01  2.61921597e-02 -3.58172514e-01
 -8.03983910e-01 -8.95382325e-04 -9.63773070e-04 -5.28036244e-06
 -1.45607618e-03 -3.51559978e-34  4.44908428e-12  1.72333531e-39
 -1.25216149e+00 -2.86413435e-01 -5.47766424e-03 -6.56621851e-02
  2.39681033e-01 -6.66400835e-01  4.98305318e-01  1.29849016e-01
  5.09161576e-02  1.30806884e-02  1.57148105e-01  1.03932749e-02
  1.08910145e-01  4.33991508e-02  1.38445766e-01  1.48877893e-02
 -9.38518610e-01 -4.21617618e-02 -2.88430613e+00 -2.26778707e-02
 -1.14117135e+00  4.55161355e+00  1.97364186e+00 -4.38670714e+00
  1.99522786e-01 -5.33598843e-01  8.97375311e-01 -1.50519859e+00
 -4.11451158e-01]
supnorm grad right now is: 4.551613554547264
Weights right now are: 
[-7.15992183e+00  9.33751298e+00  7.38661236e+00 -3.21760464e+01
  7.41449054e+00 -9.44620467e+00 -6.98767509e+00  3.14600180e+01
 -6.01315428e+00  4.16009630e+00 -9.17424795e+00  6.07124734e+00
 -1.86459744e+00  3.73957784e+01  4.42845057e+01  1.17023413e+01
  2.77937982e+01  1.09083178e+02  2.99019904e+01  2.60366110e+00
  8.10991639e+01  2.21383859e+01  3.55284851e+01  2.29765967e+01
  4.89996145e+00  2.28528573e+00 -4.96249922e+00 -1.10374499e+01
  5.58183334e+00  1.33445127e+02  1.92114887e+02 -8.09658833e+01
  2.10314816e+02  2.45274251e+01  1.02285742e+01  1.65219856e+01
 -2.73474967e+00  4.71038432e+00 -3.78827147e+00 -1.82760705e+01
  1.32787482e-01  2.41315133e+00 -3.78619969e+00  3.01460009e+00
 -5.62828773e+00  7.88771143e+01 -3.05109788e+00  2.78070232e+01
 -1.55787483e+01  1.34968625e+01  1.34413877e+01  2.28252982e+01
 -5.90930213e+00  9.12018457e+01  9.28640092e-01  6.76565917e+01
  7.12591095e+00  1.47529576e+00  1.04009929e+00 -2.54390308e+00
  5.64856285e+00  3.63377342e+00  4.01570383e+00 -2.14574182e+00
  2.92943677e+01]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1852.1830684876918
gradient value of function right now is: [-7.50030211e-01  3.47167086e-03  6.69718771e-01  7.99548881e-05
  7.50030211e-01 -3.47167086e-03 -6.69718771e-01 -7.99548881e-05
 -3.98650594e+00 -3.57523165e+00 -7.54115259e-02 -5.70360782e+00
  1.36202518e-03  1.52684311e-04  1.02605642e-11 -2.61079253e-02
 -5.05154209e-02 -4.23755095e-03  1.60703283e-29 -6.59534888e+00
  3.33194604e-06  1.97376574e-10 -5.55369229e-28  1.52249951e-03
  7.00554533e-02  1.40829097e+00  1.24842232e-02  4.48412156e-01
  1.23040509e+00  9.31090402e-05  8.33153775e-04 -4.55231141e-07
 -9.83373718e-03 -2.09560802e-32 -1.10088582e-11 -7.33034938e-39
  3.72975916e+00  1.19971599e+00  8.00551831e-02  1.61858267e-01
 -1.37737728e-01  4.49268596e+00 -2.54349003e-01  2.28987394e+00
 -4.11706927e-01 -3.98869015e-02 -8.81190605e-01 -2.42332835e-02
  1.36793699e-01 -8.34522692e-02  1.86223857e-01 -1.21307100e-02
  2.23496795e+00  1.25157283e-01  5.19298225e+00  6.25236847e-02
  2.46612872e+00 -9.20880427e+00 -5.30074290e+00  1.17877997e+01
 -8.23749416e-02  1.53576670e+00 -2.77831274e+00  3.23634455e+00
  1.22993766e+01]
supnorm grad right now is: 12.299376584871357
Weights right now are: 
[ -7.4354352    9.85954021   7.63689876 -32.85284633   7.69000392
  -9.9682319   -7.23796149  32.13681794  -6.0594089    4.05831602
 -10.1006079    5.82595965  -2.28478517  39.22633851  44.28451053
  11.60917709  27.55461858 109.38385656  29.90199036   2.28059852
  84.61081267  22.13841813  35.52848511  23.09073872   5.09784074
   2.74322521  -4.73427923 -10.91397004   6.17060441 129.42213705
 198.24315229 -81.98424124 214.05499107  24.52742505  10.22857737
  16.52198564  -2.24003377   4.12595079  -2.2143069  -19.65508198
   0.66449985   2.50250053  -4.02495859   2.99196688  -5.68278978
  80.19447359  -2.91121813  27.21922492 -15.83923475  13.59736363
  13.14810854  23.1063981   -5.92149828  91.89391606   0.94049178
  67.48345025   6.8464793    1.65831905   0.57110558  -2.46420929
   5.63262058   3.41674544   3.11534803  -2.36862271  29.27204421]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.747307558939
gradient value of function right now is: [-1.00452362e-01 -1.19744520e-03 -4.04073974e-02 -1.52915367e-05
  1.00452362e-01  1.19744520e-03  4.04073974e-02  1.52915367e-05
 -4.11926833e-01 -4.72997989e-01  1.41814809e-02 -7.82975752e-01
  1.74517929e-04  1.22095727e-05  3.49612657e-14  9.36278778e-03
  1.16269641e-02  4.91262148e-03  6.38117678e-31  3.22616958e-01
 -1.80770818e-06 -1.63914986e-10 -7.55590384e-30 -4.00316510e-04
 -3.29552225e-02  7.49587037e-01  8.89760313e-02  3.20810555e-01
 -3.21140107e-01 -6.28315914e-04 -1.07918930e-03 -8.79942391e-06
 -6.11838055e-04 -5.35274982e-35 -2.72979973e-13  6.11328306e-42
  3.51776207e-01  3.20934087e-01  1.50372987e-02  6.38492048e-02
  7.77752442e-02  6.54432917e-01  2.86777574e-01  2.27529251e-01
 -3.59811204e-02  7.85582248e-03 -9.15315713e-02  5.24379698e-03
  1.74944970e-01  2.72366228e-02  2.62093500e-01  9.85211089e-03
  1.34195262e+00  5.73308416e-02  2.54238793e+00  3.98683434e-02
  1.24422212e+00 -5.28199948e+00 -2.44295381e+00  8.10642767e+00
  1.99146319e-02  2.28738204e-01 -9.39809195e-01  3.85423105e+00
  2.92378975e+00]
supnorm grad right now is: 8.106427674005316
Weights right now are: 
[ -7.32297727   9.53654005   7.52937692 -33.77650078   7.57754598
  -9.64523174  -7.13043965  33.0604724   -6.04501459   4.12170669
  -8.1697283    6.02595392  -0.83837964  40.46541351  44.28451297
  12.34595778  28.21838659 109.76721007  29.90199036   2.27957339
  86.62812452  22.13846105  35.52848511  22.93900954   5.09547642
   2.74189355  -3.4632785  -10.82848921   5.72368159 129.05424276
 203.03928916 -85.31379119 216.963678    24.52742505  10.22859116
  16.52198564  -2.73161828   4.76872164  -4.22755466 -18.19117903
   0.79441      2.46031311  -3.84975479   2.62973437  -5.58420023
  81.57061896  -2.69766502  28.1323141  -16.01744227  14.00354043
  12.83313558  22.89376172  -5.78932359  93.64993142   0.83647958
  68.73411922   6.7950839    1.59218852   0.71227138  -2.49785904
   5.64783279   3.56372102   3.67790981  -2.18944877  29.20699089]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.9334605012275
gradient value of function right now is: [ 3.74946801e-02 -6.08186559e-04  7.08248526e-03 -3.06487158e-06
 -3.74946801e-02  6.08186559e-04 -7.08248526e-03  3.06487158e-06
 -1.97922920e-03 -8.56823394e-02 -3.31386068e-02  5.29685711e-01
 -3.58619832e-04 -5.88112015e-05  3.96611393e-13  3.89693625e-03
 -6.15610599e-03 -3.33114175e-04  1.04784428e-31 -1.39502691e-01
 -9.15253238e-07  1.92378666e-12 -2.79618710e-31 -9.82895670e-05
  3.99998612e-01 -2.91191311e-02  4.67619226e-02 -4.74469695e-02
 -6.74212331e-02  1.14202315e-04 -6.13343732e-04  6.95036100e-06
 -3.01147981e-03 -3.30199154e-34  4.62660497e-13  3.54676352e-40
 -2.92227491e-01 -1.33660572e-02  7.72354200e-03 -1.32217467e-02
 -2.48481456e-02  9.00299036e-02 -1.17841687e-01  4.50415154e-01
 -1.36959789e-01 -1.42212844e-02 -1.92017782e-01 -1.12916819e-02
  1.09942945e-01  4.45217069e-02  1.23585489e-01  9.36196566e-03
 -6.52259583e-02 -1.50699231e-03 -2.96548981e-01  2.04838231e-03
 -1.81224043e-01  8.20677405e-01  5.95621439e-01 -1.38442333e+00
 -2.09805426e-01  3.45699505e-01  1.17472146e-01 -3.61236267e-01
 -1.56742809e+00]
supnorm grad right now is: 1.5674280900816204
Weights right now are: 
[-7.45411910e+00  1.02617830e+01  7.37680839e+00 -3.26628153e+01
  7.70868781e+00 -1.03704747e+01 -6.97787112e+00  3.19467869e+01
 -5.95749479e+00  4.04535327e+00 -1.00924719e+01  5.98800318e+00
 -3.06717013e+00  3.92843097e+01  4.42845171e+01  1.19876654e+01
  2.80459825e+01  1.10798722e+02  2.99019904e+01  2.28968407e+00
  9.21445661e+01  2.21384765e+01  3.55284851e+01  2.42830766e+01
  5.04203281e+00  2.63576497e+00 -4.56932530e+00 -1.07613259e+01
  5.52286739e+00  1.28302199e+02  2.06226555e+02 -8.88799093e+01
  2.19278716e+02  2.45274251e+01  1.02285982e+01  1.65219856e+01
 -2.14570750e+00  4.21433351e+00 -2.64615365e+00 -1.96142762e+01
  1.64372321e-01  3.03176803e+00 -4.15938315e+00  3.20224420e+00
 -5.67950017e+00  8.24684614e+01 -2.18235442e+00  2.75812512e+01
 -1.60860327e+01  1.33754887e+01  1.33231913e+01  2.39381137e+01
 -5.67713760e+00  9.42695926e+01  8.81731366e-01  6.83984128e+01
  6.88498780e+00  1.64600312e+00  7.95287621e-01 -2.50409374e+00
  5.94385585e+00  3.63147053e+00  3.49185112e+00 -2.35356831e+00
  2.92062860e+01]
(65,)
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.993283165226
gradient value of function right now is: [ 6.19106893e-02 -5.97808930e-04  6.05478685e-03 -3.44978757e-06
 -6.19106893e-02  5.97808930e-04 -6.05478685e-03  3.44978757e-06
  1.58863667e-01  9.08533614e-02 -2.66936677e-02  6.63368829e-01
 -2.37641704e-04 -4.88767916e-05 -3.91244901e-13  3.86140604e-03
 -3.47971999e-03 -7.43988207e-04 -1.83399597e-31 -7.90980215e-02
 -9.20762629e-07  5.78878602e-12  5.78779318e-31 -9.72429296e-05
  3.09372570e-01 -1.32430674e-01  3.39640538e-02 -9.42230075e-02
 -4.26068391e-02  1.17309028e-04 -5.75677316e-04  6.50387724e-06
 -2.49517924e-03 -4.31510395e-35  7.68174018e-13  2.87613274e-40
 -2.70047403e-01 -1.86556943e-02  5.67113730e-03 -1.58381342e-02
 -5.89317940e-02 -3.06623719e-02 -1.43732826e-01  3.32505202e-01
 -1.36392149e-01 -1.47804084e-02 -2.01298701e-01 -1.17072865e-02
  7.60741507e-02  4.23894662e-02  8.17141147e-02  7.89439625e-03
 -2.06247705e-01 -5.83468115e-03 -5.71493322e-01 -2.27975431e-03
 -3.01608430e-01  1.42086984e+00  6.93701029e-01 -2.02755897e+00
 -1.97698844e-01  3.16662394e-01  2.06869004e-01 -7.21237160e-01
 -2.06444964e+00]
supnorm grad right now is: 2.064449641550351
Weights right now are: 
[ -7.43178289  10.96893556   7.36218331 -32.09152822   7.6863516
 -11.07762725  -6.96324604  31.37549984  -5.90058166   3.8527563
 -10.84612439   6.13953432  -4.18493349  43.03449314  44.28451783
  11.78285182  26.26624951 112.0783491   29.90199036   2.23260609
  96.39636711  22.13848925  35.52848511  25.60513716   5.34200889
   2.7966553   -4.46427482 -10.71081964   5.50393985 128.26269018
 212.65562353 -89.41614333 224.2052195   24.52742505  10.22860142
  16.52198564  -2.47766082   4.58795587  -4.57625633 -19.96479104
   1.0464834    2.62941905  -3.44883158   2.77079571  -5.16701705
  82.69456833  -3.03142203  27.90361342 -16.1111352   13.31635277
  13.16074215  24.55325018  -5.90372666  95.98078346   0.70807825
  68.25816727   7.01102482   1.47879974   0.74458334  -2.65442565
   5.68700324   3.55349005   3.46809738  -2.22224296  29.35354765]
(65,)
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1856.0013719205201
gradient value of function right now is: [ 6.44262597e-02 -8.52392735e-04  2.58673883e-03 -5.66846633e-06
 -6.44262597e-02  8.52392735e-04 -2.58673883e-03  5.66846633e-06
  1.79121437e-01  1.12927795e-01 -2.67440725e-02  6.93087750e-01
 -2.12468096e-04 -4.67760044e-05 -3.39116650e-13  5.83724112e-03
 -4.54713507e-03 -1.14689001e-03 -2.60269251e-31 -9.91378644e-02
 -1.05395688e-06  5.55084852e-12  2.30694409e-31 -1.43217826e-04
  3.19443264e-01 -1.57918824e-01  3.40219210e-02 -1.07123578e-01
 -7.76629140e-03  1.48103206e-04 -5.54264346e-04  6.37875394e-06
 -2.47495416e-03 -4.63680464e-35  7.09918943e-13  1.62605353e-40
 -2.92201494e-01 -2.98195442e-02  4.08110976e-03 -1.59251778e-02
 -7.35709079e-02 -5.83256598e-02 -1.72914313e-01  3.30509205e-01
 -1.26080165e-01 -1.37632790e-02 -1.79472772e-01 -1.11616600e-02
  7.33646633e-02  4.44832293e-02  7.62103095e-02  7.48901262e-03
 -2.22767295e-01 -6.42080073e-03 -6.16590954e-01 -2.63387078e-03
 -3.26372937e-01  1.50166908e+00  7.00188395e-01 -2.03621194e+00
 -1.93677186e-01  3.08975686e-01  2.23146730e-01 -7.36997279e-01
 -2.15033877e+00]
supnorm grad right now is: 2.1503387713867976
Weights right now are: 
[ -7.60100438  11.06935991   7.36540226 -33.26579825   7.85557309
 -11.1780516   -6.96646499  32.54976987  -6.28678739   3.83679051
 -11.05152352   5.91775818  -2.24464179  44.94848487  44.28451853
  12.26994774  26.49699026 111.62997925  29.90199036   2.23404765
  98.82057604  22.13849297  35.52848511  25.01727459   5.0666148
   2.64387926  -4.71304411 -10.57820665   5.88513168 133.66613492
 214.57668598 -90.64818832 226.76064118  24.52742505  10.22861405
  16.52198564  -2.91121024   4.90973078  -3.45958671 -19.15426012
   0.76568728   2.67245663  -3.64418934   3.23338993  -4.84644091
  83.0986197   -2.95177093  27.87516528 -15.95670124  14.73537708
  13.50480362  26.59602118  -5.6595044   97.26358238   0.97755767
  68.05311407   6.8057128    1.58615165   0.81981694  -2.59641244
   6.05902941   3.38173047   3.55808407  -2.14859701  29.1787869 ]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1856.0027290844373
gradient value of function right now is: [ 5.73344191e-02 -1.26802318e-03  6.37580391e-03 -1.04917243e-05
 -5.73344191e-02  1.26802318e-03 -6.37580391e-03  1.04917243e-05
  1.61142194e-01  7.97092352e-02 -2.72234670e-02  6.65093999e-01
 -1.90363742e-04 -4.31322154e-05 -1.53415706e-13  8.66611016e-03
 -5.31129062e-03 -1.03784152e-03 -1.94438572e-31 -1.57138244e-01
 -1.74420176e-06  3.92519568e-12  7.78170443e-32 -2.45630502e-04
  3.60127273e-01 -1.03779233e-01  3.13506850e-02 -7.34884977e-02
 -1.16980803e-02  1.44592659e-04 -5.11786538e-04  6.48067297e-06
 -2.57433817e-03 -4.96495814e-35  5.22373374e-13  6.71468047e-41
 -2.51211845e-01 -8.06404767e-03  7.90965406e-03 -1.29433812e-02
 -6.80995158e-02  1.32990480e-04 -1.74810287e-01  3.55774551e-01
 -1.26345080e-01 -1.41121669e-02 -1.92834694e-01 -1.09263202e-02
  7.65268749e-02  4.07911336e-02  8.24851989e-02  7.52392323e-03
 -1.58245658e-01 -4.03322279e-03 -4.75381276e-01 -1.14783588e-03
 -2.34741556e-01  1.10376300e+00  6.42644101e-01 -1.78665246e+00
 -2.26412472e-01  3.65350580e-01  1.84680369e-01 -6.19115894e-01
 -2.02885871e+00]
supnorm grad right now is: 2.0288587059426724
Weights right now are: 
[ -7.30666934  12.42153225   7.32533604 -33.93931224   7.56123805
 -12.53022394  -6.92639877  33.22328385  -5.729808     3.83411376
 -10.18073192   5.94511917  -1.94272404  44.94747204  44.28451861
  11.25091635  27.23913155 111.85383378  29.90199036   2.32324363
 101.74080833  22.13849464  35.52848511  25.21903725   4.92685976
   2.41968172  -4.99824406 -10.61444076   6.27459649 136.83678562
 217.45743376 -94.43954042 230.14611219  24.52742505  10.2286187
  16.52198564  -2.67977927   4.7384709   -1.68469147 -19.47376856
   1.10365745   2.37851415  -3.77779568   3.04567734  -5.41399908
  82.6716761   -2.81551026  26.70991386 -16.41551143  14.97764674
  13.59843648  25.41851722  -5.56203779  98.90441043   0.67239989
  68.4790887    6.82992722   1.62913633   1.02969664  -2.61978232
   5.6781179    3.79702327   3.53997453  -2.25642687  29.42110132]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1856.0055766230848
gradient value of function right now is: [ 6.51470684e-02 -1.17741544e-03  3.64068979e-03 -1.01483351e-05
 -6.51470684e-02  1.17741544e-03 -3.64068979e-03  1.01483351e-05
  1.98293420e-01  1.24436476e-01 -2.62214581e-02  7.13547468e-01
 -2.10959819e-04 -4.44379871e-05 -1.19152026e-13  8.14796540e-03
 -5.21209726e-03 -1.02383992e-03 -2.20696678e-31 -1.25691451e-01
 -1.81339042e-06  5.41992729e-12  6.17743372e-32 -2.45955399e-04
  3.41730886e-01 -1.41871775e-01  3.20039733e-02 -9.61143615e-02
 -1.99757829e-02  1.46229042e-04 -5.01781992e-04  6.19979427e-06
 -2.45078506e-03 -3.79389361e-35  5.93199414e-13  2.42546689e-41
 -2.81404094e-01 -2.45353797e-02  6.49241436e-03 -1.47566478e-02
 -6.68384319e-02 -5.71065922e-02 -1.71614285e-01  3.33255401e-01
 -1.23931144e-01 -1.40385821e-02 -1.86159921e-01 -1.08080356e-02
  7.24952066e-02  4.11177864e-02  7.82433694e-02  7.22055929e-03
 -2.11323506e-01 -5.63696514e-03 -5.91686281e-01 -2.34681674e-03
 -2.98249408e-01  1.37570706e+00  6.91268377e-01 -1.97972191e+00
 -2.41195513e-01  3.74283508e-01  2.20718709e-01 -7.01755151e-01
 -2.09244332e+00]
supnorm grad right now is: 2.0924433234780246
Weights right now are: 
[-7.56009323e+00  1.15853175e+01  7.52053888e+00 -3.58497097e+01
  7.81466194e+00 -1.16940092e+01 -7.12160161e+00  3.51336813e+01
 -5.93116464e+00  3.79280532e+00 -1.01152951e+01  5.82558561e+00
 -1.71315694e+00  4.86880824e+01  4.42845188e+01  1.16431404e+01
  2.72051445e+01  1.12527178e+02  2.99019904e+01  2.22823025e+00
  1.03780304e+02  2.21385368e+01  3.55284851e+01  2.38498993e+01
  4.91649278e+00  2.46636330e+00 -5.04819399e+00 -1.05074434e+01
  5.78090977e+00  1.35758293e+02  2.23582441e+02 -9.90357136e+01
  2.32721907e+02  2.45274251e+01  1.02286204e+01  1.65219856e+01
 -2.45904528e+00  4.15095283e+00 -3.38495398e+00 -1.92743764e+01
  2.10386434e-01  2.67155220e+00 -3.54528007e+00  3.30738235e+00
 -4.94586697e+00  8.29622893e+01 -3.05567464e+00  2.76223694e+01
 -1.66549408e+01  1.30950793e+01  1.36487973e+01  2.44534201e+01
 -5.54783515e+00  1.00439937e+02  7.30012515e-01  6.79675977e+01
  6.70549488e+00  1.57347106e+00  6.20428951e-01 -2.59848837e+00
  6.49548679e+00  3.47071912e+00  4.04896089e+00 -2.38204617e+00
  2.94202210e+01]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1340.4993148059123
W_T_median: 1141.6397159873827
W_T_pctile_5: 857.0810837813078
W_T_CVAR_5_pct: 783.6245520141531
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.8
F value: -1856.0055766230848
-----------------------------------------------
.16166997e+01
  3.82194470e+01 -4.19807652e+00  4.51736433e+01  5.30021645e+01
 -9.73432111e+00 -7.60101885e+00  7.36275628e+00  1.51246096e+00
 -1.20694593e-02 -2.93908379e+00  6.12472628e+00 -2.74503746e+00
  2.94131068e+01]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.782886777683
gradient value of function right now is: [ 6.60138573e-02 -1.19992591e-03  2.70632623e-02 -1.18924026e-03
 -6.60138573e-02  1.19992591e-03 -2.70632623e-02  1.18924026e-03
  6.61928538e-01  6.32454293e-01  4.88889468e-01  3.80406234e-01
 -4.29817788e-04 -1.37409815e-04 -1.01709194e-05 -9.32069017e-12
  7.45619716e-03 -1.50063999e-01  1.71759198e-02  1.07637637e-01
 -3.33512049e-04 -1.06616697e-04 -7.89052333e-06 -7.21871515e-12
 -9.90036622e-03  1.97219957e-02  3.08274905e-03  1.12447871e-03
 -4.40233392e-02 -8.75603659e-02 -1.33021789e-02 -6.19613730e-02
  1.01362962e-01 -2.12097596e-01 -1.49003503e-01 -2.13557927e-01
 -1.70120734e-02 -8.20171911e-02 -1.70086934e-03 -3.85880362e-02
  1.92198894e-01  1.10596604e-02  9.96171778e-02 -1.21800872e-01
 -2.94039824e-01  1.72398625e-01 -1.32741538e-01 -7.10496079e-03
  1.86324654e-03 -3.72127706e-01 -1.69599244e-02 -4.63436845e-03
 -8.77383404e-04 -1.84055489e-01 -5.92886307e-03 -4.56616962e-03
  1.83495380e-02 -5.32090910e-02 -2.05771165e-01  1.47869806e+00
  9.85269411e-01 -2.73135478e+00  1.01744338e-01 -6.88140551e-01
 -2.28516042e+00]
supnorm grad right now is: 2.7313547844468906
Weights right now are: 
[-7.82680375e+00 -1.28285172e+01  4.94472315e+00 -1.13799574e+01
  7.09250503e+00  1.27852694e+01 -4.45040619e+00  9.84406910e+00
  6.27044123e+00  6.20045619e+00 -9.11895216e+00  2.44225370e+00
  1.38018502e+02  2.52497229e+02  2.69862541e+02  4.02906414e+01
  7.18734735e+00  1.62749098e+00  1.13737460e+01  3.03795237e-01
  1.38805038e+02  2.52715543e+02  2.64042369e+02  4.32649278e+01
  5.53296029e+00  3.55203425e+00 -6.79392834e+00  3.78247165e+01
  6.56941955e+00 -5.40417731e+00 -3.70250797e+01  1.46062375e+01
  9.84970701e+00  1.54526704e+01 -1.12037104e+01 -9.98137451e+00
  2.77349937e+01  6.64356594e+00 -2.24234134e+01 -1.04224428e+01
  5.79701067e+00  1.68890254e+01 -2.71533414e+00 -6.66299902e+00
 -3.91582692e-01 -4.02258237e+00  7.32085452e+00  9.19833077e+00
 -3.61862014e+00 -2.84678231e+00  1.15786209e+02  5.28500756e+01
  3.94899161e+01 -4.25660912e+00  4.49312553e+01  5.31766747e+01
 -9.24388340e+00 -7.77146248e+00  7.73823904e+00  1.22184635e+00
 -1.38070819e-01 -3.00532091e+00  6.88587414e+00 -2.68495006e+00
  2.94016607e+01]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1339.0754688315
W_T_median: 1143.0983593583805
W_T_pctile_5: 856.91837426997
W_T_CVAR_5_pct: 784.5423924316996
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.8
F value: -1855.782886777683
-----------------------------------------------
