Starting at: 
2022-06-17 22:26:16
tracing parameter entered from terminal:  0.1


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1043.1209910844748
gradient value of function right now is: [-9.13391741e-02 -5.78980133e-01 -5.15949575e-01 -5.13174781e-01
  9.13391741e-02  5.78980133e-01  5.15949575e-01  5.13174781e-01
 -2.08222974e-03 -4.25697262e-03 -2.50812127e-03 -1.00976774e-03
  9.54844884e-02  2.13765569e-01  1.14042098e-01  4.61381218e-02
  5.61123588e-02  1.25088460e-01  6.70484986e-02  2.71339628e-02
  5.61690605e-02  1.25150612e-01  6.71170371e-02  2.71624733e-02
 -1.15345155e+00 -1.14210900e+00 -7.02599548e-01 -3.47182933e-01
 -8.71590870e-03 -8.65232966e-03 -5.89940607e-03 -5.03598624e-04
 -1.56432860e+00 -1.54897007e+00 -9.52880260e-01 -4.65746240e-01
 -4.43904269e-01 -4.39546079e-01 -2.67725365e-01 -1.34306196e-01
  5.81622301e-02  3.97193186e-02  4.23205792e-02  3.99329901e-02
  7.14635603e-02  4.82517021e-02  5.09796355e-02  4.82369573e-02
 -1.19549051e-01 -7.50219574e-02 -9.30261865e-02 -8.14349285e-02
 -1.77717157e-01 -1.08969667e-01 -1.07292614e-01 -1.02423887e-01
  3.04062587e-01 -9.38903477e-01  3.52112759e-01 -1.27651138e+00
  4.46010762e-01 -2.21255227e+00  3.92782667e-01 -1.73117709e+00
 -1.57157121e+01]
supnorm grad right now is: 15.715712122885012
Weights right now are: 
[ -0.03266878   1.78178586   1.36189896   0.80887876   0.28723749
  -1.89047755  -0.96296169  -1.52490715   8.18091524  13.77211284
   7.79078693   5.29579851   7.06214013  -0.54809773   7.40492626
   5.09104556   6.68872356   0.69264775   7.57876085   4.85366614
   5.91592544   0.74046394   8.00367844   5.41742051   2.80497027
   3.43748735  -3.2932913   -3.44043003   0.62343435   1.45285635
  -0.14969821   0.40224606   3.06113686   3.17624299  -3.23960724
  -4.23613772   2.59077053   3.69041715  -2.47560962  -2.39356706
 -12.73054363 -13.3250991  -10.37844738 -12.39971358 -10.24376683
 -12.76585194 -12.2156542  -12.47777533  -5.01735777  -2.92769025
   4.53147527   0.84038823   1.91713818   5.86920464   9.82931527
   8.28588496  -3.1813507   -3.9129154   -0.80237858  -3.71571466
   2.1313477   -2.9864775    1.03137865  -3.2896127   30.9749021 ]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.4826678633856
gradient value of function right now is: [ 4.22464563e-01  3.20053315e-02  1.92363510e-01  1.86505804e-01
 -4.22464563e-01 -3.20053315e-02 -1.92363510e-01 -1.86505804e-01
  2.62515557e-02  1.05442204e-02  3.10869476e-02  6.03718796e-03
  1.17681055e-01  3.93295962e-01  1.80178573e-01  2.64783144e-02
  5.00174659e-02  1.78631822e-01  7.78781667e-02  1.12548085e-02
  5.21358495e-02  1.85088428e-01  8.10851013e-02  1.17235427e-02
 -1.43099408e+00 -1.37973679e+00 -9.74498406e-01 -4.32706242e-01
 -5.66777039e-01 -5.52618881e-01 -3.20906499e-01 -1.16505470e-01
 -2.19445418e+00 -2.11336452e+00 -1.48037420e+00 -6.87957659e-01
 -2.67922227e-01 -2.58123835e-01 -1.78314540e-01 -8.09372855e-02
  9.56774950e-02  1.78877403e-02  2.69677344e-02  2.34457669e-02
  1.54740330e-01  2.59196526e-02  3.84945921e-02  3.36386602e-02
 -4.17236619e-01 -6.55754962e-02 -8.35125730e-02 -7.65319561e-02
 -6.94276032e-01 -8.70919739e-02 -1.20003485e-01 -1.07398214e-01
  4.24548916e-01 -1.79783583e+00  2.78206242e-01 -1.26141284e+00
  6.03107354e-01 -2.79074370e+00  4.76469447e-01 -2.17444050e+00
 -1.85163793e+01]
supnorm grad right now is: 18.516379339940624
Weights right now are: 
[ -3.00305668   2.02329192   1.57101716   1.0339283    3.25762539
  -2.13198361  -1.17207989  -1.74995668  17.90025979  18.32799627
  18.81912157  14.37654716   5.7137378   -0.09756178   5.98959516
   4.18571416   5.9446037    1.54500873   6.65789799   4.16696226
   5.05140596   1.54599007   6.95959598   4.64410284   3.24967843
   3.85863971  -3.75148684  -5.02572588   1.95922565   2.78896284
   0.54440089 -10.56026892   3.46034328   3.5559833   -3.85875174
  -5.9768633    3.41749097   4.46084991  -2.89559804  -3.76393779
 -14.66609087 -17.57673959 -11.74045202 -15.19167308 -10.14166104
 -15.93379432 -13.55071434 -14.90754683  -5.91169515   1.16676552
   9.57823391   5.47946455   1.81321101   7.2574605   13.54072252
  11.59191845  -4.45255323  -3.51625      1.29272601  -4.18413582
   2.48965095  -3.53020863   2.04264493  -3.75928487  31.00164068]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.9235352393898
gradient value of function right now is: [ 3.21280417e-01 -4.89136932e-01 -1.76646198e-01 -1.64414799e-01
 -3.21280417e-01  4.89136932e-01  1.76646198e-01  1.64414799e-01
  3.80386484e-03  1.07093476e-02  2.18760825e-02  8.81291323e-04
  6.21214588e-02  4.99192503e-01  4.51731820e-01  1.15474082e-02
  2.68437875e-02  2.09373868e-01  1.91426814e-01  5.14145711e-03
  2.66405063e-02  2.08228069e-01  1.89993481e-01  5.10455197e-03
 -7.50862411e-01 -7.27314567e-01 -5.33596332e-01 -1.75874651e-01
 -8.42054526e-01 -8.20377422e-01 -4.69868215e-01 -1.41684938e-01
 -4.86116345e+00 -4.72061568e+00 -3.51129575e+00 -1.12921943e+00
 -1.16566046e-01 -1.12753110e-01 -8.05460578e-02 -2.67391073e-02
  6.07311804e-02  1.18827378e-02  1.10431663e-02  1.07774976e-02
  1.48164294e-01  2.40476295e-02  2.09860809e-02  2.07235843e-02
 -9.32674006e-01 -1.23239462e-01 -9.00071527e-02 -9.25409230e-02
 -1.64431851e+00 -1.86196141e-01 -1.33148282e-01 -1.36782477e-01
  3.10317491e-01 -1.37441867e+00  5.65469729e-01 -1.89638376e+00
  7.22561626e-01 -2.78952287e+00  6.32229902e-01 -2.37299452e+00
  2.23108770e-01]
supnorm grad right now is: 4.861163447110824
Weights right now are: 
[ -3.2088742    2.10407927   1.53306628   0.99448207   3.46344291
  -2.21277096  -1.13412901  -1.71051045  17.43603732  20.60513356
  18.36358261  14.94278178   5.98527154   0.1555973    5.73772967
   4.97583266   6.88069224   1.67078673   7.57399018   4.47553084
   5.96962561   1.68405101   7.85018628   4.96409361   3.71244146
   4.21097774  -3.515652    -5.43023275   2.06620445   2.76499269
  -0.3792625  -10.58577141   3.31725774   3.33841535  -4.32388763
  -6.7866256    4.0237524    4.90614718  -2.77176096  -4.61319463
 -17.49032314 -19.72536207 -11.91470875 -16.0242221  -10.68002258
 -18.30055763 -14.74719408 -16.56969945  -5.43680243   0.61105718
  12.04926446   7.39871117   2.39724373   8.42594811  14.50074238
  12.62557771  -4.37816621  -3.18471931   0.53808034  -4.15190602
   2.83941701  -3.86317052   2.33007238  -3.97095215  31.16281825]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.33844661707
gradient value of function right now is: [-6.65901817e-01 -1.61702536e+00 -1.34049303e+00 -1.32215116e+00
  6.65901817e-01  1.61702536e+00  1.34049303e+00  1.32215116e+00
 -7.04221312e-03 -6.28225209e-02 -1.53690856e-01 -2.83169339e-03
  6.33966553e-03  1.65624250e-01  1.97375853e-01  1.73298622e-03
  6.23969265e-03  9.80863878e-02  1.20486578e-01  2.75853407e-03
  6.27432057e-03  9.80920263e-02  1.21144726e-01  2.77442520e-03
 -1.31740054e-02 -1.22781062e-02  6.88984658e-03  1.22951393e-03
  9.35555818e-01  9.41422018e-01  6.41074094e-01  1.84411955e-02
 -4.60238041e-01 -4.22216603e-01 -9.66494621e-02 -1.64869325e-01
  3.89148297e-03  3.75312235e-03  9.60278480e-03  4.31024301e-03
  1.79227115e-02  5.96902752e-03  4.96906630e-03  4.91590586e-03
  2.39137575e-02  9.91626506e-03  8.46616682e-03  8.35167771e-03
  5.53864894e-02  2.66974598e-03 -9.01165240e-03 -6.89646712e-03
  2.74171688e-01  2.50322705e-04 -1.85165297e-02 -1.59886121e-02
 -1.22191056e-01 -2.37095123e-01 -9.19100064e-02 -3.77919432e-01
 -3.29949991e-02 -7.20957386e-01 -3.67002687e-02 -6.05410908e-01
  4.91918756e+00]
supnorm grad right now is: 4.919187561657063
Weights right now are: 
[ -3.63832769   2.33032596   1.43000387   0.88703014   3.8928964
  -2.43901765  -1.0310666   -1.60305853  18.0480159   22.2141149
  17.73445312  16.45036916   6.82418866   0.39953732   4.61846665
   6.91579238   7.45995596   2.11806852   8.94097914   4.18734849
   6.63759932   2.11019022   9.35334851   4.72944504   4.28030676
   4.61085217  -3.37938792  -6.37219394   2.22841855   2.7998206
  -0.5621245  -10.8557256    3.3619645    3.29869989  -4.52597574
  -7.26348805   4.44513474   5.11442007  -3.01950728  -6.72779115
 -20.02746012 -21.57038322 -11.33063776 -15.9914903  -11.63866184
 -20.67022323 -15.88562095 -18.08392102  -4.83619546  -0.39433208
  13.51769946   8.51488119   2.44650045   9.3902378   15.65101296
  13.78951429  -4.06789205  -3.19029806   0.05827     -4.19775845
   2.95801805  -4.08617067   2.4584072   -4.15648718  31.13415828]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.6972487500684
gradient value of function right now is: [ 1.74660294e-01  6.36620526e-01  2.79588583e-01  2.67856073e-01
 -1.74660294e-01 -6.36620526e-01 -2.79588583e-01 -2.67856073e-01
  5.09301953e-04  7.95682020e-03  5.11820121e-02  3.02744591e-04
 -1.11856249e-02 -1.76102788e-01 -4.16282072e-01 -9.88148095e-03
 -7.49416119e-04 -1.05879018e-02 -5.30819384e-02 -5.46115782e-04
 -6.95074988e-04 -9.51604434e-03 -5.04775642e-02 -5.01750035e-04
  7.55616102e-02  7.35425564e-02  5.09879285e-02  2.53100460e-02
 -6.04779037e-02 -6.22314980e-02 -3.93036630e-03  2.11387508e-02
  1.16564495e+00  1.14281244e+00  9.02694147e-01  2.48071063e-01
  6.85076157e-02  6.65798911e-02  4.47022839e-02  2.48824280e-02
 -6.36774885e-03 -1.82602229e-03 -1.96719460e-03 -1.77146322e-03
 -2.16795275e-02 -3.59479147e-03 -2.59039634e-03 -2.43027510e-03
  2.35709714e-01  2.62891633e-02  7.46207718e-03  7.95235669e-03
  3.85760421e-01  4.19153631e-02  1.43850325e-02  1.51956752e-02
 -1.01208964e-01  2.96959328e-01 -2.19671197e-01  4.60485120e-01
 -1.74031161e-01  4.32910095e-01 -1.57550901e-01  3.86732739e-01
  2.64482789e+00]
supnorm grad right now is: 2.644827886762924
Weights right now are: 
[ -3.67663383   2.85571812   1.37565306   0.85389558   3.93120254
  -2.96440981  -0.9767158   -1.56992396  19.62046754  24.54331295
  16.6235418   19.02727646   8.00893516   0.87443001   3.04525657
   8.73757181   7.5486182    1.50018314  11.20790021   3.43816329
   6.73717238   1.35186411  11.79067728   3.94261153   4.89630292
   5.05369185  -3.2934911   -8.14293237   2.39901692   2.83036962
  -0.39414177 -10.54898496   3.36592567   3.24328122  -4.86284287
  -7.64169832   4.92689812   5.38513122  -3.06455913  -9.22373998
 -22.50418973 -24.22866394 -10.70464813 -16.01158712 -12.1849465
 -23.66080608 -17.36727762 -20.01703071  -4.63509193  -0.87619978
  16.03554262  10.76847172   2.78369647   9.93252174  17.1249539
  15.20963405  -3.82223892  -3.5545622   -0.04699013  -4.22744296
   2.80486703  -3.9485502    2.43764243  -4.06286591  31.12525756]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1043.5478665776989
gradient value of function right now is: [ 6.38252157e-02  7.24991022e-01  1.36227734e-01  1.41593897e-01
 -6.38252157e-02 -7.24991022e-01 -1.36227734e-01 -1.41593897e-01
 -2.46938421e-04 -6.49887315e-03 -8.57889390e-02 -1.26013698e-04
 -3.29649142e-02 -1.11067985e+00 -1.22852983e+00 -3.13069161e-02
 -6.94737866e-04 -3.85455556e-02 -9.06962246e-03 -6.50410078e-04
 -7.34209330e-04 -4.07169405e-02 -1.06238937e-02 -6.85874532e-04
  2.59012348e-01  2.47336007e-01  1.48131405e-01  1.03982786e-01
  1.50670648e+00  1.45349814e+00  9.32921798e-01  4.90718648e-01
  2.54569166e+00  2.43953918e+00  1.25551935e+00  9.71768891e-01
  2.62227659e-01  2.50181685e-01  1.51305901e-01  1.06744350e-01
 -7.45565529e-02 -2.38391587e-02 -2.34375790e-02 -2.13093403e-02
 -1.18351295e-01 -3.14541882e-02 -2.85576891e-02 -2.61622275e-02
  2.52804982e-01  5.86728618e-02  6.00495314e-02  5.45085910e-02
  8.09365444e-01  1.60786452e-01  1.33066238e-01  1.23157581e-01
 -8.36769740e-01  3.39224260e+00 -5.17679029e-01  2.77751592e+00
 -5.61121896e-01  3.93842028e+00 -4.79274295e-01  3.30977384e+00
  3.14468664e+01]
supnorm grad right now is: 31.446866371843644
Weights right now are: 
[ -3.54513825   3.06195085   1.39776685   0.94457037   3.79970696
  -3.17064254  -0.99882958  -1.66059875  21.31870625  25.70494775
  14.85895392  21.95351336   8.81079328   1.83426893   2.1627796
   9.75647343   9.05006173   0.56970252  14.28748567   4.71340582
   8.01132513   0.10572625  14.87666125   4.98394929   5.43946028
   5.33205039  -2.91796068  -8.93628628   2.54719029   2.79518798
  -0.69308628 -10.17769181   3.4715329    3.29232796  -5.13800613
  -8.0590917    5.48152876   5.63951347  -2.56612081 -10.0915631
 -24.67548536 -25.79246255  -8.95219357 -14.88754553 -13.7433813
 -26.21926656 -17.8696858  -21.02791786  -4.35917334  -1.89382603
  17.03525295  11.44867631   2.1668189   10.11714559  18.23567615
  16.2852777   -4.06401741  -3.69029677   0.19337787  -4.24459287
   3.2485336   -3.88377986   2.89400281  -4.02448995  31.24317312]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.2223172534523
gradient value of function right now is: [ 1.20787998e-01 -1.11485255e+00 -6.29921571e-03 -9.08996969e-03
 -1.20787998e-01  1.11485255e+00  6.29921571e-03  9.08996969e-03
 -2.06555475e-04 -1.38913131e-02 -6.99009538e-02 -1.61731052e-04
  1.09342335e-03  3.11391291e-01  8.80473951e-01  5.20506913e-05
  3.48646371e-04  2.87087076e-02  5.43011935e-02  3.17491590e-04
  4.10819626e-04  3.38917863e-02  6.25134520e-02  3.75183398e-04
 -1.85663853e-02 -1.87446496e-02 -9.31108243e-03  2.94066756e-03
 -2.52137635e-01 -2.45844480e-01 -5.77173342e-02 -5.52504832e-02
 -1.89462562e+00 -1.87169664e+00 -1.12488246e+00 -3.46327037e-01
 -8.96668042e-03 -9.38686819e-03 -3.03814378e-03  6.41011277e-03
  1.20165097e-02  4.79115398e-03  3.74519941e-03  3.56231309e-03
  1.88417286e-02  6.89268305e-03  5.07607406e-03  4.85444279e-03
 -3.89199427e-01 -1.02272315e-01 -4.61769539e-02 -4.65521870e-02
 -3.57055291e-01 -8.80033006e-02 -4.99416118e-02 -4.86455495e-02
 -4.98885618e-02 -2.35706201e-01  1.98496529e-01 -9.04476609e-01
  3.35983360e-01 -1.55688974e+00  2.84008454e-01 -1.27963254e+00
 -9.01957598e+00]
supnorm grad right now is: 9.019575977610542
Weights right now are: 
[ -3.6504972    3.01361077   1.19661087   0.78241275   3.90506591
  -3.12230246  -0.7976736   -1.49844113  25.4354047   26.71999954
  14.54372715  26.72161363   9.92857056   2.12906049   1.57201118
  11.02622578   7.78548926  -0.30027414  16.60152711   3.2426306
   6.46568541  -1.12018837  16.94646013   3.26337797   5.62491586
   5.25002211  -2.96768419 -10.18931353   2.58015004   2.67289503
  -1.2510066  -10.3734661    3.3711324    3.13270378  -5.4731949
  -8.36000245   5.61890579   5.47221565  -2.68878635 -11.34246561
 -27.03409701 -27.17353876  -7.33902348 -13.84120306 -15.49628562
 -28.47639329 -17.93748022 -21.60137312  -3.6011877   -2.40915857
  17.58451934  11.91888871   1.97973526  11.03679421  19.57590738
  17.66050703  -4.32649788  -3.50298802  -0.61198974  -4.12880354
   2.80985112  -3.99281605   2.36339868  -4.10841162  31.06506669]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.7019494208698
gradient value of function right now is: [-1.22458478e+00 -1.29668455e+00 -1.43090396e+00 -1.42568551e+00
  1.22458478e+00  1.29668455e+00  1.43090396e+00  1.42568551e+00
 -4.54987652e-04 -9.92402042e-02 -2.14597328e-01 -3.16360749e-04
 -1.62948865e-02 -9.06765063e-01 -7.46537882e-01 -1.68846558e-02
 -1.85935275e-04 -1.68807252e-03  3.08624019e-02 -2.12946899e-04
 -2.80181923e-04 -7.05714018e-03  3.14727780e-02 -3.10693080e-04
  1.65796980e-01  1.61186030e-01  9.20003927e-02  5.98743306e-02
  4.05677075e+00  4.02013252e+00  2.09287889e+00  5.87278051e-01
  2.12052896e+00  2.08115724e+00  1.16416714e+00  5.97220802e-01
  1.82500223e-01  1.77192251e-01  1.01502849e-01  6.75603338e-02
 -4.22835127e-02 -1.43787121e-02 -1.46374259e-02 -1.30702867e-02
 -6.42992487e-02 -1.75221943e-02 -1.61774513e-02 -1.45724176e-02
  6.74237552e-01  1.33751901e-01  8.16390142e-02  7.84277435e-02
  1.20934288e+00  2.04387924e-01  1.34862543e-01  1.26626406e-01
 -6.45269533e-01  2.66429562e+00 -6.48214342e-01  2.51812155e+00
 -8.82712518e-01  3.88921793e+00 -7.39931356e-01  3.23769997e+00
  1.54552309e+01]
supnorm grad right now is: 15.455230875072079
Weights right now are: 
[ -3.80689239   2.94524416   1.20867729   0.83503992   4.06146111
  -3.05393585  -0.80974002  -1.5510683   29.7785363   27.97266961
  14.29332449  31.16000139  10.83875792   2.40118091   1.46579271
  12.04741887   6.77687023  -0.53836405  17.70937233   2.47464308
   5.61846868  -1.48546662  17.94239854   2.68098128   5.97173776
   5.34239022  -2.65136498 -10.92945882   2.54882576   2.54058178
  -1.29034027 -10.23882608   3.6581519    3.41496612  -5.87133589
  -8.59937289   5.98306501   5.55399762  -2.31895992 -12.05599752
 -28.79951106 -28.48416688  -5.58140833 -12.66091855 -16.5571692
 -30.37857986 -17.52799919 -21.70526566  -3.14270708  -3.47459208
  18.45184111  12.5635988    2.22755035  11.55306581  21.03863414
  19.16172712  -4.85769315  -3.82592762  -0.24592039  -4.31765775
   3.06245448  -3.92075135   2.70173045  -4.07752783  31.11994021]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.530155293282
gradient value of function right now is: [ 2.83291568e-01  1.15112005e+00  4.72381416e-01  4.92599276e-01
 -2.83291568e-01 -1.15112005e+00 -4.72381416e-01 -4.92599276e-01
  3.01874280e-04  3.76635588e-02  6.95357334e-02  2.61468569e-04
  4.48695964e-03 -1.01052062e-01 -3.80983362e-01  6.43974947e-03
 -1.60273500e-04 -2.32041101e-02 -3.29188267e-02 -1.37785751e-04
 -1.94042464e-04 -3.12510791e-02 -4.45709041e-02 -1.57521460e-04
 -4.92728603e-02 -4.63058286e-02 -2.21951587e-02 -2.52861263e-02
 -6.15897118e-01 -6.10529448e-01 -2.69809753e-01 -6.62300173e-02
  9.01178628e-01  8.98452095e-01  6.49074155e-01  1.08585214e-01
 -7.63922695e-02 -7.22158789e-02 -3.71676936e-02 -3.61096575e-02
  1.21078289e-02  4.50177278e-03  4.41446041e-03  4.03815609e-03
  1.06944141e-02  3.90451595e-03  3.95179078e-03  3.59902694e-03
  3.39492671e-01  3.67816135e-02  3.91906190e-03  5.56052076e-03
  3.58437575e-01  2.20767006e-02 -9.94034991e-03 -6.97027057e-03
  1.77462654e-01 -7.53273064e-01 -1.46079854e-01 -1.68548786e-01
 -1.69383923e-01 -2.50252533e-01 -1.53000165e-01 -2.19375414e-01
 -2.07751521e+00]
supnorm grad right now is: 2.077515205263414
Weights right now are: 
[ -3.49430714   3.10268759   1.08998004   0.76532017   3.74887585
  -3.21137928  -0.69104277  -1.48134856  34.19990522  28.68977484
  14.7249708   36.03284562  12.07889377   2.52569936   1.43143614
  13.41510447   5.3823209    0.40057774  18.72793581   1.0411412
   4.48455328  -0.96906006  18.66879678   1.58176475   5.88708351
   4.98170636  -2.97209399 -11.95568344   2.51506785   2.42965974
  -1.55359737 -10.43138626   3.87736099   3.60354852  -6.16335799
  -8.60267686   5.83220173   5.11526314  -2.70450329 -13.13934142
 -30.83790612 -29.68674995  -4.17686103 -11.7723402  -18.16600351
 -32.20218791 -17.40342322 -22.04337882  -2.96183499  -3.31517061
  19.20689923  13.212157     1.86544621  12.23126442  22.25830081
  20.43741043  -4.49316248  -4.00357799  -0.1985065   -4.38368502
   2.90303003  -3.99345729   2.49636573  -4.14027861  31.11860175]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.6972389061054
gradient value of function right now is: [-1.64091391e+00 -2.77465175e+00 -2.11914062e+00 -2.14874520e+00
  1.64091391e+00  2.77465175e+00  2.11914062e+00  2.14874520e+00
 -3.66315980e-04 -1.17207989e-01 -5.18601289e-02 -3.07887455e-04
  2.61442078e-03  4.52133215e-01  7.92398702e-01  2.25740041e-03
  4.82727515e-06  2.41487346e-02  1.32069153e-02 -1.70045256e-05
 -6.73363623e-05  3.16948235e-02  1.86376072e-02 -1.05201898e-04
 -2.87894128e-02 -2.71279178e-02 -3.18550169e-02 -8.69896241e-03
  2.36637306e+00  2.37456421e+00  4.07273366e-01 -8.99766872e-03
 -4.99111112e-01 -4.96333362e-01 -4.91194656e-01 -7.84667664e-02
 -3.06989652e-02 -2.86224869e-02 -3.34629409e-02 -9.60227393e-03
 -9.76756975e-03 -5.43499564e-03 -6.28545726e-03 -5.54603523e-03
 -5.03341181e-03 -4.47173996e-03 -5.28617360e-03 -4.65410496e-03
 -1.56740272e-01  7.53304109e-02  6.17931495e-02  6.16447034e-02
 -8.25899240e-01  2.02779054e-02  5.61811444e-02  4.82174302e-02
  1.87711765e-01  4.71114427e-02  3.06437486e-01  3.23362526e-01
 -1.55694758e-01  1.68487493e+00 -6.51769747e-02  1.28272734e+00
  1.11329927e+01]
supnorm grad right now is: 11.1329927445051
Weights right now are: 
[-3.36969336e+00  2.89297752e+00  9.55277095e-01  7.34969051e-01
  3.62426207e+00 -3.00166921e+00 -5.56339825e-01 -1.45099743e+00
  3.81838109e+01  2.90867238e+01  1.50975538e+01  3.99326707e+01
  1.32417176e+01  2.60928834e+00  1.21157295e+00  1.46096533e+01
  4.19607773e+00  5.36793953e-01  2.03580199e+01 -6.46464842e-05
  4.26875775e+00 -1.14986094e+00  2.00760245e+01  1.58232098e+00
  6.20594134e+00  5.06462445e+00 -2.63665196e+00 -1.28814917e+01
  2.59483513e+00  2.41281781e+00 -1.75196064e+00 -1.02900313e+01
  3.94559174e+00  3.67005136e+00 -6.54129605e+00 -8.72073587e+00
  6.18768011e+00  5.22320401e+00 -2.35792251e+00 -1.39878638e+01
 -3.28829471e+01 -3.13301178e+01 -3.72458256e+00 -1.18142831e+01
 -2.01763304e+01 -3.42849172e+01 -1.77364661e+01 -2.28431496e+01
 -3.62586437e+00 -2.83516436e+00  1.98067999e+01  1.38432448e+01
  1.59880885e+00  1.26437386e+01  2.34893650e+01  2.16616418e+01
 -4.61689553e+00 -3.94749010e+00  2.59624397e-01 -4.34849338e+00
  2.90522187e+00 -4.01167773e+00  2.29487238e+00 -4.19164047e+00
  3.11701272e+01]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.4774387205885
gradient value of function right now is: [ 3.76537638e-01  1.40140547e+00  3.93880489e-01  3.97771895e-01
 -3.76537638e-01 -1.40140547e+00 -3.93880489e-01 -3.97771895e-01
  5.03262918e-05  1.79840245e-02  5.80662665e-02  4.15347872e-05
 -9.32932339e-03 -5.03962053e-01 -1.03445948e+00 -1.15835131e-02
  1.79757597e-05 -8.91865978e-04 -9.31738629e-03  2.26640371e-05
  1.98264051e-05 -1.46311719e-03 -1.65696650e-02  2.42658148e-05
  1.19793711e-01  1.15949261e-01  7.17652738e-02  4.42484316e-02
  2.84835246e-01  2.67652526e-01  2.52384187e-01  2.20271327e-01
  2.84937718e-01  2.77203733e-01  2.22374444e-01  9.92994317e-02
  1.64415123e-01  1.58963020e-01  9.74348682e-02  6.13094431e-02
 -8.70434519e-03 -1.17775399e-03 -1.12687172e-03 -1.02336695e-03
 -1.74540042e-02 -1.81396884e-03 -1.45461423e-03 -1.36486024e-03
  1.02076120e-01 -1.37207641e-02 -6.38686045e-03 -7.01604465e-03
  5.42103366e-01  2.36966794e-02  1.01577137e-02  1.05092868e-02
 -3.66258083e-01  1.05171859e+00 -1.88850991e-01  4.38832821e-01
 -8.79474680e-02  3.15501268e-01 -9.14644025e-02  3.23185256e-01
 -9.37265503e+00]
supnorm grad right now is: 9.372655026407038
Weights right now are: 
[ -3.09864539   3.06745711   0.9326344    0.80523632   3.3532141
  -3.1761488   -0.53369713  -1.5212647   43.35175813  30.15827628
  16.0334114   44.6730747   14.23343329   2.2462199    0.85054407
  15.70510529   3.10955378   1.62446705  21.27558289  -0.69823207
   4.49475451  -0.39504005  20.89133843   2.2247549    6.70487909
   5.24666398  -2.37468665 -13.44997704   2.82868183   2.59185078
  -1.46526073  -9.84591391   4.18509945   3.956442    -6.73630807
  -9.18423121   6.64453266   5.3528194   -2.12030256 -14.58754774
 -34.71085196 -32.74689332  -3.20859187 -11.83374911 -21.06101124
 -35.70199328 -17.6943706  -23.27129103  -3.43296934  -4.10651676
  20.51658824  14.13909776   2.01657775  13.35860161  24.63534046
  22.88625113  -5.3245132   -3.79260657   0.1119235   -4.53064428
   3.1030486   -4.08576056   2.60488183  -4.23998082  30.98585333]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.0445049427808
gradient value of function right now is: [-3.40958924e-01 -1.01129917e+00 -5.50630839e-01 -7.24865476e-01
  3.40958924e-01  1.01129917e+00  5.50630839e-01  7.24865476e-01
 -2.83965984e-05 -2.83765073e-02 -7.32031184e-03 -2.29995997e-05
  1.01096571e-02  9.52893374e-01  2.74264806e-01  1.08632456e-02
  6.09909175e-05  1.65932115e-02  7.21691206e-03  6.00721191e-05
  4.50123590e-04  9.95530929e-02  4.20696158e-02  4.50753062e-04
 -1.32680835e-01 -1.28858643e-01 -6.75133449e-02 -5.00873558e-02
 -4.20637534e-01 -3.96269951e-01 -1.53268116e-01 -3.85342312e-01
 -1.00223448e+00 -9.87605173e-01 -4.15537834e-01 -3.20258728e-01
 -1.54907873e-01 -1.50317826e-01 -7.94756653e-02 -5.87616586e-02
  3.98867345e-02  1.67959743e-02  1.45948865e-02  1.36206543e-02
  4.28107708e-02  1.69158355e-02  1.42016604e-02  1.33412312e-02
  5.41895699e-02 -2.13948079e-02 -2.83948688e-02 -2.46891280e-02
  2.03656630e-02 -7.27306989e-02 -7.48631010e-02 -6.86398657e-02
  2.91407833e-01 -2.32041027e+00  1.19819422e-01 -2.06419110e+00
  1.97279444e-01 -2.70727431e+00  1.65340281e-01 -2.40747734e+00
 -6.21770424e+00]
supnorm grad right now is: 6.217704239327443
Weights right now are: 
[ -3.06005446   2.94539844   0.49857577   0.61157372   3.31462317
  -3.05409013  -0.0996385   -1.32760211  48.3900168   31.23918811
  15.33770426  49.68343508  15.19733521   2.40364997   1.02435938
  16.62994885   1.6879944    3.53394712  24.54694094  -1.90663195
   4.51491137  -0.82981084  22.6378108    2.64632229   7.14271138
   5.34731307  -2.11826791 -13.97850361   2.64182251   2.38977892
  -1.3238998  -10.54405351   4.27006272   4.07336318  -7.00368436
  -9.40636886   7.13904855   5.49328473  -1.80700461 -14.98496786
 -36.78491209 -34.42064288  -3.21876769 -12.3520919  -22.12873598
 -37.52014657 -18.36348464 -24.3722043   -3.18454332  -3.14539713
  21.56464355  15.15322032   2.15379875  13.97959099  25.3516071
  23.63694995  -5.03759865  -4.11141121  -0.36313344  -4.49964234
   3.20122014  -4.29648218   2.43210313  -4.44542063  31.10406073]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.432560776595
gradient value of function right now is: [-8.07883671e-02  1.68361628e-01 -9.90371152e-02 -1.49708120e-01
  8.07883671e-02 -1.68361628e-01  9.90371152e-02  1.49708120e-01
  1.63003307e-05  6.12863722e-03  3.18233000e-02  1.25522355e-05
  1.08383040e-02  4.74090369e-01  2.59379194e-02  1.18938125e-02
 -8.38601126e-07  7.27128255e-04  2.24600308e-03 -1.29529351e-06
  6.16965582e-04  5.94578940e-02 -6.55751611e-03  6.44263928e-04
 -1.52157482e-01 -1.48237560e-01 -7.76308391e-02 -5.95182199e-02
 -5.29682963e-01 -5.17775784e-01 -3.37876195e-01 -2.31629691e-01
 -2.34406854e-01 -2.30230361e-01  2.92578918e-02 -1.67446299e-01
 -1.80112728e-01 -1.75343011e-01 -9.26028123e-02 -7.05334981e-02
  3.26336565e-02  1.36718783e-02  1.24191808e-02  1.20751077e-02
  3.17749872e-02  1.25364439e-02  1.11469300e-02  1.08884514e-02
  2.41800395e-01  1.02134791e-02 -1.43936555e-02 -9.99304840e-03
  1.87189111e-01 -3.75891407e-02 -5.03268525e-02 -4.67900624e-02
  3.09270520e-01 -2.03793245e+00  2.81729948e-02 -1.48514642e+00
  2.67242400e-02 -1.88014866e+00  3.20753505e-03 -1.75218298e+00
 -3.93423914e+00]
supnorm grad right now is: 3.9342391369298166
Weights right now are: 
[-2.79238184e+00  2.89949281e+00 -1.24949103e-02  1.01508982e+00
  3.04695055e+00 -3.00818450e+00  4.11432180e-01 -1.73111821e+00
  5.11958083e+01  3.22062235e+01  1.60492657e+01  5.21691102e+01
  1.62367413e+01  2.40375975e+00  1.10877838e+00  1.76858905e+01
  4.75641187e-01  1.33110008e+01  2.50193825e+01 -3.24846145e+00
  5.84377897e+00 -1.79090002e+00  2.34922036e+01  4.31652498e+00
  7.25287283e+00  5.21394154e+00 -2.34970820e+00 -1.47961646e+01
  2.52442932e+00  2.21213458e+00 -1.46392281e+00 -1.00497157e+01
  4.48951392e+00  4.29524525e+00 -7.25371536e+00 -1.01353670e+01
  7.24109781e+00  5.34593539e+00 -2.03978570e+00 -1.57708967e+01
 -3.85429973e+01 -3.52108163e+01 -2.02084056e+00 -1.17879974e+01
 -2.31719252e+01 -3.91011100e+01 -1.84168922e+01 -2.50018360e+01
 -2.90955564e+00 -2.36010313e+00  2.16895455e+01  1.51500696e+01
  1.98775346e+00  1.45617913e+01  2.65418333e+01  2.48570120e+01
 -5.03957862e+00 -4.20250820e+00  1.01455390e-02 -4.54772076e+00
  3.14578198e+00 -4.33556019e+00  2.38333014e+00 -4.43960654e+00
  3.11379413e+01]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.3078932959559
gradient value of function right now is: [ 1.71456504e-01 -4.34495258e-01  1.87568428e-01 -1.21190390e-01
 -1.71456504e-01  4.34495258e-01 -1.87568428e-01  1.21190390e-01
 -1.62269640e-06  6.02117062e-03 -5.30232617e-03 -1.60966332e-06
 -5.55748103e-03 -5.28925217e-02 -8.24369639e-02 -6.72943874e-03
 -2.55793800e-07  3.68831288e-04 -1.91661903e-04 -2.75220329e-07
  7.27932615e-05  7.51346550e-02  2.72748401e-02  7.22478473e-05
  7.62651928e-02  7.43290133e-02  4.31175807e-02  3.31262178e-02
 -3.55359238e-01 -3.59213674e-01 -6.76761040e-02  5.53658489e-02
 -5.92377123e-01 -5.90062933e-01 -3.48601514e-01 -7.83553193e-02
  1.00228853e-01  9.76412023e-02  5.66434221e-02  4.32939165e-02
 -6.69507754e-03 -2.72158267e-03 -2.49786026e-03 -2.25867527e-03
 -5.21684487e-03 -1.77997760e-03 -1.71706943e-03 -1.52378966e-03
 -2.29124393e-01 -4.29161253e-02 -1.65360520e-02 -1.90674472e-02
 -1.10302457e-01 -2.65739049e-02 -7.48242610e-03 -9.87666526e-03
 -2.09335658e-01  7.15838433e-01  8.31888016e-02  5.27187046e-02
  1.97950705e-01 -2.66178236e-01  1.88553665e-01 -2.26587199e-01
  8.48922427e+00]
supnorm grad right now is: 8.489224265281564
Weights right now are: 
[ -2.15551441   2.7563357    0.06265683   0.59689484   2.41008312
  -2.86502739   0.33628044  -1.31292322  53.14351215  33.66041341
  17.25795658  54.00547414  16.81010827   2.00455255   0.77336864
  18.2625898    1.39137084  26.57297995  25.29947959  -2.34224482
   4.64881204  -1.82780031  25.63200723   3.42147454   7.65540751
   5.4423592   -2.30030559 -15.21987321   2.29840814   1.92622382
  -1.1718983   -9.37498267   4.67696861   4.53473668  -7.67895532
 -10.56545768   7.60363227   5.5325796   -2.02120293 -16.21605451
 -40.81639455 -37.53293245  -2.41107027 -12.82894095 -24.28106902
 -41.68756474 -19.7117581  -26.85655219  -3.62005738  -2.97951574
  22.40381845  15.38764299   2.28332778  14.67568236  27.42039624
  25.7046188   -4.73846869  -4.06246073   0.32710064  -4.41339788
   3.68718015  -4.27271103   2.90073555  -4.41421129  31.17489507]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.0983466786295
gradient value of function right now is: [ 2.22314173e-02  1.36954948e+00  4.39806178e-02  2.56158508e-01
 -2.22314173e-02 -1.36954948e+00 -4.39806178e-02 -2.56158508e-01
 -2.08878367e-06 -7.78401354e-03 -1.36042481e-02 -1.51692591e-06
 -1.18039509e-02 -1.67082067e+00 -1.27166509e+00 -1.41312289e-02
 -1.99537073e-07 -5.46020440e-04 -6.71554544e-04 -1.69166267e-07
 -2.80190331e-04 -9.73070019e-02 -3.36511032e-02 -3.15617647e-04
  1.76490762e-01  1.73205564e-01  9.81281784e-02  6.99000477e-02
  2.30421630e+00  2.27551469e+00  1.37087329e+00  6.83264487e-01
  1.82204249e+00  1.80503547e+00  9.88568479e-01  5.46504868e-01
  2.27169921e-01  2.22729872e-01  1.26425789e-01  9.06293238e-02
 -3.95110072e-02 -1.84718931e-02 -1.52873595e-02 -1.43214669e-02
 -4.75809595e-02 -1.82801783e-02 -1.38572804e-02 -1.31719484e-02
  3.57072333e-01  7.21518767e-02  4.22901233e-02  4.17864313e-02
  8.68141751e-01  1.62738822e-01  8.90865360e-02  8.90050421e-02
 -7.27220896e-01  3.03351850e+00 -8.44911585e-01  3.46425306e+00
 -6.43140692e-01  3.56496788e+00 -6.40292727e-01  3.35699625e+00
  2.64083123e+01]
supnorm grad right now is: 26.408312346825966
Weights right now are: 
[-2.07663249e+00  2.89805121e+00  3.41091136e-04  8.08667460e-01
  2.33120120e+00 -3.00674290e+00  3.98596178e-01 -1.52469584e+00
  5.39095469e+01  3.36343565e+01  1.71166531e+01  5.47405488e+01
  1.75782242e+01  2.09800288e+00  9.92532027e-01  1.90284719e+01
  1.75189732e+00  3.48257401e+01  2.59460164e+01 -2.00141611e+00
  5.44516649e+00 -2.42961539e+00  2.74851984e+01  4.47095826e+00
  8.12235678e+00  5.60882639e+00 -2.16719211e+00 -1.54728514e+01
  2.52939980e+00  2.11338691e+00 -1.15115036e+00 -9.22284055e+00
  4.93389656e+00  4.84667418e+00 -8.02888332e+00 -1.12323272e+01
  8.06283571e+00  5.69111844e+00 -1.88418429e+00 -1.64614598e+01
 -4.24316425e+01 -3.89298056e+01 -1.97997871e+00 -1.29663785e+01
 -2.50707551e+01 -4.32683428e+01 -1.99936902e+01 -2.76227965e+01
 -3.79164195e+00 -3.33920691e+00  2.37152157e+01  1.63083166e+01
  2.23329188e+00  1.54407177e+01  2.84462442e+01  2.68242190e+01
 -4.74714484e+00 -4.31695453e+00 -8.07318345e-02 -4.41451811e+00
  3.57202160e+00 -4.19144854e+00  2.83383205e+00 -4.33842225e+00
  3.11966070e+01]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.1952311962652
gradient value of function right now is: [ 2.89851676e-01 -4.84015916e-01  2.19183659e-01  6.79026016e-01
 -2.89851676e-01  4.84015916e-01 -2.19183659e-01 -6.79026016e-01
  4.90967779e-06  2.44077129e-02 -6.34915020e-03  4.65264979e-06
  4.93190522e-03  7.30602173e-01  8.82234272e-01  5.56434586e-03
  4.43538111e-07  2.04565867e-03  5.53240754e-05  3.98280194e-07
 -2.77540338e-04 -6.88759418e-02  5.64741725e-03 -3.03740422e-04
 -8.87970384e-02 -8.50473850e-02 -5.79823519e-02 -3.31122144e-02
 -2.04098047e+00 -2.03019908e+00 -1.15095857e+00 -2.90556318e-01
 -7.31036279e-01 -7.24627059e-01 -7.17012550e-01 -7.63493532e-02
 -1.07394058e-01 -1.02660775e-01 -6.91420054e-02 -4.08099575e-02
 -5.42927302e-04 -2.17863983e-03 -2.51632308e-03 -2.23883071e-03
  3.67190527e-03 -1.56172236e-03 -2.10943576e-03 -1.86208203e-03
 -5.02876279e-01 -5.58890760e-02 -6.20477443e-03 -9.99877621e-03
 -9.98226559e-01 -8.02152202e-02 -9.86175699e-03 -1.44925088e-02
  1.82369425e-01 -2.73731867e-01  6.51897665e-01 -7.02310006e-01
  3.91758831e-01 -1.40087577e-01  4.24191866e-01 -2.37397898e-01
  9.80810856e+00]
supnorm grad right now is: 9.808108556332991
Weights right now are: 
[-2.03828911e+00  2.69461210e+00 -4.28766259e-02  7.05737991e-01
  2.29285782e+00 -2.80330380e+00  4.41813895e-01 -1.42176637e+00
  5.52403280e+01  3.26917128e+01  1.82969199e+01  5.59774211e+01
  1.89370673e+01  2.32170344e+00  1.08837613e+00  2.03816863e+01
  2.10054984e+00  4.71881836e+01  2.86481042e+01 -1.70573186e+00
  5.28702768e+00 -3.32663530e+00  2.82515339e+01  4.64094804e+00
  8.05574642e+00  5.21011966e+00 -2.67613762e+00 -1.65238677e+01
  2.30573974e+00  1.83299289e+00 -1.30357223e+00 -9.60868618e+00
  5.13739760e+00  5.06167270e+00 -8.46803949e+00 -1.17878568e+01
  8.00505243e+00  5.29833034e+00 -2.37336639e+00 -1.74740579e+01
 -4.44914227e+01 -4.00862832e+01 -4.14531627e-01 -1.20817946e+01
 -2.56227672e+01 -4.51287761e+01 -1.99810024e+01 -2.81993339e+01
 -4.22065167e+00 -3.55610656e+00  2.49065354e+01  1.71900669e+01
  1.95025493e+00  1.58052885e+01  2.90473731e+01  2.75652764e+01
 -4.59403656e+00 -4.36256787e+00  4.09132270e-03 -4.50192139e+00
  3.31095184e+00 -4.31575057e+00  2.70759808e+00 -4.46182497e+00
  3.12092253e+01]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.945532295128
gradient value of function right now is: [-2.25980898e-01 -1.43949566e+00 -1.01224968e-01 -3.26074172e-01
  2.25980898e-01  1.43949566e+00  1.01224968e-01  3.26074172e-01
 -7.06115685e-06 -2.43381263e-02 -2.16105889e-02 -5.48284490e-06
 -1.85032172e-03  2.29142126e-01  6.78994253e-01 -2.08254202e-03
 -5.07362608e-07 -2.71719058e-03 -5.01498609e-04 -4.15484044e-07
 -1.87844503e-04 -2.80702786e-02  1.08268488e-02 -1.91823301e-04
  3.03943350e-02  2.91894304e-02  1.23922444e-02  1.33574173e-02
  2.23913459e-01  2.18230033e-01 -1.56823561e-01 -1.99027321e-02
 -7.47302455e-01 -7.55757226e-01 -8.08347277e-01 -4.06852823e-03
  3.66492861e-02  3.52562710e-02  1.59946405e-02  1.56547226e-02
 -1.46273229e-02 -4.36118441e-03 -5.51266610e-03 -4.81033540e-03
 -1.54855696e-02 -4.37333915e-03 -5.34614748e-03 -4.69595183e-03
 -6.24344410e-01 -2.21249149e-02  1.22127952e-02  7.41893819e-03
 -9.59243434e-01 -1.56664455e-02  2.36415845e-02  1.70518216e-02
 -7.06073429e-02  9.09638543e-01  2.57861360e-01  2.74931456e-01
  2.04047438e-01  1.07488155e+00  2.40342684e-01  8.10345833e-01
  1.33072924e+01]
supnorm grad right now is: 13.307292392133203
Weights right now are: 
[ -2.07317459   2.7270934   -0.38129567   0.71305803   2.3277433
  -2.83578509   0.78023294  -1.42908641  56.1140568   30.66016799
  19.53215245  56.84648151  19.91197549   2.27436179   1.53795523
  21.32030038   2.28430024  60.29222846  29.4035502   -1.54863259
   5.53164061  -3.29189347  28.75812191   5.05987452   8.54980263
   5.28104332  -2.60666769 -16.88241619   2.52823568   1.98244236
  -1.3422543   -9.60304007   5.26125798   5.16965804  -8.69935095
 -12.86165572   8.53164414   5.4022161   -2.24631401 -17.7839696
 -46.95590729 -41.31610945   1.3017349  -11.14906224 -27.19038065
 -47.13717269 -19.93954397 -28.83165779  -3.77014322  -3.4670454
  25.44383605  17.65120799   2.22185972  15.94163429  30.36076878
  28.85725925  -5.05052591  -4.07199663   0.48387706  -4.82302697
   3.51335152  -4.31919394   2.91284788  -4.51470834  31.22989623]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.4083515548202
gradient value of function right now is: [ 3.26824040e-01 -3.61121840e-01  1.82778000e-01  2.37446058e-01
 -3.26824040e-01  3.61121840e-01 -1.82778000e-01 -2.37446058e-01
  1.29660129e-06  1.57937566e-02  5.96586959e-03  9.34201350e-07
  4.84248968e-03  8.32282608e-01  6.50151363e-01  5.26733393e-03
  2.92278106e-07  3.06526582e-03  5.79434421e-04  2.46995847e-07
  1.56035054e-04  5.99412495e-02  2.05439885e-02  1.60531007e-04
 -8.75745404e-02 -8.39089496e-02 -4.84267708e-02 -3.51675665e-02
 -1.39992849e+00 -1.38585537e+00 -6.71956732e-01 -2.64181416e-01
 -1.14009982e+00 -1.12573373e+00 -6.42085464e-01 -3.30015139e-01
 -1.01195585e-01 -9.68189993e-02 -5.58990946e-02 -4.10382158e-02
  2.00268855e-02  5.63583047e-03  5.86928732e-03  5.34858040e-03
  2.37989148e-02  5.96036451e-03  5.89268723e-03  5.41107031e-03
 -3.46914330e-01 -4.78346732e-02 -2.96006626e-02 -2.91911967e-02
 -6.30095067e-01 -6.89062416e-02 -4.63655421e-02 -4.47265290e-02
  2.64963093e-01 -1.53031685e+00  3.28345615e-01 -1.30150758e+00
  4.19068200e-01 -1.94871560e+00  3.89454224e-01 -1.74369264e+00
 -1.22084003e+01]
supnorm grad right now is: 12.208400286448603
Weights right now are: 
[ -1.66780544   2.80442633  -0.55132034   0.53846692   1.92237415
  -2.91311802   0.95025761  -1.2544953   56.75731267  27.66399233
  19.31070069  57.53946834  20.43972866   1.71929889   1.17302408
  21.83216216   2.54231761  71.93207137  29.34592654  -1.32905378
   2.24925992  -4.08646596  30.59331403   1.84962731   9.02045233
   5.44318688  -2.42961551 -16.98400666   2.55525442   1.96057659
  -1.08475864  -9.00590345   5.54508829   5.45773845  -9.08216369
 -13.21596634   8.98683977   5.54837172  -2.0741333  -17.87921996
 -48.62549335 -42.30161743   2.49584043 -10.48480961 -28.0840559
 -49.0574089  -20.33041631 -29.69933389  -3.76402459  -4.05290132
  25.98208774  17.88079256   1.93467524  16.28160489  30.68559621
  29.29339684  -4.45450792  -4.1251105    0.24508858  -4.87791901
   3.48525333  -4.47656664   2.94294921  -4.6340761   31.07242896]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.0883889956106
gradient value of function right now is: [ 2.95132186e-01  1.86295604e+00  7.49487871e-02  1.37157894e+00
 -2.95132186e-01 -1.86295604e+00 -7.49487871e-02 -1.37157894e+00
  2.74918773e-06  3.86812818e-02  1.56385436e-02  2.07400172e-06
 -2.54930059e-03 -1.26313944e+00 -5.10878740e-01 -2.53945113e-03
  6.36247924e-08  2.12635176e-03  4.23862991e-04  4.75319857e-08
 -2.35097919e-04 -2.95333566e-01 -8.29417583e-02 -2.21819600e-04
  4.51426577e-02  4.37448010e-02  2.50433760e-02  1.89722277e-02
 -4.25515817e-01 -4.36816072e-01 -2.36209300e-01  1.17421460e-01
  2.32325784e+00  2.29216991e+00  1.39497306e+00  6.03007596e-01
  4.75893094e-02  4.60757539e-02  2.64295375e-02  2.01969760e-02
 -1.85928959e-02 -5.36703980e-03 -5.77559365e-03 -5.26567129e-03
 -3.16800537e-02 -6.82866193e-03 -6.41518094e-03 -5.93804491e-03
  7.22720203e-01  6.41327095e-02  3.14419955e-02  3.09036319e-02
  8.57382984e-01  7.04003536e-02  3.99639504e-02  3.88783229e-02
 -4.69538970e-01  1.89732435e+00 -4.19854045e-01  1.40809769e+00
 -5.62398542e-01  2.06508560e+00 -5.10124299e-01  1.84252886e+00
  4.68126890e+00]
supnorm grad right now is: 4.681268898770991
Weights right now are: 
[ -1.61203313   2.62908363  -0.94866312   0.68562393   1.86660184
  -2.73777532   1.34760039  -1.40165231  57.33035622  23.52433884
  20.63488481  58.11068319  20.96276992   2.02022777   0.95422399
  22.29783394   2.66790838  81.72460625  32.9701817   -1.22769161
   1.50481756  -4.93593512  30.70332495   1.41945169   9.63402032
   5.64463045  -2.17967098 -16.97807712   2.48163556   1.83683639
  -1.48187496  -9.04188736   5.90755757   5.87233541  -9.44298827
 -13.6068703    9.63551216   5.7817011   -1.78632108 -17.79910926
 -50.26326945 -43.3954694    3.28923109 -10.10312513 -28.04956598
 -50.40827721 -20.55720249 -30.26513889  -3.05536281  -4.1819102
  27.51343791  19.10331624   2.64855815  16.9295845   31.08558965
  29.83980889  -4.8862262   -4.34141186   0.15073228  -4.8811787
   3.38054977  -4.41399707   2.97775651  -4.55512545  31.08534309]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.167258971022
gradient value of function right now is: [ 4.64870951e-01  1.35167104e+00  6.85233189e-02  8.61397564e-01
 -4.64870951e-01 -1.35167104e+00 -6.85233189e-02 -8.61397564e-01
  2.94599562e-06  4.86442407e-02  2.12375927e-02  2.35046209e-06
  2.79506063e-03  1.10197427e-01 -9.24322239e-02  3.01271334e-03
  7.04152425e-08  2.79984552e-03  1.65450164e-04  5.82121477e-08
  7.39885586e-05 -2.37670767e-02 -1.47653046e-02  7.65111475e-05
 -5.14459745e-02 -4.92146540e-02 -2.79852085e-02 -2.22398096e-02
 -1.11360529e+00 -1.10536072e+00 -4.86046306e-01 -1.26313816e-01
  2.78032891e-01  2.85100211e-01  4.06311436e-01 -1.16875737e-01
 -5.87889498e-02 -5.62082704e-02 -3.21041860e-02 -2.54497222e-02
  1.45878838e-02  6.35284764e-03  4.49485918e-03  4.31366764e-03
  1.42070101e-02  6.08792120e-03  4.24742703e-03  4.08504555e-03
  2.40809885e-01  2.26929974e-02 -1.03942449e-02 -8.04624017e-03
  9.72704811e-02 -2.57155364e-02 -2.44029877e-02 -2.31832283e-02
  2.27110325e-01 -1.24951867e+00  8.89373508e-02 -9.76977213e-01
 -4.82631905e-03 -1.05724379e+00 -1.27826186e-02 -9.75549958e-01
 -1.17374108e+01]
supnorm grad right now is: 11.737410843333286
Weights right now are: 
[-1.35830070e+00  2.97701017e+00 -7.91686998e-01  7.52862483e-01
  1.61286941e+00 -3.08570186e+00  1.19062427e+00 -1.46889087e+00
  5.81331649e+01  1.94748372e+01  2.11255169e+01  5.89722724e+01
  2.17988681e+01  1.62228003e+00  1.25837864e+00  2.31609012e+01
  2.78808483e+00  9.06755361e+01  3.32069162e+01 -1.13060263e+00
  1.39947010e-01 -4.21379827e+00  3.29502207e+01  1.08682832e-02
  9.78146832e+00  5.55162631e+00 -2.70420767e+00 -1.77857183e+01
  2.44324771e+00  1.74845395e+00 -1.36918957e+00 -8.86953002e+00
  5.92850102e+00  5.91498482e+00 -9.85170911e+00 -1.40680883e+01
  9.75513804e+00  5.65252846e+00 -2.33030347e+00 -1.86236068e+01
 -5.23463584e+01 -4.52335229e+01  2.71976180e+00 -1.09484700e+01
 -2.88003477e+01 -5.27931664e+01 -2.23735941e+01 -3.23010231e+01
 -3.85897508e+00 -3.89751442e+00  2.78229307e+01  1.93640625e+01
  2.61501321e+00  1.66632962e+01  3.08402374e+01  2.95921767e+01
 -4.83809171e+00 -4.31224853e+00  1.10875917e-01 -4.63816297e+00
  3.43651149e+00 -4.68993618e+00  2.93374989e+00 -4.77984802e+00
  3.10610782e+01]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.2737140376682
gradient value of function right now is: [ 5.55589920e-01  1.68738235e+00  9.02954926e-02  8.02804569e-01
 -5.55589920e-01 -1.68738235e+00 -9.02954926e-02 -8.02804569e-01
  5.84305053e-06  5.68320362e-02  2.99242350e-02  4.68349580e-06
  1.62797706e-03 -1.61020025e-01 -4.30705177e-01  1.81296665e-03
  1.49708525e-07  4.02484762e-03  2.19686235e-04  1.26692585e-07
  4.08900008e-05 -1.87131794e-02 -1.32668419e-02  4.32837055e-05
 -3.22530368e-02 -3.02955304e-02 -1.67376170e-02 -1.41238314e-02
 -9.28400655e-01 -9.22967211e-01 -2.73712852e-01 -7.34585075e-02
  2.48778884e-01  2.54338366e-01  3.09821285e-01 -4.18542493e-02
 -3.79376165e-02 -3.56474481e-02 -1.99087568e-02 -1.65207360e-02
  6.39851649e-03  2.00263402e-03  1.58012006e-03  1.45355053e-03
  7.12912781e-03  2.13063057e-03  1.61495930e-03  1.49506800e-03
  1.27893417e-01 -9.14580609e-04 -1.03905341e-02 -9.63382361e-03
  1.36387364e-01 -1.62642359e-02 -1.67357820e-02 -1.56608765e-02
  5.90417331e-02 -5.51393105e-01  9.08919455e-03 -4.20704938e-01
  8.04954046e-02 -6.79411088e-01  6.07061305e-02 -5.89276974e-01
 -1.21934986e+01]
supnorm grad right now is: 12.193498597167856
Weights right now are: 
[ -1.54777707   3.15823707  -1.13591381   0.62518288   1.80234579
  -3.26692877   1.53485108  -1.34121126  58.99387172  15.76517022
  22.62272828  59.90495792  22.99259744   1.6491713    1.18336244
  24.37195406   2.86660583  98.61697482  33.81800627  -1.06400877
  -2.37882327  -3.52809441  33.41925932  -2.50868022   9.9299493
   5.24540919  -3.16570383 -18.55434537   2.51558349   1.78427915
  -1.41913838  -9.74576226   6.0508719    6.04348442 -10.30888424
 -14.54858425   9.8972364    5.33464899  -2.79559375 -19.39285142
 -54.98342716 -46.56316042   3.26870666 -10.84173754 -29.3861143
 -55.27137947 -24.04774246 -34.30532829  -3.7608818   -3.88805998
  28.67330475  20.00231454   2.64282998  16.47092107  30.96112313
  29.74158711  -4.87310868  -4.15903764   0.15203808  -4.7434207
   3.87155213  -4.57337617   3.2942181   -4.72485834  31.01488905]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.187743851017
gradient value of function right now is: [-5.26041945e-01  4.40278303e-01 -9.50323627e-02 -4.48210493e-01
  5.26041945e-01 -4.40278303e-01  9.50323627e-02  4.48210493e-01
  8.91151751e-07 -2.63851502e-02  1.70814002e-03  9.82473664e-07
 -3.79692244e-03 -1.52481535e+00 -8.65449246e-01 -4.24850641e-03
 -5.59884781e-08 -6.05165245e-03 -1.48089713e-04 -4.87611266e-08
 -4.95736116e-05 -9.21955061e-02 -2.56317964e-02 -5.22850006e-05
  6.91443778e-02  6.76251405e-02  3.94062908e-02  3.21880415e-02
  1.88662850e+00  1.87115199e+00  8.35512515e-01  3.65041461e-01
  1.48475372e+00  1.46449819e+00  7.91058150e-01  4.95204901e-01
  8.17917304e-02  7.99468578e-02  4.66909446e-02  3.82258827e-02
 -2.59577496e-02 -1.10769591e-02 -9.53516595e-03 -8.94094988e-03
 -3.21060599e-02 -1.10900225e-02 -8.66855416e-03 -8.21614529e-03
  3.47889671e-01  7.30328298e-02  4.10155915e-02  4.07682972e-02
  5.26710852e-01  1.05899528e-01  6.29713182e-02  6.16919011e-02
 -4.61434302e-01  2.37903219e+00 -5.49811755e-01  2.38229234e+00
 -5.90369196e-01  2.87911229e+00 -5.52174003e-01  2.66251806e+00
  1.42580312e+01]
supnorm grad right now is: 14.258031186313339
Weights right now are: 
[ -1.53447362   2.83108716  -1.4453623    0.63409095   1.78904233
  -2.93977885   1.84429957  -1.35011934  60.2698874   13.31505624
  23.11256565  61.24861839  22.87348971   1.40333033   1.4627372
  24.25449377   2.90405359 104.93966599  30.88284109  -1.03198146
  -4.69949864  -2.93711699  33.76503322  -4.87325544  10.94142754
   5.9839886   -2.56771904 -18.25899235   2.66657957   1.90818906
  -1.27306205  -9.58359773   6.33743444   6.34445899 -10.66942294
 -14.60922853  10.90363545   6.06768486  -2.20519164 -19.09781243
 -56.96374381 -47.9310957    3.55126874 -10.94545263 -29.58864861
 -57.44418144 -25.447196   -36.01711085  -3.6083421   -3.94193019
  28.91648696  20.12242271   2.55519975  16.55116898  30.9737742
  29.84976789  -3.81652131  -4.39051709   0.34273826  -4.69794598
   3.54176605  -4.49838243   3.11409807  -4.60926663  31.11598793]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.563846289608
gradient value of function right now is: [ 2.63618760e-02 -7.33091756e-01  7.93287553e-02 -3.02149886e-01
 -2.63618760e-02  7.33091756e-01 -7.93287553e-02  3.02149886e-01
 -3.82705211e-06 -5.39551543e-02 -2.29749986e-02 -3.56155224e-06
 -7.99447971e-04  1.98939705e-01  1.76466045e-01 -8.70787964e-04
  1.06912173e-08  2.95832097e-03 -5.15370482e-05  9.77476235e-09
  1.55493521e-06  6.65419947e-02  1.55298766e-02  1.07697180e-06
  1.49783403e-02  1.45834331e-02  8.35919841e-03  7.14230426e-03
 -1.10556688e-02 -1.42153312e-02  1.44308143e-01  7.75071331e-02
 -2.92229084e-01 -2.94211684e-01 -2.58280723e-01 -3.24416934e-03
  1.71742985e-02  1.67179437e-02  9.62182386e-03  8.19419294e-03
 -4.53355677e-03 -1.67494944e-03 -1.70744080e-03 -1.48563018e-03
 -3.86091551e-03 -1.44177571e-03 -1.42544802e-03 -1.24462425e-03
 -2.18684652e-01 -2.41474625e-02 -3.53732608e-03 -4.68435546e-03
 -1.32043223e-01  4.53169373e-03  9.30008817e-03  8.03538432e-03
 -7.98411012e-02  4.57439482e-01 -1.28058605e-02  2.82911447e-01
  6.76395667e-02  3.01827749e-01  5.86023796e-02  2.76015265e-01
 -3.47361888e+00]
supnorm grad right now is: 3.473618884070676
Weights right now are: 
[ -1.41350384   2.78502943  -1.01934867   0.57594934   1.66807255
  -2.89372112   1.41828594  -1.29197772  61.50694525  10.75179087
  24.41394086  62.52666642  23.89001069   1.41322427   1.89900975
  25.26624606   2.92595853 111.07478968  28.92023057  -1.01307587
  -7.05890134  -2.81772796  33.19452514  -7.18689253  11.1247348
   5.57694453  -2.90171469 -18.78801763   2.46340882   1.64235054
  -1.25916457  -9.07509725   6.43376326   6.4555694  -11.19176071
 -15.22341353  11.10275715   5.67085717  -2.52549432 -19.60294761
 -59.48866011 -48.76957685   5.42683504  -9.54308753 -28.84997511
 -59.63680774 -26.33758257 -37.2884208   -3.76814626  -4.12587858
  29.38649885  20.45872647   2.85632641  16.47139642  30.83421002
  29.80990741  -4.12176328  -4.13939647   0.20857602  -4.76821316
   3.13689455  -4.52933668   2.74696867  -4.69662856  31.0943456 ]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.7296638574458
gradient value of function right now is: [-2.92907738e-01 -4.17193984e-01  1.96466181e-02 -5.11173522e-01
  2.92907738e-01  4.17193984e-01 -1.96466181e-02  5.11173522e-01
 -5.08240255e-06 -3.62016395e-02 -9.99700838e-03 -5.14388577e-06
  2.04894329e-03  2.00638963e-01  6.67998807e-02  2.27298539e-03
 -2.53942727e-08 -9.32907427e-04 -3.61316984e-04 -1.96213367e-08
  3.54014857e-05  5.80833487e-02  8.00914220e-03  3.70352220e-05
 -4.19326664e-02 -3.88853899e-02 -2.30960310e-02 -1.97607903e-02
  4.87543048e-01  4.92995327e-01  3.56877339e-01  4.15475931e-02
  5.02306110e-02  5.55039102e-02  9.10318512e-02 -2.13211704e-02
 -4.91820095e-02 -4.55962663e-02 -2.71518632e-02 -2.31628118e-02
  1.08116906e-02  3.80076759e-03  3.07625412e-03  2.65370929e-03
  8.50098677e-03  3.45229918e-03  2.92057718e-03  2.51527402e-03
  1.93207792e-01  1.26004978e-02 -3.58164981e-03 -2.17757423e-03
  2.82940095e-01  1.75991878e-02 -4.47605780e-03 -2.71422232e-03
  5.79281636e-02 -8.19745253e-01 -1.37084277e-01 -2.73745750e-01
 -1.07070382e-01 -3.97582097e-01 -9.35012643e-02 -3.31480335e-01
  4.56423158e+00]
supnorm grad right now is: 4.5642315751485665
Weights right now are: 
[-1.54703150e+00  2.75776112e+00 -1.47540206e+00  7.28614915e-01
  1.80160021e+00 -2.86645281e+00  1.87433933e+00 -1.44464330e+00
  6.30749465e+01  1.03072079e+01  2.53649414e+01  6.41839076e+01
  2.46028739e+01  1.23920027e+00  1.66850996e+00  2.59896351e+01
  2.94189201e+00  1.14397896e+02  2.68200361e+01 -9.99049933e-01
 -8.90423950e+00 -3.06688870e+00  3.33675510e+01 -9.19741660e+00
  1.14343300e+01  5.60035338e+00 -3.18624017e+00 -1.94103782e+01
  2.71878018e+00  1.84340945e+00 -1.28033775e+00 -9.43389548e+00
  6.72753735e+00  6.72016038e+00 -1.11823781e+01 -1.55312228e+01
  1.14061749e+01  5.68635926e+00 -2.81180917e+00 -2.02263749e+01
 -6.14100193e+01 -5.00515219e+01  6.41674347e+00 -8.96798803e+00
 -2.91868873e+01 -6.23993705e+01 -2.80412454e+01 -3.93393676e+01
 -3.68338753e+00 -4.21443023e+00  3.04864112e+01  2.14972881e+01
  3.12201565e+00  1.55368932e+01  3.00795674e+01  2.90390570e+01
 -3.81644159e+00 -4.41188535e+00  1.07732991e-01 -4.94677401e+00
  3.51106608e+00 -4.75469002e+00  3.19628087e+00 -4.95052974e+00
  3.11540936e+01]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.1870125156424
gradient value of function right now is: [ 1.08005273e-01  1.23546324e-01  7.17053396e-02  2.85737872e-01
 -1.08005273e-01 -1.23546324e-01 -7.17053396e-02 -2.85737872e-01
  6.01851400e-07 -4.07186590e-03 -1.36235228e-02  6.49865392e-07
 -7.70737173e-04 -3.13609597e-01 -2.79280094e-02 -8.55344445e-04
  4.40625955e-09  2.20737157e-03 -8.72199476e-05  4.05239746e-09
 -3.73443880e-05 -1.10804574e-01 -5.02255411e-03 -3.91472663e-05
  1.38684126e-02  1.39088373e-02  8.00813314e-03  6.98372131e-03
 -1.35172165e-01 -1.32688354e-01  7.97386677e-02  3.35803982e-02
  4.74035249e-01  4.69278587e-01  1.73647497e-01  1.93769661e-01
  1.61900547e-02  1.62314436e-02  9.37343294e-03  8.18641020e-03
 -8.90117946e-03 -3.56761987e-03 -3.98141032e-03 -3.27192853e-03
 -1.04107086e-02 -3.66670713e-03 -3.76878215e-03 -3.12803381e-03
  1.43125795e-02  7.71211238e-03  1.42180662e-02  1.14108771e-02
  1.17354193e-01  2.65461679e-02  2.36769072e-02  1.99608467e-02
 -1.23460638e-01  7.76915710e-01 -1.16083030e-01  6.78937526e-01
 -1.32461671e-01  1.15354146e+00 -1.03937534e-01  9.23255112e-01
  1.65244437e+01]
supnorm grad right now is: 16.52444374675238
Weights right now are: 
[ -1.5236921    2.65813781  -1.48509449   0.86770435   1.77826081
  -2.7668295    1.88403175  -1.58373274  64.567662    10.17245377
  26.19831148  65.7544659   24.87442251   1.52318772   1.66837309
  26.26181902   2.95359155 118.13266562  22.66314002  -0.98891946
  -9.37757513  -2.44966907  33.67592795  -9.73280661  12.02186491
   5.79121376  -3.09354459 -19.48537203   2.7492167    1.81594046
  -1.53761413  -9.92342314   6.87595407   6.82471331 -11.52049836
 -15.66721954  11.99089191   5.87696302  -2.72195851 -20.30161624
 -63.75723105 -51.05665461   8.12555569  -7.78250385 -29.21404559
 -64.76606025 -29.037109   -40.78641344  -3.94944883  -4.08263901
  31.20163489  22.12296746   3.05473067  15.11551466  30.1786988
  29.15312504  -4.02603767  -4.42542467   0.57989565  -5.04267931
   3.72267708  -4.67848014   3.40720021  -4.91446483  31.23593353]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.0135226003033
gradient value of function right now is: [-9.53651894e-01 -7.16757819e-01 -5.16742823e-02 -1.31732471e+00
  9.53651894e-01  7.16757819e-01  5.16742823e-02  1.31732471e+00
 -1.15216883e-06 -1.05663307e-01 -1.91464034e-02 -1.08399650e-06
 -3.40511527e-03 -1.28136871e+00 -9.65173362e-01 -3.83664144e-03
 -1.10779342e-08 -3.89303673e-03 -5.20146801e-04 -9.17296041e-09
 -8.32284187e-06  5.02593796e-02  4.65476510e-03 -8.96945559e-06
  6.73840895e-02  6.40597549e-02  3.95076943e-02  3.46263195e-02
  2.02766014e+00  2.00469985e+00  1.00806084e+00  4.11964229e-01
  8.99538434e-01  8.74778833e-01  4.95852190e-01  3.31001906e-01
  7.98667795e-02  7.58752046e-02  4.68871464e-02  4.11376144e-02
 -2.13168304e-02 -7.04790754e-03 -7.02598574e-03 -5.69854443e-03
 -2.63426834e-02 -6.89337118e-03 -6.09891615e-03 -4.98413165e-03
  2.63580407e-01  4.84433347e-02  2.77376426e-02  2.40653499e-02
  4.57712417e-01  8.41899854e-02  5.45699112e-02  4.65401187e-02
 -5.27421543e-01  2.55994189e+00 -3.71829943e-01  1.69186106e+00
 -4.52098867e-01  2.27082296e+00 -3.68926527e-01  1.85216716e+00
  5.99939938e+00]
supnorm grad right now is: 5.999399380452723
Weights right now are: 
[-1.57566286e+00  2.73489417e+00 -1.04493433e+00  6.93989970e-01
  1.83023157e+00 -2.84358586e+00  1.44387160e+00 -1.41001835e+00
  6.59043111e+01  9.82355953e+00  2.76763809e+01  6.71866323e+01
  2.51685511e+01  1.15350963e+00  1.29764319e+00  2.65536201e+01
  2.96230492e+00  1.22370774e+02  2.21342695e+01 -9.81089441e-01
 -9.68919282e+00 -2.05638718e+00  3.43516524e+01 -1.00668153e+01
  1.26442870e+01  6.09823789e+00 -3.06903989e+00 -1.97010870e+01
  2.87632980e+00  1.82592871e+00 -1.26481957e+00 -1.01114446e+01
  6.96036757e+00  6.84231327e+00 -1.20595490e+01 -1.55540270e+01
  1.26109697e+01  6.18135123e+00 -2.69660191e+00 -2.05096252e+01
 -6.64682821e+01 -5.25065032e+01  9.55662077e+00 -6.84230542e+00
 -2.96090764e+01 -6.77144925e+01 -3.05613664e+01 -4.27666862e+01
 -3.95338806e+00 -4.31066456e+00  3.26079633e+01  2.33718882e+01
  3.23280350e+00  1.46628424e+01  2.96633711e+01  2.86455345e+01
 -3.96334313e+00 -4.29119278e+00 -4.00551784e-02 -4.88434176e+00
  3.56006674e+00 -4.51665262e+00  3.29817936e+00 -4.75289010e+00
  3.10579229e+01]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.6295107899564
gradient value of function right now is: [ 1.16760877e-01  2.38796357e-01  1.03078108e-01 -5.22373080e-02
 -1.16760877e-01 -2.38796357e-01 -1.03078108e-01  5.22373080e-02
 -1.70605921e-06 -2.53984443e-02 -8.34794136e-03 -1.65301792e-06
 -1.68546985e-03 -4.48094749e-01 -5.44322274e-01 -1.80872487e-03
  1.07083416e-09  2.21380305e-03  7.55375443e-05  1.08623296e-09
  7.97762656e-06  7.79294980e-02  1.41008370e-02  7.88754861e-06
  3.49334168e-02  3.26976891e-02  2.07830453e-02  1.81720876e-02
  1.45432417e-01  1.33431918e-01  2.80355276e-01  1.42866242e-01
  2.25202714e-01  2.12513468e-01  1.86046005e-01  9.35985578e-02
  3.93224371e-02  3.67856607e-02  2.34136835e-02  2.05082549e-02
 -5.30133714e-03 -1.37671637e-03 -1.17565050e-03 -8.53185610e-04
 -8.62921229e-03 -1.14790707e-03 -6.64013624e-04 -4.71714267e-04
  1.04747784e-01 -4.96949038e-03 -5.19894306e-03 -4.69193983e-03
  2.63394221e-01  1.77745871e-02  1.31953738e-03  1.03933692e-03
 -3.04225503e-01  9.23368791e-01 -1.70461036e-01  3.81747270e-01
 -1.27418714e-02 -6.93609953e-03 -1.63642881e-02  2.83839641e-02
  1.02909353e+00]
supnorm grad right now is: 1.029093527229227
Weights right now are: 
[-1.70914743e+00  2.83748621e+00 -1.13196375e+00  7.68176770e-01
  1.96371614e+00 -2.94617790e+00  1.53090102e+00 -1.48420515e+00
  6.71146616e+01  9.43186841e+00  2.76370128e+01  6.84357679e+01
  2.59467586e+01  1.09333853e+00  1.73351584e+00  2.73103011e+01
  2.96932087e+00  1.27420646e+02  1.99496510e+01 -9.75293967e-01
 -1.12365021e+01 -1.50789765e+00  3.58689030e+01 -1.15727641e+01
  1.31393704e+01  5.72227598e+00 -3.07713720e+00 -1.99105993e+01
  2.87466371e+00  1.72741595e+00 -1.04983971e+00 -9.93671639e+00
  7.18377146e+00  7.02505904e+00 -1.20562139e+01 -1.60992578e+01
  1.31244854e+01  5.82067185e+00 -2.67302037e+00 -2.06890190e+01
 -6.91786347e+01 -5.28700066e+01  1.24364871e+01 -4.53917288e+00
 -2.89988829e+01 -7.02640994e+01 -3.11782480e+01 -4.39359126e+01
 -4.36271298e+00 -4.57547686e+00  3.27297255e+01  2.33663974e+01
  3.32906070e+00  1.36599577e+01  2.87509709e+01  2.76883447e+01
 -3.92170859e+00 -4.29168317e+00 -1.26621910e-01 -4.99275987e+00
  4.03065083e+00 -4.75536034e+00  3.73007929e+00 -5.06350346e+00
  3.11003054e+01]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.290655145002
gradient value of function right now is: [-1.01792435e+00 -5.12182120e-01 -2.92937695e-01 -1.27633609e+00
  1.01792435e+00  5.12182120e-01  2.92937695e-01  1.27633609e+00
 -5.73222963e-06 -5.83629061e-02 -1.75429397e-03 -5.63777238e-06
 -1.11802483e-03 -6.54388679e-01 -5.70820446e-01 -1.15070383e-03
 -3.78807745e-08 -8.38883090e-03  2.70394956e-04 -3.12568949e-08
  2.09847867e-05  6.59625803e-02  1.72979207e-04  2.13884669e-05
  2.98511022e-02  2.67956721e-02  1.65299160e-02  1.26778783e-02
  2.11569997e+00  2.09044804e+00  7.97990578e-01  2.76609570e-01
  6.04986836e-01  5.77302340e-01  3.95943919e-01  1.99480725e-01
  3.22014829e-02  2.88406480e-02  1.77900592e-02  1.37346349e-02
 -2.47439793e-03  1.43267147e-04  5.06999507e-04  3.68871516e-04
 -1.55750991e-02 -1.06489441e-03  4.03023005e-05 -6.80741296e-06
  3.60610313e-01  4.02532780e-02  1.31819479e-02  1.27152366e-02
  5.75414152e-01  5.41825884e-02  2.00609714e-02  1.76227993e-02
 -4.74380336e-01  1.05658092e+00 -2.67743989e-01  5.28363773e-01
 -3.36834142e-01  6.21433007e-01 -2.63193950e-01  4.79684292e-01
  4.08601966e+00]
supnorm grad right now is: 4.086019662686583
Weights right now are: 
[-1.68174391e+00  2.80837808e+00 -1.37952777e+00  8.55329978e-01
  1.93631263e+00 -2.91706977e+00  1.77846504e+00 -1.57135836e+00
  6.82795906e+01  9.53763093e+00  2.98813197e+01  6.96217377e+01
  2.71767803e+01  1.19218351e+00  1.40331699e+00  2.85346362e+01
  2.97379013e+00  1.31224603e+02  1.92096842e+01 -9.71597656e-01
 -1.15400450e+01 -2.12200876e+00  3.51421399e+01 -1.18835727e+01
  1.31619446e+01  5.01853768e+00 -3.49358762e+00 -2.06955082e+01
  3.09091234e+00  1.79201706e+00 -1.36668882e+00 -9.86670665e+00
  7.47071874e+00  7.27620280e+00 -1.23300409e+01 -1.60066703e+01
  1.31476866e+01  5.12313961e+00 -3.08962359e+00 -2.14747454e+01
 -7.13937537e+01 -5.33703341e+01  1.48200342e+01 -2.91108377e+00
 -2.90176897e+01 -7.22682868e+01 -3.16754071e+01 -4.50782762e+01
 -4.23926103e+00 -3.39059732e+00  3.41420167e+01  2.48768890e+01
  3.56753812e+00  1.33005286e+01  2.83425539e+01  2.72887733e+01
 -4.49784137e+00 -4.38033302e+00 -7.31866175e-02 -5.14982462e+00
  3.81718768e+00 -4.75155826e+00  3.43595294e+00 -5.10826301e+00
  3.10974285e+01]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.5560231098427
gradient value of function right now is: [ 5.09871654e-01 -1.11735566e-02  9.04821921e-02  5.43679585e-01
 -5.09871654e-01  1.11735566e-02 -9.04821921e-02 -5.43679585e-01
 -1.10943367e-06  4.29139253e-02  4.41574230e-03 -1.31291717e-06
  6.44104152e-03  1.78233448e+00  8.17979888e-01  7.11381758e-03
  8.84970958e-09  3.37686856e-03  1.91610387e-04  7.43928197e-09
  8.84580536e-05  7.34852098e-02  1.60100642e-02  9.45053023e-05
 -1.55443233e-01 -1.48002449e-01 -8.33763321e-02 -7.11291959e-02
 -1.69329813e+00 -1.66697550e+00 -6.85168112e-01 -4.01690884e-01
 -1.30609357e+00 -1.27525577e+00 -6.26624083e-01 -5.33004824e-01
 -1.79872560e-01 -1.71152499e-01 -9.65244496e-02 -8.24860151e-02
  2.88192303e-02  1.13165996e-02  9.36755501e-03  7.02794019e-03
  3.41426983e-02  1.05962236e-02  7.37268863e-03  5.58418313e-03
 -3.14514670e-01 -7.24845449e-02 -3.59269313e-02 -2.84683144e-02
 -5.34074947e-01 -1.22516176e-01 -6.27400662e-02 -4.89024576e-02
  6.54164687e-01 -3.16074515e+00  5.49653484e-01 -2.46198385e+00
  5.15042162e-01 -2.62727000e+00  3.82613107e-01 -1.96305916e+00
  4.23361465e-01]
supnorm grad right now is: 3.1607451461325264
Weights right now are: 
[ -1.57331551   2.80777726  -1.50013398   0.96229668   1.82788422
  -2.91646895   1.89907124  -1.67832507  69.22940761   9.38421875
  30.91916762  70.63196301  28.0475506    1.30922276   1.60407542
  29.44294555   2.97759193 134.63732179  15.04738544  -0.96848409
 -10.27992317  -1.92891325  35.06052014 -10.71289637  13.39140166
   4.97926837  -3.98769638 -21.47906954   3.04698612   1.56914735
  -1.45410444 -10.26767565   7.41009532   7.17421391 -12.67667784
 -16.39689858  13.35844363   5.06473586  -3.60378021 -22.29050322
 -73.00839273 -54.83796677  15.37260379  -2.78459828 -30.06604898
 -74.20259926 -32.84552691 -46.64813085  -4.07911789  -3.50452581
  35.13082967  25.58159275   2.97710316  13.29794495  27.63738219
  26.51786004  -4.2003944   -4.64271202  -0.37595298  -5.08159217
   4.40712205  -4.72179639   4.1358991   -5.06170643  31.22092657]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.0771777408274
gradient value of function right now is: [ 6.89126503e-01  1.31278677e+00  1.42453857e-01  7.68075905e-01
 -6.89126503e-01 -1.31278677e+00 -1.42453857e-01 -7.68075905e-01
 -5.65011751e-07  4.68499075e-02  1.45845166e-02 -6.82476395e-07
  1.26388947e-05 -1.56793904e-01 -3.23448825e-01  1.49308900e-05
  5.47343749e-09  4.83856302e-03  6.32290266e-04  4.62889673e-09
  1.87782745e-05  2.00907257e-02 -5.89113019e-03  2.07535513e-05
  2.69951032e-04 -5.91926076e-05  4.61773120e-04  1.53022075e-04
 -9.26033675e-01 -9.29063014e-01 -2.27200989e-01 -4.05835329e-02
  1.45236020e-01  1.41826961e-01  2.17422621e-01 -3.13077454e-02
  2.88540822e-04 -1.09590934e-04  5.15517122e-04  1.73631082e-04
  5.20592947e-03  2.24425634e-03  2.41557592e-03  1.65533617e-03
  2.26671876e-03  1.93721491e-03  2.13450698e-03  1.46526085e-03
  1.25394664e-01 -4.99384331e-03 -1.47784032e-02 -1.10338041e-02
  1.39390819e-01 -1.79009651e-02 -2.18728167e-02 -1.58158962e-02
 -6.98595098e-02 -3.34027093e-01  3.82850623e-03 -3.87410535e-01
  1.05555552e-01 -8.89586163e-01  6.98364659e-02 -5.94952029e-01
 -1.03714514e+01]
supnorm grad right now is: 10.371451366060768
Weights right now are: 
[-1.44200596e+00  2.87981734e+00 -1.71633594e+00  8.71498289e-01
  1.69657467e+00 -2.98850903e+00  2.11527320e+00 -1.58752667e+00
  7.03651528e+01  9.58263558e+00  3.19600035e+01  7.18898151e+01
  2.82032942e+01  1.09293785e+00  1.51226798e+00  2.95953674e+01
  2.97971547e+00  1.38644258e+02  1.27480283e+01 -9.66479712e-01
 -1.11555634e+01 -9.68450404e-01  3.51386783e+01 -1.17692435e+01
  1.42539910e+01  5.30893168e+00 -3.66605774e+00 -2.14246509e+01
  3.31160710e+00  1.64529896e+00 -1.69355430e+00 -9.97739996e+00
  7.57551927e+00  7.31479643e+00 -1.29175240e+01 -1.62730882e+01
  1.42106196e+01  5.38651601e+00 -3.28402980e+00 -2.22390932e+01
 -7.51887186e+01 -5.58329738e+01  1.66386378e+01 -1.91016378e+00
 -3.02777507e+01 -7.62778590e+01 -3.33932309e+01 -4.76672877e+01
 -3.79152850e+00 -2.32703306e+00  3.66840858e+01  2.71568618e+01
  3.29919948e+00  1.26218101e+01  2.67976229e+01  2.55681859e+01
 -4.69474696e+00 -4.41396942e+00 -3.95943564e-02 -5.00391844e+00
  3.98669079e+00 -4.58594377e+00  3.71421683e+00 -5.02678957e+00
  3.10308772e+01]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.0730750774376
gradient value of function right now is: [ 6.27051744e-01 -1.79664206e-01  1.01574069e-01  7.02127694e-01
 -6.27051744e-01  1.79664206e-01 -1.01574069e-01 -7.02127694e-01
 -1.59695022e-07  4.34522758e-02 -1.71599553e-03 -1.80851713e-07
 -1.44118122e-04  1.30894121e+00  7.64276335e-01 -1.71558454e-04
  3.17016061e-10  2.89305531e-03 -1.25257328e-04  2.82552973e-10
  4.59613611e-06  4.44579118e-02  1.61252962e-02  5.04747379e-06
  7.49154010e-04  1.88042418e-03  1.38631364e-03  1.66586238e-03
 -1.40950145e+00 -1.38859529e+00 -5.58482112e-01 -3.08668693e-01
 -1.19928245e+00 -1.17522059e+00 -6.38789782e-01 -4.45489834e-01
  9.82648565e-04  2.36572649e-03  1.71470709e-03  2.04661583e-03
  1.62896613e-02  7.41945113e-03  5.94191393e-03  4.12964990e-03
  2.29128886e-02  8.20989960e-03  5.54651990e-03  3.85612562e-03
 -2.34630070e-01 -5.95587611e-02 -2.96673635e-02 -2.13000384e-02
 -3.52176364e-01 -9.07345912e-02 -4.67575308e-02 -3.35461580e-02
  4.55035488e-01 -1.91638182e+00  4.31019618e-01 -1.70871042e+00
  4.12015858e-01 -2.03342432e+00  2.76332906e-01 -1.35324426e+00
 -9.24710995e+00]
supnorm grad right now is: 9.247109946849646
Weights right now are: 
[ -1.41829534   2.63616491  -1.1246103    1.09886617   1.67286405
  -2.7448566    1.52354757  -1.81489455  71.30009427   8.86238876
  31.21250655  72.9196398   27.74892991   1.09185562   1.69219943
  29.14010088   2.98081007 142.80660665  10.82653244  -0.96546868
 -10.64445175  -1.1315466   36.71384464 -11.40811964  15.32157914
   6.03105623  -2.99967073 -20.81150522   3.25318576   1.45519381
  -1.25976493  -9.6614734    7.63499575   7.3386303  -13.1483241
 -16.5016234   15.28184305   6.1085922   -2.61222433 -21.62953244
 -77.48025994 -56.95891881  17.96574413  -1.10831315 -29.73705898
 -78.00423451 -33.63971409 -48.4947327   -4.13063589  -3.38617169
  36.57750777  26.74543016   3.11518477  12.12063793  26.16659458
  24.78996172  -3.66557205  -4.67306375  -0.23636815  -4.96964774
   4.01295861  -4.64440983   3.82795815  -5.07419315  31.1131277 ]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.3864020140725
gradient value of function right now is: [ 5.66531986e-01  9.37750376e-01  1.53993846e-01  5.46644892e-01
 -5.66531986e-01 -9.37750376e-01 -1.53993846e-01 -5.46644892e-01
 -7.92050850e-07  3.17085406e-02  1.73248603e-02 -8.44752546e-07
  2.44232499e-04  4.29055774e-01 -5.50117018e-03  2.62101937e-04
  1.62678843e-09  3.84130770e-03  2.61096041e-03  1.18992440e-09
  1.34372760e-05  5.92405317e-02 -5.02709442e-03  1.40948614e-05
 -6.57626459e-03 -5.89523390e-03 -3.12244676e-03 -2.81361038e-03
 -9.62213644e-01 -9.59131781e-01 -3.20114970e-01 -1.35841086e-01
 -2.50879696e-01 -2.52269742e-01 -3.23933349e-02 -1.54386321e-01
 -7.42990337e-03 -6.64298459e-03 -3.53525054e-03 -3.17879266e-03
  1.25650824e-02  5.46783495e-03  6.07443069e-03  3.84160366e-03
  1.04828713e-02  4.48704887e-03  4.61936208e-03  2.91306828e-03
  7.65502191e-02 -1.50320770e-02 -2.05495772e-02 -1.35790792e-02
  9.24756340e-02 -2.22881519e-02 -3.49510507e-02 -2.26577170e-02
  1.24821863e-01 -1.22099553e+00  2.47186046e-02 -8.19902832e-01
  1.70890086e-01 -1.42022616e+00  1.10183141e-01 -8.86889482e-01
 -8.57198053e+00]
supnorm grad right now is: 8.571980525957283
Weights right now are: 
[ -1.60145541   2.84278754  -1.14102567   0.87712387   1.85602412
  -2.95147923   1.53996294  -1.59315225  72.35912121   9.09137897
  33.81776095  74.0590741   28.7743043    1.2574421    1.3855744
  30.14059626   2.98187355 145.64673838   9.62204695  -0.96457403
 -10.9757198   -1.01006558  35.63749915 -11.87605309  15.51686585
   5.15967205  -3.114888   -21.27955116   3.4383244    1.41754279
  -1.1623645   -9.95703969   7.80017975   7.44902944 -13.15863773
 -16.83702028  15.49779562   5.2620119   -2.70540125 -22.07766411
 -79.72298934 -57.31423728  21.16337711   1.46579798 -29.89243114
 -79.89443284 -33.81516542 -49.31822027  -3.67441219  -2.80284237
  37.63037807  27.58734464   3.13727002  11.93645617  25.18762045
  23.7895292   -4.0005549   -4.66908391  -0.52663452  -5.14907509
   4.11223289  -4.52841381   4.10729102  -5.03544176  31.08431602]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.7870873420625
gradient value of function right now is: [ 2.65242609e-01 -4.82297314e-01  1.11807927e-01  1.62357453e-01
 -2.65242609e-01  4.82297314e-01 -1.11807927e-01 -1.62357453e-01
 -1.11866988e-06 -1.26182552e-02 -5.85970622e-03 -1.21472716e-06
 -1.06168687e-03  4.21053785e-01  2.64699703e-01 -1.22650082e-03
  4.18747504e-10  2.17100592e-03  4.49050702e-04  3.62875594e-10
  4.09232275e-06  5.42123967e-02  1.51906059e-02  4.46579332e-06
  2.07230418e-02  2.13014269e-02  1.30575849e-02  1.30473760e-02
 -4.74799105e-01 -4.58871205e-01 -1.49945498e-01 -3.24911874e-02
 -7.66824114e-01 -7.42981845e-01 -4.08577354e-01 -2.47519512e-01
  2.50152670e-02  2.56898760e-02  1.57655370e-02  1.57446407e-02
  2.33170763e-03  3.62883868e-04 -6.07126393e-04 -1.75713201e-04
  1.08009335e-02  2.33876447e-03  1.69908648e-03  9.76207946e-04
 -2.70280460e-01 -4.30904510e-02 -1.94702108e-02 -1.16734756e-02
 -2.90433870e-01 -4.07938105e-02 -1.97571350e-02 -1.15591083e-02
  1.19540891e-01 -3.75909480e-01  1.65595968e-01 -4.05358085e-01
  3.50885064e-01 -9.93727745e-01  1.78614402e-01 -4.75338501e-01
 -5.29446614e+00]
supnorm grad right now is: 5.294466142956603
Weights right now are: 
[ -1.7109996    2.73793838  -1.30192242   0.94994952   1.96556831
  -2.84663007   1.70085969  -1.6659779   74.09197824   8.81232355
  33.06543806  75.95837324  28.89251389   0.83215794   1.67975577
  30.26817905   2.98296778 150.6532603   10.17531573  -0.96368625
 -12.20514051  -2.024715    37.35872015 -13.39128172  16.12035158
   5.06256799  -2.71296108 -21.08964561   3.75553045   1.32206424
  -1.29291232  -8.45422845   7.81011117   7.47817968 -13.41686814
 -17.31742749  16.08690763   5.15020335  -2.32225026 -21.9076326
 -82.15329852 -58.47680711  24.07094114   3.62722435 -28.74091068
 -81.98383548 -34.3206073  -50.66771595  -4.08325578  -3.26034258
  38.48362329  28.15058481   3.34540829  10.66788708  23.97965532
  22.33891476  -3.89298222  -4.62948385   0.28079344  -5.24871851
   4.76246845  -4.30292257   4.71890222  -5.0161297   31.10515967]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.6322052540172
gradient value of function right now is: [ 5.73087356e-01  1.18415775e+00  1.02268824e-01  8.05935271e-01
 -5.73087356e-01 -1.18415775e+00 -1.02268824e-01 -8.05935271e-01
  7.75721071e-07  5.87943561e-02  5.84418609e-03  8.16366714e-07
  2.47902276e-04 -4.10196363e-01 -3.91748309e-01  2.91955981e-04
  8.68357521e-10  3.58310489e-03  5.02189913e-04  7.50050256e-10
 -8.56164968e-06 -7.63492983e-02 -7.13947172e-03 -9.28694029e-06
 -4.77903014e-03 -4.80897258e-03 -3.17949077e-03 -3.35023670e-03
 -8.71535236e-01 -8.81258902e-01 -1.34930012e-01 -5.51178392e-02
  4.23042206e-01  4.15973468e-01  2.48366195e-01  1.37533517e-01
 -5.89126022e-03 -5.93510216e-03 -3.89878688e-03 -4.09308953e-03
  1.66483238e-04  1.18385889e-04 -1.00338307e-04 -3.81635019e-06
 -6.96996815e-03 -7.56266125e-04 -8.25388448e-04 -3.66227863e-04
  1.29101347e-01  2.98011379e-03  3.29716186e-03  7.40649378e-04
  1.74794387e-01 -1.41346877e-04 -7.63918840e-03 -4.95635770e-03
 -1.62786316e-01  1.91776668e-01 -5.72652235e-02  6.53960748e-02
 -3.51975263e-02  1.09294927e-01  1.70082635e-04  1.73208782e-02
  7.02984225e+00]
supnorm grad right now is: 7.029842249880846
Weights right now are: 
[-1.73951591e+00  2.72169864e+00 -1.62953094e+00  1.09606327e+00
  1.99408462e+00 -2.83039033e+00  2.02846821e+00 -1.81209165e+00
  7.56276045e+01  8.70010217e+00  3.21864714e+01  7.76355598e+01
  2.99470625e+01  1.03829777e+00  1.38521590e+00  3.13267515e+01
  2.98365509e+00  1.54674014e+02  1.25937955e+01 -9.63111220e-01
 -1.21384709e+01 -2.81039726e+00  3.78794392e+01 -1.33601271e+01
  1.62708843e+01  4.49014463e+00 -3.21996373e+00 -2.18801203e+01
  3.85904212e+00  8.42404048e-01 -1.12631466e+00 -8.35160798e+00
  7.92750091e+00  7.53067417e+00 -1.33840308e+01 -1.80165602e+01
  1.62381476e+01  4.58071492e+00 -2.83144678e+00 -2.27020580e+01
 -8.44005530e+01 -5.87014147e+01  2.79972299e+01  6.71673074e+00
 -2.69169097e+01 -8.40025501e+01 -3.46956819e+01 -5.21250520e+01
 -3.93719067e+00 -2.37151631e+00  3.94843791e+01  2.92071552e+01
  3.41417398e+00  9.48226075e+00  2.21426198e+01  2.00581795e+01
 -3.99936240e+00 -4.92557700e+00  7.82549686e-02 -5.51925432e+00
  4.45528720e+00 -4.13657066e+00  4.38069056e+00 -5.08387948e+00
  3.11585121e+01]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.1180369321312
gradient value of function right now is: [-7.13363030e-01 -8.21498327e-01 -1.36086013e-01 -8.04373616e-01
  7.13363030e-01  8.21498327e-01  1.36086013e-01  8.04373616e-01
  6.72903389e-06 -6.09319768e-02 -2.28421810e-02  7.49022883e-06
 -3.42674537e-03 -7.92956896e-01 -6.46022774e-01 -3.84111266e-03
 -1.43379426e-09 -4.26678615e-03 -6.12181372e-04 -1.32752767e-09
 -1.40945993e-04 -1.47523138e-02  7.45337434e-03 -1.55203294e-04
  7.26316989e-02  7.96033769e-02  3.63732595e-02  4.01531479e-02
  1.52343600e+00  1.52919195e+00  3.79430166e-01  3.00022344e-01
  6.98524139e-01  7.21696554e-01  2.11342761e-01  4.28259176e-01
  8.49445385e-02  9.30057303e-02  4.25991876e-02  4.69998722e-02
 -3.26357986e-02 -1.12331519e-02 -3.27170060e-02 -1.02571898e-02
 -3.03032073e-02 -6.74561963e-03 -1.48169418e-02 -4.56077375e-03
 -6.19789651e-02 -3.69078881e-03  4.70123867e-02  1.49115626e-02
  1.14149940e-01  4.47874196e-02  1.04662989e-01  3.68874277e-02
 -7.77152279e-01  3.76800783e+00 -2.37300844e-01  1.46217510e+00
 -4.55610416e-01  3.21552760e+00 -1.45528181e-01  1.12771876e+00
  3.36160406e+00]
supnorm grad right now is: 3.7680078252808475
Weights right now are: 
[ -1.69686474   2.60881101  -1.595422     0.99551511   1.95143345
  -2.7175027    1.99435927  -1.7115435   77.39112881   9.78574323
  32.45102184  79.57013892  30.17568313   0.75476574   1.61095355
  31.53616623   2.98420968 157.99674549  12.16621825  -0.96264625
 -13.68290433  -1.82319987  37.19234151 -15.05879121  16.68177881
   4.25236831  -2.91781385 -21.84050812   4.26704      0.67265035
  -1.50945821  -7.3125357    8.30063658   7.83326103 -13.95445733
 -17.35511038  16.66162769   4.35500715  -2.5217569  -22.65386698
 -86.85118866 -59.86033596  30.22798974   8.22259509 -26.08402235
 -86.44397693 -35.00151191 -53.59488265  -3.67600168  -2.59615079
  40.73646685  30.60922447   3.21583836   6.99220071  20.48260295
  17.52505967  -4.10042942  -4.71605463  -0.38184702  -5.33283628
   4.57246009  -3.6976636    4.79104507  -4.89541794  31.03599552]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.7634007263775
gradient value of function right now is: [-7.17498538e-03 -6.08897511e-01  8.58716103e-02 -1.79491695e-01
  7.17498538e-03  6.08897511e-01 -8.58716103e-02  1.79491695e-01
 -3.77043667e-06 -2.87770516e-02 -4.96287649e-03 -4.12567673e-06
  2.39102011e-03  6.88245626e-01  6.71171790e-01  2.69168604e-03
 -6.39629980e-12  1.22443242e-03  3.29584637e-05 -1.13320830e-12
  3.74360467e-05  7.01120011e-02  1.08936646e-02  4.11428513e-05
 -4.91897293e-02 -5.12522504e-02 -2.82572319e-02 -3.07701457e-02
 -2.39299408e-01 -2.27837453e-01 -1.49724350e-02 -6.84229823e-02
 -4.90556335e-01 -5.01886578e-01 -2.19848738e-01 -2.38510260e-01
 -5.77611963e-02 -6.01338309e-02 -3.32198093e-02 -3.61538389e-02
  1.77535039e-02  6.42472335e-03  1.68931441e-02  4.62952636e-03
  1.39955840e-02  4.00889126e-03  7.82656728e-03  2.11305103e-03
 -3.88552441e-02 -1.06111845e-02 -2.18160938e-02 -5.91048399e-03
 -4.52067788e-02 -1.12229339e-02 -3.71386094e-02 -9.62683098e-03
  4.50023799e-01 -1.86015021e+00  1.53526262e-01 -7.70636331e-01
  2.38759883e-01 -1.23739328e+00  6.18271044e-02 -3.79560885e-01
 -1.01420369e+01]
supnorm grad right now is: 10.142036860312919
Weights right now are: 
[-1.87754355e+00  2.64379084e+00 -1.12712961e+00  9.33821873e-01
  2.13211226e+00 -2.75248253e+00  1.52606688e+00 -1.64985026e+00
  7.89958347e+01  9.95244857e+00  3.39013967e+01  8.13011939e+01
  3.01667947e+01  9.57377480e-01  1.52083316e+00  3.15188290e+01
  2.98442930e+00  1.61864708e+02  1.23204113e+01 -9.62460114e-01
 -1.01582884e+01 -1.67982578e+00  3.67541934e+01 -1.14490599e+01
  1.74830513e+01  4.42395929e+00 -2.40462328e+00 -2.15466442e+01
  4.42913308e+00  4.55916355e-01 -1.11555736e+00 -7.29305509e+00
  8.42859638e+00  7.81771168e+00 -1.37579219e+01 -1.78192178e+01
  1.74701854e+01  4.53262099e+00 -2.00206388e+00 -2.23533855e+01
 -8.92073046e+01 -6.12273653e+01  3.21605104e+01  9.17551922e+00
 -2.31903100e+01 -8.79013615e+01 -3.48331480e+01 -5.46265620e+01
 -3.74860030e+00 -1.66989274e+00  4.15819384e+01  3.15157453e+01
  3.03464525e+00  5.45218388e+00  1.84902105e+01  1.45969424e+01
 -3.03654562e+00 -4.99941039e+00 -1.17027713e-01 -5.48002805e+00
  4.53422287e+00 -3.72042411e+00  5.16045304e+00 -5.01694879e+00
  3.10291240e+01]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1043.7931339062388
gradient value of function right now is: [ 6.39497455e-01 -1.28164737e+00  1.06505980e-01  7.56572745e-01
 -6.39497455e-01  1.28164737e+00 -1.06505980e-01 -7.56572745e-01
 -3.19645004e-07  4.91638714e-02 -5.14071087e-04 -3.55978944e-07
  5.25493514e-04  2.14297715e+00  2.90557924e+00  5.89679407e-04
  6.33543109e-11  2.62628216e-03  2.01278551e-05  5.91008746e-11
  9.06613682e-06  1.12212388e-02  1.33400700e-02  1.00483917e-05
 -1.40051326e-02 -1.09254766e-02 -7.51414422e-03 -7.30468607e-03
 -2.15371588e+00 -2.06522373e+00 -8.44929034e-01 -6.45447870e-01
 -2.55532848e+00 -2.43608235e+00 -1.40158409e+00 -1.00984925e+00
 -1.64707482e-02 -1.28172320e-02 -8.85371666e-03 -8.59913887e-03
  3.31883666e-02  1.05030374e-02  2.41501805e-02  6.34813072e-03
  7.40612642e-02  1.25603159e-02  1.78247805e-02  4.20161868e-03
 -8.47739916e-01 -1.05798215e-01 -7.61410594e-02 -1.83470765e-02
 -1.14399491e+00 -1.51218040e-01 -1.27693133e-01 -3.31485396e-02
  1.54893013e+00 -4.39030610e+00  7.05867411e-01 -1.94142219e+00
  1.52373494e+00 -4.28095401e+00  2.88921131e-01 -9.60363744e-01
 -1.39014491e+01]
supnorm grad right now is: 13.901449068071873
Weights right now are: 
[ -1.63120952   2.64888572  -1.25418393   1.06955109   1.88577823
  -2.75757741   1.6531212   -1.78557947  80.82370583  10.47597996
  33.51378491  83.30331146  29.91966359   0.97495198   1.83245524
  31.26947121   2.98464656 166.02142676  12.23146964  -0.96227235
 -11.52517461  -1.46347748  36.77916832 -12.77667153  18.39926107
   4.80131452  -1.79880581 -21.12164237   4.54311303   0.32441531
  -1.64560205  -7.32413374   8.51599171   7.78103689 -14.46400667
 -17.95467215  18.38981961   4.90731666  -1.39125612 -21.92751847
 -91.73498693 -63.25207868  32.73210034   8.65793219 -20.00614715
 -88.80247559 -34.04112301 -54.96521761  -4.07968153  -1.73287286
  42.28801539  32.02487642   3.44614961   4.54285025  17.51534009
  12.51965057  -2.94794479  -4.94146097   0.51017171  -5.44185462
   4.46391516  -3.82139027   5.71946183  -5.14455242  31.08819035]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.646777135592
gradient value of function right now is: [-4.24346704e-01  1.79118592e-01  4.56250294e-02 -6.13731512e-01
  4.24346704e-01 -1.79118592e-01 -4.56250294e-02  6.13731512e-01
 -3.65736648e-07 -6.15696242e-02 -1.00891473e-02 -3.95548035e-07
 -2.11012226e-03 -6.49502881e-01 -9.36705008e-01 -2.42294552e-03
 -1.14882697e-10 -6.48573686e-04 -1.27481543e-03 -9.02253983e-11
 -2.21489170e-05  2.64806113e-02 -1.49501086e-03 -2.52258466e-05
  4.02230716e-02  4.44481944e-02  2.34373852e-02  2.73712276e-02
  1.20281367e+00  1.18715840e+00  6.72324041e-01  4.33659697e-01
  9.88141181e-01  9.60400192e-01  5.35403735e-01  4.18213423e-01
  4.81295751e-02  5.31828828e-02  2.80560811e-02  3.27626728e-02
 -2.40189197e-02 -8.38622015e-03 -2.73313942e-02 -6.04515384e-03
 -3.41517630e-02 -5.88040923e-03 -1.23801996e-02 -2.52610877e-03
  3.16599838e-01  4.77079371e-02  3.87750128e-02  7.93526574e-03
  4.64483432e-01  7.09227729e-02  8.02224165e-02  1.68638625e-02
 -7.30674953e-01  2.96344582e+00 -2.89114750e-01  1.17214735e+00
 -6.16697053e-01  2.08784723e+00 -9.80429599e-02  4.58751512e-01
  8.64245888e+00]
supnorm grad right now is: 8.642458883965254
Weights right now are: 
[-1.86347934e+00  2.72994106e+00 -1.07827729e+00  9.61554617e-01
  2.11804805e+00 -2.83863275e+00  1.47721456e+00 -1.67758300e+00
  8.29851760e+01  1.03528769e+01  3.44338421e+01  8.57133475e+01
  3.01632705e+01  1.33648311e+00  1.50344290e+00  3.15089459e+01
  2.98476805e+00  1.69426690e+02  1.22282335e+01 -9.62171270e-01
 -1.23096548e+01 -1.73004933e+00  3.57203890e+01 -1.35276492e+01
  1.85104188e+01  4.60911627e+00 -1.84957134e+00 -2.12644885e+01
  5.00055733e+00  3.67119382e-01 -1.15482799e+00 -7.07686373e+00
  9.15001010e+00  8.01619330e+00 -1.42531020e+01 -1.76045305e+01
  1.84971763e+01  4.70745498e+00 -1.44228905e+00 -2.20739503e+01
 -9.38687579e+01 -6.46566386e+01  3.34920942e+01  8.30378024e+00
 -1.80389555e+01 -9.02614567e+01 -3.33508057e+01 -5.53999527e+01
 -3.88804828e+00 -1.49212706e+00  4.30100605e+01  3.27702050e+01
  3.42961504e+00  4.07586801e+00  1.64670539e+01  1.03590031e+01
 -3.64984202e+00 -4.93147965e+00  3.88387204e-02 -5.49259048e+00
  4.29508890e+00 -3.76741284e+00  6.09326749e+00 -5.18644602e+00
  3.11267603e+01]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.5903333329643
gradient value of function right now is: [-3.94146626e-01 -1.00558460e+00  8.64661292e-02 -8.17867932e-01
  3.94146626e-01  1.00558460e+00 -8.64661292e-02  8.17867932e-01
 -8.40809053e-06 -1.05365171e-01 -2.38311914e-02 -9.66164051e-06
 -1.87366529e-04  1.84707365e-01 -1.93949042e-01 -2.17876371e-04
 -1.74498774e-10  5.61018480e-04 -6.63409180e-04 -1.36520765e-10
 -1.96916186e-06  1.22917167e-01  2.34185860e-02 -2.59452369e-06
  4.70710723e-03  7.10639009e-03  6.61059491e-04  2.15131374e-03
  7.65406337e-01  7.70039973e-01  4.22035927e-01  2.94976517e-01
 -3.66574602e-02 -3.20318907e-02  3.33014950e-02 -2.87262194e-02
  5.72482616e-03  8.65803255e-03  7.93271595e-04  2.61541477e-03
 -3.82071102e-03 -2.23144199e-03 -7.25786677e-03 -2.33414530e-03
 -1.55171125e-03  8.92988666e-04  7.95090187e-04  1.97676308e-04
  7.72520329e-02  7.74233483e-03 -1.99010297e-03 -3.13076443e-04
  1.59581914e-01  2.02233568e-02  1.73097768e-02  5.30605101e-03
 -1.72048902e-01  5.05352168e-01 -1.36155724e-02  1.02533816e-01
 -1.04342817e-03 -1.06508780e-01  1.13685751e-03  3.00051941e-03
  8.87074223e+00]
supnorm grad right now is: 8.870742230747998
Weights right now are: 
[-1.81675895e+00  2.62879764e+00 -9.56169799e-01  9.15241863e-01
  2.07132766e+00 -2.73748933e+00  1.35510707e+00 -1.63127025e+00
  8.42214286e+01  1.07903911e+01  3.28574754e+01  8.71295889e+01
  3.08639328e+01  1.19545890e+00  1.19605368e+00  3.22069965e+01
  2.98489704e+00  1.74200826e+02  1.33549771e+01 -9.62058961e-01
 -1.24213900e+01 -1.11403084e+00  3.78173656e+01 -1.36543887e+01
  1.82094553e+01  4.19749486e+00 -2.66928652e+00 -2.19603108e+01
  5.07417089e+00  1.50293653e-01 -1.10886611e+00 -6.75316155e+00
  9.17104218e+00  7.99924580e+00 -1.46727053e+01 -1.74544179e+01
  1.81864666e+01  4.28802432e+00 -2.27054332e+00 -2.27780503e+01
 -9.60283898e+01 -6.66392238e+01  3.27709550e+01  6.86772244e+00
 -1.49775966e+01 -9.11618826e+01 -3.34226838e+01 -5.60780511e+01
 -3.97727448e+00 -5.58189301e-01  4.41572768e+01  3.45354894e+01
  3.65406693e+00  2.74702715e+00  1.61799286e+01  9.14793189e+00
 -3.13537566e+00 -5.08295051e+00  1.02838775e+00 -5.42251014e+00
  4.77676896e+00 -3.85390277e+00  6.18288759e+00 -5.06202444e+00
  3.11801856e+01]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.394427595325
gradient value of function right now is: [ 6.18835126e-01 -3.65343869e-01  1.23449191e-01  6.82237198e-01
 -6.18835126e-01  3.65343869e-01 -1.23449191e-01 -6.82237198e-01
 -1.64678717e-06  3.40384336e-02 -1.76206013e-03 -1.97690367e-06
  9.30097814e-04  7.82601377e-01  1.35956041e+00  1.11879532e-03
  1.22091097e-10  2.41648792e-03  1.52843229e-04  1.26117575e-10
  4.04110098e-05  1.94069233e-02  1.08886498e-02  4.84595743e-05
 -1.98469500e-02 -2.01407317e-02 -9.97453219e-03 -1.21405583e-02
 -1.29511691e+00 -1.25970318e+00 -3.98210551e-01 -3.65076475e-01
 -1.10478098e+00 -1.04428702e+00 -5.60836383e-01 -5.09886225e-01
 -2.49117383e-02 -2.52911786e-02 -1.25358472e-02 -1.52562031e-02
  2.63249382e-02  8.79847645e-03  3.09328916e-02  6.55535699e-03
  4.51009850e-02  7.13412994e-03  1.64834712e-02  3.09215847e-03
 -3.02461651e-01 -3.98568138e-02 -4.92471817e-02 -9.50035524e-03
 -4.34030108e-01 -6.81355754e-02 -9.76713554e-02 -2.23632544e-02
  7.36708564e-01 -2.90929634e+00  2.73713041e-01 -1.14552464e+00
  7.35215390e-01 -2.55584682e+00  1.11400350e-01 -5.10695689e-01
 -1.03715402e+01]
supnorm grad right now is: 10.371540217490066
Weights right now are: 
[-1.73936582e+00  2.70674357e+00 -1.17364543e+00  1.11371081e+00
  1.99393453e+00 -2.81543526e+00  1.57258270e+00 -1.82973919e+00
  8.59291426e+01  1.16742844e+01  3.32140141e+01  8.91368376e+01
  3.03086210e+01  1.05665527e+00  1.59160515e+00  3.16401422e+01
  2.98498260e+00  1.77950936e+02  1.41505444e+01 -9.61985655e-01
 -1.03361988e+01 -1.20282720e+00  3.76527814e+01 -1.15448517e+01
  1.91948134e+01  4.33504567e+00 -1.27946490e+00 -2.10945530e+01
  5.15814343e+00  5.05236170e-02 -1.15737559e+00 -6.36950635e+00
  9.51296958e+00  7.94744947e+00 -1.51026483e+01 -1.72094579e+01
  1.91634238e+01  4.41624842e+00 -8.87261707e-01 -2.19203111e+01
 -9.82633042e+01 -6.77995632e+01  3.38106075e+01  7.23996974e+00
 -1.20388145e+01 -9.27891875e+01 -3.24476006e+01 -5.57802316e+01
 -3.93321829e+00 -1.85420455e+00  4.47268127e+01  3.50507419e+01
  3.15164631e+00  1.55825673e+00  1.52943334e+01  7.30892726e+00
 -3.16812188e+00 -5.12498310e+00  5.91210707e-01 -5.68891150e+00
  4.41000986e+00 -3.77537573e+00  6.23470025e+00 -5.32200262e+00
  3.10897469e+01]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.5040243692758
gradient value of function right now is: [ 2.74692117e-01  1.17801191e-01  8.12160547e-02  3.28293633e-01
 -2.74692117e-01 -1.17801191e-01 -8.12160547e-02 -3.28293633e-01
 -2.06301389e-06  3.36176265e-02  1.32634044e-02 -2.47753148e-06
  4.68343059e-03  7.68490781e-01  8.82212395e-01  5.59230164e-03
  1.93843961e-11  9.46872910e-04  4.00645251e-05  1.89038136e-11
  7.23312047e-05  1.71266015e-02 -8.79133509e-03  8.63569995e-05
 -9.63492459e-02 -9.78043484e-02 -5.58556261e-02 -6.42501291e-02
 -9.62111746e-01 -9.27419690e-01 -4.25669203e-01 -3.77939866e-01
 -4.15858325e-01 -4.12072562e-01 -1.71421671e-01 -2.90777941e-01
 -1.19741102e-01 -1.21579508e-01 -6.94088277e-02 -7.98526535e-02
  3.43868515e-02  1.40842197e-02  3.51854508e-02  1.24934607e-02
  2.92538937e-03  5.43546639e-03  1.37488687e-02  4.74816263e-03
  7.74733797e-02 -9.66153765e-03 -2.95810273e-02 -1.05408505e-02
  2.63763651e-02 -2.42073094e-02 -6.20750984e-02 -2.25685411e-02
  7.99796784e-01 -3.48809172e+00  2.16045164e-01 -1.44172574e+00
  2.17065839e-01 -1.54558003e+00  9.84862946e-02 -7.05751461e-01
 -7.71841509e+00]
supnorm grad right now is: 7.718415094671083
Weights right now are: 
[-2.10497508e+00  2.67914787e+00 -9.39688497e-01  9.86207281e-01
  2.35954379e+00 -2.78783956e+00  1.33862577e+00 -1.70223566e+00
  8.73091128e+01  1.21485607e+01  3.49328910e+01  9.07741184e+01
  3.08188355e+01  1.38006774e+00  1.62668723e+00  3.21507065e+01
  2.98507820e+00  1.81494692e+02  1.79994806e+01 -9.61896302e-01
 -6.86994648e+00 -1.31444555e+00  3.69048559e+01 -7.97575957e+00
  1.89791396e+01  4.88035587e+00 -2.88317244e+00 -2.18110166e+01
  5.28408019e+00  4.25262362e-03 -1.57138340e+00 -6.49315795e+00
  1.01704980e+01  8.18006638e+00 -1.48585554e+01 -1.65294164e+01
  1.89480203e+01  4.96464704e+00 -2.48784590e+00 -2.26329009e+01
 -9.97828960e+01 -7.01008942e+01  3.21037529e+01  4.93875845e+00
 -1.03898507e+01 -9.36168878e+01 -3.27023314e+01 -5.66652623e+01
 -4.08187714e+00 -1.78074924e+00  4.58342763e+01  3.65400733e+01
  3.79210595e+00  1.94721592e+00  1.63064316e+01  7.70311912e+00
 -3.10690133e+00 -5.39503073e+00  1.53576347e+00 -5.45235717e+00
  4.61228124e+00 -4.00483339e+00  5.67004615e+00 -4.99142489e+00
  3.11006457e+01]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.0717220653728
gradient value of function right now is: [ 6.89139170e-01  4.28392792e-01  1.23343267e-01  7.72691697e-01
 -6.89139170e-01 -4.28392792e-01 -1.23343267e-01 -7.72691697e-01
 -3.47063316e-06  5.21689385e-02  1.98810481e-02 -4.25181567e-06
  6.99571211e-03  1.04457188e+00  1.05117056e+00  8.53610199e-03
  2.45619891e-10  2.35314426e-03  6.74991617e-04  2.55505173e-10
  1.23904976e-04  3.13956158e-02 -5.78473708e-03  1.51377010e-04
 -1.45597725e-01 -1.49284336e-01 -8.18121106e-02 -9.68031439e-02
 -1.65013815e+00 -1.62480246e+00 -6.47064350e-01 -5.69963168e-01
 -7.17472918e-01 -7.10127624e-01 -2.80519723e-01 -4.59477915e-01
 -1.84761832e-01 -1.89483770e-01 -1.03788146e-01 -1.22833350e-01
  5.06141638e-02  2.04419865e-02  5.92619565e-02  1.77413781e-02
  1.75274617e-02  8.52413980e-03  2.25544123e-02  6.64046061e-03
 -4.42365646e-03 -2.55904958e-02 -5.54282692e-02 -1.72361501e-02
 -1.09648959e-01 -5.88099943e-02 -1.22270078e-01 -4.00375052e-02
  8.79934525e-01 -5.16320183e+00  2.57417064e-01 -2.05310586e+00
  4.42423934e-01 -2.63264502e+00  1.47110655e-01 -1.00704323e+00
 -8.30535280e+00]
supnorm grad right now is: 8.305352799043314
Weights right now are: 
[-1.81988250e+00  2.71839848e+00 -1.33412026e+00  1.10386177e+00
  2.07445121e+00 -2.82709017e+00  1.73305753e+00 -1.81989015e+00
  8.81658130e+01  1.32022427e+01  3.45228165e+01  9.18022947e+01
  3.12586977e+01  1.25500068e+00  1.38973603e+00  3.25933205e+01
  2.98516388e+00  1.83988336e+02  1.90452665e+01 -9.61809431e-01
 -4.26012774e+00 -2.16984931e-01  3.79049141e+01 -5.30092838e+00
  1.93938193e+01  4.31116021e+00 -2.59819401e+00 -2.19824212e+01
  5.50447436e+00  2.52668684e-02 -1.55167899e+00 -6.62364652e+00
  1.02779362e+01  8.03894817e+00 -1.53988634e+01 -1.62033624e+01
  1.93520408e+01  4.38762642e+00 -2.21193412e+00 -2.28128478e+01
 -1.01821463e+02 -7.13361799e+01  3.32394444e+01  5.42932653e+00
 -7.31089987e+00 -9.49919192e+01 -3.21483148e+01 -5.66943260e+01
 -4.41354053e+00 -2.59035994e+00  4.58960145e+01  3.66520363e+01
  4.01606550e+00  4.62393513e-01  1.56429259e+01  6.84085003e+00
 -3.18749854e+00 -5.31171222e+00  1.24260024e+00 -5.69479890e+00
  4.84939744e+00 -4.13801529e+00  5.86901915e+00 -5.36140499e+00
  3.11245797e+01]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.1064685540682
gradient value of function right now is: [ 5.59989221e-01 -9.55658499e-01  1.45098158e-01  5.88838104e-01
 -5.59989221e-01  9.55658499e-01 -1.45098158e-01 -5.88838104e-01
 -3.15059007e-07  2.19785656e-02 -3.82721435e-03 -3.78057288e-07
 -9.43274405e-04  7.49286056e-01  1.65262657e+00 -1.13367022e-03
  4.13523305e-11  1.92716173e-03  5.86808688e-05  4.38359001e-11
  1.50235753e-06  1.29399759e-02  1.29412074e-02  1.79827622e-06
  1.61006213e-02  1.81009858e-02  1.14987837e-02  1.32838962e-02
 -1.54270684e+00 -1.35303751e+00 -6.10746986e-01 -4.75431420e-01
 -1.69129201e+00 -1.37348839e+00 -9.52579925e-01 -6.88743507e-01
  2.01019990e-02  2.26022718e-02  1.43429299e-02  1.65746602e-02
  1.47911795e-02  2.92012466e-03  3.41998715e-03  1.50086293e-03
  1.30188297e-01  1.05354689e-02  8.87087748e-03  3.36581788e-03
 -6.14340739e-01 -5.13886632e-02 -3.21112167e-02 -1.28861915e-02
 -7.49981349e-01 -7.07967078e-02 -5.11212784e-02 -2.33155777e-02
  8.55337819e-01 -2.03414331e+00  4.42432205e-01 -9.81768757e-01
  7.93295117e-01 -1.90378506e+00  2.59572935e-01 -6.41199520e-01
 -9.83618454e+00]
supnorm grad right now is: 9.836184544618044
Weights right now are: 
[-1.87120391e+00  2.65016497e+00 -1.03594360e+00  1.18326620e+00
  2.12577262e+00 -2.75885666e+00  1.43488087e+00 -1.89929458e+00
  8.91905672e+01  1.34259915e+01  3.56123254e+01  9.30285513e+01
  3.09748535e+01  1.49994686e+00  1.65240096e+00  3.23039521e+01
  2.98518904e+00  1.88053621e+02  2.05827104e+01 -9.61788970e-01
 -3.00560714e+00 -7.91165604e-01  3.79667287e+01 -4.01720957e+00
  2.04834569e+01  4.75950535e+00 -2.00756117e+00 -2.15140695e+01
  5.46272308e+00  6.48930777e-02 -1.67150936e+00 -6.56416997e+00
  1.02158468e+01  8.01244312e+00 -1.59411106e+01 -1.62474009e+01
  2.04485510e+01  4.84136009e+00 -1.60847032e+00 -2.23347868e+01
 -1.03589013e+02 -7.34265825e+01  3.28163380e+01  4.12826575e+00
 -7.02965646e+00 -9.61892050e+01 -3.17971131e+01 -5.72728553e+01
 -4.27495254e+00 -1.74596356e+00  4.67799391e+01  3.77671133e+01
  3.55205411e+00  4.61456198e-01  1.64109736e+01  7.43681883e+00
 -3.26255864e+00 -5.11583015e+00  1.36885588e+00 -5.57976285e+00
  5.23481430e+00 -4.12124316e+00  6.05439455e+00 -4.95989274e+00
  3.10623719e+01]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.6314163792065
gradient value of function right now is: [ 6.13834582e-01  7.88699406e-01  1.32408494e-01  8.22129463e-01
 -6.13834582e-01 -7.88699406e-01 -1.32408494e-01 -8.22129463e-01
  1.36209932e-07  4.97654549e-02  2.61256488e-03  1.55413929e-07
 -1.77854000e-03 -3.74423574e-01 -4.88367637e-01 -2.14282761e-03
  7.56304228e-11  1.69992554e-03  2.30189306e-04  7.82572173e-11
 -1.00587327e-05 -5.14853075e-02 -1.96131445e-03 -1.21581966e-05
  3.83140788e-02  3.86777055e-02  2.11797614e-02  2.52918693e-02
 -8.22545203e-01 -8.26550641e-01 -1.82121059e-01 -1.26754816e-01
  2.01978347e-02  8.22671232e-03 -3.02050139e-02  6.57720436e-02
  4.80029271e-02  4.84843023e-02  2.65211093e-02  3.16851783e-02
 -9.70343068e-03 -2.78139761e-03 -9.67186442e-03 -3.11547515e-03
  9.72670170e-03 -6.82522026e-04 -3.94835500e-03 -1.32839589e-03
 -1.57704456e-01 -1.10918605e-02  2.88819198e-03  2.82935745e-05
 -2.38738037e-01 -2.78230044e-02 -1.25577583e-02 -9.48894828e-03
 -1.71209460e-01  9.63312278e-01 -9.40533560e-03  3.01433456e-01
  1.52628209e-01  4.47547420e-02  4.59067612e-02  9.59053549e-02
  6.19361141e+00]
supnorm grad right now is: 6.193611406095279
Weights right now are: 
[-1.94701235e+00  2.69845185e+00 -1.00215791e+00  1.27278667e+00
  2.20158106e+00 -2.80714354e+00  1.40109518e+00 -1.98881505e+00
  9.05234268e+01  1.45640108e+01  3.57914914e+01  9.46107971e+01
  3.20059154e+01  9.87723903e-01  1.27455027e+00  3.33407238e+01
  2.98532938e+00  1.91375142e+02  2.11490701e+01 -9.61640350e-01
 -7.23467820e-01 -3.77443157e-01  3.83808405e+01 -1.69324671e+00
  2.03637925e+01  4.43870090e+00 -3.33064498e+00 -2.25306981e+01
  5.53905554e+00 -3.60631517e-02 -1.38641318e+00 -6.79254028e+00
  1.04059434e+01  7.99283031e+00 -1.62167057e+01 -1.59302177e+01
  2.03247699e+01  4.51911611e+00 -2.93073421e+00 -2.33504599e+01
 -1.05144590e+02 -7.48005924e+01  3.30612757e+01  4.25997480e+00
 -6.30811752e+00 -9.73167203e+01 -3.15759709e+01 -5.74593098e+01
 -4.77785940e+00 -1.72862638e+00  4.75175702e+01  3.85518685e+01
  3.52417156e+00  6.82225915e-01  1.64700302e+01  7.01332589e+00
 -3.40682879e+00 -5.33396953e+00  1.25846089e+00 -5.77627741e+00
  4.92511685e+00 -4.13403822e+00  5.22286315e+00 -5.22655185e+00
  3.11337346e+01]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.710102473243
gradient value of function right now is: [ 3.31018989e-01 -8.06153556e-02  1.57310565e-01  2.68822913e-01
 -3.31018989e-01  8.06153556e-02 -1.57310565e-01 -2.68822913e-01
 -6.95494753e-06 -1.21892032e-04  2.34396252e-03 -8.50864783e-06
  6.47097417e-03  5.31483509e-01  8.57222055e-01  7.89009432e-03
  2.35898710e-10  1.48328789e-03  1.36537701e-03  2.47847263e-10
  1.27785060e-04  3.65891407e-02  4.51551248e-03  1.56461287e-04
 -1.34515308e-01 -1.44131361e-01 -7.32812546e-02 -9.21220013e-02
 -6.66908342e-01 -6.59009241e-01 -2.37130928e-01 -2.20091526e-01
 -5.78666375e-01 -5.25094811e-01 -2.65746611e-01 -3.28663103e-01
 -1.70166280e-01 -1.82412904e-01 -9.26515421e-02 -1.16529824e-01
  3.30193751e-02  1.17750400e-02  4.75532265e-02  1.33929377e-02
  3.60057529e-02  5.49726110e-03  1.50450666e-02  4.18398594e-03
 -1.05263655e-01 -1.78822102e-02 -3.20965824e-02 -9.40430629e-03
 -1.39778034e-01 -3.17645454e-02 -7.89990523e-02 -2.45579501e-02
  6.59912831e-01 -3.56958311e+00  2.31281914e-01 -1.31419564e+00
  3.11280675e-01 -1.33371682e+00  1.04604353e-01 -5.97604124e-01
 -7.25610154e+00]
supnorm grad right now is: 7.256101540697522
Weights right now are: 
[-2.01600249e+00  2.75330271e+00 -9.71699911e-01  1.14550084e+00
  2.27057120e+00 -2.86199440e+00  1.37063718e+00 -1.86152922e+00
  9.17772226e+01  1.39425571e+01  3.62761606e+01  9.61217476e+01
  3.26358609e+01  1.30179935e+00  1.56888464e+00  3.39747106e+01
  2.98554013e+00  1.95932916e+02  2.05922030e+01 -9.61417649e-01
  1.95890656e+00 -3.14959306e-01  3.85093301e+01  1.12398161e+00
  2.07357346e+01  3.78100312e+00 -3.23012878e+00 -2.28870642e+01
  5.79924866e+00  1.41874300e-01 -1.22397012e+00 -6.49634147e+00
  1.05133936e+01  8.13663753e+00 -1.63350116e+01 -1.60068106e+01
  2.06911175e+01  3.85608234e+00 -2.83223880e+00 -2.37107367e+01
 -1.06519708e+02 -7.60065757e+01  3.44664555e+01  5.29527777e+00
 -5.86960257e+00 -9.85797037e+01 -3.06798359e+01 -5.73867319e+01
 -4.55399167e+00 -1.74936754e+00  4.79597128e+01  3.87943718e+01
  3.54067290e+00  2.70932396e-01  1.60516700e+01  6.40597322e+00
 -2.97342388e+00 -5.35756509e+00  9.95406260e-01 -5.89335666e+00
  5.01252198e+00 -3.95227219e+00  5.67276115e+00 -5.25554081e+00
  3.11269226e+01]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1046.1119060879585
gradient value of function right now is: [ 3.55525393e-01  5.00807919e-01  1.25351539e-01  3.61231655e-01
 -3.55525393e-01 -5.00807919e-01 -1.25351539e-01 -3.61231655e-01
 -6.87499456e-07  1.00834067e-02  2.72886053e-03 -8.33030647e-07
 -4.25724727e-04 -3.60467766e-02 -1.12639781e-01 -5.15454668e-04
  3.59164908e-11  1.46544099e-03  5.02241028e-04  3.81044303e-11
 -2.94738517e-06  5.55131055e-03 -4.00148338e-04 -3.59163042e-06
  7.61935803e-03  1.02632348e-02  3.91938375e-03  5.78099603e-03
 -4.03565372e-01 -4.06323366e-01 -6.16667812e-02 -3.92721801e-02
  2.90851515e-02  2.17426919e-02  2.98302000e-02  1.11205001e-02
  9.57981682e-03  1.28982170e-02  4.92013408e-03  7.26066144e-03
  4.77376437e-04 -8.34610162e-05 -2.21810316e-03 -5.77485979e-04
 -7.76763192e-03  1.57220234e-05 -6.52948536e-06 -8.22908009e-07
  1.35635665e-02 -6.03836880e-03 -2.66084357e-03 -1.08602934e-03
  1.23685347e-03 -1.31854344e-02 -1.16445098e-02 -6.03559756e-03
  1.63114895e-02 -2.88625095e-02 -1.44252178e-02  2.27560181e-02
  8.35571327e-02 -2.08555554e-01  2.51038038e-02 -3.34003258e-02
 -1.27430937e+00]
supnorm grad right now is: 1.2743093715234215
Weights right now are: 
[-2.12974388e+00  2.60687509e+00 -9.30615253e-01  1.33047936e+00
  2.38431259e+00 -2.71556678e+00  1.32955252e+00 -2.04650774e+00
  9.27768959e+01  1.44493433e+01  3.70405172e+01  9.73278581e+01
  3.25784302e+01  1.31626572e+00  1.34175614e+00  3.39119901e+01
  2.98557609e+00  1.99795802e+02  1.74582635e+01 -9.61382176e-01
  5.35765565e+00 -8.25663979e-01  3.78307833e+01  4.69159735e+00
  2.12089294e+01  4.18837540e+00 -3.41455968e+00 -2.28428994e+01
  5.77581957e+00  1.70065310e-01 -1.17779258e+00 -6.53751077e+00
  1.08010803e+01  8.26881288e+00 -1.64781597e+01 -1.58085943e+01
  2.11648874e+01  4.25855375e+00 -3.00975283e+00 -2.36646585e+01
 -1.07884986e+02 -7.77261833e+01  3.40487226e+01  4.73660287e+00
 -5.50501334e+00 -9.98803510e+01 -3.05135501e+01 -5.75688909e+01
 -4.69352391e+00 -2.30387070e+00  4.80706646e+01  3.84461590e+01
  3.56414467e+00  2.22254856e-01  196.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1038.2754828063341
gradient value of function right now is: [ 9.43510532e-04  8.79161294e-05  6.13591104e-01  3.59104155e-05
 -9.43510532e-04 -8objective value function right now is: -1046.1167784367376
gradient value of function right now is: [ 3.66094381e-01  5.55915036e-01  1.37015724e-01  3.82858408e-01
 -3.66094381e-01 -5.55915036e-01 -1.37015724e-01 -3.82858408e-01
 -6.71142518e-07  1.09691722e-02  3.07881492e-03 -8.16964487e-07
 -2.08423911e-04 -4.85621618e-02 -1.29667566e-01 -2.54458599e-04
  4.95423744e-11  1.43171726e-03  6.66707736e-04  5.30914839e-11
 -4.30187525e-06  8.57758754e-04 -1.29455450e-03 -5.25039553e-06
  3.57891871e-03  5.82810174e-03  1.26215736e-03  2.64686999e-03
 -3.97708961e-01 -4.02821636e-01 -6.92740314e-02 -3.99911693e-02
  6.65454830e-02  5.34842540e-02  5.01149887e-02  2.64522152e-02
  4.54330115e-03  7.37541989e-03  1.60506645e-03  3.35399348e-03
  1.85374633e-04 -1.07199527e-04 -1.87885817e-03 -4.64808724e-04
 -9.82607295e-03 -2.13041903e-04 -2.91490235e-04 -7.71935432e-05
  1.91166589e-02 -5.29365435e-03 -1.70594364e-03 -8.47760319e-04
  5.95241659e-03 -1.23986570e-02 -1.10867221e-02 -5.84149479e-03
 -8.97344987e-04 -3.99927481e-03 -2.21287102e-02  4.01629839e-02
  6.85387599e-02 -1.48091514e-01  2.13934103e-02 -2.07169797e-02
 -1.33550217e+00]
supnorm grad right now is: 1.3355021671069516
Weights right now are: 
[-2.02988627e+00  2.54395503e+00 -1.33712638e+00  1.40533624e+00
  2.28445498e+00 -2.65264672e+00  1.73606365e+00 -2.12136462e+00
  9.38336891e+01  1.47202277e+01  3.79026175e+01  9.86122705e+01
  3.19712668e+01  1.65162861e+00  1.46767821e+00  3.33021248e+01
  2.98563204e+00  2.03627379e+02  1.77368347e+01 -9.61330635e-01
  7.69876118e+00 -3.23559108e-01  3.75822385e+01  7.05375924e+00
  2.23028348e+01  4.87100090e+00 -2.60828593e+00 -2.21345092e+01
  5.54487646e+00  3.86423694e-02 -1.57181353e+00 -6.74474980e+00
  1.07685351e+01  8.48099110e+00 -1.67343194e+01 -1.57522146e+01
  2.22505768e+01  4.93746652e+00 -2.20914698e+00 -2.29604361e+01
 -1.09207359e+02 -7.95828151e98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1038.280111398229
gradient value of function right now is: [ 8.86729829e-04  9.77397689e-05  5.37362019e-01  3.60284853e-05
 -8.86729829e-04 -9.77397689e-05 -5.37362019e-01 -3.60284853e-05
 -2.52577069e-04 -2.28619922e-12 -2.89568482e-03 -4.57300605e-07
  1.33329875e-04  2.89632241e-07  1.82486514e-05  1.49566008e-09
 -4.66345583e-02 -2.857250objective value function right now is: -1046.1192401919466
gradient value of function right now is: [ 3.67734648e-01  5.39075964e-01  1.43179806e-01  3.82054737e-01
 -3.67734648e-01 -5.39075964e-01 -1.43179806e-01 -3.82054737e-01
 -7.00386136e-07  1.00938004e-02  2.29592428e-03 -8.57066691e-07
 -1.75357403e-04 -4.55495831e-02 -1.28210405e-01 -2.15284006e-04
  5.17999415e-11  1.41852258e-03  6.61926643e-04  5.63363384e-11
 -3.49465071e-06  1.44465138e-03 -6.62335470e-04 -4.28586099e-06
  3.00177289e-03  5.05886518e-03  9.47514152e-04  2.20261113e-03
 -3.88948618e-01 -3.94809684e-01 -6.41495524e-02 -3.83340545e-02
  6.40332237e-02  5.04332996e-02  4.77114467e-02  2.58482934e-02
  3.83277361e-03  6.43479742e-03  1.21396702e-03  2.80672158e-03
  1.20511726e-04 -7.62892072e-05 -1.63727557e-03 -3.86908233e-04
 -9.14330247e-03 -2.20367718e-04 -2.67978603e-04 -6.65960800e-05
  1.60129548e-02 -5.27876002e-03 -1.70885483e-03 -8.55413757e-04
  3.67259000e-03 -1.22087427e-02 -1.13602584e-02 -5.93263149e-03
 -3.50279578e-03 -1.72070972e-03 -2.29066213e-02  3.83200059e-02
  6.62774315e-02 -1.45732901e-01  2.07133012e-02 -2.13767249e-02
 -1.21552184e+00]
supnorm grad right now is: 1.2155218430593175
Weights right now are: 
[-2.17926391e+00  2.71872894e+00 -9.28392969e-01  1.24319005e+00
  2.43383262e+00 -2.82742063e+00  1.32733024e+00 -1.95921844e+00
  9.45842118e+01  1.45806293e+01  3.76644404e+01  9.95412788e+01
  3.30232040e+01  1.12456740e+00  1.37616625e+00  3.43478593e+01
  2.98571090e+00  2.07797314e+02  1.86143294e+01 -9.61248058e-01
  9.01134620e+00 -2.53440466e-01  3.87958957e+01  8.36127455e+00
  2.18143840e+01  3.84074136e+00 -3.29646888e+00 -2.30417702e+01
  5.89890076e+00  2.5427100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1038.2807896764114
gradient value of function right now is: [ 8.65310396e-04  1.11328424e-04  4.90697584e-01  3.71647806e-05
 -8.65310396e-04 -1.11328424e-04 -4.90697584e-01 -3.71647806e-05
 -2.46874593e-04 -3.48633409e-12 -2.78098842e-03 -4.56939335e-07
  1.54009859e-04  3.31878681e-07  2.07565783e-05  1.65963302e-09
 -4.94879803e-02 -3.05363837e-04 -8.31955748e-02 -8.57605618e-06
  4.15154027e-05  2.38817907e-13  3.24128972e-04  4.44266606e-08
  3.41161801e-02  9.15390007e-03  3.76747044e-05  8.59823594e-04
  6.41560274e-03  7.88677346e-05  1.09419740e-11 -2.59758535e-08
 -4.81274074e-02 -2.81889440e-02 -1.46009603e-03 -9.01908958e-03
  4.54076897e-05  2.68878740e-05  9.64511927e-07  9.71254465e-08
  1.77543376e-03  5.85364306e-03  4.62950342e-03  4.58185171e-07
 -6.37879721e-03 -9.64918362e-03 -1.17416164e-02  5.78018411e-04
 -4.47090162e-04 -3.36509824e-03 -9.19656742e-04 -2.09141615e-09
 -8.69806473e-04 -7.61699790e-04 -5.64293742e-03  7.01775372e-07
  2.08989915e-02 -4.19278401e-02  4.58902449e-02 -1.70357368e-02
  2.72824421e-02 -5.24181772e-02  2.87729129e-05 -6.90210826e-05
 -1.11623409e+00]
supnorm grad right now is: 1.1162340937170736
Weights right now are: 
[  6.57823499  -3.28352427   1.64578539 -23.3540662   -7.31253371
   3.24027653  -1.15146844  21.81817788  49.64921637  58.39683133
  14.74341819  32.2122276   12.76874879 -26.12155932  89.4573775
  -1.96757508   1.21864589  23.8527779   -2.97635928   9.09224403
  70.65029912   5.02792688  26.59679958  17.97173323  -0.94024483
   7.93908001 187.19669163   3.80088925   1.78605644  60.58564164
  22.39269549 120.74991675   3.91381056  -1.21549603 -30.2182512
  -6.68283596  13.14725145  12.39627113  26.36659724  15.37594209
 -28.87739175   6.32004536  -1.28862637 -18.94834325  -2.94698599
   6.754653     3.30103867   3.78339119 114.60791196   7.12540891
 107.25220468   2.56663285  -1.76940537  86.98269906  -2.34591294
  33.01495364   5.95963259  -6.58422269   5.92393587  -3.00158927
   2.4565148   -6.19861805  32.95216493 -21.76461726  30.99513081]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1065.5536176504952
W_T_median: 1049.9902403146561
W_T_pctile_5: 957.7683258635432
W_T_CVAR_5_pct: 931.7302008316572
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.1
F value: -1038.2807896764114
-----------------------------------------------
5518545e+00 -2.50544187e+00  4.90875027e+01  3.95886358e+01
  4.00778280e+00  1.29300200e-01  1.69776736e+01  5.48685950e+00
 -3.09257382e+00 -5.32976798e+00  7.84903368e-01 -5.72672498e+00
  5.29920484e+00 -4.25487951e+00  5.79253670e+00 -5.33196889e+00
  3.11764085e+01]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1046.1184552116376
gradient value of function right now is: [ 3.60964831e-01  5.48146597e-01  1.37416176e-01  3.73439877e-01
 -3.60964831e-01 -5.48146597e-01 -1.37416176e-01 -3.73439877e-01
 -7.04227255e-07  9.80579889e-03  2.39977489e-03 -8.69779670e-07
 -1.85883279e-04 -5.61207804e-02 -1.39667708e-01 -2.30358185e-04
  4.09836178e-11  1.36651538e-03  5.42386934e-04  4.50245369e-11
 -3.71421267e-06  1.94046399e-03 -8.13207863e-04 -4.58766523e-06
  3.31093229e-03  5.48950555e-03  9.87488208e-04  2.35544287e-03
 -3.75026720e-01 -3.81428693e-01 -5.72323077e-02 -3.20163040e-02
  7.97408410e-02  6.33721550e-02  5.52608366e-02  3.40419023e-02
  4.26947272e-03  7.04509590e-03  1.28276491e-03  3.03237400e-03
 -2.73351362e-04 -2.61497974e-04 -2.13675172e-03 -5.52719001e-04
 -1.00882860e-02 -3.94105476e-04 -4.90190071e-04 -1.30664993e-04
  1.80872802e-02 -4.87244235e-03 -1.09072463e-03 -7.47676347e-04
  6.18116538e-03 -1.14946726e-02 -9.90018254e-03 -5.65815356e-03
 -7.21362110e-03  3.79215651e-02 -3.13610733e-02  6.67469230e-02
  5.70698193e-02 -1.13074999e-01  1.95059380e-02 -1.12758228e-02
 -1.05563344e+00]
supnorm grad right now is: 1.0556334364805928
Weights right now are: 
[-1.98404359e+00  2.63637263e+00 -8.37895374e-01  1.29956707e+00
  2.23861230e+00 -2.74506432e+00  1.23683264e+00 -2.01559545e+00
  9.60387023e+01  1.51385675e+01  3.69443468e+01  1.01368237e+02
  3.34584698e+01  1.56029844e+00  1.22383141e+00  3.47811232e+01
  2.98575932e+00  2.15437214e+02  2.08012091e+01 -9.61199056e-01
  1.43356169e+01  3.02995373e-01  4.01640318e+01  1.37346220e+01
  2.25072014e+01  3.51963266e+00 -3.23111746e+00 -2.32667980e+01
  5.64449261e+00 -7.36512548e-02 -1.67839923e+00 -6.18141164e+00
  1.10137462e+01  8.56422266e+00 -1.71526408e+01 -1.56163151e+01
  2.24398710e+01  3.56764236e+00 -2.82930724e+00 -2.40990762e+01
 -1.13245302e+02 -8.34301052e+01  3.59056489e+01  4.41312097e+00
 -4.78664243e+00 -1.04603694e+02 -2.84023741e+01 -5.85498193e+01
 -4.66150437e+00 -2.97278808e+00  4.98881003e+01  4.07344789e+01
  3.91527768e+00 -8.08591654e-02  1.68375571e+01  5.23896375e+00
 -3.05748939e+00 -5.54899383e+00  9.37570926e-01 -5.86776837e+00
  4.92048077e+00 -4.16145651e+00  5.54682949e+00 -5.22079883e+00
  3.11610067e+01]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1062.1552869546938
W_T_median: 1049.763024861461
W_T_pctile_5: 967.8529769562822
W_T_CVAR_5_pct: 939.9056420680982
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.1
F value: -1046.1184552116376
-----------------------------------------------
