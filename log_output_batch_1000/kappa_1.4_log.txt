Starting at: 
2022-06-17 22:26:16
tracing parameter entered from terminal:  1.4


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2691.8850031188804
gradient value of function right now is: [-2.45005571e+00 -6.30035407e-02 -8.26483182e-03 -9.18875927e-03
  2.45005571e+00  6.30035407e-02  8.26483182e-03  9.18875927e-03
 -1.36943359e+00 -1.01504955e-03 -4.61873938e-01 -5.75240373e-01
  2.72069061e-01  2.40777099e-04  1.19026357e-01  1.56278449e-01
 -5.68631474e-02 -1.59757816e-03 -4.15036982e-02 -4.54769714e-02
 -6.03277754e-02 -1.51451378e-03 -4.24229214e-02 -4.67013803e-02
  3.14430505e-02  4.88365546e-03  8.78892744e-03  2.86621442e-05
 -5.94680617e-03 -1.46918810e-03 -2.11239547e-03 -3.76345149e-04
 -5.48004590e-01 -7.66633710e-01 -6.94181638e-01 -3.76903737e-01
 -4.70408093e-01 -7.20100232e-01 -6.38950337e-01 -3.31896834e-01
 -1.48932084e-01 -1.03173428e-01 -1.41760400e+00 -1.16909679e-01
  1.47567757e-01  9.81477155e-02  1.35288629e+00  1.15146812e-01
  3.38955148e-02  1.56077597e-02  2.12984004e-01  3.00969943e-02
 -7.56203056e-03 -1.83962966e-02 -1.61599678e-01 -5.63631762e-03
 -8.52845030e-02  7.57104726e-01 -5.43343480e-01  1.81486826e+00
  1.15162791e+00 -3.83604278e+00 -1.95724220e-01  1.27263282e+00
  3.50719619e+00]
supnorm grad right now is: 3.8360427823575063
Weights right now are: 
[-1.00333463e+00  1.98146079e+00 -3.51000559e+00 -3.87163547e+00
  1.25790334e+00 -2.09015248e+00  3.90894286e+00  3.15560708e+00
  3.51592415e+00 -1.27142834e+00 -4.42264900e+00 -3.71854540e+00
  2.57287070e+00  2.14224524e+00  2.38214354e+00  2.10369594e+00
  8.20107940e+00 -2.32990197e+00 -2.06564945e+00 -8.17065216e-01
  7.91895424e+00 -2.50060266e+00 -1.99097409e+00 -6.66974754e-01
  1.49928382e+00 -8.12680315e+00 -7.27434886e+00 -5.22341669e+00
  2.83725735e-01  6.54440893e+00  6.33218585e+00  4.44457516e+00
 -4.90607755e+00  5.42911698e+00  2.30743949e-02 -9.75573546e-01
 -6.20757322e+00  4.53107006e+00  1.21076304e+00 -1.02205949e+00
 -1.86444401e+00 -6.70074782e+00  2.02922558e+00 -3.98712711e+00
  2.99314605e+00  8.52436614e+00 -2.00405482e+00  5.81195822e+00
  2.02618539e+00  3.41108770e+00 -8.01228311e-01  3.49113577e+00
  2.52297257e+00  3.19666079e+00  1.82348776e+00  3.08662531e+00
  7.26882194e+00 -8.17497829e-01 -2.19286915e+00 -3.17228552e+00
  7.07875105e+00  1.95053574e+00  4.59531155e+00 -1.41178425e+00
  2.59530781e+01]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2693.3405775981696
gradient value of function right now is: [ 8.78984182e-01  1.12805295e-01  5.46038343e-04  5.39478562e-04
 -8.78984182e-01 -1.12805295e-01 -5.46038343e-04 -5.39478562e-04
  1.04098433e+00  4.14257342e-04  1.20934030e-01  8.71834824e-01
 -7.52669192e-01 -4.06830369e-06 -2.86972863e-03 -1.07911889e-01
  5.01271491e-03 -1.16211889e-04  2.03944903e-03  3.73357190e-03
  4.72677354e-03 -1.09720339e-04  1.77845921e-03  3.37567644e-03
 -9.65900764e-03 -8.06889308e-04 -2.35450020e-03 -2.26566526e-03
  2.36950197e-03  2.18604460e-04  6.72644090e-04  5.23007445e-04
  1.95167496e-01  8.58093647e-02  1.32245664e-01  6.00260742e-02
  1.65332020e-01  2.18031118e-01  2.76031979e-01  2.20583336e-02
  3.68873965e-02  4.11831826e-02  6.04978367e-01  4.28643681e-02
 -2.78895251e-02 -5.55417779e-02 -3.71649223e-01 -3.22890109e-02
 -5.97728412e-03 -2.59555285e-02 -6.71217861e-02 -6.84040753e-03
  8.50746745e-04  6.73717897e-03  2.43598026e-02  1.06956510e-03
  7.36087171e-02 -4.67547713e-01  4.02173483e-01 -1.12121761e+00
 -3.65646437e-01  1.23528745e+00  1.29099568e-01 -7.84311503e-01
 -4.77196233e+00]
supnorm grad right now is: 4.771962326794746
Weights right now are: 
[-1.09128382e+00  3.46270817e+00 -4.06000006e+00 -4.44456998e+00
  1.34585253e+00 -3.57139986e+00  4.45893733e+00  3.72854160e+00
  4.15314443e+00 -7.36046921e+00 -3.14693850e+00 -3.62683787e+00
  2.69610171e+00  6.87883835e+00  4.56731620e+00  2.55112171e+00
  9.63377281e+00 -3.62153862e+00 -1.86350260e+00 -3.82293740e-01
  9.51147660e+00 -3.92162932e+00 -1.80203972e+00 -2.41869468e-01
  1.73276197e+00 -1.47701643e+01 -9.73900171e+00 -4.92724204e+00
 -7.16017417e-03  1.37797769e+01  9.84142679e+00  4.91228735e+00
 -2.56131464e+00  7.68834312e+00  3.00057167e+00 -3.48872137e+00
 -1.14021542e+01  6.40535856e+00  1.35075016e+00 -4.60744827e+00
 -7.90160641e+00 -1.25226611e+01  2.07373812e+00 -1.09781928e+01
  5.46122995e+00  8.44547223e+00 -2.41248973e+00  8.72491768e+00
  3.49449011e+00  4.17044020e+00 -3.42199105e+00  4.64085482e+00
  2.43544558e+00  5.25763894e+00  6.33723632e+00  3.53642445e+00
  4.25215036e+00 -2.02307589e+00 -2.66003185e+00 -3.22171421e+00
  8.13911453e+00  2.36662002e+00  3.72863971e+00 -1.96015582e+00
  2.58387304e+01]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2692.4900790110996
gradient value of function right now is: [-1.18683225e+00 -5.03198373e-02 -1.62481332e-03 -1.50242189e-03
  1.18683225e+00  5.03198373e-02  1.62481332e-03  1.50242189e-03
 -2.26363024e+00 -3.70704839e-04 -1.50259378e-01 -2.13235603e+00
  3.91642054e-01  1.93234572e-07  1.22299947e-04 -2.74425223e-03
 -1.67634973e-02 -3.59798468e-04 -5.55033937e-03 -1.68599864e-02
 -1.51837860e-02 -3.16849410e-04 -4.87648978e-03 -1.50055473e-02
  3.02681006e-02  1.83240237e-03  6.45175202e-03  9.19239347e-04
 -6.85690407e-03 -4.43285403e-04 -1.51686817e-03 -2.03856676e-04
 -3.77534072e-01 -1.38689252e-01 -2.07598196e-01 -5.96740726e-02
 -1.15746721e-01 -8.87861231e-02 -1.22147471e-01 -3.61804370e-03
 -1.71594087e-02 -2.05907324e-02 -1.88087786e-01 -1.84925373e-02
  3.62239533e-02  6.77836824e-02  2.32515023e-01  3.85405578e-02
  2.41370701e-02  4.84433816e-02  8.64994396e-02  2.53366985e-02
 -5.20764332e-03 -2.21382095e-02 -2.02659352e-02 -5.66373784e-03
 -1.13776004e-01  3.73581081e-01 -4.29019857e-01  9.48089416e-01
  3.55322876e-01 -7.14692673e-01 -1.83702624e-01  5.73444912e-01
  3.75847090e+00]
supnorm grad right now is: 3.7584709024853575
Weights right now are: 
[ -1.89674584   3.91037358  -5.61543235  -6.02852928   2.15131455
  -4.01906527   6.01436962   5.31250089   3.94567113  -8.89809395
  -3.88479602  -3.69390944   3.57147671   7.87853446   2.15723728
   6.75882693   9.24951612  -5.6172012   -2.26155587  -1.25151561
   9.18265027  -5.94463675  -2.19458907  -1.11330291   2.2887746
 -18.91162258 -11.89091438  -5.99030228  -0.50900893  18.7275797
  12.85852616   5.78643098  -1.2350701    7.43272572   3.25825404
  -8.44223353 -12.86248295   7.47118509   2.16911703  -5.44281536
 -12.77014472 -19.29339669   2.06315175 -15.89464823   5.22253497
   7.60840311  -2.28037811   8.48049011   2.79213828   5.1612821
  -3.7991143    3.86121078   9.38075463   5.02760729  14.218864
  10.70759469   2.11530374  -2.37165156  -2.05656958  -3.58244986
   8.37691425   2.43586011   2.10359438  -2.30167912  26.01764395]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2693.066393298788
gradient value of function right now is: [-1.78210571e-01 -3.21662042e-02 -7.05479520e-05 -7.11561062e-05
  1.78210571e-01  3.21662042e-02  7.05479521e-05  7.11561063e-05
 -3.58063356e-01 -1.21951176e-03  9.73894263e-03 -1.96697642e-01
  3.01141261e-01  1.97000491e-06  8.61674288e-05  2.61340551e-02
 -4.57058549e-04 -1.68900433e-04 -3.49120091e-04 -6.62963556e-04
 -4.54269683e-04 -1.68747350e-04 -3.46900956e-04 -6.58889536e-04
  1.40200931e-02  3.80044544e-04  2.24978538e-03 -1.41264012e-04
 -1.26484055e-02 -3.86477981e-04 -2.13714130e-03  1.22937217e-05
  9.24560936e-02  7.74669891e-02  9.92956067e-02  3.65990444e-02
 -1.84855485e-01 -2.57744059e-01 -2.90405813e-01  5.04939723e-03
 -4.55119500e-02 -1.68209131e-02 -1.05264314e+00 -4.62822026e-02
  1.19976572e-02  4.27463358e-03  3.87072535e-01  1.22356490e-02
  8.67506433e-03  1.74216444e-02  7.60582868e-02  9.09706954e-03
 -9.14013788e-04 -3.20072303e-03  1.45771428e-02 -9.40597017e-04
 -1.25815702e-01  1.15490345e+00 -7.95972922e-02  6.18868521e-01
 -2.69248217e-01  3.19605370e-01 -1.57984318e-01  1.43334553e+00
 -1.56220334e-01]
supnorm grad right now is: 1.4333455309483738
Weights right now are: 
[ -1.76520782   4.71713099  -5.04885397  -5.53547394   2.01977653
  -4.82582268   5.44779124   4.81944555   4.40942795  -9.22543266
  -4.17794413  -3.18592095   3.63959409  13.68014144  -1.25541217
   6.37919518  12.4921649   -7.33676671  -1.25053192   0.50004914
  12.45725114  -7.72403185  -1.21695622   0.59562998   1.09866485
 -25.80823824 -16.73314896  -5.11395538  -0.49161787  25.71923412
  17.72573039   3.63706212  -1.0037663    8.33417439   3.56676852
  -8.86868236 -14.47276219   8.25748196   2.87186519 -10.4387445
 -16.75858196 -26.88409563   1.73438769 -19.89330576   6.08584875
   8.04095445  -2.22160433   9.09749171   2.47891591   5.33939573
  -2.43902371   3.39000522   9.50155135   3.24959758  17.94441181
  11.45505182   2.14169707  -2.04413748  -1.80705029  -3.27913762
   8.41471975   2.62184886   2.0028274   -2.05060184  25.90307383]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2693.772945183047
gradient value of function right now is: [ 4.62908075e-01 -5.27263714e-02  9.31790119e-05  1.06187158e-04
 -4.62908075e-01  5.27263714e-02 -9.31790109e-05 -1.06187157e-04
  5.36663983e-04  1.09546829e-03  1.40984484e-01  6.46709917e-02
  5.31944561e-01 -1.88232072e-05 -5.72628602e-04 -2.81744965e-03
  1.12617450e-03  9.11719330e-05  1.23338307e-03  1.33225348e-03
  1.30604279e-03  1.06484094e-04  1.42886586e-03  1.54026802e-03
 -1.45118595e-02 -3.27744692e-04 -2.11697253e-03 -1.48480818e-03
  1.40597349e-02  3.46851020e-04  2.15829231e-03  1.27005330e-03
  8.85109763e-02  4.80314591e-02  5.33168018e-02  3.90358233e-02
  2.18777310e-03  1.85640581e-02  4.99608684e-03  8.36930476e-03
 -6.19177319e-03 -1.11141985e-03 -7.36486727e-02 -6.17491179e-03
  6.65935819e-03 -8.72300439e-03  9.17138670e-02  6.46901986e-03
 -2.50741285e-03 -2.47999875e-02  6.26582422e-04 -2.84732686e-03
  1.24954126e-03  6.15430995e-03  1.82270554e-02  1.44040033e-03
 -6.99366121e-03  2.06882573e-01  1.73373936e-01 -9.98083835e-02
 -4.22328457e-01  9.78912079e-01 -3.71699838e-03  2.46533962e-01
 -1.10424800e+00]
supnorm grad right now is: 1.104247999743827
Weights right now are: 
[ -1.0640389    5.09378178  -6.07764471  -6.6509067    1.31860761
  -5.20247347   6.47658198   5.93487832   4.19676356 -11.23011717
  -2.89356124  -3.56758775   3.92258779  18.42545363  -7.50546358
  10.40030019  13.07320762  -9.06160751  -1.87813488   0.18222481
  12.98193781  -9.52599741  -1.91340786   0.20990232   1.82728338
 -30.48765387 -20.52535738  -4.4699074   -1.09524557  29.6408658
  22.01643378   1.59942106  -1.61848949   7.90547493   2.04543462
  -8.79375197 -14.17818233   9.75467212   4.3979462  -16.57897037
 -20.51365922 -30.89044708   1.9009844  -23.63561874   8.39912009
  10.55522362  -1.82111411  11.29159535   2.52904154   5.62909777
  -3.0481972    3.2425615   13.28418512   4.45102999  19.73415706
  15.38190849   2.02635572  -2.29090206  -1.9559894   -3.69459338
   8.9073576    2.52062201   1.85687086  -2.29700231  25.98700395]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2694.045122709971
gradient value of function right now is: [-6.38818396e-01  1.30446711e-02 -6.20861252e-04 -9.44502382e-04
  6.38818396e-01 -1.30446711e-02  6.20861251e-04  9.44502381e-04
 -4.80899346e-01 -1.11017847e-04 -1.53430834e-01 -4.60826003e-01
 -1.59110092e-01  2.35939134e-06  3.01300780e-03  1.04169943e-02
 -4.06900686e-03 -1.56102288e-03 -6.21864986e-03 -7.77558313e-03
 -6.08299792e-03 -2.32329562e-03 -9.27971702e-03 -1.16125811e-02
  6.36690853e-02  4.37309083e-04  6.05729810e-03  5.56883303e-04
 -3.26493854e-02 -2.17553188e-04 -3.06486847e-03 -2.97958653e-04
 -2.69140918e-01 -7.36257643e-02 -1.32122796e-01 -5.53950602e-02
 -8.46019388e-02 -8.68589596e-02 -1.12571013e-01 -7.20690248e-04
 -9.75452757e-03 -2.47008679e-03 -2.44636106e-01 -9.80135423e-03
  2.36092501e-02  2.16619084e-02  2.62246355e-01  2.37801862e-02
  3.49979159e-02  5.10423904e-02  1.24272881e-01  3.52759070e-02
 -3.76027132e-03 -1.16400861e-02 -1.15783826e-02 -3.86293462e-03
 -6.59946309e-02  4.95208681e-01 -2.12913537e-01  4.14653991e-01
  2.88013324e-01 -7.80571847e-01 -8.35459897e-02  5.96773836e-01
  3.44792256e+00]
supnorm grad right now is: 3.447922555550361
Weights right now are: 
[-1.01653541e+00  6.30510220e+00 -6.39443793e+00 -7.01597167e+00
  1.27110412e+00 -6.41379389e+00  6.79337520e+00  6.29994329e+00
  4.38702995e+00 -1.11698769e+01 -4.28482072e+00 -3.21684929e+00
  3.47059859e+00  1.99701213e+01 -7.25972926e+00  9.93701923e+00
  1.30687888e+01 -9.89488881e+00 -2.15401994e+00  1.60916734e-01
  1.28346618e+01 -1.04461777e+01 -2.32119998e+00  7.81800330e-02
  2.11422061e+00 -3.20716595e+01 -2.17549818e+01 -1.11597136e-02
 -9.72058196e-01  3.18279211e+01  2.39213002e+01 -3.27439031e+00
 -1.53568796e+00  8.56107910e+00  1.76963538e+00 -9.63632717e+00
 -1.45764315e+01  1.09824149e+01  5.36575263e+00 -2.04139105e+01
 -2.46715896e+01 -3.58498862e+01  1.91951925e+00 -2.79261264e+01
  9.32280956e+00  1.07422802e+01 -1.49945945e+00  1.20191852e+01
  3.72309974e+00  6.57969392e+00 -2.53381005e+00  4.27017018e+00
  1.83444250e+01  3.80930393e+00  2.14942627e+01  2.05438055e+01
  2.61103741e+00 -2.24640838e+00 -2.98374069e+00 -4.50819606e+00
  9.27568010e+00  2.24322140e+00  2.56800241e+00 -2.24774230e+00
  2.61459135e+01]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -2693.1473672663174
gradient value of function right now is: [-1.12585314e+00 -3.91774774e-02 -8.02288154e-04 -1.06245854e-03
  1.12585314e+00  3.91774774e-02  8.02288155e-04  1.06245854e-03
 -7.81262495e-01 -1.85739878e-03 -4.92880324e-01 -7.17353449e-01
  4.18828415e-01  5.16228334e-06  1.33890220e-02  1.28348491e-03
 -4.26445819e-03 -5.84632896e-03 -7.34122910e-03 -8.27111516e-03
 -5.55848015e-03 -7.60219008e-03 -9.54042428e-03 -1.07232506e-02
  7.37949028e-02  2.02573787e-04  4.34218430e-03  7.01621166e-03
 -6.50606907e-02 -9.75063028e-04 -7.46832117e-03 -5.50464875e-03
 -4.56473818e-01 -1.17152252e-02 -1.20475362e-01 -5.15607581e-02
  2.29546700e-02  1.79848761e-02  2.20746024e-02  5.07981970e-03
  1.56449457e-03 -6.66866084e-04  5.58693353e-02  1.91262150e-03
  8.95709782e-03  3.35280875e-02 -8.77634633e-02  1.09600777e-02
  1.04405630e-02  8.74582888e-02  3.08137308e-03  1.38154727e-02
 -3.70858635e-03 -4.95691655e-02 -1.05979564e-02 -5.51790934e-03
  1.08995449e-02 -4.57919696e-02 -4.08205861e-01  6.91573714e-01
  1.05887032e-01  8.00378028e-03  1.82367423e-02 -7.45413876e-02
  4.10394954e+00]
supnorm grad right now is: 4.10394954185922
Weights right now are: 
[ -1.18007574   5.32652665  -5.29075451  -5.85542952   1.43464445
  -5.43521834   5.68969178   5.13940114   4.87038456 -17.77848726
  -3.89381813  -2.68785634   5.08300174  32.45240474 -14.67153127
  16.31088859  15.28641927  -8.96938098  -0.40243746   1.98508829
  15.12967389  -9.31210262  -0.44836527   2.05040031   0.83304664
 -33.90433288 -24.78551558   5.16889929  -1.10132071  27.96482216
  23.84081406 -12.22364171  -1.40821475   6.40758262   0.81592236
  -9.81358713 -14.23256053  12.92628562   7.12792989 -21.63585336
 -26.66099958 -40.30003787   2.58516031 -29.83443481  10.28650689
  12.98773891  -1.10481102  13.05811966   2.86450589   5.95321523
  -1.59607686   3.17035538  19.46919649   1.18753967  25.24894754
  21.95653327   2.60353286  -2.56667898  -4.5140115   -4.3020808
   9.15669779   2.16473843   2.19975738  -2.42953795  26.13832401]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2705.923593082472
gradient value of function right now is: [-1.94298766e+00 -4.87795325e-01 -7.38489211e-03 -8.63032986e-03
  1.94298766e+00  4.87795325e-01  7.38489211e-03  8.63032986e-03
  6.09031643e-02 -4.78016196e-03  5.41598565e-02  5.50142026e-02
  4.12668353e-01 -1.96169553e-03  4.65997873e-01  5.29264880e-01
 -6.21096362e-02 -8.82199544e-02 -9.28607797e-02 -9.40361700e-02
 -7.14264512e-02 -1.01208128e-01 -1.06539729e-01 -1.07887442e-01
  7.05736204e-01  9.20936130e-07  3.58706654e-02  1.39088356e-02
  1.23560875e-01 -2.51030232e-03  6.65947371e-02 -1.75674176e-02
  4.43061068e-01 -9.23986148e-03  2.14359341e-02  6.29131958e-02
 -5.39996885e-01 -1.41249286e-01 -2.92152199e-01 -2.15899695e-02
 -3.00269036e-02 -5.30567321e-03 -9.09242755e-01 -3.64606891e-02
  4.80376488e-02  1.92369063e-02  1.37758743e+00  5.95482875e-02
  6.68574962e-02  6.12623629e-01  5.16774703e-02  9.57856199e-02
 -2.12041347e-02 -1.14852311e-01 -3.08044813e-02 -3.01243951e-02
 -9.47015285e-02  2.31259099e+00 -8.83384264e-01  1.79378816e+00
  6.14482841e-01 -2.27661094e+00 -5.69750795e-02  3.14683995e+00
  6.76487103e+00]
supnorm grad right now is: 6.764871034261994
Weights right now are: 
[ -0.73169183   1.14341294  -6.55024805  -7.0422782    0.98626054
  -1.25210463   6.94918532   6.32624982   8.51791967 -18.98918752
  -1.82962631   1.20307875   8.51317815  57.14694453 -18.79298467
  11.05084757  16.07644887  -9.36536015  -0.40061891   1.89446418
  15.93125453  -9.59848747  -0.37956145   2.02602407   0.77998521
 -36.01365307 -30.25302849   5.88473533  -3.23635504  16.22111295
  16.73098926 -23.51007751  -4.34296528   6.70637389   0.52812331
  -3.24513979 -10.16726785  14.61025027   9.61356513 -27.98174986
 -29.46408363 -47.82631266   2.15017613 -32.14485735  13.9262603
  16.55128482  -0.37919425  17.1304519    2.98864556   3.49750397
  -0.48323085   2.70269482  18.77774193  -1.140896    28.31082472
  20.70492691   0.76846911  -1.93037188  -4.65022251  -3.36621625
   8.91441378   1.50158513   0.44366458  -1.83154808  26.67121892]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2719.1991651406893
gradient value of function right now is: [-1.75754672e+00 -1.32465148e+00 -3.73582674e-04 -5.92406373e-04
  1.75754672e+00  1.32465148e+00  3.73582676e-04  5.92406376e-04
 -5.60159431e-01 -1.03061547e-01 -6.69056593e-01 -1.08156582e-01
  1.52183949e-01 -2.01928598e-03 -3.11565888e-01 -7.21638762e-01
 -4.63006766e-03 -4.32873544e-03 -5.65939466e-03 -5.66090184e-03
 -7.18000612e-03 -6.69996056e-03 -8.76256849e-03 -8.76834125e-03
  3.10154395e-02 -3.12635087e-07  2.64574167e-03 -1.46229521e-05
 -8.48923585e-01  2.11035933e-02 -2.25866439e-01 -1.01649797e-02
  1.19669547e+00  1.28176444e+00  2.42132425e+00 -3.21317355e-02
  4.65680029e-01  1.76024434e-01  3.37418976e-01  2.09056877e-02
  1.00208119e-01  2.02365852e-02  4.83132491e+00  1.14214411e-01
 -1.00938222e-01 -1.94082076e-02 -4.83960554e+00 -1.15882320e-01
  3.25168588e-01  3.71076458e-01  3.72573047e-01  3.65780570e-01
 -8.33608971e-03 -2.70177444e-02  3.07822091e-02 -1.21389861e-02
  5.99266597e-01 -8.30539528e+00 -9.92585138e-02 -1.87512334e+00
 -1.05505938e+00  6.20659545e+00  8.42975856e-01 -1.07283649e+01
 -9.87998760e-01]
supnorm grad right now is: 10.728364917528896
Weights right now are: 
[ -1.67687868   2.32848675  -7.59627094  -8.07119766   1.93144739
  -2.43717844   7.99520821   7.35516927  -1.48232716 -11.30127888
  -0.41929964   3.28730045   9.62648306  72.20474676 -17.85328914
   9.25378115  15.0728938  -10.15677066  -1.19005751   1.1049319
  14.83101439 -10.47665116  -1.26184425   1.14309052   1.4332033
 -37.4635941  -32.30161711   5.70444254  -2.58471536  12.25422997
  15.09212028 -24.86922471  -5.74957654   6.45172066  -0.09982417
  -6.5526253  -10.55587117  11.93383114   8.99877249 -24.86450832
 -31.30197841 -53.25177799   2.24448185 -33.62289554  16.65255579
  19.10998409   0.1986479   19.6669572    2.74504349   2.92300552
  -0.6898809    2.75047966  22.1998914    0.83382036  29.18284074
  23.50608785   0.08111564  -2.19187817  -3.75853389  -3.41237376
   9.03297281   1.57300025  -0.3526442   -2.15004468  26.67043112]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2722.315408856761
gradient value of function right now is: [ 7.85433628e-01  1.88368011e+00 -3.37417030e-03 -4.21814235e-03
 -7.85433628e-01 -1.88368011e+00  3.37417030e-03  4.21814235e-03
  7.18088805e-01 -1.00928783e+00  2.07496809e-01 -1.03158031e+00
 -1.45080772e+00 -1.55347060e-03 -1.30658266e+00 -9.45981744e-01
 -3.80656998e-02 -4.18456787e-02 -5.19930232e-02 -5.20327794e-02
 -4.65567530e-02 -5.10468099e-02 -6.33643931e-02 -6.34125640e-02
  1.56336960e-01 -5.43765732e-05  1.54161624e-02  1.02795755e-03
 -1.14709272e+00 -1.05169742e-01 -2.43893000e-01 -1.51540746e-01
 -1.17398961e+00 -7.96917938e-01 -1.21986541e+00 -1.18662450e-02
  1.03383052e-01 -7.04242251e-02  1.05917253e-02  6.45672170e-03
 -4.57001904e-02 -1.26714849e-02 -2.03443906e+00 -4.24197059e-02
  2.61085196e-02  5.93136370e-02  1.58873168e+00  2.91603547e-02
  1.36318611e-01  6.37904559e-01 -5.12545522e-01  1.84359771e-01
 -3.44622324e-02 -1.82142173e-01 -6.47597248e-02 -4.67750435e-02
 -1.53580344e-01  3.60155202e+00 -2.12860126e+00  6.04475194e+00
  1.45133190e+00 -5.61327840e+00 -2.48065871e-01  3.61389858e+00
  4.29140703e+00]
supnorm grad right now is: 6.044751936632637
Weights right now are: 
[ -2.79847931   2.0368835   -7.80923276  -8.22644731   3.05304802
  -2.14557519   8.20817003   7.51041893  -2.4883244   -3.9648845
   1.49296774   4.29441039   9.66719364  75.81792911 -17.52720099
   8.15870303  16.15634365 -10.29433347  -0.96551336   1.32655645
  15.96934482 -10.54724885  -0.96674187   1.43522197   3.2011838
 -39.51218728 -31.24509799   3.65082143  -2.98717791  14.81831893
  13.30876072 -21.61658341  -6.90073459   6.6925931    0.58690896
  -6.8064382   -8.96530063  10.85239818   7.28130588 -27.95568518
 -34.09550534 -54.4234442    1.54135713 -35.87641321  18.47886386
  19.38355488  -0.12593022  21.41684265   1.49351928   5.21397019
  -0.71719169   2.79113423  23.93805738   3.06375285  31.48692254
  24.30546193   1.09780841  -1.91702811  -5.46407045  -3.44246658
   8.93256201   1.08405191   0.34415665  -2.02710791  26.61136054]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2720.8819987759484
gradient value of function right now is: [-9.44308769e-01 -1.75451357e+00  9.17120923e-04  9.91595644e-04
  9.44308769e-01  1.75451357e+00 -9.17120922e-04 -9.91595643e-04
 -2.53154527e+00  9.79552526e-01 -1.42658342e+00  8.46871602e-01
 -7.49515994e-03 -8.23108770e-03 -3.39450378e-01 -8.36970209e-01
  1.36074738e-02  1.41778696e-02  1.50925352e-02  1.51013099e-02
  1.44238816e-02  1.50377946e-02  1.59994152e-02  1.60085738e-02
 -1.01510089e-02  1.36947755e-06 -7.85052815e-04 -1.97754961e-04
  1.67118234e+00  2.11568474e-01  7.16787259e-01  1.51544551e-01
  3.31405515e+00  2.00129317e+00  3.05469127e+00  1.09796691e-01
  1.54556772e+00  6.08145983e-01  1.25327416e+00  1.27731234e-02
  2.23546245e-01  4.02676362e-02  6.25010732e+00  2.14064659e-01
 -2.86755757e-01 -1.05823340e-01 -6.73042138e+00 -2.83879411e-01
 -2.28683963e-01 -3.54115018e-01 -3.11662773e+00 -2.51977275e-01
  3.17228321e-02  9.85966824e-02  8.36841793e-02  4.04076472e-02
  2.23797138e+00 -2.44953775e+01  2.29676697e+00 -9.90446093e+00
 -2.59485296e+00  1.63841233e+01  2.60973833e+00 -2.62922980e+01
 -1.31277133e+01]
supnorm grad right now is: 26.292298024410492
Weights right now are: 
[ -3.12457419   1.75190294  -8.10327165  -8.50398652   3.3791429
  -1.86059463   8.50220892   7.78795814  -2.30242403  -3.73782908
   2.00838002   4.07278808   9.61216285  72.02428644 -17.50903802
   7.92976578  16.48695756 -10.55635563  -1.00893215   1.28314787
  16.39062337 -10.76370302  -0.96234684   1.43957087   1.73020212
 -40.42109593 -35.5022474    5.25061045  -4.0010232   16.84536617
  12.30310631 -20.20294702  -7.49537227   7.99131303   1.6887835
  -6.88201697  -8.52982901  10.86588043   5.97667588 -36.44267303
 -35.85377496 -58.21806674   1.70668844 -37.63308185  20.66864006
  22.48806575  -0.12655657  23.78132772   1.99546385   4.25691766
  -0.69214707   3.07803181  26.56631204   4.18191019  34.44033243
  26.50082785   0.89948579  -2.0576994   -4.6123839   -3.6086763
   9.35943203   0.98882624   0.31806134  -2.13631244  26.55451444]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2721.781484441837
gradient value of function right now is: [ 1.16166782e+00  3.89486281e+00 -6.16909835e-03 -9.30266810e-03
 -1.16166782e+00 -3.89486281e+00  6.16909836e-03  9.30266810e-03
  8.04111995e-01 -4.27612202e+00 -8.95761444e-01 -6.09998597e+00
  3.43992951e+00  3.11779942e-02  3.67823316e+00  4.04835484e+00
 -7.71547232e-02 -9.43096258e-02 -1.01448857e-01 -1.01439197e-01
 -1.14064845e-01 -1.38969484e-01 -1.49536488e-01 -1.49521474e-01
  4.27862940e-01 -2.90666354e-07  1.49238620e-02 -3.49719490e-05
 -6.05788532e+00 -5.04196528e-01 -2.17725250e+00 -3.88734008e-01
 -2.68058652e+00 -2.01050389e+00 -2.78448107e+00 -6.20005313e-02
 -3.90541641e+00 -1.63867329e+00 -3.27532141e+00 -1.93344090e-02
 -2.85957260e-01 -5.98578978e-02 -9.24605362e+00 -2.78785319e-01
  4.19265768e-01  2.17794762e-01  1.01430743e+01  4.23589902e-01
  1.02404717e+00  2.24565944e+00  5.72859016e+00  1.13577486e+00
 -8.40184368e-02 -3.19414473e-01 -1.54552506e-01 -1.04661134e-01
 -3.10725860e+00  3.28285379e+01 -5.55922627e+00  1.91352589e+01
  5.24445633e+00 -2.82487559e+01 -3.78873740e+00  3.60370080e+01
  2.44503235e+01]
supnorm grad right now is: 36.03700795953764
Weights right now are: 
[ -2.88383003   1.62302599  -8.30852844  -8.80620761   3.13839874
  -1.73171768   8.70746571   8.09017923  -2.43290396  -3.39925412
   2.08486005   3.63572242   9.34889771  68.01814043 -17.46666853
   8.50749993  17.3268438  -10.53307826  -0.82211782   1.46966856
  17.16736999 -10.85852368  -0.87995275   1.52168142   1.05367134
 -40.34302081 -40.24827674   8.21339678  -3.32792469  15.9598463
  12.61530594 -22.04427863  -9.0312027    7.6387419    1.8390853
  -5.4804873   -8.53393936  12.39272251   4.43664755 -41.97404721
 -38.02570116 -62.84580182   1.77092269 -39.91182716  21.4507024
  22.62173296   0.12282691  24.5646741    1.35026747   3.8320118
  -0.66849148   2.15093845  30.81869473   5.8841066   36.99634861
  30.10382499   0.77279882  -2.13397548  -4.56792171  -3.65084123
   9.9036484    1.15857596   0.29829323  -2.20088131  27.0027182 ]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2722.09171174138
gradient value of function right now is: [ 2.44949206e+00  4.49957567e+00  2.96033273e-03  5.10431144e-03
 -2.44949206e+00 -4.49957567e+00 -2.96033273e-03 -5.10431144e-03
  7.48821255e+00  1.51551169e+00  6.39246238e+00  2.45626571e+00
 -7.93830260e-01  1.34259740e-03 -6.35382798e-01 -1.97980557e-01
  4.66089720e-02  5.11606113e-02  5.39220246e-02  5.39017435e-02
  7.94392077e-02  8.79252789e-02  9.26274716e-02  9.25933780e-02
 -8.06302838e-02  6.12042541e-08 -4.02453531e-03 -1.05518615e-06
  5.99342420e-01 -1.12068012e-01  6.89483440e-02 -1.06806334e-01
 -2.07866313e+00 -1.35973904e+00 -2.31065600e+00  7.05130872e-02
 -7.22042399e-01 -4.73992090e-01 -8.22660889e-01 -3.11542228e-04
 -1.10324378e-01 -4.04282669e-02 -6.07712056e+00 -1.13801254e-01
  9.78184738e-02  7.15527000e-02  5.25516976e+00  1.03610498e-01
 -3.64948630e-01 -3.56108028e-01  4.75942600e-01 -3.69917822e-01
 -1.27799869e-02 -5.35307004e-02 -3.68060744e-02 -1.58518118e-02
 -1.25509850e+00  1.23655597e+01 -1.46374113e+00  8.28474793e+00
  1.71730383e+00 -9.23370790e+00 -1.47280710e+00  1.38564131e+01
  1.34830572e+00]
supnorm grad right now is: 13.85641314384372
Weights right now are: 
[ -2.68490187   1.74944406  -8.69487677  -9.16057927   2.93947058
  -1.85813575   9.09381404   8.44455089  -2.29995418  -3.20644446
   2.56522858   3.82588564   9.15651796  64.44603204 -17.49712563
   8.72203738  17.99571124 -10.58850186  -0.81204653   1.47962019
  17.83522166 -10.94729506  -0.89761      1.50390401   0.77710416
 -40.5159811  -44.29869161   4.60782868  -3.67300761  17.3109215
  12.54939264 -21.22432835  -9.78767062   8.28773976   2.21486659
  -5.53862784  -7.98911378  13.83825222   3.97315749 -47.54176195
 -39.80015279 -66.63615174   1.67687432 -41.73068596  23.18179895
  24.27406511   0.3623536   26.37886861   1.0093352    4.51918794
  -0.77019455   1.64427926  33.33390675   5.52766318  39.53890211
  32.25980006   0.8492223   -2.22769985  -4.83270371  -3.45223911
  10.28701734   1.38854575   0.43397171  -2.25678378  26.7602005 ]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -2722.745505412395
gradient value of function right now is: [-1.00795002e+00 -2.73003646e+00 -7.41442170e-04 -1.42671579e-03
  1.00795002e+00  2.73003646e+00  7.41442170e-04  1.42671579e-03
 -4.16128925e+00 -1.26017752e+00 -4.19699912e+00 -2.90023413e+00
  2.14687646e+00  9.81098677e-03  2.16265621e+00  2.00292996e+00
 -1.29789978e-02 -1.33995609e-02 -1.42910927e-02 -1.42830943e-02
 -2.44563840e-02 -2.52062157e-02 -2.68729362e-02 -2.68584358e-02
  3.32733331e-02 -2.64924747e-10  9.28163681e-04 -1.26777085e-08
 -1.78216020e+00 -2.30265303e-02 -6.82732214e-01  6.01306915e-05
  8.54528083e-02  7.96566721e-02 -1.17113106e-01 -1.44595037e-02
 -3.07149741e-01  5.63673602e-02 -1.33183532e-01  7.14199906e-03
 -1.99225367e-02 -4.94145270e-03 -8.09667149e-01 -2.01410725e-02
  3.52486050e-02  2.47463914e-02  6.02659729e-01  3.66421574e-02
  3.14964759e-01  5.94924814e-01  1.27926614e+00  3.38114372e-01
 -7.74992818e-03 -3.25271850e-02  1.44097590e-02 -8.92054312e-03
 -1.81901851e-01  2.48565197e+00 -8.86969316e-01  2.56408919e+00
 -6.06492063e-01  2.17287112e+00 -2.47442697e-01  2.83860294e+00
  5.99037309e+00]
supnorm grad right now is: 5.990373087554043
Weights right now are: 
[ -2.78686097   1.4898972   -9.53943943  -9.97770874   3.04142968
  -1.59858889   9.93837669   9.26168035  -2.41543845  -4.2416904
   2.53079651   3.4826973    9.05603217  63.30371025 -17.26691746
   9.56707938  18.02526945 -11.16536341  -1.2771529    1.01409135
  17.8338698  -11.56663214  -1.39065261   1.01043525   0.11720684
 -40.54140166 -49.47671941   2.19228176  -3.90340666  14.19750625
  12.2551721  -23.63142425 -11.70640267   6.72642191   1.92903091
  -2.77318837  -7.82322984  16.03361062   2.94155895 -47.33730415
 -41.46630153 -70.52444022   1.98506973 -43.49488184  24.44961241
  25.25600906   0.78408091  27.67107809   1.66761159   3.45211805
  -1.20851348   2.01705113  34.60473093   4.64374105  43.69270038
  33.42187762   0.09696173  -2.32924008  -3.82254005  -3.38293818
  10.19489076   1.84919761  -0.08187605  -2.32376573  26.8415097 ]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2723.1047052558934
gradient value of function right now is: [-6.74428853e-01 -1.60946341e+00 -4.29690359e-03 -8.92959966e-03
  6.74428853e-01  1.60946341e+00  4.29690359e-03  8.92959966e-03
 -2.87298953e+00 -1.77844537e+00 -2.80457383e+00 -2.53545075e+00
  1.13692656e+00  1.19874910e-02  1.11731568e+00  1.01825410e+00
 -8.51415892e-02 -8.22351813e-02 -8.88331291e-02 -8.87630235e-02
 -1.70355497e-01 -1.64373603e-01 -1.77539422e-01 -1.77399552e-01
  1.36915471e-01 -1.33469027e-09  7.16305178e-03  6.90211267e-06
 -2.06762209e+00 -3.13949382e-02 -6.20799343e-01  1.20730665e-02
  2.51343919e-01  1.91708055e-01  2.14882769e-01  2.89429861e-02
 -5.62583953e-01 -1.29283224e-01 -5.03095855e-01  2.86154894e-03
 -2.86733998e-02 -3.94217711e-03 -1.14430476e+00 -2.72676494e-02
  6.78591183e-02  2.30183077e-02  1.99595570e+00  6.54872109e-02
  4.35597083e-01  6.93835785e-01  2.01847883e+00  4.38407692e-01
 -3.90681415e-03 -2.19385247e-02  3.36827617e-03 -4.12060328e-03
 -3.95629074e-01  5.13741167e+00 -9.89297367e-01  3.45765513e+00
 -1.60966610e-01  5.16919839e-01 -4.36800389e-01  5.41945758e+00
  6.96663003e+00]
supnorm grad right now is: 6.966630029838455
Weights right now are: 
[ -3.05106955   1.31238108 -10.26652428 -10.56247386   3.30563826
  -1.42107277  10.66546154   9.84644547  -2.5312584   -4.05841639
   2.61692801   4.12467225   8.59048111  61.34697875 -17.83909934
   9.13755219  17.8756668  -11.79092906  -1.72581441   0.56505326
  17.65904053 -12.20760231  -1.85675736   0.5438978    0.31501428
 -40.55644803 -51.76936966  11.33560519  -3.99819955  16.03026746
  13.16519966 -19.94339168 -11.46242077   8.34167209   3.4602929
  -1.30000492  -7.3412804   16.61193258   2.02238815 -50.45418669
 -43.35323326 -73.50774359   1.896038   -45.40576966  24.01725135
  22.67589803   0.55101047  27.14345906   2.51722513   5.13862002
  -0.57347272   2.72387619  37.84099988   6.5829742   44.15431838
  36.80170407   0.3429883   -2.20778905  -4.77172252  -3.43900743
  10.83676676   1.48173316   0.18895368  -2.24301971  26.87636651]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2721.4491850744544
gradient value of function right now is: [-1.36664952e+00 -3.08443637e+00 -1.47745673e-03 -4.15593945e-03
  1.36664952e+00  3.08443637e+00  1.47745673e-03  4.15593945e-03
 -5.53208523e+00 -1.23069642e+00 -5.05044236e+00 -2.44498967e+00
  8.40606302e-01  8.24167419e-03  8.08608224e-01  6.77990501e-01
 -2.90776812e-02 -2.90048087e-02 -3.13648751e-02 -3.13317664e-02
 -7.79759055e-02 -7.75651710e-02 -8.39054770e-02 -8.38181767e-02
  9.07551109e-02 -6.58050703e-08  4.76615857e-03  9.51369762e-06
 -1.29492673e+00  6.35012923e-03 -3.42806258e-01  3.94305320e-02
  6.76376656e-01  4.03976758e-01  7.21142270e-01 -9.90243014e-03
  6.84981559e-01  3.75765881e-01  7.39122474e-01  6.36625038e-03
  6.65027692e-02  2.55866792e-02  4.36342889e+00  6.35242470e-02
 -5.30185628e-02 -2.59988442e-02 -4.13743691e+00 -5.04430100e-02
  2.43830480e-01  4.34856705e-01  4.08514683e-01  2.41235054e-01
 -1.08993392e-03 -1.18388848e-02  1.46661248e-02 -1.11853466e-03
  5.57578515e-01 -7.93006669e+00  9.66504479e-02 -3.68696358e+00
 -8.09630895e-01  5.01878058e+00  5.73549290e-01 -8.13778104e+00
 -1.85932523e+00]
supnorm grad right now is: 8.137781044697359
Weights right now are: 
[ -3.36983361   1.4196078  -10.52903996 -10.76533168   3.62440232
  -1.52829949  10.92797722  10.04930329  -2.72746737  -3.82291188
   2.68336034   4.08257656   8.52527727  55.59798123 -17.63453914
   9.71315262  18.61858459 -11.82614834  -1.62672134   0.66395935
  18.36858863 -12.35133702  -1.8462291    0.55439234   1.12249367
 -40.58217705 -55.91280662  18.00878357  -3.81181709  17.16955463
  13.94917352 -19.85230047 -11.96483823   8.56791517   3.5961406
  -2.47688814  -6.99136564  17.409678     1.71536355 -53.82744509
 -44.80608373 -76.18787515   1.98595734 -46.94141089  24.6244595
  23.81557848   0.60855382  27.74602358   2.83602184   5.50908379
  -0.16082892   2.9146979   41.57425209   7.04223696  46.14122379
  40.54341554   0.27941969  -2.29866974  -5.42076495  -3.3080861
  11.37189497   1.57627357   0.21474916  -2.32793382  26.53181993]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2723.6816200816706
gradient value of function right now is: [-1.02072710e+00 -2.46724753e+00 -2.09991272e-03 -4.41392824e-03
  1.02072710e+00  2.46724753e+00  2.09991272e-03  4.41392824e-03
 -4.74641459e+00 -2.11435853e+00 -4.78510072e+00 -4.04457930e+00
  2.16496103e+00  1.15726498e-02  2.17488220e+00  2.03724788e+00
 -4.18804318e-02 -4.25611287e-02 -4.54112602e-02 -4.53810794e-02
 -8.28304130e-02 -8.40500653e-02 -8.96526901e-02 -8.95933255e-02
  1.12825211e-01 -4.09241874e-10  4.85228213e-03  1.76854527e-06
 -2.10435979e+00 -1.07855399e-01 -7.15724032e-01 -9.13976862e-02
 -3.62462299e-03 -2.65367438e-02 -4.94903990e-02 -1.84707215e-03
 -4.55147064e-01 -3.35021778e-02 -2.83784780e-01  2.48970603e-03
 -1.02337983e-02 -3.16116507e-03 -3.98341036e-01 -1.03827057e-02
  6.29052219e-02  6.54564398e-02  8.40113848e-01  6.68918977e-02
  3.04719947e-01  8.13979430e-01  4.76111373e-01  3.30863246e-01
 -2.51359155e-02 -1.05400838e-01 -1.15392916e-02 -2.88446225e-02
 -2.23820875e-02  2.10405477e+00 -1.91984440e+00  5.13396496e+00
  3.51821657e-01 -9.03556791e-01 -7.28222750e-02  2.48345034e+00
  7.13613811e+00]
supnorm grad right now is: 7.136138110604028
Weights right now are: 
[-2.93683344e+00  1.44186996e+00 -1.07531281e+01 -1.07903022e+01
  3.19140215e+00 -1.55056165e+00  1.11520653e+01  1.00742738e+01
 -2.90487722e+00 -3.31062691e+00  2.81004050e+00  3.47206913e+00
  8.40490192e+00  5.17395829e+01 -1.75500443e+01  9.88353415e+00
  1.89057772e+01 -1.18716957e+01 -1.63396243e+00  6.56114534e-01
  1.87634238e+01 -1.23385826e+01 -1.78633136e+00  6.13641981e-01
  9.31944326e-01 -4.06199999e+01 -6.05428803e+01  1.77494991e+01
 -3.87806152e+00  1.84693522e+01  1.28218042e+01 -2.07507791e+01
 -1.21176819e+01  9.75633809e+00  3.19290572e+00 -5.57821638e+00
 -7.43920889e+00  1.77861415e+01  2.15132032e+00 -5.92670519e+01
 -4.63271856e+01 -7.87624434e+01  1.41105652e+00 -4.85119023e+01
  2.66413480e+01  2.65353026e+01 -1.49691180e-02  2.97812585e+01
  2.03359335e+00  3.90254933e+00 -1.17185489e+00  2.04652982e+00
  4.18652351e+01  3.37442187e+00  4.71572517e+01  4.08356620e+01
  3.89814586e-01 -2.24714175e+00 -4.74575005e+00 -3.55076465e+00
  1.20466090e+01  1.60511012e+00  1.96965915e-01 -2.24202717e+00
  2.68605283e+01]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2718.6306556958216
gradient value of function right now is: [-2.08385085e+00 -4.32139757e+00  1.18656920e-03  3.63678499e-03
  2.08385085e+00  4.32139757e+00 -1.18656920e-03 -3.63678499e-03
 -4.45305714e+00  2.13007781e+00 -3.05469626e+00  3.30071965e+00
 -1.98413130e+00 -2.04185827e-02 -2.09448780e+00 -2.14112325e+00
  2.20614119e-02  2.44846803e-02  2.55288421e-02  2.55112176e-02
  6.30080173e-02  6.97360766e-02  7.27029091e-02  7.26515006e-02
 -1.21365405e-01  6.99791130e-09 -3.98344870e-03 -1.81363569e-06
  2.98672735e+00  1.93013312e-01  1.24427473e+00  1.37570100e-01
  1.50217824e+00  1.24861059e+00  2.90794558e+00 -1.56612749e-02
  1.56370707e+00  6.57504085e-01  2.20289076e+00  4.34303329e-03
  1.57889105e-01  2.81705994e-02  1.29771897e+01  1.62983150e-01
 -1.85414167e-01 -8.13854537e-02 -1.13260600e+01 -1.93132185e-01
 -5.28398394e-01 -8.42123168e-01 -3.74955812e+00 -5.53218216e-01
  2.45082905e-02  1.00980826e-01  3.07332485e-02  2.77018289e-02
  1.97197977e+00 -2.13033561e+01  3.00156459e+00 -1.08671603e+01
 -2.78549948e+00  1.29481338e+01  2.25242856e+00 -2.36517600e+01
 -1.80285022e+01]
supnorm grad right now is: 23.651760020712626
Weights right now are: 
[ -2.90342389   1.44400278 -10.61811374 -10.59500743   3.1579926
  -1.55269447  11.01705099   9.87897904  -2.76754307  -3.72650186
   3.04497541   3.79810999   7.84427612  50.65106242 -17.73538976
  10.52885741  19.51050425 -11.53090142  -1.26766022   1.02275891
  19.29078935 -12.10247897  -1.51792763   0.8824714    0.76889027
 -40.71267952 -62.98089582  16.67359018  -3.89319033  14.99643384
  12.48482868 -24.21721002 -13.91127554   7.57022713   2.39718684
  -2.29115464  -7.19394021  18.46109604   0.95843915 -58.79474102
 -47.3056046  -81.78510188   1.93877952 -49.52847031  27.16117235
  25.62822958   0.61970202  30.24318787   1.92233546   4.88509583
  -1.3351248    1.88743474  43.67349204   4.38919914  49.90244339
  42.72655793  -0.11345292  -2.5060691   -5.68121513  -4.12385408
  11.91414457   2.26146472  -0.27534328  -2.5032695   26.61462107]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2719.7098829242273
gradient value of function right now is: [ 3.16060908e+00  1.00578736e+01 -3.48260503e-03 -8.79975231e-03
 -3.16060908e+00 -1.00578736e+01  3.48260503e-03  8.79975231e-03
  7.75771500e+00 -4.49583027e+00  5.36450812e+00 -5.21643677e+00
  2.70116685e+00  2.50507283e-02  2.92074405e+00  3.13142976e+00
 -6.82237333e-02 -7.35935546e-02 -7.72264634e-02 -7.72046519e-02
 -1.55645234e-01 -1.67452926e-01 -1.75693807e-01 -1.75641603e-01
  3.18101555e-01 -1.75201332e-10  6.89679108e-03 -5.19870107e-07
 -5.14579335e+00 -2.96017801e-01 -1.75806865e+00 -2.01161392e-01
 -2.37483105e+00 -2.16658552e+00 -4.75574433e+00  5.24532284e-03
 -2.35103134e+00 -1.10376183e+00 -3.36988607e+00 -7.75737660e-04
 -2.37341819e-01 -5.35569343e-02 -2.34316581e+01 -2.81039141e-01
  2.57356695e-01  1.11585279e-01  1.93952035e+01  3.08687409e-01
  6.96916362e-01  1.69146394e+00  4.49950008e+00  8.49925530e-01
 -5.12049268e-02 -1.81751003e-01 -3.71293308e-02 -7.11344857e-02
 -3.53304097e+00  3.41976169e+01 -5.64716569e+00  2.04774148e+01
  4.88176242e+00 -2.31320261e+01 -4.51802742e+00  4.31958580e+01
  2.55063843e+01]
supnorm grad right now is: 43.19585796339334
Weights right now are: 
[-2.75126162e+00  1.59259501e+00 -1.10550993e+01 -1.07003870e+01
  3.00583033e+00 -1.70128670e+00  1.14540365e+01  9.98435858e+00
 -2.77327451e+00 -4.26024898e+00  3.11125765e+00  3.47328034e+00
  7.81882480e+00  4.83323402e+01 -1.77706651e+01  1.09413640e+01
  1.93931771e+01 -1.18523402e+01 -1.50227573e+00  7.90136284e-01
  1.92856105e+01 -1.24102948e+01 -1.71146523e+00  6.90987406e-01
  1.48021792e-02 -4.07121815e+01 -6.67013104e+01  2.14671930e+01
 -3.76836970e+00  1.19126719e+01  1.26670144e+01 -2.58798969e+01
 -1.47970249e+01  7.24563474e+00  2.43418478e+00  6.36080359e+00
 -7.99449352e+00  1.93399986e+01  3.34576272e-01 -5.65906763e+01
 -4.88972290e+01 -8.67380899e+01  2.13139999e+00 -5.11656496e+01
  2.90089064e+01  2.72960024e+01  7.40146737e-01  3.21680238e+01
  2.48738340e+00  4.28619542e+00 -8.00173267e-01  2.32535547e+00
  4.24132843e+01  2.65553252e+00  5.18213709e+01  4.14877054e+01
 -4.84334273e-01 -2.48378377e+00 -5.24902227e+00 -3.84710338e+00
  1.23633985e+01  2.37692613e+00 -7.81261380e-01 -2.43023147e+00
  2.67905283e+01]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2721.3559425806666
gradient value of function right now is: [ 6.22386234e-01  3.53154929e+00 -3.35086957e-04 -2.65379766e-03
 -6.22386234e-01 -3.53154929e+00  3.35086957e-04  2.65379766e-03
  1.43289259e+00 -2.10668805e+00  7.94283822e-01 -2.40490874e+00
 -3.61673401e-01  1.10223485e-02 -3.01368667e-01 -2.36347545e-01
 -6.20721396e-03 -7.20274609e-03 -7.43771110e-03 -7.43328361e-03
 -4.38756972e-02 -5.05185388e-02 -5.21809849e-02 -5.21491296e-02
  9.07502016e-02 -2.28059265e-10  1.51346736e-03 -2.45781273e-07
 -2.97136417e+00  7.90875931e-02 -8.41094903e-01  6.22099339e-02
 -5.68728712e-01 -4.96946274e-01 -9.01776855e-01 -2.73510903e-02
 -8.11426986e-01 -4.60872411e-01 -1.02536584e+00  2.38094038e-03
 -8.84603753e-02 -1.45234426e-02 -7.55985860e+00 -9.69484922e-02
  1.12898021e-01  1.44997015e-02  8.37806849e+00  1.22173008e-01
  6.41497580e-01  8.30391081e-01  4.42039666e+00  7.12635043e-01
  2.33364695e-05 -1.94789887e-02  1.99933188e-02  1.17568860e-04
 -1.69619072e+00  1.65589798e+01 -1.51046506e+00  6.71778791e+00
 -2.29533041e-01 -1.10303140e+00 -1.96477895e+00  1.91871748e+01
  9.03513043e+00]
supnorm grad right now is: 19.187174849374898
Weights right now are: 
[-3.06088546e+00  1.58926332e+00 -1.09750349e+01 -1.06661562e+01
  3.31545417e+00 -1.69795501e+00  1.13739721e+01  9.95012785e+00
 -2.67157262e+00 -4.73592038e+00  2.70728504e+00  3.94974997e+00
  7.40212601e+00  4.26285776e+01 -1.81440823e+01  1.07468514e+01
  2.02631945e+01 -1.15803645e+01 -1.06207904e+00  1.22762431e+00
  1.98379615e+01 -1.24504842e+01 -1.57365481e+00  8.26432132e-01
  1.47982409e-01 -4.07388927e+01 -7.08859008e+01  2.32587703e+01
 -4.03653944e+00  1.54237415e+01  1.36462449e+01 -2.16004878e+01
 -1.51405845e+01  7.89848066e+00  2.77034010e+00  3.55869222e+00
 -7.34625359e+00  1.95994453e+01  5.57402616e-02 -5.99920796e+01
 -5.05189273e+01 -8.97912080e+01  2.13960213e+00 -5.27653922e+01
  2.93231782e+01  2.65151276e+01  4.79210256e-01  3.24145157e+01
  2.79486678e+00  4.77162012e+00 -1.33800562e-01  2.69008437e+00
  4.46352471e+01  3.82967842e+00  5.16635560e+01  4.34306383e+01
 -3.75707828e-01 -2.39490380e+00 -5.69600360e+00 -3.81582997e+00
  1.26657132e+01  2.33374240e+00 -7.16045192e-01 -2.38033566e+00
  2.65564011e+01]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2721.4000426675248
gradient value of function right now is: [ 1.27089514e+00  1.02710964e+00  3.74009803e-03  3.29182062e-02
 -1.27089514e+00 -1.02710964e+00 -3.74009803e-03 -3.29182062e-02
  6.26259261e+00  5.04349033e+00  6.51354636e+00  5.23199788e+00
  9.09624176e-02  1.45071818e-02  7.70906641e-02  8.94658145e-02
  6.88355989e-02  8.25472807e-02  8.39323441e-02  8.37635427e-02
  5.41195746e-01  6.47534809e-01  6.58466057e-01  6.57142505e-01
 -1.61676911e+00  2.37441593e-10 -2.43975483e-02  9.45596774e-06
  5.59158830e-01 -3.57848248e-02 -5.67304373e-02  6.49973965e-03
 -9.37939301e-02 -2.49902485e-02 -6.01217870e-02  4.01821015e-02
 -2.38219912e-01 -1.28077970e-01 -2.03434088e-01  4.56098474e-03
 -1.71085696e-02 -4.57884386e-03 -7.49204941e-01 -1.59284508e-02
  3.47462437e-02  6.55302122e-03  1.47815769e+00  3.24067569e-02
 -4.59175851e-01 -1.60920996e+00  8.53769464e-01 -4.72403828e-01
  4.11424906e-03  4.46173651e-02  2.45672437e-03  4.28184963e-03
 -5.61325834e-02  3.14511639e+00  1.25196000e+00 -8.16529533e-01
 -2.63733959e-02  1.38924833e-01 -7.30553429e-02  3.16755355e+00
 -5.34942892e+00]
supnorm grad right now is: 6.51354635851294
Weights right now are: 
[-3.04551521e+00  1.33098788e+00 -1.09718700e+01 -1.05090792e+01
  3.30008392e+00 -1.43967957e+00  1.13708072e+01  9.79305083e+00
 -2.41016813e+00 -3.48721985e+00  3.04410725e+00  4.64525918e+00
  7.19329373e+00  3.71522505e+01 -1.82898912e+01  1.08516740e+01
  2.08389121e+01 -1.13972824e+01 -7.85568884e-01  1.50082249e+00
  2.03294435e+01 -1.23140946e+01 -1.28757887e+00  1.10960989e+00
 -1.83665731e-01 -4.07461347e+01 -7.51219823e+01  2.69718510e+01
 -4.41360331e+00  1.76383412e+01  1.37592700e+01 -2.08611870e+01
 -1.34025409e+01  1.05648167e+01  4.51343043e+00  3.52414545e+00
 -6.20746246e+00  2.01670755e+01  1.36033763e-01 -6.07592289e+01
 -5.16051019e+01 -9.24592762e+01  2.00389925e+00 -5.39172931e+01
  2.96071103e+01  2.67294449e+01  5.45412143e-01  3.26803739e+01
  2.99317314e+00  4.21878358e+00  8.50994909e-02  2.80981647e+00
  4.75270471e+01  2.20076483e+00  5.25665692e+01  4.59540517e+01
 -3.72093976e-01 -2.39983383e+00 -5.82912829e+00 -3.78321609e+00
  1.35649597e+01  1.99261955e+00 -5.08864373e-01 -2.45328890e+00
  2.66615496e+01]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2723.353039397589
gradient value of function right now is: [ 1.10752945e+00  3.29731373e+00 -1.39382098e-03 -1.50652281e-02
 -1.10752945e+00 -3.29731373e+00  1.39382098e-03  1.50652281e-02
  1.60527600e+00 -3.43037874e+00  8.53302502e-01 -3.89915907e+00
  1.70452019e+00  3.94596225e-02  1.75638399e+00  1.72844174e+00
 -2.70577896e-02 -3.19723016e-02 -3.27235351e-02 -3.26740230e-02
 -2.49085727e-01 -2.90770514e-01 -2.97895205e-01 -2.97445937e-01
  7.74395045e-01 -1.33649929e-10  1.79508997e-02  1.19898514e-05
 -2.80619707e+00 -1.12532187e-01 -1.02903871e+00 -6.79584534e-02
 -7.19192476e-01 -5.96695182e-01 -1.04857186e+00 -8.36725935e-03
 -1.63019788e+00 -6.17110339e-01 -1.56273665e+00 -7.47023076e-04
 -1.09144186e-01 -2.23925670e-02 -7.75193129e+00 -1.09082950e-01
  1.99055876e-01  8.77634949e-02  1.01422803e+01  2.00799925e-01
  5.87831782e-01  1.51806731e+00  3.10413467e+00  6.15775558e-01
 -2.02030424e-02 -9.59796279e-02 -1.79497530e-02 -2.21248864e-02
 -2.20565009e+00  2.13037007e+01 -3.51680152e+00  1.24795205e+01
  1.35006525e+00 -6.48483657e+00 -2.38859535e+00  2.28418638e+01
  1.69008919e+01]
supnorm grad right now is: 22.841863796769733
Weights right now are: 
[ -2.79342851   1.30178215 -11.59388062 -10.95195299   3.04799722
  -1.41047384  11.99281787  10.2359246   -2.62490593  -3.27838339
   2.88235491   4.03168298   7.05117307  33.26358708 -18.1598799
  11.3306182   20.79855218 -11.78829173  -1.10424429   1.17936363
  20.20281724 -12.77443817  -1.64971904   0.74474052   0.42721815
 -40.66580678 -77.53687664  32.67092618  -4.39775963  16.91763924
  13.59620346 -22.47757602 -14.87847977   9.18676357   2.8340919
  -0.49219009  -6.46101925  20.4397713   -0.09885508 -62.61443727
 -52.69458335 -95.2266138    1.97800163 -55.0623819   30.83048551
  27.47611353   0.29290527  33.94395629   2.79444815   4.31814987
  -0.45805059   2.57112775  50.38965187   0.16705951  53.89930358
  48.72153226  -0.14026528  -2.34247581  -6.30447838  -3.87006439
  13.95860514   2.51893806  -0.31547028  -2.3580119   26.91480576]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2716.3104341346725
gradient value of function right now is: [-3.88889739e-01 -2.28614884e+00  2.36361312e-03  3.93810405e-02
  3.88889739e-01  2.28614884e+00 -2.36361312e-03 -3.93810405e-02
  1.23165324e+00  4.73561674e+00  2.43774194e+00  5.35127194e+00
 -1.18581929e+00 -2.47186278e-02 -1.30915125e+00 -1.36338062e+00
  5.54071319e-02  5.59555419e-02  5.87509078e-02  5.87080397e-02
  7.92644073e-01  7.97909196e-01  8.37237259e-01  8.36635996e-01
 -7.19575845e-01 -5.85300516e-10 -2.72983571e-02 -2.04282375e-03
  3.23889084e+00  7.14012825e-02  8.08027506e-01  6.69793731e-02
  1.04250906e+00  9.74754580e-01  2.03600781e+00 -5.97736773e-03
  8.58322514e-01  3.97552700e-01  1.12561906e+00  2.86705360e-03
  9.97303071e-02  2.75175039e-02  1.15533785e+01  1.02493226e-01
 -1.14862814e-01 -6.02494269e-02 -1.06767205e+01 -1.18872857e-01
 -6.61684860e-01 -2.24403941e+00 -3.80568460e+00 -7.12393459e-01
  1.87653998e-02  2.07661413e-01  1.89009170e-02  2.24341855e-02
  1.64578490e+00 -1.72305951e+01  4.46366423e+00 -1.46539367e+01
 -1.80008385e+00  7.56711731e+00  1.77106016e+00 -1.86800950e+01
 -2.28802891e+01]
supnorm grad right now is: 22.880289133626505
Weights right now are: 
[ -2.62767183   1.26276402 -12.23915357 -11.23258338   2.88224054
  -1.37145571  12.63809082  10.51655499  -2.4408257   -3.73610177
   3.13599077   4.51218798   6.97304307  31.45479948 -18.01118682
  11.90626526  20.62694319 -12.18872299  -1.43834489   0.84654242
  20.03006966 -13.30693755  -2.09594053   0.29957494   0.75599282
 -40.64203394 -80.17573901  33.38746128  -3.75098311  13.79102772
  13.77558181 -25.26226173 -15.04561827   8.54173829   2.56675541
   2.48031985  -6.87493395  21.27497779  -0.63912959 -61.21337539
 -53.91057765 -98.90381346   2.00860599 -56.28000885  32.57736262
  29.49898676   0.55836468  35.66322157   3.52305726   4.39823836
  -0.51410579   3.28626817  51.05583917   0.67961663  55.95900933
  49.37900099  -0.35591431  -2.53790345  -6.61356013  -3.89501974
  13.7993008    2.94860229  -0.6063003   -2.54483839  26.32140322]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2717.86439061613
gradient value of function right now is: [-2.82604004e+00 -5.92915183e+00 -2.24583907e-04 -2.54182561e-03
  2.82604004e+00  5.92915183e+00  2.24583907e-04  2.54182561e-03
 -9.69689545e+00 -5.66423052e-01 -8.71423402e+00 -1.47531668e+00
 -3.26535225e-01 -1.43229416e-03 -3.54095032e-01 -3.54230375e-01
 -5.54381453e-03 -5.44397769e-03 -5.78568892e-03 -5.77663054e-03
 -5.16042556e-02 -5.04364315e-02 -5.36498743e-02 -5.35716003e-02
  3.38826453e-02 -1.11616531e-10  1.15329204e-03 -3.01287697e-05
 -7.07486223e-02  5.25400882e-02  4.27007667e-02  2.25035162e-02
  8.64002332e-01  7.17989494e-01  1.32010682e+00 -1.47802705e-02
  1.67041670e+00  8.17798123e-01  2.04142565e+00  3.00498003e-03
  1.26747586e-01  1.93878299e-02  1.11851528e+01  1.29926098e-01
 -1.81158242e-01 -3.80198748e-02 -1.40597635e+01 -1.86450548e-01
  8.00315419e-02  7.83142509e-02 -4.40592492e-02  8.09305873e-02
  2.06214346e-03  2.16694545e-03  1.44355718e-02  2.36038181e-03
  2.07457074e+00 -2.36128330e+01  7.93105207e-01 -5.76969464e+00
 -1.40093662e+00  7.09248293e+00  2.33481730e+00 -2.59000082e+01
 -8.51349931e+00]
supnorm grad right now is: 25.900008200523693
Weights right now are: 
[  -3.20574793    1.24289886  -12.69880084  -11.24333998    3.46031664
   -1.35159055   13.09773809   10.52731159   -2.80091739   -3.97687794
    2.86422572    4.18061109    6.81222213   28.57733407  -18.28010833
   11.79502837   20.51601014  -12.42243144   -1.65301918    0.63131984
   20.13078019  -13.50135601   -2.25450044    0.14076645    0.77291015
  -40.64322024  -83.49843562   32.18907023   -4.44411189   14.07660642
   13.28629109  -26.27297213  -15.3977425     8.61834706    2.68124609
    6.59770258   -6.68112021   21.69932231   -0.78880957  -62.93393943
  -55.17216114 -102.55814837    2.11605669  -57.59173232   34.12405551
   28.5324183     0.53368713   37.18203587    2.92758966    5.45121523
   -0.23524718    2.83217089   51.40603114    1.32897292   57.70841562
   49.48162157   -0.64453307   -2.53364069   -7.0543375    -4.19637713
   14.30560382    2.68240555   -0.90711379   -2.54250618   26.61241718]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2722.9983431798746
gradient value of function right now is: [-2.16847188e-02  7.30314131e-02 -8.93437819e-05 -9.98463992e-03
  2.16847188e-02 -7.30314131e-02  8.93437819e-05  9.98463992e-03
 -4.02883634e-01 -1.10423547e+00 -4.00867360e-01 -1.21924919e+00
  4.58979382e-01  1.44427364e-02  4.46586626e-01  4.32813897e-01
 -1.98276636e-03 -2.18073689e-03 -2.21648005e-03 -2.21477561e-03
 -1.78246020e-01 -1.92972396e-01 -1.96203612e-01 -1.96070767e-01
  2.96731012e-01  8.75790197e-06  1.39106153e-02  1.35530232e-02
 -5.76827497e-01 -3.83209881e-02 -2.28297448e-01 -2.93031921e-02
  3.00014192e-02  5.13230491e-02  8.56362074e-02 -3.79712202e-03
 -1.26737809e-01 -6.61165317e-02 -2.78052570e-02 -8.18780294e-04
  3.94286507e-03 -3.41032712e-03  7.04730476e-01  3.94310309e-03
  3.18407460e-03  2.77226729e-02 -5.06100048e-01  4.00207307e-03
  1.00083730e-01  5.29834905e-01  5.32246866e-01  1.07528545e-01
 -1.30743090e-02 -1.70670266e-01 -1.38843119e-02 -1.47994552e-02
  1.34545559e-01 -7.33143552e-01 -2.00704574e+00  5.55956155e+00
  4.89338146e-01 -1.39986566e+00  1.28612067e-01 -7.34363872e-01
  2.19175062e+00]
supnorm grad right now is: 5.559561551561735
Weights right now are: 
[-2.99925573e+00  1.29923810e+00 -1.22097128e+01 -1.08855949e+01
  3.25382444e+00 -1.40792979e+00  1.26086500e+01  1.01695665e+01
 -2.38441123e+00 -4.03090676e+00  2.94684258e+00  4.81906138e+00
  7.02316000e+00  2.59273336e+01 -1.82831152e+01  1.19965081e+01
  2.13437684e+01 -1.16781612e+01 -8.77314937e-01  1.40554295e+00
  2.04830980e+01 -1.33897656e+01 -2.10024231e+00  2.92771685e-01
  6.23235802e-01 -4.20671090e+01 -8.65839143e+01  3.78858404e+01
 -4.63875959e+00  1.59945224e+01  1.42563278e+01 -2.39722401e+01
 -1.51362841e+01  9.44082494e+00  2.85403103e+00  5.41633908e+00
 -6.33369807e+00  2.08972492e+01 -1.05094027e+00 -6.37852170e+01
 -5.63213102e+01 -1.06410792e+02  1.92323915e+00 -5.88031703e+01
  3.52908489e+01  3.06211368e+01  5.68362308e-01  3.83910962e+01
  4.53925852e+00  5.59117428e+00 -3.04316332e-01  4.33160122e+00
  5.12476830e+01 -2.25214043e+00  5.89453217e+01  4.90045849e+01
 -1.04287298e-01 -2.53042577e+00 -7.64675144e+00 -3.94257211e+00
  1.45850475e+01  2.74303680e+00 -2.98708991e-01 -2.53389236e+00
  2.65310781e+01]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2720.9479507675824
gradient value of function right now is: [-1.44097888e+00 -3.58282130e+00  2.90365581e-04  1.23374976e-02
  1.44097888e+00  3.58282130e+00 -2.90365581e-04 -1.23374976e-02
 -3.87797271e+00  2.49763977e+00 -2.75059405e+00  2.66568037e+00
 -1.50088173e+00 -4.81123162e-02 -1.54250956e+00 -1.54222024e+00
  5.82059264e-03  7.16497092e-03  7.22270406e-03  7.21449881e-03
  1.93807035e-01  2.36584191e-01  2.38498689e-01  2.38226741e-01
 -5.25072934e-01  1.90903187e-13 -6.71249304e-03  5.05464702e-06
  2.16456900e+00  1.58608150e-01  9.82548828e-01  8.25636308e-02
  7.40699198e-01  7.32736834e-01  1.48802475e+00 -1.90596408e-02
  1.11038813e+00  5.61073598e-01  1.64670267e+00  2.18204039e-03
  1.06546660e-01  8.91380635e-03  1.01909966e+01  1.29748986e-01
 -1.50364032e-01 -2.52385449e-02 -1.16002087e+01 -1.84852991e-01
 -4.02162215e-01 -7.51559800e-01 -2.64864767e+00 -4.96240362e-01
  1.56385664e-02  3.90294512e-02  2.17688275e-02  2.38392614e-02
  2.14186021e+00 -2.08185631e+01  1.57784919e+00 -5.15147933e+00
 -2.19851701e+00  9.28434219e+00  2.84907057e+00 -2.68318810e+01
 -1.47756732e+01]
supnorm grad right now is: 26.83188101596044
Weights right now are: 
[-3.12093371e+00  1.29374827e+00 -1.22889189e+01 -1.05954847e+01
  3.37550242e+00 -1.40243996e+00  1.26878562e+01  9.87945633e+00
 -2.58355960e+00 -4.03460001e+00  2.89401926e+00  4.32234934e+00
  6.60448828e+00  2.24137951e+01 -1.85611074e+01  1.19059997e+01
  2.17258005e+01 -1.14944530e+01 -6.89915129e-01  1.59515994e+00
  2.11862299e+01 -1.29901448e+01 -1.68400093e+00  7.10826316e-01
  5.19650791e-02 -3.92507805e+01 -8.98450593e+01  3.72778601e+01
 -5.15815592e+00  1.37529119e+01  1.35846315e+01 -2.70632200e+01
 -1.64031574e+01  8.41661910e+00  2.21374134e+00  6.69068201e+00
 -6.75110893e+00  2.18465222e+01 -1.11329683e+00 -6.40784999e+01
 -5.73638675e+01 -1.11473565e+02  2.25161847e+00 -5.98834681e+01
  3.83219019e+01  3.37332526e+01  3.86833183e-01  4.15580273e+01
  2.74453761e+00  4.20592452e+00 -5.32080051e-01  2.54931427e+00
  4.99847840e+01 -1.38933008e+00  6.11106728e+01  4.74723575e+01
 -6.61192637e-01 -2.56122713e+00 -7.05310532e+00 -4.76277216e+00
  1.46269602e+01  3.02560027e+00 -1.07635011e+00 -2.49174172e+00
  2.67183887e+01]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2715.2634489003294
gradient value of function right now is: [ 4.57555634e+00  1.44614715e+01 -1.10106272e-04 -2.10650851e-02
 -4.57555634e+00 -1.44614715e+01  1.10106273e-04  2.10650851e-02
  9.62164153e+00 -9.38047724e+00  6.88865976e+00 -9.99265457e+00
  2.23375822e+00  8.39711192e-02  2.43636319e+00  2.54025467e+00
 -2.25053838e-03 -2.68364768e-03 -2.72415572e-03 -2.72221808e-03
 -3.35729972e-01 -3.94150590e-01 -4.00281958e-01 -3.99982497e-01
  8.17897067e-01 -2.06679173e-12  1.44323654e-02  3.17708445e-05
 -5.95422758e+00 -5.34400051e-01 -2.31288819e+00 -4.92466653e-01
 -1.90664419e+00 -2.28002418e+00 -3.81969447e+00  8.47322526e-02
 -2.37051455e+00 -1.29835325e+00 -3.14917553e+00 -7.35759608e-03
 -1.79878396e-01 -1.43395061e-02 -2.16871136e+01 -1.92938285e-01
  2.81868017e-01  6.59140703e-02  2.35149202e+01  3.09860549e-01
  9.19684918e-01  1.84700078e+00  3.77597719e+00  1.06996752e+00
 -7.73529335e-02 -1.99758573e-01 -6.44713596e-02 -1.03375688e-01
 -3.38823894e+00  3.64445034e+01 -4.75084736e+00  1.30998976e+01
  5.76189950e+00 -2.76032389e+01 -3.91664109e+00  4.12824595e+01
  3.95933951e+01]
supnorm grad right now is: 41.28245948205113
Weights right now are: 
[  -2.86790753    1.33459193  -12.18062494  -10.49392304    3.12247624
   -1.44328362   12.57956217    9.77789465   -2.57186228   -4.27470865
    2.75038121    4.52180799    6.74763737   21.07909464  -18.56250687
   12.1327933    22.1045203   -11.22484172   -0.37101112    1.91419288
   21.25761695  -13.16456972   -1.78737764    0.60806457    0.47239644
  -39.15327818  -91.97509375   35.72538721   -4.92466448   14.64185884
   14.26581791  -25.79356666  -16.61393806    7.85912249    1.94153469
    9.87648409   -7.08128681   22.3536954    -1.47168253  -63.34671902
  -57.9858766  -113.68849631    2.14119839  -60.44890884   40.36472567
   36.20981176    0.53852704   43.60565682    3.97103986    4.35568906
   -0.39358514    3.68195562   50.30335213   -0.30449651   62.83930021
   47.37789458   -0.38321357   -2.62808764   -7.3206707    -4.93703467
   14.98256082    2.58973978   -0.81780758   -2.63365574   27.18399776]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -2722.35341899885
gradient value of function right now is: [-8.54306885e-03  2.31125585e-01  1.44530593e-06  1.09925552e-03
  8.54306885e-03 -2.31125585e-01 -1.44530593e-06 -1.09925552e-03
  8.75177620e-01  7.58389808e-01  9.53207158e-01  1.62041797e+00
 -1.12960034e+00 -5.62326187e-02 -1.12714724e+00 -1.13811736e+00
  3.08884223e-05  3.52032887e-05  3.58032458e-05  3.57732628e-05
  1.86619872e-02  2.14426455e-02  2.17265068e-02  2.17068301e-02
 -1.72454777e-02  1.24989715e-15 -3.02648343e-04  2.41651987e-07
  2.35251104e+00  5.43281206e-02  1.07946638e+00  7.81267359e-02
  7.30903037e-02  7.43927445e-02  7.36846905e-02  4.95554797e-03
 -3.04795998e-01 -1.13339967e-01 -4.29796632e-01 -1.32691534e-04
 -1.15443160e-02  1.13414184e-04 -9.60472552e-01 -1.49506811e-02
  1.83910753e-02 -5.34557753e-03  1.94870607e+00  2.19532505e-02
 -4.44880130e-01 -2.96725113e-01 -3.49785999e+00 -5.86549115e-01
  1.80457326e-02  4.23628935e-02 -1.36111829e-03  3.67976313e-02
 -4.79068232e-01  2.94602476e+00  9.41782835e-01 -2.09613723e+00
 -1.16773410e-01  7.77428654e-01 -7.92818302e-01  4.57898477e+00
 -7.37726469e+00]
supnorm grad right now is: 7.377264693507921
Weights right now are: 
[-3.25727951e+00  1.28291129e+00 -1.21911487e+01 -1.03310940e+01
  3.51184822e+00 -1.39160298e+00  1.25900859e+01  9.61506559e+00
 -2.48094190e+00 -4.22839731e+00  2.43393085e+00  4.82531867e+00
  6.89803069e+00  1.97485035e+01 -1.88330794e+01  1.18059507e+01
  2.24498593e+01 -1.08963481e+01  3.12065897e-02  2.31751549e+00
  2.14607192e+01 -1.32815717e+01 -1.74322748e+00  6.54063225e-01
  2.59004628e-01 -3.91526853e+01 -9.48829711e+01  3.43366983e+01
 -4.79288040e+00  1.62546168e+01  1.38612128e+01 -2.41132404e+01
 -1.60918988e+01  9.67687166e+00  2.44226013e+00  9.66036108e+00
 -6.95201258e+00  2.23731376e+01 -1.48846842e+00 -6.54243803e+01
 -5.94040519e+01 -1.17907468e+02  2.13680431e+00 -6.20952684e+01
  4.25990986e+01  3.83202137e+01  3.29493559e-01  4.62690048e+01
  2.77010619e+00  4.13281537e+00 -7.43778823e-01  2.76039212e+00
  4.68409437e+01 -1.81853913e+00  6.22042469e+01  4.35063335e+01
 -7.00785957e-01 -2.52746290e+00 -7.07483003e+00 -5.02791544e+00
  1.52666328e+01  2.64564215e+00 -1.29967371e+00 -2.40861683e+00
  2.64289796e+01]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -2724.1434969636366
gradient value of function right now is: [ 5.51459767e-02 -1.08975165e+00  3.53683298e-05  6.95019803e-03
 -5.51459767e-02  1.08975165e+00 -3.53683298e-05 -6.95019803e-03
  1.30823532e+00  2.50041077e+00  1.78605400e+00  2.92387724e+00
 -5.74656180e-01 -2.75524570e-02 -6.31738965e-01 -6.59209891e-01
  9.21941539e-04  8.83821676e-04  9.27421264e-04  9.26515638e-04
  1.46791185e-01  1.42583538e-01  1.48585430e-01  1.48431193e-01
 -1.55087266e-02  2.53121895e-14 -9.69226448e-04 -1.62052020e-04
  1.94781511e+00  7.57147833e-02  6.85645497e-01  1.05428389e-01
  4.33718145e-01  4.41162099e-01  8.37942204e-01 -8.87652427e-03
  4.08288652e-01  1.78669231e-01  5.73620746e-01  9.56945292e-05
  4.47587783e-02  1.93466311e-03  4.89509418e+00  5.65207007e-02
 -6.46325977e-02 -1.24561131e-02 -5.20710725e+00 -8.33540270e-02
 -2.61612195e-01 -4.41976399e-01 -1.50855755e+00 -3.45510307e-01
  2.80831333e-02  7.81699047e-02  3.73459175e-03  4.41780168e-02
  5.88573025e-01 -9.08120013e+00  1.59481603e+00 -3.65696461e+00
 -6.84635033e-01  3.43888671e+00  8.16245127e-01 -1.20653108e+01
 -9.39594720e+00]
supnorm grad right now is: 12.065310786068508
Weights right now are: 
[  -3.03547261    1.32243063  -12.93420483  -11.00600809    3.29004132
   -1.43112232   13.33314202   10.2899797    -2.17128228   -4.27293897
    2.80333903    4.65489477    7.11291677   16.90459208  -18.65869722
   12.10225272   21.87127777  -11.91579692   -0.91227636    1.37380336
   21.13211325  -13.89137838   -2.27014224    0.12695778    0.57676553
  -39.48491441  -97.56841562   35.8680318    -4.83766907   16.66338878
   14.38495704  -22.91944658  -15.92316804    9.98458803    2.29895094
   12.31682475   -6.34590719   22.45174933   -1.33439827  -65.89699093
  -59.71817907 -120.08853379    2.14907563  -62.51547128   43.2763636
   38.57075169    0.32186247   46.8675279     4.47361218    4.04870285
   -0.49415923    4.31789173   46.74745323   -4.54829898   64.10589963
   43.21876416   -0.74945058   -2.58230173   -7.47843231   -5.17764417
   14.94873882    2.8510453    -1.13169575   -2.4938552    26.67905054]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2721.4259223243457
gradient value of function right now is: [ 1.49339447e-03 -1.24435128e+00  5.91533259e-04  1.75279825e-02
 -1.49339447e-03  1.24435128e+00 -5.91533259e-04 -1.75279825e-02
  1.14278492e+00  2.77957804e+00  1.71207621e+00  2.86392716e+00
  1.57256520e-01  6.05648999e-03  9.46675800e-02  6.33956364e-02
  1.61741218e-02  1.59895589e-02  1.64227962e-02  1.63764614e-02
  3.76609478e-01  3.74370275e-01  3.83683822e-01  3.82598371e-01
 -1.23915897e-01 -2.27711829e-08 -7.02616112e-03 -4.55712625e-03
  7.85259551e-01  1.70038044e-02  1.73973089e-01  4.79516658e-02
  6.74951197e-01  4.83890607e-01  7.92452358e-01  6.62135768e-03
  4.48203194e-01  1.74788605e-01  4.68902821e-01  6.75477110e-03
  5.92362113e-02  1.56917236e-03  4.15221222e+00  6.34523057e-02
 -8.53056490e-02 -7.06285855e-03 -5.36593053e+00 -9.10523613e-02
 -2.66074293e-01 -4.40631530e-01 -8.31795339e-01 -2.94147783e-01
  1.60609503e-02  7.47501267e-02  9.27120887e-03  2.07689019e-02
  9.90804163e-01 -1.26994023e+01  1.40460146e+00 -3.23531281e+00
 -9.21518249e-01  4.63927674e+00  1.19555939e+00 -1.45364594e+01
 -5.43571900e+00]
supnorm grad right now is: 14.536459390253327
Weights right now are: 
[  -3.24891912    1.36099362  -13.65213667  -11.27220664    3.50348783
   -1.46968531   14.05107385   10.55617825   -1.70314551   -4.27906708
    2.65600815    5.64981684    7.34044502   16.69077051  -18.65200215
   12.00532482   21.83821247  -12.41997668   -1.35644447    0.92951417
   21.54791657  -13.95827008   -2.2219123     0.17553515    1.08918848
  -39.65849192  -99.88000557   37.39014431   -5.02272253   18.92562201
   14.33869649  -18.44111428  -14.17092408   13.16586626    3.38320135
    9.5555492    -5.37469598   23.27412511   -0.30600347  -66.50743189
  -60.6483847  -125.76621321    1.88717671  -63.55694674   44.18161372
   39.93746205   -0.26062078   47.93604318    3.35143865    4.8625816
   -0.46460864    3.51123665   46.21616953   -8.15610468   65.20576289
   41.83517071   -0.3593155    -2.43653741   -8.31933306   -5.32126372
   14.95059059    2.68409484   -0.69704829   -2.43119206   27.00464433]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2722.301588405695
gradient value of function right now is: [-5.88654157e-01 -1.40814303e+00 -4.47105143e-04 -5.79028010e-03
  5.88654157e-01  1.40814303e+00  4.47105143e-04  5.79028010e-03
 -2.93108013e+00 -2.74030007e+00 -2.95893236e+00 -2.92528723e+00
  1.28334370e+00  1.43537128e-02  1.28121721e+00  1.19905332e+00
 -1.11212245e-02 -1.23797564e-02 -1.26092718e-02 -1.25896555e-02
 -1.06620546e-01 -1.17594915e-01 -1.19783593e-01 -1.19601779e-01
  2.31735162e-01  8.60005339e-11  7.82975479e-03  2.73892440e-03
 -9.97930024e-01 -6.27128041e-02 -3.44447932e-01 -8.56605838e-02
  3.12679177e-02  5.40945375e-02 -2.74147218e-02  7.83557300e-03
 -1.07125323e+00 -2.77689776e-01 -1.08979329e+00  4.25498974e-03
 -4.34320862e-02 -1.53782035e-03 -3.06497250e+00 -4.26828015e-02
  1.06928181e-01  1.70315283e-02  6.18405936e+00  1.08949375e-01
  1.46875058e-01  6.69331048e-01 -1.24421205e+00  1.91859911e-01
 -3.14264714e-02 -1.01583275e-01 -1.23522421e-03 -3.99271833e-02
 -3.32832493e-01  1.07126228e+01 -1.62188109e+00  3.98541143e+00
 -2.62888043e-02  5.12559207e-01 -4.16122564e-01  1.14589083e+01
  9.40300986e+00]
supnorm grad right now is: 11.458908325117108
Weights right now are: 
[  -3.1643433     1.14120072  -13.98360664  -11.29300262    3.41891201
   -1.24989241   14.38254381   10.57697423   -2.34653685   -3.93297253
    2.58591411    4.73564167    6.94422975   12.54281314  -18.76590447
   11.83356038   22.19222209  -12.56444725   -1.44856565    0.84747808
   22.05413168  -13.86953924   -2.11253033    0.29536758    1.64679275
  -39.70805115 -103.64244491   35.6769569    -5.0991733    18.9509309
   13.61421905  -22.68402731  -15.02154506   13.32656434    2.79178958
    0.78153059   -6.08198586   22.9429993    -1.28426923  -69.76765538
  -62.8991254  -135.95684599    1.56580702  -65.91267851   44.87645208
   43.28522339    0.1831717    48.56847835    2.74691192    4.11222202
   -0.64116602    2.94435094   47.38249658   -6.82410389   65.94257369
   42.68711555   -0.27456157   -2.43215961   -8.54632099   -5.19847174
   15.68115495    2.6167048    -0.73208288   -2.46606667   26.9513319 ]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2724.5344044641047
gradient value of function right now is: [ 2.00050229e-01  4.42742312e-02  2.53278999e-04  8.20086597e-03
 -2.00050229e-01 -4.42742312e-02 -2.53278999e-04 -8.20086597e-03
  1.37789992e+00  1.28239644e+00  1.69406388e+00  1.94020530e+00
 -7.06896193e-01 -4.66308299e-02 -7.31943675e-01 -7.19256286e-01
  5.42862539e-03  6.88805614e-03  6.94337388e-03  6.91880581e-03
  1.29853696e-01  1.63739438e-01  1.65050283e-01  1.64466485e-01
 -3.96542207e-01  2.28007329e-21 -5.18068072e-03  8.46721498e-08
  1.95582977e+00  7.67186533e-02  8.74344344e-01  8.53576943e-02
  2.44756661e-01  2.00934935e-01  3.10422852e-01  3.64805775e-02
  2.52534456e-01  5.94484207e-02  2.04300718e-01  3.57491793e-03
  2.01859675e-02  7.72461676e-04  1.38969756e+00  1.81654467e-02
 -4.14801443e-02 -5.75614546e-03 -1.61804788e+00 -3.85930792e-02
 -6.19858144e-01 -7.67184420e-01 -1.64228700e+00 -6.34524933e-01
  2.31940057e-02  3.97802779e-02  7.14099453e-03  2.41753069e-02
  4.55706048e-01 -4.50504223e+00  7.92766449e-01 -1.76123535e+00
 -4.49128797e-01  2.41357439e+00  5.34180974e-01 -4.52141836e+00
 -5.93366643e+00]
supnorm grad right now is: 5.93366643403188
Weights right now are: 
[  -3.06877168    1.4504445   -13.54850006  -10.95177633    3.3233404
   -1.55913619   13.94743723   10.23574794   -2.44099655   -4.52256873
    2.92465809    4.40015472    6.64170208   14.84976098  -18.84107935
   12.23256272   22.94662693  -11.97824417   -0.76373969    1.53525377
   22.63157959  -13.57327886   -1.66476182    0.74647798    0.43171931
  -39.59502114 -106.82222569   36.50585348   -5.00220799   19.74222063
   13.42262084  -23.43624369  -14.58136889   13.45629192    2.41768487
   -1.03753325   -5.61087855   21.78101218   -1.33479356  -74.08959205
  -63.00243657 -142.17361982    1.81416267  -66.05089415   45.44516709
   44.21817947    0.24364939   49.12367546    2.14696344    2.39628222
   -0.37342545    2.11701954   51.37109945   -6.67592141   66.48542582
   46.15533296   -0.65491063   -2.50208171   -8.25326033   -5.94561634
   16.50817303    2.5519422    -0.90041692   -2.5935702    26.76543902]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2722.6080386798976
gradient value of function right now is: [-2.15985752e+00 -4.46508223e+00  1.50020091e-06  9.90157056e-05
  2.15985752e+00  4.46508223e+00 -1.50020091e-06 -9.90157056e-05
 -5.24817678e+00  3.65415016e-01 -4.50586923e+00  4.33667378e-01
 -8.19975019e-01 -2.98425116e-02 -8.54254878e-01 -8.50848971e-01
  3.48969982e-05  4.35911301e-05  4.33592703e-05  4.33818173e-05
  1.59256393e-03  2.05936917e-03  2.00033471e-03  1.99926345e-03
 -5.85356542e-03  8.35544938e-20 -1.56939432e-04 -1.06727391e-07
  1.41497488e+00  3.07529253e-02  6.52513926e-01  1.23168316e-02
  7.12190037e-01  6.56104934e-01  1.14665858e+00 -7.71135307e-03
  1.23062560e+00  6.60239413e-01  1.67057596e+00  1.19416475e-03
  6.52874087e-02  6.94613984e-04  8.47399784e+00  8.09264888e-02
 -1.12637693e-01 -2.83119751e-03 -1.23258599e+01 -1.39811643e-01
 -1.60731328e-01 -1.51810330e-01 -4.13913930e-01 -2.26235786e-01
  1.06542098e-02  1.92622007e-02  7.15559005e-03  1.73393886e-02
  1.56200684e+00 -1.68960590e+01  4.82284948e-01 -1.17939308e+00
 -1.00145762e+00  4.96265012e+00  2.21769932e+00 -2.24856314e+01
 -1.06632609e+01]
supnorm grad right now is: 22.485631380285472
Weights right now are: 
[-2.71223257e+00  1.44793138e+00 -1.42699277e+01 -1.16402085e+01
  2.96680128e+00 -1.55662307e+00  1.46688649e+01  1.09241801e+01
 -2.84704470e+00 -4.18547424e+00  2.79586913e+00  3.83765406e+00
  6.47415871e+00  1.72505236e+01 -1.86204560e+01  1.26705594e+01
  2.25713079e+01 -1.25997788e+01 -1.29072681e+00  1.00846083e+00
  2.20926533e+01 -1.43976804e+01 -2.38974780e+00  2.13326690e-02
  1.03489157e+00 -3.95959162e+01 -1.08434306e+02  3.61372423e+01
 -4.63546563e+00  1.58992539e+01  1.24168568e+01 -2.87856887e+01
 -1.59574783e+01  1.18120634e+01  9.73312309e-01 -2.19968495e+00
 -6.53754125e+00  2.16315833e+01 -1.99286974e+00 -7.60860156e+01
 -6.37016595e+01 -1.51558723e+02  1.66265315e+00 -6.69219007e+01
  4.63231438e+01  4.49601237e+01  3.06480518e-01  5.02442705e+01
  2.85022719e+00  3.09101463e+00 -6.25235619e-01  2.83321917e+00
  5.24819617e+01 -6.99494537e+00  6.92974048e+01  4.68807810e+01
 -1.11738095e+00 -2.74065612e+00 -8.56596713e+00 -6.08198448e+00
  1.59566282e+01  3.08095764e+00 -1.69260155e+00 -2.68264064e+00
  2.65131380e+01]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2720.9561592909417
gradient value of function right now is: [ 1.15919765e+00  1.55537809e+00  6.37789964e-05  1.30463494e-02
 -1.15919765e+00 -1.55537809e+00 -6.37789964e-05 -1.30463494e-02
  4.77801425e+00  2.98720515e+00  4.59508565e+00  3.25936635e+00
 -3.95920310e-01 -4.43511905e-03 -4.49166789e-01 -4.47502494e-01
  1.80954526e-03  1.78084964e-03  1.83683307e-03  1.83691779e-03
  2.93738241e-01  2.90826795e-01  2.99025689e-01  2.99010365e-01
 -8.49048585e-02 -8.15429348e-11 -5.82361950e-03 -4.70434216e-03
  1.08201003e+00  3.69119088e-02  3.08778811e-01  2.91354231e-02
 -1.31947771e-01 -1.02649780e-01 -1.70687269e-04 -1.04786092e-02
  3.01688041e-01  1.09477148e-01  3.75436827e-01  1.59558497e-03
  1.66345887e-02  5.45974860e-04  1.83785262e+00  1.82322256e-02
 -3.11166089e-02 -2.74139347e-03 -2.69339760e+00 -3.49154237e-02
 -2.56398223e-01 -4.03898531e-01 -2.81266513e-01 -2.86188105e-01
  1.20886188e-02  6.72309471e-02  6.45671954e-03  1.60079656e-02
  2.95407746e-01 -3.87611050e+00  1.10597765e+00 -2.21041507e+00
  1.08545384e-01 -5.90906085e-01  3.57125098e-01 -4.55152945e+00
 -6.40244988e+00]
supnorm grad right now is: 6.402449875145233
Weights right now are: 
[-2.60451956e+00  1.34059709e+00 -1.42070008e+01 -1.18301563e+01
  2.85908828e+00 -1.44928878e+00  1.46059379e+01  1.11141279e+01
 -2.28824579e+00 -3.94230676e+00  3.37882829e+00  4.66147078e+00
  6.66453066e+00  1.85793995e+01 -1.86780963e+01  1.27485179e+01
  2.31579590e+01 -1.23700482e+01 -1.00005317e+00  1.29866981e+00
  2.25221809e+01 -1.44856879e+01 -2.39292588e+00  1.77794346e-02
  2.66620373e+00 -3.96918000e+01 -1.09072485e+02  3.33931504e+01
 -4.52782224e+00  1.68055975e+01  1.17994701e+01 -2.96287465e+01
 -1.72866641e+01  1.07146233e+01  7.85417720e-01  6.92619921e+00
 -7.18391214e+00  2.16215403e+01 -2.35751892e+00 -7.47480864e+01
 -6.39277409e+01 -1.52122095e+02  2.02462931e+00 -6.72165595e+01
  4.78844255e+01  4.65544662e+01  4.16926809e-01  5.17797756e+01
  3.31514643e+00  4.89479960e+00 -3.31108062e-01  3.28147551e+00
  5.09951976e+01 -6.88191174e+00  7.25663712e+01  4.50929976e+01
 -8.11723863e-01 -2.84688468e+00 -9.37472982e+00 -6.24830454e+00
  1.57335129e+01  3.31714138e+00 -1.15049285e+00 -2.82425019e+00
  2.67974964e+01]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2720.634512633805
gradient value of function right now is: [-5.04771315e-01  1.31433936e+00 -1.23489741e-05 -1.56870075e-03
  5.04771315e-01 -1.31433936e+00  1.23489741e-05  1.56870075e-03
 -2.43910251e+00 -3.73702340e+00 -2.72110247e+00 -4.65565246e+00
  8.49025281e-01  4.20036857e-02  8.48756775e-01  8.32231786e-01
 -1.82532042e-04 -3.16296957e-04 -3.18014605e-04 -3.17006154e-04
 -1.60461322e-02 -2.74648634e-02 -2.76146801e-02 -2.75271396e-02
  8.56434317e-02 -7.96645719e-14  1.19754275e-03 -5.46614456e-07
 -3.36317158e+00 -3.06936088e-02 -1.27413227e+00 -5.72808803e-03
 -1.72938598e-01 -1.19969580e-01 -3.03222228e-01 -8.57007394e-03
 -3.78642349e-01 -1.83643503e-01 -5.43855823e-01  2.39842164e-03
 -3.51683871e-02 -1.24158736e-04 -2.86618154e+00 -4.87110961e-02
  4.74400265e-02  3.44517173e-04  3.77678151e+00  6.69682640e-02
  5.97252317e-01  9.29350366e-02  4.20107089e+00  7.71747010e-01
 -3.94957427e-03 -3.11143386e-05  5.43296924e-03 -6.60758067e-03
 -1.87675393e+00  1.13238568e+01 -1.91356464e-01  4.73131104e-01
 -1.36332444e-02 -5.53565808e-01 -2.66827551e+00  1.60253221e+01
  9.75100181e+00]
supnorm grad right now is: 16.02532206319817
Weights right now are: 
[  -2.88152217    1.41682153  -12.67512703  -10.01035807    3.13609088
   -1.52551323   13.07406421    9.29432968   -2.54640714   -4.61165474
    3.06255983    4.22810135    7.00072656   14.6969312   -18.74238699
   12.71301896   24.91230983  -10.52902733    0.73651962    3.04024046
   24.48296912  -12.60700924   -0.63357297    1.78394481    2.33127649
  -38.89585095 -109.65531047   36.21544352   -5.50034174   16.41341645
   13.51620877  -29.35524275  -17.42814526   10.89228878    1.51933331
    7.72446241   -5.67273663   22.72606246   -1.84796948  -74.91745867
  -65.34707035 -152.65647001    2.31788847  -68.82253872   50.60014116
   43.90661968    0.47915223   54.63409195    5.2886503     5.48715667
   -0.372543      4.92632711   49.00388034   -8.11538662   75.55333891
   43.01355671   -1.30574353   -2.68178263   -9.20051497   -7.26100839
   15.54570923    3.22314408   -1.75373274   -2.55565515   26.56670816]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2719.5784413995875
gradient value of function right now is: [-2.48489420e-01 -2.57941849e+00 -6.88401037e-07 -6.28704507e-04
  2.48489420e-01  2.57941849e+00  6.88401037e-07  6.28704507e-04
 -1.59660062e+00 -7.60669385e-01 -1.60985906e+00 -1.02609883e+00
  7.47081930e-01  2.44568331e-02  7.56942297e-01  7.22780563e-01
 -1.48370094e-05 -1.87846382e-05 -1.89044827e-05 -1.89207769e-05
 -8.97093900e-03 -1.06647288e-02 -1.07320699e-02 -1.07569188e-02
  4.15120044e-02  1.00695501e-07  5.33747592e-03  1.29957748e-02
 -4.50712876e-01 -4.60831362e-02 -2.40451759e-01 -3.42095138e-02
  2.82050836e-02  5.83291633e-03  3.90196655e-02 -7.45943138e-03
  1.32729234e-02  5.83657151e-02  5.20418477e-02  4.26694934e-04
 -1.54570179e-03 -1.14374730e-04  3.27381190e-01 -1.06461337e-04
  4.77799849e-03  1.03393400e-02 -4.23212352e-01  4.50060517e-03
 -1.97096390e-03  1.57048310e-01  4.61385722e-01  1.06313596e-02
 -6.82168481e-03 -6.10540285e-02 -1.15659117e-02 -1.05836227e-02
  2.80453735e-01 -1.22227594e-01 -9.83348280e-01  2.78591953e+00
  3.65875377e-01 -7.87530227e-01  3.74647126e-01 -5.21088986e-01
  5.43509415e+00]
supnorm grad right now is: 5.4350941518050515
Weights right now are: 
[-2.86338696e+00  1.04587262e+00 -1.35294595e+01 -1.11254518e+01
  3.11795567e+00 -1.15456431e+00  1.39283966e+01  1.04094234e+01
 -2.13113664e+00 -4.08244406e+00  2.81543875e+00  4.99385141e+00
  6.60247990e+00  1.59484045e+01 -1.89601186e+01  1.28686134e+01
  2.37105714e+01 -1.13602999e+01 -9.46944401e-02  2.20928790e+00
  2.28368031e+01 -1.39850483e+01 -1.99922210e+00  4.15688262e-01
  1.70015261e+00 -3.92679758e+01 -1.11880520e+02  3.78318526e+01
 -5.86364994e+00  2.13728476e+01  1.38398771e+01 -2.54029589e+01
 -1.57916250e+01  1.24378513e+01  1.69400907e+00  3.37342091e+00
 -6.57184123e+00  2.17436641e+01 -1.59986420e+00 -7.76221602e+01
 -6.62157516e+01 -1.59039852e+02  1.93119073e+00 -6.96436588e+01
  5.21891754e+01  4.79475039e+01  6.07304372e-01  5.60944501e+01
  3.73223059e+00  5.60908137e+00 -3.29577234e-01  3.73389301e+00
  4.74233111e+01 -1.07318633e+01  7.50625357e+01  4.09590010e+01
  1.84354856e-01 -2.74019379e+00 -1.15338907e+01 -5.34656975e+00
  1.64106071e+01  2.72102895e+00 -4.66277678e-01 -2.67298617e+00
  2.65871191e+01]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2720.5958737101
gradient value of function right now is: [-7.60623620e-01 -1.88807531e+00  7.43901534e-06  7.73167024e-03
  7.60623620e-01  1.88807531e+00 -7.43901534e-06 -7.73167024e-03
 -1.22766816e+00  3.46344397e+00 -4.18593118e-01  3.56672124e+00
 -2.15559180e+00 -1.62793589e-01 -2.18219738e+00 -2.17761015e+00
  1.89524325e-04  1.97603347e-04  2.00888719e-04  2.00459073e-04
  1.57776677e-01  1.64839755e-01  1.67214850e-01  1.66853768e-01
 -1.26005879e-01 -7.77508222e-09 -5.83152687e-03 -6.56927648e-03
  2.81507424e+00  1.89165759e-01  1.23753668e+00  1.96497228e-01
  9.59216380e-01  6.31099696e-01  1.06575939e+00 -1.31292716e-02
  1.26795445e+00  4.71426015e-01  1.19428187e+00  4.08567257e-03
  8.59208371e-02  1.38595799e-03  5.93095033e+00  7.21551699e-02
 -1.74456006e-01 -1.41395768e-02 -9.10703853e+00 -1.51389357e-01
 -5.48848237e-01 -4.28483747e-01 -3.31391461e+00 -5.30027016e-01
  3.59875687e-02  8.19202934e-02  1.68221687e-02  3.76223313e-02
  2.31778955e+00 -2.53169438e+01  1.72949561e+00 -4.27004125e+00
 -1.27490843e+00  7.40396642e+00  2.33965006e+00 -2.34125220e+01
 -1.69214039e+01]
supnorm grad right now is: 25.3169437814996
Weights right now are: 
[-3.10882480e+00  1.30126355e+00 -1.33033595e+01 -1.12665472e+01
  3.36339351e+00 -1.40995524e+00  1.37022966e+01  1.05505188e+01
 -2.69800226e+00 -3.45816085e+00  3.13292675e+00  4.51126838e+00
  6.36024439e+00  1.32229660e+01 -1.93635843e+01  1.23369710e+01
  2.35037852e+01 -1.16576358e+01 -3.52374776e-01  1.95296834e+00
  2.26883434e+01 -1.42478263e+01 -2.25930685e+00  1.59097495e-01
  1.44590748e+00 -3.85980176e+01 -1.14165900e+02  3.75760108e+01
 -5.42694193e+00  2.47238345e+01  1.46956259e+01 -2.45039639e+01
 -1.44697799e+01  1.50612939e+01  2.34297913e+00 -1.99061554e+00
 -5.66753378e+00  2.19296834e+01 -3.40139532e-01 -8.29781053e+01
 -6.74458774e+01 -1.62771995e+02  1.52660713e+00 -7.09102306e+01
  5.15289269e+01  4.70186013e+01  3.06445456e-02  5.56074622e+01
  3.54052207e+00  5.01186683e+00 -5.32462368e-01  3.52537174e+00
  5.14016543e+01 -8.79514003e+00  7.47174837e+01  4.39347073e+01
 -5.02736694e-01 -2.52637638e+00 -1.06433457e+01 -6.36223575e+00
  1.64844384e+01  2.25224092e+00 -9.22034657e-01 -2.66316113e+00
  2.66185388e+01]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2723.9961348543948
gradient value of function right now is: [-6.91136963e-01 -1.73858980e+00  1.81264758e-06  9.00752386e-03
  6.91136963e-01  1.73858980e+00 -1.81264758e-06 -9.00752386e-03
 -7.03800084e-01  1.65777045e+00  1.13276309e-02  2.14240724e+00
 -6.11061308e-01 -2.15424830e-02 -7.16862903e-01 -7.41052425e-01
  4.92691137e-05  4.52934648e-05  4.91421306e-05  4.91784542e-05
  2.03890285e-01  1.92573717e-01  2.03559621e-01  2.03617310e-01
  5.37136671e-03  1.03240131e-13 -5.44525396e-05 -3.31760405e-04
  1.81575227e+00  1.37663793e-01  7.79927096e-01  1.30149424e-01
  8.82120103e-01  8.46668991e-01  1.24600453e+00  4.62560016e-03
  6.95754621e-01  2.52345078e-01  6.98660627e-01  1.05750185e-03
  6.04440868e-02  3.14109414e-04  6.09113735e+00  6.53961635e-02
 -9.62677253e-02 -2.44487533e-03 -7.25121578e+00 -1.06358480e-01
 -2.74586253e-01 -2.00394842e-01 -4.73091270e-01 -3.29460606e-01
  3.01076642e-02  3.23733825e-02  9.37426469e-03  3.98493858e-02
  1.66631808e+00 -1.49798239e+01  6.79142623e-01 -1.28667463e+00
 -1.39840507e+00  6.78065252e+00  2.19356458e+00 -1.78020338e+01
 -8.57339437e+00]
supnorm grad right now is: 17.8020338283029
Weights right now are: 
[-2.77527910e+00  1.50686137e+00 -1.33634696e+01 -1.18068984e+01
  3.02984781e+00 -1.61555306e+00  1.37624067e+01  1.10908700e+01
 -2.57434529e+00 -3.97082934e+00  3.12090854e+00  4.35301848e+00
  6.53402136e+00  1.36320273e+01 -1.89554846e+01  1.29046078e+01
  2.32559807e+01 -1.19546879e+01 -6.24983874e-01  1.68487417e+00
  2.21490813e+01 -1.49704567e+01 -2.94088816e+00 -5.16687284e-01
  7.88178137e-01 -3.86315305e+01 -1.18610304e+02  3.76030745e+01
 -5.63430928e+00  1.96493988e+01  1.39823853e+01 -3.04259805e+01
 -1.55333388e+01  1.34684420e+01  1.04703224e+00 -1.57023050e+00
 -6.40697373e+00  2.18537055e+01 -8.04545875e-01 -8.48557925e+01
 -6.79900685e+01 -1.67334878e+02  1.93323987e+00 -7.19087954e+01
  5.25221165e+01  4.58253021e+01  5.21658437e-02  5.71004713e+01
  3.07906848e+00  3.34866718e+00 -3.81685984e-01  3.00483941e+00
  5.09414320e+01 -1.17158486e+01  7.73838547e+01  4.23459414e+01
 -1.29830406e-01 -2.61032005e+00 -9.89269168e+00 -7.73712282e+00
  1.55748839e+01  2.86752962e+00 -5.66281566e-01 -2.62515247e+00
  2.68639068e+01]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2723.344325655819
gradient value of function right now is: [ 2.88602020e-01  5.81512054e-01 -6.15393810e-07 -1.97858971e-03
 -2.88602020e-01 -5.81512054e-01  6.15393813e-07  1.97858971e-03
  9.46462569e-01 -6.24846894e-01  7.29764989e-01 -3.67963292e-01
  2.95800981e-01  4.01374142e-02  3.15346377e-01  3.01883970e-01
 -1.49041950e-05 -1.63045363e-05 -1.65870061e-05 -1.65708301e-05
 -3.66951079e-02 -3.91688608e-02 -4.00426257e-02 -4.00027267e-02
  6.15945616e-02 -2.22743035e-21  1.28876254e-03 -7.62439836e-08
 -3.52483830e-01  2.31259752e-02 -1.33360080e-01  4.14461315e-02
 -1.43080627e-01 -1.00847994e-01 -3.12248805e-01 -1.41462006e-02
 -4.77201299e-01 -2.75208499e-01 -6.66928097e-01  1.28516981e-03
 -4.10573770e-02  5.78552842e-06 -4.06856954e+00 -3.97404462e-02
  5.56432545e-02 -8.20045824e-04  5.72136314e+00  5.28474432e-02
  1.98765817e-01  8.26950409e-03  2.01567842e+00  1.67830270e-01
  1.89743615e-02  9.16978820e-03  7.27119617e-03  2.59091822e-02
 -1.53832734e+00  1.22326433e+01  3.16292624e-01 -5.25765367e-01
 -4.36072392e-01  1.15288692e+00 -1.51842984e+00  1.25097575e+01
  3.47608414e+00]
supnorm grad right now is: 12.509757478707739
Weights right now are: 
[-2.75948051e+00  1.15425399e+00 -1.32753559e+01 -1.12181795e+01
  3.01404922e+00 -1.26294568e+00  1.36742929e+01  1.05021512e+01
 -2.68957131e+00 -4.34933072e+00  3.23801877e+00  4.44370767e+00
  6.02051594e+00  1.65691907e+01 -1.92628471e+01  1.28544647e+01
  2.38115789e+01 -1.15227039e+01 -1.42644644e-01  2.16808926e+00
  2.29198078e+01 -1.45845381e+01 -2.38257430e+00  4.37331473e-02
  1.06058098e+00 -3.86306845e+01 -1.21369921e+02  3.44577917e+01
 -5.36471330e+00  1.90739475e+01  1.37095676e+01 -3.20370062e+01
 -1.63332781e+01  1.25332016e+01  5.23996038e-01 -3.55107277e-01
 -6.78198343e+00  2.09738036e+01 -1.76335424e+00 -8.44394429e+01
 -6.87852473e+01 -1.66966125e+02  2.08268024e+00 -7.26067857e+01
  5.37673994e+01  4.79514228e+01  4.36193645e-01  5.80226322e+01
  3.05046107e+00  2.71551865e+00 -1.33579507e-01  3.21855155e+00
  5.14177412e+01 -9.48105326e+00  7.79168444e+01  4.29895194e+01
 -1.10381668e+00 -2.65979626e+00 -9.78043942e+00 -7.77217686e+00
  1.55370687e+01  3.05180456e+00 -1.61100559e+00 -2.72001533e+00
  2.67028452e+01]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2721.14306899857
gradient value of function right now is: [ 1.46615587e+00  6.14603938e+00 -4.83809360e-06 -2.04414463e-02
 -1.46615587e+00 -6.14603938e+00  4.83809307e-06  2.04414463e-02
  3.88282310e+00 -4.44640225e+00  2.18199914e+00 -4.52373459e+00
  2.84062637e-01  4.95051482e-02  3.63128952e-01  4.89888920e-01
 -1.18106036e-04 -1.28941326e-04 -1.30543015e-04 -1.29836366e-04
 -3.80098426e-01 -4.10100439e-01 -4.14760937e-01 -4.12696381e-01
  6.12193033e-01  1.48854730e-11  1.87109231e-02  2.50350656e-02
 -1.90479737e+00 -1.01165723e-01 -6.90993210e-01 -1.31974549e-01
 -1.63338934e+00 -1.39538072e+00 -2.01175836e+00  9.47013504e-02
 -5.49367181e-01 -4.84694062e-01 -9.46091159e-01 -2.13225085e-03
 -9.48542150e-02 -5.26838892e-04 -1.16312206e+01 -6.90764167e-02
  1.23127676e-01  9.71218689e-03  1.41107737e+01  9.09783927e-02
  6.65563004e-01  1.83615824e+00  2.67658286e+00  6.71992466e-01
 -9.88651356e-02 -4.59634695e-01 -1.70742981e-02 -1.02361299e-01
 -6.71018513e-01  2.22471235e+01 -2.06316541e+00  4.15557619e+00
  1.92133771e+00 -9.31336723e+00 -6.29377902e-01  1.74913161e+01
  1.74307862e+01]
supnorm grad right now is: 22.24712350861593
Weights right now are: 
[-3.50497961e+00  1.47189438e+00 -1.32980217e+01 -1.11212256e+01
  3.75954832e+00 -1.58058607e+00  1.36969587e+01  1.04051972e+01
 -2.51503312e+00 -4.33523225e+00  3.12836558e+00  4.90262545e+00
  6.77693073e+00  1.41902667e+01 -1.91223367e+01  1.29158990e+01
  2.37312315e+01 -1.16183497e+01 -1.79517598e-01  2.12857808e+00
  2.28170562e+01 -1.47398692e+01 -2.46419512e+00 -4.01850245e-02
  4.70523118e-01 -3.83734860e+01 -1.22319693e+02  3.74555106e+01
 -5.48224101e+00  2.24253045e+01  1.57714139e+01 -2.81582134e+01
 -1.63640075e+01  1.33305721e+01  2.17993669e+00  6.36906436e+00
 -4.61533795e+00  2.23761295e+01 -2.19903212e+00 -8.53180329e+01
 -6.99771852e+01 -1.69098404e+02  1.95261763e+00 -7.39557949e+01
  5.54465726e+01  4.53392306e+01  8.25117487e-01  5.94459802e+01
  4.55019816e+00  2.08799925e+00  3.98764900e-01  4.37381518e+00
  4.99576973e+01 -1.25320127e+01  8.14470252e+01  4.12855154e+01
 -5.77470691e-01 -2.65706126e+00 -1.19485955e+01 -6.86135722e+00
  1.57033672e+01  2.45795362e+00 -1.03954712e+00 -2.86740753e+00
  2.69884833e+01]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2723.5198322536817
gradient value of function right now is: [-1.55263619e-01 -1.70400149e+00  9.65781880e-08  5.63192817e-04
  1.55263619e-01  1.70400149e+00 -9.65781878e-08 -5.63192817e-04
 -5.56274522e-01  9.40301538e-01 -4.23573198e-01  9.40893033e-01
 -4.07638415e-01 -3.36860350e-02 -4.00680743e-01 -4.00565805e-01
  3.01341955e-06  2.46758197e-06  2.58481487e-06  2.58644404e-06
  1.39144612e-02  1.28460039e-02  1.31720967e-02  1.31677253e-02
  2.71351216e-02 -2.91274416e-11  1.17975873e-03  6.78933713e-04
  9.03339780e-01  4.63173303e-02  3.45559090e-01  4.11922651e-02
  8.33203574e-02  8.53036299e-02  2.17628562e-01 -1.30557138e-02
  3.15659603e-01  2.15974728e-01  5.74450877e-01  1.06727583e-03
  1.48333712e-02  1.68489621e-04  2.06805325e+00  1.73845709e-02
 -2.97232323e-02 -8.76526106e-04 -3.31296079e+00 -3.58778721e-02
 -1.20870917e-01 -1.65068508e-02 -7.92361756e-01 -1.49550065e-01
  1.72822152e-03 -1.36743442e-02  6.64449201e-03  3.30451323e-03
  8.19597968e-01 -5.85967094e+00  3.37960587e-02 -2.10993314e-01
 -5.83205149e-01  2.50205586e+00  1.16569830e+00 -7.48550687e+00
 -6.44166599e+00]
supnorm grad right now is: 7.48550687027594
Weights right now are: 
[-2.90485485e+00  1.20351580e+00 -1.31972275e+01 -1.10085328e+01
  3.15942356e+00 -1.31220749e+00  1.35961645e+01  1.02925044e+01
 -2.54935103e+00 -4.40276997e+00  3.00011023e+00  5.00135547e+00
  6.66439428e+00  1.24360988e+01 -1.89987379e+01  1.32288321e+01
  2.41935575e+01 -1.13706417e+01  7.87572690e-02  2.40151001e+00
  2.34061978e+01 -1.45820313e+01 -2.25459576e+00  1.82898491e-01
  3.14263052e+00 -3.83920248e+01 -1.24061617e+02  3.39566217e+01
 -4.86533523e+00  1.87829947e+01  1.52970599e+01 -3.22855003e+01
 -1.81050597e+01  1.04003046e+01  5.76094027e-01  8.76919439e+00
 -6.40039023e+00  2.22893947e+01 -2.44890511e+00 -8.55353184e+01
 -7.08644376e+01 -1.72928350e+02  2.19433574e+00 -7.45471339e+01
  5.82565678e+01  4.82795627e+01  4.63770286e-01  6.20843535e+01
  6.66577205e+00  3.59785448e+00 -7.13280604e-01  7.26285627e+00
  4.74834718e+01 -1.18525536e+01  8.27142931e+01  3.83487144e+01
 -6.16379851e-01 -2.76427332e+00 -1.19707322e+01 -7.13723620e+00
  1.56421344e+01  3.02614367e+00 -1.82680843e+00 -2.83842933e+00
  2.65560719e+01]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2724.472476220583
gradient value of function right now is: [ 2.53572470e-01 -5.81624428e-01 -1.97790232e-06 -7.45224458e-03
 -2.53572470e-01  5.81624428e-01  1.97790233e-06  7.45224458e-03
 -3.49265144e-01 -1.15397729e+00 -8.44783805e-01 -1.34158932e+00
  5.92264023e-01  3.45283160e-02  6.33079056e-01  6.50842746e-01
 -5.24482465e-05 -5.13596142e-05 -5.33665212e-05 -5.32175206e-05
 -1.56677227e-01 -1.53011958e-01 -1.58935232e-01 -1.58490618e-01
  4.32904019e-02 -3.05811803e-22  7.18418691e-04 -1.13824363e-03
 -7.09294433e-01 -2.99153750e-02 -3.02013646e-01 -2.51998835e-02
 -2.64879223e-01 -3.28297261e-01 -5.25812233e-01  5.25287290e-03
  1.05006827e-01  3.60452905e-02  5.59056001e-02  1.21782414e-04
 -1.72459831e-02 -1.64853203e-04 -2.40930323e+00 -1.48186517e-02
  1.91122712e-02  1.03256596e-03  2.11458776e+00  1.88132987e-02
  1.75841546e-01  8.48749794e-02  1.53330763e+00  1.71187283e-01
 -8.55334841e-03  2.04671600e-02 -3.67427745e-03 -1.08375401e-02
 -2.28634367e-01  3.52428042e+00  3.65238910e-02 -1.28237679e-03
  5.83872589e-01 -2.68503865e+00 -3.33090070e-01  3.35720195e+00
  3.66492781e+00]
supnorm grad right now is: 3.6649278057128276
Weights right now are: 
[  -2.76644093    1.20988463  -13.29168612  -11.31499406    3.02100964
   -1.31857632   13.69062311   10.59896567   -2.2152663    -5.05514537
    2.58988122    5.22283015    6.53641885   16.65021758  -19.23070751
   13.16568175   23.50824979  -12.03268574   -0.54779876    1.77780795
   22.7710523   -15.23671249   -2.87395297   -0.43514693    0.84270641
  -38.21658293 -128.31573324   33.31316933   -5.67729631   20.90584757
   14.52825633  -30.31059853  -17.14689427   11.63468219    0.58392422
    4.4318828    -5.6207939    21.85392353   -1.77789762  -87.04004901
  -71.40234259 -173.35699265    2.07342463  -75.41414183   59.71330632
   48.24102971    0.37240509   63.46818736    3.17602073    1.5665181
   -0.21230156    4.16906006   49.19866091  -11.28477182   83.33104513
   39.16159829   -0.65956419   -2.66731467  -11.41004103   -8.07650258
   15.82536007    2.803238     -1.49921201   -2.8264844    26.81796585]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2720.096504336096
gradient value of function right now is: [-1.75311016e+00 -4.47124061e+00  1.47951172e-06  4.14786170e-03
  1.75311016e+00  4.47124061e+00 -1.47951170e-06 -4.14786170e-03
 -6.12143966e+00 -1.03139781e-01 -5.38554265e+00 -5.58595076e-01
  8.75257371e-02  5.91382815e-03  7.14562078e-02  5.53496070e-02
  3.33610003e-05  4.00722083e-05  4.01142091e-05  4.00375385e-05
  6.76389708e-02  8.08626081e-02  8.09430937e-02  8.07850420e-02
 -1.75623809e-01 -3.26163527e-13 -3.93996967e-03 -2.87132413e-03
  8.09209137e-02  8.40400127e-02  8.67717690e-02  7.30719427e-02
  3.62759695e-01  4.13697612e-01  7.77894098e-01 -1.74706905e-02
  7.36415855e-01  4.69899092e-01  1.20054679e+00  1.85728390e-03
  4.07151212e-02  2.46110944e-04  5.25086107e+00  3.32629090e-02
 -8.73859731e-02 -1.17980658e-03 -8.17271668e+00 -7.40725123e-02
  8.71566908e-03 -4.37449591e-01  2.02493850e+00 -5.72632000e-02
  1.75067535e-02  3.97471766e-02  1.44288453e-02  2.31613952e-02
  2.19709517e+00 -1.50871309e+01  1.80361004e-01 -3.73085887e-01
 -1.67503620e+00  6.43713690e+00  2.27779269e+00 -1.34241124e+01
 -7.47072561e+00]
supnorm grad right now is: 15.087130900138861
Weights right now are: 
[-3.17711263e+00  1.17432318e+00 -1.33567915e+01 -1.05515747e+01
  3.43168135e+00 -1.28301487e+00  1.37557285e+01  9.83554628e+00
 -2.29766328e+00 -4.88336388e+00  2.41040774e+00  5.08570884e+00
  6.63949001e+00  1.45761259e+01 -1.91098370e+01  1.34791422e+01
  2.41255987e+01 -1.13720952e+01  1.38548270e-01  2.46858911e+00
  2.35714260e+01 -1.45072956e+01 -2.11812279e+00  3.27147103e-01
  8.57924217e-01 -3.87762330e+01 -1.28470496e+02  3.40746340e+01
 -6.02901411e+00  2.01434056e+01  1.45923121e+01 -3.07277954e+01
 -1.75898383e+01  1.05560313e+01  4.14685309e-01  1.01817281e+01
 -5.90599437e+00  2.21876181e+01 -2.01677293e+00 -8.73661957e+01
 -7.18971856e+01 -1.70065672e+02  2.34954871e+00 -7.58563733e+01
  6.14197036e+01  3.74720706e+01  5.04865952e-01  6.45430820e+01
  3.38415452e+00  1.95957291e+00 -2.55879875e-01  4.27604749e+00
  4.74970609e+01 -1.35976424e+01  8.54455189e+01  3.75783030e+01
 -6.10568547e-01 -2.57504002e+00 -1.21037953e+01 -7.93343741e+00
  1.55718501e+01  3.31609882e+00 -1.49902633e+00 -2.81429629e+00
  2.65802030e+01]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2721.4509166128764
gradient value of function right now is: [ 1.83181929e-02  2.40341162e+00 -5.70042162e-07 -3.91322100e-03
 -1.83181929e-02 -2.40341162e+00  5.70042163e-07  3.91322100e-03
 -7.28709281e-01 -3.07542857e+00 -1.27405730e+00 -2.79242601e+00
 -8.59508541e-02 -4.41899289e-03 -6.53004206e-02 -5.07639345e-02
 -1.38077619e-05 -1.51370723e-05 -1.53702279e-05 -1.52911642e-05
 -6.93974244e-02 -7.50682367e-02 -7.61294378e-02 -7.57598567e-02
  1.05599352e-01 -3.30766189e-08  2.94642430e-03  2.50037590e-03
 -7.35195704e-01 -2.02568488e-03 -1.74958476e-01 -2.46223119e-02
 -2.26151760e-01 -1.45261944e-01 -6.89867631e-01  2.32330506e-02
 -6.92428871e-01 -3.71221236e-01 -1.42890872e+00  3.04477755e-03
 -5.61354529e-02 -2.18604788e-04 -6.68592156e+00 -4.68005479e-02
  9.31307615e-02  3.06512660e-03  1.03095059e+01  7.89759470e-02
  1.73278012e-01  2.43219466e-01 -9.14011031e-01  2.21335729e-01
 -2.20839849e-02 -4.70438055e-02 -1.89189437e-03 -3.17312106e-02
 -1.14850504e+00  1.77419512e+01 -6.67228621e-01  1.52127128e+00
  3.42304304e-01 -1.63894109e+00 -1.12022247e+00  1.57947699e+01
  9.91416063e+00]
supnorm grad right now is: 17.74195121594856
Weights right now are: 
[  -3.29409578    1.34120021  -13.28113088  -10.55266895    3.54866449
   -1.4498919    13.68006779    9.83664056   -2.19609433   -4.87637109
    2.55018801    5.47646052    6.43644939   13.00236254  -19.43129074
   13.21774493   24.17914237  -11.24040017    0.25740791    2.59230148
   23.52724979  -14.66330902   -2.27493794    0.17810134    1.39863661
  -39.70826498 -128.65908541   35.23412548   -5.92343101   21.47452307
   16.83001602  -28.47885513  -15.36591228   12.72949288    1.2496015
   11.67394961   -4.78642      21.63714049   -1.44343368  -91.69346665
  -72.09047347 -167.43853378    1.92249159  -76.18236134   62.28317042
   32.54092753    0.44163799   64.97302558    5.93635654    3.25027081
   -0.66194933    6.88810841   47.19288451  -14.32060248   85.16010875
   37.34023715   -0.29965694   -2.51256561  -13.21265908   -7.53060037
   16.33307443    2.90549871   -1.30945575   -2.68391544 92.0% of gradient des90.0% of gradient descent iterationsobjective value function right now is: -2724.197606225007
gradient value of function right now is: [ 3.34408073e-01 -2.86848162e-04 -2.13342172e-02 -1.50866118e-03
 -3.34408073e-01  2.86848162e-04  2.13342172e-02  1.50866118e-03
  3.29299412e-01  1.05685917e-02 -3.55738568e-02  3.87311605e-01
 -1.79092033e-05 -2.73144273e-04  4.61240207e-06 -2.90889674e-03
  7.27575294e-01  3.85250400e-05  2.60836508e-02 -1.33497554e-02
 -2.45747276e-02  6.34729280e-04 -1.29234717e-02  2.65052570e-04
 -1.27384950e-04 -2.66659058e-04 -1.22220876e-04 -3.63843879e-02
  2.56912859e-02  1.33483916e-04  1.23417013e-02  7.31143935e-02
 -8.33821429e-01  6.49149427e-03  3.70930379e-03 -5.54831449e-02
  1.56804418e-01  1.75869167e-03  5.48324055e-03  2.30205311e-01
 -4.62949388e-03 -5.80401933e-02 -6.36588884e-01 -6.93416795e-03
  2.73265573e-03  2.73987146e-01  2.79143720e-01  3.90860193e-03
  6.61992679e-03  9.49368292e-03  6.58845811e-01  9.54221498e-03
  6.23598290e-03  1.20947478e+00  2.03031646e+00  8.42256749e-03
  4.78941264e-01 -1.70913892e+00 -1.13772489e+00  4.18833234e+00
 -9.62675306e-02  1.48174555e-01  5.85886437e-01 -2.17065052e+00
 -3.17852300e+00]
supnorm grad right now is: 4.18833233641669
Weights right now are: 
[-1.11448754e+00 -1.05833378e+01  1.87529499e+01 -1.00986662e+01
  3.80188820e-01  1.05400899e+01 -1.82586330e+01  8.56277782e+00
  6.71380538e+00 -7.83976273e+00 -1.56817623e+01 -6.70698479e+00
  1.62281382e+01  5.81619544e+00  2.25778459e+00  6.49674030e+00
  2.29459073e+00  1.02236994e+02  1.63783903e+01  9.00929696e+00
  2.02326618e+01 -8.24780321e+00 -3.40937464e+01  1.57637359e+01
 -6.06745863e+01  4.60151652e+01  2.94619373e+01  1.98926253e-01
  6.66800292e+00 -1.11756289e+01 -2.63911945e+01  6.34574960e+00
 -1.90922075e+00 -6.16566213e+01 -2.95325247e+01  3.35037162e+01
  4.94710809e+00  1.32195778e+01 -6.42380066e+01 -3.12571829e+00
  3.10234837e+01 -3.04879688e+00 -1.06678676e+00  2.00850114e+01
 -1.29865972e+01 -2.65596018e+01  3.04506343e+01 -8.97517052e+00
  1.08879334e+01  8.09685618e+01  2.45948097e+00 -3.48695973e+00
 -1.23381981e+02  2.12828755e+00  2.14948394e+00 -1.13082105e+02
  5.68081546e-01 -2.52826404e+00  1.186892.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2724.21420770528294.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2724.066819706939
gradient value of function right now is: [ 2.12856692e-01 -1.89423189e-04 -1.99212534e-02 -2.39821584e-03
 -2.12856692e-01  1.89423189e-04  1.99212534e-02  2.39821584e-03
  2.73473989e-01  6.17822486e-03 -4.62073702e-02  3.39855707e-01
  1.22543182e-05 -2.92183429e-04 -2.43085051e-07 -1.78125596e-03
  6.81701358e-01  3.41071345e-04  2.49291271e-02 -1.68667595e-02
 -3.71572907e-02 -2.03822127e-04 -2.00288081e-02 -6.58858482e-04
  7.68992061e-05 -9.37470049e-05  2.17538790e-05  6.61162640e-02
 -1.51441720e-02 -1.61342364e-04  6.94455070e-03  2.69258631e-02
 -1.01987334e+00  1.19362525e-03  3.44408746e-03 -7.52886697e-02
  1.79753035e-01  1.60555954e-03  5.34206316e-03  2.49524090e-01
 -4.26502536e-03 -7.19643094e-02 -5.38856445e-01 -5.83627674e-03
 -4.72819141e-03  1.18573657e-01  1.14041176e-01 -6.00827861e-03
  2.77637731e-03  7.89630071e-03  5.10552176e-01  3.84177286e-03
  1.03242369e-02  1.64263410e+00  2.53792438e+00  1.24686685e-02
  4.90941806e-01 -2.61128623e+00 -1.04521064e+00  4.23809662e+00
  2.46341052e-03  4.15478764e-02  5.46628310e-01 -2.91411269e+00
 -3.25099527e+00]
supnorm grad right now is: 4.238096624606458
Weights right now are: 
[  -1.05428851   -9.61649759   19.03240738   -8.74791713    0.31998979
    9.5732497   -18.53809043    7.21202877    6.29100248  -10.66280027
  -16.99123806   -6.61288797   17.81295088   10.03953787   -1.84436289
    4.82964032    2.20959593  100.70886918   15.79729178    9.85246518
   21.50597452   -6.68378518  -33.0055287    17.76555369  -57.86875605
   47.09667353   31.25894002    1.07650881    6.76789989  -10.66399914
  -28.76450302    5.32280375   -1.96070187  -61.46593709  -28.82710114
   34.81820819    4.78887382   17.70615965  -64.79544703   -2.49252076
   32.06798032   -3.26996494   -0.77788251   21.04457946  -13.2596632
  -26.92718504   30.75950606   -8.99983376   12.72761665   83.02011421
    0.90698545   -1.33900869 -125.06514911    2.14052935    2.25863291
 -114.86626799   -0.26908412   -2.48240748   12.02993451    2.23617246
   16.04158219    8.09507136   -0.27837478   -2.51519015   26.60863864]
(65,)
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2724.1764802689763
gradient value of function right now is: [ 9.76491437e-02 -3.14843875e-04 -1.81724085e-02 -2.15265458e-03
 -9.76491437e-02  3.14843875e-04  1.81724085e-02  2.15265458e-03
  1.80434923e-01  5.98468835e-03 -4.57311917e-02  2.41496733e-01
 -1.35629465e-05 -4.55520914e-04  1.60868091e-07 -3.21934863e-03
  6.24137410e-01  3.07658371e-04  2.18640587e-02 -1.47806030e-02
 -3.40959680e-02  8.65484978e-04 -1.82280411e-02  3.96889205e-04
  5.19517737e-04 -2.98211133e-05 -9.98312572e-05  9.54807758e-02
 -1.08421704e-02  2.84062058e-04  7.72595141e-03  3.17314696e-02
 -9.48550268e-01  5.17782344e-03  3.32503118e-03 -6.02925886e-02
  1.56321037e-01  1.36206137e-03  3.68631585e-03  2.19256217e-01
 -1.74760157e-03 -6.37055432e-02 -4.72159884e-01 -2.80590444e-03
  4.49693995e-03  1.51929809e-01  1.55706962e-01  5.76890958e-03
  6.19671358e-03  6.59450451e-03  4.13917445e-01  7.95079595e-03
  8.17648606e-03  1.36884786e+00  2.30816446e+00  9.69040359e-03
  4.81252338e-01 -2.17437823e+00 -9.09768182e-01  3.71015870e+00
 -1.22866925e-01  1.95738062e-01  5.42155435e-01 -2.41141813e+00
 -2.86678896e+00]
supnorm grad right now is: 3.710158698325229
Weights right now are: 
[  -1.25523345   -8.17218016   19.09436382   -8.75453407    0.52093472
    8.12893227  -18.60004687    7.21864571    6.69558193  -10.81783636
  -15.00909853   -6.36121671   11.44505369   10.38615613   -0.68115546
    3.42654277    2.36687167   99.82414065   17.38540227    9.62982971
   21.30779147   -3.96798575  -33.51124133   19.8631773   -64.69732509
   58.86647755   33.76613214   -1.57605538    7.41984313   -8.01643843
  -32.14618058    4.07218669   -1.63834449  -60.08765763  -27.8811178
   36.33009262    4.66621228   16.33620071  -66.18542284   -3.01167251
   29.46869852   -4.63026927   -0.64346446   18.52291858   -9.9053085
  -27.90448841   30.93730523   -6.36408584   11.65200467   83.25595678
    1.33833231   -2.81378913 -127.34875715    2.03468008    2.12810479
 -116.94139893    0.79146315   -2.60655453   11.95708143    2.55506014
   15.11876273    8.78145369   -0.28819573   -2.59268671   26.87513432]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2724.166918933955
gradient value of function right now is: [ 1.34665108e-01 -3.27871916e-04 -1.81134979e-02 -2.26470628e-03
 -1.34665108e-01  3.27871916e-04  1.81134979e-02  2.26470628e-03
  1.32405049e-01  3.49017008e-03 -3.61460292e-02  1.80050441e-01
  7.24086297e-05 -4.98085566e-04 -3.58596910e-07 -1.90662598e-03
  6.26184353e-01  3.29654398e-04  2.25083390e-02 -1.52058719e-02
 -3.44052981e-02 -1.23479779e-04 -1.86201324e-02 -5.05818549e-04
  4.46894034e-04 -1.42035949e-04  1.19481068e-04  6.60291795e-02
 -2.30763496e-02  1.52255157e-04  3.98578136e-03  1.76725548e-02
 -8.75902804e-01  3.03174599e-03  1.65447900e-03 -6.00672205e-02
  1.53253321e-01  2.48365586e-03  3.40914880e-03  2.09593271e-01
 -1.86233972e-03 -6.00789804e-02 -4.11313614e-01 -2.73752522e-03
  3.19522027e-04  1.29882137e-01  1.29569135e-01  6.94378996e-04
  4.13869745e-03  5.76693581e-03  3.25930694e-01  5.41212382e-03
  8.43916000e-03  1.31016188e+00  2.17532505e+00  9.97074416e-03
  4.60259311e-01 -2.19686322e+00 -8.13324908e-01  3.37925422e+00
 -1.93563863e-02  4.73420449e-02  5.09402947e-01 -2.40487327e+00
 -2.77928343e+00]
supnorm grad right now is: 3.379254215621483
Weights right now are: 
[  -1.33762705   -4.98903057   19.07959513   -9.59017066    0.60332833
    4.94578268  -18.58527818    8.0542823     6.32263823   -8.08579848
  -15.04224821   -6.79151412   10.70837677   14.27504631    0.5503604
    5.61664701    2.60737609  102.34261948   16.76514668    9.66863871
   20.80721972   -7.10229674  -34.36863042   18.06985101  -63.85335662
   67.75680504   32.12081161   -0.42415512    6.35041829  -13.86733149
  -28.6739151     4.48558949   -1.6748297   -60.37361166  -30.55623853
   36.15792079    4.45320948   18.8216149   -65.47646021   -3.21262615
   31.17661087   -3.80288009   -0.61548838   19.94745807  -12.20590266
  -27.85651344   31.04877481   -8.01542811   16.11896186   85.74034768
    1.83318552    1.06267008 -128.99947534    2.01954685    2.24413459
 -118.70136591    0.75233458   -2.5203747    12.0860947     2.5966446
   16.13429666    7.3366622     0.50752219   -2.58472943   26.74587505]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2724.1017979660796
gradient value of function right now is: [ 1.44641726e-01 -2.07088581e-04 -1.63429958e-02 -2.65140589e-03
 -1.44641726e-01  2.07088581e-04  1.63429958e-02  2.65140589e-03
  1.13760749e-01  2.90557268e-03 -3.71195151e-02  1.69713165e-01
  6.29399277e-05 -3.31371436e-04 -5.88490252e-07  1.59270389e-04
  5.65315508e-01  2.77356136e-04  2.09946295e-02 -1.93356847e-02
 -3.79783223e-02 -3.02353736e-03 -2.11931612e-02 -3.43128099e-03
  1.77723573e-04 -1.15078757e-04  3.98633232e-05  4.89019505e-02
 -2.32667754e-02  3.51092634e-05  2.87721874e-03  1.50560330e-02
 -8.93738987e-01 -4.84594761e-03 -2.98078546e-03 -7.72917566e-02
  1.77387608e-01  2.36944985e-03  3.29674035e-03  2.17794914e-01
 -3.21455205e-03 -6.77885079e-02 -4.16895607e-01 -4.22545935e-03
 -1.31916760e-02  1.10965413e-01  9.71820170e-02 -1.77509286e-02
 -2.07826339e-03  5.32833686e-03  2.98653848e-01 -2.89359579e-03
  8.42641800e-03  1.33716566e+00  2.18263963e+00  9.99462314e-03
  3.92813130e-01 -2.13311800e+00 -8.03682787e-01  3.39624271e+00
  2.64887985e-01 -3.59758588e-01  3.96754801e-01 -2.27917600e+00
 -2.76967591e+00]
supnorm grad right now is: 3.3962427080575357
Weights right now are: 
[  -1.11548251   -5.56391382   19.45250992  -10.16111925    0.38118379
    5.52066592  -18.95819296    8.62523089    6.55568455   -5.50553574
  -15.20509085   -6.84937771   13.72202299   15.42073255    0.63705349
    6.50011061    2.32997356  103.63831929   16.53697193    9.86250276
   20.72922569  -10.25393027  -34.90024302   15.04154072  -66.02018511
   65.07829209   32.55224723   -1.9326259     6.76507937  -12.76328564
  -25.19345373    6.34451695   -1.84549473  -64.53598533  -34.84739314
   34.35389841    4.8087642    18.06548466  -66.74169303   -2.98292866
   30.05838598   -3.49732435   -0.73600786   18.25478567  -13.10911429
  -27.94806708   31.47107638   -9.09744437   14.31377407   86.18244853
    2.42397485   -0.59784    -130.81163505    2.057678      2.08275117
 -120.53230168    0.47560466   -2.58458837   12.48113177    2.60090967
   17.18851375    6.90285745   -0.42539062   -2.50034257   26.48686105]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1507.1515658915732
W_T_median: 1345.6325388152100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2724.798014701014
gradient value of function right now is: [-3.38911353e-01 -1.42645671e+00 -1.46505292e-07 -6.55140924e-05
  3.38911353e-01  1.42645671e+00  1.46505302e-07  6.55140924e-05
 -9.45891054e-01  6.72643915e-01 -6.18208373e-01  6.87591548e-01
 -1.44520755e-01 -3.97622124e-03 -1.62407098e-01 -1.59169169e-01
 -9.84414731e-07 -4.10435876e-06 -3.97159671e-06 -3.83215918e-06
  7.26338376e-03  3.36632863e-03  3.45689801e-03  3.60579405e-03
  7.80302898e-02 -8.98739730e-12  7.69568009e-04 -1.69109267e-03
  4.66066179e-01  2.69978019e-02  1.77807911e-01  2.97606739e-02
  3.22570418e-01  2.92243971e-01  4.05358774e-01  9.78797999e-03
  3.50476858e-01  1.34371045e-01  3.59955117e-01  2.59442022e-03
  1.96010590e-02  1.04820837e-04  1.74161809e+00  1.35409589e-02
 -3.59389477e-02 -5.71507583e-04 -2.58166025e+00 -2.57499046e-02
 -4.43986731e-02  3.16373106e-02 -2.20175704e-02 -4.99268879e-02
  2.84311420e-03  2.99164894e-04  4.99657830e-03  4.47292511e-03
  7.70689154e-01 -6.89010858e+00  1.86780524e-01 -4.46712405e-01
 -5.52191262e-01  2.72337638e+00  7.54818130e-01 -5.43957202e+00
 -4.07236305e+00]
supnorm grad right now is: 6.890108583648812
Weights right now are: 
[-2.75104857e+00  1.13563529e+00 -1.35618065e+01 -1.02878593e+01
  3.00561728e+00 -1.24432698e+00  1.39607432e+01  9.57183089e+00
 -2.70556340e+00 -3.15944048e+00  3.29790978e+00  4.39802673e+00
  6.54388341e+00  1.42072306e+01 -1.90978153e+01  1.31524978e+01
  2.32248573e+01 -1.24737353e+01 -7.20779360e-01  1.63508801e+00
  2.31965593e+01 -1.57372036e+01 -2.86854400e+00 -4.10486516e-01
  2.29630441e+00 -4.03065203e+01 -1.38394948e+02  3.84515927e+01
 -5.14020134e+00  2.88477828e+01  1.48010546e+01 -3.11544463e+01
 -1.36915560e+01  1.53378881e+01  2.16766623e+00 -5.12329085e+00
 -4.63676609e+00  2.39505325e+01 -2.97793885e+00 -1.08216181e+02
 -7.42241836e+01 -1.88278733e+02  1.33803646e+00 -8.21345449e+01
  6.26719009e+01  3.62146379e+01 -5.94632897e-03  6.34154412e+01
  2.04258169e+00  3.88275236e+00 -9.26307039e-03  5.64972462e+00
  6.76606986e+01 -1.14096258e+01  9.27804306e+01  4.30779052e+01
  8.14147877e-02 -2.51064983e+00 -1.46508452e+01 -7.85395448e+00
  1.78285924e+01  2.45595816e+00 -1.57503541e+00 -3.32294854e+00
  2.72024926e+01]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1508.848780128101
W_T_median: 1349.7022811863073
W_T_pctile_5: 716.1860016453643
W_T_CVAR_5_pct: 612.5221599061243
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.4
F value: -2724.798014701014
-----------------------------------------------
