Starting at: 
2022-06-17 22:26:16
tracing parameter entered from terminal:  0.9


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1945.6397869842724
gradient value of function right now is: [ 3.76001859e-02  1.35928017e-02  2.03069597e-02  6.35305965e-02
 -3.76001859e-02 -1.35928017e-02 -2.03069597e-02 -6.35305965e-02
  2.28370450e-02  1.15255832e-01  2.88581190e-04  4.13882893e-02
  1.56970608e-02  3.79813432e-02  1.96234734e-04  3.11852542e-03
  9.67995162e-03  3.89859988e-02  1.21643795e-04  1.22988910e-02
  2.75523510e-02  2.12825719e-01  3.51075431e-04  9.25163561e-02
  1.21821260e-01  1.06194592e-02  1.49841676e-02 -2.31359848e-04
 -2.83936924e-01 -3.12209539e-02 -4.14254023e-02 -6.39440542e-04
  4.90342376e-04  3.45045988e-05  5.78456412e-05  2.75022917e-06
 -4.33880389e-01 -8.34592362e-01 -8.89399188e-01 -5.32403650e-01
  5.80314144e-02  6.77740252e-01  2.12131795e-01  7.61925724e-02
 -6.83469944e-02 -3.71374740e-02 -1.29246030e-01 -6.61426060e-02
 -1.32114237e-01 -5.92400816e-02 -2.10463871e-01 -1.27415605e-01
 -1.30115975e-02 -1.35711020e-01 -4.64842965e-02 -1.65995547e-02
  1.09536524e-01 -1.06616838e-01 -8.61641631e-01  1.06626498e+00
  4.00599160e-01 -5.50306185e-01  1.09184612e-01 -1.63863471e-01
 -3.50289982e+00]
supnorm grad right now is: 3.5028998243843037
Weights right now are: 
[-3.26698047 -3.80632543 -1.57726699 -3.40087161  2.53268175  3.76307769
  2.07158394  1.86498329 -1.65040652  2.48883314 -0.60660638  9.27557667
 -3.5368501   5.48076669 -0.80173013  8.81871901  0.26336249  3.26170199
  0.1733867   9.23213791 -1.90252362  1.51887531 -0.43827296  9.47302827
  0.97136805  3.83851489  4.63334236  4.17180087  0.99073137 -5.55938559
 -6.7933192  -2.35062384  5.70043628  2.97934916  3.22304263  3.10381209
  7.6579522  -0.55143769 -1.17086418 -1.50911988 -4.18685668  2.87389221
 -3.21351549 -3.81443835  2.37281715 -4.74407566  0.63257022  1.25114884
  1.17625067 -6.22653705  1.29838994  0.65972075  3.08687958 -1.97934847
  4.27225143  3.84721758  4.51098682 -2.57818878  4.91020978  2.69547449
  0.59725099 -2.35063948  4.2820371  -2.20165185 27.11847293]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.058597231492
gradient value of function right now is: [ 2.20107542e-01  6.24733902e-03  4.88319835e-02  6.23593370e-01
 -2.20107542e-01 -6.24733902e-03 -4.88319835e-02 -6.23593370e-01
  8.52258279e-03  1.02346813e+00  4.11527586e-04  2.33934615e-02
  3.26130317e-03  3.82513423e-02  2.29889462e-04  2.42320252e-04
  1.43057176e-03  1.00488476e-01  7.33320305e-05  1.72064565e-03
  1.56683120e-02  2.93729731e+00  7.13003925e-04  8.75030811e-02
  5.29267941e-02  9.57227725e-03  5.23257355e-03  5.56374862e-05
 -9.96657732e-01 -3.49493249e-01 -2.55517718e-01 -1.58849833e-02
  2.00787967e-03  1.77718326e-04  9.79799751e-05  1.36649958e-08
 -4.83683885e-01 -6.32879296e-01 -8.76781945e-01 -3.74458588e-01
  5.13467006e-02  5.85471216e-01  1.97085783e-01  5.22632022e-02
 -7.87644607e-02 -3.31142468e-02 -5.94544443e-01 -7.73362588e-02
 -8.48138725e-02 -6.21455062e-02 -5.14576527e-01 -8.38266145e-02
 -4.05777670e-03 -5.72971548e-02 -1.40516121e-02 -4.13712012e-03
  2.76832088e-01  1.13654745e-02 -6.71356133e-01  8.28719508e-01
  5.07115464e-01 -1.91053577e-01  2.14031306e-01 -2.20510181e-02
 -6.08582698e+00]
supnorm grad right now is: 6.085826982302467
Weights right now are: 
[ -3.26151907  -5.59200758  -1.02976466  -3.89979376   2.52722035
   5.54875985   1.52408162   2.36390544   0.0597826    3.14963407
   0.49779412  11.1685761  -11.10088722   8.54329997  -9.8051568
  10.58063609   2.93289155   5.00859742   1.78312095  11.08733772
  -1.77631878   1.81943269  -0.20879828  11.04246758   0.92056948
   7.77676936   7.93680464   4.18354014   0.9776552   -3.5902711
  -4.5838778   -0.65418536   3.31158324  10.55342426   9.39871658
   5.03580528   8.2441329   -0.16863081  -0.97080285  -1.1185574
  -5.62429164   2.72115003  -2.44639142  -4.70728114   3.28983437
  -1.5649941    0.38825781   2.3657234    1.4777044   -7.38590968
   1.91522382   1.09358272  11.77047053  -1.27831806   8.80164499
  11.61723884   5.48130891  -2.15303156   5.58315702   2.92110021
   0.44665223  -3.7759627    5.48347938  -2.12023133  27.02942758]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1945.9230077442144
gradient value of function right now is: [-1.40172431e-01 -4.40274210e-03 -8.50656994e-03 -4.51837389e-01
  1.40172431e-01  4.40274210e-03  8.50656994e-03  4.51837389e-01
 -3.51871574e-03 -2.66895614e-01 -4.16994389e-03  2.09042762e-03
 -1.56906308e-03 -1.67202751e-02 -2.12803113e-03 -4.20115620e-06
  1.86805196e-04  6.58680023e-03  2.24681495e-04 -1.03033552e-06
 -1.06446451e-02 -1.44273448e+00 -1.23804213e-02  3.89678327e-02
 -3.42236491e-02 -2.03142750e-03 -1.99046530e-03 -2.06264322e-08
  1.16656907e+00  2.61521344e-01  2.38462065e-01  3.67838865e-03
 -5.28425482e-02 -2.71650801e-03 -2.87236054e-03 -2.35440949e-09
 -8.72035847e-02 -1.93781992e-01 -3.53294501e-01 -1.70320131e-01
 -1.35892447e-03  2.65807999e-01 -8.27634888e-02  1.18023206e-03
  8.27841496e-02  4.62071774e-02  3.97849413e-01  7.32022194e-02
  1.15806711e-01  4.54879752e-02  4.05213356e-01  1.06664520e-01
 -2.52485306e-03 -8.81124293e-02 -3.27677018e-03 -2.86065821e-03
 -1.78473412e-01 -2.45473612e-01 -2.46694723e-01  4.57502904e-01
 -1.85828557e-01 -1.27465499e-01 -1.20039731e-01 -1.95359729e-01
  4.96625759e+00]
supnorm grad right now is: 4.966257589984856
Weights right now are: 
[ -2.21948098  -4.88325787   1.10580961  -4.16810112   1.48518226
   4.84001013  -0.61149266   2.6322128    1.78478914   4.11216557
   0.44992608  11.61624007 -12.22232081  13.82596183 -14.39300659
  12.29826721   8.08548264   9.59750151   7.02753575  12.05027714
  -2.03986348   1.82062476  -2.08372192  11.59033555   1.84892228
  13.99377343  16.04533169   3.92290026   0.90979424  -2.71173006
  -3.34558634  -2.79991757   1.22717988  18.58555878  18.28396519
   4.92696488   9.44191334   0.57929048   0.04401067  -3.40175099
  -5.34300106   3.16437164  -1.29650787  -4.26981152   3.35065038
  -0.31269909   0.89602527   2.4785027    1.88397949  -6.13742384
   2.02297112   1.71293924  26.91249379  -2.23395216  13.76183994
  26.10785096   5.57035361  -3.30852224   5.8873747    3.52731771
   0.7281709   -4.23719612   5.66547289  -3.06618539  27.44964799]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.6138040119615
gradient value of function right now is: [ 4.72585406e-03 -9.93384026e-04  1.28592774e-03  4.06321190e-01
 -4.72585406e-03  9.93384026e-04 -1.28592774e-03 -4.06321190e-01
 -6.19416075e-06  1.11184895e-03 -2.22437736e-05 -4.81249739e-07
 -3.03965010e-04 -1.81860972e-03 -8.83453130e-04  3.53992947e-08
  3.34920101e-05 -3.42134714e-03  1.21554831e-04 -7.20553322e-07
 -3.88364954e-04  1.58828942e+00 -1.60056279e-03 -2.73789115e-02
 -5.18168624e-03 -1.92803151e-05 -3.22453127e-04  2.68084523e-09
 -6.48104431e-01 -3.39382710e-01 -4.12688864e-01 -7.75285893e-03
 -1.93476419e-02 -2.85220287e-04 -1.28759124e-03  7.63808787e-10
  3.37357250e-02  1.10545953e-01  2.37571725e-01  1.01808332e-01
 -3.47671813e-04 -2.15782746e-01  1.30409236e-01 -8.14622311e-04
 -9.44595146e-03 -6.27706547e-02 -1.83136509e-01 -9.41912862e-03
 -6.94722244e-03 -4.30969197e-02 -2.17762235e-01 -7.05875442e-03
  4.23850548e-03  1.32781022e-01  4.36608706e-03  4.38703483e-03
  2.14343559e-02  1.37641449e-01  4.80525581e-02 -1.93153647e-01
  3.85562594e-01  7.87961168e-02  1.37850320e-02  1.34821630e-01
 -1.70255683e+00]
supnorm grad right now is: 1.702556826874641
Weights right now are: 
[ -0.55617211  -4.87536177   2.80772515  -4.29220466  -0.17812661
   4.83211403  -2.31340819   2.75631634   6.44301751   9.31660323
   4.33140178  11.58583595 -13.38364511  17.40924668 -16.88376822
  14.30066574   8.19895043  11.75925951   7.92201312  12.07641323
  -2.38906301   2.13484467  -3.30133093  10.91182628   1.54241566
  18.80413271  21.88259497   3.92054368   1.41614426  -2.21715456
  -3.01033587  -3.34697332   0.15602903  23.46958844  23.97919634
   4.92853534  11.14635029   1.17119467   1.95044307  -4.60458947
  -8.49668604   3.09018687  -0.35961938  -7.2718669    3.54570841
  -0.19534183   1.4716737    2.72359011   1.67268918  -7.36560536
   2.12634391   1.46240393  32.78698851  -2.74474057  17.07520133
  31.35624455   6.02534415  -3.13248112   6.23749613   3.31393642
   0.52949911  -3.68480288   6.08936887  -3.0764648   27.17406791]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.5253676960517
gradient value of function right now is: [-5.93519381e-04  2.51278514e-03 -2.87361916e-03 -6.65486530e-01
  5.93519381e-04 -2.51278514e-03  2.87361916e-03  6.65486530e-01
  2.09599070e-06  7.96022149e-05  9.18291218e-06  4.56433771e-08
  6.73080618e-04  3.00448430e-04  2.85082817e-03 -1.22523099e-07
  1.02458076e-04  6.61431949e-03  4.15085599e-04  7.32566102e-06
 -4.83345004e-03 -2.75837906e+00 -1.92195895e-02 -6.53636522e-02
 -9.97217780e-03 -6.08269074e-04 -1.46177979e-03 -1.13197211e-09
  5.00382017e-01  1.79667052e-01  2.89527550e-01  4.00203243e-02
 -6.56616025e-02 -2.39299477e-03 -7.12619555e-03 -1.23102525e-09
  1.99098558e-01  2.33679841e-01  4.86150456e-01  2.97545202e-01
 -1.05340028e-02 -2.49388843e-01 -1.26638880e-01 -1.03703868e-02
  1.21947396e-02  1.17426613e-03  1.42719565e-01  1.18595933e-02
  4.49995414e-02 -1.84110138e-02  3.22505158e-01  4.38150968e-02
  3.42835266e-04  1.10880025e-01  1.31072708e-02  3.28948616e-04
 -1.20613922e-01 -4.69048459e-02  6.82671050e-01 -1.03795182e+00
 -3.21791408e-01  1.24485976e-01 -1.03128944e-01 -3.95940544e-02
  3.66958233e+00]
supnorm grad right now is: 3.6695823334902977
Weights right now are: 
[ -0.18947072  -3.46612719   3.04884623  -4.22383674  -0.544828
   3.42287945  -2.55452927   2.68794842   9.26459187  16.88322887
   6.89331345  12.12198005 -10.53036956  21.14172654 -14.59791794
  15.31281977  10.45757832  12.51837063  10.37521188  12.39709937
  -3.70092451   1.91600135  -5.2211844   11.17251883   2.31149776
  20.98489403  24.66083018   3.92120328   1.03446162  -1.81143504
  -2.36539154  -3.40221365   0.4685297   24.96011807  26.30609249
   4.92912574  11.13148629   0.49047033   2.14600036  -5.07570912
  -8.8130137    5.26330821  -0.10177749  -7.53423599   5.10889428
   2.676957     2.4424926    4.39327023   1.51430672  -7.77996093
   2.36177308   1.33848056  37.43001714  -2.08019886  18.22995308
  35.76505926   6.45977459  -3.6328684    6.45202619   2.52877717
   0.47908484  -4.42424883   6.50473764  -3.62881441  27.25486713]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.782269538459
gradient value of function right now is: [ 1.73399850e-03  1.96989761e-03  6.59060891e-03 -1.82117721e-01
 -1.73399850e-03 -1.96989761e-03 -6.59060891e-03  1.82117721e-01
 -1.06996823e-05 -6.40818408e-04 -3.74792591e-05 -1.74723284e-08
  1.19136846e-04  3.45589245e-03  4.34928951e-04  1.18973749e-07
 -1.01857183e-04 -6.27231179e-03 -3.51769607e-04  1.28016117e-06
  7.45820886e-04 -7.14612936e-01  2.55787399e-03 -8.16145155e-03
  4.95896782e-03  1.06676200e-04  4.56410763e-04 -4.88633953e-12
  1.99622119e-01  1.51845937e-01  2.13891766e-01  7.55287324e-03
  2.30396714e-02  4.81322163e-04  2.07965793e-03 -4.56158966e-12
 -8.46427337e-03 -1.86263261e-02  6.50124774e-02 -2.97845865e-02
  3.52238066e-03  4.05765499e-02 -9.11454598e-02  3.53246965e-03
 -3.40981254e-03  3.67935944e-03  1.14716739e-02 -3.24326976e-03
 -1.12808434e-02  1.68605844e-02  3.52052585e-02 -1.03968407e-02
  2.63183881e-03  6.85560629e-02  1.00205394e-02  2.67048554e-03
  1.50112887e-02  1.25319049e-01 -9.72292928e-02  2.31998249e-01
 -1.33338113e-01  1.18454884e-01  1.25155044e-02  1.18383673e-01
 -1.20173315e-01]
supnorm grad right now is: 0.7146129360335783
Weights right now are: 
[  0.54731496  -4.62736146   2.8461802   -3.9758536   -1.28161368
   4.58411372  -2.35186325   2.43996528   9.32498571  21.07215797
   6.99398954  12.04514614 -13.37895738  23.28578501 -17.13948199
  15.72746834   8.6671995   14.20710234   8.91661856  11.39608426
  -3.36490355   2.00671429  -5.25663909  11.43267435   2.05398866
  25.36890261  29.28606617   3.92132747   1.70088103  -0.79879776
  -2.41298344  -5.18953805   0.57215813  28.65898774  30.33493726
   4.92926964  11.97670262   0.71664394   2.78198185  -5.28622525
 -11.31061491   6.58339924   0.42413369 -10.06771496   3.74828478
   3.52914734   2.50378114   3.07550678   2.05115913  -8.09473406
   1.40619047   1.92214928  40.67319732  -1.79057378  20.64059407
  38.91387571   6.70582072  -3.4834945    5.75553015   3.22961742
   0.07825817  -3.26243281   6.76931066  -3.45845088  27.17921659]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -1945.2553148101836
gradient value of function right now is: [-4.11241354e-05 -1.83028186e-03  6.69394388e-05 -8.25806546e-01
  4.11241354e-05  1.83028186e-03 -6.69394388e-05  8.25806546e-01
  5.70162412e-06  1.22948380e-05  2.85256433e-05 -1.39332333e-09
 -3.56227088e-04 -2.46482589e-03 -1.71500514e-03 -1.79538427e-08
  4.20406242e-05 -2.68633629e-04  2.11539050e-04  4.18394011e-08
 -8.51438645e-04 -3.94183784e+00 -4.26060974e-03 -1.02687202e-01
 -7.94071091e-03 -4.51022563e-05 -3.52483935e-04 -8.73743021e-14
  2.22120269e-01  1.81734610e-01  3.70836720e-01  2.37589481e-02
 -4.89034928e-02 -2.56756456e-04 -2.25272406e-03 -1.30667082e-13
  1.11235613e-01  6.95509185e-02  1.08033540e+00  3.22627103e-01
 -4.46086816e-03 -4.41752900e-01 -9.71806089e-02 -4.19560922e-03
  4.25918695e-03 -1.64634670e-02  2.22449705e-02  4.26949397e-03
  3.65513073e-02  3.05359188e-03  1.12890238e-01  3.66646420e-02
  5.17751817e-03  5.38541049e-01  6.39881165e-02  4.87465910e-03
 -5.41524120e-02  1.98339347e-01  9.09767647e-01 -1.45633934e+00
 -6.41061586e-01  1.01698834e+00 -4.90383413e-02  1.74224793e-01
  7.73628749e+00]
supnorm grad right now is: 7.736287491109353
Weights right now are: 
[  1.10867409  -3.68906322   2.70631985  -3.71394332  -1.84297281
   3.64581548  -2.2120029    2.178055     9.57431778  24.70293229
   7.11129292  12.03428227 -13.79005877  25.52235659 -17.16302542
  15.93786671   7.72251577  16.37297699   8.13349746  11.23442498
  -3.3697873    2.01415844  -5.75979901  12.337058     1.99237677
  30.3006059   32.00502389   3.92123998   1.56192226  -0.74494688
  -2.7177581   -8.694157     0.26968894  32.93672067  32.22473706
   4.92912664  13.19282965   1.20612573   2.89841828  -5.34229556
 -14.34405877   5.37405874   0.6057691  -13.12109897   3.57512221
   6.51518448   2.57673951   2.9648954    3.82034164 -12.12843875
   1.01282557   3.72478122  40.41858958  -1.41373863  22.3944953
  38.60151793   7.65614085  -3.829992     6.01998611   2.90724109
   0.49371835  -3.10086531   7.74711803  -3.88679312  27.4713801 ]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.238017837577
gradient value of function right now is: [-8.48300298e-04 -3.74660936e-03 -3.77422582e-03 -5.35468819e-01
  8.48300298e-04  3.74660936e-03  3.77422582e-03  5.35468819e-01
  1.10715350e-05  2.58855436e-04  2.63045497e-05  2.68951761e-09
 -4.41680238e-04 -4.43797841e-03 -1.03228709e-03 -5.13954688e-08
  3.78414299e-05  1.14912594e-03  8.99510678e-05  1.37561573e-08
 -1.05661613e-03 -2.11300853e+00 -2.50730370e-03 -5.45857291e-02
 -1.09451617e-02 -5.69544877e-05 -8.23609158e-04  9.60286426e-15
  3.04656933e-01 -3.27022817e-02  2.09810902e-01  4.91001932e-03
 -3.26888504e-02 -1.72720700e-04 -2.52126758e-03  1.41824122e-14
  1.01622066e-01  6.66168503e-02  5.55835454e-01  2.69431461e-01
 -7.87381536e-03 -2.32359690e-01 -3.73548215e-02 -7.66331808e-03
  4.52262935e-03 -1.57281875e-02  4.30429762e-03  4.43188334e-03
  6.13340064e-02  1.56587238e-04  1.51153365e-01  6.05393047e-02
  9.17716616e-04  1.72432291e-01  6.26161844e-03  8.84536999e-04
 -1.08345006e-01 -3.79082606e-02  8.27256504e-01 -1.25628835e+00
  1.16953655e-02  1.50383640e-01 -1.00398312e-01 -3.67787935e-02
  4.12403215e+00]
supnorm grad right now is: 4.124032149447259
Weights right now are: 
[  0.62883898  -4.37127306   1.19460434  -3.7940719   -1.3631377
   4.32802533  -0.70028739   2.25818358  10.16290118  31.67952091
   7.32200701  12.03423881 -16.72233001  27.6802746  -19.38994026
  15.98587552   7.31858717  22.31173547   7.48965432  11.18033371
  -3.20031418   1.85008381  -5.37619921  12.54303561   1.0868618
  34.78212216  36.73521009   3.92124034   2.01829062  -2.27316251
  -2.27152102  -8.09734693   0.21330337  37.28365379  36.36219316
   4.9291277   13.02980017   1.94016158   3.1057316   -5.32596579
 -17.01694859   6.90284499   0.99847024 -15.89717847   2.76325693
   9.2469293    4.01616315   2.15385148   3.39413988 -12.47862699
   0.74661805   3.29117379  42.73746499  -1.68101249  23.12162137
  40.8915925    7.50617024  -4.48736822   6.30191801   2.67129593
   1.63198902  -3.6818557    7.59347046  -4.52107573  27.29374283]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.2643951825648
gradient value of function right now is: [ 1.76807324e-03  5.15273064e-03  4.19675329e-03  2.82683449e-01
 -1.76807324e-03 -5.15273064e-03 -4.19675329e-03 -2.82683449e-01
 -3.22841217e-05 -1.01194560e-03 -6.05127926e-05 -1.83627534e-08
  3.28915126e-04  4.91267216e-03  6.08599053e-04  9.81813917e-08
 -2.06803681e-05 -7.89625025e-04 -3.88177641e-05 -1.53963314e-08
  7.50554135e-04  8.55030798e-01  1.40272243e-03  3.88935734e-02
  8.78800500e-03  2.18438106e-05  5.23534687e-04  1.06584737e-15
 -1.92385665e-01 -1.77508853e-02 -1.03715263e-01 -9.37128977e-03
  1.97844904e-02  4.96892396e-05  1.20412866e-03  2.13676631e-15
 -4.81654458e-02 -2.44785020e-02 -4.30885570e-01 -1.78279375e-01
  2.14268330e-03  1.23362946e-01  7.57800213e-02  1.94553324e-03
 -1.15973418e-03  6.16740734e-03 -1.10527974e-02 -1.10403804e-03
 -2.51038728e-02  6.86360014e-03 -1.44304017e-01 -2.39030274e-02
 -2.41699836e-03 -1.99609395e-01 -1.97101233e-02 -2.29729463e-03
  9.80168581e-02  5.61639330e-04 -5.68576260e-01  8.35406563e-01
  2.11344194e-01 -3.32728586e-01  8.93195254e-02  2.27954439e-03
 -4.87714947e+00]
supnorm grad right now is: 4.87714947363278
Weights right now are: 
[  1.89245492  -4.16656642   1.00637695  -3.84503262  -2.62675364
   4.12331868  -0.51205999   2.3091443   10.52061423  34.06717268
   7.44479908  12.02968077 -16.80832362  29.43020453 -19.16510999
  16.03446145   9.4639588   27.31174925   9.55005614  11.1721392
  -3.85373072   1.80464606  -5.71744597  13.22669084   1.64141126
  39.15793356  41.57448939   3.92124029   2.2352718   -1.97422027
  -2.29471312  -5.09076737   1.03913331  41.53471965  40.90304285
   4.92912765  12.72798236   1.80971349   3.19450184  -5.80808316
 -19.69021583   7.41851727   0.23772376 -18.58548355   2.13344689
  10.56949541   5.02393803   1.56035601   3.50030449 -13.38105099
   0.76341529   3.42513776  45.36346878  -2.59235388  25.4504989
  43.52765456   7.70535904  -3.92866821   5.67047753   2.77199786
   0.5780957   -3.77243901   7.85017801  -3.95672084  26.96079706]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1945.787635768891
gradient value of function right now is: [ 5.61691961e-04  1.41584379e-03  1.04002398e-03  1.69510949e+00
 -5.61691961e-04 -1.41584379e-03 -1.04002398e-03 -1.69510949e+00
 -6.23080490e-06 -4.97521117e-04 -1.26139183e-05 -1.22109012e-08
 -3.61053812e-04  2.73971331e-03 -6.15223888e-04  6.96800205e-08
 -5.04380700e-07 -4.09630435e-05 -1.00708879e-06 -1.06763313e-09
  8.32430466e-04  3.29341185e+00  1.72048786e-03  8.40989061e-03
  5.13273948e-04  9.32778255e-06  5.43920520e-04  4.19349118e-14
 -1.65901513e+00 -1.26135282e-01 -1.31722419e+00 -1.42978123e-02
  5.58206106e-03  2.64094137e-05  1.45678174e-03  1.06191745e-13
 -3.06008855e-02 -1.23606864e-02 -9.73760003e-02 -1.78476040e-02
  1.71745661e-02  9.21611041e-02  4.54135137e-01  1.62490511e-02
 -1.10055314e-03 -3.82566777e-03 -5.52840112e-02 -1.03272019e-03
 -4.60905408e-02 -4.44400651e-02 -6.00204255e-01 -4.46503071e-02
  1.18738883e-04  6.58992162e-03 -5.68781743e-03  1.08742239e-04
  2.18071822e-01  3.97824013e-02 -3.71908285e-01  2.75029899e-01
  4.52401121e-01 -1.14480546e-01  1.97790988e-01  3.80722607e-02
 -6.19425260e+00]
supnorm grad right now is: 6.194252598159801
Weights right now are: 
[  2.01346304  -4.70231796   0.35569106  -3.1664039   -2.74776176
   4.65907023   0.13862589   1.63051558   9.50022106  36.54578717
   6.16016395  12.03074476 -16.05759634  30.47039779 -17.99675199
  16.07778373  11.27507196  33.10685811  11.3068135   11.17729919
  -6.93087599   2.17637138  -8.67752709  13.58177148   1.40187845
  41.59385802  44.02903198   3.92124031   1.75493095  -1.59387981
  -2.13255918  -6.11874508   0.83020251  43.88447765  42.62095759
   4.92912769  12.10636761   1.36645041   3.5614426   -6.36744363
 -20.15972194   7.39887333   0.16145104 -19.02527716   2.01868351
  10.69974499   6.19049843   1.60280337   4.11980243 -12.02816153
   1.08839878   4.04673255  48.61967948  -1.66744993  28.24354459
  46.69908152   6.97615143  -4.34945625   6.00049391   2.8239276
   0.10241559  -3.46312351   7.10433484  -4.43862055  27.06160704]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1945.82378657581
gradient value of function right now is: [ 1.21583385e-03  1.48594926e-03  1.30307994e-03  1.12072199e+00
 -1.21583385e-03 -1.48594926e-03 -1.30307994e-03 -1.12072199e+00
  1.77269689e-05 -1.92132353e-03  1.94166472e-05 -3.50330447e-08
 -3.14934233e-04  1.32013863e-03 -4.20463253e-04  1.68038793e-08
  1.11170940e-06 -1.05331833e-03 -1.08035988e-06 -1.94629656e-08
 -9.90591471e-05  3.47146266e+00 -7.65697480e-05  2.51554146e-02
 -5.76506160e-03 -1.64183864e-06  3.42705178e-05  3.36438800e-14
 -7.39445354e-01 -1.80289412e-01 -8.31984710e-01 -4.26571606e-02
 -7.62887019e-03 -1.82571174e-06  1.31412095e-04  7.34781466e-14
 -3.17160167e-02 -1.39624668e-02 -2.99625306e-01 -9.47254572e-02
  8.91089998e-03  9.66776678e-02  1.73419929e-01  8.53005817e-03
 -4.88800102e-04 -1.52391527e-03 -4.64879249e-02 -4.42614697e-04
 -4.16804594e-03 -1.57927201e-02 -1.68289526e-01 -3.93660994e-03
 -2.71414215e-03 -1.67368102e-01 -2.72879362e-02 -2.62535873e-03
  9.95503326e-02 -1.24454556e-01 -3.51307735e-01  4.41496225e-01
  7.35344904e-01 -3.78031083e-01  8.89336352e-02 -1.16448639e-01
 -6.53210696e+00]
supnorm grad right now is: 6.532106962715302
Weights right now are: 
[  5.54271746  -3.84467831   3.26689052  -3.53264529  -6.27701618
   3.80143057  -2.77257357   1.99675697   5.92546657  36.34166394
   2.18277153  12.02622016 -16.76186185  33.0417185  -18.20639898
  16.10148934   8.6656883   35.86098294   8.19762748  11.17758185
  -7.37965657   1.99791556  -8.93877     13.76281454   1.6473291
  43.02700598  47.60338091   3.92124032   2.161091    -2.01803534
  -2.39130126  -6.19511963   1.38034238  45.5626937   45.93658569
   4.92912772  12.53323201   3.15146428   3.90687416  -6.37915385
 -21.63851936   8.18961659   0.29374161 -20.59248746   0.51332916
  12.75656085   8.13926811   0.11548697   3.23819956 -12.98115516
   1.33529826   3.12697775  49.67158045  -2.38984697  28.59874494
  47.78059399   7.05181867  -4.99310455   6.29675441   2.69115143
   1.23021878  -4.26536628   7.17797556  -5.00365304  27.03953706]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.0745726849361
gradient value of function right now is: [ 5.52411293e-03  2.00465201e-02  4.25353917e-03  1.26762472e+00
 -5.52411293e-03 -2.00465201e-02 -4.25353917e-03 -1.26762472e+00
 -3.38604989e-04 -6.77271695e-03 -3.94863564e-04 -1.54479780e-07
  2.62715325e-03  1.85027717e-02  2.94721784e-03  4.67869293e-07
 -7.15490413e-05 -1.91446569e-03 -8.48703140e-05 -4.28690437e-08
  3.46885328e-03  1.93449778e+00  4.09728574e-03  5.69678923e-03
  6.73993991e-02  2.06228018e-08  1.72882731e-03  5.97559985e-15
 -1.34396490e+00 -2.07115385e-02 -8.53289250e-01 -2.17963423e-02
  8.43541394e-02  2.82205589e-08  2.34061097e-03  1.64042072e-14
 -1.90761919e-02 -3.53902679e-03 -7.58387173e-02 -2.94486329e-02
  1.01555607e-02  8.66584570e-02  2.66724200e-01  9.76698888e-03
 -1.79816004e-06  1.44743848e-03 -1.28532235e-05 -1.73647531e-06
 -9.58226294e-02 -2.17213893e-02 -5.27012117e-01 -9.39723013e-02
  3.93207442e-04 -4.37174898e-03 -5.32450844e-03  3.82155771e-04
  2.15329484e-01  2.24394651e-01 -3.26662433e-01  3.05271485e-01
  2.23691472e-01 -7.78259357e-02  2.02999534e-01  2.15294472e-01
 -5.35917457e+00]
supnorm grad right now is: 5.359174567430689
Weights right now are: 
[ 4.52273035e+00 -4.47080391e+00  2.03739778e+00 -3.32635147e+00
 -5.25702907e+00  4.42755618e+00 -1.54308083e+00  1.79046315e+00
  3.77166829e+00  3.91054685e+01  4.26260319e-02  1.19985092e+01
 -1.70410904e+01  3.26964704e+01 -1.81894479e+01  1.63098942e+01
  7.56841937e+00  4.06527483e+01  7.15304643e+00  1.11760589e+01
 -7.21618094e+00  2.22006035e+00 -8.70166746e+00  1.42590750e+01
  2.08002112e+00  4.37665954e+01  5.02029576e+01  3.92124054e+00
  2.19237980e+00 -1.50720403e-01 -2.04152658e+00 -5.94266373e+00
  1.98569249e+00  4.64991264e+01  4.83312387e+01  4.92912816e+00
  1.24109292e+01  3.81101148e+00  4.02927171e+00 -6.28085141e+00
 -2.27727517e+01  6.89446103e+00 -4.00872043e-01 -2.17801908e+01
  3.53397944e+00  1.70892186e+01  1.28730041e+01  3.11369816e+00
  3.44790865e+00 -1.29923505e+01  8.91701879e-01  3.38005812e+00
  4.91056397e+01 -1.91700727e+00  3.02453251e+01  4.71711921e+01
  8.60302571e+00 -4.22181001e+00  6.31371417e+00  3.27094596e+00
  6.89375618e-01 -3.48538391e+00  8.70762039e+00 -4.25625354e+00
  2.71005812e+01]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1945.8653739129186
gradient value of function right now is: [ 3.54420217e-05 -1.29513272e-03  5.57396077e-05  1.18746611e+00
 -3.54420217e-05  1.29513272e-03 -5.57396077e-05 -1.18746611e+00
  3.31016748e-05 -6.63258394e-05  3.60674397e-05 -9.13856195e-11
 -8.43709332e-04 -1.46084703e-03 -9.14198191e-04 -1.47573398e-08
  3.62600645e-06 -2.01438493e-05  3.94008139e-06 -8.32756540e-11
 -1.08181556e-03  2.71166919e+00 -1.17218341e-03 -7.96914304e-03
 -2.33513541e-02  6.00243867e-11 -7.00942416e-04  1.95152392e-12
 -1.23154430e+00 -9.25601810e-02 -1.17739799e+00 -7.84023645e-02
 -2.74429479e-02  1.13044486e-10 -8.12578468e-04  5.27115285e-12
  2.26846844e-02  1.93934903e-03  9.60128206e-02  8.57964238e-02
  6.96086190e-03 -1.74165245e-02  1.35533268e-01  6.57942915e-03
  4.81345582e-05 -3.44803539e-03  4.45841516e-03  4.33466686e-05
  3.38815945e-03 -4.20684287e-02 -1.38955574e-01  3.43757250e-03
 -7.94750455e-04  1.57521225e-02 -1.64711187e-02 -7.45653947e-04
  6.66103962e-02 -9.96718527e-02  8.51178665e-03 -3.11420272e-01
  4.98934284e-01 -1.91193950e-01  5.82158239e-02 -9.30543283e-02
 -3.95583562e+00]
supnorm grad right now is: 3.9558356178255103
Weights right now are: 
[  3.63798837  -5.77086319   1.28893396  -3.20770027  -4.37228709
   5.72761545  -0.794617     1.67181195   5.86647834  40.79376085
   2.19960334  12.00503011 -17.38068024  33.46671649 -18.31475034
  16.32197112  11.12511635  42.94479719  10.81625707  11.17935737
  -8.95293987   2.14554807 -10.36208529  14.8888924    1.38303615
  43.80968061  51.14101506   3.92123949   2.04936083   0.88459207
  -2.57974327  -4.81749882   1.3593457   46.55584158  49.04948965
   4.92912599  13.61770177   8.96442265   4.00962239  -5.99871422
 -26.78252254   5.63399106  -0.91402445 -25.80840493   6.54868378
  16.03141996  21.79236115   5.85063422   4.20362311 -13.88206531
   1.72047901   4.13298877  53.56508476  -1.6533573   31.7045163
  51.60655695   6.86815688  -5.40548937   6.4239996    2.75163492
   1.48544089  -4.04116322   6.99658291  -5.45534329  27.12471519]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.4403225718677
gradient value of function right now is: [-4.09727783e-03 -1.00113154e-02 -3.01282357e-03 -6.86296523e-01
  4.09727783e-03  1.00113154e-02  3.01282357e-03  6.86296523e-01
  3.48973073e-05  2.22983931e-03  3.44771695e-05  1.35279445e-07
 -1.45688381e-04 -1.07471893e-02 -1.42806110e-04 -6.65422814e-07
  3.40890133e-06  2.16598021e-04  3.37302043e-06  1.31804096e-08
 -1.14424826e-04 -9.71266712e-01 -1.13241250e-04 -4.28927075e-04
 -3.64504252e-03 -6.81206438e-14 -1.74125321e-04 -3.25884305e-14
  9.51667431e-01  1.35348147e-03  7.41389163e-01  8.01573776e-04
 -3.69450794e-03 -2.06590328e-13 -1.79372535e-04 -9.93940499e-14
  1.14418666e-02  8.96884202e-04  3.42244645e-03  1.36441471e-03
 -8.61463726e-03 -4.13823349e-02 -1.38262275e-01 -8.08345647e-03
 -1.68733963e-05 -1.81604385e-03 -1.89949099e-03 -1.45904781e-05
  2.92975047e-02  1.82713937e-02  1.81529332e-01  2.86109965e-02
 -5.56953403e-05 -2.25001201e-02  4.14196484e-03 -4.59800083e-05
 -1.06986255e-01 -1.50763905e-02  1.75719390e-01 -3.38195324e-02
 -1.94317478e-01 -3.02423541e-02 -9.71996018e-02 -1.45384503e-02
  4.11891045e-01]
supnorm grad right now is: 0.9712667120122331
Weights right now are: 
[  2.99080577  -6.33200646   0.69167651  -3.73555382  -3.7251045
   6.28875872  -0.19735955   2.1996655    3.96723299  43.2430058
   0.25963252  12.02258002 -17.51897276  33.01774841 -18.1354522
  16.36175392  10.73397146  46.79651312  10.44111844  11.18796924
  -8.31439286   2.05500406  -9.66006943  15.67349741   2.18688731
  43.80968047  55.1552423    3.92123946   2.91551874   1.02494919
  -2.21752863  -5.0919168    2.31653939  46.55583941  52.82174013
   4.92912591  11.77122014  10.74243518   3.70028564  -7.8447099
 -25.46098801   5.99111797  -0.43522494 -24.45295834  11.67276504
  19.60146338  28.29161603  10.64812745   3.10928048 -14.67420543
   1.1325519    3.07205852  56.16435842  -1.98469105  33.25211182
  54.19923494   7.73954431  -4.64479322   6.26304473   2.46420327
   1.82218637  -3.39249962   7.89879493  -4.74275544  27.03727107]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1945.3426873492308
gradient value of function right now is: [ 1.54715184e-03  5.17080315e-03  8.02334774e-04  1.38026260e+00
 -1.54715184e-03 -5.17080315e-03 -8.02334774e-04 -1.38026260e+00
 -2.28920954e-05 -1.44799067e-03 -2.00741476e-05 -1.94257819e-07
  7.16876252e-05  6.10747873e-03  6.42631800e-05  8.38242679e-07
 -6.15179838e-06 -3.63675458e-04 -5.38342573e-06 -4.88173201e-08
  1.68694954e-04  3.12243493e+00  1.49661244e-04  9.88197217e-03
  3.10746557e-03  2.21688838e-13  2.33835169e-04  1.33056916e-13
 -1.28123272e+00 -5.80068802e-02 -1.11152521e+00 -7.37195164e-02
  2.88264626e-03  5.75553281e-13  2.18846423e-04  3.69503624e-13
 -4.72916156e-02 -6.55240545e-03 -1.12160506e-01 -5.90852137e-02
  1.08371422e-02  9.75293879e-02  2.29124480e-01  1.01092825e-02
  3.17990679e-05  6.81781288e-03  7.94565934e-03  2.69297626e-05
 -2.34834931e-02 -2.83739610e-02 -2.92528700e-01 -2.28119474e-02
  1.69102951e-04 -4.45966357e-02 -1.51226231e-02  1.50513341e-04
  1.56457299e-01  3.84314779e-02 -4.87607825e-01  5.07383796e-01
  3.99214431e-01 -8.47354832e-02  1.42858792e-01  3.78893717e-02
 -8.18003628e+00]
supnorm grad right now is: 8.180036282037372
Weights right now are: 
[  4.23501635  -5.75910708   2.49246189  -3.38974408  -4.96931507
   5.71585934  -1.99814494   1.85385576   3.63129747  44.55002164
  -0.338772    12.03615635 -18.80697967  33.30304119 -19.0713577
  16.42909548  10.14586742  50.78028483   9.74375042  11.19932554
  -9.55682149   1.91587174 -10.79048275  15.18065736   1.45461538
  43.80968051  57.39420796   3.92123942   2.56202363   2.67269259
  -3.03996429  -4.61640682   1.75678834  46.55583938  54.93462489
   4.9291258   10.82418246  10.33557163   4.36827787  -8.95392306
 -23.26530569   5.43384874   0.10593061 -22.22304576  13.85800657
  22.16096736  31.96602717  12.44923196   4.26896406 -13.3465315
   1.49442896   4.2677264   59.70084909  -1.59234567  34.42361964
  57.79308297   8.01396225  -4.78673963   6.73880884   2.92142133
   2.00955742  -3.08409989   8.17644908  -4.94717105  26.80031195]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.461702032885
gradient value of function right now is: [-7.48908540e-04 -4.70546245e-03 -3.10803272e-04 -4.42538579e-01
  7.48908540e-04  4.70546245e-03  3.10803272e-04  4.42538579e-01
  1.30714063e-04  8.21979715e-04  1.02942935e-04  1.18913015e-07
 -9.03684149e-04 -4.38406166e-03 -7.05447530e-04 -6.47964677e-07
  3.35879356e-05  2.25639429e-04  2.65372250e-05  3.25382158e-08
 -9.81636312e-04 -1.27907431e+00 -7.75852550e-04 -2.33893498e-02
 -2.84715167e-02  2.84036493e-14 -1.13788585e-03  2.43781938e-14
  2.33142072e-01  6.93730815e-02  1.70543987e-01  1.27462563e-01
 -2.29541352e-02  7.63434921e-14 -9.24703192e-04  6.49841730e-14
  1.07786249e-01  1.27665826e-02  2.99133013e-01  1.73829837e-01
  7.95667594e-04 -1.28656429e-01 -9.18591005e-03  7.45140542e-04
 -1.89532066e-05 -2.58900337e-02 -6.57099065e-03 -1.67850687e-05
  3.04245693e-02 -5.23965459e-03  1.09606091e-01  3.14155623e-02
 -1.08932317e-04  1.22194696e-01  1.19175408e-02 -9.83943819e-05
 -4.90569298e-02 -6.71780241e-02  7.92855798e-01 -1.25345531e+00
 -1.72557528e-01  1.46015075e-01 -5.09647586e-02 -6.78380383e-02
  2.48612148e+00]
supnorm grad right now is: 2.4861214789700155
Weights right now are: 
[  5.02068264  -5.0033268    3.79309525  -3.0252577   -5.75498137
   4.96007906  -3.2987783    1.48936938   3.08441217  46.233652
  -1.18503858  11.95139335 -18.24582053  33.97801363 -18.21914231
  17.18413119   8.7640973   52.82076867   8.12966963  11.18309297
 -12.48151926   1.99593203 -13.66440077  15.37980697   1.2052079
  43.80968102  59.11337725   3.92123904   2.35055133   4.31889821
  -2.35824724  -4.9747895    1.56083943  46.55583893  56.47707904
   4.92912499  10.9801847   13.68515178   3.92438077  -8.59994032
 -24.81972285   4.72690256  -1.10124526 -23.74026165  17.25697181
  21.49486082  34.06488407  15.44558335   4.48926186 -15.23238955
   1.88402556   4.4693906   59.64409834  -1.58991644  34.82339886
  57.79526589   8.1699862   -5.7489245    6.86051076   2.3469333
   1.62941036  -3.86372666   8.23524427  -5.89196516  27.17719396]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.6261656471343
gradient value of function right now is: [ 4.60714960e-03  1.64887261e-02  2.51057085e-03 -6.27893008e-01
 -4.60714960e-03 -1.64887261e-02 -2.51057085e-03  6.27893008e-01
 -1.09824196e-04 -3.39765118e-03 -7.28040156e-05 -1.13431545e-06
  5.29246934e-04  1.44584886e-02  3.47649156e-04  4.70887806e-06
 -3.34293889e-05 -1.09768611e-03 -2.22833449e-05 -3.69651056e-07
  5.63116272e-04 -1.63123454e+00  3.76626778e-04 -1.68169471e-02
  1.67398534e-02 -2.66622781e-15  7.23906740e-04 -3.18359881e-15
  3.81161275e-01  2.06071693e-02  6.71273495e-01  4.30438694e-02
  1.11080004e-02 -7.71810793e-15  4.92095548e-04 -9.22000855e-15
  4.43632037e-02  5.65266028e-03  2.23726742e-01  5.76134799e-02
 -5.75815368e-03 -9.87917155e-02 -1.16954779e-01 -5.44301116e-03
 -2.06139276e-05 -8.85477785e-03 -5.89540447e-03 -1.75122887e-05
 -2.78451840e-02  4.75927896e-03 -4.24945167e-02 -2.73970123e-02
  2.24418722e-03  1.49973604e-01  1.97382030e-02  2.06853610e-03
  1.18429980e-02  2.69866297e-01  3.22801272e-01 -3.96520216e-01
 -3.64061774e-01  3.04894402e-01  1.45523634e-02  2.49914926e-01
  3.08323504e+00]
supnorm grad right now is: 3.0832350413283867
Weights right now are: 
[  4.09175054  -5.55324258   2.88650041  -3.28899477  -4.82604926
   5.50999484  -2.39218346   1.75310645   2.94459269  48.41728761
  -1.45483572  12.26050678 -18.83098195  34.00155303 -18.44785326
  16.77267947   8.33315043  55.37729572   7.68192733  11.30700033
 -11.51992991   2.12524896 -12.6150829   15.54769197   1.8568055
  43.80968098  62.34826599   3.92123902   2.63296558   3.96756323
  -2.32857805  -6.33076908   2.39783973  46.55583885  59.54893872
   4.92912494  10.09135648  15.47696327   4.11468562 -10.09954101
 -23.2201808    5.62023582  -1.48577565 -22.17569773  19.67730013
  22.91021336  36.80099429  17.60843674   3.0741802  -14.46342119
   1.17846105   3.02656989  64.54471854  -1.6478868   35.75262013
  62.88372167   9.47375002  -3.85454632   6.99622146   2.66807889
   1.84055724  -3.58568873   9.66203856  -3.93090666  27.34859073]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.613193898083
gradient value of function right now is: [ 1.22565223e-04 -1.39714885e-04  7.63463000e-05 -6.93790076e-01
 -1.22565223e-04  1.39714885e-04 -7.63463000e-05  6.93790076e-01
  4.90801316e-05 -1.47888022e-04  2.97212673e-05 -2.00847369e-08
 -3.62465143e-04  2.48115105e-05 -2.18507649e-04 -2.58379440e-07
  1.74030923e-05 -6.71897468e-05  1.05574107e-05 -1.22770141e-08
 -2.41096902e-04 -1.46500236e+00 -1.46047834e-04 -1.21508259e-02
 -1.02401862e-02 -2.17996169e-16 -3.47503375e-04 -2.45062029e-16
  4.76742919e-01  6.08740277e-03  5.07551234e-01  2.49271720e-02
 -6.12785393e-03 -6.79633032e-16 -2.07906592e-04 -7.72505722e-16
  1.26796966e-02 -4.46990982e-03  1.83637794e-01  7.65577563e-03
 -3.42862472e-05 -6.91856750e-02 -1.15380081e-01 -6.97633337e-06
 -2.51875343e-06  4.54154066e-03 -3.36915574e-03 -2.07672891e-06
  1.92184596e-02  1.92702036e-02  1.16432823e-01  1.92171612e-02
  7.04603312e-04  1.68657839e-01  2.91462407e-02  6.23466805e-04
 -2.21553575e-02  2.12266523e-02  1.28339892e-01 -8.72841710e-02
 -5.12605482e-01  7.19587219e-01 -2.02610805e-02  1.59129500e-02
  1.48657906e+00]
supnorm grad right now is: 1.486579055966567
Weights right now are: 
[  4.76337311  -5.89465653   4.03283256  -3.17004121  -5.49767183
   5.85140879  -3.53851561   1.63415289   2.76615756  49.83082822
  -1.77890887  12.79457542 -20.15051558  33.59948949 -19.46497825
  16.79588724   7.01354263  56.56905278   6.35833645  11.61111902
 -12.56298868   1.9493321  -13.60282251  15.74555769   1.30245882
  43.80968098  64.64349719   3.92123901   2.60935695   5.4238741
  -2.38918495  -6.86260924   1.92147027  46.55583885  61.61157329
   4.92912493   9.4553343   15.59361705   4.34635509 -11.04477238
 -23.22360484   5.13290181  -1.19668553 -22.14589415  24.41579634
  25.41795748  37.04925448  21.95921794   4.10477055 -11.93350633
   1.23124534   4.07020211  66.28426314  -1.42748921  37.44864587
  64.6282731    8.99862777  -5.28547166   6.6793759    2.7597525
   0.82605458  -3.23641369   9.17101654  -5.40846048  27.14536586]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.4693238604802
gradient value of function right now is: [-1.98513327e-03 -6.45222121e-03 -1.31952896e-03  9.07323307e-01
  1.98513327e-03  6.45222121e-03  1.31952896e-03 -9.07323307e-01
  1.95531991e-05  1.24030920e-03  1.24262278e-05  2.63155620e-07
 -6.90417946e-05 -4.86994075e-03 -4.37025140e-05 -5.00425343e-07
  1.12407414e-05  6.61097073e-04  7.12791604e-06  1.47410881e-07
 -4.28505527e-05  1.71732076e+00 -2.72425279e-05 -4.95845023e-03
 -2.06215025e-03  5.59595080e-16 -1.18197179e-04  5.92315207e-16
 -7.10892717e-01 -1.36394152e-01 -8.60085178e-01 -1.85984878e-01
 -1.23745749e-03  1.88908177e-15 -7.17767171e-05  2.00064340e-15
  2.34635450e-02  1.76549597e-03  5.94663726e-02  5.35729475e-02
  3.74090921e-03  1.52840128e-02  1.52328011e-01  3.38204180e-03
  1.09925259e-04  1.73641454e-03  1.67039056e-02  9.47170804e-05
  3.42114371e-03 -1.74405958e-02 -6.68767852e-02  3.45499835e-03
 -8.74684720e-04 -1.63644252e-02 -3.29798778e-02 -7.80996102e-04
  7.21657938e-02 -4.62319183e-02 -1.36478863e-01 -6.81432780e-02
  4.08120526e-01 -2.16981595e-01  6.21839506e-02 -4.16568491e-02
 -3.71601489e+00]
supnorm grad right now is: 3.7160148890496987
Weights right now are: 
[ 4.65295191e+00 -6.61695829e+00  4.27524318e+00 -3.04115638e+00
 -5.38725063e+00  6.57371055e+00 -3.78092623e+00  1.50526806e+00
  2.70079719e+00  5.16052147e+01 -1.93728564e+00  1.33656687e+01
 -2.00458464e+01  3.27653019e+01 -1.91477702e+01  1.65698018e+01
  6.15376084e+00  5.80284598e+01  5.49152754e+00  1.19093999e+01
 -1.31938534e+01  2.37372771e+00 -1.42810062e+01  1.49433824e+01
  1.62515548e+00  4.38096810e+01  6.66854943e+01  3.92123902e+00
  2.98329070e+00  5.71968882e+00 -2.05568622e+00 -7.75873860e+00
  2.27335301e+00  4.65558388e+01  6.33861800e+01  4.92912493e+00
  1.05880039e+01  1.90325961e+01  4.82548929e+00 -1.00302758e+01
 -2.55527755e+01  4.48094595e+00 -2.75517921e-02 -2.46248745e+01
  2.53743418e+01  2.39962538e+01  3.78380076e+01  2.29252391e+01
  2.82020236e+00 -1.50864842e+01  1.18508382e+00  2.78034397e+00
  6.81486945e+01 -1.52148226e+00  3.71839865e+01  6.65454790e+01
  8.22025322e+00 -5.05289269e+00  6.94031667e+00  2.47142710e+00
  2.32045705e+00 -4.17329525e+00  8.37949179e+00 -5.15186067e+00
  2.70862308e+01]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.16129595558
gradient value of function right now is: [-1.58286376e-02 -5.12621921e-02 -1.11868974e-02 -9.06586564e-01
  1.58286376e-02  5.12621921e-02  1.11868974e-02  9.06586564e-01
  2.28244924e-04  9.80569306e-03  1.24817706e-04  1.29304829e-05
 -5.86931729e-04 -4.07554883e-02 -3.19457586e-04 -4.79188485e-05
  1.52979908e-04  5.94496736e-03  8.37334498e-05  8.10728900e-06
 -2.72046745e-04 -5.20563199e-01 -1.49246823e-04  1.43954656e-02
 -1.65757916e-02 -7.49924379e-17 -6.34220729e-04 -9.18600475e-17
  1.20598936e+00  3.17905605e-02  7.49890799e-01  3.34355767e-02
 -8.22100433e-03 -2.45706538e-16 -3.20775895e-04 -3.01187907e-16
 -5.44763458e-02 -9.71495807e-03 -2.00407142e-01 -7.70707580e-02
 -6.45017378e-03  5.21973918e-02 -1.74507765e-01 -5.69338595e-03
 -2.92107066e-05  1.34787046e-02 -8.03484958e-03 -2.22236581e-05
  5.02287356e-02  2.87925315e-02  3.30977250e-01  4.70306986e-02
 -6.53959701e-04 -1.08529236e-01 -3.34832479e-04 -5.73415645e-04
 -1.10978263e-01 -8.38214303e-02 -2.24992441e-01  5.63485911e-01
 -1.85120186e-01 -2.81181456e-01 -9.57099185e-02 -7.32989087e-02
  2.76850756e+00]
supnorm grad right now is: 2.768507558323956
Weights right now are: 
[  5.16827819  -6.60373297   5.07758119  -3.25777224  -5.90257691
   6.56048523  -4.58326424   1.72188392   2.47171316  52.43673098
  -2.37148592  13.59194581 -20.40383238  32.68053897 -19.26441851
  16.69245297   5.18577752  58.57250909   4.38079062  12.03593874
 -12.88261485   2.12878454 -13.89691818  16.56044027   1.95558719
  43.80968098  69.84515842   3.92123902   3.26480598   7.09438874
  -2.62604246  -6.93596719   2.70123504  46.55583885  66.39924382
   4.92912493   9.09422215  19.50942217   3.25842816 -11.38858597
 -26.83618352   4.70000994  -1.94180896 -25.94218279  27.69744629
  24.93164273  38.88871401  25.12383172   2.98367069 -14.79490444
   1.36757684   3.01541397  69.34372276  -1.32880676  37.65313774
  67.69023435   8.05830925  -4.96197937   7.0596904    2.99234716
   1.64513517  -3.90460796   8.36151704  -5.05757177  27.28176237]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.5307147056333
gradient value of function right now is: [-1.66289210e-03 -1.04342743e-02 -8.96854854e-04 -8.90481328e-02
  1.66289210e-03  1.04342743e-02  8.96854854e-04  8.90481328e-02
  4.11618122e-04  2.00692283e-03  1.64831284e-04  1.40518728e-06
 -1.96809068e-03 -7.10419778e-03 -7.86776863e-04 -5.10676088e-06
  1.95591124e-04  9.48394520e-04  7.86288190e-05  6.65487608e-07
 -1.80774192e-03  2.92781302e-01 -7.28305137e-04  6.03420853e-03
 -6.94883792e-02 -6.41226635e-18 -2.64152842e-03 -1.33949937e-17
  1.45216637e-01 -1.69770054e-02 -6.99337074e-02 -2.69901048e-02
 -2.68752847e-02 -1.50357200e-17 -1.02440510e-03 -3.05744466e-17
 -2.15145438e-02 -4.79885529e-03 -8.12382562e-02 -3.03133630e-02
  8.97723583e-04  5.24278459e-02 -2.01502584e-02  8.07076355e-04
 -1.43713944e-06  7.86952281e-03  1.87959595e-03 -1.16002780e-06
  6.07868647e-02  5.49052278e-03  2.48189722e-01  5.87421627e-02
 -3.59135044e-04 -6.66636344e-02 -6.14334809e-03 -2.95066467e-04
 -1.17765030e-01 -1.22960436e-01 -1.84983790e-01  3.53215109e-01
 -6.85482903e-02 -1.41395942e-01 -1.16448842e-01 -1.16729385e-01
  1.21039173e+00]
supnorm grad right now is: 1.2103917264633992
Weights right now are: 
[  6.76109315  -4.4209927    6.49379135  -2.84062717  -7.49539188
   4.37774496  -5.9994744    1.30473884   3.1127135   50.62267298
  -2.01709625  13.97563639 -21.8897139   35.8226562  -20.37242744
  17.50537012   5.15422745  56.99224675   4.12774982  12.36959466
 -14.82746599   2.136223   -15.49234889  16.22601492   0.71114475
  43.80968098  71.72597363   3.92123902   2.55553877   7.21346979
  -2.13037291  -8.29277254   1.77162636  46.55583885  68.45228923
   4.92912493   9.54296106  20.48136513   3.8679797  -11.70579486
 -28.3128412    4.13039142  -2.31398099 -27.49270131  29.29689934
  26.54276895  41.08220394  26.56308665   4.01251887 -14.12817666
   1.87970782   4.11432955  71.43293162  -1.67575805  37.75517008
  69.84208847   6.68817519  -6.40678284   7.09053917   2.73482315
   0.47863479  -3.97435968   6.94660616  -6.64827216  27.24324783]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.4601132972039
gradient value of function right now is: [ 5.25445356e-04  2.94506268e-04  4.21435094e-04  5.15533899e-01
 -5.25445356e-04 -2.94506269e-04 -4.21435094e-04 -5.15533899e-01
  3.82289911e-05 -1.88826810e-04  1.55174945e-05 -2.60925444e-07
 -1.81823065e-04 -3.51292232e-04 -7.49721622e-05  6.03187412e-07
  2.18544577e-05 -1.60856972e-04  8.84604403e-06 -1.67476288e-07
 -6.82753364e-05  1.22076617e+00 -2.73583550e-05  1.47374605e-02
 -4.97461452e-03  5.50517635e-20 -8.58401331e-05  3.50373700e-19
 -2.95210229e-01 -2.12058690e-02 -4.45102525e-01 -4.78371894e-02
 -1.89226505e-03  1.78441239e-19 -3.02228592e-05  1.09686712e-18
 -5.83856446e-02 -7.32754161e-03 -1.87482548e-01 -7.19991505e-02
  3.65749536e-03  1.16570826e-01  1.08488804e-01  3.34725088e-03
  7.19203501e-07  1.39234719e-02  3.46040765e-03  5.45312800e-07
  1.89894434e-03 -1.56355952e-03 -3.64867641e-02  1.57367284e-03
 -3.68781952e-04 -1.35506405e-01 -1.57409138e-02 -3.30940602e-04
  1.97369495e-02 -5.59390401e-02 -4.85688595e-01  6.85502812e-01
  1.95165776e-01 -3.06731173e-01  1.57162135e-02 -5.11339956e-02
 -4.53151908e+00]
supnorm grad right now is: 4.5315190773769025
Weights right now are: 
[  4.93092208  -6.38721127   4.78143674  -3.12298971  -5.66522081
   6.34396353  -4.28711979   1.58710139   2.01965803  53.16998562
  -3.10360271  14.53629577 -22.439608    35.59594615 -20.80007669
  16.77101768   3.63240355  59.59871117   2.68419401  12.6647021
 -13.44675571   2.14343953 -14.19877363  15.83553657   1.58736576
  43.80968098  75.21037221   3.92123901   2.96622618   8.88772568
  -2.24707673  -7.91626191   2.5585189   46.55583885  71.68259026
   4.92912493   9.74007576  19.5255663    4.42549069 -11.60549373
 -25.55120557   4.72129648  -0.83972002 -24.70572223  30.78301271
  27.50632266  45.93760563  27.66441388   2.91322028 -13.15251243
   0.80056002   3.02650164  73.54537394  -1.39269201  36.39091075
  72.15319215   8.14262754  -6.34032456   6.77028961   2.68531097
   1.00580743  -3.68474406   8.386419    -6.43820607  26.95763719]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.688124866335
gradient value of function right now is: [ 1.95696882e-03  7.63462481e-03  1.27741466e-03  2.69268565e-01
 -1.95696882e-03 -7.63462481e-03 -1.27741466e-03 -2.69268565e-01
 -7.41024255e-05 -1.47408507e-03 -2.93563445e-05 -1.29253030e-06
  3.39651462e-04  6.33402394e-03  1.33778391e-04  5.63168498e-06
 -4.57382399e-05 -8.95764407e-04 -1.81318204e-05 -7.89559946e-07
  2.84289076e-04  6.65210323e-01  1.13162574e-04 -8.28840909e-04
  1.16706417e-02  2.20435947e-18  4.77743362e-04  9.08820338e-18
 -3.07182435e-01 -2.77073204e-02 -2.49337695e-01 -4.69612254e-02
  4.32683603e-03  6.10991166e-18  1.79427877e-04  2.47794577e-17
 -5.34617422e-02 -9.11886606e-03  4.57553484e-02 -3.77408468e-02
  7.32118195e-04  1.82710013e-02  3.25110287e-02  5.93044810e-04
  5.23890344e-06  1.40689400e-02  5.72347017e-03  3.32740499e-06
 -1.85745515e-02  1.04282728e-03 -7.69753812e-02 -1.44193159e-02
  8.62491219e-04  9.88039393e-02 -5.43136818e-03  8.06900908e-04
  2.66088601e-02  1.03099156e-01 -3.86107512e-01  5.13855550e-01
  1.62448760e-01  1.07678848e-01  2.24170417e-02  9.33091065e-02
 -2.88802546e+00]
supnorm grad right now is: 2.888025464382581
Weights right now are: 
[  5.20451689  -6.69086572   5.41252456  -3.34366709  -5.93881561
   6.64761798  -4.9182076    1.80777877   1.87024723  54.53848074
  -3.32948387  14.82931705 -23.23527528  35.50151307 -21.43083138
  16.98007762   3.2958788   60.63458232   2.35643785  12.84202557
 -12.76067149   2.17226006 -13.52273723  16.52203984   1.63299339
  43.80968098  78.06498101   3.92123901   2.83046351   8.45650564
  -2.69865972  -8.84169912   2.71581725  46.55583885  74.4769499
   4.92912493   9.45872626  21.25805807   3.56651376 -12.31184697
 -26.40015512   4.7468749   -1.50067759 -25.55550046  31.40667614
  28.12689605  46.77890195  28.17708635   2.66908323 -12.91078491
   1.70079053   2.73142542  77.93288335  -0.39371188  37.30093828
  76.5108017    8.82342652  -4.51458284   7.60050059   3.16391559
   1.73813187  -3.15217191   9.36393045  -4.54075751  27.05128011]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.793133860098
gradient value of function right now is: [-1.90599602e-04 -3.03018604e-03 -7.82327068e-05 -4.98352755e-01
  1.90599602e-04  3.03018604e-03  7.82327068e-05  4.98352755e-01
  1.42321147e-04  2.94401457e-04  5.10900240e-05  5.29023523e-08
 -6.40021743e-04 -3.25296041e-03 -2.29425156e-04 -6.51917016e-07
  8.93457860e-05  1.18617315e-04  3.20916700e-05  2.22309792e-08
 -4.02796708e-04 -4.13502020e-01 -1.44461930e-04  8.35963335e-03
 -2.10911133e-02 -1.54042968e-18 -6.71875292e-04 -4.50172886e-18
  5.00125911e-01 -7.80995864e-03  3.76465050e-01 -9.85460081e-03
 -7.04472961e-03 -3.97625180e-18 -2.22899129e-04 -1.12417130e-17
 -3.35934564e-02 -2.99311213e-03 -1.06173228e-01 -5.56536020e-02
 -2.82906582e-03  2.50537479e-02 -8.85660738e-02 -2.53616441e-03
 -3.15932847e-06  6.72410990e-03 -1.58840162e-03 -2.35576831e-06
  3.03030848e-02  2.09491433e-02  1.38089303e-01  2.95888696e-02
 -2.82956281e-04 -9.56473630e-02 -1.31305125e-03 -2.29963232e-04
 -3.75168822e-02 -3.09546009e-02 -1.81081063e-01  3.82470087e-01
 -1.04427870e-01 -1.21697012e-01 -3.61035099e-02 -2.97957956e-02
  8.71856543e-01]
supnorm grad right now is: 0.8718565431948496
Weights right now are: 
[  6.28052989  -5.93472802   6.61439831  -3.08902912  -7.01482861
   5.89148028  -6.12008135   1.5531408    2.64525151  54.04727344
  -2.70368784  14.78124147 -23.38583714  36.22089757 -21.39237516
  17.80957261   3.61597419  59.93543917   2.5792038   12.83249601
 -14.89878178   1.9567123  -15.60996329  15.81193933   1.12659017
  43.80968098  78.9802994    3.92123901   2.77735663   8.50000348
  -2.20884297  -9.43704784   2.28586805  46.55583885  75.29303279
   4.92912493  10.93400417  22.47069136   4.40477043 -12.07561317
 -27.32232139   3.7219068   -1.30791301 -26.58908605  31.25796584
  28.60837026  44.50287335  28.00523579   4.37730175 -12.99516293
   1.75769289   4.55371047  80.23144961  -2.03522315  39.54929158
  78.76119397   9.39852074  -5.15487928   7.31482391   3.18529481
   1.23335697  -4.27908035   9.73176684  -5.32880917  27.1976675 ]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.8872981593222
gradient value of function right now is: [-2.20064977e-04 -9.75022245e-04 -1.41684608e-04  4.44153947e-01
  2.20064977e-04  9.75022245e-04  1.41684608e-04 -4.44153947e-01
 -1.92317052e-05  1.73620576e-04 -6.15546074e-06  2.30753012e-08
  1.10960756e-04 -1.09972849e-03  3.55868812e-05  2.67552941e-07
 -1.29136962e-05  1.02930879e-04 -4.13367965e-06  1.57505560e-08
  5.40336866e-05  7.32684084e-01  1.72236744e-05 -3.35373426e-03
  3.38754738e-03  3.75160511e-19  9.12500743e-05  1.07315831e-18
 -3.19390387e-01 -3.93820987e-02 -3.15668020e-01 -5.71049331e-02
  9.93536447e-04  9.99040787e-19  2.62507474e-05  2.79336904e-18
  1.51078497e-02  4.12604494e-04  4.37696215e-02  2.39342214e-02
  2.13768443e-04 -1.22309657e-02  7.93291395e-02  1.13738441e-04
  3.09184938e-06  1.27196318e-03  4.67585574e-03  2.26962301e-06
 -7.08891099e-03 -1.11552960e-02 -6.12207831e-02 -6.79817297e-03
  2.03857430e-05  1.78650308e-02 -7.91872168e-03  2.27377589e-05
  1.68934713e-02  1.32632149e-02 -7.20250111e-02  3.28294276e-02
  1.69590556e-01 -2.42531016e-02  1.46203761e-02  1.33920194e-02
 -2.64782408e+00]
supnorm grad right now is: 2.647824078884397
Weights right now are: 
[  4.49509947  -7.43299658   4.8091616   -3.00726399  -5.22939819
   7.38974884  -4.31484465   1.47137567   1.71087753  56.45023508
  -3.62309492  15.01577065 -23.89644581  35.07168755 -21.66207123
  18.88360407   2.31078053  62.22970916   1.38332013  13.03945373
 -13.55549152   2.1409111  -14.21517291  15.60937816   1.70015493
  43.80968098  82.93883479   3.92123901   2.91924152   8.55726284
  -2.34833075 -10.06335332   2.95252133  46.55583885  79.09365298
   4.92912493  10.62927388  23.52445154   4.47957575 -12.02963352
 -30.37613279   3.50206967  -0.93155241 -29.92160615  32.74093184
  30.02678957  45.85781189  29.14466207   2.37125727 -13.96631241
   1.80101763   2.48623377  80.78379542  -1.42708917  40.41711415
  79.2060167    9.13724557  -5.27912651   7.61282391   2.79144398
   1.46440478  -3.73046482   9.46932544  -5.38003821  27.09493615]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.5491295750182
gradient value of function right now is: [ 1.46813025e-03  7.16309902e-03  9.28639002e-04 -9.97624900e-01
 -1.46813025e-03 -7.16309902e-03 -9.28639002e-04  9.97624900e-01
 -3.28840298e-05 -1.51298095e-03 -1.05710654e-05 -1.84833292e-07
  5.00644640e-05  6.44416378e-03  1.87414276e-05  7.29348688e-07
 -2.11835481e-05 -9.23432625e-04 -6.80503168e-06 -1.15243593e-07
  2.03998795e-04 -2.15389574e+00  6.48122976e-05 -1.74623086e-02
  4.34964860e-03 -1.37476979e-20  2.93610425e-04 -2.82663822e-20
  6.92415656e-01  4.85039995e-02  6.92616487e-01  8.70855209e-02
  1.33447899e-03 -3.98828602e-20  8.60229504e-05 -8.05396628e-20
  5.89160498e-02  4.67476622e-03  2.30764869e-01  6.87789719e-02
 -9.92797235e-04 -9.07303679e-02 -1.52768717e-01 -8.69532352e-04
 -6.85639916e-06 -1.59589188e-02 -1.39660430e-02 -5.14381098e-06
 -8.89548496e-03  3.81504135e-03  9.87314227e-02 -8.38247559e-03
  5.43826175e-04  1.56032308e-01  3.30686495e-02  4.68883235e-04
  6.68714087e-03  7.92937391e-02  5.92665240e-01 -7.56079921e-01
 -6.00531629e-01  5.54148161e-01  1.15861314e-02  7.60513920e-02
  4.01790894e+00]
supnorm grad right now is: 4.017908938699177
Weights right now are: 
[ 6.03366505e+00 -5.89096468e+00  6.44042020e+00 -3.11603172e+00
 -6.76796378e+00  5.84771694e+00 -5.94610324e+00  1.58014340e+00
  5.49079086e-02  5.56921435e+01 -5.45351046e+00  1.52666089e+01
 -2.34675632e+01  3.62445770e+01 -2.09506883e+01  1.90555948e+01
  2.31909215e-01  6.13468052e+01 -8.12533245e-01  1.32529664e+01
 -1.49401251e+01  2.04714791e+00 -1.54086179e+01  1.58885901e+01
  1.69929354e+00  4.38096810e+01  8.52852413e+01  3.92123901e+00
  2.61660663e+00  1.01598519e+01 -2.60477240e+00 -9.41360391e+00
  3.04278997e+00  4.65558388e+01  8.13592874e+01  4.92912493e+00
  1.11778489e+01  2.67009693e+01  4.01716992e+00 -1.22058121e+01
 -3.01166607e+01  5.52342299e+00 -2.21026281e+00 -2.98356612e+01
  3.48645021e+01  2.89686541e+01  4.57490753e+01  3.07939208e+01
  3.54843965e+00 -1.37492031e+01  1.09690688e+00  3.95761459e+00
  8.23797969e+01 -9.24845232e-01  4.15086148e+01  8.05485697e+01
  1.00614527e+01 -5.26383938e+00  7.55836110e+00  2.71916507e+00
  1.25884158e+00 -3.62708629e+00  1.03593524e+01 -5.40198745e+00
  2.72821068e+01]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.6733454008317
gradient value of function right now is: [ 3.93842147e-03  2.24025633e-02  2.30328459e-03  2.60736299e-01
 -3.93842147e-03 -2.24025633e-02 -2.30328459e-03 -2.60736299e-01
 -1.47066917e-04 -5.54055859e-03 -4.33391113e-05 -5.79161932e-07
  4.22166156e-04  2.13882008e-02  1.25983749e-04  2.17098565e-06
 -8.69190520e-05 -3.12920224e-03 -2.55957610e-05 -3.31442917e-07
  1.34364695e-03 -5.16671444e-01  3.96073307e-04 -1.04554687e-02
  3.07337091e-02 -1.94407554e-21  1.48865462e-03 -2.64261267e-21
 -3.78743637e-01  3.79240348e-04  1.29200216e-01  1.27312819e-02
  8.65352640e-03 -7.18439670e-21  4.21723553e-04 -1.11079921e-20
  2.90246584e-02  1.55387758e-03  1.38814402e-01  3.78751342e-02
  1.01231187e-04 -5.78721968e-02  5.66979113e-03 -2.95276689e-06
 -4.43721573e-06 -4.19082474e-03 -4.28305098e-03 -3.50760077e-06
 -7.02638201e-02 -6.06716347e-03 -2.47156692e-01 -6.21135895e-02
  4.93020451e-04  1.28647417e-01  1.83450326e-02  4.64139754e-04
  8.31625214e-02  1.71183379e-01  1.69537885e-01 -2.54432393e-01
 -2.24174472e-01  4.41391330e-01  8.40842708e-02  1.70607117e-01
  4.32697318e-01]
supnorm grad right now is: 0.5166714443357165
Weights right now are: 
[  6.96550592  -4.98482826   7.36060055  -2.89614879  -7.69980464
   4.94158052  -6.86628359   1.36026047   0.57047955  55.29480342
  -4.98835547  15.26427172 -25.21234489  38.01715114 -22.51095583
  19.50377324   0.53807796  60.85886109  -0.50287837  13.26296316
 -14.86164083   2.12409448 -15.2893017   15.84187186   0.95238384
  43.80968098  87.83361977   3.92123901   2.4279541    9.81683528
  -1.94563645 -10.44264914   2.36756446  46.55583885  83.78339207
   4.92912493  11.13845894  28.00459739   4.38876445 -12.79289002
 -29.96086999   4.90148971  -1.47879675 -29.70442158  34.24034078
  30.18983535  46.38844054  30.23182051   2.6885045  -11.09327921
   1.38120259   3.02925938  84.42886302  -0.85728102  41.9714913
  82.74111727   9.80902167  -5.38389507   7.78057358   2.94367505
   1.36334141  -3.57259424  10.13839777  -5.40487456  27.30051275]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.6827758719187
gradient value of function right now is: [ 6.67926300e-04  5.80500554e-03  3.94449153e-04  3.84752883e-01
 -6.67926300e-04 -5.80500555e-03 -3.94449153e-04 -3.84752883e-01
  2.14779064e-05 -1.01775844e-03  5.87760457e-06 -5.15498680e-08
 -3.42556351e-04  7.84084685e-03 -9.58998045e-05  3.80461232e-07
  1.39383248e-05 -6.11057180e-04  3.81961538e-06 -3.11035063e-08
 -1.71411578e-04  4.56233610e-01 -4.46652612e-05  5.21390712e-03
 -1.07454891e-02  1.73780576e-21 -1.77883783e-04  1.11767163e-20
 -4.34851223e-01 -1.79730574e-02 -2.05182643e-01 -2.31370612e-02
 -2.77531691e-03  4.37659930e-21 -4.02191184e-05  2.70345068e-20
 -1.26615631e-02  4.53112929e-04 -7.42379370e-02 -2.15625707e-02
  1.14686357e-03  7.29694833e-02  3.77129446e-02  1.02226395e-03
 -2.99749155e-07  5.69489241e-04  1.47780868e-03 -2.41218233e-07
  5.52621588e-03 -3.02463857e-03 -7.35454724e-02  6.01587113e-03
 -4.87208735e-04 -1.07736819e-01 -9.83026762e-03 -4.13648506e-04
  2.37454040e-02 -3.40267530e-02 -8.58881546e-02  1.88054851e-01
  1.21825231e-01 -2.14260572e-01  2.15770623e-02 -2.87028809e-02
 -3.26110435e+00]
supnorm grad right now is: 3.261104354640423
Weights right now are: 
[  6.88305313  -6.19025755   7.64086965  -3.04971375  -7.61735185
   6.14700981  -7.14655269   1.51382542  -0.20742706  57.1205088
  -5.76344018  15.45611631 -24.70157274  35.92764234 -21.82529396
  19.21947936  -0.77208438  62.15123184  -1.77914216  13.3930001
 -16.74864085   1.94446433 -17.08710611  16.0872163    0.89669172
  43.80968098  89.61987721   3.92123901   2.37787346   9.96552642
  -2.37811541 -10.86660443   2.29622932  46.55583885  85.38769397
   4.92912493  11.73358534  26.63312137   4.00493435 -12.96406145
 -31.46440373   3.23988852  -1.78464053 -31.0881095   34.74042902
  31.11528812  48.98249412  30.65174294   3.45665638 -11.96127339
   1.4628092    3.8137213   85.42219861  -2.17950663  40.84695365
  83.81859875   9.57741832  -6.12304698   8.1002732    3.12713325
   1.15531367  -4.05629809   9.84576727  -6.31122792  27.00030288]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.6280317179844
gradient value of function right now is: [ 4.16540326e-03  3.14200347e-02  2.63498918e-03  2.89801372e-01
 -4.16540326e-03 -3.14200347e-02 -2.63498918e-03 -2.89801372e-01
 -2.12425399e-04 -6.08048788e-03 -5.59399546e-05 -1.18143660e-06
  1.47843274e-03  3.14172909e-02  3.84239728e-04  6.08221005e-06
 -1.41939145e-04 -3.91368502e-03 -3.73814257e-05 -7.66571164e-07
  1.57924925e-03 -5.65957681e-01  4.20442250e-04 -5.14946503e-03
  5.85107044e-02 -4.43005113e-22  1.43414308e-03 -5.51597171e-22
 -5.74152904e-01  6.07888639e-02  1.74200360e-01  9.64287281e-02
  1.44875304e-02 -1.73941092e-21  3.64320118e-04 -2.99243885e-21
  2.71395123e-02  2.99636401e-03  6.23145312e-02  2.51252606e-02
  6.71466300e-04 -3.56117347e-02  4.02999939e-02  6.73284907e-04
 -3.16618849e-06 -1.00371429e-02 -1.23302438e-02 -2.53028620e-06
 -9.10879629e-02 -6.70914138e-03 -2.99596052e-01 -9.38241134e-02
  1.56743338e-04  5.36827389e-02  2.21481302e-02  1.35358702e-04
  8.80919903e-02  1.55044389e-01  3.12673696e-01 -4.14022882e-01
 -1.23793355e-01  2.57193213e-01  9.47935041e-02  1.64592441e-01
 -7.73260571e-01]
supnorm grad right now is: 0.7732605705267876
Weights right now are: 
[  7.50660526  -5.50372538   8.28643241  -3.00171814  -8.24090398
   5.46047764  -7.79211546   1.46582982   0.28762171  57.07301788
  -5.3399313   15.44427929 -23.9408349   36.63169005 -20.89943824
  20.03571448  -0.13611938  61.99012038  -1.18820658  13.39478755
 -16.0137876    2.24492162 -16.41237243  16.22901209   1.81816063
  43.80968098  92.02890163   3.92123901   2.44112961  11.67567636
  -1.91599097 -10.121757     3.29369512  46.55583885  87.56953778
   4.92912493  10.60700552  27.04721051   4.4440126  -14.77316455
 -29.47176541   3.54257829  -1.2983764  -29.28863433  34.15955727
  32.99978227  49.6784693   30.12545285   2.28178694 -12.08474649
   1.54950865   2.48695924  90.68607083  -1.28962845  41.92308098
  89.13911431  10.77776075  -5.4804683    8.26410862   2.85409723
   1.23030522  -3.70098745  10.9694505   -5.64193488  27.20711789]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.0888173085232
gradient value of function right now is: [-1.67017452e-03 -1.19823718e-02 -1.15273440e-03 -4.95548554e-01
  1.67017452e-03  1.19823718e-02  1.15273440e-03  4.95548554e-01
  1.73312256e-04  1.85947170e-03  4.98748667e-05  2.99268814e-07
 -1.35249133e-03 -1.13713273e-02 -3.98783525e-04 -2.50569202e-06
  1.25885873e-04  1.32461859e-03  3.61215386e-05  2.06059420e-07
 -1.48311439e-03 -5.62491745e-01 -4.59128441e-04  1.80989786e-03
 -5.77813141e-02 -3.35229052e-16 -3.08338814e-03 -4.37368519e-15
  5.25113561e-01  1.31731304e-02  2.27768975e-01  2.62542935e-02
 -1.62069963e-02 -2.99919057e-16 -8.77221520e-04 -3.40994373e-15
  3.20193374e-03  2.11056181e-03 -3.32387961e-02 -4.49410288e-03
 -9.66570568e-04  3.11592234e-02 -7.92170038e-02 -8.28344821e-04
 -2.97885335e-06 -4.19104024e-03 -4.53694927e-03 -2.37467399e-06
  2.81637866e-02  1.71821564e-02  3.06351935e-01  2.65301947e-02
 -1.88573188e-04 -6.78730848e-02  3.62868287e-03 -1.71067297e-04
 -4.80066247e-02 -4.25748428e-02  1.31290711e-01 -7.58885424e-02
 -3.44496434e-01 -1.71885898e-01 -4.29118491e-02 -3.82540225e-02
 -8.05335300e-01]
supnorm grad right now is: 0.8053353003602691
Weights right now are: 
[  6.84813731  -6.21642948   7.74350766  -3.18569308  -7.58243603
   6.17318175  -7.2491907    1.64980475   2.23125583  58.66437697
  -3.52334865  15.44986814 -26.30336391  36.89756482 -23.10203852
  20.49788244   1.71859106  63.42906527   0.56269894  13.39795366
 -18.67685227   1.96718229 -18.98045719  16.09078778  -0.51286688
  43.80968098  91.08950841   3.92123901   2.77160039  10.62799881
  -2.37351772 -10.84327055   1.04258988  46.55583885  86.59817343
   4.92912493  11.53912021  26.4739666    4.78316204 -15.39755696
 -30.16896261   3.31056213  -1.52453999 -30.0887691   33.18013944
  33.54159769  49.69868941  29.32865664   3.87823943 -10.31368509
   3.74623875   3.93229868  92.40975534  -1.64527478  42.78465911
  91.02815629   9.67214651  -6.3738466    9.03568056   3.03966743
   1.18609364  -3.68940743   9.94878441  -6.46447776  26.93747407]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.5282405034666
gradient value of function right now is: [ 7.79640521e-04  9.81335571e-03  4.70961809e-04  1.12592564e+00
 -7.79640521e-04 -9.81335571e-03 -4.70961809e-04 -1.12592564e+00
 -7.05743828e-05 -1.10398611e-03 -1.72358494e-05 -1.16125164e-07
  8.06398870e-04  1.20008519e-02  1.95807508e-04  1.43156774e-06
 -4.65207767e-05 -7.00014879e-04 -1.13519477e-05 -7.22266810e-08
  2.70938691e-03  1.59247168e+00  6.80131867e-04  4.46086476e-04
  6.59866963e-02  6.98590787e-19  2.31149733e-03  1.16369515e-17
 -1.20807994e+00 -4.40693029e-02 -6.40348205e-01 -6.83799234e-02
  1.58671646e-02  1.29654124e-18  5.75394260e-04  1.32593446e-17
 -1.45976768e-02 -2.78733187e-03  6.53017216e-03 -8.17708310e-03
  3.13465152e-03  2.12873922e-02  1.50407692e-01  2.96041360e-03
  1.05214356e-06  7.34245535e-03  8.23059921e-03  8.68146880e-07
 -3.75277322e-02 -2.41282929e-02 -3.99840347e-01 -3.71505620e-02
  1.79579541e-04  3.98020863e-02 -1.31094070e-02  1.61090038e-04
  8.29883677e-02  9.80299002e-02 -2.89922789e-01  2.97622125e-01
  3.92743571e-01  3.26533227e-02  8.12087768e-02  9.62263990e-02
 -4.31984514e+00]
supnorm grad right now is: 4.319845136930346
Weights right now are: 
[  6.17727468  -5.65510694   7.15412887  -3.12046934  -6.9115734
   5.6118592   -6.65981192   1.58458101   1.99132125  60.00635361
  -3.55719509  15.4199425  -22.8411921   38.64486319 -19.29893339
  21.55937884   1.44865954  64.64696193   0.50496757  13.37927654
 -18.06603102   2.15795534 -18.17511336  15.1799157    1.34014188
  43.80968098  92.53433835   3.92123901   2.30065115  10.98407463
  -2.41002289 -11.26334173   2.92040383  46.55583885  87.89528292
   4.92912493  11.41251552  24.88911714   5.47015025 -15.62820046
 -28.24065651   3.26106906  -1.44105351 -28.19277455  33.64542338
  35.52556139  50.43931578  29.69948452   2.74624649  -9.8446114
   2.85065861   2.75352515  94.45972273  -0.70107973  42.59381755
  93.01309129  11.85440062  -5.73889246   7.7356254    2.93887462
   1.63764016  -3.94939613  12.04551491  -5.85768245  27.15786287]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.0166185976304
gradient value of function right now is: [-6.59338613e-03 -2.90848296e-02 -4.98585023e-03 -1.25405844e+00
  6.59338613e-03  2.90848296e-02  4.98585023e-03  1.25405844e+00
  4.42702392e-04  6.16303906e-03  1.14825262e-04  1.28012832e-06
 -1.47880308e-03 -2.01832642e-02 -3.82139406e-04 -4.79608625e-06
  3.73117193e-04  4.98471680e-03  9.67356235e-05  1.02385711e-06
 -1.23965490e-03 -1.63192022e+00 -3.29684315e-04 -5.11284456e-03
 -5.88900173e-02 -2.18690720e-17 -2.53873115e-03 -6.34809149e-17
  9.60092017e-01  1.58525868e-01  7.58892318e-01  2.15587366e-01
 -1.35418168e-02 -2.22981645e-17 -5.96893535e-04 -6.86653492e-17
  3.54976652e-02  7.03641536e-03  5.07616814e-02  2.87104204e-02
 -2.16804596e-03 -3.79723204e-02 -1.31188194e-01 -1.98693472e-03
 -6.69186693e-06 -1.96824057e-02 -2.22740300e-02 -5.34539004e-06
  4.44861899e-02  2.35471741e-02  2.92313951e-01  4.34747046e-02
  3.18078444e-05  3.71980016e-02  3.06129110e-02  2.67527533e-05
 -8.80053901e-02 -4.62343947e-02  6.62265717e-01 -7.68537737e-01
 -4.29445037e-01  8.39622819e-02 -8.33088151e-02 -4.50141868e-02
  5.28355317e+00]
supnorm grad right now is: 5.283553169829297
Weights right now are: 
[  6.93107951  -5.52870483   8.07684626  -3.05187826  -7.66537823
   5.48545709  -7.58252931   1.51598994   1.74335369  60.29170722
  -3.73459621  15.39926742 -23.77817289  39.23591141 -20.0832366
  21.71345583   1.14788919  64.62073289   0.4063135   13.36188981
 -19.60664508   2.17463546 -19.71750204  16.13432138   0.42625565
  43.80968098  93.3029696    3.92123901   2.8944887   11.68762575
  -2.11243726 -10.79106454   2.01309921  46.55583885  88.36117899
   4.92912493  11.1820698   26.07359606   4.99879967 -17.24402159
 -30.72995843   3.16283842  -0.95297476 -30.74537556  33.59053282
  35.00661075  48.81789536  29.65910182   4.04176395 -11.36187007
   3.21737107   4.05507946 100.19426035  -0.96885019  44.62871395
  98.83312575   9.88124324  -7.66340328   8.16800452   2.50485859
   1.68064757  -3.88180374  10.09301679  -7.84054258  27.2251333 ]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.744515072594
gradient value of function right now is: [-2.55300523e-03 -1.37364932e-02 -1.94325932e-03 -3.19554648e-01
  2.55300523e-03  1.37364932e-02  1.94325932e-03  3.19554648e-01
  2.03500853e-04  2.19094366e-03  4.54981813e-05  1.50211844e-07
 -1.00892235e-03 -1.14090816e-02 -2.24474599e-04 -7.17605596e-07
  1.76904157e-04  1.81256689e-03  3.95498186e-05  1.25958642e-07
 -5.75939385e-04 -6.37598493e-01 -1.29312485e-04 -8.60760657e-03
 -3.41550886e-02  3.20734025e-21 -1.00705630e-03  7.25364728e-20
  3.70546915e-01  6.95757801e-02  1.79961426e-01  1.06561074e-01
 -6.63299822e-03  8.80347023e-21 -1.97573742e-04  1.40788670e-19
  5.07521214e-02  6.79834937e-03  9.57042904e-02  5.31609343e-02
  3.15996183e-04 -1.99527692e-02  1.01679058e-02  2.84701960e-04
 -1.70751506e-06 -1.54768484e-02 -8.65854878e-03 -1.36962804e-06
  4.79962641e-02  7.57603683e-05  1.23435821e-01  4.69671047e-02
 -8.10986299e-06  6.29170779e-02  1.87997106e-02 -8.38571823e-06
 -4.55104499e-02 -6.62458050e-02  5.13101439e-01 -7.42943467e-01
 -1.86542621e-01  2.20959347e-01 -4.39481179e-02 -6.37059460e-02
  2.63897911e+00]
supnorm grad right now is: 2.638979110907353
Weights right now are: 
[ 6.15601547e+00 -6.53134665e+00  7.38765848e+00 -2.99314550e+00
 -6.89031419e+00  6.48809891e+00 -6.89334152e+00  1.45725718e+00
  5.84341747e-01  6.17337259e+01 -4.84314375e+00  1.53942884e+01
 -2.41481964e+01  3.85023303e+01 -2.02420886e+01  2.20867887e+01
  6.81064785e-03  6.58807775e+01 -6.58156158e-01  1.33590423e+01
 -1.83225369e+01  2.43646374e+00 -1.84092226e+01  1.57145315e+01
  1.09108076e+00  4.38096810e+01  9.61337859e+01  3.92123901e+00
  2.88449753e+00  1.20105161e+01 -2.06629767e+00 -1.12489491e+01
  2.75924210e+00  4.65558388e+01  9.10886992e+01  4.92912493e+00
  1.19745701e+01  2.63486370e+01  5.31635822e+00 -1.72983321e+01
 -3.18307811e+01  3.56448128e+00 -2.68189261e-01 -3.19304400e+01
  3.44263204e+01  3.61915790e+01  5.34007662e+01  3.03044697e+01
  2.65884218e+00 -1.37309779e+01  2.33438299e+00  2.63936573e+00
  1.01560744e+02 -1.87094912e+00  4.26007375e+01  1.00333812e+02
  1.02791949e+01 -7.19574403e+00  8.21541993e+00  2.40090637e+00
  1.63895071e+00 -3.58991723e+00  1.05080025e+01 -7.32682321e+00
  2.73181215e+01]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.8452250171877
gradient value of function right now is: [ 6.68162089e-04  7.56825356e-03  4.35348030e-04 -1.80974004e-01
 -6.68162089e-04 -7.56825356e-03 -4.35348030e-04  1.80974004e-01
 -1.76624187e-05 -9.31420479e-04 -3.56528145e-06 -4.40975413e-08
  7.54315655e-05  9.87732370e-03  1.63453229e-05  4.58718924e-07
 -1.30946236e-05 -6.61709696e-04 -2.64271808e-06 -3.15701011e-08
  6.07282509e-04 -9.02118231e-01  1.22542855e-04 -1.66862101e-03
  1.33449432e-02 -3.86809051e-23  5.80654459e-04 -6.56598909e-23
 -3.02179044e-03  7.00942169e-02  4.66858221e-01  9.96780465e-02
  2.60047358e-03 -1.60071950e-22  1.13482315e-04 -2.79114863e-22
  1.10781647e-02  2.83933121e-03  1.74286856e-02  8.69318258e-03
 -1.48920082e-03 -4.24505776e-02 -4.45849209e-03 -1.24563411e-03
 -6.55461154e-06 -8.54028892e-03 -1.31629020e-02 -4.66035005e-06
 -2.75320949e-02  2.84266730e-03 -1.23275698e-01 -2.90277076e-02
  1.43428711e-04  1.65576655e-02  1.89858887e-02  1.15181914e-04
  4.29603814e-02  1.05720128e-01  2.99219748e-01 -3.42247716e-01
 -1.06343540e-01  1.25253852e-01  4.62570154e-02  1.02878361e-01
  1.22870077e+00]
supnorm grad right now is: 1.228700773859491
Weights right now are: 
[  6.24941612  -6.11616869   7.48339272  -3.05544105  -6.98371484
   6.07292095  -6.98907577   1.51955273  -0.19897013  62.00104098
  -5.56045656  15.36683256 -24.51639077  39.53771171 -20.44144202
  22.36482129  -1.01179093  66.07191615  -1.58668262  13.34131494
 -18.70533703   2.18097102 -18.64527912  15.80466496   0.99975865
  43.80968098  98.01925048   3.92123901   2.32117092  12.09001395
  -1.67955955 -11.30482053   2.80184672  46.55583885  92.99174443
   4.92912493  11.8429635   28.35393602   4.8422142  -17.97203212
 -34.50471707   3.49316055  -0.9915126  -34.61794948  33.20426828
  35.9357006   50.69278587  29.29796902   3.27148037 -13.71292788
   1.35796158   3.30368976 109.72371535  -1.23675443  45.61610496
 108.73669875  10.08352702  -5.72841159   8.28558389   2.734409
   1.34031032  -3.99502155  10.37029188  -6.01044098  27.30586725]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1945.4179430996053
gradient value of function right now is: [-2.88590541e-03 -1.64582711e-02 -2.20961423e-03 -1.96259276e+00
  2.88590541e-03  1.64582711e-02  2.20961423e-03  1.96259276e+00
  4.54679059e-05  2.35403509e-03  9.08291110e-06  3.43649154e-08
 -2.76665078e-04 -1.63678298e-02 -5.50064498e-05 -2.49133025e-07
  4.22233298e-05  2.01593699e-03  8.43151600e-06  2.98052477e-08
 -1.26182749e-04 -2.91018678e+00 -2.54531560e-05 -1.41088610e-02
 -8.59426696e-03 -5.14791218e-23 -2.00295378e-04 -2.43968906e-22
  1.76086045e+00  2.00577539e-02  1.47463660e+00  5.52368927e-02
 -1.47731419e-03 -2.47932158e-22 -3.53713052e-05 -1.12569064e-21
  5.65644310e-02  2.81776530e-03  1.77864921e-01  6.71600822e-02
 -5.39152900e-03 -1.74314030e-01 -3.27176027e-01 -4.80462748e-03
 -2.80862289e-06 -7.45604648e-03 -9.18007016e-03 -2.09343232e-06
  3.40017045e-02  1.47632657e-02  3.18113410e-01  3.26456296e-02
  4.50311237e-04  2.13902766e-01  3.96196005e-02  3.95369980e-04
 -7.75524174e-02  3.29171055e-02  5.00005933e-01 -5.69162860e-01
 -9.09889647e-01  7.48657787e-01 -6.79770636e-02  2.89913171e-02
  9.45656340e+00]
supnorm grad right now is: 9.456563397533511
Weights right now are: 
[  5.55340553  -6.69857855   6.92996276  -3.1462536   -6.28770425
   6.65533081  -6.43564581   1.61036527  -1.13158142  63.5242934
  -6.36333604  15.38911205 -24.08271686  39.54750505 -19.73449928
  22.45006835  -1.99973944  67.42197514  -2.35913185  13.36059715
 -18.77009481   2.14758819 -18.82467319  14.97328597   1.27242567
  43.80968098  99.19848789   3.92123901   2.9374164   11.18607153
  -2.0003597  -11.9895181    3.04284515  46.55583885  93.66734438
   4.92912493  13.15496852  26.75042034   5.77384901 -17.69976867
 -33.1415063    3.92126528  -1.32380499 -33.13568224  33.2810209
  36.07430523  53.42694602  29.28333951   2.74994272 -16.74416313
   1.25896549   2.89416319 111.03515721  -1.26407602  43.70679465
 110.41048176  10.88928841  -6.13032883   7.88789243   2.89087015
   1.47091953  -3.83585678  11.24600634  -6.24312016  27.50477938]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.0150716627245
gradient value of function right now is: [ 2.68072461e-03  2.21920827e-02  1.88612359e-03  1.77798429e+00
 -2.68072461e-03 -2.21920827e-02 -1.88612359e-03 -1.77798429e+00
 -8.37622513e-05 -3.11544973e-03 -1.33823104e-05 -1.33255961e-07
  6.99708035e-04  2.29866688e-02  1.10705929e-04  9.60024765e-07
 -6.88788656e-05 -2.43023172e-03 -1.09977847e-05 -1.04857623e-07
  1.11978203e-03  1.93554414e+00  1.80775971e-04  2.36969201e-03
  3.62996800e-02  8.79271147e-23  9.92675935e-04  1.37388390e-22
 -2.07485744e+00 -6.15531988e-02 -1.13243182e+00 -8.62283223e-02
  5.38362010e-03  3.42994744e-22  1.50876432e-04  5.31432431e-22
 -1.93735728e-02 -2.62971922e-03 -2.37987665e-02 -1.49028924e-02
  2.57954874e-03  1.68615368e-02  2.40160711e-01  2.19102807e-03
  9.11093840e-06  7.50353713e-03  1.04644150e-02  6.24558394e-06
 -6.81214201e-02 -2.30683092e-02 -4.90950754e-01 -6.72700340e-02
  1.68659681e-04 -1.95054919e-03 -1.82040189e-02  1.41253557e-04
  1.44321171e-01  1.82318739e-01 -3.50656331e-01  3.06750461e-01
  4.88227366e-01 -9.31262343e-02  1.39194951e-01  1.83093675e-01
 -4.40874278e+00]
supnorm grad right now is: 4.4087427781090085
Weights right now are: 
[  5.99935183  -5.62909158   7.33149041  -2.94115663  -6.73365056
   5.58584384  -6.83717346   1.4052683   -0.29614787  63.15988802
  -5.28529673  15.37172778 -23.97764228  41.12387706 -19.55081311
  22.92648373  -1.16019938  67.01750198  -1.24692394  13.35278183
 -18.48077847   2.44301795 -18.35520355  15.70712907   1.70045117
  43.80968098 101.66924574   3.92123901   2.48242628  11.16314768
  -2.24420415 -11.74684715   3.70950842  46.55583885  96.16325231
   4.92912493  12.16679128  26.77350846   4.96344797 -18.40147756
 -36.44180661   2.70950197  -1.22160646 -36.44970582  32.74317694
  36.89083427  49.79045292  28.8691866    3.17815367 -15.6521547
   1.49061773   3.38465104 113.8551441   -1.12786779  46.82376051
 113.26531748  10.45529694  -5.10432536   8.15925654   3.0858325
   1.74558812  -4.19103478  10.84952192  -5.33399809  27.28257658]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.005924006652
gradient value of function right now is: [-6.44404835e-03 -2.68803014e-02 -5.24591130e-03 -6.59920637e-01
  6.44404835e-03  2.68803014e-02  5.24591130e-03  6.59920637e-01
  2.22840598e-04  4.16276331e-03  3.87575462e-05  2.63631084e-07
 -9.64749197e-04 -1.90783421e-02 -1.67336536e-04 -1.48348512e-06
  2.15531974e-04  3.86907461e-03  3.74473618e-05  2.42190734e-07
 -6.90012288e-04 -2.34588296e-01 -1.21647075e-04  7.96927517e-03
 -3.63386996e-02 -3.29029666e-20 -1.32967197e-03 -1.40346890e-19
  7.53928227e-01  1.04659578e-02  3.35261134e-01  1.19477532e-02
 -5.45697393e-03 -5.03417241e-20 -2.03703854e-04 -2.02656188e-19
 -2.30077350e-02 -8.72765565e-04 -1.06114585e-01 -2.92850979e-02
 -1.63584671e-03  6.49791590e-02 -1.27724867e-01 -1.55594577e-03
 -3.09666005e-06  1.56907678e-03 -5.81725330e-03 -2.39698416e-06
  3.49911413e-02  1.64642148e-02  2.29957215e-01  3.53549807e-02
 -2.99997542e-04 -1.29752214e-01 -2.79694079e-03 -2.41112159e-04
 -7.34153469e-02 -7.04527725e-02 -4.45058002e-02  2.39896110e-01
 -1.50439965e-01 -3.36148401e-01 -7.54666610e-02 -6.73884123e-02
  2.36801673e-01]
supnorm grad right now is: 0.7539282271861019
Weights right now are: 
[  5.32282303  -6.23190627   6.76168368  -3.28023896  -6.05712175
   6.18865853  -6.26736673   1.74435063  -0.99884116  64.77948544
  -5.69354585  15.37780653 -24.02777062  41.09485656 -19.33145942
  22.98122168  -2.08652961  68.42328319  -1.74518149  13.35697259
 -20.97081644   2.2362725  -20.72230987  15.65774637   0.71755025
  43.80968098 102.36104086   3.92123901   2.99196696  11.32956203
  -1.98908103 -11.86959272   2.6902565   46.55583885  96.6756383
   4.92912493  12.3921285   28.00858435   4.84886453 -18.25793739
 -34.76908185   4.43314995  -0.88305707 -35.01941199  33.38834877
  37.15017377  51.49679006  29.35100067   3.59599596 -13.40934919
   2.68768205   3.7798262  117.79516255  -1.53029552  46.41492836
 117.23759313   9.22627095  -7.63917579   8.51003306   2.73418779
   1.22569797  -4.36161097   9.42717027  -7.93180907  27.01064821]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1945.6642542795748
gradient value of function right now is: [ 8.03090892e-03  2.68236645e-02  6.87994672e-03  7.78153081e-01
 -8.03090892e-03 -2.68236645e-02 -6.87994672e-03 -7.78153081e-01
 -2.21594376e-04 -4.59842013e-03 -2.99764739e-05 -1.29403584e-07
  7.42003437e-04  1.66661413e-02  9.98439564e-05  5.77175130e-07
 -2.28416136e-04 -4.58894964e-03 -3.08855217e-05 -1.28700781e-07
  3.91319414e-04  1.33934660e+00  5.32377990e-05  6.00029903e-03
  2.49756610e-02  2.05349549e-23  7.26250780e-04  4.46525993e-23
 -5.58388523e-01 -5.49415718e-02 -5.71104151e-01 -7.74646979e-02
  2.80342079e-03  6.96761033e-23  8.30742396e-05  1.43200808e-22
 -1.79153488e-02 -4.04048944e-04 -7.86981696e-02 -1.97951830e-02
  2.34663060e-03  9.70371405e-02  1.43551922e-01  2.03648262e-03
  1.50716140e-06  4.62812521e-03  5.47540413e-03  1.06644637e-06
 -3.83746180e-02 -9.13199441e-03 -1.68117939e-01 -3.92256244e-02
 -2.15008543e-04 -1.07999767e-01 -1.75402002e-02 -1.69748427e-04
  6.02599814e-02  9.76277801e-03 -2.60652655e-01  3.82808690e-01
  3.42560447e-01 -3.46566962e-01  5.76094547e-02  1.88268074e-02
 -7.33784758e+00]
supnorm grad right now is: 7.337847583806076
Weights right now are: 
[  5.77110095  -6.91739153   7.38267538  -3.25269264  -6.50539967
   6.8741438   -6.88835842   1.71680432  -1.01658144  65.51755025
  -5.52097101  15.36147055 -25.2368636   40.48874225 -20.36707423
  23.0827206   -1.98865635  68.84764613  -1.43820308  13.34080157
 -18.71541889   2.25742544 -18.44642143  15.2526455    1.48463088
  43.80968098 106.36502743   3.92123901   3.19261729  11.33877068
  -2.24168683 -12.099972     3.66769763  46.55583885 100.65368592
   4.92912493  13.18151342  29.85939172   4.83367924 -18.06567236
 -37.51546579   4.14250189  -1.03475491 -38.04642093  33.44778951
  37.00251802  51.75703134  29.42557591   2.2812313  -14.2748354
   1.82010953   2.41834112 121.12333518  -0.89273416  47.48023666
 120.71992227  10.83210625  -6.09583166   8.59877879   2.79514708
   1.70027087  -3.77309555  11.15356374  -6.34614518  26.79708025]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.2076630810361
gradient value of function right now is: [ 2.26354271e-03  1.00558598e-02  1.83497160e-03 -1.03005891e+00
 -2.26354271e-03 -1.00558598e-02 -1.83497160e-03  1.03005891e+00
 -5.89970783e-05 -2.51868480e-03 -8.50285680e-06 -2.15165797e-07
  1.22946126e-04  6.14387452e-03  1.86104111e-05  5.86375835e-07
 -5.48436003e-05 -2.32740183e-03 -7.90551566e-06 -1.98474477e-07
  3.18297996e-04 -9.31165615e-01  4.57905980e-05  5.81250229e-03
  9.10280634e-03 -2.44320036e-25  3.97554106e-04 -7.50683806e-25
  1.26180754e+00  1.22399685e-02  9.59368377e-01  1.61365481e-02
  1.18824558e-03 -1.08566316e-24  5.13534316e-05 -3.08304088e-24
 -3.07222282e-02 -4.63442040e-03 -7.25881387e-02 -2.97217428e-02
 -2.32036816e-03  3.01458439e-03 -2.05762012e-01 -1.93340455e-03
 -6.55761208e-07  5.19223852e-03 -5.80811529e-03 -6.07879024e-07
 -2.96698752e-03  1.36940303e-02  1.65293375e-01 -1.79853431e-02
 -2.38086167e-04 -7.48961931e-02  4.10490844e-03 -1.40815620e-04
  1.38203109e-02  4.62265731e-02 -1.08992402e-01  2.73200418e-01
 -4.25033599e-01 -1.10178583e-01  2.21624845e-02  6.68218353e-02
  3.69576478e+00]
supnorm grad right now is: 3.6957647784939627
Weights right now are: 
[  7.8146384   -5.53582965   9.50756102  -3.19448886  -8.54893712
   5.49258191  -9.01324407   1.65860054  -0.47123209  64.55711519
  -5.04127119  15.38904789 -25.56197743  41.80207173 -20.64466815
  23.12613546  -1.35403353  67.63879206  -0.83991353  13.36713987
 -18.78440136   2.37852652 -18.603387    16.35147159   1.46853186
  43.80968098 107.66534796   3.92123901   2.73710965  12.22306763
  -1.98136263 -11.70986577   3.64004264  46.55583885 101.78367062
   4.92912493  11.74990979  28.61166316   3.93804002 -19.10786127
 -37.51927344   2.90279778  -3.08231891 -38.41501536  34.4689856
  38.45258551  54.1183204   30.14776324   3.45045389 -15.11658746
   1.03164922   3.24409324 123.44910817  -1.37973259  46.24003728
 122.97863515  12.05917904  -5.74055678   8.61249856   3.36833908
   0.99168307  -4.6078139   11.83144156  -6.58072105  27.39955377]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.536927396746
gradient value of function right now is: [-1.75750880e-04 -4.31790790e-03 -1.33231797e-04 -1.49541704e-01
  1.75750880e-04  4.31790790e-03  1.33231797e-04  1.49541704e-01
  8.12190980e-05  2.42895528e-04  1.05380522e-05  1.56694393e-08
 -1.86980021e-03 -4.43211588e-03 -2.42032753e-04 -2.98088454e-07
  7.21300529e-05  2.10072737e-04  9.35820058e-06  1.35612338e-08
 -1.68096783e-03  6.05481234e-02 -2.18457544e-04  6.57452456e-03
 -7.76477527e-02 -2.67179599e-22 -1.37408778e-03 -1.39820837e-21
  2.52504132e-01 -8.47509524e-03  4.61763118e-02 -1.42571037e-02
 -9.21826945e-03 -6.73600474e-23 -1.63766572e-04 -6.76600094e-22
 -3.57656946e-02 -5.60578770e-03 -7.52203536e-02 -3.58041705e-02
 -1.95817225e-04  4.68941246e-02 -2.12236632e-02 -1.88136441e-04
 -9.70238038e-07  7.22764023e-03 -1.10987708e-03 -5.96139777e-07
  5.39041775e-02  6.87441767e-03  1.71459134e-01  6.10538480e-02
 -1.61216787e-04 -8.73400844e-02 -4.00024402e-03 -9.36442348e-05
 -4.75009896e-02 -6.52295574e-02 -2.34622630e-01  3.84174224e-01
  1.42765163e-02 -1.91147607e-01 -6.16722038e-02 -7.29797102e-02
  2.40440433e+00]
supnorm grad right now is: 2.4044043265464365
Weights right now are: 
[  6.89736365  -6.02979141   8.57005737  -2.83024897  -7.63166238
   5.98654367  -8.07574041   1.29436065   0.44296224  65.62689751
  -4.07252493  15.43199529 -25.75989985  41.66811096 -20.72022217
  23.17303846  -0.44337608  68.66265984   0.13737763  13.40864251
 -19.92089063   2.20533069 -19.68595105  15.73910536   1.14946174
  43.80968098 109.08011478   3.92123901   2.36734843  12.39502042
  -2.01516944 -11.48681803   3.34149349  46.55583885 103.09196828
   4.92912493  11.93089958  26.90634366   4.59461542 -19.2425299
 -39.64127586   2.39603187  -1.70632465 -41.06596584  34.37342057
  39.86569977  52.51776047  30.10963849   2.62730381 -15.00291594
   2.73759793   3.00359259 125.98803976  -1.46042451  48.03392839
 126.25986846   9.22121423  -7.31562539   8.20295713   3.36782886
   1.06955327  -4.68747652   9.60301654  -8.02898236  27.36897282]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1945.5275701244832
gradient value of function right now is: [ 5.79711717e-04  1.07989074e-02  4.19175512e-04  2.25005149e+00
 -5.79711717e-04 -1.07989074e-02 -4.19175512e-04 -2.25005149e+00
 -3.20175206e-05 -9.55141120e-04 -5.08559293e-06 -2.45945309e-08
  6.15564084e-04  1.55686167e-02  9.63347042e-05  4.00901631e-07
 -2.77329540e-05 -7.95927911e-04 -4.40250181e-06 -2.05841985e-08
  1.75849012e-03  2.45601546e+00  2.83124340e-04  4.85465605e-03
  5.09918451e-02  1.14032757e-23  1.40795108e-03  4.93525395e-23
 -2.03941358e+00 -5.73646874e-02 -1.05232916e+00 -7.77154756e-02
  7.74745632e-03  5.59240839e-23  2.20399174e-04  1.90782770e-22
 -2.38619831e-02  2.16656866e-03 -6.42507877e-02 -1.97672764e-02
  2.46952036e-03  9.19818517e-02  1.78786382e-01  1.85559194e-03
  8.61135754e-06 -1.16766071e-04  1.09916740e-02  4.34620152e-06
 -6.80039036e-02 -2.80982052e-02 -5.01134654e-01 -6.82505213e-02
 -3.12863514e-04 -1.18924521e-01 -2.46142324e-02 -1.83523198e-04
  1.32373108e-01  7.81201439e-02 -1.08366958e-01  2.52884721e-02
  6.25100794e-01 -2.36063771e-01  1.31701125e-01  1.06261273e-01
 -7.06482777e+00]
supnorm grad right now is: 7.0648277690397165
Weights right now are: 
[  6.96127123  -6.33933236   8.71967119  -2.7609835   -7.69556995
   6.29608463  -8.22535424   1.22509518  -0.38810825  66.23077364
  -4.81412399  15.43110726 -25.92528195  41.47505265 -20.6506053
  23.30859657  -1.27529553  69.12870984  -0.60095857  13.40619562
 -20.6075387    1.96935965 -20.56295641  15.12653291   1.26191535
  43.80968098 110.71554595   3.92123901   2.22012562  11.94227287
  -2.51637326 -12.44169183   3.29884128  46.55583885 104.11900168
   4.92912493  12.47488891  29.6718995    5.05558933 -18.74368571
 -37.12343205   1.81587268  -1.82341405 -38.94518009  35.26984343
  39.79597498  54.38446678  30.50335205   3.4309886  -13.06250392
   1.99869004   3.80415942 131.67202541  -0.87823608  47.2402681
 131.64716679  10.84957199  -6.46162521   8.71413997   2.88386558
   1.7731011   -5.05996936  11.55761892  -7.04881687  27.02672755]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.7234704738225
gradient value of function right now is: [ 1.29877811e-03  4.28102425e-03  1.12723052e-03 -1.32699111e-02
 -1.29877811e-03 -4.28102425e-03 -1.12723052e-03  1.32699111e-02
  6.67871979e-05 -1.19662541e-03  8.51427823e-06 -1.20970216e-07
 -3.41795727e-04  2.86220890e-03 -4.47337224e-05  7.44592190e-07
  6.87909798e-05 -1.20742873e-03  8.78299944e-06 -1.18149458e-07
 -1.17881150e-04 -3.05918187e-02 -1.45210639e-05  8.65894722e-03
 -1.07857613e-02  1.58276111e-24 -8.55667172e-05  1.62010870e-23
  1.46785725e-01  2.27399870e-02  1.39157861e-01  3.00066823e-02
 -1.16425795e-03  4.65687293e-24 -7.03781296e-06  4.05286869e-23
 -4.42514949e-02 -4.94524978e-03 -9.92019686e-02 -3.93172036e-02
  1.61154103e-04  7.25080000e-02  5.88030129e-02  1.33428066e-04
 -8.60841697e-07  4.61426825e-03 -5.19735242e-03 -3.85906864e-07
  1.60729857e-02  1.15632432e-02  1.72677838e-03  1.65012963e-02
 -3.04132206e-04 -1.20650054e-01 -2.37814815e-03 -1.61012245e-04
  1.25079576e-02 -2.60812297e-02 -1.57596883e-01  3.45764219e-01
  1.06171002e-01 -2.84168705e-01  1.01033981e-02 -1.09550427e-02
 -2.07984656e+00]
supnorm grad right now is: 2.07984655559843
Weights right now are: 
[  8.19432955  -7.03242335  10.11734158  -2.99014722  -8.92862827
   6.98917561  -9.62302463   1.4542589   -1.11373708  66.22168041
  -5.32380536  15.41614127 -26.32750444  40.5227233  -20.82168259
  23.46606139  -2.04282656  68.81622734  -1.13521253  13.39165112
 -20.25124259   2.0435332  -20.18485074  15.7982264    1.78172476
  43.80968098 113.22114777   3.92123901   2.92281369  12.6303971
  -2.36062585 -11.82871492   3.90822121  46.55583885 106.47767388
   4.92912493  12.08597004  29.27241691   4.09660894 -19.7225452
 -39.47153676   2.4252769   -0.37464801 -41.7631083   35.86635107
  40.3708948   54.95962147  30.75340329   2.68336642 -10.85495934
   2.15923712   3.11414937 133.58892004  -1.7727267   48.24312838
 133.50496941  10.8705743   -6.48612321   9.1175708    3.36583279
   1.14220384  -4.26650197  11.53069193  -7.28026895  27.08372128]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.3583422997344
gradient value of function right now is: [ 5.24856037e-04  5.53257526e-03  4.10682718e-04 -8.63797649e-01
 -5.24856037e-04 -5.53257526e-03 -4.10682718e-04  8.63797649e-01
 -4.00257298e-05 -9.28496981e-04 -4.93575224e-06 -1.30053262e-08
  7.32053673e-04  5.16199491e-03  8.74033837e-05  7.82680402e-08
 -3.65468550e-05 -8.27266853e-04 -4.50126815e-06 -1.15505152e-08
  7.82373124e-04 -1.14688916e+00  9.84734815e-05  4.55439236e-03
  3.43844489e-02 -3.30854657e-25  9.40937477e-04 -9.18169135e-25
  6.25312259e-01  3.48253243e-03  7.66798991e-01  1.42340734e-02
  3.91277784e-03 -1.60363418e-24  1.11115570e-04 -4.24174695e-24
 -1.38621128e-02  1.38718055e-03 -5.31108491e-02 -1.82355253e-02
 -3.45289568e-03 -2.01684493e-02 -7.37025562e-02 -1.89494534e-03
 -1.50756733e-05 -1.48350839e-03 -4.16431569e-03 -5.15111003e-06
 -1.17675529e-01  1.56813000e-03 -6.31322405e-02 -1.17674711e-01
 -3.32590949e-05 -7.79844843e-02  5.80564343e-03  8.80758978e-06
 -4.61984228e-02  2.40200231e-02  6.80031491e-02 -1.00570956e-01
 -2.06094559e-01 -2.88127163e-02 -2.60200494e-02  1.94652662e-02
  8.37908736e-01]
supnorm grad right now is: 1.1468891631933378
Weights right now are: 
[  9.08134191  -5.86032167  10.97348041  -3.09183316  -9.81564063
   5.81707393 -10.47916346   1.55594484  -0.7297769   65.05055037
  -5.18865909  15.49694942 -28.21684819  41.95009824 -22.39165923
  23.17693947  -1.72885154  67.68670088  -1.02451904  13.47749744
 -20.68314821   1.94748084 -20.50048167  14.15175739   0.56754807
  43.80968098 113.9800954    3.92123901   2.31894339  11.26457065
  -1.35148405 -13.05472751   2.91307943  46.55583885 107.14495877
   4.92912493  13.25378193  28.79883636   4.93190022 -18.86594663
 -41.54419439   2.87947011  -2.38169746 -44.07004023  34.67552853
  40.50764495  55.00507756  30.18044541   1.26996373 -13.33602811
   1.6927112    1.66175238 138.38497391  -1.58532737  48.4974019
 139.32206952   8.15973039  -6.82995457   8.6545208    2.91899408
   1.5726282   -4.56536372   9.01512521  -8.21550346  27.09690525]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.5201410862242
gradient value of function right now is: [-2.98285927e-03 -1.70908546e-02 -2.57745447e-03 -7.55511937e-01
  2.98285927e-03  1.70908546e-02  2.57745447e-03  7.55511937e-01
  1.47276079e-04  2.99485488e-03  1.63642273e-05  5.36549799e-08
 -8.70192301e-04 -1.63341845e-02 -1.04926431e-04 -4.07091722e-07
  1.49689109e-04  3.04525854e-03  1.63685312e-05  5.37265007e-08
 -5.84314547e-04 -7.18203396e-01 -8.05265084e-05 -4.35883878e-03
 -3.48557906e-02 -7.11880974e-21 -1.38064715e-03 -2.41545353e-20
  7.39314543e-01  2.12567279e-03  4.20101094e-01  1.23163259e-02
 -3.74296123e-03 -1.02143247e-20 -1.56189817e-04 -3.25908975e-20
  1.91716721e-02  1.34466700e-03  4.10317776e-02  1.90821280e-02
 -1.38964109e-03 -2.15648821e-02 -1.31442047e-01 -1.07659409e-03
 -1.92328730e-06 -2.67584562e-03 -7.19240257e-03 -5.00753875e-07
  2.72619625e-02  1.11713530e-02  2.41994980e-01  2.70788805e-02
  2.12600467e-05  3.42123372e-02  1.67795517e-02  6.99632869e-06
 -4.71253891e-02 -3.31514440e-02  1.54298347e-01 -1.48703251e-01
 -4.10743599e-01  2.93249671e-01 -4.50439459e-02 -3.72083097e-02
  1.18665756e+00]
supnorm grad right now is: 1.1866575574338825
Weights right now are: 
[ 7.79530953e+00 -7.82567842e+00  9.87321561e+00 -3.06199448e+00
 -8.52960825e+00  7.78243068e+00 -9.37889865e+00  1.52610616e+00
 -2.15233045e+00  6.74578354e+01 -5.96025238e+00  1.55031499e+01
 -2.86745275e+01  4.07253740e+01 -2.25733527e+01  2.32600279e+01
 -3.12904314e+00  6.98583987e+01 -1.75748025e+00  1.34845837e+01
 -2.14248556e+01  2.23053880e+00 -2.11929683e+01  1.34556548e+01
  1.49832048e-02  4.38096810e+01  1.14908393e+02  3.92123901e+00
  2.97834831e+00  1.19158610e+01 -1.77367013e+00 -1.30593419e+01
  2.46180029e+00  4.65558388e+01  1.07793525e+02  4.92912493e+00
  1.38318789e+01  2.89349548e+01  5.49127368e+00 -1.88179912e+01
 -3.63142972e+01  4.32904958e+00 -5.41229771e-01 -3.66291770e+01
  3.37784112e+01  4.18565966e+01  5.34873730e+01  2.98238535e+01
  2.17902512e+00 -1.12018122e+01  3.10458795e+00  2.73017140e+00
  1.40960634e+02 -5.92776867e-01  5.01756315e+01  1.43591146e+02
  1.05439217e+01 -6.60653397e+00  8.95307062e+00  2.94349557e+00
  8.73456467e-01 -4.17683542e+00  1.17121332e+01 -7.73198653e+00
  2.70476910e+01]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1946.7741104683876
gradient value of function right now is: [ 1.42221187e-05 -1.19564447e-03  1.70362445e-05 -3.14496837e-01
 -1.42221187e-05  1.19564447e-03 -1.70362444e-05  3.14496837e-01
  8.65031384e-05  4.71584437e-05  7.54312371e-06 -1.49994527e-10
 -4.10081209e-04 -1.39119957e-03 -3.60519389e-05  4.67858178e-10
  9.29616601e-05  3.89653533e-05  8.10954278e-06 -1.73909257e-10
 -1.32521563e-04 -1.05418499e+00 -1.14466686e-05 -1.74590810e-02
 -1.30585361e-02  1.99692406e-26 -2.29838111e-04  1.52391033e-25
  1.10941722e-01  5.51069366e-02  9.91968594e-02  8.14076087e-02
 -9.33139764e-04  8.22122864e-26 -1.58380873e-05  5.27524351e-25
  7.51857471e-02  5.38347236e-03  1.75004777e-01  8.50185635e-02
  5.79329144e-04 -8.98309910e-02  1.07407132e-02  3.27392272e-04
 -2.07276906e-06 -1.24308219e-02 -7.55689023e-03 -4.71271769e-07
  1.20176018e-02 -1.30198887e-02  2.14332884e-02  1.27818317e-02
  1.21305467e-04  1.64002713e-01  1.98172178e-02  4.52731593e-05
 -1.02624096e-02 -1.09193688e-02  4.64862910e-01 -7.26167401e-01
 -2.08641379e-01  4.06419627e-01 -1.35904860e-02 -2.19092455e-02
  2.18482611e+00]
supnorm grad right now is: 2.1848261098484407
Weights right now are: 
[  8.47559913  -7.85918228  10.65731181  -2.70891559  -9.20989785
   7.81593455 -10.16299485   1.17302726  -3.06694828  68.03673486
  -6.52979075  15.49133613 -27.73320952  40.4000479  -21.45368358
  23.33234971  -3.89801059  70.22745523  -2.20560884  13.47207742
 -20.27959225   1.98229016 -19.95722613  13.31471626   1.25528525
  43.80968098 117.46502817   3.92123901   2.95542679  12.83919772
  -2.40320449 -12.51690446   3.84189728  46.55583885 110.24348079
   4.92912493  14.33960257  28.0921261    5.64876305 -19.29060223
 -37.30097794   3.51532194  -1.27165686 -37.49401241  34.77702256
  42.5348998   56.80219567  30.06838092   2.18047952 -15.08185451
   1.77165772   2.79224411 141.77780304  -0.79756751  48.14161706
 146.37365086  10.66596825  -6.86553453   8.90640569   2.95934264
   1.54597506  -4.19278532  12.11855421  -7.901472    27.26844422]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1947.110515536452
gradient value of function right now is: [-3.67021023e-04 -3.10595285e-03 -3.17921345e-04  6.70259528e-02
  3.67021023e-04  3.10595285e-03  3.17921345e-04 -6.70259528e-02
  4.33579556e-05  4.16275359e-04  3.42854804e-06  5.04920367e-09
 -2.93274626e-04 -3.46101868e-03 -2.31333814e-05 -1.38013688e-08
  4.60466894e-05  4.25117071e-04  3.64067075e-06  5.29103510e-09
 -1.49370610e-04  2.59203725e-01 -1.18412341e-05  1.84064011e-03
 -1.08212008e-02  2.80316962e-26 -2.57609293e-04  4.50586795e-25
  4.85003438e-02 -1.98555785e-02 -4.65921350e-02 -2.84578118e-02
 -7.14173441e-04  1.05069338e-25 -1.71136896e-05  1.17262784e-24
 -6.41285747e-03 -3.51962206e-04 -2.15599729e-02 -6.67064938e-03
  1.28704135e-04  2.96393275e-02  2.59205173e-02 -2.03151113e-05
  5.23977472e-08  1.66291370e-03  2.13774361e-03 -3.47360917e-08
  1.82423024e-02  1.77596424e-03  3.32494102e-02  1.88450527e-02
 -8.95155421e-05 -3.99360407e-02 -5.48619340e-03 -2.81051770e-05
 -5.64616450e-03 -2.79456503e-02 -6.55970153e-02  1.27520806e-01
  5.50034097e-02 -9.48913137e-02 -1.20268614e-02 -2.39957587e-02
 -4.99697407e-01]
supnorm grad right now is: 0.4996974070827752
Weights right now are: 
[  7.75999364  -8.32986161   9.92907495  -2.82534452  -8.49429236
   8.28661388  -9.434758     1.2894562   -2.12569679  69.10702089
  -5.79716421  15.49358016 -28.66212252  40.38297728 -22.20653713
  23.48322304  -2.82991223  71.18416643  -1.36955068  13.47510883
 -18.4475214    2.46352087 -18.10787729  14.47797491   1.55858484
  43.80968098 119.70969698   3.92123901   2.8596984   13.2797119
  -3.00974184 -12.25762973   4.37545643  46.55583885 112.50340489
   4.92912493  13.31810828  26.82544217   4.68470819 -21.02819214
 -37.99211468   3.60432153  -0.52626413 -38.71012535  35.66978734
  43.40903437  58.71748459  30.2264045    2.11991136 -14.84529096
   1.73841776   2.54327951 147.21423524  -0.8303497   47.07149464
 152.55941004  10.2410258   -6.3613773    8.98459412   2.87793776
   1.85217388  -4.10129369  12.13880625  -7.69303363  27.32232634]
(65,)
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1947.0795824914162
gradient value of function right now is: [-8.01552564e-04 -6.25872582e-03 -6.98130577e-04  5.18286064e-02
  8.01552564e-04  6.25872582e-03  6.98130577e-04 -5.18286064e-02
  7.84125194e-05  8.94475140e-04  6.70290372e-06  1.23608199e-08
 -5.18421946e-04 -6.70318859e-03 -4.40238535e-05 -6.79957860e-08
  8.29705662e-05  9.20557742e-04  7.09078751e-06  1.28439528e-08
 -3.07239582e-04  2.93796456e-01 -2.63965958e-05  2.82890799e-03
 -2.01094587e-02  1.41215483e-25 -5.21015138e-04  4.51520130e-24
  1.00182674e-01 -2.39422221e-02 -5.58163717e-02 -3.34135966e-02
 -1.44337944e-03  5.06073819e-25 -3.78858677e-05  7.84723948e-24
 -1.14048616e-02 -9.38651144e-04 -3.01826241e-02 -1.15976403e-02
  7.96670375e-05  3.32740756e-02  2.01890662e-02 -6.84095640e-05
  2.71276756e-07  2.53495354e-03  2.75760350e-03 -7.20176764e-09
  3.17074977e-02  4.28380983e-03  7.27769165e-02  3.43629003e-02
 -8.60457897e-05 -4.61247074e-02 -6.77588126e-03 -2.43711480e-05
 -1.56960153e-02 -3.90633088e-02 -9.31704377e-02  1.73882528e-01
  6.58860706e-02 -1.21285225e-01 -2.27563174e-02 -3.57218748e-02
 -3.49285432e-01]
supnorm grad right now is: 0.3492854318974602
Weights right now are: 
[  9.15231673  -7.3232316   11.35568747  -2.95986159  -9.88661546
   7.27998386 -10.86137052   1.42397327  -3.78568073  68.41118269
  -6.65563997  15.49170945 -29.90563847  41.27558259 -23.48425092
  23.58108741  -4.47124562  70.34738713  -2.24895853  13.47348177
 -18.61572623   2.16884092 -18.29185879  13.51498161   1.19664847
  43.80968098 121.11952744   3.92123901   2.91767391  12.91948765
  -2.16257837 -12.9239496    3.74704056  46.55583885 113.40935447
   4.92912493  14.48601759  27.59286375   5.04627891 -20.20865702
 -40.99887735   2.17733976  -1.00770763 -42.68370721  35.91586849
  43.65302707  55.34458027  30.36856393   2.66757846 -11.84476916
   1.80387693   2.69403962 148.89306367  -1.22545084  49.52866039
 155.09213819   9.9227337   -6.18400033   9.0145999    2.65681787
   1.50773639  -4.59204699  11.51801637  -7.29299422  27.38240485]
(65,)
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1947.090985311711
gradient value of function right now is: [-5.43948727e-04 -4.86752506e-03 -4.73739482e-04  1.36445653e-02
  5.43948727e-04  4.86752506e-03  4.73739482e-04 -1.36445653e-02
  7.09546271e-05  6.44948541e-04  6.29478101e-06  7.63162295e-09
 -5.19548809e-04 -5.45423735e-03 -4.57779283e-05 -5.62741079e-08
  7.49252317e-05  6.61757260e-04  6.64542948e-06  7.88224178e-09
 -3.08096275e-04  2.25427860e-01 -2.74874957e-05  2.72311171e-03
 -2.01861544e-02  1.03734765e-25 -4.80024443e-04  1.43878056e-24
  1.12487989e-01 -2.23005478e-02 -3.06951542e-02 -2.99383005e-02
 -1.51239417e-03  3.84396349e-25 -3.64576670e-05  3.30490401e-24
 -1.02722669e-02 -3.12787077e-04 -3.04454453e-02 -1.04590108e-02
 -1.79388613e-04  3.22349053e-02  7.74517125e-03 -1.76981326e-04
  2.11546598e-07  1.76042309e-03  2.02217815e-03 -2.33448772e-08
  2.91655153e-02  3.26802296e-03  7.33225715e-02  3.07930732e-02
 -1.26081241e-04 -5.08352424e-02 -6.04053542e-03 -3.52969375e-05
 -1.72354223e-02 -4.18458635e-02 -7.16018547e-02  1.45272013e-01
  6.05966273e-02 -1.31640124e-01 -2.21140702e-02 -3.43750484e-02
 -3.28863936e-01]
supnorm grad right now is: 0.32886393594438057
Weights right now are: 
[  7.329596    -9.17145968   9.57635655  -3.02101207  -8.06389472
   9.12821194  -9.0820396    1.48512375  -3.77140583  70.72751104
  -6.48083575  15.49755766 -30.09585383  40.15321067 -23.63774735
  23.57888305  -4.43477456  72.57084182  -2.06288888  13.47950814
 -18.75403851   2.55239849 -18.43113131  13.89362211   1.62161876
  43.80968098 122.3263789    3.92123901   2.85221459  13.00959607
  -2.4691163  -13.01866303   4.12807345  46.55583885 114.36572012
   4.92912493  14.26076356  26.87832078   4.6660558  -20.89178063
 -40.65794351   2.35871719  -0.99366169 -43.34702558  35.56401376
  44.33977355  56.70531608  30.32131701   2.54596311 -11.30502119
   2.30530792   2.74460371 150.62558503  -1.91227787  49.26786871
 157.35076596  11.34821824  -5.29327715   9.24893562   3.18177235
   0.78803929  -4.10428947  12.94256017  -5.92501414  27.11768109]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1947.0946174959522
gradient value of function right now is: [-2.83750178e-04 -3.08393751e-03 -2.47434592e-04  5.08916699e-02
  2.83750178e-04  3.08393751e-03  2.47434592e-04 -5.08916699e-02
  5.76292185e-05  3.41309378e-04  5.23763366e-06  4.41977475e-09
 -5.10432438e-04 -3.60168159e-03 -4.61799523e-05 -3.75156839e-08
  6.10275555e-05  3.51840449e-04  5.54558226e-06  4.60695153e-09
 -3.01350570e-04  2.57405399e-01 -2.75080760e-05  2.58051880e-03
 -1.99530415e-02  1.07310924e-25 -4.45042628e-04  1.54618156e-24
  4.69709219e-02 -2.44529903e-02 -7.23083732e-02 -3.15714195e-02
 -1.54107970e-03  3.81395568e-25 -3.47174785e-05  3.52702007e-24
 -1.00616297e-02 -3.55365540e-04 -2.83613757e-02 -9.87169530e-03
  2.55295602e-04  3.52700478e-02  1.16437638e-02  7.87333896e-05
  7.97266380e-08  1.73548005e-03  2.27910333e-03 -2.93632637e-08
  2.69185925e-02  2.13192271e-03  6.20430105e-02  2.83214154e-02
 -1.15883661e-04 -4.75842435e-02 -5.87509127e-03 -3.59354786e-05
 -1.18131087e-02 -4.19368854e-02 -7.36427190e-02  1.43817841e-01
  5.32796360e-02 -1.17379075e-01 -1.76909760e-02 -3.44045861e-02
 -4.05830397e-01]
supnorm grad right now is: 0.4058303970688512
Weights right now are: 
[  7.75995792  -8.1696718   10.04392244  -2.91364909  -8.49425664
   8.12642406  -9.54960548   1.37776076  -6.72813771  70.84315577
  -7.74742503  15.48995885 -28.23262447  41.82035169 -21.6960042
  23.7947864   -7.5252417   72.60023166  -3.49372028  13.4713684
 -20.25677421   1.93924631 -19.92046642  13.76084762   2.15127655
  43.80968098 123.06992963   3.92123901   2.39142513  12.73044711
  -2.73343273 -13.19399316   4.51225286  46.55583885 114.85963853
   4.92912493  13.37141654  25.20584447   4.78845652 -21.84802589
 -38.37890805   2.36416244  -0.8652717  -41.1484461   35.32818375
  44.55893825  56.59244042  30.28599269   2.48461463  -8.36480132
   1.75669791   2.86777325 152.68156717  -0.92021167  49.45086065
 159.57989136  11.48405128  -7.11079234   9.75634969   3.05437894
   1.15143309  -4.06623126  12.81214294  -8.13297116  27.38523898]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1947.0774697625554
gradient value of function right now is: [-2.87747955e-04 -3.09901782e-03 -2.51355216e-04  4.02732394e-02
  2.87747955e-04  3.09901782e-03  2.51355216e-04 -4.02732394e-02
  5.71636938e-05  3.55785795e-04  5.36928860e-06  4.94286649e-09
 -4.80133067e-04 -3.58352503e-03 -4.47106533e-05 -4.15529405e-08
  6.05668297e-05  3.66626571e-04  5.68742581e-06  5.13713316e-09
 -2.92539296e-04  2.43937258e-01 -2.76683346e-05  2.52093513e-03
 -1.91587747e-02  1.28591416e-25 -4.64639761e-04  1.70626204e-24
  4.81735586e-02 -2.31432479e-02 -7.59234608e-02 -2.93846022e-02
 -1.53372666e-03  4.43690463e-25 -3.77118057e-05  3.94651648e-24
 -9.55895400e-03 -1.96143818e-04 -2.78422981e-02 -9.34511058e-03
  4.03834353e-04  3.98537619e-02  8.06505929e-03  1.66433654e-04
 -2.44696767e-08  1.46507392e-03  1.98967723e-03 -3.86618652e-08
  2.46899972e-02  1.16445676e-03  6.70363355e-02  2.57008561e-02
 -1.15665459e-04 -5.01894214e-02 -5.49172794e-03 -3.74244652e-05
 -1.28311457e-02 -4.41248328e-02 -6.44734847e-02  1.29790037e-01
  4.42134322e-02 -1.17939853e-01 -1.85414114e-02 -3.57312071e-02
 -3.08497786e-01]
supnorm grad right now is: 0.3084977858585332
Weights right now are: 
[  9.95650885  -5.32836333  12.20994035  -3.02019254 -10.69080757
   5.2851156  -11.7156234    1.48430422  -2.58278953  68.55207306
  -3.56630082  15.47074241 -28.99325568  45.06182951 -22.20235607
  23.93978589  -3.35237133  70.28415884   0.64838741  13.45123743
 -22.96203105   1.96127905 -22.77815531  13.37013176   0.68360517
  43.80968098 122.97452212   3.92123901   2.39774071  13.86666682
  -1.8623363  -12.95684874   2.99496974  46.55583885 114.36648176
   4.92912493  14.02188648  25.15866876   5.38198186 -21.95705377
 -40.0191949    2.40971429  -1.56655196 -43.30839055  35.45647244
  45.61189065  55.63917829  30.32140813   3.63118718  -8.47039602
   2.4799998    4.13040165 156.76333584  -0.62661267  50.26700756
 163.29504745  11.2364558   -6.70173869   8.93855366   3.1442525
   0.71485774  -4.67344298  12.49867087  -8.27061464  27.23734746]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1447.3309415960741
W_T_median: 1239.8785636501248
W_T_pctile_5: 740.2551533345161
W_T_CVAR_5_pct: 644.4815312073919
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.9
F value: -1947.0774697625554
-----------------------------------------------
