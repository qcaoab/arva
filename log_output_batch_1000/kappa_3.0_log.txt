Starting at: 
2022-06-17 22:26:16
tracing parameter entered from terminal:  3.0


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.639128616061
gradient value of function right now is: [ 4.85343884e-04  2.07950261e-05  4.83889241e-04  4.84189124e-04
 -4.85343884e-04 -2.07950261e-05 -4.83889241e-04 -4.84189124e-04
  7.80997181e-06  9.81008280e-07  7.43029022e-06  8.18439238e-06
  1.91748154e-05  2.41002163e-06  1.82443292e-05  2.00951808e-05
  1.05443811e-05  1.32462644e-06  1.00319277e-05  1.10500021e-05
  1.01652196e-05  1.27696651e-06  9.67118653e-06  1.06526436e-05
  7.90685204e-07  2.68016592e-07  9.44807409e-07  1.63271209e-07
  9.37234184e-07  3.03333237e-07  1.10088109e-06  1.90711507e-07
  4.62290541e-06  1.53947341e-06  5.48964101e-06  9.48572140e-07
  8.24784877e-07  2.90982477e-07  1.00118654e-06  1.72425177e-07
  8.29424694e-07  1.35663522e-06  3.05654923e-07  6.65003144e-07
  3.41379661e-07  5.52891945e-07  1.33407820e-07  2.83650604e-07
  5.93229717e-07  9.86478802e-07  1.64877422e-07  3.88227009e-07
  5.33026447e-07  8.65787758e-07  1.44538435e-07  3.33573943e-07
  2.06430121e-07  4.34521401e-07  3.68862599e-08  6.33901782e-09
 -2.42466853e-08  3.85117134e-09 -8.98970663e-08 -4.67576944e-08
 -2.14449558e+00]
supnorm grad right now is: 2.1444955835582835
Weights right now are: 
[-3.0420435  -0.57762914 -1.85996074 -2.58041706  3.29661221  0.46893745
  2.25889801  1.86438868 -2.2018427  -0.90234239 -2.15648418 -1.94013479
  1.85739344  0.49844555  0.34493683  1.07864026 -1.22087779 -0.48395121
 -2.32491287 -2.00821872 -1.9421473  -0.91762693 -2.0620282  -1.62487624
 -0.97490017 -0.83346314 -1.72439832 -0.91288122  0.47162769  1.45811511
  1.55402145  0.51079002 -0.93348522 -0.57207676 -1.19556681 -1.15136628
 -2.50345681 -1.42927045 -1.27731244 -1.06612171 -0.54231168 -1.02622133
  0.2652186   0.37717994  0.47187251  1.16674739 -0.16104112  0.42046298
 -1.43406138 -0.54148957 -0.43057477 -1.57580141  0.64424827  1.19700991
  0.53500684  1.69931293  1.31789752 -0.40600778 -0.12406857 -2.19327097
  2.09135139  1.59046997 -0.07974727  1.08094624 24.85074096]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.8045293777
gradient value of function right now is: [ 8.86095316e-07  6.73205637e-08  8.85569547e-07  8.85805699e-07
 -8.86095892e-07 -6.73206082e-08 -8.85570123e-07 -8.85806274e-07
  1.45525237e-08  1.78003525e-09  1.42942935e-08  1.52502604e-08
  6.81566111e-08  8.34191638e-09  6.69534148e-08  7.14276458e-08
  1.36939740e-08  1.67506821e-09  1.34510133e-08  1.43505742e-08
  1.34413429e-08  1.64412676e-09  1.32028476e-08  1.40858092e-08
 -1.69315613e-09 -5.43702465e-10 -1.94487124e-09 -3.42519879e-10
  4.10607064e-11  2.22702093e-11  5.83578208e-11  1.01166386e-11
  6.33374606e-09  2.13975602e-09  7.40829728e-09  1.30184724e-09
  5.08841610e-10  1.86655860e-10  6.13711965e-10  1.07500878e-10
  7.63964694e-10  1.20536650e-09  2.86940191e-10  6.23525443e-10
  3.73552503e-10  5.82874733e-10  1.34771906e-10  2.90983362e-10
  5.60165567e-10  8.93348144e-10  1.57393145e-10  3.68770669e-10
  5.65752635e-10  8.80239667e-10  1.49766605e-10  3.46164864e-10
  1.97954428e-10  3.52071932e-10  3.83327836e-11  1.15495138e-12
 -2.08444578e-11  3.64130541e-12 -8.86297205e-11 -5.16247190e-11
 -5.46843792e-01]
supnorm grad right now is: 0.5468437915263001
Weights right now are: 
[-4.03682972 -0.6471082  -2.86962918 -3.69524064  4.29139849  0.53841651
  3.26856652  2.97921233 -2.25914364 -0.90925839 -2.24080836 -1.98667733
  1.63990572  0.47498127  0.06047668  0.90563844 -1.43230219 -0.51320516
 -2.64006282 -2.19417275 -2.14142724 -0.95028096 -2.39049081 -1.80669425
 -0.97448675 -0.8335538  -1.72456862 -0.9130542   0.46451642  1.45505503
  1.54220047  0.50844552 -1.08646413 -0.63329476 -1.38233201 -1.20457849
 -2.52010871 -1.43624187 -1.29861875 -1.07238758 -0.59867195 -1.09560368
  0.24252184  0.33214886  0.4355355   1.1207969  -0.17868127  0.38820282
 -1.46222368 -0.57635437 -0.43920664 -1.59450715  0.61590161  1.16248363
  0.5266323   1.68146417  1.28423582 -0.47828476 -0.12920591 -2.19426197
  2.09372082  1.5899847  -0.07253638  1.08636515 24.95757216]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.814982278785
gradient value of function right now is: [ 1.14591410e-07  9.40247077e-09  1.14524506e-07  1.14554358e-07
 -1.14591711e-07 -9.40249588e-09 -1.14524806e-07 -1.14554659e-07
  1.99751104e-09  2.44331027e-10  1.96319585e-09  2.09352907e-09
  9.88986759e-09  1.21045775e-09  9.72088655e-09  1.03657283e-08
  1.93112273e-09  2.36217416e-10  1.89795291e-09  2.02395341e-09
  1.88327614e-09  2.30359327e-10  1.85092583e-09  1.97380393e-09
 -2.54698045e-10 -8.17764616e-11 -2.92507996e-10 -5.15388420e-11
 -6.47388294e-12 -7.86911864e-13 -5.84334486e-12 -1.05261921e-12
  8.99762199e-10  3.03455555e-10  1.05160845e-09  1.84901271e-10
  7.06899413e-11  2.59102111e-11  8.52180253e-11  1.49363139e-11
  1.07337915e-10  1.69493961e-10  4.00236265e-11  8.73219631e-11
  5.36309067e-11  8.37421164e-11  1.90722069e-11  4.13983840e-11
  7.92102923e-11  1.26363284e-10  2.20807778e-11  5.19216451e-11
  7.97594779e-11  1.24136923e-10  2.09589499e-11  4.86192392e-11
  2.78418552e-11  4.96859129e-11  5.25059236e-12  1.33160598e-13
 -2.89480656e-12  4.96396168e-13 -1.24460048e-11 -7.30726744e-12
 -9.28854770e-02]
supnorm grad right now is: 0.09288547702714696
Weights right now are: 
[-4.37498806 -0.67434232 -3.20822237 -4.03758751  4.62955684  0.56565064
  3.60715971  3.32155921 -2.2652545  -0.9100059  -2.24683292 -1.99305484
  1.61045625  0.47138127  0.03147684  0.87489036 -1.43815898 -0.51392183
 -2.6458184  -2.20030992 -2.14715963 -0.95098245 -2.39612434 -1.81270122
 -0.97373932 -0.83331399 -1.7237101  -0.91290288  0.46451696  1.45505133
  1.54219631  0.50844486 -1.08918437 -0.63421143 -1.38551041 -1.20513727
 -2.52032466 -1.43632089 -1.29887893 -1.07243317 -0.59899791 -1.09611932
  0.24240064  0.331884    0.43537447  1.12054499 -0.17873862  0.38807826
 -1.46246362 -0.57673779 -0.43927333 -1.59466439  0.61565973  1.16210651
  0.52656896  1.68131681  1.28415123 -0.47843599 -0.12922208 -2.19426251
  2.09372961  1.58998334 -0.07249861  1.08638769 24.98575435]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.54153359481
gradient value of function right now is: [ 5.96492643e-08  5.01272068e-09  5.96146449e-08  5.96300611e-08
 -5.96487208e-08 -5.01267427e-09 -5.96141017e-08 -5.96295179e-08
  1.05736796e-09  1.29460354e-10  1.03947732e-09  1.10831116e-09
  5.33565660e-09  6.53649816e-10  5.24585606e-09  5.59295582e-09
  1.02981981e-09  1.26090875e-10  1.01239775e-09  1.07943767e-09
  1.00226294e-09  1.22714094e-10  9.85305948e-10  1.05055167e-09
 -1.39878994e-10 -4.45258602e-11 -1.60122194e-10 -2.82528305e-11
 -5.94681695e-12 -1.22436317e-12 -5.98744149e-12 -1.06616694e-12
  4.82271922e-10  1.60889912e-10  5.61274726e-10  9.88648737e-11
  3.73288111e-11  1.35075703e-11  4.47612273e-11  7.86444007e-12
  5.70784877e-11  9.06522451e-11  2.01594694e-11  4.52779153e-11
  2.87458063e-11  4.51378141e-11  9.63249513e-12  2.15562902e-11
  4.24085773e-11  6.78343912e-11  1.12934450e-11  2.71857011e-11
  4.27072740e-11  6.66463575e-11  1.06796937e-11  2.54074753e-11
  1.47872473e-11  2.69892675e-11  2.75019351e-12  1.05008720e-13
 -1.51183882e-12  1.90780925e-13 -6.57897876e-12 -4.13530023e-12
  2.78675349e+00]
supnorm grad right now is: 2.786753494588652
Weights right now are: 
[-4.48037189e+00 -6.83092512e-01 -3.31354482e+00 -4.14293733e+00
  4.73494068e+00  5.74400828e-01  3.71248217e+00  3.42690902e+00
 -2.26710777e+00 -9.10232530e-01 -2.24865449e+00 -1.99499720e+00
  1.60119878e+00  4.70248487e-01  2.23768869e-02  8.65187433e-01
 -1.43995725e+00 -5.14141740e-01 -2.64758591e+00 -2.20219464e+00
 -2.14891158e+00 -9.51196689e-01 -2.39784632e+00 -1.81453738e+00
 -9.73499456e-01 -8.33236851e-01 -1.72343445e+00 -9.12854328e-01
  4.64524967e-01  1.45505269e+00  1.54220402e+00  5.08446243e-01
 -1.09002301e+00 -6.34494745e-01 -1.38649123e+00 -1.20530968e+00
 -2.52039025e+00 -1.43634499e+00 -1.29895808e+00 -1.07244704e+00
 -5.99097784e-01 -1.09627681e+00  2.42363108e-01  3.31802457e-01
  4.35324394e-01  1.12046690e+00 -1.78756550e-01  3.88039496e-01
 -1.46253733e+00 -5.76855239e-01 -4.39294035e-01 -1.59471284e+00
  6.15585532e-01  1.16199115e+00  5.26549304e-01  1.68127142e+00
  1.28412536e+00 -4.78482102e-01 -1.29226934e-01 -2.19426261e+00
  2.09373231e+00  1.58998285e+00 -7.24870204e-02  1.08639443e+00
  2.51420376e+01]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.807047639842
gradient value of function right now is: [ 4.14724361e-08  3.53908504e-09  4.14484227e-08  4.14591023e-08
 -4.14720160e-08 -3.53904871e-09 -4.14480029e-08 -4.14586823e-08
  7.43477618e-10  9.09187043e-11  7.30903280e-10  7.79251456e-10
  3.79367431e-09  4.64217272e-10  3.72986958e-09  3.97639683e-09
  7.27187305e-10  8.89291910e-11  7.14890340e-10  7.62178769e-10
  7.06920365e-10  8.64486584e-11  6.94965242e-10  7.40935526e-10
 -9.99872546e-11 -3.21711229e-11 -1.14912889e-10 -2.02458964e-11
 -5.23868896e-12 -1.19080620e-12 -5.41033561e-12 -9.62442470e-13
  3.40307134e-10  1.14939073e-10  3.97941853e-10  6.99630059e-11
  2.62362492e-11  9.64377079e-12  3.16625238e-11  5.54841339e-12
  4.02381535e-11  6.34900993e-11  1.51191526e-11  3.28646864e-11
  2.03462189e-11  3.17434088e-11  7.26573260e-12  1.57209677e-11
  2.97597108e-11  4.74562831e-11  8.34237643e-12  1.95606068e-11
  2.99523008e-11  4.65994438e-11  7.92303645e-12  1.83208589e-11
  1.04399711e-11  1.85617794e-11  1.93740075e-12  3.56718034e-14
 -1.08430856e-12  1.94448133e-13 -4.68603815e-12 -2.72352907e-12
 -4.85744877e-01]
supnorm grad right now is: 0.48574487657989046
Weights right now are: 
[-4.54416704e+00 -6.88494995e-01 -3.37730297e+00 -4.20671193e+00
  4.79873582e+00  5.79803311e-01  3.77624031e+00  3.49068364e+00
 -2.26824547e+00 -9.10371683e-01 -2.24977289e+00 -1.99618964e+00
  1.59542863e+00  4.69542290e-01  1.67040809e-02  8.59139377e-01
 -1.44106762e+00 -5.14277555e-01 -2.64867746e+00 -2.20335844e+00
 -2.14999164e+00 -9.51328793e-01 -2.39890806e+00 -1.81566941e+00
 -9.73348107e-01 -8.33188177e-01 -1.72326055e+00 -9.12823682e-01
  4.64532078e-01  1.45505423e+00  1.54221126e+00  5.08447532e-01
 -1.09054221e+00 -6.34670041e-01 -1.38709823e+00 -1.20541643e+00
 -2.52043045e+00 -1.43635975e+00 -1.29900658e+00 -1.07245554e+00
 -5.99159230e-01 -1.09637393e+00  2.42340133e-01  3.31752255e-01
  4.35293403e-01  1.12041847e+00 -1.78767570e-01  3.88015525e-01
 -1.46258277e+00 -5.76927801e-01 -4.39306740e-01 -1.59474275e+00
  6.15539810e-01  1.16191992e+00  5.26537245e-01  1.68124342e+00
  1.28410936e+00 -4.78510511e-01 -1.29229913e-01 -2.19426267e+00
  2.09373397e+00  1.58998256e+00 -7.24798420e-02  1.08639862e+00
  2.49439214e+01]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.815251900386
gradient value of function right now is: [ 3.13237917e-08  2.70260754e-09  3.13057009e-08  3.13137393e-08
 -3.13235535e-08 -2.70258647e-09 -3.13054629e-08 -3.13135012e-08
  5.65587954e-10  6.91754464e-11  5.56075299e-10  5.92819321e-10
  2.91206333e-09  3.56389547e-10  2.86335826e-09  3.05240894e-09
  5.54852517e-10  6.78643898e-11  5.45521826e-10  5.81568109e-10
  5.38953928e-10  6.59182771e-11  5.29889936e-10  5.64903206e-10
 -7.73837620e-11 -2.48645678e-11 -8.88880186e-11 -1.56650409e-11
 -4.67261473e-12 -1.12465758e-12 -4.90282151e-12 -8.70887241e-13
  2.60161984e-10  8.76982577e-11  3.03987744e-10  5.34633864e-11
  1.99045808e-11  7.30148829e-12  2.40004121e-11  4.20762929e-12
  3.06484940e-11  4.84072805e-11  1.14099781e-11  2.49219360e-11
  1.55546117e-11  2.42910060e-11  5.49430479e-12  1.19502311e-11
  2.27062324e-11  3.62251233e-11  6.31404741e-12  1.48636267e-11
  2.28570391e-11  3.55771611e-11  5.99439128e-12  1.39200492e-11
  7.94890112e-12  1.41899864e-11  1.46589682e-12  2.84999135e-14
 -8.22924663e-13  1.41386893e-13 -3.56872195e-12 -2.10080934e-12
  3.12322554e-02]
supnorm grad right now is: 0.031232255367254203
Weights right now are: 
[-4.59018432e+00 -6.92443111e-01 -3.42329364e+00 -4.25271444e+00
  4.84475311e+00  5.83751428e-01  3.82223099e+00  3.53668614e+00
 -2.26907331e+00 -9.10472937e-01 -2.25058677e+00 -1.99705733e+00
  1.59118565e+00  4.69023001e-01  1.25322475e-02  8.54691938e-01
 -1.44187853e+00 -5.14376741e-01 -2.64947469e+00 -2.20420838e+00
 -2.15077962e+00 -9.51425173e-01 -2.39968276e+00 -1.81649533e+00
 -9.73235796e-01 -8.33152089e-01 -1.72313154e+00 -9.12800952e-01
  4.64538403e-01  1.45505571e+00  1.54221785e+00  5.08448704e-01
 -1.09092216e+00 -6.34798107e-01 -1.38754219e+00 -1.20549448e+00
 -2.52045963e+00 -1.43637045e+00 -1.29904175e+00 -1.07246170e+00
 -5.99204079e-01 -1.09644479e+00  2.42323430e-01  3.31715789e-01
  4.35270690e-01  1.12038298e+00 -1.78775603e-01  3.87998066e-01
 -1.46261596e+00 -5.76980780e-01 -4.39315971e-01 -1.59476449e+00
  6.15506410e-01  1.16186790e+00  5.26528480e-01  1.68122306e+00
  1.28409774e+00 -4.78531234e-01 -1.29232069e-01 -2.19426272e+00
  2.09373517e+00  1.58998236e+00 -7.24746264e-02  1.08640170e+00
  2.49698977e+01]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.536907141073
gradient value of function right now is: [ 2.47875486e-08  2.15687956e-09  2.47732712e-08  2.47796110e-08
 -2.47875940e-08 -2.15688348e-09 -2.47733165e-08 -2.47796563e-08
  4.49748746e-10  5.50608165e-11  4.42250069e-10  4.71441191e-10
  2.33365012e-09  2.85862456e-10  2.29495228e-09  2.44630949e-09
  4.42227258e-10  5.41414595e-11  4.34855049e-10  4.63557744e-10
  4.29288548e-10  5.25562211e-11  4.22131554e-10  4.49994340e-10
 -6.26247433e-11 -1.99495412e-11 -7.17029447e-11 -1.26531972e-11
 -4.21060929e-12 -1.05044971e-12 -4.46408056e-12 -7.92071826e-13
  2.08081546e-10  6.94090537e-11  2.42145546e-10  4.26586474e-11
  1.57653923e-11  5.71022456e-12  1.89101590e-11  3.32288807e-12
  2.43822614e-11  3.87257631e-11  8.61189843e-12  1.93465004e-11
  1.24185847e-11  1.94989057e-11  4.14645697e-12  9.28675188e-12
  1.81639586e-11  2.90534616e-11  4.83354350e-12  1.16387728e-11
  1.82953159e-11  2.85503877e-11  4.57345309e-12  1.08829746e-11
  6.31519612e-12  1.15218854e-11  1.15495694e-12  3.83746527e-14
 -6.44398669e-13  8.20464847e-14 -2.82178729e-12 -1.77479353e-12
  2.81605698e+00]
supnorm grad right now is: 2.816056982921788
Weights right now are: 
[-4.62607243e+00 -6.95552821e-01 -3.45916104e+00 -4.28859104e+00
  4.88064121e+00  5.86861136e-01  3.85809838e+00  3.57256273e+00
 -2.26972310e+00 -9.10552415e-01 -2.25122566e+00 -1.99773841e+00
  1.58782828e+00  4.68612094e-01  9.23090865e-03  8.51172719e-01
 -1.44251670e+00 -5.14454800e-01 -2.65010216e+00 -2.20487730e+00
 -2.15139933e+00 -9.51500971e-01 -2.40029206e+00 -1.81714488e+00
 -9.73146298e-01 -8.33123337e-01 -1.72302874e+00 -9.12782833e-01
  4.64544086e-01  1.45505710e+00  1.54222385e+00  5.08449768e-01
 -1.09122159e+00 -6.34899019e-01 -1.38789202e+00 -1.20555602e+00
 -2.52048247e+00 -1.43637883e+00 -1.29906929e+00 -1.07246653e+00
 -5.99239292e-01 -1.09650043e+00  2.42310344e-01  3.31687162e-01
  4.35252791e-01  1.12035502e+00 -1.78781911e-01  3.87984324e-01
 -1.46264207e+00 -5.77022441e-01 -4.39323217e-01 -1.59478157e+00
  6.15480127e-01  1.16182698e+00  5.26521601e-01  1.68120706e+00
  1.28408860e+00 -4.78547545e-01 -1.29233751e-01 -2.19426275e+00
  2.09373612e+00  1.58998220e+00 -7.24705195e-02  1.08640412e+00
  2.51711318e+01]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.549853333658
gradient value of function right now is: [ 2.07454263e-08  1.81837357e-09  2.07334959e-08  2.07387905e-08
 -2.07456395e-08 -1.81839236e-09 -2.07337090e-08 -2.07390036e-08
  3.78151444e-10  4.62932352e-11  3.71865049e-10  3.96394063e-10
  1.97394913e-09  2.41789556e-10  1.94131333e-09  2.06926210e-09
  3.72514974e-10  4.56044569e-11  3.66323176e-10  3.90486374e-10
  3.61437842e-10  4.42473782e-11  3.55429758e-10  3.78874332e-10
 -5.32455822e-11 -1.69690464e-11 -6.09730624e-11 -1.07595483e-11
 -3.85826577e-12 -9.83520068e-13 -4.11617569e-12 -7.30044871e-13
  1.75460686e-10  5.85442440e-11  2.04204761e-10  3.59738736e-11
  1.32260834e-11  4.79345050e-12  1.58680494e-11  2.78820184e-12
  2.05116701e-11  3.25738864e-11  7.25638108e-12  1.62886010e-11
  1.04727322e-11  1.64411354e-11  3.49985807e-12  7.83317499e-12
  1.52869726e-11  2.44500144e-11  4.07277133e-12  9.80093717e-12
  1.53993239e-11  2.40295792e-11  3.85478710e-12  9.16670930e-12
  5.31245577e-12  9.68502063e-12  9.67943970e-13  3.06766081e-14
 -5.42171329e-13  6.98422202e-14 -2.37699376e-12 -1.49263432e-12
  2.73645179e+00]
supnorm grad right now is: 2.736451792357928
Weights right now are: 
[-4.65568495e+00 -6.98139498e-01 -3.48875650e+00 -4.31819407e+00
  4.91025371e+00  5.89447811e-01  3.88769382e+00  3.60216574e+00
 -2.27026208e+00 -9.10618317e-01 -2.25175560e+00 -1.99830334e+00
  1.58502530e+00  4.68269147e-01  6.47460498e-03  8.48234655e-01
 -1.44304714e+00 -5.14519660e-01 -2.65062371e+00 -2.20543327e+00
 -2.15191412e+00 -9.51563917e-01 -2.40079824e+00 -1.81768446e+00
 -9.73071200e-01 -8.33099173e-01 -1.72294243e+00 -9.12767625e-01
  4.64549283e-01  1.45505841e+00  1.54222937e+00  5.08450748e-01
 -1.09147065e+00 -6.34983098e-01 -1.38818321e+00 -1.20560722e+00
 -2.52050137e+00 -1.43638578e+00 -1.29909211e+00 -1.07247053e+00
 -5.99268530e-01 -1.09654654e+00  2.42299385e-01  3.31663296e-01
  4.35237889e-01  1.12033179e+00 -1.78787206e-01  3.87972843e-01
 -1.46266374e+00 -5.77056967e-01 -4.39329279e-01 -1.59479580e+00
  6.15458298e-01  1.16179305e+00  5.26515845e-01  1.68119374e+00
  1.28408103e+00 -4.78561028e-01 -1.29235142e-01 -2.19426278e+00
  2.09373691e+00  1.58998206e+00 -7.24671063e-02  1.08640611e+00
  2.52176249e+01]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.754760113466
gradient value of function right now is: [ 1.80098092e-08  1.58862624e-09  1.79994620e-08  1.80040516e-08
 -1.80101009e-08 -1.58865231e-09 -1.79997536e-08 -1.80043432e-08
  3.29685208e-10  4.03380046e-11  3.24204269e-10  3.45580333e-10
  1.72929955e-09  2.11713370e-10  1.70071078e-09  1.81275393e-09
  3.25267147e-10  3.97985602e-11  3.19860462e-10  3.40949892e-10
  3.15468228e-10  3.85987159e-11  3.10224053e-10  3.30678057e-10
 -4.67692176e-11 -1.49775505e-11 -5.36527385e-11 -9.46165530e-12
 -3.58373255e-12 -9.27973790e-13 -3.84081728e-12 -6.81032008e-13
  1.53171003e-10  5.13918104e-11  1.78644127e-10  3.14451088e-11
  1.15160210e-11  4.20355019e-12  1.38565992e-11  2.43194667e-12
  1.78926697e-11  2.83301337e-11  6.51067720e-12  1.43972426e-11
  9.15169271e-12  1.43254340e-11  3.14801273e-12  6.93792866e-12
  1.33073300e-11  2.12538740e-11  3.62867056e-12  8.62816326e-12
  1.34038323e-11  2.08864802e-11  3.44185881e-12  8.07905935e-12
  4.63683863e-12  8.35512936e-12  8.43792555e-13  1.88422656e-14
 -4.76819395e-13  7.30509837e-14 -2.08379263e-12 -1.26370809e-12
  1.28528155e+00]
supnorm grad right now is: 1.2852815539764701
Weights right now are: 
[-4.68065904e+00 -7.00335890e-01 -3.51371623e+00 -4.34316017e+00
  4.93522781e+00  5.91644205e-01  3.91265356e+00  3.62713186e+00
 -2.27071861e+00 -9.10674135e-01 -2.25220451e+00 -1.99878186e+00
  1.58263800e+00  4.67977075e-01  4.12696390e-03  8.45732275e-01
 -1.44349720e+00 -5.14574688e-01 -2.65106625e+00 -2.20590500e+00
 -2.15235072e+00 -9.51617298e-01 -2.40122754e+00 -1.81814208e+00
 -9.73006954e-01 -8.33078470e-01 -1.72286855e+00 -9.12754613e-01
  4.64554033e-01  1.45505963e+00  1.54223445e+00  5.08451648e-01
 -1.09168214e+00 -6.35054589e-01 -1.38843061e+00 -1.20565070e+00
 -2.52051735e+00 -1.43639167e+00 -1.29911141e+00 -1.07247391e+00
 -5.99293311e-01 -1.09658563e+00  2.42290021e-01  3.31643004e-01
  4.35225237e-01  1.12031205e+00 -1.78791737e-01  3.87963064e-01
 -1.46268210e+00 -5.77086233e-01 -4.39334450e-01 -1.59480789e+00
  6.15439816e-01  1.16176431e+00  5.26510930e-01  1.68118241e+00
  1.28407462e+00 -4.78572433e-01 -1.29236315e-01 -2.19426279e+00
  2.09373758e+00  1.58998194e+00 -7.24642113e-02  1.08640780e+00
  2.51086368e+01]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.813951955049
gradient value of function right now is: [ 1.59027973e-08  1.41058359e-09  1.58936690e-08  1.58977161e-08
 -1.59029587e-08 -1.41059811e-09 -1.58938303e-08 -1.58978775e-08
  2.92172037e-10  3.57337080e-11  2.87316323e-10  3.06252789e-10
  1.53918759e-09  1.88366624e-10  1.51375235e-09  1.61343955e-09
  2.88636493e-10  3.53023158e-11  2.83840266e-10  3.02547427e-10
  2.79844482e-10  3.42261905e-11  2.75194011e-10  2.93331262e-10
 -4.17378922e-11 -1.34145005e-11 -4.79448888e-11 -8.45075922e-12
 -3.35292099e-12 -8.79427773e-13 -3.60714494e-12 -6.39416084e-13
  1.35920072e-10  4.57901062e-11  1.58774178e-10  2.79295920e-11
  1.01914373e-11  3.73967458e-12  1.22892945e-11  2.15492307e-12
  1.58630454e-11  2.50621995e-11  5.89183018e-12  1.28878221e-11
  8.12660481e-12  1.26939364e-11  2.85461496e-12  6.22145528e-12
  1.17801666e-11  1.87959381e-11  3.26736996e-12  7.70140693e-12
  1.18649890e-11  1.84701661e-11  3.10402523e-12  7.21752553e-12
  4.11234495e-12  7.34553842e-12  7.47144143e-13  1.16792885e-14
 -4.25097682e-13  7.25338252e-14 -1.85421917e-12 -1.09595124e-12
  1.84749930e-01]
supnorm grad right now is: 0.18474992974268012
Weights right now are: 
[-4.70245664e+00 -7.02263922e-01 -3.53550131e+00 -4.36495080e+00
  4.95702542e+00  5.93572238e-01  3.93443865e+00  3.64892250e+00
 -2.27111837e+00 -9.10723026e-01 -2.25259762e+00 -1.99920088e+00
  1.58053677e+00  4.67719934e-01  2.06047979e-03  8.43529685e-01
 -1.44389185e+00 -5.14622956e-01 -2.65145434e+00 -2.20631868e+00
 -2.15273342e+00 -9.51664103e-01 -2.40160388e+00 -1.81854322e+00
 -9.72950080e-01 -8.33060204e-01 -1.72280323e+00 -9.12743100e-01
  4.64558492e-01  1.45506079e+00  1.54223924e+00  5.08452497e-01
 -1.09186792e+00 -6.35117122e-01 -1.38864756e+00 -1.20568887e+00
 -2.52053131e+00 -1.43639678e+00 -1.29912823e+00 -1.07247686e+00
 -5.99315024e-01 -1.09661991e+00  2.42282017e-01  3.31625415e-01
  4.35214122e-01  1.12029470e+00 -1.78795608e-01  3.87954582e-01
 -1.46269823e+00 -5.77111932e-01 -4.39338905e-01 -1.59481841e+00
  6.15423571e-01  1.16173904e+00  5.26506699e-01  1.68117255e+00
  1.28406900e+00 -4.78582474e-01 -1.29237339e-01 -2.19426281e+00
  2.09373816e+00  1.58998183e+00 -7.24616734e-02  1.08640929e+00
  2.49968607e+01]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.815197373725
gradient value of function right now is: [ 1.41781984e-08  1.26376770e-09  1.41700682e-08  1.41736714e-08
 -1.41787703e-08 -1.26381938e-09 -1.41706397e-08 -1.41742431e-08
  2.61271220e-10  3.19511636e-11  2.56936042e-10  2.73863054e-10
  1.38198031e-09  1.69111244e-10  1.35918050e-09  1.44865059e-09
  2.58408521e-10  3.16019970e-11  2.54121498e-10  2.70862904e-10
  2.50460425e-10  3.06292681e-11  2.46304957e-10  2.62531359e-10
 -3.76003845e-11 -1.20957052e-11 -4.32063023e-11 -7.61480067e-12
 -3.15035935e-12 -8.34950344e-13 -3.39983520e-12 -6.02522795e-13
  1.21757001e-10  4.10565805e-11  1.42279587e-10  2.50249436e-11
  9.09737634e-12  3.34277720e-12  1.09760595e-11  1.92427750e-12
  1.41878784e-11  2.24047902e-11  5.29449315e-12  1.15530827e-11
  7.28036101e-12  1.13666129e-11  2.56862152e-12  5.58453222e-12
  1.05358750e-11  1.68067551e-11  2.93336811e-12  6.90068716e-12
  1.06127630e-11  1.65170889e-11  2.78803979e-12  6.46920390e-12
  3.67838837e-12  6.55670009e-12  6.66632792e-13  8.96005728e-15
 -3.80669323e-13  6.65473986e-14 -1.66092866e-12 -9.75934867e-13
 -5.03514098e-02]
supnorm grad right now is: 0.05035140979626949
Weights right now are: 
[-4.72173898e+00 -7.03978333e-01 -3.55477259e+00 -4.38422698e+00
  4.97630774e+00  5.95286647e-01  3.95370991e+00  3.66819866e+00
 -2.27147312e+00 -9.10766406e-01 -2.25294648e+00 -1.99957273e+00
  1.57866404e+00  4.67490789e-01  2.18666154e-04  8.41566621e-01
 -1.44424251e+00 -5.14665837e-01 -2.65179918e+00 -2.20668624e+00
 -2.15307335e+00 -9.51705671e-01 -2.40193816e+00 -1.81889954e+00
 -9.72899209e-01 -8.33043853e-01 -1.72274479e+00 -9.12732802e-01
  4.64562669e-01  1.45506190e+00  1.54224374e+00  5.08453294e-01
 -1.09203310e+00 -6.35172762e-01 -1.38884053e+00 -1.20572281e+00
 -2.52054367e+00 -1.43640132e+00 -1.29914313e+00 -1.07247948e+00
 -5.99334315e-01 -1.09665033e+00  2.42274851e-01  3.31609773e-01
  4.35204230e-01  1.12027928e+00 -1.78799079e-01  3.87947030e-01
 -1.46271254e+00 -5.77134738e-01 -4.39342876e-01 -1.59482775e+00
  6.15409144e-01  1.16171662e+00  5.26502922e-01  1.68116378e+00
  1.28406402e+00 -4.78591373e-01 -1.29238244e-01 -2.19426282e+00
  2.09373868e+00  1.58998174e+00 -7.24594247e-02  1.08641061e+00
  2.49901115e+01]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.783416516519
gradient value of function right now is: [ 1.28552834e-08  1.15094943e-09  1.28479170e-08  1.28511806e-08
 -1.28556898e-08 -1.15098619e-09 -1.28483232e-08 -1.28515868e-08
  2.37565398e-10  2.90424176e-11  2.33624363e-10  2.49010815e-10
  1.26099306e-09  1.54257321e-10  1.24019508e-09  1.32180742e-09
  2.35201379e-10  2.87542658e-11  2.31300168e-10  2.46533381e-10
  2.27906796e-10  2.78618110e-11  2.24126293e-10  2.38886995e-10
 -3.43821458e-11 -1.10934802e-11 -3.95521946e-11 -6.96788293e-12
 -2.98224931e-12 -7.97543904e-13 -3.22719836e-12 -5.71773965e-13
  1.10821444e-10  3.74951862e-11  1.29669931e-10  2.27952525e-11
  8.26132417e-12  3.04876999e-12  9.98514853e-12  1.74929414e-12
  1.29031922e-11  2.03399769e-11  4.89433441e-12  1.05910270e-11
  6.62974989e-12  1.03329194e-11  2.37833182e-12  5.12669990e-12
  9.57004005e-12  1.52531485e-11  2.70123133e-12  6.31156728e-12
  9.63977853e-12  1.49901604e-11  2.57057815e-12  5.92111209e-12
  3.34634720e-12  5.92073162e-12  6.05900232e-13  4.75503253e-15
 -3.47932261e-13  6.56529913e-14 -1.51559008e-12 -8.71159482e-13
 -9.34369469e-01]
supnorm grad right now is: 0.9343694686497258
Weights right now are: 
[-4.73892228e+00 -7.05513201e-01 -3.57194604e+00 -4.40140480e+00
  4.99349105e+00  5.96821515e-01  3.97088337e+00  3.68537648e+00
 -2.27179014e+00 -9.10805178e-01 -2.25325825e+00 -1.99990503e+00
  1.57698402e+00  4.67285190e-01 -1.43368015e-03  8.39805534e-01
 -1.44455621e+00 -5.14704204e-01 -2.65210769e+00 -2.20701506e+00
 -2.15337736e+00 -9.51742852e-01 -2.40223714e+00 -1.81921820e+00
 -9.72853407e-01 -8.33029132e-01 -1.72269218e+00 -9.12723528e-01
  4.64566580e-01  1.45506294e+00  1.54224796e+00  5.08454043e-01
 -1.09218100e+00 -6.35222576e-01 -1.38901327e+00 -1.20575320e+00
 -2.52055470e+00 -1.43640536e+00 -1.29915643e+00 -1.07248181e+00
 -5.99351529e-01 -1.09667753e+00  2.42268479e-01  3.31595791e-01
  4.35195389e-01  1.12026547e+00 -1.78802171e-01  3.87940269e-01
 -1.46272533e+00 -5.77155145e-01 -4.39346418e-01 -1.59483611e+00
  6.15396255e-01  1.16169656e+00  5.26499557e-01  1.68115594e+00
  1.28405955e+00 -4.78599344e-01 -1.29239052e-01 -2.19426283e+00
  2.09373914e+00  1.58998167e+00 -7.24574068e-02  1.08641180e+00
  2.48826859e+01]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.805592222309
gradient value of function right now is: [ 1.15910288e-08  1.04176833e-09  1.15843955e-08  1.15873334e-08
 -1.15906744e-08 -1.04173612e-09 -1.15840413e-08 -1.15869792e-08
  2.14608352e-10  2.62492400e-11  2.11063754e-10  2.24957237e-10
  1.14340323e-09  1.39939592e-10  1.12462576e-09  1.19859474e-09
  2.12670693e-10  2.60129846e-11  2.09158632e-10  2.22926557e-10
  2.06024726e-10  2.51994940e-11  2.02622169e-10  2.15959788e-10
 -3.13316371e-11 -1.00631678e-11 -3.59811003e-11 -6.34324929e-12
 -2.81715254e-12 -7.58309176e-13 -3.05459455e-12 -5.41145035e-13
  1.00391895e-10  3.37788599e-11  1.17213589e-10  2.06238600e-11
  7.44345480e-12  2.72866845e-12  8.97172195e-12  1.57367387e-12
  1.16561151e-11  1.84264752e-11  4.30403158e-12  9.44433665e-12
  5.99977654e-12  9.37684881e-12  2.09129177e-12  4.57397432e-12
  8.66985175e-12  1.38365114e-11  2.39218601e-12  5.65306867e-12
  8.73631972e-12  1.36031007e-11  2.27298802e-12  5.29968833e-12
  3.02013943e-12  5.40754180e-12  5.44219483e-13  8.03441208e-15
 -3.11703078e-13  5.17903088e-14 -1.36442777e-12 -8.12978730e-13
  5.07083785e-01]
supnorm grad right now is: 0.507083785221419
Weights right now are: 
[-4.75454994e+00 -7.06915000e-01 -3.58756475e+00 -4.41702748e+00
  5.00911870e+00  5.98223314e-01  3.98650208e+00  3.70099915e+00
 -2.27207920e+00 -9.10840526e-01 -2.25354252e+00 -2.00020802e+00
  1.57544684e+00  4.67097093e-01 -2.94556277e-03  8.38194184e-01
 -1.44484253e+00 -5.14739217e-01 -2.65238926e+00 -2.20731517e+00
 -2.15365476e+00 -9.51776775e-01 -2.40250995e+00 -1.81950897e+00
 -9.72811383e-01 -8.33015610e-01 -1.72264388e+00 -9.12715018e-01
  4.64570292e-01  1.45506393e+00  1.54225199e+00  5.08454755e-01
 -1.09231605e+00 -6.35268114e-01 -1.38917109e+00 -1.20578095e+00
 -2.52056473e+00 -1.43640905e+00 -1.29916854e+00 -1.07248393e+00
 -5.99367234e-01 -1.09670233e+00  2.42262608e-01  3.31583005e-01
  4.35187314e-01  1.12025286e+00 -1.78805023e-01  3.87934078e-01
 -1.46273700e+00 -5.77173752e-01 -4.39349671e-01 -1.59484375e+00
  6.15384507e-01  1.16167828e+00  5.26496463e-01  1.68114878e+00
  1.28405549e+00 -4.78606595e-01 -1.29239784e-01 -2.19426284e+00
  2.09373956e+00  1.58998159e+00 -7.24555698e-02  1.08641288e+00
  2.50182868e+01]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.791260335385
gradient value of function right now is: [ 1.06124956e-08  9.57302735e-10  1.06064277e-08  1.06091145e-08
 -1.06130615e-08 -9.57354404e-10 -1.06069933e-08 -1.06096802e-08
  1.96902606e-10  2.40857807e-11  1.93657249e-10  2.06400279e-10
  1.05243785e-09  1.28817394e-10  1.03519034e-09  1.10325200e-09
  1.95288941e-10  2.38890709e-11  1.92070669e-10  2.04709159e-10
  1.89143292e-10  2.31367596e-11  1.86026073e-10  1.98266781e-10
 -2.89314949e-11 -9.28459093e-12 -3.32142962e-11 -5.85631675e-12
 -2.67928331e-12 -7.25486410e-13 -2.91036789e-12 -5.15531835e-13
  9.22658275e-11  3.10105338e-11  1.07679611e-10  1.89497859e-11
  6.81687995e-12  2.49599162e-12  8.21237596e-12  1.44083064e-12
  1.06947850e-11  1.69162425e-11  3.92822411e-12  8.64359965e-12
  5.51261380e-12  8.62007633e-12  1.90998459e-12  4.18973735e-12
  7.96108084e-12  1.27085887e-11  2.18669881e-12  5.17913380e-12
  8.02353734e-12  1.24964187e-11  2.07735337e-12  4.85528253e-12
  2.77032368e-12  4.97153813e-12  4.97887801e-13  7.76811534e-15
 -2.85475708e-13  4.61667707e-14 -1.25168858e-12 -7.51159351e-13
  7.99443727e-01]
supnorm grad right now is: 0.7994437266144683
Weights right now are: 
[-4.76886126e+00 -7.08203599e-01 -3.60186789e+00 -4.43133424e+00
  5.02343001e+00  5.99511911e-01  4.00080520e+00  3.71530590e+00
 -2.27234447e+00 -9.10872964e-01 -2.25380341e+00 -2.00048608e+00
  1.57403138e+00  4.66923896e-01 -4.33777849e-03  8.36710423e-01
 -1.44510551e+00 -5.14771377e-01 -2.65264790e+00 -2.20759084e+00
 -2.15390950e+00 -9.51807925e-01 -2.40276048e+00 -1.81977599e+00
 -9.72772559e-01 -8.33003130e-01 -1.72259928e+00 -9.12707158e-01
  4.64573832e-01  1.45506489e+00  1.54225583e+00  5.08455436e-01
 -1.09244019e+00 -6.35309927e-01 -1.38931610e+00 -1.20580645e+00
 -2.52057393e+00 -1.43641243e+00 -1.29917963e+00 -1.07248587e+00
 -5.99381651e-01 -1.09672508e+00  2.42257248e-01  3.31571301e-01
  4.35179887e-01  1.12024128e+00 -1.78807629e-01  3.87928406e-01
 -1.46274771e+00 -5.77190832e-01 -4.39352643e-01 -1.59485075e+00
  6.15373703e-01  1.16166148e+00  5.26493637e-01  1.68114222e+00
  1.28405176e+00 -4.78613251e-01 -1.29240455e-01 -2.19426285e+00
  2.09373995e+00  1.58998152e+00 -7.24538845e-02  1.08641388e+00
  2.50406214e+01]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.015751702186
gradient value of function right now is: [ 9.55419966e-09  8.64458947e-10  9.54874710e-09  9.55116092e-09
 -9.55371223e-09 -8.64414183e-10 -9.54825997e-09 -9.55067366e-09
  1.77403825e-10  2.17317538e-11  1.74505712e-10  1.85980338e-10
  9.51862172e-10  1.16664744e-10  9.36396954e-10  9.97918820e-10
  1.76089300e-10  2.15712804e-11  1.73213069e-10  1.84602572e-10
  1.70512069e-10  2.08876176e-11  1.67726756e-10  1.78755474e-10
 -2.63736525e-11 -8.35557189e-12 -3.01333459e-11 -5.32300099e-12
 -2.52855384e-12 -6.85951283e-13 -2.74812673e-12 -4.86933770e-13
  8.35152271e-11  2.76433691e-11  9.68952643e-11  1.70917344e-11
  6.11704515e-12  2.19805437e-12  7.31281416e-12  1.28712173e-12
  9.63000276e-12  1.53564405e-11  3.27307652e-12  7.50735201e-12
  4.97545374e-12  7.84118815e-12  1.58859719e-12  3.63768269e-12
  7.22198357e-12  1.15724362e-11  1.85971970e-12  4.55331631e-12
  7.28430705e-12  1.13881061e-11  1.75723261e-12  4.25793452e-12
  2.48966910e-12  4.61216426e-12  4.43626078e-13  1.68437603e-14
 -2.51047068e-13  2.38180751e-14 -1.11521500e-12 -7.35873635e-13
  4.83885179e+00]
supnorm grad right now is: 4.838851786557561
Weights right now are: 
[-4.78202691e+00 -7.09393253e-01 -3.61502601e+00 -4.44449569e+00
  5.03659566e+00  6.00701566e-01  4.01396332e+00  3.72846736e+00
 -2.27258901e+00 -9.10902870e-01 -2.25404392e+00 -2.00074241e+00
  1.57272261e+00  4.66763740e-01 -5.62509636e-03  8.35338478e-01
 -1.44534814e+00 -5.14801050e-01 -2.65288653e+00 -2.20784516e+00
 -2.15414447e+00 -9.51836661e-01 -2.40299158e+00 -1.82002229e+00
 -9.72736562e-01 -8.32991558e-01 -1.72255792e+00 -9.12699870e-01
  4.64577206e-01  1.45506580e+00  1.54225949e+00  5.08456085e-01
 -1.09255479e+00 -6.35348538e-01 -1.38944998e+00 -1.20583000e+00
 -2.52058239e+00 -1.43641554e+00 -1.29918984e+00 -1.07248766e+00
 -5.99394927e-01 -1.09674605e+00  2.42252301e-01  3.31560503e-01
  4.35173039e-01  1.12023058e+00 -1.78810039e-01  3.87923166e-01
 -1.46275759e+00 -5.77206591e-01 -4.39355387e-01 -1.59485721e+00
  6.15363746e-01  1.16164598e+00  5.26491030e-01  1.68113616e+00
  1.28404832e+00 -4.78619392e-01 -1.29241071e-01 -2.19426286e+00
  2.09374030e+00  1.58998146e+00 -7.24523287e-02  1.08641480e+00
  2.52872698e+01]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.778317022222
gradient value of function right now is: [ 9.21363091e-09  8.36711809e-10  9.20836786e-09  9.21069702e-09
 -9.21408753e-09 -8.36753548e-10 -9.20882421e-09 -9.21115348e-09
  1.71678983e-10  2.09862133e-11  1.68847650e-10  1.79953589e-10
  9.22420196e-10  1.12831666e-10  9.07296528e-10  9.66924943e-10
  1.70520029e-10  2.08451585e-11  1.67708249e-10  1.78739123e-10
  1.65091879e-10  2.01811152e-11  1.62369400e-10  1.73049081e-10
 -2.54257642e-11 -8.20904948e-12 -2.92554041e-11 -5.15389708e-12
 -2.46425298e-12 -6.75067617e-13 -2.68640332e-12 -4.75664727e-13
  8.05353973e-11  2.72558164e-11  9.42414242e-11  1.65671563e-11
  5.93175376e-12  2.19126517e-12  7.17219005e-12  1.25644395e-12
  9.32595048e-12  1.46986833e-11  3.54360880e-12  7.66213459e-12
  4.81607323e-12  7.50482290e-12  1.72790191e-12  3.72268940e-12
  6.92369217e-12  1.10342633e-11  1.95648901e-12  4.56873278e-12
  6.97754643e-12  1.08493546e-11  1.86323125e-12  4.28895798e-12
  2.41792405e-12  4.27375879e-12  4.34091693e-13  2.04213735e-15
 -2.51503650e-13  4.79280674e-14 -1.09863214e-12 -6.30544132e-13
 -1.00306723e+00]
supnorm grad right now is: 1.003067225756916
Weights right now are: 
[-4.79420023e+00 -7.10496891e-01 -3.62719238e+00 -4.45666514e+00
  5.04876898e+00  6.01805203e-01  4.02612969e+00  3.74063680e+00
 -2.27281557e+00 -9.10930575e-01 -2.25426675e+00 -2.00097990e+00
  1.57150676e+00  4.66614964e-01 -6.82103052e-03  8.34063939e-01
 -1.44557309e+00 -5.14828559e-01 -2.65310778e+00 -2.20808096e+00
 -2.15436228e+00 -9.51863296e-01 -2.40320580e+00 -1.82025061e+00
 -9.72703051e-01 -8.32980767e-01 -1.72251941e+00 -9.12693079e-01
  4.64580421e-01  1.45506668e+00  1.54226300e+00  5.08456706e-01
 -1.09266108e+00 -6.35384395e-01 -1.38957419e+00 -1.20585186e+00
 -2.52059022e+00 -1.43641842e+00 -1.29919929e+00 -1.07248932e+00
 -5.99407233e-01 -1.09676548e+00  2.42247707e-01  3.31550474e-01
  4.35166686e-01  1.12022067e+00 -1.78812276e-01  3.87918298e-01
 -1.46276674e+00 -5.77221188e-01 -4.39357934e-01 -1.59486320e+00
  6.15354524e-01  1.16163163e+00  5.26488605e-01  1.68113054e+00
  1.28404512e+00 -4.78625079e-01 -1.29241644e-01 -2.19426286e+00
  2.09374063e+00  1.58998140e+00 -7.24508802e-02  1.08641564e+00
  2.49040184e+01]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.700514500805
gradient value of function right now is: [ 8.45375160e-09  7.69772343e-10  8.44892955e-09  8.45106315e-09
 -8.45335445e-09 -7.69735632e-10 -8.44853264e-09 -8.45066614e-09
  1.57649331e-10  1.92905113e-11  1.55066179e-10  1.65260063e-10
  8.49748592e-10  1.04040560e-10  8.35903973e-10  8.90810089e-10
  1.56689516e-10  1.91735969e-11  1.54122474e-10  1.64254209e-10
  1.51675272e-10  1.85596013e-11  1.49190203e-10  1.58997668e-10
 -2.35632237e-11 -7.53994833e-12 -2.70215176e-11 -4.76681433e-12
 -2.34696900e-12 -6.43972701e-13 -2.55974730e-12 -4.53334463e-13
  7.42119697e-11  2.48490201e-11  8.64825692e-11  1.52291235e-11
  5.42974760e-12  1.97969443e-12  6.52968397e-12  1.14658680e-12
  8.56137198e-12  1.35695371e-11  3.08637607e-12  6.86018131e-12
  4.42936600e-12  6.93969595e-12  1.50310278e-12  3.33246934e-12
  6.38900118e-12  1.02088004e-11  1.72743431e-12  4.12492833e-12
  6.44242162e-12  1.00434938e-11  1.63969330e-12  3.86623857e-12
  2.21655022e-12  4.00753002e-12  3.95443720e-13  7.60523081e-15
 -2.27256881e-13  3.32036514e-14 -1.00143240e-12 -6.15443004e-13
  1.78505991e+00]
supnorm grad right now is: 1.7850599147387125
Weights right now are: 
[-4.80550873e+00 -7.11525243e-01 -3.63849442e+00 -4.46797003e+00
  5.06007749e+00  6.02833557e-01  4.03743174e+00  3.75194171e+00
 -2.27302640e+00 -9.10956351e-01 -2.25447411e+00 -2.00120089e+00
  1.57037234e+00  4.66476179e-01 -7.93688575e-03  8.32874771e-01
 -1.44578256e+00 -5.14854170e-01 -2.65331380e+00 -2.20830054e+00
 -2.15456507e+00 -9.51888090e-01 -2.40340525e+00 -1.82046317e+00
 -9.72671714e-01 -8.32970676e-01 -1.72248338e+00 -9.12686732e-01
  4.64583497e-01  1.45506753e+00  1.54226635e+00  5.08457299e-01
 -1.09276009e+00 -6.35417803e-01 -1.38968994e+00 -1.20587221e+00
 -2.52059749e+00 -1.43642109e+00 -1.29920807e+00 -1.07249086e+00
 -5.99418694e-01 -1.09678355e+00  2.42243403e-01  3.31541131e-01
  4.35160763e-01  1.12021143e+00 -1.78814375e-01  3.87913758e-01
 -1.46277526e+00 -5.77234760e-01 -4.39360316e-01 -1.59486878e+00
  6.15345936e-01  1.16161828e+00  5.26486338e-01  1.68112530e+00
  1.28404216e+00 -4.78630356e-01 -1.29242174e-01 -2.19426287e+00
  2.09374094e+00  1.58998135e+00 -7.24495383e-02  1.08641643e+00
  2.51075171e+01]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.672910972496
gradient value of function right now is: [ 7.91722139e-09  7.22912168e-10  7.91270841e-09  7.91470484e-09
 -7.91676707e-09 -7.22870153e-10 -7.91225436e-09 -7.91425067e-09
  1.47866097e-10  1.80944054e-11  1.45446937e-10  1.55005854e-10
  7.98975937e-10  9.78292442e-11  7.85978365e-10  8.37590986e-10
  1.47055348e-10  1.79956909e-11  1.44649812e-10  1.54156236e-10
  1.42326912e-10  1.74166640e-11  1.39998559e-10  1.49199273e-10
 -2.22090461e-11 -7.10290004e-12 -2.54635453e-11 -4.49234340e-12
 -2.25701089e-12 -6.21432364e-13 -2.46425082e-12 -4.36398326e-13
  6.96939327e-11  2.33198525e-11  8.11955226e-11  1.42995592e-11
  5.08498911e-12  1.85267699e-12  6.11327599e-12  1.07360755e-12
  8.02954530e-12  1.27312724e-11  2.88512239e-12  6.42396431e-12
  4.15870826e-12  6.51787192e-12  1.40595196e-12  3.12277489e-12
  5.99547988e-12  9.58158155e-12  1.61639076e-12  3.86524558e-12
  6.04647640e-12  9.42780546e-12  1.53410722e-12  3.62288506e-12
  2.07841525e-12  3.76324581e-12  3.69999967e-13  7.31224592e-15
 -2.12881432e-13  3.04625969e-14 -9.39198283e-13 -5.79909062e-13
  1.98398789e+00]
supnorm grad right now is: 1.983987893605799
Weights right now are: 
[-4.81616028e+00 -7.12496585e-01 -3.64913989e+00 -4.47861820e+00
  5.07072904e+00  6.03804898e-01  4.04807721e+00  3.76258987e+00
 -2.27322527e+00 -9.10980673e-01 -2.25466971e+00 -2.00140935e+00
  1.56929948e+00  4.66344883e-01 -8.99223696e-03  8.31750098e-01
 -1.44598028e+00 -5.14878352e-01 -2.65350827e+00 -2.20850779e+00
 -2.15475644e+00 -9.51911495e-01 -2.40359348e+00 -1.82066378e+00
 -9.72641986e-01 -8.32961119e-01 -1.72244923e+00 -9.12680710e-01
  4.64586478e-01  1.45506835e+00  1.54226961e+00  5.08457876e-01
 -1.09285365e+00 -6.35449296e-01 -1.38979918e+00 -1.20589144e+00
 -2.52060434e+00 -1.43642361e+00 -1.29921633e+00 -1.07249231e+00
 -5.99429499e-01 -1.09680062e+00  2.42239421e-01  3.31532374e-01
  4.35155172e-01  1.12020270e+00 -1.78816314e-01  3.87909502e-01
 -1.46278331e+00 -5.77247593e-01 -4.39362533e-01 -1.59487403e+00
  6.15337826e-01  1.16160565e+00  5.26484229e-01  1.68112038e+00
  1.28403936e+00 -4.78635358e-01 -1.29242676e-01 -2.19426287e+00
  2.09374123e+00  1.58998130e+00 -7.24482658e-02  1.08641718e+00
  2.51067046e+01]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.766676980319
gradient value of function right now is: [ 7.49369629e-09  6.86083675e-10  7.48942622e-09  7.49131480e-09
 -7.49317771e-09 -6.86035391e-10 -7.48890795e-09 -7.49079638e-09
  1.40192669e-10  1.71500618e-11  1.37898035e-10  1.46959420e-10
  7.59095904e-10  9.29188855e-11  7.46742467e-10  7.95770988e-10
  1.39502183e-10  1.70660741e-11  1.37219198e-10  1.46235876e-10
  1.34997369e-10  1.65145983e-11  1.32787945e-10  1.41513420e-10
 -2.11209210e-11 -6.77370831e-12 -2.42409022e-11 -4.27504167e-12
 -2.18218132e-12 -6.03373601e-13 -2.38568736e-12 -4.22416582e-13
  6.61001967e-11  2.21882101e-11  7.71033907e-11  1.35724847e-11
  4.81699074e-12  1.76225838e-12  5.80080540e-12  1.01805584e-12
  7.61320552e-12  1.20506184e-11  2.77971574e-12  6.13719253e-12
  3.94599687e-12  6.17432468e-12  1.35621735e-12  2.98628286e-12
  5.67752553e-12  9.06611553e-12  1.55122212e-12  3.68413268e-12
  5.72568579e-12  8.92043405e-12  1.47404497e-12  3.45543117e-12
  1.97136443e-12  3.54549010e-12  3.50768271e-13  5.06122139e-15
 -2.02856707e-13  3.19154195e-14 -8.93080115e-13 -5.40406914e-13
  1.15277788e+00]
supnorm grad right now is: 1.1527778796753987
Weights right now are: 
[-4.82614723e+00 -7.13409813e-01 -3.65912115e+00 -4.48860198e+00
  5.08071599e+00  6.04718127e-01  4.05805847e+00  3.77257365e+00
 -2.27341203e+00 -9.11003510e-01 -2.25485341e+00 -2.00160512e+00
  1.56828964e+00  4.66221327e-01 -9.98559385e-03  8.30691509e-01
 -1.44616607e+00 -5.14901070e-01 -2.65369101e+00 -2.20870254e+00
 -2.15493625e+00 -9.51933481e-01 -2.40377034e+00 -1.82085226e+00
 -9.72613962e-01 -8.32952097e-01 -1.72241703e+00 -9.12675031e-01
  4.64589341e-01  1.45506914e+00  1.54227274e+00  5.08458430e-01
 -1.09294157e+00 -6.35478944e-01 -1.38990191e+00 -1.20590951e+00
 -2.52061077e+00 -1.43642597e+00 -1.29922409e+00 -1.07249367e+00
 -5.99439644e-01 -1.09681663e+00  2.42235634e-01  3.31524111e-01
  4.35149917e-01  1.12019450e+00 -1.78818162e-01  3.87905482e-01
 -1.46279086e+00 -5.77259630e-01 -4.39364633e-01 -1.59487897e+00
  6.15330210e-01  1.16159381e+00  5.26482230e-01  1.68111574e+00
  1.28403673e+00 -4.78640038e-01 -1.29243146e-01 -2.19426287e+00
  2.09374150e+00  1.58998125e+00 -7.24470718e-02  1.08641788e+00
  2.50852884e+01]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.638225194806
gradient value of function right now is: [ 7.23417978e-09  6.64150419e-10  7.23005605e-09  7.23187946e-09
 -7.23459308e-09 -6.64189023e-10 -7.23046910e-09 -7.23229263e-09
  1.35657848e-10  1.65753245e-11  1.33426020e-10  1.42194458e-10
  7.35558296e-10  8.99353530e-11  7.23529145e-10  7.71038697e-10
  1.35058273e-10  1.65025665e-11  1.32836665e-10  1.41566276e-10
  1.30679687e-10  1.59671642e-11  1.28529936e-10  1.36976495e-10
 -2.04170801e-11 -6.61858755e-12 -2.35275355e-11 -4.14260226e-12
 -2.13124985e-12 -5.93331561e-13 -2.33508962e-12 -4.13239545e-13
  6.38500395e-11  2.17034587e-11  7.48429304e-11  1.31482044e-11
  4.66463030e-12  1.73338730e-12  5.65381015e-12  9.89500435e-13
  7.36962155e-12  1.15870968e-11  2.86047936e-12  6.11727852e-12
  3.81968780e-12  5.93809289e-12  1.39947810e-12  2.98169648e-12
  5.46469065e-12  8.69886213e-12  1.57174009e-12  3.63753976e-12
  5.50863705e-12  8.55537042e-12  1.49974906e-12  3.41910330e-12
  1.91080663e-12  3.34489516e-12  3.41278891e-13 -1.33791084e-15
 -1.99943838e-13  4.17315390e-14 -8.72608825e-13 -4.86591767e-13
 -2.15219674e+00]
supnorm grad right now is: 2.1521967444429664
Weights right now are: 
[-4.83551516e+00 -7.14268599e-01 -3.66848374e+00 -4.49796693e+00
  5.09008390e+00  6.05576911e-01  4.06742104e+00  3.78193858e+00
 -2.27358746e+00 -9.11024961e-01 -2.25502596e+00 -2.00178901e+00
  1.56733897e+00  4.66105002e-01 -1.09207732e-02  8.29694931e-01
 -1.44634067e+00 -5.14922422e-01 -2.65386276e+00 -2.20888557e+00
 -2.15510520e+00 -9.51954141e-01 -2.40393652e+00 -1.82102936e+00
 -9.72587519e-01 -8.32943591e-01 -1.72238664e+00 -9.12669677e-01
  4.64592091e-01  1.45506990e+00  1.54227574e+00  5.08458963e-01
 -1.09302426e+00 -6.35506798e-01 -1.38999850e+00 -1.20592650e+00
 -2.52061680e+00 -1.43642819e+00 -1.29923136e+00 -1.07249495e+00
 -5.99449176e-01 -1.09683169e+00  2.42232088e-01  3.31516366e-01
  4.35144975e-01  1.12018679e+00 -1.78819894e-01  3.87901711e-01
 -1.46279795e+00 -5.77270945e-01 -4.39366602e-01 -1.59488360e+00
  6.15323056e-01  1.16158268e+00  5.26480356e-01  1.68111139e+00
  1.28403427e+00 -4.78644439e-01 -1.29243584e-01 -2.19426288e+00
  2.09374176e+00  1.58998120e+00 -7.24459527e-02  1.08641854e+00
  2.48114325e+01]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.215007891135
gradient value of function right now is: [ 6.93478490e-09  6.38264795e-10  6.93083185e-09  6.93257944e-09
 -6.93477474e-09 -6.38263459e-10 -6.93082170e-09 -6.93256929e-09
  1.30276036e-10  1.59068840e-11  1.28127426e-10  1.36547309e-10
  7.07530283e-10  8.64527679e-11  6.95932383e-10  7.41628073e-10
  1.29763430e-10  1.58447937e-11  1.27623627e-10  1.36010310e-10
  1.25541733e-10  1.53289179e-11  1.23471375e-10  1.31585173e-10
 -1.96280524e-11 -6.40107232e-12 -2.26696171e-11 -3.98784166e-12
 -2.07431921e-12 -5.80364827e-13 -2.27632307e-12 -4.02710037e-13
  6.12793188e-11  2.09764379e-11  7.20279463e-11  1.26388013e-11
  4.47883719e-12  1.67919712e-12  5.44885429e-12  9.52046878e-13
  7.07750344e-12  1.10857112e-11  2.84094681e-12  5.97127821e-12
  3.66979452e-12  5.68406403e-12  1.39262349e-12  2.91440959e-12
  5.23244701e-12  8.31417732e-12  1.54804827e-12  3.53222321e-12
  5.27356015e-12  8.17554575e-12  1.48027508e-12  3.32405603e-12
  1.83630132e-12  3.16545495e-12  3.28236922e-13 -4.57334159e-15
 -1.93872969e-13  4.59427958e-14 -8.42324344e-13 -4.47803002e-13
 -3.91650592e+00]
supnorm grad right now is: 3.9165059209051805
Weights right now are: 
[-4.84441853e+00 -7.15086795e-01 -3.67738203e+00 -4.50686746e+00
  5.09898727e+00  6.06395108e-01  4.07631934e+00  3.79083912e+00
 -2.27375442e+00 -9.11045379e-01 -2.25519019e+00 -2.00196403e+00
  1.56643233e+00  4.65994061e-01 -1.18126553e-02  8.28744500e-01
 -1.44650694e+00 -5.14942755e-01 -2.65402631e+00 -2.20905986e+00
 -2.15526607e+00 -9.51973814e-01 -2.40409476e+00 -1.82119800e+00
 -9.72562262e-01 -8.32935457e-01 -1.72235761e+00 -9.12664559e-01
  4.64594758e-01  1.45507064e+00  1.54227867e+00  5.08459480e-01
 -1.09310302e+00 -6.35533363e-01 -1.39009054e+00 -1.20594269e+00
 -2.52062253e+00 -1.43643030e+00 -1.29923828e+00 -1.07249616e+00
 -5.99458233e-01 -1.09684601e+00  2.42228712e-01  3.31508968e-01
  4.35140277e-01  1.12017944e+00 -1.78821545e-01  3.87898106e-01
 -1.46280470e+00 -5.77281712e-01 -4.39368480e-01 -1.59488803e+00
  6.15316255e-01  1.16157209e+00  5.26478571e-01  1.68110723e+00
  1.28403192e+00 -4.78648621e-01 -1.29244004e-01 -2.19426288e+00
  2.09374200e+00  1.58998116e+00 -7.24448807e-02  1.08641917e+00
  2.47019177e+01]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.798064258733
gradient value of function right now is: [ 6.45322253e-09  5.95093961e-10  6.44954925e-09  6.45117296e-09
 -6.45360987e-09 -5.95130024e-10 -6.44993636e-09 -6.45156018e-09
  1.21267086e-10  1.48248327e-11  1.19281426e-10  1.27115955e-10
  6.60396872e-10  8.07858621e-11  6.49646987e-10  6.92281285e-10
  1.20849826e-10  1.47742568e-11  1.18871309e-10  1.26678815e-10
  1.16901711e-10  1.42912495e-11  1.14987687e-10  1.22540091e-10
 -1.84335215e-11 -5.94778735e-12 -2.12043229e-11 -3.73629851e-12
 -1.98972800e-12 -5.56047618e-13 -2.18257340e-12 -3.86277597e-13
  5.72511857e-11  1.93509346e-11  6.69599256e-11  1.17742137e-11
  4.15568243e-12  1.53392877e-12  5.02280453e-12  8.80174546e-13
  6.58552167e-12  1.03866247e-11  2.48812711e-12  5.39651735e-12
  3.42051378e-12  5.33351215e-12  1.21757150e-12  2.63240581e-12
  4.89813013e-12  7.80860450e-12  1.37694554e-12  3.22368640e-12
  4.93962980e-12  7.68308900e-12  1.31184542e-12  3.02801074e-12
  1.70657399e-12  3.02327733e-12  3.03172135e-13  1.02123929e-15
 -1.77229504e-13  3.29858632e-14 -7.77604847e-13 -4.50280444e-13
 -6.84145332e-01]
supnorm grad right now is: 0.6841453318072319
Weights right now are: 
[-4.85286308e+00 -7.15864570e-01 -3.68582178e+00 -4.51530933e+00
  5.10743182e+00  6.07172882e-01  4.08475908e+00  3.79928099e+00
 -2.27391296e+00 -9.11064766e-01 -2.25534614e+00 -2.00213022e+00
  1.56556961e+00  4.65888496e-01 -1.26613485e-02  8.27840113e-01
 -1.44666490e+00 -5.14962072e-01 -2.65418168e+00 -2.20922544e+00
 -2.15541888e+00 -9.51992500e-01 -2.40424507e+00 -1.82135817e+00
 -9.72538173e-01 -8.32927708e-01 -1.72232993e+00 -9.12659678e-01
  4.64597344e-01  1.45507136e+00  1.54228150e+00  5.08459981e-01
 -1.09317789e+00 -6.35558580e-01 -1.39017798e+00 -1.20595808e+00
 -2.52062796e+00 -1.43643229e+00 -1.29924483e+00 -1.07249731e+00
 -5.99466844e-01 -1.09685960e+00  2.42225518e-01  3.31501975e-01
  4.35135804e-01  1.12017246e+00 -1.78823106e-01  3.87894697e-01
 -1.46281111e+00 -5.77291941e-01 -4.39370256e-01 -1.59489222e+00
  6.15309782e-01  1.16156202e+00  5.26476881e-01  1.68110330e+00
  1.28402969e+00 -4.78652606e-01 -1.29244400e-01 -2.19426288e+00
  2.09374223e+00  1.58998112e+00 -7.24438669e-02  1.08641977e+00
  2.49474493e+01]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.805773100656
gradient value of function right now is: [ 6.14142814e-09  5.67540271e-10  6.13793415e-09  6.13947837e-09
 -6.14182778e-09 -5.67577805e-10 -6.13833356e-09 -6.13987788e-09
  1.15536970e-10  1.41250325e-11  1.13647409e-10  1.21110336e-10
  6.30392328e-10  7.71190548e-11  6.20143167e-10  6.60832712e-10
  1.15191044e-10  1.40831533e-11  1.13307435e-10  1.20747955e-10
  1.11414819e-10  1.36211535e-11  1.09592823e-10  1.16789392e-10
 -1.76294559e-11 -5.68583889e-12 -2.02759131e-11 -3.57302935e-12
 -1.93007751e-12 -5.40578090e-13 -2.11860558e-12 -3.74946333e-13
  5.45990080e-11  1.84436689e-11  6.38430990e-11  1.12273984e-11
  3.95423905e-12  1.45869332e-12  4.77808880e-12  8.37411848e-13
  6.27366502e-12  9.89802829e-12  2.36364647e-12  5.13430464e-12
  3.26129958e-12  5.08684172e-12  1.15716604e-12  2.50583689e-12
  4.66837967e-12  7.44346963e-12  1.30919874e-12  3.06882561e-12
  4.70850884e-12  7.32472561e-12  1.24719439e-12  2.88258602e-12
  1.62567243e-12  2.88341864e-12  2.88301925e-13  1.07641995e-15
 -1.68711926e-13  3.10386974e-14 -7.40860202e-13 -4.30660719e-13
 -5.20388238e-01]
supnorm grad right now is: 0.5203882380843982
Weights right now are: 
[-4.86089107e+00 -7.16605624e-01 -3.69384520e+00 -4.52333477e+00
  5.11545981e+00  6.07913936e-01  4.09278250e+00  3.80730642e+00
 -2.27406388e+00 -9.11083223e-01 -2.25549459e+00 -2.00228842e+00
  1.56474688e+00  4.65787816e-01 -1.34707034e-02  8.26977643e-01
 -1.44681533e+00 -5.14980469e-01 -2.65432965e+00 -2.20938313e+00
 -2.15556439e+00 -9.52010295e-01 -2.40438820e+00 -1.82151071e+00
 -9.72515168e-01 -8.32920300e-01 -1.72230349e+00 -9.12655017e-01
  4.64599846e-01  1.45507206e+00  1.54228425e+00  5.08460467e-01
 -1.09324922e+00 -6.35582623e-01 -1.39026131e+00 -1.20597274e+00
 -2.52063313e+00 -1.43643419e+00 -1.29925107e+00 -1.07249840e+00
 -5.99475036e-01 -1.09687256e+00  2.42222468e-01  3.31495300e-01
  4.35131548e-01  1.12016581e+00 -1.78824598e-01  3.87891442e-01
 -1.46281721e+00 -5.77301686e-01 -4.39371950e-01 -1.59489622e+00
  6.15303633e-01  1.16155243e+00  5.26475268e-01  1.68109955e+00
  1.28402756e+00 -4.78656396e-01 -1.29244777e-01 -2.19426289e+00
  2.09374245e+00  1.58998109e+00 -7.24428993e-02  1.08642034e+00
  2.49702307e+01]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.74660566433
gradient value of function right now is: [ 5.79429416e-09  5.36459846e-10  5.79100089e-09  5.79245621e-09
 -5.79459322e-09 -5.36488111e-10 -5.79129976e-09 -5.79275517e-09
  1.09067667e-10  1.33430039e-11  1.07291714e-10  1.14334657e-10
  5.96416914e-10  7.30084810e-11  5.86761405e-10  6.25246210e-10
  1.08788522e-10  1.33092272e-11  1.07017382e-10  1.14042241e-10
  1.05209978e-10  1.28711335e-11  1.03496978e-10  1.10290726e-10
 -1.67471124e-11 -5.36906114e-12 -1.92179593e-11 -3.38968403e-12
 -1.86391577e-12 -5.21944637e-13 -2.04577669e-12 -3.62145526e-13
  5.16629374e-11  1.73280078e-11  6.02431167e-11  1.06064332e-11
  3.72417845e-12  1.36187082e-12  4.48383333e-12  7.87088106e-13
  5.92088049e-12  9.37634855e-12  2.15362252e-12  4.76542312e-12
  3.08192968e-12  4.82433300e-12  1.05356181e-12  2.32567677e-12
  4.42118343e-12  7.06149460e-12  1.20380362e-12  2.86433571e-12
  4.46101104e-12  6.95168223e-12  1.14428772e-12  2.68772026e-12
  1.53272262e-12  2.76002657e-12  2.70686927e-13  3.58904797e-15
 -1.57565142e-13  2.42958186e-14 -6.95967902e-13 -4.23405560e-13
  1.36908169e+00]
supnorm grad right now is: 1.3690816860715869
Weights right now are: 
[-4.86852338e+00 -7.17311602e-01 -3.70147317e+00 -4.53096466e+00
  5.12309213e+00  6.08619915e-01  4.10041048e+00  3.81493632e+00
 -2.27420751e+00 -9.11100786e-01 -2.25563587e+00 -2.00243898e+00
  1.56396240e+00  4.65691827e-01 -1.42424588e-02  8.26155261e-01
 -1.44695856e+00 -5.14997984e-01 -2.65447055e+00 -2.20953328e+00
 -2.15570291e+00 -9.52027234e-01 -2.40452446e+00 -1.82165592e+00
 -9.72493193e-01 -8.32913227e-01 -1.72227824e+00 -9.12650564e-01
  4.64602271e-01  1.45507274e+00  1.54228691e+00  5.08460939e-01
 -1.09331715e+00 -6.35605518e-01 -1.39034067e+00 -1.20598671e+00
 -2.52063804e+00 -1.43643600e+00 -1.29925700e+00 -1.07249944e+00
 -5.99482830e-01 -1.09688488e+00  2.42219574e-01  3.31488953e-01
  4.35127494e-01  1.12015947e+00 -1.78826014e-01  3.87888344e-01
 -1.46282302e+00 -5.77310952e-01 -4.39373561e-01 -1.59490002e+00
  6.15297771e-01  1.16154331e+00  5.26473735e-01  1.68109598e+00
  1.28402554e+00 -4.78659997e-01 -1.29245137e-01 -2.19426289e+00
  2.09374266e+00  1.58998105e+00 -7.24419774e-02  1.08642088e+00
  2.50845570e+01]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.798208747015
gradient value of function right now is: [ 5.56856811e-09  5.16598286e-10  5.56540393e-09  5.56680199e-09
 -5.56875614e-09 -5.16616170e-10 -5.56559184e-09 -5.56698995e-09
  1.04947555e-10  1.28357285e-11  1.03237983e-10  1.10014066e-10
  5.74789396e-10  7.03442757e-11  5.65480650e-10  6.02565541e-10
  1.04720778e-10  1.28083571e-11  1.03015162e-10  1.09776546e-10
  1.01265926e-10  1.23855093e-11  9.96164605e-11  1.06154749e-10
 -1.61510251e-11 -5.18939502e-12 -1.85492114e-11 -3.27064655e-12
 -1.81763077e-12 -5.10503421e-13 -1.99687246e-12 -3.53429242e-13
  4.97226306e-11  1.67192638e-11  5.80372115e-11  1.02138725e-11
  3.58092818e-12  1.31368924e-12  4.31706248e-12  7.57383664e-13
  5.69774279e-12  9.01015560e-12  2.09899000e-12  4.61275395e-12
  2.96737612e-12  4.63866837e-12  1.02774732e-12  2.25280302e-12
  4.24999707e-12  6.78350186e-12  1.16948967e-12  2.76734542e-12
  4.28821438e-12  6.67792934e-12  1.11281486e-12  2.59817657e-12
  1.47499431e-12  2.64211099e-12  2.60392637e-13  2.36195408e-15
 -1.52148932e-13  2.50973438e-14 -6.71059396e-13 -4.01846490e-13
  6.77883027e-01]
supnorm grad right now is: 0.677883026801153
Weights right now are: 
[-4.87584214e+00 -7.17989934e-01 -3.70878777e+00 -4.53828110e+00
  5.13041089e+00  6.09298247e-01  4.10772509e+00  3.82225277e+00
 -2.27434539e+00 -9.11117647e-01 -2.25577151e+00 -2.00258352e+00
  1.56320800e+00  4.65599515e-01 -1.49846158e-02  8.25364421e-01
 -1.44709612e+00 -5.15014806e-01 -2.65460586e+00 -2.20967747e+00
 -2.15583594e+00 -9.52043502e-01 -2.40465532e+00 -1.82179536e+00
 -9.72472028e-01 -8.32906414e-01 -1.72225391e+00 -9.12646277e-01
  4.64604635e-01  1.45507341e+00  1.54228950e+00  5.08461398e-01
 -1.09338242e+00 -6.35627515e-01 -1.39041692e+00 -1.20600012e+00
 -2.52064275e+00 -1.43643773e+00 -1.29926268e+00 -1.07250044e+00
 -5.99490316e-01 -1.09689671e+00  2.42216783e-01  3.31482859e-01
  4.35123598e-01  1.12015339e+00 -1.78827381e-01  3.87885368e-01
 -1.46282860e+00 -5.77319854e-01 -4.39375111e-01 -1.59490367e+00
  6.15292146e-01  1.16153455e+00  5.26472259e-01  1.68109255e+00
  1.28402360e+00 -4.78663455e-01 -1.29245479e-01 -2.19426289e+00
  2.09374286e+00  1.58998101e+00 -7.24410948e-02  1.08642140e+00
  2.50650285e+01]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.81413974196
gradient value of function right now is: [ 5.36629677e-09  4.98808186e-10  5.36324806e-09  5.36459490e-09
 -5.36637391e-09 -4.98815640e-10 -5.36332516e-09 -5.36467201e-09
  1.01261096e-10  1.23810101e-11  9.96102406e-11  1.06147685e-10
  5.55411209e-10  6.79528644e-11  5.46409627e-10  5.82240943e-10
  1.01080791e-10  1.23593235e-11  9.94331324e-11  1.05958881e-10
  9.77367671e-11  1.19501634e-11  9.61434986e-11  1.02453330e-10
 -1.56126432e-11 -5.03056210e-12 -1.79496974e-11 -3.16366859e-12
 -1.77498945e-12 -5.00069872e-13 -1.95194653e-12 -3.45419485e-13
  4.79780074e-11  1.61853654e-11  5.60715463e-11  9.86291677e-12
  3.45321784e-12  1.27213853e-12  4.17026613e-12  7.31098862e-13
  5.49731602e-12  8.67890069e-12  2.05823148e-12  4.48522793e-12
  2.86434153e-12  4.47047557e-12  1.00889210e-12  2.19230316e-12
  4.09509264e-12  6.53137961e-12  1.14218378e-12  2.68441548e-12
  4.13165861e-12  6.42933270e-12  1.08804368e-12  2.52184992e-12
  1.42388049e-12  2.53254318e-12  2.51338761e-13  1.06784974e-15
 -1.47509636e-13  2.63647948e-14 -6.49306254e-13 -3.80840193e-13
 -1.77140804e-01]
supnorm grad right now is: 0.17714080408614089
Weights right now are: 
[-4.88287401e+00 -7.18642908e-01 -3.71581565e+00 -4.54531074e+00
  5.13744277e+00  6.09951222e-01  4.11475297e+00  3.82928241e+00
 -2.27447799e+00 -9.11133866e-01 -2.25590195e+00 -2.00272252e+00
  1.56248122e+00  4.65510565e-01 -1.56996284e-02  8.24602514e-01
 -1.44722846e+00 -5.15030993e-01 -2.65473604e+00 -2.20981620e+00
 -2.15596391e+00 -9.52059154e-01 -2.40478120e+00 -1.82192951e+00
 -9.72451596e-01 -8.32899843e-01 -1.72223044e+00 -9.12642138e-01
  4.64606945e-01  1.45507406e+00  1.54229204e+00  5.08461848e-01
 -1.09344527e+00 -6.35648662e-01 -1.39049029e+00 -1.20601304e+00
 -2.52064727e+00 -1.43643939e+00 -1.29926813e+00 -1.07250140e+00
 -5.99497515e-01 -1.09690810e+00  2.42214122e-01  3.31477021e-01
  4.35119849e-01  1.12014752e+00 -1.78828684e-01  3.87882517e-01
 -1.46283397e+00 -5.77328429e-01 -4.39376592e-01 -1.59490717e+00
  6.15286734e-01  1.16152611e+00  5.26470849e-01  1.68108926e+00
  1.28402173e+00 -4.78666796e-01 -1.29245808e-01 -2.19426289e+00
  2.09374305e+00  1.58998098e+00 -7.24402456e-02  1.08642191e+00
  2.49826162e+01]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5141.098143633466
gradient value of function right now is: [ 4.91893990e-09  4.57755937e-10  4.91615212e-09  4.91738366e-09
 -4.91906980e-09 -4.57768188e-10 -4.91628194e-09 -4.91751352e-09
  9.27190412e-11  1.13659641e-11  9.12290466e-11  9.72109640e-11
  5.10220685e-10  6.25764515e-11  5.02065709e-10  5.34958716e-10
  9.25927302e-11  1.13507538e-11  9.11049687e-11  9.70786852e-11
  8.95181521e-11  1.09736283e-11  8.80797072e-11  9.38550373e-11
 -1.44983574e-11 -4.56293126e-12 -1.65240213e-11 -2.92205927e-12
 -1.68810983e-12 -4.71470851e-13 -1.85103529e-12 -3.27953501e-13
  4.42236678e-11  1.45109042e-11  5.11377215e-11  9.03231133e-12
  3.14397754e-12  1.11911790e-12  3.74399950e-12  6.60132960e-13
  5.02805833e-12  8.05414222e-12  1.63369946e-12  3.84081374e-12
  2.62747197e-12  4.15802973e-12  7.97646650e-13  1.87446522e-12
  3.79499079e-12  6.09316212e-12  9.41120901e-13  2.34942778e-12
  3.83388592e-12  6.00588007e-12  8.87440880e-13  2.19671049e-12
  1.29701733e-12  2.44459048e-12  2.25949552e-13  1.03552355e-14
 -1.29150386e-13  7.20782097e-15 -5.81702148e-13 -4.04535336e-13
  7.18312889e+00]
supnorm grad right now is: 7.183128894583678
Weights right now are: 
[-4.88958793e+00 -7.19267533e-01 -3.72252576e+00 -4.55202253e+00
  5.14415669e+00  6.10575846e-01  4.12146307e+00  3.83599420e+00
 -2.27460474e+00 -9.11149365e-01 -2.25602663e+00 -2.00285539e+00
  1.56178547e+00  4.65425434e-01 -1.63841135e-02  8.23873144e-01
 -1.44735500e+00 -5.15046468e-01 -2.65486053e+00 -2.20994886e+00
 -2.15608626e+00 -9.52074115e-01 -2.40490156e+00 -1.82205777e+00
 -9.72432022e-01 -8.32893537e-01 -1.72220794e+00 -9.12638172e-01
  4.64609183e-01  1.45507469e+00  1.54229450e+00  5.08462283e-01
 -1.09350535e+00 -6.35668923e-01 -1.39056050e+00 -1.20602539e+00
 -2.52065159e+00 -1.43644098e+00 -1.29927335e+00 -1.07250231e+00
 -5.99504394e-01 -1.09691897e+00  2.42211558e-01  3.31471412e-01
  4.35116264e-01  1.12014192e+00 -1.78829940e-01  3.87879775e-01
 -1.46283909e+00 -5.77336609e-01 -4.39378018e-01 -1.59491054e+00
  6.15281564e-01  1.16151806e+00  5.26469491e-01  1.68108610e+00
  1.28401994e+00 -4.78669967e-01 -1.29246123e-01 -2.19426290e+00
  2.09374324e+00  1.58998095e+00 -7.24394311e-02  1.08642239e+00
  2.54772600e+01]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.7597988687
gradient value of function right now is: [ 4.98890730e-09  4.65416264e-10  4.98607441e-09  4.98732555e-09
 -4.98926064e-09 -4.65449871e-10 -4.98642753e-09 -4.98767877e-09
  9.43481784e-11  1.15312336e-11  9.28093047e-11  9.88990961e-11
  5.18992169e-10  6.34734614e-11  5.10577614e-10  5.44052046e-10
  9.42476300e-11  1.15192870e-11  9.27106403e-11  9.87938907e-11
  9.11128050e-11  1.11358704e-11  8.96268248e-11  9.55077089e-11
 -1.46102098e-11 -4.72411730e-12 -1.68192832e-11 -2.96292420e-12
 -1.69420126e-12 -4.79740400e-13 -1.86614734e-12 -3.30140489e-13
  4.47264627e-11  1.51488343e-11  5.23526305e-11  9.20298522e-12
  3.21288083e-12  1.18967562e-12  3.88823515e-12  6.81061382e-13
  5.12186316e-12  8.06901159e-12  1.95509453e-12  4.21837787e-12
  2.67148891e-12  4.16093991e-12  9.59812962e-13  2.06451754e-12
  3.80932300e-12  6.06950804e-12  1.07987751e-12  2.51760850e-12
  3.84334737e-12  5.97469823e-12  1.03021651e-12  2.36714978e-12
  1.32707000e-12  2.33960786e-12  2.34140358e-13 -5.27662248e-16
 -1.38248550e-13  2.69680785e-14 -6.07245298e-13 -3.46989589e-13
 -1.22294847e+00]
supnorm grad right now is: 1.2229484705657765
Weights right now are: 
[-4.89606826e+00 -7.19871499e-01 -3.72900241e+00 -4.55850081e+00
  5.15063701e+00  6.11179812e-01  4.12793972e+00  3.84247247e+00
 -2.27472720e+00 -9.11164337e-01 -2.25614709e+00 -2.00298376e+00
  1.56111222e+00  4.65343066e-01 -1.70464555e-02  8.23167378e-01
 -1.44747731e+00 -5.15061422e-01 -2.65498084e+00 -2.21007706e+00
 -2.15620450e+00 -9.52088573e-01 -2.40501788e+00 -1.82218172e+00
 -9.72413059e-01 -8.32887425e-01 -1.72218613e+00 -9.12634329e-01
  4.64611374e-01  1.45507531e+00  1.54229692e+00  5.08462710e-01
 -1.09356343e+00 -6.35688520e-01 -1.39062838e+00 -1.20603733e+00
 -2.52065576e+00 -1.43644252e+00 -1.29927839e+00 -1.07250319e+00
 -5.99511037e-01 -1.09692946e+00  2.42209072e-01  3.31465982e-01
  4.35112799e-01  1.12013651e+00 -1.78831160e-01  3.87877119e-01
 -1.46284404e+00 -5.77344506e-01 -4.39379398e-01 -1.59491379e+00
  6.15276568e-01  1.16151029e+00  5.26468176e-01  1.68108305e+00
  1.28401822e+00 -4.78673020e-01 -1.29246428e-01 -2.19426290e+00
  2.09374342e+00  1.58998092e+00 -7.24386434e-02  1.08642285e+00
  2.49146776e+01]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.7835417615315
gradient value of function right now is: [ 4.73942048e-09  4.42797771e-10  4.73673188e-09  4.73791919e-09
 -4.73989155e-09 -4.42842117e-10 -4.73720268e-09 -4.73839011e-09
  8.96559857e-11  1.09661388e-11  8.82005854e-11  9.39858428e-11
  4.94158764e-10  6.04799204e-11  4.86183754e-10  5.18047047e-10
  8.95920911e-11  1.09586338e-11  8.81379512e-11  9.39190366e-11
  8.66036678e-11  1.05928560e-11  8.51979303e-11  9.07861569e-11
 -1.39687091e-11 -4.48570580e-12 -1.60392766e-11 -2.82846178e-12
 -1.64228886e-12 -4.64344164e-13 -1.80800848e-12 -3.19968169e-13
  4.26055605e-11  1.43133090e-11  4.97123266e-11  8.75023320e-12
  3.04588093e-12  1.11660360e-12  3.67085763e-12  6.44145500e-13
  4.86569842e-12  7.69834229e-12  1.78492797e-12  3.93174631e-12
  2.54111775e-12  3.97418805e-12  8.75450795e-13  1.92386508e-12
  3.63309485e-12  5.80021094e-12  9.96042819e-13  2.36141918e-12
  3.66718023e-12  5.71214687e-12  9.47855228e-13  2.21759774e-12
  1.25931429e-12  2.25937963e-12  2.21142357e-13  1.96505164e-15
 -1.29764457e-13  2.09674945e-14 -5.73676545e-13 -3.45584346e-13
  9.26168400e-01]
supnorm grad right now is: 0.9261684002033175
Weights right now are: 
[-4.90227931e+00 -7.20451365e-01 -3.73520993e+00 -4.56470988e+00
  5.15684805e+00  6.11759677e-01  4.13414723e+00  3.84868155e+00
 -2.27484468e+00 -9.11178701e-01 -2.25626266e+00 -2.00310691e+00
  1.56046539e+00  4.65263927e-01 -1.76828212e-02  8.22489296e-01
 -1.44759468e+00 -5.15075774e-01 -2.65509631e+00 -2.21020010e+00
 -2.15631797e+00 -9.52102446e-01 -2.40512950e+00 -1.82230066e+00
 -9.72394816e-01 -8.32881543e-01 -1.72216516e+00 -9.12630631e-01
  4.64613503e-01  1.45507591e+00  1.54229926e+00  5.08463125e-01
 -1.09361918e+00 -6.35707343e-01 -1.39069355e+00 -1.20604879e+00
 -2.52065976e+00 -1.43644399e+00 -1.29928322e+00 -1.07250404e+00
 -5.99517410e-01 -1.09693952e+00  2.42206674e-01  3.31460769e-01
  4.35109472e-01  1.12013132e+00 -1.78832338e-01  3.87874567e-01
 -1.46284879e+00 -5.77352085e-01 -4.39380726e-01 -1.59491690e+00
  6.15271776e-01  1.16150283e+00  5.26466911e-01  1.68108012e+00
  1.28401657e+00 -4.78675953e-01 -1.29246718e-01 -2.19426290e+00
  2.09374359e+00  1.58998089e+00 -7.24378889e-02  1.08642329e+00
  2.50574736e+01]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.801383389273
gradient value of function right now is: [ 4.61696261e-09  4.32111663e-10  4.61434329e-09  4.61549983e-09
 -4.61696866e-09 -4.32112435e-10 -4.61434933e-09 -4.61550588e-09
  8.74472716e-11  1.06900521e-11  8.60246012e-11  9.16671897e-11
  4.82508488e-10  5.90231741e-11  4.74705234e-10  5.05816633e-10
  8.74123131e-11  1.06860919e-11  8.59904354e-11  9.16307205e-11
  8.44906726e-11  1.03286791e-11  8.31162152e-11  8.85679566e-11
 -1.36300533e-11 -4.39889480e-12 -1.56796948e-11 -2.76302722e-12
 -1.61366341e-12 -4.57978968e-13 -1.77868305e-12 -3.14681957e-13
  4.15301472e-11  1.40335782e-11  4.85671011e-11  8.54080538e-12
  2.97077112e-12  1.09708439e-12  3.59119849e-12  6.29355558e-13
  4.74602255e-12  7.48628046e-12  1.79172678e-12  3.88810871e-12
  2.47903556e-12  3.86581312e-12  8.80036522e-13  1.90428990e-12
  3.53468554e-12  5.63521008e-12  9.92640456e-13  2.32502856e-12
  3.56719848e-12  5.54866823e-12  9.46464670e-13  2.18567232e-12
  1.22930092e-12  2.17804747e-12  2.16130902e-13  7.99514747e-17
 -1.27672150e-13  2.37363897e-14 -5.62169206e-13 -3.26247604e-13
 -6.23493529e-01]
supnorm grad right now is: 0.6234935287133357
Weights right now are: 
[-4.90825966e+00 -7.21010634e-01 -3.74118689e+00 -4.57068834e+00
  5.16282840e+00  6.12318946e-01  4.14012419e+00  3.85466000e+00
 -2.27495791e+00 -9.11192542e-01 -2.25637405e+00 -2.00322560e+00
  1.55984111e+00  4.65187569e-01 -1.82969933e-02  8.21834868e-01
 -1.44770785e+00 -5.15089607e-01 -2.65520763e+00 -2.21031873e+00
 -2.15642736e+00 -9.52115817e-01 -2.40523711e+00 -1.82241533e+00
 -9.72377199e-01 -8.32875853e-01 -1.72214488e+00 -9.12627059e-01
  4.64615578e-01  1.45507650e+00  1.54230155e+00  5.08463529e-01
 -1.09367293e+00 -6.35725523e-01 -1.39075643e+00 -1.20605985e+00
 -2.52066361e+00 -1.43644542e+00 -1.29928787e+00 -1.07250486e+00
 -5.99523553e-01 -1.09694921e+00  2.42204341e-01  3.31455721e-01
  4.35106265e-01  1.12012632e+00 -1.78833484e-01  3.87872094e-01
 -1.46285337e+00 -5.77359377e-01 -4.39382017e-01 -1.59491992e+00
  6.15267160e-01  1.16149565e+00  5.26465681e-01  1.68107728e+00
  1.28401497e+00 -4.78678771e-01 -1.29246999e-01 -2.19426290e+00
  2.09374375e+00  1.58998086e+00 -7.24371610e-02  1.08642371e+00
  2.49237761e+01]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.361716929306
gradient value of function right now is: [ 4.33882728e-09  4.06568868e-10  4.33636950e-09  4.33745467e-09
 -4.33847086e-09 -4.06534953e-10 -4.33601330e-09 -4.33709836e-09
  8.21456984e-11  1.00571075e-11  8.08207317e-11  8.61189959e-11
  4.54333372e-10  5.56556741e-11  4.47046657e-10  4.76328658e-10
  8.21409719e-11  1.00567953e-11  8.08162759e-11  8.61141894e-11
  7.93881856e-11  9.71955209e-12  7.81077965e-11  8.32281398e-11
 -1.29205677e-11 -4.11375489e-12 -1.47884629e-11 -2.61118962e-12
 -1.55486695e-12 -4.39143204e-13 -1.71104440e-12 -3.02938777e-13
  3.91720361e-11  1.30262806e-11  4.55266135e-11  8.02617206e-12
  2.78049857e-12  1.00662139e-12  3.33379301e-12  5.86285669e-13
  4.45564007e-12  7.08800508e-12  1.55229775e-12  3.51505058e-12
  2.33170936e-12  3.66565690e-12  7.60696003e-13  1.72015555e-12
  3.34368963e-12  5.35167668e-12  8.78200413e-13  2.12854137e-12
  3.37706568e-12  5.27356310e-12  8.32870012e-13  1.99580570e-12
  1.15167707e-12  2.11049321e-12  2.00923453e-13  4.67890668e-15
 -1.17023270e-13  1.37579494e-14 -5.21916804e-13 -3.35006811e-13
  3.61956764e+00]
supnorm grad right now is: 3.61956763568986
Weights right now are: 
[-4.91406856e+00 -7.21554711e-01 -3.74699249e+00 -4.57649541e+00
  5.16863730e+00  6.12863023e-01  4.14592979e+00  3.86046706e+00
 -2.27506797e+00 -9.11205996e-01 -2.25648232e+00 -2.00334098e+00
  1.55923338e+00  4.65113228e-01 -1.88949043e-02  8.21197778e-01
 -1.44781789e+00 -5.15103058e-01 -2.65531588e+00 -2.21043408e+00
 -2.15653371e+00 -9.52128818e-01 -2.40534173e+00 -1.82252681e+00
 -9.72360017e-01 -8.32870312e-01 -1.72212512e+00 -9.12623577e-01
  4.64617622e-01  1.45507708e+00  1.54230380e+00  5.08463928e-01
 -1.09372522e+00 -6.35743184e-01 -1.39081757e+00 -1.20607060e+00
 -2.52066734e+00 -1.43644680e+00 -1.29929239e+00 -1.07250565e+00
 -5.99529526e-01 -1.09695863e+00  2.42202085e-01  3.31450832e-01
  4.35103143e-01  1.12012145e+00 -1.78834593e-01  3.87869698e-01
 -1.46285782e+00 -5.77366469e-01 -4.39383266e-01 -1.59492284e+00
  6.15262667e-01  1.16148866e+00  5.26464490e-01  1.68107454e+00
  1.28401343e+00 -4.78681511e-01 -1.29247269e-01 -2.19426290e+00
  2.09374391e+00  1.58998083e+00 -7.24364553e-02  1.08642412e+00
  2.52595454e+01]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.411942554256
gradient value of function right now is: [ 4.38264761e-09  4.11544383e-10  4.38016109e-09  4.38125870e-09
 -4.38304239e-09 -4.11582173e-10 -4.38055563e-09 -4.38165335e-09
  8.32097832e-11  1.01620880e-11  8.18510290e-11  8.72197453e-11
  4.60106123e-10  5.62308474e-11  4.52639028e-10  4.82303691e-10
  8.32263766e-11  1.01644301e-11  8.18675745e-11  8.72373169e-11
  8.04323533e-11  9.82295200e-12  7.91190630e-11  8.43085109e-11
 -1.29843996e-11 -4.22700081e-12 -1.49857835e-11 -2.63730454e-12
 -1.55820844e-12 -4.45276783e-13 -1.72141735e-12 -3.04376636e-13
  3.94786157e-11  1.34756441e-11  4.63503241e-11  8.13764916e-12
  2.82615530e-12  1.05700602e-12  3.43449641e-12  6.00513025e-13
  4.51654695e-12  7.08557937e-12  1.78979294e-12  3.78785562e-12
  2.36020638e-12  3.66120081e-12  8.81283717e-13  1.85834349e-12
  3.34889386e-12  5.32528531e-12  9.79584287e-13  2.24808779e-12
  3.37882466e-12  5.24213723e-12  9.37071802e-13  2.11711005e-12
  1.17099246e-12  2.02944430e-12  2.06291659e-13 -2.99578168e-15
 -1.23235255e-13  2.79251952e-14 -5.39092383e-13 -2.92452369e-13
 -3.20671504e+00]
supnorm grad right now is: 3.206715040531143
Weights right now are: 
[-4.91965784e+00 -7.22079010e-01 -3.75257860e+00 -4.58208291e+00
  5.17422659e+00  6.13387323e-01  4.15151591e+00  3.86605457e+00
 -2.27517395e+00 -9.11218952e-01 -2.25658658e+00 -2.00345207e+00
  1.55864735e+00  4.65041540e-01 -1.94714703e-02  8.20583439e-01
 -1.44792387e+00 -5.15116015e-01 -2.65542014e+00 -2.21054517e+00
 -2.15663614e+00 -9.52141340e-01 -2.40544249e+00 -1.82263418e+00
 -9.72343423e-01 -8.32864964e-01 -1.72210604e+00 -9.12620214e-01
  4.64619616e-01  1.45507764e+00  1.54230600e+00  5.08464317e-01
 -1.09377560e+00 -6.35760185e-01 -1.39087647e+00 -1.20608096e+00
 -2.52067094e+00 -1.43644812e+00 -1.29929673e+00 -1.07250641e+00
 -5.99535279e-01 -1.09696770e+00  2.42199931e-01  3.31446140e-01
  4.35100134e-01  1.12011676e+00 -1.78835651e-01  3.87867399e-01
 -1.46286211e+00 -5.77373301e-01 -4.39384462e-01 -1.59492565e+00
  6.15258336e-01  1.16148193e+00  5.26463349e-01  1.68107190e+00
  1.28401194e+00 -4.78684158e-01 -1.29247530e-01 -2.19426290e+00
  2.09374407e+00  1.58998080e+00 -7.24357749e-02  1.08642452e+00
  2.47389555e+01]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.793981748037
gradient value of function right now is: [ 4.17487840e-09  3.92524389e-10  4.17251220e-09  4.17355663e-09
 -4.17526413e-09 -3.92560752e-10 -4.17289772e-09 -4.17394224e-09
  7.92692336e-11  9.68963258e-12  7.79817710e-11  8.30947791e-11
  4.39148042e-10  5.37154561e-11  4.32058123e-10  4.60363237e-10
  7.93094997e-11  9.69483956e-12  7.80215869e-11  8.31371489e-11
  7.66404776e-11  9.36835530e-12  7.53958124e-11  8.03391972e-11
 -1.24483460e-11 -4.01996126e-12 -1.43234396e-11 -2.52388046e-12
 -1.51293847e-12 -4.31283220e-13 -1.66998793e-12 -2.95413138e-13
  3.77096910e-11  1.27496159e-11  4.41085396e-11  7.75618044e-12
  2.68559672e-12  9.92699008e-13  3.24768184e-12  5.69089926e-13
  4.30120808e-12  6.78255562e-12  1.62831074e-12  3.52860666e-12
  2.25055890e-12  3.50844921e-12  8.00777223e-13  1.73048054e-12
  3.20377339e-12  5.10684947e-12  9.01713096e-13  2.10972519e-12
  3.23395121e-12  5.02951888e-12  8.60163311e-13  1.98399627e-12
  1.11396643e-12  1.97097357e-12  1.95287247e-13 -2.97869026e-16
 -1.15799676e-13  2.18081565e-14 -5.10239877e-13 -2.95078093e-13
 -7.60724873e-01]
supnorm grad right now is: 0.7607248733287464
Weights right now are: 
[-4.92507162e+00 -7.22587633e-01 -3.75798931e+00 -4.58749498e+00
  5.17964036e+00  6.13895945e-01  4.15692662e+00  3.87146664e+00
 -2.27527669e+00 -9.11231512e-01 -2.25668765e+00 -2.00355977e+00
  1.55807852e+00  4.64971955e-01 -2.00311230e-02  8.19987120e-01
 -1.44802665e+00 -5.15128581e-01 -2.65552125e+00 -2.21065292e+00
 -2.15673547e+00 -9.52153483e-01 -2.40554021e+00 -1.82273831e+00
 -9.72327305e-01 -8.32859762e-01 -1.72208750e+00 -9.12616947e-01
  4.64621567e-01  1.45507820e+00  1.54230815e+00  5.08464698e-01
 -1.09382447e+00 -6.35776699e-01 -1.39093362e+00 -1.20609101e+00
 -2.52067442e+00 -1.43644941e+00 -1.29930094e+00 -1.07250715e+00
 -5.99540847e-01 -1.09697649e+00  2.42197831e-01  3.31441569e-01
  4.35097221e-01  1.12011222e+00 -1.78836685e-01  3.87865157e-01
 -1.46286626e+00 -5.77379922e-01 -4.39385628e-01 -1.59492839e+00
  6.15254146e-01  1.16147541e+00  5.26462239e-01  1.68106932e+00
  1.28401050e+00 -4.78686716e-01 -1.29247784e-01 -2.19426290e+00
  2.09374422e+00  1.58998077e+00 -7.24351126e-02  1.08642491e+00
  2.49285837e+01]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.81467592141
gradient value of function right now is: [ 4.02868034e-09  3.79296721e-10  4.02639813e-09  4.02740539e-09
 -4.02916228e-09 -3.79342253e-10 -4.02687980e-09 -4.02788718e-09
  7.65370973e-11  9.35774537e-12  7.52962509e-11  8.02322344e-11
  4.24613281e-10  5.19485031e-11  4.17770130e-10  4.45133936e-10
  7.65978289e-11  9.36544214e-12  7.53561925e-11  8.02960507e-11
  7.40144267e-11  9.04936412e-12  7.28145768e-11  7.75878080e-11
 -1.20600284e-11 -3.88678077e-12 -1.38661489e-11 -2.44407600e-12
 -1.47921889e-12 -4.21778704e-13 -1.63286407e-12 -2.88876471e-13
  3.64495024e-11  1.22940390e-11  4.25946450e-11  7.49291268e-12
  2.58965647e-12  9.54474529e-13  3.12789278e-12  5.48393525e-13
  4.15237494e-12  6.55604983e-12  1.55389089e-12  3.38750502e-12
  2.17430353e-12  3.39363176e-12  7.64157776e-13  1.66163162e-12
  3.09675987e-12  4.93916390e-12  8.63088451e-13  2.02920367e-12
  3.12648347e-12  4.86523349e-12  8.22782846e-13  1.90772220e-12
  1.07507215e-12  1.91197518e-12  1.88061253e-13  2.73740256e-16
 -1.11391937e-13  1.99063878e-14 -4.91874972e-13 -2.88924367e-13
 -1.28776757e-01]
supnorm grad right now is: 0.12877675706505684
Weights right now are: 
[-4.93030089e+00 -7.23079618e-01 -3.76321562e+00 -4.59272259e+00
  5.18486965e+00  6.14387932e-01  4.16215294e+00  3.87669426e+00
 -2.27537600e+00 -9.11243653e-01 -2.25678535e+00 -2.00366387e+00
  1.55752795e+00  4.64904604e-01 -2.05728100e-02  8.19409950e-01
 -1.44812602e+00 -5.15140729e-01 -2.65561901e+00 -2.21075709e+00
 -2.15683149e+00 -9.52165222e-01 -2.40563468e+00 -1.82283897e+00
 -9.72311682e-01 -8.32854723e-01 -1.72206953e+00 -9.12613781e-01
  4.64623475e-01  1.45507874e+00  1.54231026e+00  5.08465070e-01
 -1.09387174e+00 -6.35792658e-01 -1.39098888e+00 -1.20610073e+00
 -2.52067778e+00 -1.43645065e+00 -1.29930500e+00 -1.07250786e+00
 -5.99546235e-01 -1.09698500e+00  2.42195805e-01  3.31437162e-01
  4.35094401e-01  1.12010782e+00 -1.78837681e-01  3.87862995e-01
 -1.46287027e+00 -5.77386325e-01 -4.39386753e-01 -1.59493103e+00
  6.15250092e-01  1.16146910e+00  5.26461167e-01  1.68106684e+00
  1.28400911e+00 -4.78689190e-01 -1.29248028e-01 -2.19426290e+00
  2.09374436e+00  1.58998074e+00 -7.24344743e-02  1.08642528e+00
  2.50149829e+01]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.6364411875165
gradient value of function right now is: [ 3.95874182e-09  3.73294534e-10  3.95649865e-09  3.95748855e-09
 -3.95872806e-09 -3.73293119e-10 -3.95648490e-09 -3.95747480e-09
  7.53007494e-11  9.19967245e-12  7.40759579e-11  7.89322907e-11
  4.18078224e-10  5.11127280e-11  4.11319348e-10  4.38262622e-10
  7.53798136e-11  9.20961117e-12  7.41539348e-11  7.90153256e-11
  7.28336905e-11  8.89831978e-12  7.16491243e-11  7.63462905e-11
 -1.18563147e-11 -3.84657217e-12 -1.36660372e-11 -2.40637811e-12
 -1.46080542e-12 -4.18387389e-13 -1.61492990e-12 -2.85574737e-13
  3.58197938e-11  1.21754358e-11  4.19852759e-11  7.37646132e-12
  2.54880609e-12  9.48520197e-13  3.09093135e-12  5.40970157e-13
  4.08617342e-12  6.42423756e-12  1.58738270e-12  3.39373110e-12
  2.13949770e-12  3.32574761e-12  7.81864861e-13  1.66633515e-12
  3.03660963e-12  4.83344939e-12  8.73402013e-13  2.02106345e-12
  3.06502338e-12  4.75997602e-12  8.34741423e-13  1.90265793e-12
  1.05852318e-12  1.85151924e-12  1.85569165e-13 -1.86003349e-15
 -1.10841399e-13  2.32973036e-14 -4.86723162e-13 -2.71703197e-13
 -2.15988182e+00]
supnorm grad right now is: 2.1598818177686416
Weights right now are: 
[-4.93537889e+00 -7.23558026e-01 -3.76829074e+00 -4.59779898e+00
  5.18994764e+00  6.14866339e-01  4.16722806e+00  3.88177065e+00
 -2.27547250e+00 -9.11255451e-01 -2.25688028e+00 -2.00376503e+00
  1.55699226e+00  4.64839063e-01 -2.10998716e-02  8.18848370e-01
 -1.44822261e+00 -5.15152539e-01 -2.65571403e+00 -2.21085834e+00
 -2.15692482e+00 -9.52176633e-01 -2.40572649e+00 -1.82293680e+00
 -9.72296456e-01 -8.32849819e-01 -1.72205203e+00 -9.12610695e-01
  4.64625351e-01  1.45507928e+00  1.54231233e+00  5.08465437e-01
 -1.09391771e+00 -6.35808157e-01 -1.39104259e+00 -1.20611017e+00
 -2.52068104e+00 -1.43645185e+00 -1.29930894e+00 -1.07250855e+00
 -5.99551468e-01 -1.09699326e+00  2.42193847e-01  3.31432897e-01
  4.35091659e-01  1.12010354e+00 -1.78838645e-01  3.87860902e-01
 -1.46287418e+00 -5.77392554e-01 -4.39387840e-01 -1.59493358e+00
  6.15246148e-01  1.16146296e+00  5.26460132e-01  1.68106444e+00
  1.28400775e+00 -4.78691605e-01 -1.29248264e-01 -2.19426290e+00
  2.09374450e+00  1.58998072e+00 -7.24338549e-02  1.08642565e+00
  2.48189562e+01]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.527712231235
gradient value of function right now is: [ 3.72061648e-09  3.51159801e-10  3.71851182e-09  3.71944057e-09
 -3.72092789e-09 -3.51189820e-10 -3.71882304e-09 -3.71975188e-09
  7.07236306e-11  8.65614339e-12  6.95847791e-11  7.41439011e-11
  3.93592047e-10  4.82014227e-11  3.87290456e-10  4.12644083e-10
  7.08190709e-11  8.66805891e-12  6.96788523e-11  7.42440879e-11
  6.84205115e-11  8.37429667e-12  6.73188360e-11  7.17294308e-11
 -1.12465595e-11 -3.59031508e-12 -1.28849561e-11 -2.27436261e-12
 -1.40746699e-12 -4.00339866e-13 -1.55232150e-12 -2.74771012e-13
  3.37999024e-11  1.12724389e-11  3.93262236e-11  6.93032106e-12
  2.38425414e-12  8.66634730e-13  2.86330451e-12  5.03258425e-13
  3.83473592e-12  6.09132085e-12  1.35599301e-12  3.04684154e-12
  2.01192599e-12  3.15840159e-12  6.66060293e-13  1.49436063e-12
  2.87562524e-12  4.59941286e-12  7.64512702e-13  1.84167499e-12
  2.90503879e-12  4.53339324e-12  7.26124891e-13  1.72841393e-12
  9.91487231e-13  1.80536734e-12  1.72357420e-13  2.96763831e-15
 -1.01183583e-13  1.32069568e-14 -4.51034780e-13 -2.84447763e-13
  2.86482868e+00]
supnorm grad right now is: 2.8648286791007327
Weights right now are: 
[-4.94031486e+00 -7.24023684e-01 -3.77322392e+00 -4.60273340e+00
  5.19488362e+00  6.15331998e-01  4.17216124e+00  3.88670507e+00
 -2.27556636e+00 -9.11266926e-01 -2.25697262e+00 -2.00386342e+00
  1.55647055e+00  4.64775244e-01 -2.16131860e-02  8.18301446e-01
 -1.44831658e+00 -5.15164027e-01 -2.65580648e+00 -2.21095685e+00
 -2.15701562e+00 -9.52187733e-01 -2.40581582e+00 -1.82303198e+00
 -9.72281612e-01 -8.32845036e-01 -1.72203496e+00 -9.12607688e-01
  4.64627194e-01  1.45507980e+00  1.54231436e+00  5.08465797e-01
 -1.09396245e+00 -6.35823242e-01 -1.39109487e+00 -1.20611937e+00
 -2.52068421e+00 -1.43645302e+00 -1.29931278e+00 -1.07250922e+00
 -5.99556563e-01 -1.09700129e+00  2.42191935e-01  3.31428746e-01
  4.35088988e-01  1.12009938e+00 -1.78839586e-01  3.87858864e-01
 -1.46287798e+00 -5.77398607e-01 -4.39388899e-01 -1.59493606e+00
  6.15242308e-01  1.16145700e+00  5.26459120e-01  1.68106211e+00
  1.28400644e+00 -4.78693948e-01 -1.29248493e-01 -2.19426290e+00
  2.09374464e+00  1.58998069e+00 -7.24332538e-02  1.08642600e+00
  2.51699547e+01]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.717173386738
gradient value of function right now is: [ 3.71961893e-09  3.51661687e-10  3.71751283e-09  3.71844207e-09
 -3.71964282e-09 -3.51663982e-10 -3.71753671e-09 -3.71846595e-09
  7.08382382e-11  8.65617408e-12  6.96885452e-11  7.42559259e-11
  3.94289419e-10  4.82133241e-11  3.87928869e-10  4.13332584e-10
  7.09496682e-11  8.67005019e-12  6.97983518e-11  7.43728785e-11
  6.85439122e-11  8.37586532e-12  6.74315476e-11  7.18509421e-11
 -1.12138196e-11 -3.63190115e-12 -1.29170305e-11 -2.27513620e-12
 -1.40354041e-12 -4.02539567e-13 -1.55227420e-12 -2.74510399e-13
  3.37481461e-11  1.14472039e-11  3.95243665e-11  6.94657437e-12
  2.39282778e-12  8.88310601e-13  2.89879677e-12  5.07589685e-13
  3.84291861e-12  6.04904692e-12  1.47801830e-12  3.17667542e-12
  2.01454693e-12  3.13510270e-12  7.28264742e-13  1.56067783e-12
  2.85935745e-12  4.55396561e-12  8.15452952e-13  1.89518699e-12
  2.88674406e-12  4.48572512e-12  7.78973003e-13  1.78382614e-12
  9.95370975e-13  1.74865335e-12  1.74009830e-13 -1.31348819e-15
 -1.03945788e-13  2.09944522e-14 -4.57465300e-13 -2.58990574e-13
 -1.60803634e+00]
supnorm grad right now is: 1.6080363373504032
Weights right now are: 
[-4.94509942e+00 -7.24475657e-01 -3.77800577e+00 -4.60751645e+00
  5.19966819e+00  6.15783971e-01  4.17694310e+00  3.89148812e+00
 -2.27565740e+00 -9.11278059e-01 -2.25706219e+00 -2.00395886e+00
  1.55596389e+00  4.64713250e-01 -2.21116896e-02  8.17770300e-01
 -1.44840776e+00 -5.15175177e-01 -2.65589618e+00 -2.21105242e+00
 -2.15710370e+00 -9.52198504e-01 -2.40590248e+00 -1.82312432e+00
 -9.72267176e-01 -8.32840388e-01 -1.72201837e+00 -9.12604762e-01
  4.64628999e-01  1.45508032e+00  1.54231636e+00  5.08466150e-01
 -1.09400588e+00 -6.35837870e-01 -1.39114559e+00 -1.20612829e+00
 -2.52068729e+00 -1.43645415e+00 -1.29931648e+00 -1.07250987e+00
 -5.99561500e-01 -1.09700909e+00  2.42190105e-01  3.31424729e-01
  4.35086400e-01  1.12009533e+00 -1.78840486e-01  3.87856893e-01
 -1.46288167e+00 -5.77404489e-01 -4.39389920e-01 -1.59493847e+00
  6.15238587e-01  1.16145120e+00  5.26458148e-01  1.68105984e+00
  1.28400516e+00 -4.78696226e-01 -1.29248717e-01 -2.19426290e+00
  2.09374477e+00  1.58998067e+00 -7.24326673e-02  1.08642634e+00
  2.48793935e+01]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.587453384757
gradient value of function right now is: [ 3.63629921e-09  3.44248256e-10  3.63424038e-09  3.63514867e-09
 -3.63656526e-09 -3.44273918e-10 -3.63450627e-09 -3.63541463e-09
  6.93160563e-11  8.46743405e-12  6.81898208e-11  7.26588399e-11
  3.86178751e-10  4.72071607e-11  3.79942545e-10  4.04822534e-10
  6.94418821e-11  8.48306353e-12  6.83137858e-11  7.27908799e-11
  6.70829660e-11  8.19469611e-12  6.59931047e-11  7.03180931e-11
 -1.09819366e-11 -3.56698119e-12 -1.26635512e-11 -2.22954452e-12
 -1.38224547e-12 -3.97413476e-13 -1.52997263e-12 -2.70511632e-13
  3.30156085e-11  1.12358825e-11  3.87165097e-11  6.80097573e-12
  2.34078206e-12  8.72625675e-13  2.84068698e-12  4.97041505e-13
  3.76038257e-12  5.90859388e-12  1.46937421e-12  3.13248273e-12
  1.97175859e-12  3.06325912e-12  7.24636363e-13  1.53991891e-12
  2.79392182e-12  4.44597108e-12  8.07489213e-13  1.86424897e-12
  2.82051075e-12  4.37907983e-12  7.72188800e-13  1.75574575e-12
  9.74276708e-13  1.69924670e-12  1.70434653e-13 -2.13516333e-15
 -1.02185564e-13  2.19726465e-14 -4.48804755e-13 -2.48557505e-13
 -2.44362314e+00]
supnorm grad right now is: 2.443623142587969
Weights right now are: 
[-4.94974660e+00 -7.24915241e-01 -3.78265032e+00 -4.61216215e+00
  5.20431536e+00  6.16223555e-01  4.18158764e+00  3.89613383e+00
 -2.27574590e+00 -9.11288880e-01 -2.25714926e+00 -2.00405163e+00
  1.55547088e+00  4.64652930e-01 -2.25967701e-02  8.17253456e-01
 -1.44849641e+00 -5.15186017e-01 -2.65598340e+00 -2.21114536e+00
 -2.15718934e+00 -9.52208976e-01 -2.40598673e+00 -1.82321409e+00
 -9.72253123e-01 -8.32835856e-01 -1.72200221e+00 -9.12601914e-01
  4.64630768e-01  1.45508083e+00  1.54231831e+00  5.08466495e-01
 -1.09404810e+00 -6.35852118e-01 -1.39119494e+00 -1.20613698e+00
 -2.52069027e+00 -1.43645525e+00 -1.29932009e+00 -1.07251050e+00
 -5.99566295e-01 -1.09701668e+00  2.42188311e-01  3.31420807e-01
  4.35083885e-01  1.12009140e+00 -1.78841370e-01  3.87854966e-01
 -1.46288524e+00 -5.77410202e-01 -4.39390918e-01 -1.59494083e+00
  6.15234975e-01  1.16144558e+00  5.26457197e-01  1.68105763e+00
  1.28400391e+00 -4.78698433e-01 -1.29248935e-01 -2.19426290e+00
  2.09374490e+00  1.58998065e+00 -7.24320960e-02  1.08642668e+00
  2.47768701e+01]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.680408176774
gradient value of function right now is: [ 3.52531008e-09  3.34138307e-10  3.52331498e-09  3.52419507e-09
 -3.52580678e-09 -3.34185806e-10 -3.52381138e-09 -3.52469161e-09
  6.72338634e-11  8.21481592e-12  6.61432736e-11  7.04774339e-11
  3.75047535e-10  4.58556001e-11  3.69000921e-10  3.93160302e-10
  6.73724061e-11  8.23199156e-12  6.62797455e-11  7.06228004e-11
  6.50793641e-11  7.95162062e-12  6.40238103e-11  6.82190282e-11
 -1.06843534e-11 -3.46378503e-12 -1.23116019e-11 -2.16821988e-12
 -1.35522179e-12 -3.89667535e-13 -1.50006204e-12 -2.65247517e-13
  3.20555179e-11  1.08844754e-11  3.75573079e-11  6.59980236e-12
  2.26777074e-12  8.43093538e-13  2.74892035e-12  4.81234427e-13
  3.64696885e-12  5.73727422e-12  1.40980001e-12  3.02217246e-12
  1.91355515e-12  2.97625725e-12  6.95213396e-13  1.48592821e-12
  2.71275331e-12  4.31927215e-12  7.76896282e-13  1.80181937e-12
  2.73901736e-12  4.25496959e-12  7.42513159e-13  1.69649795e-12
  9.44610172e-13  1.65545495e-12  1.64947953e-13 -1.59874481e-15
 -9.87793222e-14  2.03610359e-14 -4.34722322e-13 -2.44416269e-13
 -1.88072911e+00]
supnorm grad right now is: 1.8807291061459313
Weights right now are: 
[-4.95427465e+00 -7.25344084e-01 -3.78717581e+00 -4.61668877e+00
  5.20884340e+00  6.16652398e-01  4.18611312e+00  3.90066044e+00
 -2.27583218e+00 -9.11299428e-01 -2.25723415e+00 -2.00414208e+00
  1.55498966e+00  4.64594057e-01 -2.30702562e-02  8.16748973e-01
 -1.44858286e+00 -5.15196586e-01 -2.65606845e+00 -2.21123598e+00
 -2.15727285e+00 -9.52219185e-01 -2.40606889e+00 -1.82330164e+00
 -9.72239389e-01 -8.32831430e-01 -1.72198642e+00 -9.12599131e-01
  4.64632509e-01  1.45508132e+00  1.54232024e+00  5.08466836e-01
 -1.09408929e+00 -6.35866007e-01 -1.39124307e+00 -1.20614544e+00
 -2.52069318e+00 -1.43645633e+00 -1.29932361e+00 -1.07251112e+00
 -5.99570975e-01 -1.09702407e+00  2.42186554e-01  3.31416988e-01
  4.35081429e-01  1.12008757e+00 -1.78842235e-01  3.87853090e-01
 -1.46288873e+00 -5.77415771e-01 -4.39391891e-01 -1.59494311e+00
  6.15231450e-01  1.16144009e+00  5.26456269e-01  1.68105548e+00
  1.28400270e+00 -4.78700582e-01 -1.29249146e-01 -2.19426290e+00
  2.09374503e+00  1.58998063e+00 -7.24315420e-02  1.08642701e+00
  2.48298925e+01]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.785429747345
gradient value of function right now is: [ 3.41078597e-09  3.23648488e-10  3.40885673e-09  3.40970771e-09
 -3.41048980e-09 -3.23620119e-10 -3.40856073e-09 -3.40941163e-09
  6.50640014e-11  7.95253463e-12  6.40111351e-11  6.82047263e-11
  3.63427920e-10  4.44498958e-11  3.57582296e-10  3.80989257e-10
  6.52135592e-11  7.97104959e-12  6.41584409e-11  6.83616359e-11
  6.29909751e-11  7.69920073e-12  6.19717378e-11  6.60316639e-11
 -1.03770210e-11 -3.35353030e-12 -1.19431802e-11 -2.10437095e-12
 -1.32706654e-12 -3.81323748e-13 -1.46854013e-12 -2.59723133e-13
  3.10615555e-11  1.05074488e-11  3.63393649e-11  6.38969134e-12
  2.19136555e-12  8.10974654e-13  2.65123736e-12  4.64527482e-13
  3.52841306e-12  5.56215874e-12  1.33958580e-12  2.89873915e-12
  1.85278619e-12  2.88741344e-12  6.60412729e-13  1.42534063e-12
  2.62953113e-12  4.19081696e-12  7.41705349e-13  1.73334974e-12
  2.65555892e-12  4.12934324e-12  7.08092816e-13  1.63117752e-12
  9.13560147e-13  1.61415310e-12  1.59081807e-13 -7.35832706e-16
 -9.50768206e-14  1.81798358e-14 -4.19642443e-13 -2.41906213e-13
 -9.01745870e-01]
supnorm grad right now is: 0.9017458699347569
Weights right now are: 
[-4.95869216e+00 -7.25762978e-01 -3.79159082e+00 -4.62110488e+00
  5.21326091e+00  6.17071291e-01  4.19052813e+00  3.90507655e+00
 -2.27591641e+00 -9.11309727e-01 -2.25731701e+00 -2.00423038e+00
  1.55451937e+00  4.64536519e-01 -2.35329889e-02  8.16255949e-01
 -1.44866727e+00 -5.15206907e-01 -2.65615150e+00 -2.21132447e+00
 -2.15735439e+00 -9.52229155e-01 -2.40614911e+00 -1.82338711e+00
 -9.72225954e-01 -8.32827099e-01 -1.72197097e+00 -9.12596408e-01
  4.64634223e-01  1.45508182e+00  1.54232213e+00  5.08467171e-01
 -1.09412951e+00 -6.35879578e-01 -1.39129008e+00 -1.20615371e+00
 -2.52069602e+00 -1.43645737e+00 -1.29932703e+00 -1.07251172e+00
 -5.99575541e-01 -1.09703128e+00  2.42184843e-01  3.31413259e-01
  4.35079031e-01  1.12008382e+00 -1.78843079e-01  3.87851256e-01
 -1.46289214e+00 -5.77421209e-01 -4.39392842e-01 -1.59494535e+00
  6.15228009e-01  1.16143473e+00  5.26455362e-01  1.68105338e+00
  1.28400152e+00 -4.78702686e-01 -1.29249352e-01 -2.19426290e+00
  2.09374515e+00  1.58998061e+00 -7.24309998e-02  1.08642733e+00
  2.48966737e+01]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.58028707242
gradient value of function right now is: [ 3.35816401e-09  3.19074571e-10  3.35626418e-09  3.35710209e-09
 -3.35817410e-09 -3.19075446e-10 -3.35627426e-09 -3.35711218e-09
  6.41305769e-11  7.83377738e-12  6.30901531e-11  6.72236073e-11
  3.58457915e-10  4.38173814e-11  3.52678116e-10  3.75765217e-10
  6.42918355e-11  7.85371548e-12  6.32489659e-11  6.73927788e-11
  6.20971567e-11  7.58543433e-12  6.10898057e-11  6.50921474e-11
 -1.02233289e-11 -3.32128062e-12 -1.17896453e-11 -2.07565982e-12
 -1.31236083e-12 -3.78468611e-13 -1.45403309e-12 -2.57062440e-13
  3.05890253e-11  1.04112158e-11  3.58723786e-11  6.30128596e-12
  2.16047405e-12  8.05692692e-13  2.62223462e-12  4.58803374e-13
  3.47826566e-12  5.46476920e-12  1.36009970e-12  2.89836768e-12
  1.82642580e-12  2.83719097e-12  6.71393392e-13  1.42631227e-12
  2.58495132e-12  4.11319376e-12  7.47458259e-13  1.72510418e-12
  2.61008082e-12  4.05213855e-12  7.14991708e-13  1.62513462e-12
  9.01009550e-13  1.57096250e-12  1.57179347e-13 -2.14103203e-15
 -9.45288524e-14  2.03931147e-14 -4.15496641e-13 -2.29972580e-13
 -2.48247006e+00]
supnorm grad right now is: 2.4824700553570813
Weights right now are: 
[-4.96296239e+00 -7.26168400e-01 -3.79585863e+00 -4.62537376e+00
  5.21753114e+00  6.17476713e-01  4.19479595e+00  3.90934543e+00
 -2.27599789e+00 -9.11319688e-01 -2.25739717e+00 -2.00431579e+00
  1.55406399e+00  4.64480811e-01 -2.39810542e-02  8.15778556e-01
 -1.44874895e+00 -5.15216893e-01 -2.65623186e+00 -2.21141009e+00
 -2.15743328e+00 -9.52238799e-01 -2.40622672e+00 -1.82346981e+00
 -9.72212938e-01 -8.32822898e-01 -1.72195600e+00 -9.12593769e-01
  4.64635893e-01  1.45508230e+00  1.54232398e+00  5.08467498e-01
 -1.09416844e+00 -6.35892722e-01 -1.39133559e+00 -1.20616171e+00
 -2.52069876e+00 -1.43645838e+00 -1.29933035e+00 -1.07251230e+00
 -5.99579957e-01 -1.09703825e+00  2.42183181e-01  3.31409642e-01
  4.35076712e-01  1.12008020e+00 -1.78843899e-01  3.87849478e-01
 -1.46289544e+00 -5.77426465e-01 -4.39393764e-01 -1.59494751e+00
  6.15224682e-01  1.16142955e+00  5.26454483e-01  1.68105134e+00
  1.28400037e+00 -4.78704716e-01 -1.29249551e-01 -2.19426290e+00
  2.09374527e+00  1.58998058e+00 -7.24304745e-02  1.08642763e+00
  2.48105638e+01]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.784939248843
gradient value of function right now is: [ 3.20364764e-09  3.04654107e-10  3.20183742e-09  3.20263579e-09
 -3.20340934e-09 -3.04631360e-10 -3.20159926e-09 -3.20239756e-09
  6.11537921e-11  7.47936723e-12  6.01685641e-11  6.41088744e-11
  3.42448080e-10  4.19090645e-11  3.36963565e-10  3.59012148e-10
  6.13224565e-11  7.50020798e-12  6.03346641e-11  6.42858082e-11
  5.92252849e-11  7.24354154e-12  5.82712038e-11  6.20872056e-11
 -9.81926340e-12 -3.15503523e-12 -1.12768008e-11 -1.98868544e-12
 -1.27505620e-12 -3.65923654e-13 -1.41033967e-12 -2.49514862e-13
  2.92653025e-11  9.83221754e-12  3.41469203e-11  6.01071309e-12
  2.05404639e-12  7.53815125e-13  2.47647834e-12  4.34562922e-13
  3.31527567e-12  5.24488926e-12  1.21731974e-12  2.68031311e-12
  1.74343972e-12  2.72630422e-12  5.99837495e-13  1.31812337e-12
  2.47904789e-12  3.95752460e-12  6.79864849e-13  1.61135658e-12
  2.50466104e-12  3.90115635e-12  6.47743348e-13  1.51494453e-12
  8.57474872e-13  1.53754209e-12  1.48617455e-13  6.65327202e-16
 -8.84224736e-14  1.44050285e-14 -3.92521815e-13 -2.36532620e-13
  9.01452012e-01]
supnorm grad right now is: 0.9014520124811599
Weights right now are: 
[-4.96714941e+00 -7.26566364e-01 -3.80004329e+00 -4.62955946e+00
  5.22171817e+00  6.17874677e-01  4.19898061e+00  3.91353114e+00
 -2.27607781e+00 -9.11329460e-01 -2.25747581e+00 -2.00439957e+00
  1.55361676e+00  4.64426094e-01 -2.44211086e-02  8.15309704e-01
 -1.44882908e+00 -5.15226691e-01 -2.65631070e+00 -2.21149409e+00
 -2.15751067e+00 -9.52248262e-01 -2.40630287e+00 -1.82355094e+00
 -9.72200134e-01 -8.32818773e-01 -1.72194128e+00 -9.12591174e-01
  4.64637549e-01  1.45508277e+00  1.54232581e+00  5.08467822e-01
 -1.09420665e+00 -6.35905600e-01 -1.39138022e+00 -1.20616957e+00
 -2.52070145e+00 -1.43645937e+00 -1.29933359e+00 -1.07251287e+00
 -5.99584288e-01 -1.09704510e+00  2.42181574e-01  3.31406112e-01
  4.35074435e-01  1.12007664e+00 -1.78844690e-01  3.87847742e-01
 -1.46289867e+00 -5.77431624e-01 -4.39394661e-01 -1.59494963e+00
  6.15221414e-01  1.16142447e+00  5.26453628e-01  1.68104935e+00
  1.28399925e+00 -4.78706707e-01 -1.29249747e-01 -2.19426290e+00
  2.09374538e+00  1.58998056e+00 -7.24299581e-02  1.08642794e+00
  2.50544586e+01]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.727755066751
gradient value of function right now is: [ 3.11298087e-09  2.96348201e-10  3.11122265e-09  3.11199803e-09
 -3.11278092e-09 -2.96328928e-10 -3.11102281e-09 -3.11179814e-09
  5.94461601e-11  7.27220157e-12  5.84900853e-11  6.23198503e-11
  3.33272954e-10  4.07951143e-11  3.27944318e-10  3.49399212e-10
  5.96231279e-11  7.29405379e-12  5.86643538e-11  6.25054868e-11
  5.75807572e-11  7.04403917e-12  5.66547582e-11  6.03642986e-11
 -9.57283181e-12 -3.06952816e-12 -1.09852825e-11 -1.93790655e-12
 -1.25167269e-12 -3.59116771e-13 -1.38432356e-12 -2.44943844e-13
  2.84760040e-11  9.54351841e-12  3.31942026e-11  5.84538216e-12
  1.99434368e-12  7.29709283e-13  2.40150064e-12  4.21643136e-13
  3.22206175e-12  5.10429194e-12  1.16848635e-12  2.59009653e-12
  1.69552642e-12  2.65476911e-12  5.75716404e-13  1.27392674e-12
  2.41239227e-12  3.85354323e-12  6.54757346e-13  1.56026720e-12
  2.43772999e-12  3.79929030e-12  6.23339457e-13  1.46640013e-12
  8.33189311e-13  1.50150851e-12  1.44161834e-13  1.12405664e-15
 -8.56391769e-14  1.30568350e-14 -3.81003797e-13 -2.33138686e-13
  1.55017799e+00]
supnorm grad right now is: 1.5501779880336337
Weights right now are: 
[-4.97121736e+00 -7.26953443e-01 -3.80410894e+00 -4.63362613e+00
  5.22578612e+00  6.18261757e-01  4.20304626e+00  3.91759781e+00
 -2.27615550e+00 -9.11338958e-01 -2.25755224e+00 -2.00448101e+00
  1.55318155e+00  4.64372851e-01 -2.48493358e-02  8.14853458e-01
 -1.44890699e+00 -5.15236217e-01 -2.65638735e+00 -2.21157577e+00
 -2.15758592e+00 -9.52257462e-01 -2.40637690e+00 -1.82362982e+00
 -9.72187661e-01 -8.32814757e-01 -1.72192694e+00 -9.12588647e-01
  4.64639171e-01  1.45508324e+00  1.54232761e+00  5.08468140e-01
 -1.09424381e+00 -6.35918119e-01 -1.39142363e+00 -1.20617721e+00
 -2.52070406e+00 -1.43646034e+00 -1.29933674e+00 -1.07251342e+00
 -5.99588503e-01 -1.09705175e+00  2.42180006e-01  3.31402687e-01
  4.35072218e-01  1.12007319e+00 -1.78845463e-01  3.87846057e-01
 -1.46290182e+00 -5.77436640e-01 -4.39395533e-01 -1.59495169e+00
  6.15218234e-01  1.16141952e+00  5.26452796e-01  1.68104741e+00
  1.28399816e+00 -4.78708650e-01 -1.29249936e-01 -2.19426290e+00
  2.09374550e+00  1.58998054e+00 -7.24294589e-02  1.08642823e+00
  2.50612329e+01]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.813476185394
gradient value of function right now is: [ 3.06497829e-09  2.92133614e-10  3.06324696e-09  3.06401040e-09
 -3.06478024e-09 -2.92114117e-10 -3.06304903e-09 -3.06381242e-09
  5.85836927e-11  7.16322848e-12  5.76395671e-11  6.14137596e-11
  3.28664435e-10  4.02126605e-11  3.23399271e-10  3.44557519e-10
  5.87698329e-11  7.18619495e-12  5.78228561e-11  6.16090078e-11
  5.67540213e-11  6.93954745e-12  5.58394559e-11  5.94957280e-11
 -9.43283244e-12 -3.03769806e-12 -1.08420970e-11 -1.91140608e-12
 -1.23800919e-12 -3.56294548e-13 -1.37062169e-12 -2.42444568e-13
  2.80445739e-11  9.44623554e-12  3.27549977e-11  5.76336724e-12
  1.96559911e-12  7.23749971e-13  2.37307949e-12  4.16179825e-13
  3.17568100e-12  5.01719072e-12  1.18106890e-12  2.58303862e-12
  1.67116375e-12  2.60985439e-12  5.82565039e-13  1.27135134e-12
  2.37226770e-12  3.78465655e-12  6.57526993e-13  1.54999501e-12
  2.39682426e-12  3.73081478e-12  6.27088513e-13  1.45808693e-12
  8.21555264e-13  1.46492596e-12  1.42292831e-13  4.03171968e-17
 -8.50137160e-14  1.47746050e-14 -3.76879596e-13 -2.23445489e-13
  2.10549340e-01]
supnorm grad right now is: 0.21054933958822775
Weights right now are: 
[-4.97520174 -0.727333   -3.80809107 -4.63760925  5.22977051  0.61864132
  4.2070284   3.92158094 -2.27623165 -0.91134827 -2.25762716 -2.00456083
  1.55275462  0.46432061 -0.02526943  0.81440588 -1.44898337 -0.51524556
 -2.6564625  -2.21165584 -2.15765968 -0.95226648 -2.40644947 -1.82370714
 -0.97217542 -0.83281081 -1.72191287 -0.91258616  0.46464077  1.4550837
  1.54232938  0.50846845 -1.09428025 -0.6359304  -1.3914662  -1.2061847
 -2.52070662 -1.43646128 -1.29933983 -1.07251396 -0.59959263 -1.09705827
  0.24217847  0.33139932  0.43507005  1.1200698  -0.17884622  0.3878444
 -1.4629049  -0.57744156 -0.43939639 -1.59495371  0.61521512  1.16141467
  0.52645198  1.68104552  1.28399709 -0.47871055 -0.12925012 -2.1942629
  2.09374561  1.58998052 -0.07242897  1.08642852 24.9844541 ]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5141.719375805038
gradient value of function right now is: [ 3.10251394e-09  2.96171886e-10  3.10075906e-09  3.10153276e-09
 -3.10203676e-09 -2.96125960e-10 -3.10028215e-09 -3.10105573e-09
  5.94248753e-11  7.25123267e-12  5.84573493e-11  6.22867779e-11
  3.33271565e-10  4.06977825e-11  3.27879883e-10  3.49340910e-10
  5.96233977e-11  7.27569271e-12  5.86528055e-11  6.24949951e-11
  5.75770235e-11  7.02579886e-12  5.66396625e-11  6.03499666e-11
 -9.50393616e-12 -3.11670542e-12 -1.09990250e-11 -1.93370992e-12
 -1.24369732e-12 -3.61638593e-13 -1.38174302e-12 -2.44111582e-13
  2.83262674e-11  9.74683733e-12  3.33614159e-11  5.84971098e-12
  1.99950050e-12  7.56090604e-13  2.44103958e-12  4.26011420e-13
  3.22244384e-12  5.03285292e-12  1.32655454e-12  2.75364834e-12
  1.69374602e-12  2.61605338e-12  6.56833110e-13  1.35812806e-12
  2.38395035e-12  3.78265976e-12  7.19915069e-13  1.62592859e-12
  2.40665092e-12  3.72580705e-12  6.90967839e-13  1.53471384e-12
  8.35631103e-13  1.42230254e-12  1.45818436e-13 -4.35692576e-15
 -8.89205252e-14  2.30989469e-14 -3.88166899e-13 -1.99170918e-13
 -5.23673616e+00]
supnorm grad right now is: 5.236736163613911
Weights right now are: 
[-4.97906261 -0.72770118 -3.81194976 -4.6414689   5.23363138  0.6190095
  4.21088709  3.92544059 -2.27630546 -0.91135729 -2.25769978 -2.00463822
  1.5523403   0.46426992 -0.02567712  0.81397152 -1.44905742 -0.51525461
 -2.65653536 -2.21173347 -2.15773119 -0.95227523 -2.40651983 -1.82378211
 -0.97216352 -0.83280698 -1.72189919 -0.91258375  0.46464234  1.45508415
  1.54233112  0.50846876 -1.0943156  -0.6359423  -1.39150747 -1.20619196
 -2.52070909 -1.43646219 -1.29934282 -1.07251449 -0.59959663 -1.0970646
  0.24217699  0.33139608  0.43506794  1.1200665  -0.17884695  0.3878428
 -1.46290789 -0.57744633 -0.43939721 -1.59495566  0.6152121   1.16140997
  0.52645119  1.68104368  1.28399606 -0.47871239 -0.1292503  -2.1942629
  2.09374572  1.58998051 -0.07242849  1.0864288  24.56156949]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.8135371629
gradient value of function right now is: [ 2.96845637e-09  2.83396086e-10  2.96677996e-09  2.96751909e-09
 -2.96810597e-09 -2.83362217e-10 -2.96642976e-09 -2.96716880e-09
  5.67896581e-11  6.94273610e-12  5.58743051e-11  5.95325529e-11
  3.19027463e-10  3.90275797e-11  3.13916100e-10  3.34451915e-10
  5.69870485e-11  6.96707005e-12  5.60686591e-11  5.97395909e-11
  5.50284764e-11  6.72746357e-12  5.41415827e-11  5.76863348e-11
 -9.16293447e-12 -2.95511986e-12 -1.05376347e-11 -1.85734781e-12
 -1.21180909e-12 -3.49420289e-13 -1.34244965e-12 -2.37434174e-13
  2.71931084e-11  9.17482597e-12  3.17811345e-11  5.59055621e-12
  1.90385367e-12  7.02561503e-13  2.30062120e-12  4.03320604e-13
  3.07807595e-12  4.85884531e-12  1.15435129e-12  2.51372940e-12
  1.62061621e-12  2.52884281e-12  5.69801722e-13  1.23798641e-12
  2.29793609e-12  3.66463711e-12  6.41356146e-13  1.50660236e-12
  2.32175084e-12  3.61256321e-12  6.12043390e-13  1.41778510e-12
  7.96486182e-13  1.41510547e-12  1.37869791e-13 -3.30960535e-16
 -8.26091564e-14  1.49360737e-14 -3.65894178e-13 -2.14649383e-13
 -2.23545021e-01]
supnorm grad right now is: 0.2235450214234389
Weights right now are: 
[-4.98285301 -0.72806302 -3.81573802 -4.6452581   5.23742179  0.61937133
  4.21467536  3.9292298  -2.27637796 -0.91136616 -2.25777112 -2.00471422
  1.55193293  0.46422008 -0.02607797  0.81354445 -1.44913018 -0.51526351
 -2.65660694 -2.21180974 -2.15780144 -0.95228382 -2.40658895 -1.82385576
 -0.97215181 -0.83280321 -1.72188573 -0.91258138  0.46464389  1.4550846
  1.54233283  0.50846906 -1.09435034 -0.63595398 -1.39154803 -1.20619909
 -2.52071152 -1.43646308 -1.29934575 -1.072515   -0.59960057 -1.09707081
  0.24217553  0.33139289  0.43506587  1.12006327 -0.17884767  0.38784124
 -1.46291083 -0.57745101 -0.43939803 -1.59495757  0.61520913  1.16140535
  0.52645042  1.68104188  1.28399505 -0.47871421 -0.12925048 -2.1942629
  2.09374582  1.58998049 -0.07242803  1.08642908 25.32741805]
(65,)
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.81528042042
gradient value of function right now is: [ 2.93073946e-09  2.79935554e-10  2.92908465e-09  2.92981424e-09
 -2.93120454e-09 -2.79980708e-10 -2.92954945e-09 -2.93027916e-09
  5.60873374e-11  6.85744155e-12  5.51838815e-11  5.87967067e-11
  3.15241142e-10  3.85673845e-11  3.10193604e-10  3.30484645e-10
  5.62880865e-11  6.88218484e-12  5.53815392e-11  5.90072652e-11
  5.43510927e-11  6.64519842e-12  5.34756774e-11  5.69766167e-11
 -9.06035096e-12 -2.92005460e-12 -1.04169453e-11 -1.83630649e-12
 -1.20177032e-12 -3.46521527e-13 -1.33131096e-12 -2.35474396e-13
  2.68671648e-11  9.05747580e-12  3.13900308e-11  5.52264279e-12
  1.87947156e-12  6.92870887e-13  2.27019098e-12  3.98075792e-13
  3.03970800e-12  4.80080855e-12  1.13514573e-12  2.47789632e-12
  1.60083579e-12  2.49922950e-12  5.60305788e-13  1.22041171e-12
  2.27026125e-12  3.62150401e-12  6.31416209e-13  1.48620970e-12
  2.29390310e-12  3.57020032e-12  6.02410625e-13  1.39841453e-12
  7.86664997e-13  1.39973342e-12  1.36131704e-13 -1.81236287e-16
 -8.14957855e-14  1.44499260e-14 -3.61291760e-13 -2.13030493e-13
  1.56149972e-03]
supnorm grad right now is: 0.0015614997150898624
Weights right now are: 
[-4.98656354 -0.72841763 -3.81944645 -4.64896746  5.24113231  0.61972595
  4.21838379  3.93293915 -2.27644899 -0.91137484 -2.25784101 -2.00478868
  1.55153354  0.46417123 -0.02647095  0.81312576 -1.44920147 -0.51527222
 -2.65667709 -2.21188447 -2.15787028 -0.95229223 -2.40665668 -1.82392792
 -0.97214033 -0.83279951 -1.72187253 -0.91257906  0.46464542  1.45508504
  1.54233452  0.50846936 -1.09438435 -0.63596547 -1.39158781 -1.20620609
 -2.5207139  -1.43646396 -1.29934863 -1.07251551 -0.59960442 -1.09707688
  0.24217408  0.33138974  0.43506384  1.12006011 -0.17884839  0.38783968
 -1.4629137  -0.57745559 -0.43939883 -1.59495946  0.61520623  1.16140084
  0.52644965  1.68104011  1.28399405 -0.47871598 -0.12925065 -2.1942629
  2.09374592  1.58998047 -0.07242757  1.08642935 24.88088453]
(65,)
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.815246654293
gradient value of function right now is: [ 2.89878336e-09  2.77026107e-10  2.89714676e-09  2.89786829e-09
 -2.89905685e-09 -2.77052772e-10 -2.89742009e-09 -2.89814169e-09
  5.54885732e-11  6.78413397e-12  5.45949077e-11  5.81690136e-11
  3.12019879e-10  3.81727542e-11  3.07024753e-10  3.27107608e-10
  5.56924887e-11  6.80926205e-12  5.47956799e-11  5.83828901e-11
  5.37749254e-11  6.57465645e-12  5.29089308e-11  5.63726118e-11
 -8.97119729e-12 -2.89164776e-12 -1.03148781e-11 -1.81828332e-12
 -1.19306574e-12 -3.44157347e-13 -1.32184811e-12 -2.33797339e-13
  2.65850884e-11  8.96341232e-12  3.10618759e-11  5.46478832e-12
  1.85875614e-12  6.85356463e-13  2.24533562e-12  3.93704017e-13
  3.00717533e-12  4.74900808e-12  1.12373090e-12  2.45200571e-12
  1.58402004e-12  2.47276459e-12  5.54761339e-13  1.20785676e-12
  2.24594247e-12  3.58253539e-12  6.24972114e-13  1.47056565e-12
  2.26939681e-12  3.53189021e-12  5.96311742e-13  1.38378154e-12
  7.78200710e-13  1.38438879e-12  1.34604897e-13 -2.23657042e-16
 -8.06323007e-14  1.43438100e-14 -3.57471034e-13 -2.10627244e-13
 -2.96658379e-02]
supnorm grad right now is: 0.029665837915092936
Weights right now are: 
[-4.99018409 -0.72876399 -3.82306496 -4.65258687  5.24475287  0.62007231
  4.2220023   3.93655857 -2.27651833 -0.91138332 -2.25790923 -2.00486137
  1.55114329  0.46412349 -0.02685496  0.81271664 -1.44927108 -0.51528073
 -2.65674558 -2.21195744 -2.15793749 -0.95230045 -2.40672281 -1.82399838
 -0.9721291  -0.83279589 -1.72185962 -0.91257678  0.46464692  1.45508547
  1.54233619  0.50846966 -1.09441758 -0.63597669 -1.39162665 -1.20621292
 -2.52071622 -1.43646482 -1.29935143 -1.072516   -0.59960817 -1.09708281
  0.24217266  0.33138666  0.43506186  1.12005702 -0.17884909  0.38783817
 -1.46291651 -0.57746007 -0.43939962 -1.5949613   0.61520339  1.16139643
  0.5264489   1.68103837  1.28399308 -0.47871771 -0.12925082 -2.1942629
  2.09374602  1.58998045 -0.07242712  1.08642961 24.95802959]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.815096056739
gradient value of function right now is: [ 2.86798139e-09  2.74222321e-10  2.86636234e-09  2.86707610e-09
 -2.86846746e-09 -2.74269090e-10 -2.86684813e-09 -2.86756202e-09
  5.49156469e-11  6.71394409e-12  5.40313167e-11  5.75683788e-11
  3.08935000e-10  3.77945891e-11  3.03989893e-10  3.23873404e-10
  5.51227081e-11  6.73945427e-12  5.42351833e-11  5.77855518e-11
  5.32232425e-11  6.50706860e-12  5.23662367e-11  5.57942478e-11
 -8.88551533e-12 -2.86454353e-12 -1.02170416e-11 -1.80099950e-12
 -1.18463916e-12 -3.41877990e-13 -1.31270037e-12 -2.32175181e-13
  2.63147085e-11  8.87397421e-12  3.07482694e-11  5.40947467e-12
  1.83898670e-12  6.78255120e-13  2.22170545e-12  3.89545837e-13
  2.97599888e-12  4.69927684e-12  1.11311489e-12  2.42773923e-12
  1.56790011e-12  2.44734430e-12  5.49614655e-13  1.19609841e-12
  2.22257725e-12  3.54505177e-12  6.18950705e-13  1.45584907e-12
  2.24585604e-12  3.49503496e-12  5.90614759e-13  1.37001459e-12
  7.70142094e-13  1.36939694e-12  1.33177052e-13 -2.79529085e-16
 -7.98251861e-14  1.42681759e-14 -3.53873959e-13 -2.08234247e-13
 -7.72786395e-02]
supnorm grad right now is: 0.07727863945848461
Weights right now are: 
[-4.9937268  -0.72910323 -3.82660567 -4.65612846  5.24829557  0.62041154
  4.225543    3.94010014 -2.27658621 -0.91139162 -2.25797601 -2.00493252
  1.55076091  0.4640767  -0.02723123  0.81231575 -1.44933923 -0.51528907
 -2.65681263 -2.21202889 -2.15800329 -0.95230849 -2.40678755 -1.82406735
 -0.97211809 -0.83279234 -1.72184696 -0.91257455  0.4646484   1.4550859
  1.54233783  0.50846995 -1.09445014 -0.63598764 -1.39166466 -1.20621961
 -2.52071849 -1.43646565 -1.29935417 -1.07251648 -0.59961185 -1.09708863
  0.24217131  0.33138368  0.43505992  1.12005399 -0.17884976  0.3878367
 -1.46291925 -0.57746446 -0.43940038 -1.59496309  0.61520062  1.1613921
  0.52644818  1.68103668  1.28399213 -0.4787194  -0.12925098 -2.1942629
  2.09374612  1.58998043 -0.07242669  1.08642987 24.98119022]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -5142.815255122723
gradient value of function right now is: [ 2.83613838e-09  2.71311476e-10  2.83453751e-09  2.83524323e-09
 -2.83581640e-09 -2.71280344e-10 -2.83421572e-09 -2.83492136e-09
  5.43104131e-11  6.64007044e-12  5.34361235e-11  5.69340337e-11
  3.05677920e-10  3.73967735e-11  3.00786578e-10  3.20459511e-10
  5.45201057e-11  6.66590046e-12  5.36425788e-11  5.71539644e-11
  5.26411653e-11  6.43602184e-12  5.17938161e-11  5.51841738e-11
 -8.79632468e-12 -2.83522937e-12 -1.01137505e-11 -1.78282427e-12
 -1.17594072e-12 -3.39457175e-13 -1.30316795e-12 -2.30490010e-13
  2.60313402e-11  8.77617838e-12  3.04142474e-11  5.35082270e-12
  1.81792580e-12  6.70297572e-13  2.19601318e-12  3.85050968e-13
  2.94315336e-12  4.64774370e-12  1.09970738e-12  2.39937415e-12
  1.55093989e-12  2.42104235e-12  5.43051058e-13  1.18229059e-12
  2.19836748e-12  3.50652909e-12  6.11649412e-13  1.43908731e-12
  2.22148164e-12  3.45721327e-12  5.83641927e-13  1.35427465e-12
  7.61477890e-13  1.35498064e-12  1.31556277e-13 -2.47535208e-16
 -7.89019467e-14  1.40350342e-14 -3.49854642e-13 -2.06249732e-13
 -2.49820701e-02]
supnorm grad right now is: 0.024982070147348746
Weights right now are: 
[-4.99720014 -0.72943617 -3.83007706 -4.65960071  5.25176892  0.62074449
  4.22901439  3.9435724  -2.2766528  -0.91139976 -2.25804153 -2.00500233
  1.55038547  0.46403078 -0.02760065  0.81192218 -1.4494061  -0.51529724
 -2.65687842 -2.21209899 -2.15806785 -0.95231638 -2.40685107 -1.82413503
 -0.97210727 -0.83278885 -1.72183452 -0.91257236  0.46464986  1.45508632
  1.54233945  0.50847023 -1.09448206 -0.63599843 -1.391702   -1.20622617
 -2.52072072 -1.43646648 -1.29935687 -1.07251695 -0.59961546 -1.09709431
  0.24216994  0.33138072  0.43505802  1.12005103 -0.17885043  0.38783524
 -1.46292195 -0.57746875 -0.43940113 -1.59496486  0.61519789  1.16138787
  0.52644745  1.68103502  1.2839912  -0.47872106 -0.12925114 -2.1942629
  2.09374622  1.58998042 -0.07242626  1.08643012 24.98752577]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1551.6347824807378
W_T_median: 1406.0687944589158
W_T_pctile_5: 624.1985510162535
W_T_CVAR_5_pct: 487.91093300764965
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 3.0
F value: -5142.815255122723
-----------------------------------------------
.62915464e-11  2.26837086e-13  2.67183576e-11
  7.65231106e-11  7.58860727e-11  6.54861364e-13  7.71182712e-11
  5.68048033e-12  2.89003831e-12  5.37518127e-12  5.64183895e-12
  6.21484367e-12  3.16229997e-12  5.87764277e-12  6.17169765e-12
  1.72381641e-12  8.76898677e-13  1.63227417e-12  1.71239515e-12
  1.32170095e-12  6.72983216e-13  1.24498087e-12  1.31098152e-12
  1.60584580e-13  1.64424457e-13  1.18137809e-13  1.86645380e-13
  2.64212789e-12  2.63803121e-12  1.25467597e-12  2.91238156e-12
  7.16469809e-13  7.55151218e-13  6.34981284e-13  8.71457150e-13
  1.28454079e-13  1.36316713e-13  1.33782828e-13  1.59462181e-13
  1.60747198e-13 -3.42964190e-14  3.52937682e-13  8.51841280e-14
  7.38092685e-14  3.87216358e-14  2.44411399e-13 -3.53120975e-14
 -1.36175356e-01]
supnorm grad right now is: 0.1361753563516552
Weights right now are: 
[-5.23570613e+00 -4.77312416e+00 -3.36127417e-01 -4.67755445e+00
  4.50140735e+00  4.72987639e+00  8.30444370e-01  3.14166606e+00
 -2.74896110e+00 -1.17306093e+00 -1.11397828e+00 -1.63078038e+00
 -1.65523937e+00 -1.00312925e+00 -5.48421678e-01 -2.94366651e+00
  1.59802653e+00  1.54533342e+00  2.66864308e-01  1.71447710e+00
 -1.88217162e+00 -2.05378461e+00 -4.42688555e-01 -1.78333851e+00
 -1.67311224e+00 -1.28638431e+00 -1.40215752e+00 -1.01667745e+00
 -1.09885446e+00 -1.02254665e+00 -1.77861106e+00 -7.48379367e-01
  1.81353511e+00  8.55083253e-01  8.96039508e-01  1.75270331e+00
 -1.43854060e+00 -1.31966410e+00 -1.91722604e+00 -2.25128519e+00
 -1.24000644e+00 -1.51405065e+00 -2.11387163e+00 -1.65856798e+00
  3.09386765e-01 -2.13275417e-01  4.07984421e-02 -1.06028887e-01
 -1.23196858e+00 -1.36707765e+00  1.65405739e-02 -1.12471718e+00
 -2.14726280e+00 -1.34195751e+00 -1.18035266e+00 -1.21923889e+00
 -2.34649421e-01 -1.36728237e+00 -5.31622120e-01 -9.17424004e-01
 -3.77198217e-01  7.85131918e-01 -1.37423203e+00 -1.21122546e+00
  2.45921934e+01]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1550.413291756052
W_T_median: 1404.2325046781002
W_T_pctile_5: 624.0906801703813
W_T_CVAR_5_pct: 487.92797957094484
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 3.0
F value: -5139.1671809527215
-----------------------------------------------
