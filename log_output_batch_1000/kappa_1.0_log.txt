Starting at: 
2022-06-17 22:26:16
tracing parameter entered from terminal:  1.0


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2095.362359089021
gradient value of function right now is: [ 8.52129837e+00  5.56738757e+00  4.85271952e+00  4.78764614e+00
 -8.52129837e+00 -5.56738757e+00 -4.85271952e+00 -4.78764614e+00
  6.60130681e+00  8.15005687e-02  1.86979741e-01  3.03401816e+00
 -3.22078462e+00 -1.21200097e-02 -3.34972858e-02 -1.10061014e+00
  9.71185338e-01  1.35792864e-02  2.15460133e-02  3.12716319e-01
 -1.95968732e+00 -4.56977899e-03 -1.28247688e-02 -5.73919487e-01
  3.57217196e-01  2.63380012e+00  3.59332500e+00  2.71559397e+00
  7.58689083e-02  1.40547558e-02  1.60013416e-01  9.81714986e-02
  1.61602952e-01  4.26079272e-02  3.45930957e-01  2.20377348e-01
  9.18899963e-01  1.28670250e+00  2.44180468e+00  1.86441379e+00
  3.21003734e-01  2.94514765e-02  3.70817209e-01  6.81308858e-02
 -2.20584928e+00 -4.10268578e-01 -2.35618514e+00 -5.66718559e-01
 -1.19591126e-01 -4.72141362e-01 -1.29556460e-01 -6.64481926e-01
 -5.20400208e-01 -3.50007784e-01 -5.58197163e-01 -5.11973205e-01
 -5.60672481e-01  1.12413709e+00  2.53718580e+00 -3.24210820e+00
 -1.80073937e+00  3.80370491e+00  1.40031157e+00 -2.29535301e+00
 -1.35326977e+01]
supnorm grad right now is: 13.532697727454694
Weights right now are: 
[-2.38680183  2.56430201 -0.88133177  1.85394217  2.64137055 -2.6729937
  1.28026904 -2.56997055  1.55628341 -5.00048326 -3.96402568 -0.21302522
  3.02168161  3.78775342  3.40060831  2.94840919  4.93666543 -9.15937011
 -6.55966384  2.56059043  4.4300141   2.81178842  3.27680844  3.26135041
 -2.18265108  3.93152951 -0.52221212  0.32295269  1.39292309  4.37866642
  6.71232494  5.26546915  1.37613557  4.80722504  4.74987102  4.17755435
 -2.63431738  3.24988343  1.12354104  1.71501382  1.48691521  1.17498344
  3.35221649  3.60839074 -0.78617924 11.83688114 -2.65705824  6.73164372
 -2.39420311  3.27162998 -2.28331905  0.1516981  -0.24503902  4.03243691
 -1.54951677  1.30285649  6.4408944   2.29232341  2.86788879 -1.73444085
  6.10253707  2.31517108  1.9592259  -1.68673708 27.00849209]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2114.021424675008
gradient value of function right now is: [-2.06064715e+00 -1.10309184e+00 -4.89366646e-02 -1.03988233e+00
  2.06064715e+00  1.10309184e+00  4.89366646e-02  1.03988233e+00
 -1.58700506e+00  1.39342690e-01  2.32495264e-01  7.82371456e-01
  2.93001075e+00 -9.89044923e-02 -1.67279267e-01 -5.61255149e-01
 -1.76433152e-01  3.83776701e-02  5.21145580e-02  1.04945951e-01
  2.86296025e+00 -9.93834191e-02 -1.67819743e-01 -5.61167442e-01
  7.54531859e-01 -2.09767623e+01 -1.51123399e+01 -8.62008721e+00
  1.25251818e-01  3.26422995e-03  3.14806393e-01  3.32011528e-03
  9.59679198e-02  3.53976808e-03  2.52180749e-01  3.49910406e-03
  1.05742390e-01  1.01895269e-02  2.75148968e-01  9.72369487e-03
  1.16772703e-01  3.21421230e-01  1.19224245e-02  4.36518198e-01
  3.65094645e+00  1.71090312e-02  2.37280544e+00 -2.24620365e-02
 -1.11592070e+00 -1.80126677e+00 -4.99065833e-01 -2.19215409e+00
 -3.28641161e+01 -3.00916111e+00 -2.10506207e+01 -3.08207743e+00
 -4.09583606e-01 -4.59858771e+00  1.02015412e+01 -5.16316637e+01
 -7.43227298e+00  3.63923959e+01  7.29585256e+00 -4.52693054e+01
 -1.09360413e+01]
supnorm grad right now is: 51.631663729802874
Weights right now are: 
[ -2.09925034   4.21873017  -4.73517749   4.03940611   2.35381905
  -4.32742186   5.13411476  -4.75543449  -1.29869397  -3.68695789
  -1.01411635  -0.24982006   3.4269064    2.40654737   1.7146097
   1.13890852  10.29454099 -15.2330763   -8.68904555   2.91994521
   3.56390044   2.83955646   1.62189457   0.83179507  -2.21018355
   3.09265556  -0.1446777   -6.88325909   0.0808384   19.44590481
  12.66174347  11.12910286  -0.53448318  17.24416009  10.72791174
   7.52373062  -4.60599484   9.42939549   7.44159155   4.11201583
  12.05700793   2.00772528   9.80206912   2.51198488  -2.66363132
  16.1322568   -3.98346261   8.98819713  -0.81955588   3.1208405
  -2.11292874   1.13344602   0.44425233  12.58950831  -3.32464486
  10.10014573   3.61011648   1.86723773   1.88100815  -1.08982399
   6.93619883   1.52154535   1.39399167  -1.13288235  27.7131665 ]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2129.1415956484534
gradient value of function right now is: [-6.69357953e+00 -7.67229786e-01  5.30026825e-02 -7.33841172e-01
  6.69357953e+00  7.67229786e-01 -5.30026825e-02  7.33841172e-01
 -4.79162900e+00 -1.54257245e-01 -2.35643117e-01 -6.54951997e-01
  3.12623319e+00  5.09252741e-02  8.13953988e-02  2.61457893e-01
 -9.40067089e-02 -3.91546390e-02 -4.70345535e-02 -6.96207220e-02
  3.09550758e+00  5.19772343e-02  8.27363741e-02  2.63204370e-01
 -8.42284077e-01  1.15808141e+01 -5.25274846e+00  3.30716748e+00
 -4.35612223e-02 -1.15020950e-04 -1.53883333e-01 -6.41312351e-05
 -1.80374877e-02 -1.22211228e-04 -7.16934023e-02 -6.36661359e-05
 -1.46072426e-02 -9.81907031e-04 -9.00664937e-02 -4.59885160e-04
 -1.05204275e-01 -3.92726606e-01 -2.82356106e-03 -3.73701554e-01
 -1.41887368e+00  1.46520451e-01 -1.75745732e+00  1.36376157e-01
  1.30140293e+00  2.04998482e+00  4.91895027e-02  1.99308643e+00
  2.14902313e+01  7.71119795e-01  1.33422849e+01  7.83185370e-01
  4.11600392e+00 -3.70522329e+00 -5.46732395e+00  3.23968187e+01
  4.16504724e+00 -2.18635373e+01 -3.20353883e+00  2.70091039e+01
  1.54809810e+01]
supnorm grad right now is: 32.39681873021334
Weights right now are: 
[ -2.03574185   3.73328922  -1.95215895   3.51337514   2.29031056
  -3.84198091   2.35109622  -4.22940352  -1.57600587  -2.4277515
   0.6601776    1.56069468   4.51986643   2.02345921   2.12413534
   2.70272542  12.16724964 -16.29138568  -9.02392601   3.33763887
   4.63195021   2.39911908   1.96445839   2.33001415  -2.92158366
   2.59362554   0.67761878  -8.57392442   2.328422    27.46192105
  16.01921856  15.37841049   1.53298158  26.57663089  13.80031965
  12.34432885  -2.54252822  20.41466407   9.67067969   9.9294809
  19.2989952    3.31410208  10.18306479   2.94093523  -1.6818013
  21.13245402  -3.95892224  14.68533849  -2.59754203   2.98802006
  -0.32543381   1.35714267   1.20840168  20.47942253  -3.22835704
  17.21088947   4.83083911   2.72939256   1.25487218  -1.44817175
   9.09291775   1.73856658   1.33531266  -1.44053315  27.97672019]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2124.7800607640465
gradient value of function right now is: [-1.42304857e+01 -3.07704346e+00 -6.73295572e-01 -2.92569308e+00
  1.42304857e+01  3.07704346e+00  6.73295572e-01  2.92569308e+00
 -7.64240733e+00 -1.89011768e-01 -2.06333063e-01 -8.72583648e-01
  5.24502844e+00  2.65894544e-02  3.00383003e-02  2.12750899e-01
 -5.48735945e-01 -4.60964237e-02 -4.79329446e-02 -8.00236564e-02
  5.05100636e+00  2.57427859e-02  2.90576996e-02  2.03118189e-01
 -7.31143997e-01  9.04638937e+00 -2.07680714e+01  2.78526039e+00
 -3.54080817e-02 -1.33689076e-05 -1.70775166e-01 -4.11713702e-06
 -1.44264268e-02 -9.15127537e-06 -7.21741114e-02 -2.86435478e-06
  6.62063011e-03 -4.05644080e-04 -3.05761682e-02 -1.24615966e-04
 -4.84414268e-02 -1.90597054e-01 -7.73716798e-04 -1.73350747e-01
  2.68568960e+00  4.35975319e-01 -3.21594668e-01  4.22823857e-01
  3.43927654e+00  3.33885514e+00  5.95009515e-01  3.20919674e+00
  2.11813989e+01  4.49498144e-01  1.48386189e+01  4.75355824e-01
  5.97039448e+00 -9.11237320e+00 -7.34333251e+00  4.03692050e+01
  4.42040750e+00 -2.44895339e+01 -4.98658196e+00  3.41136915e+01
  2.70628421e+01]
supnorm grad right now is: 40.36920499197615
Weights right now are: 
[ -1.90495363   3.34951924  -2.13572404   3.09586629   2.15952234
  -3.45821093   2.53466131  -3.81189468  -1.45373505  -5.27548897
  -1.07120465   2.26134164   5.41035972   2.99053803   2.88790442
   4.22500214  13.13495344 -17.48802842  -9.70724706   4.12507456
   5.62818081   3.38975883   2.74870127   3.84352063  -2.41140534
   2.33594578   0.99537446  -9.32881937   6.18606059  33.54977692
  20.76957551  18.35774069   6.1063382   31.97969692  19.97068153
  15.01291201  -2.68871093  27.94960325  11.22324429  14.49992556
  28.88725237   3.9656011   14.04463439   3.35831022  -1.3384978
  25.42299366  -3.72265186  19.83827828  -3.00289854   3.05814076
   0.6972261    1.77076631   1.48504436  28.13462469  -2.97936814
  24.43656759   5.74964033   3.02461341   1.01617123  -1.62861095
  10.11119752   1.89513569   1.13893943  -1.60640126  27.90097501]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2120.751901001582
gradient value of function right now is: [ 1.46352452e+01  3.76791392e+00  8.95602068e-01  3.25997435e+00
 -1.46352452e+01 -3.76791392e+00 -8.95602068e-01 -3.25997435e+00
  7.47484854e+00  9.23979449e-02  8.55392928e-02  5.22702710e-01
 -5.92616345e+00 -1.53469873e-02 -1.38658680e-02 -1.40443067e-01
  6.69948281e-01  2.10826951e-02  2.04243999e-02  3.74117915e-02
 -4.99901758e+00 -1.17111686e-02 -1.05863518e-02 -1.05189285e-01
  6.48587602e-01 -4.08712995e+00  2.26704175e+01 -1.53196368e+00
  2.22610797e-02  1.26484618e-06  9.43685617e-02  2.68746634e-07
  9.85813641e-03  5.82818532e-07  4.33593904e-02  1.24961333e-07
 -3.10977283e-03  6.70949532e-05  1.69100700e-02  1.69274985e-05
  4.71154109e-02  2.85399199e-01  7.55303805e-04  2.56348438e-01
 -3.21500332e+00 -3.01139284e-01 -2.69777980e-01 -2.87746430e-01
 -3.30223155e+00 -2.82062104e+00 -5.83732886e-01 -2.69051026e+00
 -1.31109130e+01 -2.83801802e-01 -1.17038863e+01 -2.98908360e-01
 -6.84510410e+00  9.73470271e+00  4.33425028e+00 -2.77337269e+01
 -2.76023944e+00  1.54100018e+01  2.99262438e+00 -2.39151499e+01
 -2.57850619e+01]
supnorm grad right now is: 27.733726911696536
Weights right now are: 
[ -1.70810343   3.44405918  -1.92645253   3.0659975    1.96267214
  -3.55275087   2.32538979  -3.78202589  -1.18667566  -7.056966
  -2.81068961   2.706893     5.09151174   3.48039669   3.30508859
   5.28146184  12.64764372 -18.75263966 -10.96761587   4.39154939
   5.74323746   3.87543923   3.16196493   4.87379426  -3.48938909
   2.13110366   1.18952489  -9.9444003    8.6166339   34.44721936
  24.59107579  18.5870214    9.64158164  32.52618153  25.1320374
  15.15445392  -7.31653505  29.4105941   15.18653352  14.84959602
  35.28730816   4.00691749  16.03519869   3.39736661  -1.75725342
  29.35495884  -3.84715429  24.24948835  -3.40468037   2.94886824
   0.87454286   1.88779097   1.56994985  35.01943361  -3.16948459
  31.04114383   5.93998786   3.48916098   1.11776693  -1.95807437
  10.62327849   2.23294003   1.25270652  -1.94149121  27.7941783 ]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2129.638476068042
gradient value of function right now is: [-1.79211419e+00 -1.17843564e+00 -2.32663025e-01 -8.46315254e-01
  1.79211419e+00  1.17843564e+00  2.32663025e-01  8.46315254e-01
 -3.71839104e-01  4.61874740e-02  4.15600065e-02  2.12966903e-01
  1.44696863e+00 -3.69961238e-03 -3.19793591e-03 -3.24980879e-02
 -1.49187601e-01  9.33662697e-03  8.83964145e-03  1.66255649e-02
  9.51985125e-01 -1.55041906e-03 -1.34514412e-03 -1.26227748e-02
  4.37457133e-02 -9.30512788e+00 -9.08371110e+00 -1.85704253e+00
  4.96167391e-03 -1.03679880e-10  2.63457769e-02 -1.88425256e-11
  1.86291102e-03  7.46147099e-11  1.05611513e-02  1.72884000e-11
 -7.14136385e-03 -1.18299003e-06 -2.71040609e-02 -1.85741057e-07
 -1.81437754e-04 -1.12576089e-02 -1.04454397e-05 -1.19744810e-02
  1.18740971e+00 -1.33175109e-02  5.00615091e-01 -1.33078139e-02
  6.66789864e-01 -4.27015130e-01  4.28008589e-01 -4.11274693e-01
 -1.44990465e+01 -3.11267041e-01 -7.92688776e+00 -3.06058957e-01
  7.59930940e-01 -2.22264403e+00  3.57210319e+00 -2.01482868e+01
 -2.43440392e+00  1.28283817e+01  3.05228392e+00 -1.78753379e+01
 -5.73371249e+00]
supnorm grad right now is: 20.148286816110616
Weights right now are: 
[ -1.92622301   3.72933854  -1.77288502   3.11185843   2.18079173
  -3.83803023   2.17182229  -3.82788681  -1.47229937  -6.37592507
  -2.33267656   3.15022737   4.7413437    1.84871467   1.61706786
   7.50955035  13.31058931 -20.46901555 -12.86730544   4.42323267
   6.76473503   2.16289511   1.4097708    6.68094898  -3.50827329
   2.01171404   1.10946868 -10.16438046   8.48116849  34.54316828
  29.20556459  18.59991641  10.09984704  32.56452517  30.54943681
  15.15958626 -10.96753265  27.75933966  15.11638318  12.5391132
  42.7350995    3.89835227  18.44716093   3.33323658  -1.71212894
  33.31581765  -3.57597831  28.50474808  -2.97840629   2.72911842
   0.24678609   1.78278939   1.63950201  40.1840508   -3.0056672
  36.1343691    6.35281355   3.15488056   0.91619118  -1.99533639
  10.10957623   2.07864427   1.03970676  -1.98620164  27.82192934]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -2125.266576671819
gradient value of function right now is: [-8.88775767e+00 -4.76993560e+00 -1.32900487e+00 -1.77226747e+00
  8.88775767e+00  4.76993560e+00  1.32900487e+00  1.77226747e+00
 -3.37805474e+00  7.40905541e-03  6.18565906e-03  6.27698660e-02
  5.40208535e+00  1.48997657e-03  1.18049526e-03  5.89481534e-03
 -7.02270686e-01  1.16100991e-04  1.12652292e-04  4.44468193e-04
  1.73914365e+00  7.99456774e-05  6.24050369e-05  4.96749664e-04
  1.01165800e-02 -1.41736124e+01 -2.30568443e+01 -2.34969894e+00
  3.78287161e-03  5.37818689e-10  1.20338221e-04  1.68038516e-10
  1.57545768e-03  1.26148518e-10 -2.22729592e-04  3.92355075e-11
 -8.18559385e-03  7.34108328e-07 -2.44762835e-02  4.00854446e-07
 -2.29979015e-04 -6.67652035e-02 -8.00941272e-06 -6.47976563e-02
  5.84604246e+00  1.91616327e-01  2.95054898e+00  1.88794989e-01
  4.23760767e+00  6.27367444e-01  2.61141447e+00  6.22206862e-01
 -1.97636908e+01 -4.21784431e-01 -1.00852055e+01 -4.14620345e-01
  1.20526835e+00 -3.42085846e+00  3.21766246e+00 -1.98529846e+01
 -2.60267379e+00  1.36946197e+01  2.92265265e+00 -1.81521266e+01
  2.01640530e+00]
supnorm grad right now is: 23.056844282081023
Weights right now are: 
[ -2.0746085    3.89644283  -1.7263406    3.205764     2.32917721
  -4.00513452   2.12527787  -3.92179238  -1.63903301  -6.7814314
  -3.25222576   3.28219946   3.86957819   1.38079971   1.50204079
   9.48074451  12.65511126 -20.80484305 -13.39374211   5.42919008
  10.75419721   1.5925725    1.19103527   7.53384787  -2.27499618
   2.08909445   1.35675948 -10.56786938  12.38051754  34.54999297
  33.19470747  18.60056904  14.6733615   32.56618749  35.26542083
  15.15973113 -11.72444284  28.14345653  18.27058926  11.36283807
  50.8443362    3.38598037  23.22357541   2.75277255  -1.1753324
  37.38795422  -3.9266851   32.85333687  -2.81086513   2.88107851
   0.91090318   2.12064373   1.59382215  45.65871504  -3.14747813
  41.49704023   6.5460807    3.44396296   1.15473394  -2.03063799
  10.44433043   2.10440487   1.23641152  -2.02851371  27.88920856]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2127.0287069108126
gradient value of function right now is: [-9.29266866e+00 -3.03414614e+00  1.48010711e-01  4.95735297e-01
  9.29266866e+00  3.03414614e+00 -1.48010711e-01 -4.95735297e-01
 -6.03391602e+00 -9.54372159e-02 -7.76878606e-02 -5.74680847e-01
  6.25135853e+00  1.78064547e-02  1.35350575e-02  2.25923437e-01
 -6.40377533e-01 -1.64980085e-02 -1.47697973e-02 -3.55726352e-02
  1.93327028e-01  5.42573177e-05  4.12910432e-05  6.84895293e-04
 -5.15697498e-01  8.51265023e+00 -6.33472900e+00  1.75463732e+00
 -7.20560591e-03 -1.42307003e-09 -5.40144983e-02 -2.37568064e-10
 -3.15188366e-03 -2.36948124e-10 -2.48493183e-02 -3.81668059e-11
 -1.39381859e-02 -1.41291218e-05 -4.06678001e-02 -2.84301898e-06
 -2.68323636e-02 -2.73400418e-01 -1.47651092e-03 -2.47355124e-01
  7.12648841e-01  6.12385308e-02 -5.47997207e-01  5.60304910e-02
  1.76494806e+00  2.84065445e+00 -5.42159058e-02  2.70609028e+00
  1.51751358e+01  3.05633744e-01  1.22926933e+01  3.05864744e-01
  4.56555758e+00 -6.80676508e+00 -5.73704151e+00  3.12615849e+01
  2.72390624e+00 -1.44927013e+01 -4.75714931e+00  2.80743514e+01
  2.54158695e+01]
supnorm grad right now is: 31.261584875751872
Weights right now are: 
[ -2.32895978   3.82968605  -2.35732608   4.21689683   2.58352849
  -3.93837774   2.75626335  -4.93292521  -1.714801    -6.64195164
  -3.41655057   4.07653068   3.45700955   0.35574877   0.84512463
   9.06301367  12.05604585 -21.15177903 -14.03532977   6.7137708
  17.59563299  -0.11971162  -0.0626567    6.50322203  -3.51068859
   2.40770101   1.88716416 -10.77282813  13.29160651  34.54985611
  37.0157498   18.60045921  16.53715691  32.56617596  39.77961652
  15.15971141 -13.17993437  24.51194785  19.93000826   9.76413292
  52.3070162    4.41029157  25.43146952   3.76955402  -1.95402117
  40.64985341  -4.57014693  36.20263661  -3.34246971   2.89939993
   0.44702485   2.2449124    1.48408182  50.60088775  -2.94210908
  46.41330168   7.3366979    3.59348905   0.74074913  -2.03548028
   9.94267476   2.10808128   0.87381574  -2.02666844  27.97297774]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2129.027110776415
gradient value of function right now is: [ 9.06958027e+00  5.29152255e+00  1.93698807e+00  1.02050175e+00
 -9.06958027e+00 -5.29152255e+00 -1.93698807e+00 -1.02050175e+00
  3.88519937e+00  5.29120373e-02  4.34689411e-02  2.43245445e-01
 -4.75488256e+00 -1.33650849e-02 -1.05485218e-02 -1.11031657e-01
  9.42439939e-01  3.87329822e-03  3.45518951e-03  8.32995277e-03
 -7.44163510e-01 -6.75173247e-06 -5.22473397e-06 -8.75327648e-05
  1.45863008e-01  2.78667030e+00  1.27621861e+01  4.48361352e-01
  1.38972386e-03  4.06774239e-11  1.66924667e-02  9.87093410e-12
  5.48549549e-04  4.41409307e-12  6.98102746e-03  1.03485764e-12
  4.50256370e-03  4.45101265e-06  1.18574206e-03  1.51006977e-06
  5.13744808e-03  7.72422186e-02  4.27048205e-04  6.89729057e-02
 -2.45761106e+00 -1.06450482e-01 -6.74419555e-01 -1.01430893e-01
 -3.04090368e+00 -1.48942104e+00 -1.12479408e+00 -1.42968942e+00
  3.40246286e+00 -6.85349413e-03 -8.66046062e-01 -9.78630901e-03
 -1.81731694e+00  3.64101194e+00  1.17891548e+00 -6.36863834e+00
  9.16011371e-01 -2.05266733e+00  9.29884346e-01 -5.62027733e+00
 -1.08968520e+01]
supnorm grad right now is: 12.762186083387803
Weights right now are: 
[-2.27163799e+00  4.06545313e+00 -2.57723210e+00  4.68370459e+00
  2.52620670e+00 -4.17414482e+00  2.97616937e+00 -5.39973297e+00
 -1.46744452e+00 -5.66961126e+00 -2.69072131e+00  5.01831794e+00
  3.33584017e+00 -1.59439458e+00 -5.74305855e-01  7.86939628e+00
  1.36882557e+01 -2.16885995e+01 -1.48804496e+01  7.87255170e+00
  2.16450367e+01 -7.07936976e-01 -2.92918336e-01  4.62640377e+00
 -2.66646926e+00  2.68168175e+00  2.31778968e+00 -1.10977477e+01
  1.32764111e+01  3.45498810e+01  4.13437076e+01  1.86004524e+01
  1.77024504e+01  3.25661807e+01  4.48040400e+01  1.51597106e+01
 -1.56085564e+01  2.15551249e+01  2.08672588e+01  8.59325614e+00
  5.57258686e+01  4.61701835e+00  3.03631806e+01  3.97608731e+00
 -1.99490234e+00  4.35429508e+01 -4.02782253e+00  3.91045921e+01
 -2.91390340e+00  2.66800862e+00  3.39319593e-02  2.12756865e+00
  1.43126006e+00  5.34318867e+01 -3.34138274e+00  4.92862312e+01
  7.51805086e+00  3.87088683e+00  9.79867105e-01 -2.21556930e+00
  8.98943819e+00  1.65271150e+00  1.11421310e+00 -2.21810649e+00
  2.80186126e+01]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2126.997719694047
gradient value of function right now is: [ 8.43627748e+00  5.46706209e+00  2.29906603e+00  1.28220430e+00
 -8.43627748e+00 -5.46706209e+00 -2.29906603e+00 -1.28220430e+00
  3.12039052e+00  1.64922202e-02  1.21427353e-02  1.70409204e-01
 -3.61699558e+00 -2.84231444e-03 -2.06933006e-03 -7.03803505e-02
  9.42006241e-01 -3.26069643e-03 -3.00049554e-03 -4.32964185e-03
 -7.03770651e-01 -4.85500949e-07 -3.51316691e-07 -3.60276834e-05
  1.52577362e-01  3.41536944e+00  1.15416107e+01  5.94401505e-01
  8.80537932e-04  3.61152080e-11  3.87194463e-03  6.06952176e-12
  3.46422625e-04  3.84386007e-12  1.11943923e-03  6.23588005e-13
 -7.77765343e-04  8.62112477e-06 -1.31517753e-02  1.64546194e-06
  4.26326038e-03  2.51559049e-02  1.91829358e-04  2.16279917e-02
 -2.16193109e+00 -1.01707801e-01 -6.33771730e-01 -9.77179801e-02
 -3.14916347e+00 -6.69163914e-01 -1.23133757e+00 -6.33745855e-01
  4.34234066e+00  1.05606112e-01  3.10911570e+00  1.03252632e-01
 -2.49453244e+00  4.60849335e+00  5.62245956e-01  3.27877237e+00
 -2.32751006e-01 -8.76096252e-03  3.74952587e-01  3.40830117e+00
 -1.14281713e+01]
supnorm grad right now is: 11.541610686305194
Weights right now are: 
[ -2.38482115   3.9375454   -2.83108004   4.38051718   2.63938986
  -4.04623709   3.23001731  -5.09654556  -1.51430939  -5.6192536
  -2.92344954   5.47224326   3.46999456  -1.9557605   -0.40181953
   8.5354152   15.05158842 -23.00645763 -16.41285642   7.48237964
  24.35360578  -0.84721734  -0.33980782   4.92337731  -2.01886155
   2.46677161   2.68852386 -11.29870467  12.40723523  34.54988759
  44.48261508  18.60045172  17.64778116  32.5661816   48.58813034
  15.15971051 -17.60112996  18.14111258  20.29919287   6.48533556
  58.00509519   5.2788086   33.32853406   4.75804223  -1.85111296
  45.41881106  -4.57255322  40.92424341  -2.78291162   3.09548601
  -0.2574413    2.56578171   1.59181345  57.57734655  -3.16592101
  53.52763624   7.48160809   4.15921818   0.87413864  -2.0479157
   9.28474524   1.90758694   1.02286438  -2.03168213  27.60836635]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2132.0901963915917
gradient value of function right now is: [ 3.76156920e+00  1.78173823e+00  2.19351859e-01 -5.82313259e-03
 -3.76156920e+00 -1.78173823e+00 -2.19351859e-01  5.82313259e-03
  2.05693968e+00  1.83472077e-02  1.38649553e-02  1.49741900e-01
 -2.15202390e+00 -2.87028904e-03 -1.99844551e-03 -7.15355614e-02
  2.24623101e-01  9.97247799e-04  9.57454435e-04  1.61256555e-03
 -9.69168949e-02 -2.00419176e-07 -1.39850436e-07 -2.01264012e-05
  1.90483389e-01  4.93820081e-01  3.26150989e+00  1.56682966e-01
  6.93895920e-04  2.49352260e-11  5.75675413e-03  4.49880817e-12
  2.82474247e-04  1.94584735e-12  2.43997613e-03  3.40806167e-13
  1.21134090e-03  6.20261703e-06 -9.55941338e-03  1.20063865e-06
  2.94914068e-03  2.20332940e-02  1.34413923e-04  1.89986579e-02
 -5.97015988e-01 -2.79519883e-02 -1.42008983e-01 -2.65182860e-02
 -1.04890804e+00 -4.91401713e-01 -2.98720133e-01 -4.56176441e-01
  8.48814764e-01  2.50999950e-02  6.00510236e-01  2.39546815e-02
 -1.15648707e+00  2.06788332e+00  5.58434443e-01  3.60928785e-01
 -8.94788095e-02  5.39560610e-01  4.26212721e-01  4.56579343e-01
 -6.78660251e+00]
supnorm grad right now is: 6.786602509443312
Weights right now are: 
[ -2.3749895    3.93921938  -2.6161595    4.73171381   2.62955821
  -4.04791107   3.01509677  -5.44774219  -1.55598532  -6.04497367
  -3.18728149   5.64314119   3.43568988   0.46086475   2.29661543
   7.65216426  16.45525041 -21.60890013 -15.27515042   9.9513477
  26.97425599  -0.83598954  -0.30522149   4.45366103  -1.20736314
   2.51522807   2.67169179 -11.72171819  11.31628958  34.54989101
  45.84950908  18.60045149  17.58960835  32.56618201  50.84649374
  15.1597105  -19.85449184  14.96011287  21.33705461   5.23166002
  62.8376488    5.33767893  39.23322922   4.86334774  -1.4587168
  48.13270928  -4.05286088  43.67188894  -2.31169918   2.93592308
   0.21950256   2.44291553   1.54551251  61.31111084  -3.3884079
  57.27905802   7.66859475   3.99354625   0.82017506  -2.14431038
   9.3449784    1.82897989   0.96378188  -2.12942179  27.69784633]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2122.1843531296636
gradient value of function right now is: [-3.87076351e+00 -4.01238093e+00 -2.55036546e+00 -1.66643621e+00
  3.87076351e+00  4.01238093e+00  2.55036546e+00  1.66643621e+00
  1.53440741e-01  1.94268656e-02  1.45399359e-02  1.71365815e-01
  5.31626482e-01 -1.48420098e-03 -9.65117260e-04 -6.64873636e-02
 -5.84017455e-01  1.22089817e-03  1.07842555e-03  2.34730913e-03
  5.84983634e-01 -6.05968826e-08 -4.24075212e-08 -5.06127004e-06
  2.04400575e-01 -1.15423754e+01 -1.05831256e+01 -2.39329720e+00
  1.13053703e-03  1.71000413e-11  7.47054494e-03  2.59146503e-12
  5.33888889e-04  1.45439217e-12  3.62447986e-03  2.00529687e-13
  7.31984675e-03  2.04605667e-05  8.75488062e-03  4.98226037e-06
  7.95815535e-03  1.15207359e-01  8.23544318e-04  9.99843441e-02
  2.63811853e+00  4.19514933e-02  1.32403893e+00  4.16143079e-02
  2.76956596e+00 -5.35421302e-01  1.88218949e+00 -4.77010890e-01
 -2.11067356e+01 -3.08971457e-01 -1.19701336e+01 -3.04282817e-01
 -4.38994250e-01 -3.53639643e-01  4.21511885e+00 -2.88930085e+01
 -3.76179383e+00  2.02499419e+01  3.76485671e+00 -2.67182651e+01
 -7.18357258e+00]
supnorm grad right now is: 28.893008464132354
Weights right now are: 
[ -2.48051648   3.62640692  -2.8751834    4.37822614   2.73508519
  -3.73509862   3.27412067  -5.09425452  -1.60165951  -6.84886725
  -4.18611463   4.95782304   3.15656907   2.8997137    5.29934329
   9.30897592  17.54014516 -24.65851077 -18.53805365   7.71634205
  28.89674216  -0.82602433  -0.28730582   4.68041519  -3.44390899
   2.2444675    2.82097472 -11.61621148  12.48794645  34.54988891
  46.86467242  18.60045047  19.17765457  32.56618197  51.92090129
  15.15971042 -21.54709796  10.50477798  22.17016415   3.68439794
  62.36213755   5.09412046  46.81570069   4.73329956  -1.38010398
  49.88696279  -4.387094    45.32719372  -2.56987527   2.97372959
   0.15783134   2.5171268    1.4787367   65.23735639  -3.42946237
  61.25878337   7.98107269   4.05120358   1.11673486  -2.30629627
   9.13676307   1.82043001   1.29484397  -2.29407796  27.87544902]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2130.5400667120202
gradient value of function right now is: [ 6.95391283e+00  4.67664165e+00  1.36127006e+00  6.90541411e-01
 -6.95391283e+00 -4.67664165e+00 -1.36127006e+00 -6.90541411e-01
  2.41632016e+00 -1.38488411e-02 -1.25452095e-02  3.63683506e-02
 -2.97769912e+00 -3.70171943e-04 -9.93600924e-05 -4.26854070e-02
  4.69847493e-01 -2.33177807e-03 -2.09420728e-03 -3.72435176e-03
 -4.15337134e-01 -2.25531524e-09  4.57789323e-09 -6.64738316e-06
  9.07845915e-02  9.88929690e-01  8.89895021e+00  1.36960564e-01
  1.44314858e-04  3.70044411e-12 -2.49481559e-03  5.93359811e-13
  5.72090933e-05  2.62306776e-13 -1.71840232e-03  3.95174109e-14
  1.83238379e-03  1.31721487e-05  1.02739978e-02  2.57420483e-06
  4.42912202e-03  3.32968543e-02  2.97468757e-04  3.03853659e-02
 -1.42537368e+00 -4.93991058e-02 -4.61254312e-01 -4.77131048e-02
 -3.08017367e+00 -7.49643920e-01 -1.18373519e+00 -7.17195435e-01
  9.69497458e-01 -3.01372004e-02 -1.55079760e+00 -3.15694113e-02
 -1.29544988e+00  2.59870875e+00  7.06612478e-01 -6.96743821e+00
  7.00629832e-01 -1.21002140e+00  5.94873573e-01 -6.41601842e+00
 -7.83376919e+00]
supnorm grad right now is: 8.89895021257802
Weights right now are: 
[ -2.35914774   3.70799611  -2.39985676   4.77275754   2.61371645
  -3.8166878    2.79879403  -5.48878592  -1.57362856  -6.64397422
  -4.01051672   5.91612601   3.10162503   3.44230222   6.51913541
   8.85470997  19.38873922 -24.88448617 -18.93563249   8.10884194
  30.13804108  -0.82899902  -0.28401025   5.61567763  -2.5248296
   2.34419826   2.90064175 -11.71747879  12.94483637  34.54988613
  48.80761787  18.60044989  19.83958147  32.5661818   54.20390614
  15.15971038 -24.6663388    7.92773326  21.50781077   2.01383506
  61.95914077   5.79512669  51.96148402   5.46898804  -1.4769563
  52.74981986  -4.42531175  48.12579007  -2.7525519    2.75137484
   0.28758736   2.37831577   1.59275001  69.10924746  -3.43218586
  65.18319816   8.5778049    4.27377524   0.55236987  -2.40321624
   9.47773583   1.87028838   0.68374292  -2.39912395  27.97086279]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -2116.8579765766194
gradient value of function right now is: [ 5.81765641e+00  2.60090443e+00  1.31312428e-01  3.68495810e-02
 -5.81765641e+00 -2.60090443e+00 -1.31312428e-01 -3.68495810e-02
  3.98334728e+00  1.42135554e-01  1.13331962e-01  6.64541488e-01
 -3.22216546e+00 -1.05510534e-02 -7.14146439e-03 -2.09687214e-01
  1.28916993e-01  9.94316222e-03  8.90221737e-03  1.71480790e-02
 -1.11872143e-02 -1.32318256e-07 -8.80998762e-08 -1.12431660e-05
  3.05111787e-01 -7.90384065e+00 -9.97385020e-03 -2.11071633e+00
  5.81682288e-04  3.65182368e-12  4.71243069e-02  5.04349520e-13
  2.90614107e-04  2.68502597e-13  2.57725421e-02  3.49319468e-14
  3.89173983e-03  1.05937407e-05 -7.52132911e-02  2.06951002e-06
  1.02576148e-02  1.22047313e-01  1.25104575e-03  1.10463972e-01
 -8.57535471e-02 -3.64102356e-02  1.43116778e-01 -3.49125399e-02
 -2.00253212e-01 -2.56835950e+00  6.14555133e-01 -2.43678139e+00
 -1.89682103e+01 -2.17630748e-01 -1.19948543e+01 -2.18807245e-01
 -2.07640228e+00  2.87789913e+00  5.31293241e+00 -2.78476914e+01
 -3.92387861e+00  1.95920896e+01  4.67983985e+00 -2.61400140e+01
 -1.84763662e+01]
supnorm grad right now is: 27.84769141551172
Weights right now are: 
[-2.45059617e+00  3.57139281e+00 -2.62997990e+00  4.47827944e+00
  2.70516488e+00 -3.68008450e+00  3.02891717e+00 -5.19430782e+00
 -1.45357855e+00 -6.48173897e+00 -3.97466422e+00  6.51350226e+00
  2.98284227e+00  4.48750081e+00  8.03908682e+00  8.81490138e+00
  2.07587201e+01 -2.72455905e+01 -2.15520224e+01  6.73359466e+00
  3.14439721e+01 -8.34532543e-01 -2.85611128e-01  6.42952867e+00
 -2.70286064e+00  2.13818324e+00  2.92102269e+00 -1.20383436e+01
  1.30402529e+01  3.45498847e+01  5.03769816e+01  1.86004495e+01
  2.02512681e+01  3.25661817e+01  5.58260862e+01  1.51597104e+01
 -2.37209402e+01  4.44719479e-01  2.19644435e+01 -1.52429844e+00
  5.94997785e+01  6.47431551e+00  5.80811886e+01  6.16203256e+00
 -1.59410609e+00  5.52993713e+01 -4.38332659e+00  5.06277056e+01
 -2.38419487e+00  2.71847122e+00  4.29431159e-02  2.30503868e+00
  1.47488556e+00  7.26278729e+01 -3.25933715e+00  6.87445500e+01
  8.29567006e+00  4.56510774e+00  6.40707703e-01 -2.50182823e+00
  8.80667858e+00  1.90643171e+00  7.76257559e-01 -2.48583673e+00
  2.77628879e+01]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2129.4504622949576
gradient value of function right now is: [-9.76770411e+00 -5.48371844e+00 -9.73754306e-01 -4.35832636e-01
  9.76770411e+00  5.48371844e+00  9.73754306e-01  4.35832636e-01
 -5.08771426e+00 -1.01138800e-01 -7.89014935e-02 -6.06848663e-01
  4.43054417e+00  5.92005920e-03  3.74841083e-03  1.80165309e-01
 -4.00443905e-01 -6.52626446e-03 -5.81771984e-03 -1.13730432e-02
  3.29622336e-01  4.67026887e-08  3.00734056e-08  4.62252111e-06
 -3.40516810e-01  3.91484159e+00 -8.47496189e+00  1.02386533e+00
 -1.84168742e-03 -1.32409729e-12 -3.87040990e-02 -1.06198056e-13
 -9.53199072e-04 -1.02621891e-13 -2.15567561e-02 -7.58962618e-15
 -3.17693170e-03 -2.63707723e-06  4.71655386e-02 -2.80228477e-07
 -1.10640347e-02 -1.13892169e-01 -1.64747047e-03 -1.00875360e-01
  1.43444306e+00  5.88858543e-02 -2.02608882e-02  5.64103934e-02
  3.03377785e+00  2.51623995e+00  4.20488880e-01  2.39339850e+00
  9.52652201e+00  1.44150967e-01  8.01896933e+00  1.46128009e-01
  2.28271572e+00 -3.62715669e+00 -4.84688288e+00  2.40759834e+01
  2.12724252e+00 -1.17999206e+01 -4.28533829e+00  2.25921811e+01
  2.16967718e+01]
supnorm grad right now is: 24.075983387409615
Weights right now are: 
[ -2.62416158   3.39742966  -2.44379441   4.95620978   2.87873029
  -3.50612135   2.84273168  -5.67223816  -1.6137732   -7.09126657
  -4.72382012   5.68276254   3.15451246   6.9131383   10.74840527
   9.58035042  22.21218432 -28.81501467 -23.26221136   5.73567703
  33.16808702  -0.83642858  -0.28569453   6.79858822  -2.92078432
   2.40185821   2.80222779 -12.16149577  11.79505944  34.54988422
  51.2025053   18.6004494   18.93728601  32.56618169  56.63368989
  15.15971035 -24.361928    -1.4327561   22.91994415  -2.09757598
  60.88818997   5.16090707  60.38393432   4.77967249  -1.45039861
  57.39633678  -4.32504151  52.62273854  -2.29013629   2.77059446
  -0.42289927   2.38830733   1.63239348  76.03866086  -3.26413335
  72.22781594   8.38219709   4.37538275   0.58231907  -2.28499167
   8.819997     1.74868115   0.73050583  -2.26716696  27.98136954]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2132.6778591466477
gradient value of function right now is: [-3.89401796e+00 -1.88523782e+00  2.56968668e-01  3.12089826e-01
  3.89401796e+00  1.88523782e+00 -2.56968668e-01 -3.12089826e-01
 -2.66263125e+00 -5.96087210e-02 -4.81467368e-02 -3.73360215e-01
  2.46023361e+00  3.50638086e-03  2.34970058e-03  1.51172224e-01
 -7.48677548e-02 -4.21846706e-03 -3.79935353e-03 -7.19413489e-03
 -8.14723821e-03  1.34484544e-08  8.69178288e-09 -2.32580349e-06
 -2.81151641e-01  4.12039251e+00 -1.15971458e+00  7.19359327e-01
 -4.60348171e-04 -3.22546692e-13 -2.04540196e-02 -2.03581631e-14
 -2.69450278e-04 -2.17656052e-14 -1.26761169e-02 -1.25306445e-15
  7.79540640e-03  2.90753874e-05  5.74987750e-02  8.26084586e-07
 -8.18783946e-03 -8.84060413e-02 -1.58213126e-03 -7.84129728e-02
 -1.01272424e+00 -1.47724064e-02 -7.67405471e-01 -1.52682686e-02
  2.44794357e-01  1.46814112e+00 -3.49208109e-01  1.39858528e+00
  7.06800758e+00  8.88639410e-02  4.45219106e+00  8.90790742e-02
  1.30366668e+00 -1.87777700e+00 -1.98423069e+00  1.04502284e+01
  1.54066958e+00 -7.59604494e+00 -1.76196050e+00  9.90419004e+00
  1.00349063e+01]
supnorm grad right now is: 10.450228423213968
Weights right now are: 
[ -2.61912515   3.42103047  -2.2054722    5.58088797   2.87369386
  -3.52972216   2.60440947  -6.29691635  -1.54472666  -7.66467397
  -5.47253867   6.56986305   2.89703621   4.87768444   9.79363348
   7.9859627   23.85530178 -29.51581826 -24.16198795   5.83631057
  34.55329202  -0.83944142  -0.28701314   6.65088797  -3.61220714
   2.45608215   2.9613736  -12.08810432  11.25862636  34.54988378
  52.97351514  18.60044932  19.29661338  32.56618167  58.64260163
  15.15971034 -26.98153575  -5.20758761  21.31919646  -1.66054284
  57.50613989   5.29254749  63.12102052   4.86003921  -1.29411897
  58.30283928  -4.30595589  53.43688533  -1.91755699   2.64087522
   0.3178136    2.23550998   1.6763708   79.12925075  -3.54453272
  75.37908232   8.49363346   4.3623405    0.8053366   -2.39725958
   8.68135897   1.70533265   0.96990506  -2.38014345  28.0344701 ]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2129.0185449641704
gradient value of function right now is: [-3.95991486e+00 -3.80508556e+00 -1.51335138e+00 -1.11387316e+00
  3.95991486e+00  3.80508556e+00  1.51335138e+00  1.11387316e+00
 -1.85144973e-01  1.31663626e-02  9.53115905e-03  1.22561385e-01
  7.80535481e-01 -1.49729376e-03 -9.91184341e-04 -5.16066288e-02
 -2.93150921e-01  3.28037895e-04  3.05536925e-04  4.69069100e-04
  3.90482071e-01 -3.16633716e-09 -2.18197821e-09  2.98369703e-06
  1.06934611e-01 -7.25209539e+00 -9.18217179e+00 -1.25553068e+00
  1.89791855e-04  3.28608226e-13  6.25243595e-03  4.78828358e-14
  1.02855484e-04  1.99092762e-14  3.48371018e-03  2.69851132e-15
  1.73848504e-03 -1.45239101e-05 -8.73741700e-03 -2.57418993e-06
  2.46237288e-03  6.65720984e-02  3.96409282e-04  5.96117645e-02
  2.18517669e+00  4.48351069e-02  9.83753069e-01  4.44889681e-02
  3.02734798e+00 -2.07345879e-01  1.57789723e+00 -1.72514384e-01
 -1.20452864e+01 -1.15835578e-01 -5.01751834e+00 -1.13889277e-01
  1.47029325e-01 -7.55204419e-01  2.72795059e+00 -1.17789168e+01
 -3.07641352e+00  1.36484198e+01  2.50724752e+00 -1.11661714e+01
 -9.75686556e-01]
supnorm grad right now is: 13.648419819140555
Weights right now are: 
[ -2.57398998   3.41117302  -2.41292012   4.93972937   2.82855869
  -3.51986471   2.81185739  -5.65575776  -1.37471377  -7.39808828
  -4.92202495   6.04367917   2.86307897   8.01227361  13.4867929
   8.06444312  26.67585216 -29.88951979 -24.74591484   6.39525321
  35.51221522  -0.83924915  -0.28662622   4.86322862  -3.02467767
   2.20144036   2.82760407 -12.47827631   9.08458231  34.54988352
  53.02016266  18.60044927  17.12235514  32.56618165  58.81741263
  15.15971034 -28.82257921  -5.88732466  21.95696512  -0.9106609
  58.00007792   6.50613493  69.36768596   6.17081284  -1.47764852
  60.27289811  -4.76459834  55.26920674  -2.23507366   2.70356605
  -0.08790445   2.33112881   1.50046949  81.876008    -3.70822594
  78.21267565   8.65767014   4.49030801   1.09544832  -2.36897459
   8.52471496   1.78742823   1.24114485  -2.35198409  28.02831815]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2130.8745082458345
gradient value of function right now is: [-5.48541553e+00 -4.07591491e+00 -1.23474182e+00 -9.04861866e-01
  5.48541553e+00  4.07591491e+00  1.23474182e+00  9.04861866e-01
 -1.70993260e+00 -2.51545682e-02 -2.05478203e-02 -1.10952017e-01
  1.83549303e+00  1.12247915e-03  6.72570626e-04  3.04874485e-02
 -2.36783296e-01 -1.21372492e-03 -1.12212674e-03 -1.77451611e-03
  3.40652368e-01  2.33655333e-09  1.50528844e-09  1.50268208e-06
 -1.02850124e-02 -4.43112584e+00 -9.54906281e+00 -6.39297208e-01
  6.80988749e-06  7.61256333e-14 -6.82676847e-03  1.49452890e-14
  2.87649190e-06  3.58666235e-15 -3.85653395e-03  7.83449431e-16
 -2.81545968e-04 -1.86882404e-06  1.46125526e-02 -2.16908421e-07
 -4.81752676e-05 -5.86026932e-03 -1.51186318e-04 -5.09101018e-03
  1.74192065e+00  4.94892671e-02  1.24393750e+00  4.93431228e-02
  3.35924174e+00  7.25549669e-01  2.00439067e+00  6.93896314e-01
 -6.22215242e+00 -6.03494905e-02 -3.23214435e+00 -5.90879951e-02
 -2.38603783e-01  4.21727163e-01  3.42017869e-01 -3.71531880e+00
 -1.69041237e+00  7.89167696e+00  3.84725230e-01 -3.58931200e+00
  3.83359988e+00]
supnorm grad right now is: 9.549062814314128
Weights right now are: 
[ -2.62196839   3.40186577  -2.32681269   5.37855087   2.8765371
  -3.51055746   2.72574995  -6.09457925  -1.68094249  -6.7391099
  -4.24458219   6.2681731    3.07711408   7.49753854  13.72425196
   8.20147298  28.41711836 -29.67050469 -24.72874542   7.51489095
  37.33856066  -0.83985846  -0.28685218   4.49447145  -2.7659592
   2.22348467   2.90468739 -11.8712953    7.71933829  34.54988345
  54.7583768   18.60044926  16.02342576  32.56618165  60.97676727
  15.15971034 -30.97259527  -4.9845862   21.78426509   0.37162914
  57.32806422   7.12765323  72.33864705   6.80597906  -1.33921693
  62.93918668  -4.10137399  57.84800029  -2.14591084   2.86082086
  -0.22651096   2.50445051   1.77758113  84.49442097  -3.66569654
  80.90637024   8.40995772   4.59351852   0.73238161  -2.40471308
   8.52171933   1.76815732   0.97892657  -2.38388621  27.97123955]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2130.2943913447266
gradient value of function right now is: [ 5.69040660e+00  2.76436162e+00  4.82640804e-01  3.03362125e-01
 -5.69040660e+00 -2.76436162e+00 -4.82640804e-01 -3.03362125e-01
  3.80613756e+00  3.75606369e-01  3.16419577e-01  1.13875187e+00
 -2.18415812e+00 -6.26161489e-03 -4.11015840e-03 -1.45210086e-01
  1.49486856e-01  3.41616123e-02  3.18814079e-02  4.73343179e-02
 -1.31691041e-01 -3.18979138e-08 -2.53708911e-08  1.58056642e-05
  1.19314465e-01 -1.47336208e+00  4.30105796e+00 -5.13735561e-01
  2.67598117e-04  1.00586797e-13  7.07441260e-02  1.49710357e-14
  1.25638443e-04  4.40414550e-15  3.54419379e-02  5.99430846e-16
 -3.65286032e-02 -1.13352242e-04 -2.29691874e-01 -1.63627479e-05
 -9.99087168e-05 -3.45500279e-03 -1.53422071e-04 -2.41206849e-03
 -8.32795206e-01 -4.11690210e-02 -4.19353292e-01 -3.99128020e-02
 -1.97281619e+00 -3.08056305e+00 -9.40522893e-01 -2.95439673e+00
 -4.63025135e+00 -3.78190984e-02 -2.52655531e+00 -3.79256077e-02
 -3.06403643e-01  8.25735991e-01  2.78791119e+00 -9.25715179e+00
 -1.15936988e+00  6.93842920e+00  2.41065716e+00 -8.52610994e+00
 -1.42987956e+01]
supnorm grad right now is: 14.298795588304024
Weights right now are: 
[ -2.5850926    3.42140948  -2.30221743   5.71376323   2.83966131
  -3.53010117   2.7011547   -6.42979161  -1.55824658  -5.65805062
  -2.75685562   6.44689905   2.98930051  10.08901271  17.6173096
   8.01928591  30.09231046 -30.43388296 -25.70191143   7.66410932
  38.83409938  -0.83977872  -0.28673012   0.90150862  -3.67764984
   2.24875403   3.05289397 -11.99193253   7.56179749  34.54988335
  55.14405629  18.60044923  16.04732769  32.56618165  61.75721671
  15.15971034 -33.46891738  -7.83702102  20.99345296   0.49285056
  55.29554276   6.32514681  74.22042083   6.02849891  -1.57250425
  64.75549158  -4.74989788  59.52239627  -2.14864782   2.54640162
   0.11096059   2.12921128   1.76335942  86.9335562   -3.5072306
  83.43258613   9.13788593   4.20718426   0.76002239  -2.44299021
   8.46190968   1.58564961   0.99594324  -2.41485989  27.64682161]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2120.3865541368814
gradient value of function right now is: [ 1.43343957e+01  8.15037710e+00  1.09272100e+00  8.08328688e-01
 -1.43343957e+01 -8.15037710e+00 -1.09272100e+00 -8.08328688e-01
  8.02924943e+00  3.45893064e-01  2.80867708e-01  1.17844927e+00
 -6.57154040e+00 -1.00952775e-02 -6.00273658e-03 -2.60146359e-01
  3.08646873e-01  1.96459988e-02  1.81293452e-02  2.71708858e-02
 -2.79996354e-01 -1.48996119e-07 -1.21144660e-07  1.67725877e-04
  4.38650369e-01 -3.84318741e+00  8.02858338e+00 -1.21068736e+00
  2.68347422e-04  3.89765417e-13  7.77844392e-02  3.66092565e-14
  1.28873483e-04  1.26813660e-14  3.80738473e-02  1.07052000e-15
  3.72436080e-03  1.39657025e-03 -1.44338963e-01  1.71903527e-04
  1.79598470e-02  2.46694935e-01  2.08514590e-03  2.10819187e-01
 -1.56631726e+00 -5.94423523e-02 -3.86842345e-01 -5.59563153e-02
 -2.64465348e+00 -4.29221853e+00 -4.68501242e-01 -3.97409727e+00
 -1.15574333e+01 -9.54138807e-02 -7.95644330e+00 -9.75565842e-02
 -3.42737469e+00  5.08941960e+00  5.04727755e+00 -1.94964087e+01
 -3.16312379e+00  1.57784822e+01  4.24222141e+00 -1.83225813e+01
 -2.76213650e+01]
supnorm grad right now is: 27.621365033287283
Weights right now are: 
[-2.40073876e+00  3.22743681e+00 -2.99181735e+00  4.90653784e+00
  2.65530747e+00 -3.33612850e+00  3.39075462e+00 -5.62256623e+00
 -1.20798573e+00 -6.00668102e+00 -2.96856733e+00  6.09853135e+00
  2.85636809e+00  1.31126524e+01  2.19811563e+01  7.42416469e+00
  3.21318038e+01 -3.11203083e+01 -2.65597462e+01  7.64356144e+00
  3.99173959e+01 -8.36715922e-01 -2.84126868e-01 -6.09287281e+00
 -3.95141840e+00  2.02276580e+00  3.13326961e+00 -1.23327073e+01
  1.11539066e+01  3.45498833e+01  5.53953164e+01  1.86004492e+01
  1.91457920e+01  3.25661816e+01  6.25924063e+01  1.51597103e+01
 -3.19983750e+01 -1.23183966e+01  2.32719423e+01  6.57556949e+00
  5.55168599e+01  7.63212332e+00  7.78703307e+01  7.37269924e+00
 -2.01280606e+00  6.53766748e+01 -5.04692373e+00  5.99605868e+01
 -2.60161569e+00  2.80087568e+00  5.67975739e-02  2.36374655e+00
  1.74883665e+00  9.04670198e+01 -3.38982704e+00  8.70378024e+01
  8.67285741e+00  4.91885289e+00  9.41143677e-01 -2.53075935e+00
  9.06013371e+00  1.89716698e+00  1.15828651e+00 -2.50836325e+00
  2.76187376e+01]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2126.5810385782684
gradient value of function right now is: [ 1.45095736e+01  7.90278508e+00  6.32850450e-01  3.74494623e-01
 -1.45095736e+01 -7.90278508e+00 -6.32850450e-01 -3.74494623e-01
  9.83839742e+00  5.69638564e-01  4.63099784e-01  1.99173792e+00
 -7.53412679e+00 -1.69520394e-02 -9.93521812e-03 -4.32203455e-01
  2.28547577e-01  3.84079083e-02  3.55681629e-02  3.13100690e-02
 -1.34974887e-01 -6.29680372e-07 -5.26269808e-07  3.46244227e-02
  2.69573383e-01 -3.43428184e+00  5.61581894e+00 -8.25641524e-01
  6.06733409e-05  1.38725960e-13  1.25423680e-01  1.37143779e-14
  2.90343409e-05  3.42289009e-15  6.44396673e-02  3.07876676e-16
  3.49592756e-03  4.60307708e-01  1.31480775e-01  6.11712921e-02
  8.75285061e-03  8.51355351e-02  1.43580012e-03  7.53702977e-02
 -6.89974342e-01 -3.60821351e-02 -2.59097160e-01 -3.47389904e-02
 -2.64627047e+00 -6.16527134e+00 -1.33183350e+00 -5.89546464e+00
 -8.90790349e+00 -8.53638648e-02 -5.69270142e+00 -8.54503560e-02
 -1.95939196e+00  3.13243860e+00  5.50343741e+00 -1.62262156e+01
 -1.93957803e+00  1.05483669e+01  4.63592468e+00 -1.51681776e+01
 -2.44489524e+01]
supnorm grad right now is: 24.448952404920448
Weights right now are: 
[ -2.36512206   3.23758077  -3.00836073   5.10025938   2.61969077
  -3.34627246   3.407298    -5.81628777  -1.06853446  -6.1835785
  -3.23211688   6.90978385   2.44528161  11.31481225  20.5203038
   7.96573257  32.98437584 -32.00035423 -27.52146656   8.51302776
  41.81965682  -0.82737322  -0.27630674 -10.87233303  -2.64917578
   1.93549379   3.26878801 -12.331568     8.41530999  34.54988325
  56.92209449  18.60044921  16.96473489  32.56618165  64.56247581
  15.15971034 -30.44663388 -16.77376204  21.42413711  14.27827816
  54.83607227   9.00194134  82.3617082    8.72210318  -2.48688873
  68.29886387  -4.45244895  62.8489018   -2.80267092   2.54985231
   0.56560294   2.09362015   1.63826175  92.65729688  -3.2476202
  89.2446317    9.11896797   4.47834013   0.44467629  -2.57661062
   8.78039912   1.79457756   0.61750488  -2.5614778   27.79744482]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2126.668168469105
gradient value of function right now is: [-9.61058436e+00 -4.01920559e+00  5.01583127e-01  9.98757878e-01
  9.61058436e+00  4.01920559e+00 -5.01583127e-01 -9.98757878e-01
 -7.30263226e+00 -4.41808316e-01 -3.53767705e-01 -1.56527438e+00
  5.00967574e+00  1.10463329e-02  5.71037049e-03  1.72155566e-01
 -7.11832598e-02 -2.27083010e-02 -2.09905403e-02  1.20414545e-01
 -3.78095445e-02  2.86815447e-07  2.35419397e-07 -2.55056458e-01
 -1.64032467e-01  1.11232847e+01 -8.45498329e-01  2.26233639e+00
 -2.97430099e-05 -1.77407706e-13 -1.00668468e-01 -8.63558286e-15
 -1.35473445e-05 -4.69333402e-15 -4.74306411e-02 -1.92254536e-16
 -8.86167427e-04 -3.20503517e+00 -2.55004110e+00 -2.60582233e-01
 -1.13040067e-02 -7.81986423e-02 -1.72270289e-03 -7.40357998e-02
 -5.92805168e-01  2.32002038e-02 -9.20923413e-01  2.22346947e-02
  7.72243861e+00  4.74848978e+00  5.01626178e+00  4.62932552e+00
  2.49444414e+01  2.62129029e-01  1.58076397e+01  2.65021578e-01
  2.28319953e+00 -3.49546261e+00 -9.95529428e+00  4.58302549e+01
  5.48033201e+00 -2.85587105e+01 -9.05346090e+00  4.41267538e+01
  3.16465903e+01]
supnorm grad right now is: 45.83025493218251
Weights right now are: 
[ -2.58591253   3.25088164  -3.06617753   4.56497693   2.84048124
  -3.35957333   3.4651148   -5.28100531  -1.61788819  -6.34312019
  -3.2339583    6.62182651   2.93820712  13.80226366  23.47111273
   8.55969501  35.33439004 -33.78198666 -29.41116058   9.19272407
  42.26601973  -0.81769437  -0.26848091 -10.1977501   -4.41870688
   2.06980274   3.38823417 -11.90895645   5.41263947  34.54988322
  56.68474574  18.60044921  14.28786689  32.56618164  64.70706811
  15.15971034 -28.24783563 -16.57263883  21.23957969  19.46561195
  48.9426247   10.64457245  81.78994491  10.28681029  -2.75646945
  68.7215002   -4.29439618  63.41240239  -2.35239654   2.83425566
   0.64154474   2.42325019   1.68464917  95.09519914  -3.34948791
  91.63269313   9.05738282   4.46964816   0.34323235  -2.46540499
   8.67621906   1.78392058   0.43168614  -2.44928753  28.07373619]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2130.1825093761627
gradient value of function right now is: [ 3.68486029e+00  2.04796839e+00 -2.34907652e-01 -3.32263193e-01
 -3.68486029e+00 -2.04796839e+00  2.34907652e-01  3.32263193e-01
  2.02729070e+00  3.82272857e-02  2.26609679e-02  3.04170557e-01
 -1.65199707e+00 -4.68862961e-03 -2.67400689e-03 -4.58333801e-02
  5.10968109e-02 -2.70792954e-04 -2.45618287e-04 -2.05443471e-02
 -2.17532448e-02 -5.92278013e-09 -3.51630572e-09  3.02639986e-02
  1.60294138e-01 -4.57083164e+00  6.71725085e-01 -1.05028195e+00
  1.26471514e-04  9.03724032e-13  2.07352538e-02  7.37759064e-14
  5.65374330e-05  1.70702596e-14  9.17923120e-03  1.12381899e-15
  1.90981165e-03  3.73352241e-01  2.84488896e-01  3.29564812e-02
  8.88123131e-03  4.21225971e-02  1.60472954e-03  3.84318041e-02
 -2.65144234e-02 -1.58334694e-02  1.25426292e-01 -1.53339321e-02
 -1.37241520e+00 -8.08304362e-01 -5.59092789e-01 -7.64465553e-01
 -1.03996312e+01 -9.96804203e-02 -6.88239507e+00 -1.02091700e-01
 -1.53241706e+00  2.68661245e+00  2.98893836e+00 -1.83259652e+01
 -2.60109726e+00  1.30697476e+01  2.74541107e+00 -1.77602858e+01
 -1.22405624e+01]
supnorm grad right now is: 18.32596517267436
Weights right now are: 
[ -2.55253909   3.45740593  -3.00675509   4.60156571   2.8071078
  -3.56609762   3.40569236  -5.3175941   -1.70594736  -6.67157783
  -3.23630604   6.19841871   2.79387468  16.04413764  26.22309103
   7.65399229  35.9443748  -35.5733515  -31.30608798   9.58064271
  44.0384339   -0.81464452  -0.26605747  -8.77709116  -3.34828179
   2.07482845   3.54850779 -12.28540123   3.05170994  34.54988321
  55.45252215  18.6004492   12.34652133  32.56618164  63.77224148
  15.15971034 -28.12563604 -16.33715262  20.89721127  23.12191696
  48.48998784   9.76307632  82.71704974   9.37466587  -2.70746011
  70.44697721  -3.74665201  65.23100107  -2.67612755   3.38407579
   0.28792124   2.96058032   1.60812876  97.73265382  -3.46721718
  94.23818115   9.15201873   4.15252184   0.29515487  -2.58264286
   8.63430768   1.88206546   0.43227103  -2.55502001  27.79005969]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2133.213898016888
gradient value of function right now is: [ 8.55174163e-02  9.47356278e-02  3.18982623e-02  2.05397976e-02
 -8.55174163e-02 -9.47356278e-02 -3.18982623e-02 -2.05397976e-02
 -6.84544999e-02 -6.22734233e-02 -4.94473561e-02 -1.64613372e-01
 -4.56994776e-02  2.09361841e-04  1.79344635e-04  2.53183267e-02
 -1.35538489e-02 -2.85237850e-03 -2.59152919e-03 -1.16635758e-02
  1.63212642e-02  3.56331117e-09  2.80841831e-09  1.34892138e-02
  6.78460813e-03 -3.89144510e-01 -2.72031861e-01 -7.61470541e-02
  1.60427683e-05  7.71029553e-14 -1.16344703e-02  1.31065727e-14
  7.50191530e-06  5.05040658e-16 -4.84319698e-03  9.50985564e-17
 -3.71452814e-05  1.70833512e-01  1.51802531e-01  2.63120582e-02
  1.40705959e-03  1.21518250e-03  4.50015831e-05  1.07020612e-03
 -3.53465816e-01 -1.47463795e-02 -2.82705197e-01 -1.46447308e-02
 -3.80888326e-01  4.10705296e-01 -3.60765695e-01  4.02471314e-01
 -1.45085158e+00 -2.06215527e-02 -1.02690768e+00 -2.06427172e-02
 -1.58993170e-03  4.84643809e-02  1.18020287e-01 -4.52375521e+00
 -2.32158011e-01  2.04118190e+00  1.27109551e-01 -4.29941307e+00
  6.37656020e-02]
supnorm grad right now is: 4.523755209144457
Weights right now are: 
[ -2.65834775   3.25179549  -2.80658626   4.39682319   2.91291646
  -3.36048718   3.20552353  -5.11285157  -1.61250076  -6.93135874
  -3.2181521    6.14497158   2.44608162  15.99565019  26.64741905
   6.67428506  37.88820294 -36.65331795 -32.47817671  10.6076591
  44.73012819  -0.81281287  -0.26474271  -6.55860344  -5.00374579
   1.98508166   3.5678329  -11.93780057   1.23853814  34.54988315
  55.30931491  18.60044919  10.9670701   32.56618164  64.75787498
  15.15971034 -31.19837787 -16.40365258  20.26833018  24.53525997
  46.24143775   9.54515812  84.43023389   9.14012716  -3.27796988
  70.16764498  -4.15745862  64.96398133  -2.46965599   3.01372472
   0.46065914   2.67025797   1.7154054  100.07190063  -3.76491727
  96.53146235   9.07421545   4.10792929   0.29868901  -2.54216889
   8.54390709   1.75040162   0.41681432  -2.53476317  27.94931916]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2132.4646958148433
gradient value of function right now is: [-2.45357254e+00 -7.84793119e-01  3.08685723e-01  5.19038538e-01
  2.45357254e+00  7.84793119e-01 -3.08685723e-01 -5.19038538e-01
 -2.46345813e+00 -1.35568597e-01 -9.90305010e-02 -6.03889844e-01
  1.63756095e+00  6.31032810e-03  2.88795379e-03  8.52643120e-02
  1.40447812e-02 -3.97531196e-03 -3.62704605e-03  7.61593755e-02
 -4.94642900e-02  2.33014563e-09  1.34433614e-09 -1.69514309e-01
 -1.55138143e-01  3.38354138e+00  6.19972690e-01  6.54547788e-01
 -8.72875025e-05 -1.89643685e-12 -4.68630826e-02 -9.55578545e-14
 -3.66351937e-05 -1.31690561e-14 -2.02785653e-02 -4.89562406e-16
  2.71516430e-03 -1.12825645e+00 -8.72754332e-01 -9.59316087e-02
 -9.74876702e-03 -5.29150851e-02 -1.76686049e-03 -4.74720544e-02
 -5.85794235e-01 -8.76434402e-03 -6.97853564e-01 -9.70160193e-03
  1.61648683e+00  1.59321776e+00  8.14616930e-01  1.50826988e+00
  9.03592707e+00  7.94234308e-02  5.14847868e+00  7.98574250e-02
  2.29798091e+00 -4.23531867e+00 -2.76635826e+00  1.29967883e+01
  2.89090866e+00 -1.42449878e+01 -2.50559556e+00  1.24572967e+01
  1.14480684e+01]
supnorm grad right now is: 14.244987809622282
Weights right now are: 
[ -2.75499966   3.33918009  -2.74079195   4.13518366   3.00956838
  -3.44787178   3.13972922  -4.85121204  -1.67382025  -7.56450472
  -3.8668231    6.28731953   2.58550499  17.88549433  29.22838692
   6.59316556  38.78646384 -38.08378577 -33.96631667  11.8918219
  45.80709418  -0.81261008  -0.26460353  -2.52782314  -5.02077783
   1.72734246   3.94336647 -12.39866838  -3.7803259   34.5498831
  54.97080263  18.60044918   7.60765143  32.56618164  64.34575374
  15.15971034 -32.17150194 -16.52382519  19.72148     24.58051138
  43.56892612   9.88329964  87.12998922   9.52988747  -3.22885559
  69.98834667  -3.50436588  64.84873292  -2.27362622   3.15845585
   0.45622671   2.7916646    1.7206726  102.63699318  -3.88537393
  99.07168489   8.97138915   3.83534692   0.45435861  -2.53940431
   8.57811115   1.60754406   0.60908493  -2.52508517  27.99553363]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2131.7775446491273
gradient value of function right now is: [ 3.23266401e+00  1.60277797e+00  2.44493208e-01  1.76165757e-01
 -3.23266401e+00 -1.60277797e+00 -2.44493208e-01 -1.76165757e-01
  2.57300644e+00  2.60893308e-01  2.00090294e-01  9.07740974e-01
 -1.12676650e+00 -3.99449699e-03 -1.82554949e-03 -1.18930789e-01
  3.63515372e-02  6.36403849e-03  5.69465823e-03  6.01246614e-03
 -2.65674081e-02 -1.13505675e-09 -6.51572474e-10  3.38927310e-02
  9.04256595e-02 -1.76983155e+00  5.34844385e-01 -5.26803581e-01
  1.99954257e-05  9.27248789e-13  5.54259968e-02  4.70342040e-14
  7.31308518e-06  5.30128327e-15  1.89333731e-02  2.39528412e-16
  1.11333793e-03  2.53166047e-02 -1.63447809e-01  1.25562529e-02
  5.65419753e-03  3.42544599e-02  1.41009633e-03  3.00914679e-02
 -3.84068739e-01 -1.77467064e-02 -2.60726235e-01 -1.70443842e-02
 -2.49604361e-01 -1.57094523e+00 -1.95522738e-01 -1.50006386e+00
 -4.76164241e+00 -2.54964361e-02 -2.20606356e+00 -2.40960619e-02
 -5.81052163e-01  8.71152908e-01  2.25437475e+00 -6.78011517e+00
 -2.38419946e+00  9.87647942e+00  1.97166532e+00 -6.07317447e+00
 -1.01249502e+01]
supnorm grad right now is: 10.124950217076837
Weights right now are: 
[ -2.74203146   3.08887163  -2.41860904   3.83086349   2.99660017
  -3.19756332   2.81754631  -4.54689187  -1.40722123  -6.13669562
  -2.19247318   6.64982642   2.49700146  20.03745842  31.95286373
   7.7999343   40.09611753 -42.50855647 -38.50471665  12.75041839
  46.27636816  -0.81256189  -0.26457317   0.68951973  -4.18100846
   1.79215783   4.13675808 -12.16299051  -6.92804986  34.54988322
  55.27523803  18.60044917   5.75313766  32.56618164  64.84587202
  15.15971034 -32.65914815 -16.71173622  19.18578841  27.01185562
  41.48078757  10.23564575  90.87888138   9.96193854  -3.45538004
  70.01426374  -3.83395588  64.76210398  -2.56474462   2.7240936
   0.7456966    2.3464603    1.65701991 105.5078328   -3.87785415
 101.93892109   9.03223579   3.93219991   0.29420802  -2.46020639
   8.37218004   1.92165458   0.46077382  -2.45757123  27.75350976]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2130.6296181231114
gradient value of function right now is: [ 1.08867027e+00  2.43424642e+00  1.98357331e+00  2.09419700e+00
 -1.08867027e+00 -2.43424642e+00 -1.98357331e+00 -2.09419700e+00
 -2.08989576e+00 -1.37674692e-01 -9.40527340e-02 -6.46008731e-01
  9.37802721e-01  6.43279739e-03  2.70351875e-03  5.44869839e-02
  1.32962522e-01 -3.37145315e-03 -2.91728132e-03  9.03762670e-02
 -1.86652091e-01  7.10931946e-10  2.92627081e-10 -2.80830845e-01
 -9.45868621e-02  5.07379667e+00  3.51183075e+00  1.18983216e+00
 -8.31950109e-05 -1.78573353e-12 -5.03909887e-02 -2.63768380e-14
 -3.06006506e-05 -7.14447593e-15 -1.85535347e-02 -6.67398557e-17
 -2.08331625e-03 -7.64944048e-01 -5.97574706e-01 -6.47368281e-02
 -7.22469712e-03 -5.33007260e-02 -1.27525480e-03 -4.62731579e-02
 -1.07031864e+00 -2.83089799e-02 -4.96044374e-01 -2.79506024e-02
 -4.85483207e-01  1.62856698e+00 -1.82715997e-01  1.51183892e+00
  1.17655641e+01  6.69622686e-02  5.07585785e+00  6.61397430e-02
 -2.84834591e-02  1.11217538e+00 -3.19382835e+00  1.06234612e+01
  3.82857350e+00 -1.83060054e+01 -2.83487779e+00  1.01519843e+01
  9.65242083e+00]
supnorm grad right now is: 18.306005391158198
Weights right now are: 
[ -2.8725343    3.2114699   -2.50085117   3.63569854   3.12710301
  -3.32016159   2.89978843  -4.35172692  -1.77298312  -7.14356395
  -2.94957905   5.93736467   2.53765304  18.73629433  31.63875091
   7.61871785  39.98324136 -46.53307036 -42.65576605  12.61229791
  47.89390264  -0.81253548  -0.26453981   0.23743208  -5.38853468
   2.39662577   4.2645284  -12.45247964  -8.91963391  34.54988318
  54.40609533  18.60044916   5.02272774  32.56618164  64.76051762
  15.15971034 -32.00963189 -16.90411101  19.09404564  28.56115237
  38.07013416   9.78122458  91.49845314   9.51191709  -3.9261259
  68.56415141  -3.65452182  63.3219047   -2.64034245   3.10495622
   0.96113038   2.69814818   1.74892425 108.24068627  -3.90202353
 104.66211653   8.62446012   3.95157587   0.2918952   -2.60709662
   8.55638532   1.59656088   0.50056546  -2.57991164  27.98703544]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -2132.396408374694
gradient value of function right now is: [ 9.08703028e-01  5.55014214e-01  2.76322554e-01  1.64829597e-01
 -9.08703028e-01 -5.55014214e-01 -2.76322554e-01 -1.64829597e-01
  5.46431767e-01  1.02327450e-03 -4.23794606e-03  1.20812328e-01
 -1.76203733e-01 -2.30166076e-03 -8.96364049e-04  6.51160996e-03
  7.54612326e-03 -9.94610480e-04 -8.68714812e-04 -2.35444789e-02
 -5.78466371e-03 -4.47403249e-11 -1.95003179e-11  6.64811822e-02
  7.70096178e-02 -2.28986838e+00 -4.73474566e-01 -6.44173223e-01
  5.39928990e-05  3.50526299e-12  8.44318263e-03  1.41934828e-13
  1.78395896e-05  3.76143605e-15  2.49707917e-03  1.04939000e-16
 -5.78745751e-04  1.83330484e-01  8.99837372e-02  2.87264348e-02
  5.52764314e-03  1.77745840e-02  9.20032542e-04  1.33926487e-02
 -3.86256896e-01 -2.13021932e-02 -2.22114868e-01 -1.99085744e-02
 -1.77497543e-01 -2.86552359e-02 -9.47949763e-02  3.48582776e-04
 -6.49329791e+00 -5.38206824e-02 -3.85280771e+00 -5.26995936e-02
 -3.41426927e-01  4.85884265e-01  1.67668627e+00 -1.21391105e+01
 -1.93921527e+00  9.94399129e+00  1.47338533e+00 -1.12128017e+01
 -5.72515208e+00]
supnorm grad right now is: 12.139110510895557
Weights right now are: 
[ -2.78709312   3.21842031  -2.08878277   3.63877672   3.04166183
  -3.327112     2.48772004  -4.3548051   -1.54017126  -7.49161974
  -3.25324968   6.41370486   2.66680507  17.92883296  30.81507195
   8.01756488  41.02951337 -45.49734312 -41.69325593  14.19338992
  49.70460706  -0.81253216  -0.26453393   0.35457478  -3.68011659
   2.15238324   4.22103287 -12.71271595 -13.13210653  34.54988377
  55.03289755  18.60044916   3.15396124  32.56618164  66.72285548
  15.15971034 -33.51743853 -16.81612465  18.70789661  29.26231693
  35.45012222  10.01482296  91.90332039   9.76007214  -3.22895753
  69.45454712  -3.16320664  63.75794806  -2.68670452   3.20998258
   0.74851155   2.74378726   1.64106553 110.42369808  -3.86775059
 106.96436503   8.70757168   3.76988132   0.23794103  -2.58662898
   8.38483593   1.77089115   0.60717846  -2.55868903  27.81463583]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -2127.083818147869
gradient value of function right now is: [-1.01665917e+01 -7.63711169e+00 -2.41857865e+00 -2.31613859e+00
  1.01665917e+01  7.63711169e+00  2.41857865e+00  2.31613859e+00
 -4.01359192e+00 -1.43186477e-01 -9.61805721e-02 -9.36684271e-01
  2.48595778e+00  4.49052888e-03  1.75191783e-03  2.71156468e-01
 -2.03346319e-01 -2.93179675e-03 -2.50283674e-03 -4.29493726e-02
  2.47079219e-01  3.52125807e-10  1.20934236e-10  1.54167360e-01
 -1.62833654e-01 -5.01483410e-01 -6.64851703e+00  6.49988814e-02
 -9.38174239e-05 -2.95054114e-11 -5.20251954e-02 -5.54464773e-13
 -3.00720951e-05 -1.86155000e-14 -1.84693447e-02 -2.18248844e-16
  1.39533402e-02  3.95279956e-01  6.49074891e-01 -1.25401663e-03
 -1.27469091e-02 -4.70109568e-02 -2.05058092e-03 -3.80079387e-02
  1.71628789e+00  5.81447145e-02  6.28779562e-01  5.44803226e-02
  3.09168296e+00  1.98807113e+00  1.69680203e+00  1.82576453e+00
  6.31265494e-01  6.22954719e-04  6.36884946e-01  1.87615039e-03
  1.96339063e+00 -4.04829868e+00 -2.35954826e+00  6.59525581e+00
  5.41854027e-01 -2.15712812e+00 -1.82539111e+00  5.65204898e+00
  2.00313674e+01]
supnorm grad right now is: 20.031367370601547
Weights right now are: 
[ -3.03503317   2.82596382  -2.15503359   3.22942487   3.28960188
  -2.93465551   2.55397086  -3.94545325  -1.58943752  -7.86042059
  -3.64051924   6.77940943   2.61298248  19.7757217   32.88985733
   8.00029741  42.16503225 -49.90843295 -46.17476573  12.99434908
  50.03007491  -0.8125377   -0.26452962  -0.15158982  -5.5349455
   2.4545325    4.37184    -13.25237258 -20.30205436  34.54988377
  54.25250722  18.60044911  -0.6322349   32.56618164  65.30892012
  15.15971034 -31.6024737  -16.71288613  18.98794656  29.03787633
  30.9947561    9.37886269  91.30384329   9.1435242   -3.40668629
  67.3423718   -3.02716843  61.52512079  -2.44624332   3.17837255
   0.7931951    2.56427213   1.65527293 113.43088849  -3.86873821
 109.92308628   8.98488571   4.00347138   0.24377991  -2.61829194
   8.65725863   1.72082856   0.57382181  -2.58512154  28.02728508]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2129.255065313109
gradient value of function right now is: [-7.98473064e+00 -5.99651021e+00 -1.77409150e+00 -1.97022469e+00
  7.98473064e+00  5.99651021e+00  1.77409150e+00  1.97022469e+00
 -2.86076021e+00 -1.00168305e-01 -6.96388406e-02 -6.52500522e-01
  2.12961315e+00  2.93097484e-03  1.08530529e-03  2.35940772e-01
 -1.96344731e-01 -4.41405979e-03 -3.75144107e-03 -1.31333541e-02
  2.16682772e-01  1.16837131e-10  3.78931523e-11  7.47075928e-01
 -6.67835970e-02 -1.73803566e+00 -5.67239107e+00 -2.02116852e-01
 -2.29724978e-05 -7.73683370e-12 -3.34190918e-02 -3.87340939e-14
 -6.86493797e-06 -6.95355972e-15 -1.11224726e-02 -2.17080292e-17
  1.94181176e-04 -2.63051764e-02  1.27395813e-01 -7.36568892e-03
 -5.61670719e-03 -3.62308233e-02 -8.40272510e-04 -2.03223907e-02
  9.93769874e-01  4.35030707e-02  4.82642250e-01  3.75428476e-02
  3.37791476e+00  1.66744050e+00  1.94769267e+00  1.35344187e+00
 -1.82785206e+00 -1.29785801e-02 -1.04031408e+00 -1.25592258e-02
  7.39603733e-01 -1.45661271e+00 -1.62272786e+00  1.89015856e+00
 -3.85458434e-01  2.55771891e+00 -1.02959277e+00  9.14223754e-01
  1.28716501e+01]
supnorm grad right now is: 12.871650147828891
Weights right now are: 
[-2.87251026e+00  3.10801935e+00 -2.36512386e+00  2.92298203e+00
  3.12707897e+00 -3.21671104e+00  2.76406112e+00 -3.63901041e+00
 -1.76215495e+00 -7.06226221e+00 -2.27736165e+00  6.82017614e+00
  2.72468413e+00  2.16928911e+01  3.64499267e+01  7.57014827e+00
  4.42046534e+01 -5.32296282e+01 -4.96085042e+01  1.39144812e+01
  5.07803666e+01 -8.12536558e-01 -2.64524498e-01  4.32748432e-01
 -4.80103333e+00  2.09274985e+00  4.08319525e+00 -1.30560673e+01
 -2.18192155e+01  3.45498900e+01  5.34154305e+01  1.86004493e+01
 -1.29741251e+00  3.25661816e+01  6.45674721e+01  1.51597103e+01
 -3.00400124e+01 -1.70402146e+01  1.88967627e+01  3.11810602e+01
  2.97468122e+01  9.85761695e+00  9.33445556e+01  9.58924201e+00
 -3.57782667e+00  6.78790430e+01 -3.06611113e+00  6.17060488e+01
 -2.47611915e+00  2.97907926e+00  1.05157535e+00  2.29810349e+00
  1.61587619e+00  1.16017740e+02 -3.92614105e+00  1.12490947e+02
  8.64667531e+00  4.12165070e+00  4.15173951e-02 -2.58962608e+00
  8.74726799e+00  1.71645205e+00  8.44236409e-01 -2.55607919e+00
  2.80595795e+01]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2131.3892511195886
gradient value of function right now is: [-7.11636963e+00 -5.46204026e+00 -2.30304895e+00 -2.63654970e+00
  7.11636963e+00  5.46204026e+00  2.30304895e+00  2.63654970e+00
 -2.52390977e+00 -1.16893217e-01 -7.91838612e-02 -8.95977635e-01
  1.67121974e+00  3.60497716e-03  1.33128394e-03  4.39303058e-01
 -1.32104251e-01 -2.93305775e-03 -2.48249223e-03 -1.21532047e-01
  1.70000598e-01  1.01348690e-10  2.95313209e-11  3.45313224e-01
 -9.04367497e-02 -9.40207621e-01 -4.60055122e+00  1.85376350e-01
 -4.17235393e-05 -7.11392636e-11 -4.51268786e-02 -1.00964802e-12
 -1.27689287e-05 -5.05023746e-14 -1.55667235e-02 -3.80485087e-16
  5.76021691e-04  1.12190093e+00  1.28990557e+00  3.15625500e-02
 -6.19723901e-03 -3.38494591e-02 -1.15453768e-03 -1.94172856e-02
  2.89767296e+00  7.82844121e-02  1.36440146e+00  6.53190194e-02
 -2.12853619e-01  1.56047791e+00 -4.29404582e-01  1.22288482e+00
  6.05894683e-01 -6.20747364e-03  1.23179366e+00 -1.16267506e-03
  1.63448175e+00 -3.41003112e+00 -1.76849941e+00  6.73074695e+00
  7.58758026e-01 -4.69788217e+00 -1.35134079e+00  5.61610447e+00
  1.33063172e+01]
supnorm grad right now is: 13.306317246642104
Weights right now are: 
[-2.87604198e+00  3.21792289e+00 -2.13077111e+00  3.07091577e+00
  3.13061069e+00 -3.32661459e+00  2.52970838e+00 -3.78694415e+00
 -1.69606921e+00 -8.01538005e+00 -3.31779382e+00  6.84547195e+00
  2.54462449e+00  2.34001222e+01  3.95102339e+01  7.61673898e+00
  4.47129371e+01 -5.42990248e+01 -5.07048430e+01  1.40644808e+01
  5.26689936e+01 -8.12542864e-01 -2.64523868e-01 -2.14084552e-02
 -4.43311301e+00  1.92617444e+00  4.27355298e+00 -1.28742230e+01
 -2.18983094e+01  3.45498820e+01  5.29975968e+01  1.86004492e+01
 -1.09964281e+00  3.25661816e+01  6.39479106e+01  1.51597103e+01
 -2.87676770e+01 -1.69980766e+01  1.87644338e+01  3.28378161e+01
  3.15177497e+01  1.09843572e+01  9.76770364e+01  1.10017490e+01
 -3.14711038e+00  6.73234785e+01 -2.90117737e+00  6.01642130e+01
 -2.67171393e+00  3.24570429e+00  4.91781284e-01  2.82457354e+00
  1.62477312e+00  1.18016730e+02 -3.99208820e+00  1.14643077e+02
  8.53291789e+00  3.88205675e+00  4.36926729e-01 -2.55557560e+00
  8.28038126e+00  1.50450920e+00  1.16813930e+00 -2.55283633e+00
  2.79995381e+01]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2132.861179720358
gradient value of function right now is: [-2.08869718e+00 -1.54475409e+00 -3.34421730e-01 -1.75302333e-01
  2.08869718e+00  1.54475409e+00  3.34421730e-01  1.75302333e-01
 -9.28249118e-01 -7.04296095e-03 -4.34560105e-03 -1.08762587e-01
  7.88257259e-01  1.26129406e-03  3.73436559e-04  3.84794209e-02
 -4.69717875e-02 -2.90490530e-03 -2.44399516e-03  2.71856194e-02
  4.92024521e-02  3.85381997e-11  5.74103686e-12 -5.76598022e-02
 -4.21665478e-02  8.11836874e-01 -1.17868451e+00  2.49713372e-01
 -4.89575015e-06 -2.30463199e-11 -7.92883975e-03 -6.97026614e-14
 -1.28889112e-06 -6.63328382e-15 -3.77894739e-03 -2.38953153e-18
  5.37314238e-04 -2.89092898e-01 -2.53676199e-01 -9.24367880e-03
 -2.08955316e-03 -1.86099206e-02 -5.12782541e-04 -1.36714215e-02
 -5.11552892e-01 -4.25140228e-03 -1.79027430e-01 -3.42342792e-03
  1.59117678e+00  8.04643138e-01  8.72131845e-01  7.12532015e-01
  2.21537457e+00  1.60702077e-03  3.78232425e-01 -6.46077045e-06
 -4.58638766e-02  2.47102835e-01 -8.67585954e-01  4.11198212e-01
  1.07209795e+00 -4.00861574e+00 -6.01875528e-01  4.75485148e-02
  4.52980056e+00]
supnorm grad right now is: 4.529800559490745
Weights right now are: 
[ -2.89578016   3.17496797  -2.10441823   2.89627351   3.15034887
  -3.28365966   2.5033555   -3.61230189  -1.55816915  -7.17402987
  -1.85129214   6.99925272   2.53007374  23.31203686  40.92488544
   7.93903546  46.5108952  -56.55117418 -53.00574994  13.98004663
  53.75247062  -0.81254588  -0.26452272  -0.2379107   -4.84997805
   2.29813598   4.38061336 -12.64784846 -25.14369461  34.54988562
  52.82975746  18.60044927  -3.17275716  32.56618165  64.60065586
  15.15971034 -30.51562074 -16.49932576  18.58862029  34.39983458
  31.05950143   9.76515014  99.66992554   9.83844131  -3.351088
  67.88483135  -3.33925517  60.23534552  -2.27057178   2.74574316
   0.92385317   2.04137738   1.96729984 119.94264848  -4.14462453
 116.70467243   8.62371447   4.21713543   0.31940925  -2.66352735
   8.46432996   1.58974231   0.7461863   -2.64625597  28.06469194]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2129.954569124424
gradient value of function right now is: [ 9.83465779e+00  6.28687654e+00  6.68595383e-01  4.35742763e-01
 -9.83465779e+00 -6.28687654e+00 -6.68595383e-01 -4.35742763e-01
  5.56759233e+00  2.24954822e-01  1.42560841e-01  1.07633099e+00
 -3.95957447e+00 -5.68720480e-03 -1.83062224e-03 -2.33562111e-01
  8.85181358e-02  8.32913653e-03  7.12973047e-03 -1.09655605e-02
 -8.19987002e-02 -8.35082519e-11 -1.68348130e-11  6.13913363e-02
  2.00187102e-01 -1.70586583e+00  4.10136322e+00 -4.59299685e-01
  4.37410561e-05  8.26132576e-11  8.99121646e-02  7.50101774e-13
  8.73876711e-06  1.31129833e-14  2.77450195e-02  1.09785830e-16
  3.76545383e-03  2.60252582e-01 -5.85235901e-03  3.75956651e-02
  1.85774572e-02  1.07863659e-01  2.37261533e-03  7.31194803e-02
 -6.49579367e-01 -2.93374409e-02 -2.13290401e-01 -2.60640176e-02
 -2.11331670e+00 -4.54186547e+00 -8.82175610e-01 -3.85137298e+00
 -5.89110679e+00 -4.66052526e-02 -3.63639221e+00 -4.93437389e-02
 -2.25108187e+00  3.79325692e+00  4.39784996e+00 -1.29027709e+01
 -1.90660437e+00  9.97434389e+00  3.01346600e+00 -1.20055641e+01
 -2.00445302e+01]
supnorm grad right now is: 20.044530180332774
Weights right now are: 
[ -2.81913698   3.27690293  -1.92562279   2.99273307   3.07370569
  -3.38559462   2.32456006  -3.70876146  -1.37702446  -8.96352409
  -3.65635247   6.77707626   2.4309684   23.23614957  42.91506185
   8.08691032  49.20103398 -53.76374406 -50.37266898  14.98302678
  55.29416721  -0.81254907  -0.26452235  -0.39332223  -4.50181336
   2.07375439   4.3020315  -13.27500104 -26.90574723  34.54990247
  52.6060115   18.60044853  -3.44291381  32.56618165  65.89114025
  15.15971034 -30.46842209 -16.20678617  18.48663939  34.65717244
  32.83173309   9.10766364 102.479291     9.13766557  -3.07983259
  66.7433331   -3.12305634  58.7451366   -2.40231595   2.65000486
   0.86906656   1.70727462   1.77531177 122.70647429  -4.00052873
 119.51238066   8.35965993   3.94522726   0.26611322  -2.58117447
   8.52898228   1.70282263   0.84240923  -2.4951676   27.6204131 ]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2116.433655601036
gradient value of function right now is: [ 1.42501202e+01  1.19309502e+01  3.82176515e+00  3.52142803e+00
 -1.42501202e+01 -1.19309502e+01 -3.82176515e+00 -3.52142803e+00
  3.07757121e+00  1.89181309e-02  1.38366586e-02  1.53290323e-01
 -3.36861981e+00 -1.91832539e-04 -3.76283257e-05 -1.13168291e-01
  2.36740721e-01  1.67274099e-03  1.43366419e-03  1.47589830e-02
 -4.08768998e-01 -3.07730746e-11 -1.83138989e-12 -3.40080643e-02
  1.24132351e-01  4.80384343e+00  1.47583113e+01  8.51316234e-01
  1.95392920e-05  1.31898165e-10  5.82359694e-03  1.68176513e-12
  2.27003297e-06  1.42382746e-14  1.88681134e-03  1.62435244e-16
  3.18595901e-03 -7.85438109e-02 -6.93420154e-02  3.25228508e-03
  1.89925864e-02  7.64166463e-02  1.61455508e-03  5.23062840e-02
 -1.47784357e+00 -5.25253111e-02 -4.53042206e-01 -4.37169320e-02
 -6.40403698e+00 -2.43838487e+00 -2.43633554e+00 -2.04288835e+00
  7.77217261e+00  2.31440133e-02  2.07874177e+00  1.68780898e-02
 -4.17397787e+00  7.62141303e+00  1.28701980e+00 -4.88686004e-01
  3.00374448e+00 -1.30748652e+01  5.06058088e-01 -1.07909236e-02
 -1.59434375e+01]
supnorm grad right now is: 15.943437493196939
Weights right now are: 
[ -2.80682902   3.41120193  -1.6878933    3.34195378   3.06139773
  -3.51989362   2.08683056  -4.05798216  -1.79542874  -8.40864575
  -2.74987686   6.52686891   2.4829239   26.333987    46.75704218
   8.29514887  50.80905432 -56.19884095 -52.85340006  15.23813101
  56.64247915  -0.81255094  -0.26452202  -0.15090047  -4.78233218
   2.15373199   4.36776473 -13.08340655 -32.4826223   34.54992629
  51.71495331  18.60044748  -8.60498453  32.56618165  65.03637383
  15.15971034 -29.24076728 -16.34908999  18.65166031  35.68490492
  31.74744937   8.46677125 104.49986646   8.34881419  -3.07549896
  66.91090035  -3.10388034  58.35310755  -2.79289454   2.72006404
   0.41203277   1.8637036    2.00547892 124.59940381  -4.12743276
 121.44591767   8.14628701   4.13860303   0.3973097   -2.68565615
   8.67077151   1.61991471   0.94139211  -2.66169458  27.93658242]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2123.541904374528
gradient value of function right now is: [-4.59307906e+00 -5.17538779e+00 -1.78440599e+00 -2.25010006e+00
  4.59307906e+00  5.17538779e+00  1.78440599e+00  2.25010006e+00
  1.36990487e+00  2.58136813e-01  1.65973957e-01  6.15299285e-01
  3.62987475e-01 -2.60352352e-03 -7.94913258e-04  2.25552838e-01
 -1.70421977e-01  4.05326463e-03  3.37031658e-03 -1.12751839e-01
  2.33160998e-01 -7.21079902e-12 -2.69144968e-12  4.39909642e-01
  5.56461379e-02 -6.13279902e+00 -6.01892064e+00 -9.06414470e-01
  1.85210005e-04  1.47690507e-09  8.00283494e-02  1.49199594e-11
  3.86654633e-05  1.23123329e-14  1.95072179e-02  1.24080451e-16
 -2.13524396e-02  1.58397745e+00  1.08938591e+00  1.34474232e-01
 -3.25380790e-04 -1.33748349e-02 -1.20792975e-04 -8.87870016e-03
  5.20428107e-01  7.49053367e-03  3.42639930e-01  7.97263820e-03
  1.33006548e-01 -1.08979494e+00 -1.26697411e-01 -9.98548243e-01
 -1.37404347e+01 -1.22843045e-01 -8.28574739e+00 -1.16540623e-01
  3.27962626e-01 -1.37203586e+00  3.72788571e+00 -2.49648848e+01
 -3.19892620e+00  1.81190193e+01  3.24816044e+00 -2.29981451e+01
 -8.12200171e+00]
supnorm grad right now is: 24.964884802235915
Weights right now are: 
[-2.93990391e+00  2.90674567e+00 -2.29788529e+00  2.85217563e+00
  3.19447262e+00 -3.01543736e+00  2.69682256e+00 -3.56820402e+00
 -1.23817886e+00 -8.04581322e+00 -2.58089684e+00  7.36582812e+00
  2.76880279e+00  2.52224255e+01  4.63067947e+01  9.24894493e+00
  5.23002024e+01 -6.01678482e+01 -5.69392299e+01  1.56577432e+01
  5.82197387e+01 -8.12551264e-01 -2.64521933e-01  7.87025834e-02
 -4.67402423e+00  1.69070228e+00  4.13357514e+00 -1.32265394e+01
 -3.53717797e+01  3.45496397e+01  5.26171743e+01  1.86004454e+01
 -1.03432260e+01  3.25661817e+01  6.60147506e+01  1.51597103e+01
 -2.78999843e+01 -1.64364171e+01  1.84853725e+01  3.66885499e+01
  3.04155194e+01  8.06814015e+00  1.06787911e+02  7.86697761e+00
 -3.71891160e+00  6.69452376e+01 -2.91855737e+00  5.80994687e+01
 -2.82988151e+00  2.88986952e+00  1.12275525e+00  2.06113963e+00
  1.99582728e+00  1.27102785e+02 -3.86446818e+00  1.23987938e+02
  8.81663751e+00  3.83679486e+00  2.80353209e-01 -2.68209394e+00
  8.59928562e+00  1.73272154e+00  8.04502007e-01 -2.64948158e+00
  2.76304101e+01]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2132.4846620878056
gradient value of function right now is: [-5.46331660e+00 -4.54183992e+00 -1.42870376e+00 -1.57271542e+00
  5.46331660e+00  4.54183992e+00  1.42870376e+00  1.57271542e+00
 -1.54444894e+00 -1.03182050e-02 -9.06369510e-03 -2.38931641e-01
  1.39588704e+00  1.05505458e-03  2.24416636e-04  1.96044278e-01
 -8.79308517e-02 -1.73897564e-03 -1.40380156e-03 -5.60338949e-02
  1.23268180e-01  8.45553892e-12  5.53475722e-13  1.46219288e-01
 -1.26152640e-01 -1.01982791e+00 -4.26630188e+00  1.14694962e-02
 -9.22390266e-06 -9.72550369e-09 -6.01295994e-03 -9.25607321e-11
 -1.71381378e-06 -1.70400778e-13 -2.79552511e-03 -1.08274763e-15
  5.73893935e-03  7.47001191e-01  7.91531000e-01  3.12560636e-02
 -8.66684149e-03 -3.68798202e-02 -1.44527540e-03 -1.80305566e-02
  1.43425739e+00  4.09295220e-02  6.03139397e-01  2.97650489e-02
  3.82863218e-01  7.96400911e-01  7.22247267e-02  5.74848665e-01
 -8.87699244e-01 -2.16206541e-02 -1.94983888e-01 -1.36212425e-02
  1.47907796e+00 -3.07259631e+00 -1.08607821e-01 -3.28443135e-01
  2.34984797e-01 -6.02062609e-01 -6.98076478e-02 -1.81677631e-01
  6.13966819e+00]
supnorm grad right now is: 6.139668185744586
Weights right now are: 
[ -2.9354499    3.00191965  -2.12153218   3.31857801   3.19001861
  -3.11061134   2.52046945  -4.0346064   -1.54256032  -7.83011512
  -1.63636346   7.5328422    2.42890418  26.65425101  49.21552854
   7.23026857  53.05776717 -63.76539693 -60.67907453  15.35096919
  59.30141234  -0.81255256  -0.26452188  -0.13707692  -4.59539337
   2.0165662    4.18601382 -13.29236434 -39.47072726  34.54861203
  51.09178254  18.60042205 -12.80411929  32.56618167  64.57708475
  15.15971034 -25.79057987 -16.83800396  18.75727547  36.42490645
  29.31940735  10.11865966 109.06631435   9.84469558  -3.28776432
  67.01846385  -2.58090241  57.76951831  -2.99889063   2.81194966
   0.8787939    2.4072966    1.91194319 129.27808439  -4.35865983
 126.12707038   8.86300675   3.87550305   0.37768823  -2.55373009
   8.49418979   1.60012897   1.31656971  -2.58041588  27.89373695]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2132.867130385815
gradient value of function right now is: [ 2.56919851e+00  1.24759553e+00 -5.68548976e-01 -8.58663999e-01
 -2.56919851e+00 -1.24759553e+00  5.68548976e-01  8.58663999e-01
  2.04798091e+00  2.05931108e-02  9.14804805e-03  1.27122056e-01
 -1.70731954e+00 -1.49118304e-03 -2.77958699e-04 -2.20983472e-03
 -8.88348865e-03 -4.60623476e-04 -3.69980518e-04 -5.67739306e-02
  2.44159024e-02 -1.72134208e-11 -4.06813850e-13  1.66086601e-01
  1.45025240e-01 -1.78266943e+00  3.63910805e-01 -2.31211222e-01
  7.68684520e-05  6.60653437e-08  1.39875080e-02  8.49202343e-10
  8.87480805e-06  1.37510246e-13  1.61325947e-03  1.18414071e-15
 -5.07735552e-03  6.53979251e-01  5.76703842e-01  3.22603003e-02
  4.35976058e-03  4.45008610e-02  1.02398517e-03  2.23237952e-02
  8.65244582e-01  1.27554454e-02  4.14788421e-01  1.03224952e-02
 -1.50816696e+00 -1.05615484e+00 -1.07835313e+00 -6.61223109e-01
 -3.37116098e+00 -3.31833708e-02 -1.53342165e+00 -2.61463735e-02
  1.31372904e-01 -6.67576323e-01  2.24946530e+00 -6.40275235e+00
 -1.02808171e+00  4.81886300e+00  1.49550453e+00 -4.88361752e+00
 -5.82914530e+00]
supnorm grad right now is: 6.402752345742769
Weights right now are: 
[ -2.78092953   3.19812652  -2.02839985   3.14297091   3.03549824
  -3.30681821   2.42733712  -3.85899929  -1.43998566  -8.68818428
  -1.50319675   6.80355013   2.31185044  26.39738789  50.39555056
   7.58120548  54.72383918 -62.21787437 -59.2090383   16.07657417
  61.2015023   -0.81255125  -0.26452182  -0.17364881  -3.14687024
   1.90343095   4.26084605 -13.49034604 -43.48470443  34.54828201
  49.73570452  18.60046636 -14.27265961  32.56618169  65.76215274
  15.15971034 -29.16380529 -16.45556963  18.87434652  37.85608522
  30.52790331   9.56540743 112.38231904   9.24385532  -3.02400358
  67.78423289  -2.75205335  57.31537809  -2.79265366   2.78242052
   0.93082604   2.27268174   1.92828244 131.34124474  -4.25003897
 128.54910942   9.11873951   3.87668129   0.27404217  -2.61446081
   8.48675597   1.73088046   1.23118353  -2.57140662  27.90329244]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2129.443060879851
gradient value of function right now is: [-3.96002795e+00 -3.11784066e+00 -7.21801692e-01 -1.02379945e+00
  3.96002795e+00  3.11784066e+00  7.21801692e-01  1.02379945e+00
 -1.11333603e+00 -1.59403366e-02 -1.12734542e-02 -2.32331404e-01
  1.02295779e+00 -1.19853542e-04 -9.72464680e-05  1.91338430e-01
 -6.00984375e-02 -8.28018729e-04 -6.61492013e-04 -6.11460497e-02
  9.34002972e-02  1.96981159e-12  6.76409212e-14  1.92819829e-01
 -8.14319805e-03 -2.98241505e+00 -4.32925016e+00 -5.50621295e-01
  1.08491877e-05  7.85977464e-11 -3.71301815e-03  4.03253692e-12
  2.13770573e-06 -3.78947450e-15 -8.68872470e-04  3.45568241e-17
 -4.04432773e-05  7.31228659e-01  6.49917208e-01  5.27829460e-02
  1.71302294e-04 -6.15596533e-03 -1.69607498e-04 -4.52183429e-03
  1.11731390e-01  7.04051500e-04  1.10152254e-01  1.32523128e-03
  5.23403050e-01  6.33131266e-01  1.69655333e-01  5.60671957e-01
 -7.81509659e+00 -8.04979846e-02 -5.15684750e+00 -7.59238283e-02
 -1.12642318e-01  1.81016277e-01  1.15252344e+00 -1.70077340e+01
 -1.80707061e+00  1.08781180e+01  1.11528268e+00 -1.56581774e+01
  4.78464895e-01]
supnorm grad right now is: 17.007733971998235
Weights right now are: 
[-2.90072367e+00  3.08778066e+00 -2.01397003e+00  3.22678805e+00
  3.15529238e+00 -3.19647235e+00  2.41290730e+00 -3.94281643e+00
 -1.59187731e+00 -8.80741241e+00 -1.86723437e+00  6.93305971e+00
  2.85117352e+00  2.61984152e+01  5.08324066e+01  8.67099502e+00
  5.72752171e+01 -6.58885982e+01 -6.29795942e+01  1.66731316e+01
  6.13346745e+01 -8.12550096e-01 -2.64521803e-01 -1.23990618e-02
 -3.82510416e+00  2.23137741e+00  4.01238931e+00 -1.39626118e+01
 -4.69897265e+01  3.45559744e+01  5.01172299e+01  1.86004429e+01
 -1.68177489e+01  3.25661817e+01  6.60658407e+01  1.51597103e+01
 -2.84199614e+01 -1.67055609e+01  1.87373871e+01  3.86352219e+01
  3.02625693e+01  9.48482895e+00  1.14791453e+02  9.43843112e+00
 -3.51387211e+00  6.65469588e+01 -3.32573853e+00  5.56121397e+01
 -3.03745747e+00  2.84350757e+00  9.61111468e-01  2.28160475e+00
  1.73620112e+00  1.34040785e+02 -4.22858699e+00  1.31160051e+02
  8.94422059e+00  4.04160688e+00 -6.50763965e-02 -2.64753938e+00
  8.86100346e+00  1.75063222e+00  4.21513289e-01 -2.64093598e+00
  2.78661640e+01]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2130.241040111168
gradient value of function right now is: [ 6.38736063e-01  1.21349781e+00  8.80508401e-01  1.69624231e+00
 -6.38736063e-01 -1.21349781e+00 -8.80508401e-01 -1.69624231e+00
 -1.03513190e+00 -8.01805362e-02 -4.76188063e-02  4.84258591e-02
  5.44168493e-01  1.71527292e-03  3.89282877e-04 -2.84210470e-01
  3.16040423e-02 -2.28325032e-03 -1.81282747e-03  9.15615501e-02
 -8.73541394e-02  3.01146160e-12  2.71854366e-13 -8.34480159e-01
  1.87141528e-02  3.55327956e+00  2.45212434e+00  2.77738823e-01
 -4.23228603e-06  5.84467741e-09 -3.20242114e-02  2.72096239e-11
 -7.94215813e-07  3.44902431e-14 -6.98617185e-03  2.27012796e-16
  2.43462458e-04 -1.01265677e+00 -9.06874520e-01 -4.38810891e-02
  2.73901582e-03  9.78041266e-04  7.13421839e-05  3.56443184e-04
 -2.40084379e+00 -6.72917851e-02 -6.79399983e-01 -5.72747466e-02
  1.38615774e+00  1.03676635e+00  7.56723736e-01  9.12512314e-01
  4.18209709e+00  4.49362935e-02  2.06962219e+00  4.11189987e-02
 -1.80213891e+00  3.88884857e+00 -9.43885826e-01  4.42757217e+00
  5.12774953e-01 -3.04141579e+00 -9.52214758e-01  4.99067100e+00
  1.73015808e+00]
supnorm grad right now is: 4.990670997199117
Weights right now are: 
[-2.89889104e+00  3.15146217e+00 -1.96627338e+00  3.37932534e+00
  3.15345976e+00 -3.26015386e+00  2.36521065e+00 -4.09535373e+00
 -1.68991332e+00 -8.93474116e+00 -2.20985403e+00  7.26698422e+00
  2.66660891e+00  2.74032910e+01  5.30638586e+01  8.58607697e+00
  5.94833822e+01 -6.91604844e+01 -6.63046329e+01  1.64213128e+01
  6.18394682e+01 -8.12549186e-01 -2.64521778e-01  6.76375993e-03
 -3.21263255e+00  2.16090245e+00  4.05608650e+00 -1.37486366e+01
 -5.24661026e+01  3.45632426e+01  5.00295870e+01  1.86002884e+01
 -1.84867174e+01  3.25661817e+01  6.57545085e+01  1.51597103e+01
 -2.71631613e+01 -1.69845399e+01  1.88487879e+01  3.89133060e+01
  3.09070527e+01  1.10131789e+01  1.18944891e+02  1.08925813e+01
 -3.88992965e+00  6.68176575e+01 -3.13679498e+00  5.56818958e+01
 -2.45919308e+00  2.99066250e+00  9.87403804e-01  2.39369742e+00
  1.86848194e+00  1.36051678e+02 -4.05883133e+00  1.33377459e+02
  8.43490660e+00  4.25813085e+00  4.71526778e-01 -2.71381580e+00
  8.53206279e+00  1.69913496e+00  1.09749017e+00 -2.63378742e+00
  2.79379307e+01]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2130.5418607990296
gradient value of function right now is: [ 2.69686407e+00  2.46779104e+00  6.05194513e-01  1.19568821e+00
 -2.69686407e+00 -2.46779104e+00 -6.05194513e-01 -1.19568821e+00
  2.12067971e-01  1.43719820e-03 -5.35883247e-03  2.43118646e-01
 -1.31566818e-01  6.09323782e-04  5.69710358e-05 -2.15489149e-01
  4.66654599e-02 -3.42498826e-03 -2.74080371e-03  8.97243843e-02
 -9.69976333e-02  4.52857112e-12  8.73524237e-14 -3.84382145e-01
 -3.70831206e-02  4.11857311e+00  3.65095707e+00  7.11364316e-01
 -2.16884985e-05 -1.98718648e-08 -1.84579655e-05  1.62774435e-12
 -2.58938571e-06 -5.68732995e-14 -2.80008311e-03  9.92462351e-17
 -3.46039411e-04 -1.10808010e+00 -1.06221781e+00 -7.15396552e-02
 -4.46956959e-04 -2.23948810e-02 -4.85009866e-04 -1.28885811e-02
 -1.91564191e+00 -2.90579702e-02 -9.22037999e-01 -2.21726187e-02
 -1.88616933e-02  5.11071156e-01 -8.05032872e-02  3.67869165e-01
  9.51099579e+00  8.13041737e-02  5.61637869e+00  6.72211853e-02
 -5.54119123e-01  1.64609048e+00 -2.54232945e+00  1.62491206e+01
  2.50883217e+00 -1.33851423e+01 -1.91993460e+00  1.35503352e+01
 -4.88601483e-01]
supnorm grad right now is: 16.249120641070878
Weights right now are: 
[ -2.87729865   3.13313345  -2.20076113   3.17562924   3.13186737
  -3.24182514   2.5996984   -3.89165762  -1.39419716  -8.64609317
  -2.03128033   7.81393033   2.61301082  27.76423878  53.77077645
   9.25487291  61.31910327 -70.90050503 -68.05789989  16.37148591
  62.98658626  -0.81254688  -0.26452177  -0.63020642  -4.02273427
   1.99377517   4.23747375 -13.40886522 -54.28767605  34.50462335
  50.61987631  18.59787518 -21.01847249  32.56618166  66.36325751
  15.15971034 -26.29346295 -17.24544984  18.5473368   39.21766729
  30.0630409    8.41400279 121.89314752   8.28634173  -3.10929427
  68.25372828  -2.03229404  56.69305208  -2.29774151   2.89961156
   0.71786278   2.188474     2.09916125 137.642092    -4.12186868
 135.06202954   8.96550472   4.09506831   0.14317925  -2.53981783
   8.29642989   1.66337214   0.91599722  -2.54473962  27.74472161]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2131.825335020897
gradient value of function right now is: [-3.50575038e+00 -1.99849913e+00 -1.16248607e-01 -1.69935254e-01
  3.50575038e+00  1.99849913e+00  1.16248607e-01  1.69935254e-01
 -2.25508125e+00 -9.73407397e-02 -4.90109769e-02 -5.34697894e-01
  1.41154357e+00  3.73055720e-03  7.15471887e-04  1.28070809e-01
 -1.32742304e-02 -1.09256790e-03 -8.55283897e-04  1.91521321e-02
  1.83148115e-02  8.91713933e-12  3.02723116e-13  1.14018580e-01
 -7.94305611e-02  1.05457002e+00 -1.81486584e+00  2.11394399e-01
 -8.71468468e-05 -9.20566658e-08 -5.17091630e-02 -1.95310926e-10
 -1.17694868e-05 -1.79320831e-13 -8.85600159e-03 -2.19175704e-16
 -4.65814490e-04 -2.15897700e-01 -8.87946565e-02 -2.01892601e-02
 -4.64149285e-03 -3.75602715e-02 -1.08233725e-03 -2.35322703e-02
 -1.63688089e-01  7.92578548e-03 -2.74055204e-02  6.96229142e-03
  1.27802353e+00  1.51727064e+00  7.06466496e-01  1.23825493e+00
  2.78652460e+00  1.73500277e-02  1.12861869e+00  1.35288714e-02
  9.00617131e-02  2.13112253e-01 -2.27333187e+00  5.37327534e+00
  9.88020650e-01 -3.67864395e+00 -1.50041579e+00  3.95328140e+00
  1.03773540e+01]
supnorm grad right now is: 10.377353970842298
Weights right now are: 
[-2.94656225e+00  3.08496312e+00 -2.07150337e+00  3.18060571e+00
  3.20113096e+00 -3.19365481e+00  2.47044064e+00 -3.89663409e+00
 -1.75055319e+00 -9.80510162e+00 -2.43900437e+00  6.79480943e+00
  2.52024018e+00  2.59938995e+01  5.46084319e+01  8.33551231e+00
  6.43367226e+01 -7.23181973e+01 -6.95276968e+01  1.67428526e+01
  6.31128504e+01 -8.12508455e-01 -2.64521754e-01 -9.25833168e-02
 -4.48705224e+00  1.99397334e+00  4.22712627e+00 -1.35322481e+01
 -5.56746658e+01  3.43623625e+01  4.92685937e+01  1.85992508e+01
 -2.11330051e+01  3.25661816e+01  6.65534458e+01  1.51597103e+01
 -2.46669870e+01 -1.72985552e+01  1.90386952e+01  4.00775332e+01
  2.96582875e+01  9.92040322e+00  1.25596292e+02  9.71118106e+00
 -2.71472577e+00  6.84175445e+01 -3.19004203e+00  5.59913150e+01
 -2.39274938e+00  3.11974366e+00  3.40732978e-01  2.40058418e+00
  2.26140177e+00  1.39425040e+02 -4.51926371e+00  1.37125896e+02
  9.09322691e+00  4.49519049e+00  2.96814262e-01 -2.68262616e+00
  8.37871184e+00  1.77299369e+00  9.05549595e-01 -2.70424609e+00
  2.79586514e+01]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2132.920792345531
gradient value of function right now is: [-2.91740795e+00 -1.86510023e+00 -2.64773634e-01  6.82095404e-02
  2.91740795e+00  1.86510023e+00  2.64773634e-01 -6.82095404e-02
 -1.78550562e+00 -1.02921835e-01 -5.25013162e-02 -2.95176968e-01
  1.14673763e+00  2.79842430e-03  4.12127118e-04 -1.75893656e-02
 -2.18186968e-02 -1.54009537e-03 -1.17875065e-03  2.80596836e-02
  1.16408505e-02  8.84446377e-11  1.18018151e-13 -2.74858526e-01
 -1.59670716e-01  2.75940613e+00 -2.04171761e-01  5.30068475e-01
 -4.67452471e-04 -6.87824371e-06 -4.64578079e-02 -4.16668449e-08
 -7.10660831e-06 -4.03246188e-13 -6.29627602e-03 -1.73568047e-15
 -2.25084346e-03 -3.90034120e-01 -2.62452950e-01 -2.36374843e-02
 -6.82089115e-03 -5.42564143e-02 -1.65875232e-03 -2.61609408e-02
 -1.46492578e-01  1.79576897e-03 -3.16055705e-01 -1.42192963e-03
  5.53659833e-01  1.67332787e+00  2.80514776e-01  1.20994860e+00
  6.60337562e+00  4.35628646e-02  4.07495735e+00  4.11121807e-02
  1.17974095e+00 -2.12728444e+00 -2.08527055e+00  1.08281002e+01
  2.29450412e+00 -1.18444824e+01 -1.50431956e+00  9.46452383e+00
  7.94916987e+00]
supnorm grad right now is: 11.844482411418001
Weights right now are: 
[ -2.91810686   3.04777534  -2.19250259   3.16706866   3.17267557
  -3.15646703   2.59143986  -3.88309705  -1.51734173  -9.62438875
  -1.81720788   6.99864321   2.40249762  26.01131578  53.04024686
   9.41709678  65.32762198 -73.27449888 -70.53986333  17.23703313
  65.47254522  -0.81250051  -0.26452175  -0.23393558  -3.1513603
   1.76095214   4.27539196 -13.555223   -56.24697157  33.81113363
  48.90904596  18.58926351 -22.60515729  32.56618162  68.38065559
  15.15971033 -24.54350984 -16.98520533  19.02911473  41.93347831
  28.11038326   8.37870001 130.46753084   8.16078506  -3.02871452
  68.98835054  -3.29002008  55.94904197  -2.35968685   2.76928936
   0.92287163   2.0370096    2.27573325 141.30206645  -4.37238664
 139.23463316   9.51009688   4.26729953   0.37581359  -2.6429356
   8.32039878   1.58150089   1.38039069  -2.60589282  27.94787749]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2130.185675778262
gradient value of function right now is: [-8.71858955e+00 -6.56762952e+00 -1.44142038e+00 -2.27831680e+00
  8.71858955e+00  6.56762952e+00  1.44142038e+00  2.27831680e+00
 -2.94832896e+00 -5.59528343e-02 -2.59941592e-02 -7.16104335e-01
  2.26974432e+00  2.03521191e-03  2.68065573e-04  3.37669799e-01
 -1.07616931e-01 -4.11468145e-04 -3.12012372e-04 -4.52109763e-02
  1.59139574e-01  2.51072248e-12  2.60521710e-14  8.57548466e-01
 -2.13302853e-01 -1.96903178e+00 -6.51113861e+00 -3.63546585e-02
 -4.48871447e-04 -2.70204475e-06 -3.05305777e-02 -6.88421741e-09
 -8.45931781e-06 -3.12210304e-13 -3.68146237e-03 -6.78753419e-16
  1.67563819e-02  8.07328051e-01  9.05556749e-01  1.26194475e-02
 -9.17222401e-03 -7.03466059e-02 -2.06340230e-03 -4.54968447e-02
  2.09424721e+00  6.14106012e-02  8.77408296e-01  5.38080822e-02
  1.03408165e+00  1.52776787e+00  4.29319246e-01  1.22323512e+00
 -9.68237958e-01 -2.13069702e-03  3.34383911e-01  8.23173963e-04
  1.13340157e+00 -2.23350373e+00 -1.55937311e+00  5.48775993e+00
 -1.11728851e-01  5.50071140e-01 -7.71218441e-01  4.22496734e+00
  1.17744266e+01]
supnorm grad right now is: 11.774426635127387
Weights right now are: 
[-2.95481309e+00  3.06558315e+00 -2.24093038e+00  2.77658731e+00
  3.20938180e+00 -3.17427484e+00  2.63986765e+00 -3.49261569e+00
 -1.67542629e+00 -1.00082773e+01 -2.12767021e+00  7.26269767e+00
  2.82551838e+00  2.56713298e+01  5.47664305e+01  9.59407302e+00
  6.71649962e+01 -7.53885045e+01 -7.26916494e+01  1.82243276e+01
  6.66532575e+01 -8.12480887e-01 -2.64521758e-01  2.55977212e-02
 -4.14398837e+00  1.96895966e+00  3.95526337e+00 -1.41167775e+01
 -5.71878575e+01  3.53496211e+01  4.91195331e+01  1.85709125e+01
 -2.65162160e+01  3.25661817e+01  6.89117038e+01  1.51597103e+01
 -2.68855888e+01 -1.66661710e+01  1.87674732e+01  4.23064859e+01
  2.78583853e+01  6.93915018e+00  1.31512234e+02  7.49100194e+00
 -2.96060212e+00  6.82538722e+01 -3.62229299e+00  5.49620672e+01
 -2.32727920e+00  2.71219285e+00  5.47832457e-01  1.81908553e+00
  2.04412311e+00  1.44010117e+02 -4.42081003e+00  1.41754163e+02
  9.31170002e+00  4.31458847e+00  3.67440842e-01 -2.56586472e+00
  8.60592933e+00  1.68488627e+00  1.04881858e+00 -2.52026082e+00
  2.79477970e+01]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2131.651352213111
gradient value of function right now is: [-3.87890026e+00 -2.18797188e+00  2.82039156e-01  5.20720366e-01
  3.87890026e+00  2.18797188e+00 -2.82039156e-01 -5.20720366e-01
 -2.74786397e+00 -1.03144523e-01 -4.85639637e-02 -4.87106328e-01
  1.78307290e+00  4.48388539e-03  5.10944885e-04  7.86217844e-02
 -3.59766004e-03 -1.38787128e-03 -1.05258838e-03  4.32670316e-02
 -3.31389892e-03  2.16337219e-11  4.52963092e-14 -1.30189573e-01
 -2.45156870e-01  2.87245431e+00 -9.52009213e-01  5.66587482e-01
 -1.76682374e-03 -2.14290434e-06 -5.68953677e-02 -2.64642898e-09
 -9.34477490e-05 -2.73858746e-13 -6.11209162e-03 -3.26544780e-16
  8.18203456e-03 -6.03808837e-01 -4.06861563e-01 -2.86054348e-02
 -9.63435121e-03 -8.25462085e-02 -2.48346775e-03 -5.60550234e-02
 -3.53841533e-01 -3.66100004e-03 -4.42652538e-01 -5.91565709e-03
  1.21543644e+00  1.69121469e+00  2.42888505e-01  1.38200381e+00
  7.24040072e+00  5.24826500e-02  5.01036427e+00  5.02106257e-02
  1.74152491e+00 -3.42686499e+00 -2.76456987e+00  1.41214663e+01
  2.31956910e+00 -1.23564454e+01 -1.97704399e+00  1.26705867e+01
  8.21182755e+00]
supnorm grad right now is: 14.121466292507627
Weights right now are: 
[-2.94662499e+00  2.99622615e+00 -1.96854518e+00  3.41455460e+00
  3.20119370e+00 -3.10491784e+00  2.36748245e+00 -4.13058298e+00
 -1.49716988e+00 -9.81989206e+00 -1.32267300e+00  7.37250459e+00
  2.56082810e+00  2.52647433e+01  5.70162538e+01  9.26645836e+00
  6.91426322e+01 -7.79139736e+01 -7.53341718e+01  1.74117792e+01
  6.78822227e+01 -8.12468246e-01 -2.64521758e-01 -3.64546225e-01
 -3.32777272e+00  1.77466797e+00  4.20849234e+00 -1.36544453e+01
 -5.49354235e+01  3.55391454e+01  4.88266019e+01  1.85492975e+01
 -2.37362988e+01  3.25661818e+01  6.89608829e+01  1.51597103e+01
 -2.44897449e+01 -1.66396797e+01  1.92458388e+01  4.44702565e+01
  2.98776393e+01  6.01071889e+00  1.35292769e+02  5.88734433e+00
 -3.33125472e+00  6.81143282e+01 -3.07658348e+00  5.43895909e+01
 -2.04088741e+00  2.79099748e+00  8.86160787e-02  1.84017045e+00
  2.12821102e+00  1.46113289e+02 -3.99765649e+00  1.43955907e+02
  9.27470741e+00  3.82525880e+00  1.09675289e-02 -2.62472215e+00
  8.39687125e+00  1.57996656e+00  5.80502477e-01 -2.59731083e+00
  2.76573354e+01]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2129.005824395635
gradient value of function right now is: [-5.53431766e+00 -4.37098916e+00 -5.90842989e-01 -7.80762349e-01
  5.53431766e+00  4.37098916e+00  5.90842989e-01  7.80762349e-01
 -1.68456529e+00 -3.66015307e-02 -1.73850284e-02 -2.64804746e-01
  1.35371331e+00  1.29661671e-03  1.70681342e-04  1.14132079e-01
 -6.24533005e-02 -1.01984669e-04 -7.71086356e-05 -1.19637004e-02
  1.22806797e-01 -5.24212241e-11  2.78592296e-14  1.18207126e-01
 -1.57986147e-02 -4.24516315e+00 -5.88952233e+00 -7.07115656e-01
  1.48633140e-04  2.39855577e-06 -1.88083872e-02  1.29666796e-08
 -4.25481695e-06  5.30204041e-14 -2.46353755e-03  5.47176904e-16
 -1.97205856e-03  2.26503073e-01  2.23948496e-01  2.38905893e-02
 -7.91325117e-04 -6.83572413e-03 -3.10446304e-04 -5.45983787e-03
  3.93329665e-01  4.48094958e-03  1.07793568e-01  4.01179857e-03
  3.66257255e+00  8.41495204e-01  1.78218447e+00  7.87785681e-01
 -8.17499896e+00 -5.68284897e-02 -4.04124971e+00 -5.52300789e-02
  1.47156090e+00 -3.58661234e+00  1.61258839e+00 -1.28736872e+01
 -2.19925528e+00  1.18749115e+01  1.59142516e+00 -1.25302981e+01
  5.35707409e+00]
supnorm grad right now is: 12.873687187250402
Weights right now are: 
[ -2.97801165   3.07249026  -2.11710949   3.52845227   3.23258037
  -3.18118195   2.51604676  -4.24448066  -1.72389338 -10.59033951
  -2.5563926    7.57266299   2.6510953   25.40118187  57.02200214
   9.19440184  71.726535   -79.50845625 -76.97106219  18.2344857
  68.25165554  -0.81231355  -0.26452176  -0.36911223  -2.4968512
   1.69862048   4.50855637 -14.1980384  -56.38343327  36.31855362
  49.04270073  18.49678657 -25.88596583  32.5661819   69.68722849
  15.15971033 -23.66622251 -16.8520764   19.17927608  45.21558616
  29.96518629   6.77632983 137.94561507   6.53016156  -2.78535451
  69.41578231  -2.77555998  55.74896007  -1.94865708   2.85476396
   0.42706012   2.08160095   1.9818595  147.95132858  -4.38139949
 145.81710809   9.10690857   4.04369374   0.52720923  -2.78624213
   8.28758892   1.64100385   0.88421386  -2.74436422  28.06778071]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2133.8542627044326
gradient value of function right now is: [ 5.15289569e-01  3.12980009e-01  5.64232577e-04 -7.10038219e-02
 -5.15289569e-01 -3.12980009e-01 -5.64232577e-04  7.10038219e-02
  2.82513413e-01 -1.51790747e-02 -1.19307716e-02 -2.50799913e-02
 -1.63189114e-01 -1.67429365e-04 -1.26071151e-05  1.57915335e-02
 -1.35344514e-03 -3.38712995e-04 -2.60865351e-04 -2.40023382e-03
  3.59772019e-03 -1.26571332e-11  1.54110809e-15  6.15545225e-02
  5.16460447e-02 -3.41380644e-01 -4.39908157e-02 -5.08266277e-02
  3.70398303e-04  1.48114511e-06 -1.44303607e-04  5.17500230e-09
  1.33190134e-05  2.26063614e-13 -6.69876754e-04  7.18652259e-16
 -1.01506807e-03  6.68879689e-02  3.37215886e-02  7.67979550e-03
  2.96688243e-03  1.09152116e-02  2.69755588e-04  8.10336318e-03
 -2.49313618e-01 -9.99931465e-03 -1.80345634e-01 -9.19042114e-03
 -8.85332370e-02  1.38002342e-01  2.35390908e-02  1.47910161e-01
 -1.00307366e+00 -5.87198583e-03 -4.20991352e-01 -5.38453355e-03
 -2.57128411e-01  5.15160191e-01  4.35154167e-01 -2.40124309e+00
 -4.26120813e-01  2.30477293e+00  3.55549813e-01 -1.99842342e+00
 -1.77390253e+00]
supnorm grad right now is: 2.401243085651195
Weights right now are: 
[ -2.89051271   3.08492357  -1.88519423   3.55759448   3.14508142
  -3.19361527   2.2841315   -4.27362287  -1.58375986  -9.3356105
  -0.52985399   7.87965838   2.33443196  26.23226716  59.68917593
   9.04500668  72.86765832 -82.40035038 -79.91407745  16.90241756
  69.85478665  -0.81238976  -0.26452177  -0.86998902  -1.77859691
   1.6326743    4.45666377 -13.54169639 -54.67189586  33.31131005
  48.99969254  18.4575185  -29.78850152  32.5661819   68.92258959
  15.15971033 -22.80685305 -16.79621894  19.52132041  46.04399349
  27.64724766   8.23306552 138.23752087   7.68259403  -2.678922
  69.30060064  -2.84636542  55.60886633  -2.29431877   2.60996193
   0.32902397   2.02434173   2.11607409 149.46019097  -4.38346801
 147.2065794    9.16658825   4.41146501   0.28394485  -2.73686781
   8.44936586   1.69346255   0.90844994  -2.76370279  27.96616401]
(65,)
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2133.769332090759
gradient value of function right now is: [ 3.32530612e-01  2.00286835e-01  1.29609830e-02 -5.76044072e-02
 -3.32530612e-01 -2.00286835e-01 -1.29609830e-02  5.76044072e-02
  1.75367498e-01 -2.01744685e-02 -1.40262435e-02 -4.65829314e-02
 -8.64484807e-02 -1.73778387e-04 -9.21016983e-06  1.91996679e-02
 -1.70185626e-03 -1.96013131e-04 -1.45159364e-04  2.97453812e-04
  4.94570620e-03 -6.36765514e-12  1.68171615e-15  6.88131457e-02
  4.56990768e-02 -4.19030692e-01 -1.92542581e-01 -7.00132110e-02
  2.72497706e-04  1.20998426e-06 -2.11146391e-03  5.71489157e-09
  1.12085984e-05  2.01480730e-13 -6.37302712e-04  7.43217350e-16
 -5.14922569e-05  4.32295216e-02  1.61271176e-02  6.45043957e-03
  2.97836711e-03  1.03138938e-02  2.71423376e-04  7.62362962e-03
 -2.71814186e-01 -9.80371261e-03 -1.85672269e-01 -9.08808816e-03
  1.74117170e-02  1.72666701e-01  4.51022380e-02  1.74970783e-01
 -1.14565593e+00 -5.93258887e-03 -4.95559007e-01 -5.56557137e-03
 -2.21344782e-01  4.55207655e-01  3.44474820e-01 -2.41215750e+00
 -5.06708634e-01  2.65995177e+00  2.92348038e-01 -2.04804223e+00
 -1.86287480e+00]
supnorm grad right now is: 2.6599517689802776
Weights right now are: 
[ -2.8182449    3.19697193  -1.64471541   3.51432883   3.07281361
  -3.30566362   2.04365268  -4.23035721  -1.5491712  -10.92717519
  -1.88278576   7.45136513   2.42177522  25.02244983  58.11773587
   9.83731201  76.6922175  -80.43538132 -77.98138283  17.69238877
  70.20129939  -0.81234436  -0.26452177  -0.63211765  -2.88808437
   1.94561682   4.33817431 -14.35629508 -56.14923485  31.48291915
  48.3941135   18.45037671 -32.72511957  32.56618174  71.88030104
  15.15971033 -20.47902256 -16.87209921  19.15909156  45.29373941
  21.84827259   9.78258268 137.18741247   9.21999399  -2.74228085
  68.53320273  -2.79665773  54.97825948  -2.28049841   2.57789846
   0.48654118   1.99270524   2.06392068 151.83669426  -4.31952429
 149.50127514   9.95306513   4.23159251   0.39739956  -2.68143673
   8.49634145   1.78413541   0.60282588  -2.6527332   27.89389999]
(65,)
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2133.7457304150103
gradient value of function right now is: [ 3.77639172e-01  2.55677148e-01  1.81080984e-02 -5.12667554e-02
 -3.77639172e-01 -2.55677148e-01 -1.81080984e-02  5.12667554e-02
  1.59381810e-01 -1.89788417e-02 -1.34870584e-02 -4.51496688e-02
 -7.30889093e-02 -1.13041736e-04 -8.66914674e-06  1.74136089e-02
 -5.23672365e-04 -1.29914903e-04 -9.72479708e-05  2.81273906e-03
  2.72559829e-03 -4.10594990e-12  1.37061539e-15  8.05320567e-02
  4.13673283e-02 -4.35440196e-01 -1.44353817e-01 -7.75760585e-02
  2.19363118e-04  1.38543906e-06 -1.73412189e-03  7.92606662e-09
  8.11463984e-06  1.97531750e-13 -5.19012218e-04  8.26480575e-16
  4.54638033e-04  3.15450281e-02  5.67371575e-03  5.53994128e-03
  3.08587637e-03  1.03897314e-02  2.70938317e-04  8.02160281e-03
 -2.77684260e-01 -9.59157496e-03 -1.83634240e-01 -8.97765483e-03
 -2.94422994e-02  1.51983231e-01 -5.59756934e-04  1.54932295e-01
 -1.18277818e+00 -5.19402913e-03 -4.87692508e-01 -4.91929798e-03
 -2.26328343e-01  4.77349704e-01  3.19665041e-01 -2.23884013e+00
 -5.45789355e-01  2.78252924e+00  2.72710716e-01 -1.90800602e+00
 -1.80170949e+00]
supnorm grad right now is: 2.782529235080998
Weights right now are: 
[ -2.97026273   3.04376419  -2.0913056    3.17150913   3.22483144
  -3.15245588   2.49024286  -3.88753752  -1.4377175   -9.86069025
  -0.46397875   8.16213722   2.46871194  25.95100941  60.58190976
  11.26630274  78.40295184 -83.85427687 -81.46580231  16.77524826
  71.18449448  -0.81233874  -0.26452177  -0.59577226  -3.62198813
   1.61374998   4.42291638 -14.32874165 -58.5992826   28.69391501
  49.03129367  18.39568894 -36.34467445  32.56618169  71.70783853
  15.15971033 -21.80080736 -17.04169633  18.73851639  46.12273839
  21.83887576   7.70972084 141.78728556   7.10086953  -2.96689237
  68.03280899  -2.27981082  54.70214969  -1.9148065    3.08653669
   0.54912899   2.59589814   2.14943971 153.75315692  -4.09889365
 151.29340391   9.76285811   4.6917581    0.46127679  -2.70555441
   8.39450309   1.54195833   0.6633459   -2.70838468  27.87630037]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2133.7997688973783
gradient value of function right now is: [ 3.81668675e-01  2.60861091e-01  2.48704157e-02 -3.69384108e-02
 -3.81668675e-01 -2.60861091e-01 -2.48704157e-02  3.69384108e-02
  1.57347130e-01 -1.77861936e-02 -1.27681020e-02 -3.99201866e-02
 -6.45444979e-02 -1.18161818e-04 -9.80989924e-06  1.54627671e-02
 -2.95246316e-04 -2.19289494e-04 -1.66946304e-04  3.67865901e-03
  1.82626758e-03 -1.34985629e-12  1.01598979e-15  7.82092048e-02
  2.91984580e-02 -3.88000745e-01 -1.17763393e-01 -6.65600216e-02
  1.97936463e-04  8.85636657e-07 -1.36092642e-03  7.63476794e-09
  7.91673633e-06  1.08852707e-13 -4.71335700e-04  6.51914625e-16
  1.47193422e-04  2.45749450e-02 -2.46261677e-03  5.04864759e-03
  2.67961390e-03  8.17755704e-03  1.77746851e-04  6.27675990e-03
 -2.84473957e-01 -9.44998551e-03 -1.81844400e-01 -8.84856238e-03
 -5.59279125e-02  1.50780432e-01 -1.30761793e-02  1.52284194e-01
 -1.06464838e+00 -4.62327931e-03 -4.27831729e-01 -4.43859497e-03
 -2.24455774e-01  4.90254758e-01  2.77928534e-01 -2.07881608e+00
 -4.62064010e-01  2.44045958e+00  2.39062471e-01 -1.77797628e+00
 -1.75493446e+00]
supnorm grad right now is: 2.4404595757066043
Weights right now are: 
[ -2.8159568    3.23682745  -2.08320051   3.40317732   3.07052551
  -3.34551914   2.48213778  -4.1192057   -1.40491216 -11.52895072
  -1.265299     7.93934836   2.28172239  21.27266792  60.57023263
   8.77967027  81.762672   -81.55993194 -79.27158217  18.36210777
  72.04574415  -0.81233048  -0.26452177  -0.78781768  -3.81615515
   1.68537977   4.51576703 -14.34979495 -56.16758382  26.99702079
  48.94665399  18.27155301 -35.51166309  32.56618134  76.07911922
  15.15971033 -21.73755903 -17.06228757  18.69665869  46.02566504
  23.56640143   6.69362502 144.98972466   6.11277953  -2.23687114
  68.21617299  -2.91225112  54.92941391  -2.03388254   3.10771593
   0.23913551   2.49728553   2.0900036  155.48746927  -4.31032499
 153.02413698   9.59923486   4.44749645   0.26254512  -2.75829883
   7.91960036   1.73990461   0.77118584  -2.75260392  27.84687296]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2133.798548038882
gradient value of function right now is: [ 4.12548295e-01  2.77488328e-01  2.65235000e-02 -4.01205617e-02
 -4.12548295e-01 -2.77488328e-01 -2.65235000e-02  4.01205617e-02
  1.82294839e-01 -1.48782677e-02 -1.12936219e-02 -3.14264432e-02
 -7.03505739e-02 -1.80472151e-04 -1.50425907e-05  1.62935499e-02
 -3.30389947e-06 -2.25472567e-04 -1.72221520e-04  2.79395747e-03
  1.43776788e-03 -7.27541089e-13  5.94286786e-16  7.95582519e-02
  2.69998201e-02 -4.59185920e-01 -1.27478907e-01 -7.97295430e-02
  2.17177515e-04  7.89971919e-07 -4.95469248e-05  8.52759517e-09
  8.87016367e-06  7.19708791e-14 -3.26077996e-04  5.79891353e-16
 -5.40616252e-05  3.64287169e-02  4.20153715e-03  5.99279504e-03
  2.73987113e-03  7.85101513e-03  1.82824994e-04  5.65704104e-03
 -2.88100139e-01 -1.00369266e-02 -1.81084998e-01 -9.09428738e-03
 -8.49261000e-02  1.23630988e-01 -2.95344123e-02  1.28228921e-01
 -1.25249727e+00 -6.10447445e-03 -5.37648369e-01 -5.68979639e-03
 -2.38653781e-01  5.18351579e-01  3.48978196e-01 -2.51558973e+00
 -5.24332002e-01  2.77519448e+00  2.93294609e-01 -2.11412865e+00
 -1.94724266e+00]
supnorm grad right now is: 2.775194475654074
Weights right now are: 
[-2.98371548e+00  2.98811733e+00 -2.15258965e+00  3.17623569e+00
  3.23828419e+00 -3.09680902e+00  2.55152692e+00 -3.89226407e+00
 -1.47304912e+00 -1.08838812e+01  6.04435095e-01  7.30286661e+00
  2.43437012e+00  2.06513934e+01  6.43631063e+01  9.87907679e+00
  8.36289051e+01 -8.32935525e+01 -8.11827862e+01  1.76149463e+01
  7.34148047e+01 -8.12323594e-01 -2.64521765e-01 -1.67075293e-01
 -3.28913922e+00  1.81468833e+00  4.67472703e+00 -1.37168501e+01
 -5.30725110e+01  2.91410727e+01  4.82170869e+01  1.83396036e+01
 -3.62655289e+01  3.25661815e+01  7.66321087e+01  1.51597103e+01
 -2.39393233e+01 -1.64608186e+01  1.88498780e+01  4.82812541e+01
  1.85944158e+01  6.65137335e+00  1.46846157e+02  6.27741218e+00
 -2.76317608e+00  6.90155911e+01 -2.82312378e+00  5.56453277e+01
 -2.14411158e+00  2.98195767e+00  8.19538826e-02  2.45212925e+00
  2.02043780e+00  1.57047523e+02 -4.78245095e+00  1.54604063e+02
  1.03772329e+01  4.84875270e+00  3.92884798e-02 -2.73762735e+00
  7.85997694e+00  1.65088563e+00  8.67694022e-01 -2.72773514e+00
  2.79035476e+01]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1448.9040389645725
W_T_median: 1228.6332042535148
W_T_pctile_5: 778.8178454154394
W_T_CVAR_5_pct: 684.9152713542604
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.0
F value: -2133.798548038882
-----------------------------------------------
-1.88145469e-08 -1.57758627e-04
  5.74201009e-02 -1.08026750e-02  1.86766854e-04 -7.31322724e-03
 -1.99448316e-02 -3.46689529e-04 -5.82536487e-18 -5.14295014e-06
 -7.68658076e-03 -2.03197760e-02 -1.23726942e-04 -4.47478903e-03
  8.19596799e-07  5.66387690e-02  1.54692571e-03  9.42333752e-04
  1.50132939e-02 -8.16395139e-03  8.13652871e-02  1.88251858e-02
 -2.41295778e-09  3.68531037e-04 -1.52042567e-03 -6.59366339e-05
  1.82556079e-04 -2.76452013e-02  8.59563987e-03  1.06918158e-03
 -2.03671483e-02 -1.64187267e-02 -3.92926361e-02  1.24214645e-01
 -2.02673881e-02 -7.44285210e-02 -5.34384316e-03 -9.32965545e-02
 -1.53777056e-01]
supnorm grad right now is: 0.1537770559124733
Weights right now are: 
[ 7.81233452e+00 -5.02699249e+00  7.67252518e+00 -2.70115942e+00
 -8.54663324e+00  4.98374475e+00 -7.17820823e+00  1.16527110e+00
  4.36981752e+01  6.29193018e+01 -3.65246260e+00  1.23457686e+01
  2.28672579e+01  5.89099434e+01 -5.04404222e+01  1.99211369e+01
  4.52989548e+01  7.35668689e+01 -3.88412007e+00  1.17507928e+01
 -3.62190649e+00  1.18093824e+00 -1.51501327e+01  3.68820338e+01
  1.05348426e+00  5.50776061e+00  2.26438961e+01  8.50205228e+01
  4.12893259e+00 -4.20953910e+00  9.21099476e+00 -6.44392132e+00
  2.00616100e+00  1.39616603e+02  6.56392253e+01  1.30497416e+02
  1.91622629e+01 -6.98562025e-03  6.16236169e+01 -1.69617765e+01
 -1.43639471e+02  4.14628961e+00 -3.80092114e+01 -1.10827935e+02
  3.43321646e+00 -3.88537107e+00  8.26278938e-01  3.38144466e+00
  1.97660811e-01  8.37991302e+01  2.31155237e+01  4.42291806e+01
 -3.07458138e+00  2.07791404e+00  9.90989293e+00  3.87887551e+00
  1.10563396e+01 -1.28523511e+01  1.03962687e+01  3.81751161e+00
 -4.49949577e-01 -5.23958277e+00  5.26208054e+00 -4.44386107e+00
  2.70011872e+01]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1471.3663271122682
W_T_median: 1269.7135071413209
W_T_pctile_5: 719.4590493143604
W_T_CVAR_5_pct: 621.4323758352929
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.0
F value: -2092.7982316067355
-----------------------------------------------
