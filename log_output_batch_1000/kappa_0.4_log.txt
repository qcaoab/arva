Starting at: 
2022-06-17 22:26:16
tracing parameter entered from terminal:  0.4


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1370.4044413860581
gradient value of function right now is: [ 4.78557897e-01 -1.68428890e+00 -6.78610643e-01  2.14379553e-01
 -4.78557897e-01  1.68428890e+00  6.78610643e-01 -2.14379553e-01
  1.21649950e-01  8.24288192e-02  8.89210752e-04  6.09541964e-03
  1.95202480e-01 -8.92493531e-01 -6.20114671e-02 -3.58678160e-01
 -6.13382096e-01  3.15844569e+00  2.29921288e-01  1.29692801e+00
 -2.74109199e-01  1.22635759e+00  8.21703430e-02  4.43649343e-01
  1.46786735e-01  3.38112922e-01  6.03260027e-01  3.21775120e-02
  2.63697046e-01 -1.94506772e-01 -2.27789244e-01  4.21386194e-01
 -6.00066479e-01 -9.58299775e-02 -3.62245572e-01 -5.35886309e-01
 -3.38980835e+00 -5.73424514e-01 -2.04628462e+00 -3.01921806e+00
 -3.13989751e-02 -3.14601296e-02 -2.05958565e-01 -2.66429551e-02
 -6.82757536e-02 -6.33603719e-02 -8.94756091e-01 -6.52647345e-02
  7.97630697e-01  7.48771564e-01  8.25137078e+00  7.60404278e-01
 -3.32120087e-01 -3.15346627e-01 -2.88314824e+00 -3.16573483e-01
  1.94637685e+00 -5.92090600e+00  1.49206292e+00 -4.39208503e+00
 -2.33065776e+00  8.03394626e+00  1.62900766e+00 -4.94404143e+00
 -1.50440755e+01]
supnorm grad right now is: 15.044075489255173
Weights right now are: 
[-9.84870923e-01 -7.02470525e-01  2.26608165e+00  8.32560053e-01
  1.23943963e+00  5.93778834e-01 -1.86714438e+00 -1.54858844e+00
  8.12942280e+00  8.33325407e+00  4.89735475e+00  5.22652418e+00
  3.53112939e+00 -5.45162262e-01 -3.16722206e+00 -1.24600998e+00
  3.43034798e+00 -1.54391602e+00  2.05808130e+00  3.98359842e+00
  4.35315388e+00 -9.96344302e-03  2.17575721e+00  3.97535615e+00
  3.30326210e+00  1.49614415e+00 -1.15579923e+00  3.55692604e+00
 -1.79230720e+00  2.57152389e+00  4.35667634e+00 -3.63123378e+00
  1.72427042e+00  1.15162387e+00  9.69249857e+00 -4.19927485e+00
 -1.25652249e+00 -4.01205188e+00  1.20144093e+01 -4.70930611e+00
  2.76929425e+00  1.74010917e+00 -2.23157029e+00  2.37848692e+00
  8.57648882e-01  1.88595588e+00  3.69532378e+00  1.41430865e+00
 -5.52130474e+00 -3.66159739e+00  1.69737973e+00 -4.47373515e+00
  8.12646555e+00  8.04027339e+00 -3.01361990e+00  7.89560181e+00
  2.78021999e+00 -2.33597132e+00  2.74504066e+00 -2.41999012e+00
  4.42613753e+00  1.41199070e+00  2.85362824e+00 -2.37268716e+00
  3.08878696e+01]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1369.057173040179
gradient value of function right now is: [ 2.82500206e-01  9.57652122e-01  3.43439765e+00  2.18377765e+00
 -2.82500206e-01 -9.57652122e-01 -3.43439765e+00 -2.18377765e+00
  3.49256549e-02  1.27508357e-02  1.11165216e-05  6.92363206e-04
  6.44963288e-01  4.20679247e-01 -6.77977947e-02 -9.49156383e-02
 -2.41736351e+00 -1.93440360e+00  8.62049023e-03 -3.08523068e-01
 -8.72647278e-01 -6.60477057e-01 -2.00088503e-03 -7.45419815e-02
  2.09801420e+00  9.57917796e-01  4.11925160e+00  3.57662182e-01
 -1.19040694e+00 -5.11150850e-01 -1.38063355e+00 -5.34660664e-01
 -3.59446338e-01 -4.09001874e-03 -1.09178215e-01 -3.35628065e-01
  6.50178525e-01  3.27347913e-01  5.63135382e-01  5.20693242e-01
 -6.63746389e-01 -6.71021728e-01 -1.26329366e+00 -5.88662354e-01
 -1.32778204e-01 -1.35674809e-01  1.28798743e-01 -1.19806169e-01
  1.50342732e-01  1.49902606e-01  9.34853122e-01  1.36433705e-01
 -1.07841317e-01 -1.07987452e-01 -6.32539376e-01 -9.42462514e-02
  1.04710702e+00 -1.57313365e+00  8.18865364e-01 -1.24436391e+00
 -6.98151362e-01  2.33072003e+00  9.24517300e-01 -1.36183198e+00
 -2.31238722e+01]
supnorm grad right now is: 23.123872228492797
Weights right now are: 
[-0.20662869 -2.22784296  2.80641968  0.96440032  0.4611974   2.11915127
 -2.40748241 -1.6804287  11.75906798 11.54378016  9.71975488  7.92959569
  9.01540466  3.01208925 -9.76634464  1.16502969  3.89182294 -1.1170851
  3.01584885  3.42155437  5.24840413  0.94403866  2.29146514  4.62985605
  3.87859516  2.07662949 -1.54591746  1.86152985 -2.42301829  2.92015186
  4.64254043 -4.82410213  1.4890364   1.75862977 13.11037836 -5.96134138
 -1.30898468 -4.09208286 12.14509562 -5.33235387  2.26277539  1.15787418
 -2.41428688  2.29038782  0.25307992  0.96986187  4.31145903  1.81589385
 -7.98757495 -6.17383985  2.23636258 -7.00560326 11.16108736 11.16745919
 -2.96879294 10.82251616  2.75760001 -2.53326882  2.69390713 -2.56635898
  4.37249215  1.27717862  3.14277866 -2.57290927 30.81980126]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.931699697299
gradient value of function right now is: [ 3.34461428e-03  8.86869486e-02  6.68304514e-01  3.29312136e-01
 -3.34461428e-03 -8.86869486e-02 -6.68304514e-01 -3.29312136e-01
 -2.80225236e-04 -1.12622193e-04 -2.15168671e-08 -3.67110576e-06
  1.50853469e-01 -2.59151285e-01 -1.40785880e-01 -3.07391467e-01
 -1.17398464e+00  1.98366065e+00  1.24032674e-01  9.06665385e-01
 -8.91124028e-02 -5.13585422e-02  1.53292798e-04 -1.96758411e-03
  9.09024441e-01  8.06970095e-01  1.89348273e+00  1.29179349e-01
 -3.12348906e-01 -2.71077261e-01 -4.73307572e-01 -1.15788404e-01
 -1.03161358e+00 -7.41302165e-02 -3.68501299e-01 -8.48771212e-01
 -1.34359529e+00  7.37754345e-02 -5.28734130e-01 -8.33360152e-01
 -1.90928302e-01 -2.84531730e-01 -2.22354690e-01 -1.33836862e-01
 -5.15019239e-02 -6.73026392e-02 -2.12064986e-01 -3.96575576e-02
  3.88386995e-01  4.28572365e-01  5.61432159e+00  3.31910689e-01
 -1.80581801e-01 -2.01532675e-01 -2.68006724e+00 -1.53265354e-01
  1.34450944e+00 -5.26914489e+00  1.25754317e+00 -4.92443066e+00
 -1.86274926e+00  8.72361859e+00  1.11387881e+00 -4.31650930e+00
 -8.27285765e+00]
supnorm grad right now is: 8.723618593926636
Weights right now are: 
[  0.32246498  -2.52416948   2.96598585   0.33704044  -0.06789627
   2.41547779  -2.56704858  -1.05306882  22.29308965  22.0824593
  10.64712536  14.64957862  12.20416183   4.46044669 -11.03246681
   1.55829869   3.95504739  -0.71397926   4.03296573   3.62328912
   8.67103755   4.81593457   2.78822761   3.94709493   4.24390321
   1.59616677  -1.85209889   0.51231421  -2.87239394   2.5704163
   4.51988634  -5.5506048    1.39870568   1.1297991   14.62832774
  -6.50207188  -1.1899326   -4.23440111  12.50403103  -5.94376247
   2.07609258   0.146242    -2.56427916   3.27283828   0.6439914
  -0.43220314   4.55840681   4.8713817   -9.5712297   -7.63001978
   2.67402892  -8.71373307  13.27638683  13.60053132  -2.85079145
  12.5464427    3.40169909  -2.74461442   2.5726227   -2.81702015
   4.75559221   1.29049662   4.14577531  -2.77348413  31.05425134]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.6690344500946
gradient value of function right now is: [ 7.73976108e-04  8.26727704e-02 -4.14366536e-01  2.33314483e-02
 -7.73976108e-04 -8.26727704e-02  4.14366536e-01 -2.33314483e-02
 -9.12654261e-04 -3.09595037e-04 -7.79490181e-08 -1.71259348e-05
  6.42047103e-02  3.94041819e-02  2.08650298e-02  2.19271780e-02
 -9.88078186e-01  4.39889836e+00  1.27607560e-01  1.77668709e+00
 -7.99930729e-03 -3.69243988e-03 -1.33257961e-06 -2.89504942e-04
  4.86994304e-01  3.03537615e-01  1.50300389e+00 -1.93661657e-01
 -2.04358106e-02 -6.78935089e-02 -1.27625551e-01  3.46353642e-02
 -5.04838454e-01 -4.67265834e-02 -2.30469831e-01 -3.28176345e-01
 -2.35743898e+00 -1.88722534e-01 -1.08262809e+00 -1.45080058e+00
 -2.66074625e-01 -3.37879977e-01 -4.01808192e-01 -2.26624677e-01
 -4.41151006e-02 -5.50162154e-02 -4.45054122e-01 -3.65320686e-02
  3.77952407e-01  4.31429857e-01  6.06906124e+00  3.30742145e-01
 -1.78778801e-01 -2.05725229e-01 -2.95745891e+00 -1.55908326e-01
  1.20053346e+00 -5.98627065e+00  1.14151709e+00 -5.82112818e+00
 -1.80601885e+00  8.81320308e+00  1.04808622e+00 -5.04101734e+00
 -9.49644827e+00]
supnorm grad right now is: 9.496448271498839
Weights right now are: 
[  3.08263708  -2.65678662   3.06045935   0.52891009  -2.82806837
   2.54809493  -2.66152208  -1.24493847  29.01007408  24.68625189
  10.62642508  11.01835088  14.37241843   6.23623399 -11.45211321
   1.83697196   3.89970112  -0.49646328   6.04910286   3.22203317
  17.4260142   10.48817546   2.75832874   7.12614274   4.42235902
   1.19554111  -2.05678783   1.3915546   -2.78318382   2.41686051
   5.27125549  -5.48745695   1.81584608  -0.82619413  16.17581496
  -6.74596778  -1.11435187  -4.60562438  12.67076038  -6.26325983
   1.80804613  -0.92701855  -2.53839735   3.68205066   1.40755203
  -0.98634828   4.63963668   6.68931972 -10.99195818  -8.57464652
   2.75312936 -10.1796125   14.71436183  15.65149058  -2.43988256
  13.4626911    3.43741569  -2.99875653   2.40005208  -3.05272156
   4.7217691    1.15646113   4.17281082  -3.01804984  31.01939573]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1370.501719274337
gradient value of function right now is: [-6.94195142e-02 -8.79316005e-01 -1.64251129e+00 -2.78305342e-01
  6.94195142e-02  8.79316005e-01  1.64251129e+00  2.78305342e-01
  5.85191766e-02  2.73296840e-02  2.49810974e-05  1.47068694e-03
 -5.26890158e-01 -2.03853704e-01  6.55479472e-02  1.26896791e-01
  2.77922154e-02 -2.92217113e+00 -1.38923098e-01 -1.65214527e+00
  8.66773562e-02  5.38498453e-02  5.74651299e-05  3.16730106e-03
  1.45596632e+00  1.41902462e-01  2.48709817e+00  2.20541368e-01
  6.38347189e-01  4.67215684e-01  9.50489590e-01  5.41876213e-02
  1.14146836e+00  2.55193124e-01  5.42192888e-01  8.73903797e-01
  1.93553487e+00  5.37102384e-01  1.10128767e+00  1.38106773e+00
 -5.03289227e-01 -7.43696398e-01 -8.31577017e-01 -4.45660006e-01
 -2.25241001e-02 -7.06067588e-02  5.42999277e-01 -1.54881600e-02
 -2.33006759e-01 -4.07678046e-01 -5.28485973e+00 -2.06837946e-01
  1.23714140e-01  2.22113993e-01  2.66770868e+00  1.09298416e-01
 -9.83214005e-01  4.39354224e+00 -3.05944775e+00  6.20339347e+00
  2.48027628e+00 -8.76203276e+00 -4.10822528e-01  3.64069136e+00
  1.08450402e+01]
supnorm grad right now is: 10.845040168097707
Weights right now are: 
[  3.85612517  -3.42095696   3.06377423   1.09100369  -3.60155646
   3.31226527  -2.66483696  -1.80703208  32.20489675  22.86596873
  10.33415009   8.94195349  15.98269609   6.99181096 -12.84215681
   1.59225023   4.21361273  -0.74111169   8.71864806   2.95111844
  24.57169095  12.4731818    3.48659003  10.2211884    4.92793061
   1.51164799  -1.87470127   1.67402971  -2.74341422   2.63993809
   5.84148157  -5.33477113   1.72633349  -3.45730754  16.73438918
  -7.42735799  -0.9911681   -4.29683657  13.03564284  -6.66939848
   2.15334839  -1.7952923   -2.64491791   4.52499868   4.41567273
  -0.26918545   4.22112483  10.73846778 -12.69335905  -9.29912994
   2.71650707 -11.97864277  16.25863723  18.00302158  -2.27248503
  14.64584778   3.93139112  -3.17183124   1.84379394  -3.24587658
   4.6589437    0.91006925   4.52600322  -3.14860447  30.99551679]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1367.8546858390323
gradient value of function right now is: [-2.60273052e-03 -1.58654923e-01 -4.50544459e+00 -2.37360957e-02
  2.60273052e-03  1.58654923e-01  4.50544459e+00  2.37360957e-02
  3.62976396e-03  2.00626109e-03 -2.37317567e-07 -2.46009676e-06
 -1.95089359e-01 -1.69470515e-02  3.99340096e-02  9.58991561e-02
  4.85986897e+00 -4.90373303e-01 -1.47160503e-01 -1.75083776e+00
  2.31963401e-02  1.60646821e-02 -6.41297496e-07  7.76347290e-05
 -7.48550675e+00 -1.52843337e+00 -1.20633262e+01 -2.73490195e-01
  8.53849897e-01  9.30294196e-02  1.03028418e+00  1.48026342e-02
  1.12499435e+00  3.24106293e-01  5.74420742e-01  8.37186505e-01
  1.08598404e+00  3.29680029e-01  6.14861799e-01  7.41099496e-01
  1.41342127e+00  2.98302199e+00  2.87389204e+00  1.26065508e+00
  7.75336628e-02  2.48602891e-01  6.50006802e-01  6.45983275e-02
 -2.97392862e-01 -5.82926006e-01 -4.72535917e+00 -2.79979397e-01
  1.30207542e-01  2.37133133e-01  2.45122556e+00  1.24514579e-01
 -3.26026251e+00  5.16609906e+00 -1.34232365e+00  5.79745715e+00
  3.93788392e+00 -9.75750792e+00 -3.90419907e+00  5.26568041e+00
  3.83059175e+01]
supnorm grad right now is: 38.30591754478635
Weights right now are: 
[  4.06067724  -2.84298714   2.76272314   2.51484127  -3.80610853
   2.73429545  -2.36378587  -3.23086965  34.54888937  19.97797606
  11.6733452   10.45107533  17.59475574   7.77595774 -13.81420212
   1.64592631   4.70699605  -0.74907612   9.4337389    2.05548363
  26.83739401  11.86241071   8.57959906  14.87805802   4.6242505
   1.29218684  -2.24485329   2.01692971  -3.10325468   2.39114866
   5.427557    -5.05088072   1.58557727  -4.40453508  17.41956319
  -8.12114575  -1.16515342  -5.24008546  12.67583348  -7.10628883
   2.57845327  -2.02783959  -2.77246974   4.95855333   9.09022728
   1.0213381    3.52816437  16.1463344  -13.97410028  -9.13472003
   2.82402547 -13.308593    17.11998961  19.92165145  -2.34775957
  15.25342147   4.08049633  -3.28785155   2.024597    -3.26298028
   4.70002806   1.03057505   4.44489032  -3.23451808  31.12474843]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -1369.1228830250748
gradient value of function right now is: [-4.18866988e-03 -2.55931004e-02  6.19140724e-01 -4.46928329e-03
  4.18866988e-03  2.55931004e-02 -6.19140724e-01  4.46928329e-03
 -6.40972030e-04  4.59227008e-03  8.68135867e-06  2.24355076e-03
  6.48643816e-02 -3.51377152e-02  4.12716766e-02 -1.23250706e-02
 -1.40700811e+00  3.19627883e-01 -3.80150355e-02  4.06624541e-01
 -9.76610301e-03  9.26594555e-03  2.55223380e-05  6.52372313e-03
  1.88158816e+00  1.04434305e-03  3.46124168e+00 -7.72776287e-02
  5.08803135e-01  5.26911743e-01  4.53584760e-01  3.94932871e-01
  5.16499510e-01  4.04847009e-02  1.29317133e-01  3.54518084e-01
 -4.28785574e-01 -4.18528700e-01 -5.16912553e-01 -2.75172109e-01
 -6.06236076e-01 -1.11452661e+00 -1.10980125e+00 -5.79066032e-01
 -2.37750725e-02 -1.11908458e-01  1.62208880e-02 -2.09416396e-02
 -2.02200750e-02  6.45908331e-03 -1.47878105e+00 -2.07456760e-02
  2.52629376e-02  3.06482035e-02  9.40400807e-01  2.47859183e-02
  6.02410755e-01  8.75810533e-01 -2.56733056e-01  1.15459645e+00
 -4.63969365e-02 -2.28690506e+00  9.79288204e-01  5.99380815e-01
 -1.62933705e+01]
supnorm grad right now is: 16.293370492673457
Weights right now are: 
[  3.97365093  -3.16992933   2.84099072   3.11816097  -3.71908222
   3.06123764  -2.44205345  -3.83418935  37.22647783  19.00289712
  12.21520366  14.16695602  19.11444658   8.2921883  -14.6462168
   1.59905245   4.38188376  -0.81939597   9.3348115    1.9193352
  29.50722635  11.59129341  10.36334969  18.79577452   4.89247727
   1.64525584  -1.80037362   2.59551055  -3.16100146   2.83976565
   5.68090548  -4.78807393   1.91648425  -4.93058331  18.16514612
  -8.30853925  -1.45763106  -6.0208442   12.84981301  -8.00957266
   2.65411394  -1.67593219  -3.23400409   4.92906865  10.80156381
  -0.45333793   2.87315749  18.39208064 -15.44706641  -8.67545836
   2.76904368 -14.84319536  18.63056029  22.4508615   -2.27736389
  16.51208585   4.08872068  -3.16542181   1.74946391  -3.08932042
   4.41722931   0.88177649   4.2629023   -3.17117542  30.84888033]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1370.8918807099465
gradient value of function right now is: [-1.51262039e-02 -1.36534685e-01  1.61234146e+00 -4.35248268e-02
  1.51262039e-02  1.36534685e-01 -1.61234146e+00  4.35248268e-02
  5.44172573e-03  5.93816819e-03  3.13745341e-06  8.76082492e-04
 -3.99159473e-02 -5.74835907e-02 -1.82656523e-02 -2.40992867e-02
 -1.12288394e+00 -2.68468686e+00 -6.78549370e-02 -1.65266491e+00
  1.62759600e-02  1.68268904e-02  1.07869810e-05  3.00585771e-03
  1.60360164e+00  3.10504737e-02  2.80271120e+00  3.98148060e-02
 -3.93860199e-01  7.67283635e-02 -2.44067887e-01 -1.23851479e-01
  4.73119897e-01  9.91502118e-02  2.18438847e-01  2.68234199e-01
  7.42643684e-01  1.56762554e-01  3.69139494e-01  3.90558110e-01
 -4.45101386e-01 -8.73644594e-01 -1.05919101e+00 -4.48188440e-01
  6.34810191e-03 -2.51586562e-03  4.04857865e-01  7.94586226e-03
 -5.64235245e-02 -1.47608160e-01 -2.08899037e+00 -6.45562461e-02
  4.13783664e-02  8.90003220e-02  1.23102943e+00  4.66262978e-02
 -3.81132373e-02  1.80025444e+00 -1.39610871e+00  3.03900325e+00
  3.91589193e-01 -2.44347248e+00  1.82259984e-01  1.84105161e+00
  1.01147860e+00]
supnorm grad right now is: 3.0390032510281992
Weights right now are: 
[  2.67124579  -3.43871211   2.91343397   2.46632416  -2.41667708
   3.33002042  -2.5144967   -3.18235255  40.3516779   19.90931005
  12.61478981  15.55666444  20.52603395   8.97126033 -15.44838887
   1.93035152   3.98897859  -0.88361191  10.65438196   1.78762201
  32.18061594  12.35761861  11.82453759  20.73877372   4.76532548
   1.84111764  -1.79529857   4.98155124  -3.37549818   2.72084688
   5.71241353  -4.98565645   2.07461776  -5.57675742  18.61733181
  -8.65987597  -1.55926472  -6.31216487  13.25442817  -8.22937805
   2.64896096  -1.53264945  -3.02306396   4.9022458   14.78388007
   0.88410117   2.75919488  22.58375938 -16.33614337  -7.34631278
   2.8609988  -15.77654574  19.10021829  24.47775056  -2.31451767
  16.82315157   4.32987257  -3.28388432   1.52898818  -3.184258
   4.3740062    1.11350857   4.38412051  -3.1520993   31.04221297]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.2727593429022
gradient value of function right now is: [ 8.83328729e-03  1.59840439e-01  1.32483917e+00  3.68221462e-02
 -8.83328729e-03 -1.59840439e-01 -1.32483917e+00 -3.68221462e-02
 -3.20894384e-03 -5.87546507e-03 -1.57959552e-06 -1.00186390e-03
  4.69349954e-02  2.38164233e-01  1.02389829e-01  1.57228836e-01
 -3.83726069e-02 -6.46267178e-01  6.96477488e-04 -1.05835186e-01
 -1.96123328e-02 -4.20062171e-02 -8.68353714e-06 -5.34908622e-03
  2.03815367e-01  8.26044378e-02 -8.76757458e-02  6.59890597e-02
 -6.21531518e-01 -2.61563947e-01 -6.29578160e-01 -1.66279621e-01
  2.73039115e-01  9.94612585e-02  1.03007165e-01  2.62754563e-01
  3.02211505e-02  1.21109041e-01  1.30827102e-01  1.90987449e-03
  3.93728119e-02  2.38018825e-01 -4.21386548e-01  3.04703522e-02
  6.25401338e-03  5.73087292e-02  1.10269319e-01  6.39322343e-03
  3.66459601e-02  6.12707622e-02  1.73182985e-01  4.12763648e-02
 -2.60278902e-02 -6.99735131e-02 -1.68470810e-01 -2.90728023e-02
  1.25012630e-02 -8.99846514e-01  8.17713504e-01 -1.13060484e+00
 -1.48111912e-01  6.02990820e-01 -1.08444354e-01 -1.02727937e+00
 -2.06947987e-01]
supnorm grad right now is: 1.3248391680078737
Weights right now are: 
[  2.90633638  -3.12769053   2.77475611   3.78417949  -2.65176767
   3.01899884  -2.37581885  -4.50020788  42.3147827   18.28836278
  12.30170948  16.36286459  21.48123065  10.37810021 -15.31652175
   2.8353372    4.31913637  -0.94027138  12.77352095   1.74012201
  33.13096442  11.09730883  11.20527373  20.67891442   4.4383324
   1.8399854   -1.82166017   8.20848123  -3.3247707    1.8250418
   6.11443056  -6.30214179   2.19973418  -5.21448179  19.0744341
  -8.75590093  -1.50954805  -7.65001127  13.23546758  -8.31995496
   2.41540566  -1.21101579  -3.00652068   4.549625    18.0593735
   0.83998512   2.9167282   25.78721515 -17.90231338  -6.18663475
   2.67891378 -17.25508764  19.31424984  26.09473993  -2.49745939
  16.90546676   4.49582511  -3.56782889   1.72129218  -3.32521168
   5.00643027   1.037242     4.5022182   -3.39863984  31.03791633]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.412274920072
gradient value of function right now is: [ 1.63446478e-02  1.97074677e-01  1.80448860e+00  5.77697420e-02
 -1.63446478e-02 -1.97074677e-01 -1.80448860e+00 -5.77697420e-02
 -9.87808811e-03 -9.09191427e-03 -1.35413242e-06 -1.44220280e-03
  1.18436403e-01  3.19907521e-03 -6.44275641e-02 -7.56044225e-02
 -1.47868085e+00  2.47937731e+00  8.29978661e-02  2.34947866e+00
 -5.01072849e-02 -4.46635384e-02 -5.09580697e-06 -5.34847452e-03
  2.64509555e+00  7.05165759e-01  4.06283238e+00  2.46857711e-02
 -2.07860880e-01 -4.82904699e-02 -3.42674386e-01  1.03573802e-01
 -9.56194911e-01 -3.15605790e-01 -4.95126506e-01 -6.53135578e-01
 -9.28633938e-01 -3.25248301e-01 -5.54450748e-01 -5.38221458e-01
 -2.66652751e-01 -1.38158620e+00 -5.58641715e-01 -2.57154855e-01
 -4.37024809e-02 -3.29934204e-01 -9.64964401e-01 -4.47843328e-02
  1.16785427e-01  4.94521190e-01  3.58547152e+00  1.27047689e-01
 -6.04456350e-02 -2.13322549e-01 -2.03026715e+00 -6.67296451e-02
  1.35705091e+00 -3.51194565e+00  1.99930108e+00 -6.36568866e+00
 -1.81673061e+00  6.83176053e+00  1.66339048e+00 -3.93260773e+00
 -1.86625071e+01]
supnorm grad right now is: 18.66250712407588
Weights right now are: 
[  3.51700699  -2.9104715    2.74650014   4.32111746  -3.26243828
   2.80177981  -2.34756287  -5.03714584  43.81611043  17.10763243
  12.20859091  14.07579358  23.25822468  10.32184141 -16.29919473
   2.30057039   4.60610944  -0.93670292  13.47998758   2.36478493
  33.99081691  11.96986136  10.95852309  18.88029481   4.47193605
   2.43018965  -1.73152855  10.84336164  -3.21545934   0.6858818
   6.00283733  -7.53267143   1.78124258  -5.2832908   18.78058989
  -9.61814095  -1.17295263  -9.75654239  13.0983078   -8.48824515
   2.42542008  -1.27878587  -2.6744045    4.53586459  19.71422386
   0.62636362   2.40870871  27.46044601 -19.47012155  -4.50080305
   2.63007595 -18.7785106   20.02433723  28.21136255  -2.68812471
  17.41479365   4.72248331  -3.65969038   0.9415684   -3.22088346
   5.08503678   0.79530855   4.86294499  -3.52154342  30.98295834]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1370.233719034806
gradient value of function right now is: [ 9.27839761e-03  1.29364536e-01  4.03327965e+00  3.16874807e-02
 -9.27839761e-03 -1.29364536e-01 -4.03327965e+00 -3.16874807e-02
 -7.66643904e-03 -1.30851973e-02 -6.27620122e-07 -1.03526715e-03
  6.41349235e-02  1.00293545e-01  1.14771833e-02  2.34742492e-02
 -1.56037919e+00 -2.15461876e+00 -8.76025381e-04 -4.52803152e-01
 -2.92296921e-02 -4.55982529e-02 -1.79470108e-06 -2.90532187e-03
  3.21756069e+00  5.34512171e-01  4.47538670e+00  2.09835998e-02
 -1.01688421e+00 -3.07436269e-01 -1.05555844e+00 -5.69615775e-02
  5.51530093e-02  1.36330422e-02  2.26624191e-02  3.73339658e-02
  3.75068653e-01  1.91432332e-01  3.16603984e-01  7.26144736e-02
 -3.28859355e-01 -1.66045955e+00 -1.17826426e+00 -3.30784723e-01
 -1.61329869e-02 -2.27404178e-01  6.47892095e-02 -1.55763937e-02
  3.87550910e-02  2.74548595e-01  8.46236225e-02  3.96980724e-02
 -7.47063556e-03 -4.41634126e-02  8.08580583e-03 -7.69966048e-03
  7.31977119e-01 -5.56128736e-01  3.25302377e-01 -3.20914475e-01
 -7.59378300e-01  1.03534470e+00  9.71983876e-01 -7.10944803e-01
 -1.42421252e+01]
supnorm grad right now is: 14.242125213893102
Weights right now are: 
[  4.97156805  -2.74749985   2.71385952   4.76114879  -4.71699934
   2.63880816  -2.31492225  -5.47717717  45.18084142  15.56509942
  11.99640896   8.81957092  24.3625769   11.28760659 -16.2661352
   2.33154993   4.43132275  -1.16027299  12.19642328   2.19247039
  35.74879231  12.45896099  10.19580841  12.86675264   4.40845144
   3.38786776  -1.8094182   17.67934503  -3.40251434  -0.44958861
   5.76965811  -9.73674666   2.33867638  -5.59186023  18.85720831
  -9.85292093  -1.39989079 -11.03719707  13.40450702  -9.81171726
   2.36716442  -1.20086224  -2.91585972   4.51029873  21.21474022
   1.78404891   2.49503531  29.0217575  -20.56590327  -3.49054502
   2.49943543 -19.80998617  20.79980081  29.96625247  -2.52290405
  17.97417367   4.8635577   -3.66099405   0.49984543  -2.86297788
   4.78328137   1.07524815   4.94513495  -3.51849222  30.95221665]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1370.7586584488063
gradient value of function right now is: [-2.63159003e-03 -3.23532880e-02 -2.89809948e+00 -8.48925961e-03
  2.63159003e-03  3.23532880e-02  2.89809948e+00  8.48925961e-03
  2.90434990e-03  3.37851157e-03 -1.68723475e-07 -6.37602985e-04
 -3.74813918e-02  2.30291862e-02  3.34857294e-02  5.16316342e-02
  5.06476623e-01  4.75207651e+00  5.17952539e-02  3.00425315e+00
  8.68836688e-03  9.79243938e-03 -3.19428145e-08 -6.70101667e-04
 -1.02455414e+00 -1.10086648e-01 -1.38510664e+00 -5.09266233e-03
  3.83820557e-01  9.22538530e-02  3.64113201e-01  5.18880003e-02
 -3.64756553e-01 -6.32753678e-02 -1.67794594e-01 -1.29499214e-01
 -1.46971741e+00 -3.11088471e-01 -7.53471895e-01 -5.14481414e-01
  1.30013244e-01  5.53647059e-01  3.33077949e-01  1.25065784e-01
 -2.06597609e-02 -6.51940968e-02 -1.03560775e+00 -2.47099562e-02
  7.73856647e-02  2.44056739e-01  3.33128743e+00  9.11334840e-02
 -5.75289759e-02 -2.14915727e-01 -2.14115390e+00 -6.61467111e-02
  1.93790553e-01 -3.33515491e+00  1.43203628e+00 -7.46357115e+00
 -4.44763602e-01  4.56592704e+00  1.83758045e-01 -3.73776435e+00
  4.43286065e+00]
supnorm grad right now is: 7.463571145092994
Weights right now are: 
[  5.48880933  -3.33212924   2.47406718   4.58509694  -5.23424062
   3.22343755  -2.07512992  -5.30112532  46.36894552  15.00257578
  11.83916197   5.80787293  23.25198359  12.10374366 -16.62827392
   2.26956834   4.52835203  -1.10521952  12.63805161   2.56610429
  37.86923809  12.93757327   9.80840755   9.41167021   4.3685598
   3.54363529  -1.75682451  24.29079187  -3.22531923  -0.92666308
   6.24747592 -12.87390917   2.5626218   -5.56602233  18.83364985
 -10.53256203  -1.13005606 -12.45884162  13.54227877 -10.72552219
   2.27337366  -1.08543436  -3.10921409   4.53475815  22.43066647
   2.90557865   2.25481913  30.29634283 -21.34029199  -2.62158706
   2.56206609 -20.5229956   21.54552671  31.67498642  -2.62413843
  18.38600797   4.85044795  -3.89044305   0.12319273  -3.13677455
   5.4552275    0.91453105   5.07775058  -3.71448171  31.08873755]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.0768752888841
gradient value of function right now is: [ 8.81907995e-03  4.11423374e-02  1.54270026e+00  1.64312624e-02
 -8.81907995e-03 -4.11423374e-02 -1.54270026e+00 -1.64312624e-02
 -6.29908442e-03 -1.10855300e-02 -2.48871872e-06 -2.43142859e-03
  3.20522964e-02 -4.17409074e-02 -6.01869301e-02 -6.47016096e-02
 -5.31560453e-01 -1.30986250e+00  4.78322258e-03 -8.41508301e-01
 -1.17378894e-02 -1.61868785e-02 -2.41626019e-06 -2.49082305e-03
  1.22161984e+00  5.33982996e-02  1.58323622e+00  3.37914067e-03
 -2.97303366e-01 -9.37768929e-02 -2.14813260e-01 -2.88685268e-02
 -1.95186254e-01 -3.46664638e-02 -3.74934705e-02 -1.35223574e-01
  5.64580278e-01  1.88410124e-01  3.12189352e-01  1.05375941e-01
 -1.48125067e-01 -5.35780554e-01 -4.06990380e-01 -1.51425811e-01
  4.66908047e-03  9.22347468e-02  2.37973650e-01  5.47095894e-03
  1.89041358e-03 -6.14572768e-02 -7.90462575e-02  1.01876034e-03
  2.69081675e-03  9.69414234e-03 -1.03951903e-01  3.41120362e-03
  4.09625530e-02  1.97043352e-01 -5.19684300e-01  6.33862411e-01
 -3.10157380e-01  7.77559515e-01  8.58319017e-02  2.04778099e-01
  7.22675728e+00]
supnorm grad right now is: 7.226757282965462
Weights right now are: 
[  5.83695676  -3.41060768   2.58001111   4.73840443  -5.58238805
   3.30191599  -2.18107384  -5.45443282  46.46202133  15.72102485
  11.74208945   3.38891934  25.27536912  12.51806822 -17.0522201
   2.1895289    4.61194036  -1.25743559  14.58992966   2.23147912
  38.22691282  14.25748554   9.56681842   7.12115258   4.45273553
   4.30768589  -1.87798148  28.59632778  -2.6301285   -1.18750433
   6.70678224 -14.89289583   2.72192338  -6.63476896  18.26474591
 -11.28773297  -0.71677704 -13.47851911  13.44055454 -11.59371921
   2.1962034   -1.3196304   -3.72012004   4.48281129  23.85893879
   3.07936205   2.17827547  31.86698142 -21.465688    -1.33705067
   2.5967176  -20.70996542  22.6588257   33.97054531  -2.31366162
  19.173651     5.03765325  -3.81051146   0.15392251  -3.02789244
   4.64205617   1.30772614   5.11440518  -3.61321162  31.1186398 ]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -1369.4636097906323
gradient value of function right now is: [-3.08579173e-03 -6.69768643e-02 -4.98062161e+00 -7.44159610e-03
  3.08579173e-03  6.69768643e-02  4.98062161e+00  7.44159610e-03
  4.15247394e-03  7.00163721e-03  2.31510439e-07 -1.06454138e-04
 -5.46177126e-02 -1.29040716e-01 -6.17005266e-02 -8.16998159e-02
  1.74899579e+00  2.59448424e+00  8.91176520e-03  9.93709133e-02
  8.97418051e-03  1.31163951e-02  3.22822986e-07  1.14922636e-04
 -3.73033282e+00 -1.82219315e-01 -4.61445410e+00 -4.33918883e-03
  1.11639560e+00  1.06550462e-01  9.36306750e-01  1.35790641e-02
 -4.03331328e-01 -4.69269421e-02 -7.79134964e-02 -1.87143234e-01
 -4.18532574e-01  1.12943200e-03 -1.27001613e-01 -6.14930340e-02
  3.65252521e-01  2.36784242e+00  1.01256799e+00  3.80859970e-01
 -6.41746294e-04  2.53383445e-01 -4.63694330e-01 -9.56519515e-04
 -4.17521225e-02 -8.09826893e-01  1.00518968e+00 -4.37445320e-02
 -1.34988245e-02 -4.46798560e-02 -9.82912460e-01 -1.52896504e-02
 -8.08617429e-01 -5.14839533e-01 -1.85194777e-01 -1.85855831e+00
  8.71025385e-01  9.40423417e-01 -1.15283622e+00 -5.15980104e-01
  1.68066643e+01]
supnorm grad right now is: 16.80666433576494
Weights right now are: 
[  6.82609084  -3.99442995   2.1843663    5.25235594  -6.57152213
   3.88573826  -1.78542904  -5.96838432  46.68575237  14.3481616
  11.28639518  -1.18311373  24.09262858  12.89836595 -18.33228484
   1.51279043   4.85216055  -1.22101088  15.45300889   2.21982148
  39.44721715  13.56061662   9.09841427   2.45709595   4.17647902
   4.76653169  -2.07756557  31.02503681  -3.14127411  -2.71889879
   6.30794691 -17.60586002   2.80032241  -5.92588072  18.66466392
 -12.10661239  -0.27143973 -14.96423141  13.38278137 -12.18847263
   3.06402853  -1.1044448   -4.51658973   5.44409501  25.64293741
   4.44155765   1.5242424   33.65598147 -21.45925508  -0.71941348
   2.75484441 -20.78265498  24.5372554   36.31556923  -2.48008529
  20.59918406   5.3901236   -3.75490081  -0.29178024  -3.10478429
   5.16239016   0.99724042   5.27531769  -3.65698693  31.07309288]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1368.4980314281972
gradient value of function right now is: [ 3.76334503e-04 -8.76276970e-02 -1.96022306e+00 -1.91438594e-03
 -3.76334503e-04  8.76276970e-02  1.96022306e+00  1.91438594e-03
  8.01070595e-04 -5.13499516e-03  8.11746277e-05 -3.63399356e-03
 -1.94766669e-02 -3.27159339e-01 -2.55693654e-01 -3.19348405e-01
  8.66416187e-01  2.40641853e+00  6.58182189e-02  1.45377716e+00
  2.34203597e-03  6.78833318e-04 -3.56714657e-07 -6.55483930e-04
 -1.63593167e+00  5.42274341e-02 -2.13002046e+00  6.92741517e-04
  4.72375695e-02 -8.98405189e-02  2.60768096e-02 -1.80643017e-03
 -1.65880499e+00 -2.84462010e-01 -3.69852097e-01 -7.66802759e-01
 -6.63652340e-01  7.70670323e-02 -4.13414754e-02 -1.75457617e-01
  2.46527895e-01  7.11832130e-01  8.04210467e-01  2.35746936e-01
 -1.84040295e-02 -1.87257993e-02 -1.30339011e+00 -2.35570843e-02
  4.01111231e-02  1.42848015e-01  4.38187771e+00  5.73837101e-02
 -7.18356920e-02 -2.76278061e-01 -4.41994745e+00 -8.77546761e-02
  1.13288624e-01 -3.50319523e+00  1.85264947e+00 -1.05165323e+01
 -1.04219132e+00  6.90964102e+00  8.01515883e-02 -4.02965223e+00
  6.16824466e+00]
supnorm grad right now is: 10.516532311643946
Weights right now are: 
[  6.01577563  -3.4925976    2.3050511    4.46131948  -5.76120692
   3.38390591  -1.90611383  -5.17734787  48.08134362  14.76889519
  10.06004878  -5.74663024  24.66493898  13.69796573 -17.9106595
   1.83577967   4.33463758  -1.33213565  14.46834493   2.29672069
  41.17683083  16.38434533   8.97669998   0.88295797   4.00328273
   5.52322505  -2.2947087   36.6023292   -2.49047528  -3.38353147
   6.84537736 -22.37798995   3.65882036  -6.60918336  18.720179
 -12.60813496   0.05393933 -15.94059704  13.13402282 -13.89898612
   2.95961001  -1.3913542   -4.42947408   5.66260468  28.72495544
   5.17515997   1.76713217  36.72260732 -20.76952877  -0.45777562
   2.86169555 -19.99757705  25.57785539  38.98621282  -2.31751757
  21.27182547   4.89133624  -3.75864135  -0.32302663  -3.1860684
   5.058163     1.44569931   5.22891622  -3.50134265  31.11068999]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1370.936023081869
gradient value of function right now is: [-1.69421655e-03 -2.29640815e-02 -2.56162526e+00 -3.37602220e-03
  1.69421655e-03  2.29640815e-02  2.56162526e+00  3.37602220e-03
  1.68968000e-03  2.19475267e-03  1.06599893e-05 -1.14289085e-03
 -1.76846804e-02 -3.71425946e-02 -2.54002457e-02 -2.54684107e-02
  1.80425561e+00  5.31682689e-01  2.04893983e-03 -2.19893332e-01
  5.21266782e-03  5.20366142e-03 -8.97354316e-08 -1.65650406e-04
 -4.58442071e+00  2.17608238e-02 -5.11486932e+00 -4.43216554e-03
  4.02808290e-01  6.89090339e-04  2.30350254e-01  8.70664551e-03
 -5.15213168e-02 -2.54191591e-02 -1.70210171e-02 -3.87135823e-02
  8.79130122e-02  3.66887659e-02  4.25760312e-02  2.70316995e-02
  4.46366925e-01  9.24863985e-01  1.37939652e+00  4.26631266e-01
  8.86428528e-03 -1.06780690e-01  1.06413314e-01  9.50198624e-03
 -1.31894252e-01  4.93384020e-02 -1.16641615e+00 -1.37340225e-01
  1.79153479e-02  4.35229589e-02  3.55168871e-01  2.08061810e-02
 -6.44576237e-01  2.10799975e+00  8.35014666e-02  9.46748323e-01
  9.97231447e-01 -2.19581203e+00 -9.25791928e-01  2.43003656e+00
  1.65247318e+01]
supnorm grad right now is: 16.52473182420304
Weights right now are: 
[  5.41285305  -3.71726624   2.34695879   6.64925923  -5.15828434
   3.60857455  -1.94802152  -7.36528761  47.69082219  14.79939961
  13.21347148  -6.75581641  27.93768314  13.96651235 -18.18824888
   1.6157       4.86695913  -1.25566331  16.26864212   2.33173767
  39.54434902  16.86908367   9.00463402   1.5628301    3.87806517
   5.95882886  -2.57698467  38.26382386  -1.95658913  -4.34301321
   6.6790505  -26.70415232   4.04584098  -7.80712805  17.77897928
 -12.83647055   0.41876661 -16.42574362  13.07433106 -14.38320454
   2.2866455   -2.16929816  -4.40335035   5.76126345  30.64191601
   4.58559846   1.89949268  39.05523693 -20.72960669   0.10055074
   2.89392585 -19.6942183   26.89650146  41.33933931  -1.97941708
  21.75892639   4.96027108  -3.79226042  -0.4308836   -3.28238513
   4.91459173   1.15810778   5.42187487  -3.5754111   31.04161944]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1370.3602100945527
gradient value of function right now is: [-1.41305774e-02 -5.58543742e-02 -2.35884432e+00 -1.69214111e-02
  1.41305774e-02  5.58543742e-02  2.35884432e+00  1.69214111e-02
  7.55598144e-03  2.60224223e-02 -2.01447787e-05  1.24193272e-02
 -5.08393289e-02  3.92984048e-02  7.38103496e-02  9.42474699e-02
  3.02844910e-01 -1.62662683e-01 -2.65386363e-02 -6.88430474e-01
  2.01417278e-02  2.62087482e-02  5.93486429e-07  1.55990790e-03
 -1.25160773e+00 -2.50616626e-01 -5.55848588e-01 -3.68662173e-03
  1.32024300e+00  3.06005627e-01  9.03089792e-01  9.48342415e-03
  6.70128422e-01  1.70939037e-01  1.70510342e-01  3.02013450e-01
  1.31123044e-02 -2.81945054e-01 -3.60421328e-01  1.30449071e-01
 -8.27595319e-02  3.26254918e-01  9.22641016e-03 -7.53073429e-02
  2.84607958e-02  5.43904682e-02  1.12829262e+00  3.02896710e-02
 -8.44546734e-02 -6.82603753e-01 -2.65527652e+00 -8.72410229e-02
  3.85619096e-02  1.57450842e-01  2.10839074e+00  4.37147581e-02
 -6.10991404e-01  3.32946778e+00 -5.25904174e-01  6.33294341e+00
  1.24421179e+00 -5.55614525e+00 -5.29582851e-01  3.60786963e+00
  2.32397351e+00]
supnorm grad right now is: 6.3329434140503365
Weights right now are: 
[  4.20158893  -3.8768844    2.37400865   6.3189856   -3.94702022
   3.76819271  -1.97507138  -7.03501398  49.37172886  15.55419815
  13.35057432  -6.40365018  28.20003486  14.19659858 -18.29861754
   1.33257458   4.86084111  -1.28811049  15.65680092   2.65506397
  41.39419101  16.67052962   8.98503268   3.78732243   3.88651079
   5.91772281  -2.39959644  41.84518839  -1.93143558  -5.41522275
   7.07522968 -31.66619249   4.61893669  -7.40651318  18.37625961
 -13.38095526   0.86826874 -17.96161703  12.42239051 -14.58844019
   1.97033229  -1.93547566  -5.82372055   6.13911588  32.53292598
   4.2188046    1.51064662  41.6258466  -21.18256119  -0.53693993
   2.95419984 -20.15888703  28.13624114  44.08633222  -2.08541207
  22.0492561    4.97746405  -3.64941385  -0.87268475  -3.09332198
   5.10672741   0.87485331   5.73587642  -3.44234529  30.94630685]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1364.773050540626
gradient value of function right now is: [-7.47194067e-03 -1.28339054e-02  3.81476398e-01  1.50499687e-02
  7.47194067e-03  1.28339054e-02 -3.81476398e-01 -1.50499687e-02
 -4.98505214e-03  6.97941043e-02  5.55258779e-04  7.03999423e-02
  5.25820209e-02 -3.32348353e-01 -2.53653116e-01 -3.58495976e-01
 -1.45235495e+00  5.69981052e+00  7.32698471e-02  4.31962628e+00
 -2.16094645e-02 -1.47996675e-02 -2.99855755e-06 -1.67372863e-03
  3.53658910e+00  1.32056127e-01  3.40100523e+00 -2.54528467e-03
 -3.48589736e-02  6.22801997e-03 -1.57154032e-01  1.66416049e-02
 -2.27261469e+00 -6.02988606e-01 -5.71076040e-01 -8.05685977e-01
 -2.61650503e+00 -4.51591717e-01 -7.39149259e-01 -2.62730117e-01
 -1.49909259e-01 -1.56967647e+00  6.74252331e-02 -1.20211985e-01
 -7.41960702e-02 -9.11585931e-01 -4.07634385e+00 -7.27361029e-02
  1.50754036e-01  1.77094190e+00  5.81226071e+00  1.43429154e-01
 -8.10109251e-02 -3.87841503e-01 -5.20098824e+00 -8.63844939e-02
  2.01520107e+00 -6.24676230e+00  5.25446163e+00 -1.96638561e+01
 -3.22391407e+00  9.86731361e+00  2.05420853e+00 -6.35384294e+00
 -2.22533063e+01]
supnorm grad right now is: 22.253306288430924
Weights right now are: 
[  3.67360796  -3.47967933   2.46048473   6.53443218  -3.41903925
   3.37098764  -2.06154746  -7.25046057  50.49817959  14.40225211
  17.70265257  -7.67132711  30.03978434  14.07709794 -19.0250469
   0.67693511   4.61262846  -1.19378527  15.96744999   2.76081935
  41.5456102   17.78746012   8.96815619   1.99960821   3.90749049
   5.74521452  -2.44510423  46.85042112  -1.33553923  -5.52158969
   7.50255495 -33.80351561   4.875288    -9.72895497  16.28716142
 -14.53742072   0.90574968 -18.27551357  12.28548401 -16.43703691
   1.94582812  -1.91153837  -5.76886737   6.66437072  34.26433121
   4.51952177   1.52174382  43.97077895 -19.94789601  -0.35601724
   3.28485528 -18.75574679  29.21700105  46.18770772  -2.14545728
  22.14647797   5.269105    -3.82828401  -0.57691902  -3.30896128
   4.56985627   1.18734688   5.8135378   -3.67875119  31.05272675]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.7329942748786
gradient value of function right now is: [ 7.27236052e-03  8.96882004e-03  5.25961238e-01  5.49419657e-04
 -7.27236052e-03 -8.96882004e-03 -5.25961238e-01 -5.49419657e-04
 -5.37286843e-04 -4.08086887e-02 -5.82485602e-04 -3.67647521e-02
 -1.00417128e-03  4.72124588e-02  3.00193415e-02  4.31814690e-02
  5.31117397e-01 -2.25687660e+00 -2.35319801e-02 -1.66644814e+00
 -1.63150912e-04 -1.34193975e-03 -2.92579513e-08 -3.31563727e-05
 -1.44947391e+00 -1.80766365e-02 -1.52287054e+00  1.36564364e-03
 -2.39746106e-01 -4.08062359e-02 -8.63881921e-02 -7.41900748e-03
  4.66458021e-01  1.53597537e-01  1.45504832e-01  1.94245339e-01
  3.95679645e-01  1.28658609e-01  1.72547734e-01  5.11118541e-02
  7.52437330e-02  6.55091846e-01 -1.78274455e-02  5.18225471e-02
  7.40882131e-03  2.35977356e-01  5.09195162e-01  6.30552891e-03
 -2.07067628e-02 -5.70464887e-01 -6.61753616e-01 -1.31966716e-02
  5.84307610e-03  4.88541508e-02  7.25785411e-01  7.00169339e-03
 -4.06699553e-01  4.62936964e-01 -8.66144879e-01  2.98200255e+00
  5.51213331e-01 -1.58339482e+00 -3.63498305e-01  4.91470307e-01
  5.62179652e+00]
supnorm grad right now is: 5.62179651936465
Weights right now are: 
[  3.47778598  -3.68914821   2.51694389   5.40420313  -3.22321727
   3.58045651  -2.11800662  -6.12023151  51.71213024  13.4603629
  19.2080409   -8.4054226   31.69544236  14.80741756 -18.30381256
   1.08946899   4.70919605  -1.30840475  15.6936293    2.26239235
  42.88562882  19.46173918   8.93059551   4.14305699   3.74131286
   6.20258297  -2.66943835  51.35857433  -1.62597635  -6.43808938
   7.48562226 -34.73250332   5.53762159  -8.03496531  17.91560058
 -14.20102698   1.93523999 -18.08188148  12.6601805  -17.27348635
   1.25967122  -2.03731952  -7.02963758   6.58888121  35.71107086
   4.13179152   1.71928466  45.95107191 -19.36277937  -0.47943878
   3.3676451  -17.91908039  30.60433379  47.65175849  -2.22046685
  22.78728041   5.36368401  -4.02518251  -0.53449629  -3.39621902
   5.62747639   0.92329547   6.32012724  -3.75861842  31.02052789]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.2169993067378
gradient value of function right now is: [-6.58568648e-03 -4.46743816e-02 -7.47034180e-01 -1.18356066e-02
  6.58568648e-03  4.46743816e-02  7.47034180e-01  1.18356066e-02
  7.15338854e-03 -2.20237368e-02 -2.62518037e-04 -2.65359142e-02
 -3.53220902e-02  3.10617180e-04  2.81977565e-02  3.70394387e-02
  1.28366955e-02 -1.45398753e+00 -1.01021331e-02 -1.53703780e+00
  9.50147902e-03  1.04828985e-02  2.88401155e-07  1.06136962e-04
 -1.67378294e-01 -8.66349324e-02  3.28183221e-01  3.04274527e-04
  4.48651170e-01 -9.20542052e-03  2.61957733e-01 -3.08323791e-03
  2.77361633e-01  8.18589956e-02  6.70628219e-02  9.86619429e-02
  9.36895105e-01  3.60796798e-01  4.05836479e-01  8.06085932e-02
 -6.43902573e-02  4.91851066e-02 -1.41077311e-01 -4.66377973e-02
  2.24814466e-02  6.83886535e-01  1.03691179e+00  1.52975595e-02
 -2.07082422e-02 -1.05573901e+00 -1.06232512e+00 -1.34729008e-02
  1.32683748e-02  7.74549176e-02  8.57779497e-01  1.31705798e-02
 -5.96700593e-01  1.42453998e+00 -2.03604566e+00  5.08431090e+00
  5.24618548e-01 -1.85712643e+00 -2.85164352e-01  1.16678728e+00
  8.04104885e+00]
supnorm grad right now is: 8.041048849265616
Weights right now are: 
[  4.09566502  -3.9985525    2.37321723   4.19394561  -3.84109631
   3.88986081  -1.97427996  -4.90997399  52.47563974  13.13122317
  25.13292946  -8.12190614  31.90126275  15.40980238 -18.33784644
   1.19011471   4.81300552  -1.10300502  18.15177472   2.39827771
  45.28463013  18.46892695   8.89110065   2.18421125   3.63036605
   7.11518435  -2.31041666  57.23299672  -1.38722344  -6.79985419
   7.54280698 -36.63846489   5.79339538  -8.46647596  17.57468971
 -14.47158963   2.31482199 -17.55647596  13.00367511 -17.2950253
   1.70411962  -2.50842448  -6.79420944   7.80442289  36.85909463
   4.15240185   1.40168387  47.71521203 -20.12809791  -0.09100934
   3.61856538 -18.53378509  32.69389769  49.43491827  -2.03565725
  24.12448671   4.88926618  -4.01021672  -1.18989063  -3.38378837
   5.26385268   0.97362469   6.25375283  -3.84616122  31.03035599]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1368.6304732448455
gradient value of function right now is: [ 1.77628234e-02  5.81997476e-02  4.73644380e+00  1.15877792e-02
 -1.77628234e-02 -5.81997476e-02 -4.73644380e+00 -1.15877792e-02
 -6.35015384e-03 -4.06253363e-02 -2.90852468e-04 -2.22238149e-02
  4.12221779e-02  6.82696250e-02  2.22260606e-02  3.03247619e-02
 -1.16160297e+00 -4.06114000e+00 -1.40721490e-02 -1.60798416e+00
 -8.74617359e-03 -1.12699764e-02 -1.91476427e-07 -1.94077910e-04
  3.84987656e+00  1.39760649e-01  3.09947853e+00  8.66837247e-04
 -1.55957562e+00 -1.92289019e-01 -7.80780685e-01 -4.59315558e-03
  3.34381397e-01  7.06969490e-02  5.03639224e-02  1.04895201e-01
  1.31615119e+00  2.79880677e-01  3.76290894e-01  8.83397906e-02
 -1.19610656e-01 -1.03740937e+00 -3.90874389e-01 -8.83020115e-02
  6.95532706e-03 -6.50893742e-02  1.23560214e+00  1.17324175e-02
  9.78215203e-02  1.15003887e+00 -3.22908095e-01  6.77689191e-02
  1.88583633e-02  8.27128777e-02  1.35050504e+00  2.18886391e-02
  7.83714875e-01  6.04809416e-01 -1.31367908e+00  5.26085700e+00
 -9.50067397e-01 -2.55528570e-01  4.77674105e-01  8.10675872e-01
 -1.11220475e+01]
supnorm grad right now is: 11.122047473273245
Weights right now are: 
[  3.43246793  -4.05538921   2.68656294   4.09887724  -3.17789922
   3.94669752  -2.28762567  -4.81490563  53.55014386  12.76218659
  25.70158266  -7.70352163  32.2852852   15.5508817  -18.71200055
   0.84483739   5.13418199  -1.35695616  17.33975578   2.70230475
  47.2827573   17.14706479   8.86588962   3.34186797   3.86574921
   6.64459102  -2.33113317  58.91927157  -1.73213471  -6.85015107
   7.60911706 -37.99182993   6.47994589  -8.56429219  17.10567117
 -15.17269322   2.41311221 -19.10864255  12.088314   -18.63820101
   1.27865064  -1.88019044  -8.16795607   8.27045581  37.93200324
   3.93676624   1.29743776  50.14539439 -21.22355132   0.3666426
   3.59494461 -19.23933427  34.66032033  51.57936049  -1.91703728
  24.71871179   4.64987845  -3.8773381   -1.29532728  -3.24159847
   4.78619639   1.20547481   6.02929467  -3.59560975  30.87313656]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.017378335345
gradient value of function right now is: [-1.45865841e-02 -3.50136821e-02 -2.06334891e+00 -1.16567541e-02
  1.45865841e-02  3.50136821e-02  2.06334891e+00  1.16567541e-02
  5.40279293e-03  2.12209794e-02 -2.15429787e-05  7.51465398e-03
 -2.15022490e-02 -3.14584287e-02 -1.27811762e-02 -1.19856791e-02
  1.22271937e+00 -3.17712971e-01 -9.47098684e-03 -3.74083614e-01
  1.12490435e-02  1.41549192e-02  7.17380810e-07  2.92362435e-04
 -3.86207914e+00 -8.72595994e-02 -3.50190860e+00 -1.66339478e-03
  4.18840754e-01  5.64110271e-02  1.90410846e-01  4.60840961e-03
  2.11783880e-01 -3.05294877e-03 -6.55139769e-04  3.28168137e-02
  3.78358848e-01 -3.05875519e-02 -2.83320967e-02  8.01519341e-02
  2.08834416e-01  1.10554796e+00  3.25762554e-01  1.43695977e-01
  2.77307798e-02  1.27314181e-01  7.18622983e-01  2.10965364e-02
 -1.11085094e-01 -6.47065732e-01 -1.28632426e+00 -8.24361473e-02
  3.64092494e-02  8.09997729e-02  1.39320132e+00  3.23184180e-02
 -1.09527500e+00  3.06750855e+00 -5.81464944e-02  3.88330152e+00
  1.11904313e+00 -2.61801373e+00 -1.08602171e+00  2.42867517e+00
  9.92215725e+00]
supnorm grad right now is: 9.922157252278833
Weights right now are: 
[  3.61582364  -3.68660002   2.32839435   5.90265395  -3.36125493
   3.57790833  -1.92945708  -6.61868234  53.00481435  13.24074374
  29.18393236  -6.57811287  34.84466033  15.82173704 -19.01461501
   0.64237967   5.18898728  -1.34811367  20.63510442   2.51431304
  46.57163068  17.05101352   8.88042896   5.90644786   3.47548132
   6.9419762   -2.41057636  62.21769315  -0.71702062  -7.8556933
   8.00867786 -40.71509569   6.51743638  -8.41968314  16.80372329
 -15.65312154   2.83831549 -18.89376812  12.30178778 -18.27477847
   0.47790027  -1.70173927  -7.55564123   8.90525955  39.30634099
   4.21121311   1.31484067  52.22730713 -20.86512163   0.25468583
   3.90421948 -18.85324874  36.87877673  53.05180171  -1.8349455
  25.16915472   4.86301888  -3.63217292  -0.36884802  -3.42978572
   5.06640557   1.10463574   5.98833947  -3.63958921  31.00155729]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.614429702508
gradient value of function right now is: [ 4.68980148e-03  1.13365260e-04  1.58421396e+00  3.58094040e-03
 -4.68980148e-03 -1.13365260e-04 -1.58421396e+00 -3.58094040e-03
 -2.29210512e-03 -5.10701119e-03  1.85988092e-05  1.76091397e-03
  1.14740585e-02 -7.98404041e-02 -6.58862568e-02 -9.13843341e-02
 -5.77817641e-01 -7.62986202e-01  9.19903094e-03 -2.38366730e-01
 -3.47078672e-03 -4.88672059e-03 -3.59412079e-07 -3.48227078e-04
  1.66386373e+00  3.46068432e-02  1.49049429e+00  6.39490055e-04
 -4.81672465e-01 -5.55300859e-02 -1.74920497e-01 -4.42051824e-03
 -5.33694223e-01 -8.49963123e-02 -4.93083473e-02 -2.33314564e-01
  2.68883085e-01  9.69108999e-02  1.06704649e-01 -1.22492020e-02
 -9.04029342e-02 -5.00907759e-01 -1.35075190e-01 -5.16723420e-02
 -3.06093859e-03 -1.25746483e-03 -1.01613840e-01 -4.46929674e-03
  4.17642171e-02  3.16545500e-01  6.45702027e-01  3.33879183e-02
 -1.97506720e-02 -6.51086621e-02 -1.64826801e+00 -2.42671420e-02
  3.15473481e-01 -1.15137722e+00  4.14417930e-02 -3.41014934e+00
 -6.21861051e-01  2.16877618e+00  3.49650865e-01 -1.13239374e+00
 -7.55149290e+00]
supnorm grad right now is: 7.551492901466618
Weights right now are: 
[ 3.78028024e+00 -4.50019716e+00  2.42663027e+00  5.62715742e+00
 -3.52571152e+00  4.39150547e+00 -2.02769300e+00 -6.34318580e+00
  5.43794588e+01  1.30631709e+01  3.41865264e+01 -6.56207144e+00
  3.50057687e+01  1.55006555e+01 -1.96941417e+01  1.07312609e-02
  5.04491008e+00 -1.65566565e+00  2.06014942e+01  2.80364699e+00
  4.79092718e+01  1.74654756e+01  8.85017178e+00  5.95376256e+00
  3.34908553e+00  7.51703044e+00 -1.92542940e+00  6.49955206e+01
 -7.99370371e-01 -8.73422872e+00  8.19072452e+00 -4.36588767e+01
  7.06115346e+00 -8.37048859e+00  1.64604141e+01 -1.58914225e+01
  3.03555755e+00 -1.98830647e+01  1.13844256e+01 -1.95358474e+01
 -3.43102017e-01 -1.94333946e+00 -6.82631343e+00  9.81849482e+00
  4.03120436e+01  4.34971862e+00  1.62563105e+00  5.46707524e+01
 -2.16809812e+01  5.66391446e-01  4.05565174e+00 -1.98909222e+01
  3.69660426e+01  5.50505775e+01 -2.20993715e+00  2.34975262e+01
  4.64775929e+00 -4.09170479e+00 -1.03008414e+00 -3.41664090e+00
  4.89833348e+00  1.42851587e+00  6.28971907e+00 -3.71706753e+00
  3.09993828e+01]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.1256967517204
gradient value of function right now is: [-3.41560531e-03 -3.31633840e-02 -1.60202775e+00 -4.42700635e-03
  3.41560531e-03  3.31633840e-02  1.60202775e+00  4.42700635e-03
  1.91126090e-03  5.81697874e-03  1.11520666e-04  4.69076169e-03
 -1.33476578e-02 -1.01383134e-01 -7.14534307e-02 -9.11826394e-02
 -5.58433912e-02  2.54148844e+00  2.08446495e-02  1.31513900e+00
  3.60372269e-03  3.54268578e-03 -1.88366812e-08 -1.02906600e-04
 -9.32304795e-02 -1.08721012e-03  2.81415194e-01 -1.89377040e-04
  1.77946418e-01 -3.67793655e-02  3.37925319e-02  7.26656541e-04
 -7.43973731e-01 -1.53668150e-01 -8.10711582e-02 -2.49770305e-01
 -9.32808904e-01 -6.12828467e-03  3.99513481e-02 -1.82482849e-01
 -5.64267416e-02 -2.31439017e-01  5.94568028e-02 -4.01905294e-02
 -1.95272607e-02  4.71291180e-02 -1.66926108e+00 -2.50988668e-02
  6.13581049e-04 -3.83344318e-02  1.10105832e+00  4.52581363e-03
 -4.48023988e-02 -1.87944076e-01 -3.10678409e+00 -5.06348588e-02
  9.88958962e-02 -2.64054541e+00  9.53993009e-01 -1.01013297e+01
 -3.71692213e-01  3.77133356e+00  2.13475346e-01 -2.72866262e+00
 -4.22011862e-01]
supnorm grad right now is: 10.10132971053831
Weights right now are: 
[  3.58824122  -4.20270544   2.29197631   4.3942333   -3.33367251
   4.09401375  -1.89303904  -5.11026168  56.06720018  12.91423635
  38.4394492   -6.58141746  35.21843501  16.1488548  -19.52574377
   0.23183104   5.20211584  -1.25106862  22.41019777   3.11729319
  49.96913455  17.36360873   8.84794925   7.18858504   3.10462623
   8.34218765  -1.69705324  72.96960692  -0.76801939  -8.85120917
   8.21588361 -48.06493295   7.34015925  -8.25932836  16.35553037
 -15.99671351   3.74375519 -18.71107588  12.3326165  -19.27488192
  -0.84814352  -2.00184988  -7.58929358   9.49437881  39.67506138
   4.44229054   1.24280898  55.56112423 -23.56953078   0.78351187
   4.39033268 -22.0087529   38.00696553  56.56637298  -2.30413667
  23.16437559   5.00251895  -4.28088786  -1.10468396  -3.4373697
   5.83967041   1.06977189   6.30724877  -4.03624967  31.06309017]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.702514450128
gradient value of function right now is: [-3.24893884e-02 -1.34400756e-01 -3.08315240e+00 -3.20519775e-02
  3.24893884e-02  1.34400756e-01  3.08315240e+00  3.20519775e-02
  1.12706116e-02  1.95526293e-02 -7.54222835e-06 -2.27780129e-03
 -9.32640765e-02 -1.06978366e-01 -6.10397357e-03 -8.43401605e-03
  6.69944157e-01 -1.13935914e+00 -5.09218352e-03 -1.38151730e+00
  2.13762056e-02  2.88895274e-02  4.92937316e-06  1.46887256e-03
 -1.66354009e+00 -1.71746325e-01 -8.40223573e-01 -2.25928672e-04
  1.63865939e+00  1.58387006e-01  6.59253649e-01 -2.20917271e-03
  1.08165434e-01  4.57277300e-02  3.15365986e-02  1.99786304e-02
  1.30579058e+00  3.80589295e-01  2.72310552e-01  1.27125326e-01
  5.71337210e-02  4.33714246e-01 -1.56456690e-02  4.58483129e-02
  3.65481180e-02  1.03096820e+00  1.72444708e+00  3.04206117e-02
 -6.28132842e-02 -1.60130737e+00 -1.45208887e+00 -5.27702801e-02
  1.77127170e-02  1.12307982e-01  1.06876097e+00  2.20157148e-02
 -1.13068500e+00  2.42416010e+00 -2.28983803e+00  7.06143670e+00
  1.29043725e+00 -2.74637796e+00 -9.48321877e-01  2.43810594e+00
  2.14305353e+01]
supnorm grad right now is: 21.43053534342562
Weights right now are: 
[  2.82025439  -4.69314601   2.26793505   4.3065403   -2.56568568
   4.58445432  -1.86899778  -5.02256868  59.09830335  13.37241403
  41.16192889  -6.36363549  34.06786063  16.40520277 -19.32575988
   0.18350921   5.59441901  -1.42286496  22.77151745   2.99506145
  52.13782284  16.95590294   8.8882438   11.00364032   3.21013241
   7.60552426  -1.7717237   76.57782988  -0.15539012  -9.50285373
   9.19592866 -52.46986728   7.81771463  -7.76538613  16.14106407
 -16.42142797   4.10045381 -18.73559895  12.04345025 -19.65142091
  -0.79606887  -1.85480155  -6.87046216  10.94686782  40.79856314
   4.41284774   1.58259146  57.51588452 -22.07652541   1.33678526
   5.08104265 -20.55670893  39.88498992  57.96104804  -2.29975068
  23.45414724   5.22466981  -4.31835242  -1.02605237  -3.49975522
   5.27741515   1.12886043   6.68672388  -3.87025755  31.15369028]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.7960637476117
gradient value of function right now is: [-2.44144284e-03 -2.52184232e-02 -1.89919589e+00 -2.97892238e-03
  2.44144284e-03  2.52184232e-02  1.89919589e+00  2.97892238e-03
  1.26224895e-03  3.85590999e-03  2.00467951e-05  1.34072796e-03
 -1.81137899e-02 -5.90278043e-02 -3.70632007e-02 -4.71913900e-02
  5.10999769e-01  1.43375370e+00  4.46182301e-03  5.50524641e-01
  2.06604786e-03  2.05614933e-03  1.20478054e-07 -1.45823585e-05
 -1.80670735e+00  7.58187819e-04 -1.42966931e+00 -8.77761512e-04
  5.51329353e-01  4.74801646e-02  1.02666694e-01  3.50016635e-03
 -2.78363545e-01 -5.23984952e-02 -7.94868336e-03 -1.07027387e-01
 -4.74713542e-01 -1.27601372e-01 -8.39458705e-02 -2.10054469e-02
  8.82353431e-02  1.17226555e-01  2.88057090e-01  7.46969972e-02
  2.13884334e-03 -1.89584436e-01 -4.67184250e-01  1.89842195e-04
 -4.16097628e-02  3.33077731e-03 -1.60664576e-01 -4.11211881e-02
 -2.73855262e-03 -2.53379225e-02 -6.73481669e-01 -4.95590121e-03
 -1.04800614e-01  1.66078655e-01  4.76194001e-01 -2.14406505e+00
  3.61312787e-01 -1.78219079e-01 -2.38681217e-01  1.69876230e-01
  1.22160867e+01]
supnorm grad right now is: 12.216086667635214
Weights right now are: 
[  3.51986037  -4.92415544   2.39885593   3.47324393  -3.26529166
   4.81546375  -1.99991866  -4.18927231  59.99545134  13.07699569
  43.91702049  -6.92003085  35.15346759  16.48122301 -20.06943235
  -0.10228171   5.82386984  -1.33605904  25.31172534   2.83260454
  53.38764856  17.81553784   8.88817451   9.59021362   2.7357418
   8.98093928  -1.43205292  75.70822371   0.35699332 -11.27826831
   8.6339034  -55.48084501   8.25456914  -7.57555917  16.06924547
 -16.6260226    4.20701013 -19.06138084  11.48709274 -20.91115052
  -2.09670867  -1.59141157  -7.01550088  10.96163793  40.70877297
   4.12196458   1.15763273  58.71051702 -23.48632529   1.86300839
   5.62187511 -21.74706324  42.17435529  59.21927717  -2.31237029
  24.31579455   5.03800744  -4.45680201  -1.07056868  -3.4689862
   6.10360172   1.23820679   7.09322357  -3.69570027  31.13956854]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1366.463869132759
gradient value of function right now is: [ 4.75344779e-02  1.54708721e-01  5.20178908e+00  4.50807653e-02
 -4.75344779e-02 -1.54708721e-01 -5.20178908e+00 -4.50807653e-02
 -2.59700049e-02 -8.01775952e-02 -1.41361251e-04 -2.44242294e-02
  8.90209678e-02  4.77846184e-02 -4.94806095e-03 -3.14115080e-03
 -8.12471071e-01 -3.58257587e+00 -8.85659017e-03 -1.50487991e+00
 -4.11755842e-02 -3.93241570e-02 -4.25369631e-06 -1.54934150e-03
  3.89728692e+00  1.49975720e-01  2.51289464e+00  4.92160473e-04
 -1.08544494e+00 -1.77654034e-01 -2.75542089e-01 -2.76458245e-03
  2.02948376e-01  4.72496829e-02  1.36988528e-02  3.97953322e-02
  1.10033138e+00  3.24586838e-01  2.45644748e-01  6.29703375e-02
 -2.43777548e-01 -9.39938489e-01 -3.62861693e-01 -1.34582897e-01
 -8.07349596e-03 -1.16895807e-01  7.06091664e-01  6.55077852e-04
  5.29770655e-02  2.88001433e-01  1.48468197e-01  3.25569487e-02
  1.08883758e-02  5.27627409e-02  9.00947719e-01  1.23188520e-02
  3.95702835e-01  1.77352064e-01 -8.47123175e-01  3.73453245e+00
 -7.93946622e-01  5.11138929e-01  5.29677629e-01  4.20518659e-01
 -1.41710459e+01]
supnorm grad right now is: 14.171045899781003
Weights right now are: 
[  5.3834913   -3.84708507   2.47848576   6.48683046  -5.12892259
   3.73839338  -2.07954849  -7.20285885  59.32943965  13.17303036
  50.0166603   -7.71365219  35.51215737  16.93778418 -20.36953563
  -0.19438179   5.90949262  -1.56039554  25.17616256   2.67149646
  52.78502295  16.75790781   8.76086923   9.12383978   3.08583165
   9.37551908  -0.78113634  83.00934644   0.41379541 -11.60963856
   9.37839886 -59.90041741   9.04152144  -7.32255555  16.55582258
 -16.62388532   4.99376409 -18.83158313  11.30836486 -21.51510295
  -2.11713265  -1.39296332  -8.16443437  10.91037382  40.56668587
   4.3691367    1.09352567  59.99370711 -23.87676689   2.1806552
   7.09025262 -21.57841642  44.33533099  60.12643281  -1.91476622
  24.89707272   4.60514775  -4.17369586  -1.02330734  -3.38249812
   5.46020993   1.27871822   7.0916366   -3.83395003  30.89889592]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -1368.674299620898
gradient value of function right now is: [ 2.90245171e-02  6.50964854e-02  5.03790644e+00  8.50516497e-03
 -2.90245171e-02 -6.50964854e-02 -5.03790644e+00 -8.50516497e-03
 -7.69415044e-03 -1.31353795e-01 -6.47389178e-04 -8.74070417e-02
  4.81820721e-02  9.62705242e-02  4.17626620e-02  5.46779955e-02
 -7.12234058e-01 -4.93238185e+00 -1.27539772e-02 -2.33190784e+00
 -6.50064432e-03 -9.69315862e-03 -2.58304888e-06 -4.04640156e-04
  2.62083850e+00  1.50138033e-01  1.28593144e+00  7.83215235e-04
 -1.61885116e+00 -2.87726845e-01 -4.46723008e-01 -5.11338147e-03
  4.78025558e-01  1.27813016e-01  3.74428168e-02  1.72568262e-01
  1.49655658e+00  5.19658478e-01  3.83425869e-01  9.42778535e-02
 -5.15992563e-02 -7.68305910e-01 -3.61408038e-01 -3.61352812e-02
 -6.55352307e-03 -2.46365352e-01  1.05058926e+00 -3.31478111e-04
  5.78326658e-02  6.51448050e-01  1.55335604e-02  3.86170174e-02
  1.18126234e-02  9.08109039e-02  1.45644624e+00  1.23784904e-02
  6.13933646e-01  3.62472900e-01 -1.66284673e+00  6.55554309e+00
 -6.10103832e-01  5.78714013e-02  4.21865925e-01  1.71151429e-01
 -7.51807151e+00]
supnorm grad right now is: 7.518071505982653
Weights right now are: 
[  4.73691127  -4.78281822   2.57345241   5.03237581  -4.48234256
   4.67412653  -2.17451514  -5.7484042   62.08653655  12.93926533
  55.07514315  -8.92393353  32.92911176  17.64136625 -19.71497516
   0.24458359   6.40813787  -1.59975164  24.86201061   2.6382298
  55.23113355  19.06093196   8.60630051  11.05724117   2.85025383
  10.48777437  -1.10329466  87.79347669   0.87530401 -11.9759269
   9.46694746 -64.40685809   9.76649215  -7.38170896  14.4312127
 -16.57840249   5.54228347 -18.47106343  11.55319738 -23.30180285
  -1.90014048  -1.2161691   -7.91742793  12.23916805  39.70105285
   4.38433191   1.58808912  60.84906641 -25.52594061   3.12651545
   7.48744117 -23.6060761   45.17176736  60.80330049  -2.00945349
  24.05125615   4.87499266  -4.41330098  -1.29104298  -3.48030211
   5.64633261   0.86587822   6.44926035  -4.19422412  30.88899492]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -1369.8860973363282
gradient value of function right now is: [ 1.11904139e-04 -3.40696288e-02 -1.78567345e+00 -6.65911623e-04
 -1.11904139e-04  3.40696288e-02  1.78567345e+00  6.65911623e-04
  3.06112319e-05  2.40116676e-03  3.18730393e-05  3.27425354e-03
 -8.56688491e-03 -1.43779298e-01 -1.08502118e-01 -1.43026825e-01
  1.77483457e-01  3.28392025e+00  2.27811385e-02  2.20314785e+00
  1.15029516e-03  2.35565163e-04 -1.04060381e-06 -2.54636327e-04
 -7.62520635e-01  4.42646506e-02 -1.14844374e+00 -4.97191434e-04
  9.85630792e-02  2.48762217e-02 -2.09850281e-02  1.28575636e-03
 -1.10604089e+00 -2.69679225e-01 -2.78994561e-02 -4.10928838e-01
 -1.34123087e+00 -2.50405765e-01 -4.81814801e-02 -1.57973887e-01
  8.00705007e-02 -1.92212582e-01  2.40814079e-01  6.27050429e-02
 -2.97236776e-02 -5.57850302e-01 -2.38838264e+00 -2.62855360e-02
 -1.93956952e-02  3.38560101e-01  5.05907177e-02 -2.29487122e-02
 -4.69589964e-02 -2.02709403e-01 -4.39457577e+00 -5.14666178e-02
  6.53193445e-01 -2.85712639e+00  2.21802808e+00 -1.27786307e+01
 -3.42272648e-01  2.14658675e+00  2.57976513e-01 -2.48061419e+00
  1.04669064e+00]
supnorm grad right now is: 12.778630694530134
Weights right now are: 
[  4.58919447  -4.12700452   2.20344071   7.28740552  -4.33462576
   4.01831283  -1.80450345  -8.00343391  61.69109349  15.02394886
  57.84682316  -7.44299312  31.15589278  17.30726842 -20.57640324
  -0.55974141   6.89708007  -1.48680443  26.49177802   2.79766996
  54.81900907  17.97996813   8.43900451   7.78713525   2.45104175
  10.43117197  -1.33994674  98.26131093   1.1342264  -11.5863277
  10.17649793 -71.25206184   9.61483704  -7.96227775  14.86600061
 -17.32871045   5.38204086 -18.7225147   10.23316628 -23.62583989
  -2.13035884  -1.519525    -8.30681949  12.2925014   38.8999362
   4.19918031   1.15000752  61.10847434 -26.36387111   3.4363607
   8.06768764 -24.40291198  46.80960729  61.12671311  -2.02701101
  24.87987712   4.78049193  -4.41301896  -1.47738626  -3.72615634
   5.18442824   1.35435379   6.78684437  -4.09459054  31.11869466]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1370.980474154038
gradient value of function right now is: [ 2.20081252e-03 -2.68693637e-02  1.89383040e+00  6.94604126e-04
 -2.20081252e-03  2.68693637e-02 -1.89383040e+00 -6.94604126e-04
 -5.04313550e-04 -4.15154519e-03  2.60725819e-05 -7.33564556e-04
  3.24140160e-03 -1.73443275e-01 -1.36018610e-01 -1.83833074e-01
 -1.75190475e-01 -9.09177433e-01  2.21203224e-02  1.47788473e-01
 -5.90232819e-04 -2.25665678e-03 -1.39705084e-06 -1.37906737e-04
  7.06227632e-01  1.28602078e-01 -6.59513459e-02  1.67493423e-04
 -1.04482975e+00 -2.56131814e-01 -2.83303373e-01 -1.47828528e-03
 -1.24752850e+00 -3.23695779e-01 -2.31864250e-02 -4.95975451e-01
  2.10007148e-01  2.47469692e-01  2.42435475e-01 -7.70927456e-02
  2.34737615e-02 -3.93933627e-01  3.52116128e-02  2.64227204e-02
 -3.34142692e-02 -5.60610121e-01 -1.61144462e+00 -2.78797871e-02
  1.16193109e-02  3.75220249e-01  1.04076511e-01  2.76968940e-03
 -4.06783379e-02 -1.81801762e-01 -3.97680994e+00 -5.27099812e-02
  8.30875493e-01 -2.88487161e+00  1.54025790e+00 -1.11365232e+01
 -1.01833454e+00  3.72358474e+00  4.83854431e-01 -2.79254570e+00
 -6.58783716e+00]
supnorm grad right now is: 11.136523203073128
Weights right now are: 
[  2.93525111  -3.96310195   2.23767335   6.90157654  -2.6806824
   3.85441026  -1.83873608  -7.61760492  63.79685736  15.430931
  61.30274561  -9.25562331  30.68734164  17.54764352 -20.68936309
  -0.82768127   6.85221041  -1.50179463  25.89696301   2.31042014
  55.33340235  19.99986615   8.21627464   6.86372526   2.5172401
  11.08235115  -1.07076508 110.33826432   1.18334039 -12.88610078
   9.41966272 -74.49566568   9.72419149  -7.94993852  14.26367234
 -18.05805688   6.07165322 -18.28626415  10.38572541 -23.8742188
  -2.13628044  -1.08591279  -8.20365177  13.15615081  38.1327308
   3.9622124    0.8920177   62.06600937 -27.72017425   3.42463633
   9.3016657  -25.3264749   49.20158813  61.7204125   -2.3657492
  25.84513688   4.53383181  -4.51776051  -1.19392878  -3.65195163
   5.226139     1.14493668   7.00350271  -3.98442123  31.0500624 ]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.4781821913527
gradient value of function right now is: [-2.32029194e-03 -2.53173994e-04 -2.43090684e+00 -1.31567700e-03
  2.32029194e-03  2.53173994e-04  2.43090684e+00  1.31567700e-03
  4.27996198e-04  6.17160154e-03 -2.89748196e-05  4.07191326e-03
 -1.29272499e-02  8.54108195e-02  7.13290690e-02  9.34555639e-02
  1.21579596e-01  2.89291581e+00 -4.19445509e-03  1.15462889e+00
  1.53116882e-03  1.41328435e-03  2.45946511e-07  4.96874110e-05
 -4.83512282e-01 -2.96351111e-02 -1.73182259e-01 -2.24434014e-04
  5.07257855e-01  1.07817306e-01  9.26513517e-02  1.84537557e-03
  4.22766412e-01  1.35467350e-01  6.18313118e-03  2.18639439e-01
 -1.21772966e+00 -3.77938687e-01 -1.53213358e-01 -5.70011935e-02
  1.47067933e-02  1.50167557e-01  8.18409491e-02  2.48613446e-03
 -1.05166278e-02 -1.66784852e-01 -6.18563409e-01 -5.99192682e-03
 -1.19817787e-02 -8.18011889e-02  2.10295209e-02 -5.27136649e-03
 -4.31837912e-03 -2.39182390e-02  4.13287007e-01 -2.67364291e-03
 -2.96182623e-02 -5.63004004e-01  7.55980193e-01 -1.67234254e+00
  4.24331098e-01 -1.19509722e+00 -3.59083099e-02 -4.49918229e-01
  4.79386468e-01]
supnorm grad right now is: 2.892915814569534
Weights right now are: 
[  2.73806321  -3.76161098   2.1862995    6.30596188  -2.4834945
   3.65291929  -1.78736223  -7.02199026  66.69025206  15.41544964
  64.19053963  -9.87256982  30.39998113  17.96897747 -20.31608056
  -0.64600401   6.47689777  -1.31922516  24.24004453   2.76708909
  56.05637017  21.56266149   8.20721254   6.40267495   2.5489501
  10.7979012   -1.14945029 117.96226332   1.24793247 -12.93841914
  10.58110602 -75.25806233  10.86965899  -7.59605416  13.37250014
 -17.65739539   6.02432682 -18.1366682    9.87830927 -26.00508679
  -2.75330818  -1.84810232  -8.89594773  12.08537863  37.43418313
   4.00559146   1.26442805  62.13331982 -29.64379147   3.62943674
  10.3329447  -28.39190118  50.45611353  62.72293105  -1.89178419
  25.60162651   4.35841015  -4.39861128  -1.49669297  -3.52333227
   5.13600722   0.60830901   6.34380579  -4.62514578  30.97002307]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.7055682197333
gradient value of function right now is: [-1.17148874e-03 -1.58580420e-03 -2.73010335e-01 -2.51393061e-04
  1.17148874e-03  1.58580420e-03  2.73010335e-01  2.51393061e-04
 -5.63546539e-04  3.13959322e-02  3.11202465e-04  3.58793184e-02
  4.60463580e-03 -1.13385510e-02 -2.15028206e-02 -2.48392623e-02
 -1.23935329e-01  2.66490778e+00  1.10046115e-02  1.95809702e+00
  6.53230148e-04 -1.83758329e-03 -1.10125107e-06 -1.67885219e-04
  6.38641206e-01  4.47804961e-02 -4.43431172e-01  7.38901914e-05
 -4.43344362e-01 -4.19558783e-02 -6.87319218e-02 -1.63485623e-04
 -3.87285742e-01 -1.11888158e-01  2.77200471e-03 -1.05717268e-01
 -1.24327906e+00 -2.74973681e-01  3.30433150e-02 -1.44734743e-01
  5.82480347e-02 -2.32656855e-01  1.49905059e-01  4.71348348e-02
 -4.68287856e-02 -4.34604966e-01 -2.20876857e+00 -3.47138344e-02
  1.17194705e-02  4.06739681e-01  9.48867179e-02  8.14442607e-04
 -3.72025125e-02 -1.61164865e-01 -2.13771856e+00 -3.07305625e-02
  8.14534103e-01 -3.26581239e+00  1.04923450e+00 -1.00745211e+01
 -2.85829248e-01  1.97279883e+00  3.67339019e-01 -2.66586171e+00
 -5.46501905e+00]
supnorm grad right now is: 10.074521077441444
Weights right now are: 
[  4.0277748   -4.79722603   2.33062392   6.60763712  -3.77320609
   4.68853434  -1.93168665  -7.3236655   66.44502211  15.23400747
  71.59311746 -10.79935961  29.63044297  18.06411183 -20.69000072
  -0.99817578   6.7627214   -1.3215416   26.03800692   2.78427152
  56.45596194  22.0039759    7.70890996   3.70788681   2.62712964
  11.94356196  -1.40174288 128.70831592   1.66392416 -13.09698346
  10.61039616 -77.81371829  10.41166323  -7.25884462  14.79132878
 -18.20457659   6.58561835 -18.19885539   9.49537653 -25.08444846
  -1.46378283  -1.58245407  -9.51400403  14.18462963  37.83338284
   4.68573139   0.56034276  62.71529842 -29.58347681   4.13042959
  10.71801137 -29.17365801  51.61188396  62.71091346  -2.34971282
  26.3390245    4.75452534  -4.49126454  -1.64404508  -3.61391753
   5.73780748   0.54669167   6.47397713  -4.53616046  31.06717439]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1370.5268520911684
gradient value of function right now is: [-6.13191477e-03 -7.98322869e-03 -3.14922703e+00 -2.12406235e-03
  6.13191477e-03  7.98322869e-03  3.14922703e+00  2.12406235e-03
  1.31565700e-03  7.93723078e-03 -1.39028700e-04  1.85496605e-04
 -1.35251003e-02  4.09359249e-02  4.21590957e-02  5.77581542e-02
  1.17729792e+00  8.51860506e-01 -1.78987643e-02 -4.70699563e-01
  3.03182780e-03  6.30084220e-03  1.94030361e-06  3.92228091e-04
 -4.40167614e+00 -1.46187973e-01 -3.47349726e+00 -8.90161171e-04
  1.25321660e+00  2.30875684e-01  1.71027191e-01  3.93057756e-03
  6.73067245e-01  2.05135514e-01 -3.30825752e-03  2.30101179e-01
 -5.30803234e-01 -3.15177339e-01 -2.35044788e-01  6.98268209e-02
  2.60035784e-01  1.00852355e+00  3.73645247e-01  1.72661593e-01
  2.49175518e-02  1.10022887e-01  1.08020572e+00  2.65497426e-02
 -6.82170919e-02 -3.18032440e-01 -2.30586019e-01 -4.95797214e-02
  2.95040877e-02  1.25610131e-01  2.28333817e+00  3.57421676e-02
 -6.99388697e-01  2.71540049e+00 -4.45568139e-01  7.32218576e+00
  1.41903865e+00 -2.91248361e+00 -1.17549985e+00  2.99129943e+00
  1.65886926e+01]
supnorm grad right now is: 16.588692585335654
Weights right now are: 
[  3.12487456  -3.47736037   2.35981575   9.35019363  -2.87030585
   3.36866868  -1.96087848 -10.06622202  66.25283639  16.28106733
  74.51601159 -10.96693559  30.90829108  18.51668577 -20.93687477
  -1.37160712   6.59584178  -1.23829535  25.18769837   2.40127848
  54.58348124  20.992766     7.47601636   7.29210207   2.52570079
  10.19472681  -1.54367728 147.89406102   1.67797877 -11.99661918
  10.480124   -80.08238874  10.73147594  -7.86845142  14.00341599
 -18.442358     5.97909807 -18.11640218   9.34165664 -25.29826807
  -2.46177618  -1.5316891   -8.16018777  14.28474143  36.63599293
   4.86544145   0.96221668  62.68756607 -32.14713531   4.4034451
  12.01168267 -33.73343163  53.34481289  63.13387101  -1.76390707
  27.22656999   4.55937197  -4.26716415  -1.25970177  -3.50810663
   5.06587012   0.60874321   6.34800578  -3.89452257  30.96508962]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.2244478073158
gradient value of function right now is: [ 3.39613511e-03  5.76718708e-02  1.87169657e+00  5.45776710e-03
 -3.39613511e-03 -5.76718708e-02 -1.87169657e+00 -5.45776710e-03
 -5.09247662e-04 -1.32464187e-03 -1.38760888e-06 -3.54071816e-04
  3.95219704e-02  3.33951433e-02  1.11321472e-02  1.56237447e-02
 -4.39770634e-01 -1.54895877e+00 -4.12869932e-03 -9.34138106e-01
 -8.61356465e-03 -7.89552687e-03 -7.52641163e-07 -1.50358475e-04
  1.53937047e+00  1.21384593e-02  1.14058209e+00  2.20936652e-04
 -5.71982879e-01 -5.63317346e-02 -6.22559359e-02 -1.49301328e-03
  1.50897810e-01  6.41503611e-02  1.31519636e-02  4.44865492e-02
  4.15023173e-01  1.72494105e-01  7.15238496e-02  7.89127165e-03
 -9.30965625e-02 -2.79265235e-01 -1.72387037e-01 -4.71677713e-02
 -3.99711003e-03  1.74983453e-01  2.33461658e-01 -5.00824980e-03
  2.64921906e-02  7.70629741e-02  8.71947909e-02  2.03655535e-02
 -1.68216242e-03  1.54698438e-02  1.01756721e-01 -3.22866199e-03
  1.44024131e-01 -3.92927800e-01 -9.85827650e-01  1.75739698e+00
 -4.21839315e-01  5.81919176e-01  3.71492714e-01 -4.68865892e-01
 -4.95650996e+00]
supnorm grad right now is: 4.956509963900967
Weights right now are: 
[  1.31553238  -3.85305087   2.40944837   9.51405138  -1.06096367
   3.74435918  -2.0105111  -10.23007976  67.01703726  17.66813057
  78.14852806  -9.51043393  29.47708922  19.37373331 -20.70402164
  -1.04838203   6.54247405  -1.32565902  27.12215219   2.56761268
  54.85201136  20.97308858   7.02756715   4.80408968   2.70340973
  10.22627311  -1.10174671 156.16946253   1.65745743 -12.34910511
  10.05984255 -83.40457682  10.64242408  -7.75489582  14.20658295
 -18.96121852   6.24237093 -18.19398932   8.59236536 -25.39430505
  -2.33357268  -1.7512686   -9.02545662  14.49070707  35.95691833
   4.77470765   1.04163624  63.2314699  -33.5517799    3.97005354
  12.48692106 -35.30996386  54.17778094  63.45096642  -2.31226248
  27.11612585   4.12556888  -4.96082461  -1.62531042  -3.56218746
   5.16132809   0.63851938   6.36493478  -4.1884964   30.98020264]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1368.8619571123115
gradient value of function right now is: [ 8.14647708e-04  3.42639124e-02  3.77764761e+00  2.79582166e-03
 -8.14647708e-04 -3.42639124e-02 -3.77764761e+00 -2.79582166e-03
 -1.47068770e-04 -3.72207068e-04 -7.49451648e-08 -1.67734182e-05
  1.52582710e-02  7.68371167e-02  4.81844893e-02  6.11673269e-02
  1.91609708e-01 -6.10592905e+00 -1.98022371e-02 -3.25509548e+00
 -3.77858879e-03 -6.37255154e-03 -9.72034325e-07 -1.52352940e-04
 -5.36873684e-01  5.50322496e-02 -1.53561024e+00  2.67030269e-04
 -9.16458265e-01 -1.86649650e-01 -1.92314276e-01 -2.12800755e-03
  6.76116518e-01  2.26305413e-01  3.82058987e-02  2.16680556e-01
  1.75213649e+00  6.03503240e-01  2.70568170e-01  1.42277273e-01
  1.53075148e-01  2.60286897e-01 -1.85090395e-01  9.57593335e-02
  9.99300010e-03  1.70229266e-01  1.55497758e+00  1.67452891e-02
  5.08168899e-03  1.18013351e-01 -5.62607322e-02  5.45481509e-03
  1.95890988e-02  1.51691512e-01  2.02767644e+00  2.79406524e-02
  3.21368145e-03  1.58594748e+00 -2.42292023e+00  1.14602932e+01
 -3.01324090e-02 -6.12658004e-01 -5.53202542e-01  1.82302354e+00
  5.91630378e+00]
supnorm grad right now is: 11.460293171517295
Weights right now are: 
[  1.6011499   -3.92883886   2.51658316   9.13870843  -1.34658119
   3.82014717  -2.11764589  -9.85473681  73.77701729  21.70898168
  78.60768354  -7.57665826  30.15246536  19.75271851 -20.85596731
  -1.15477707   6.74421231  -1.34347651  27.71530073   2.26813368
  56.15733159  20.84097028   6.62848664   5.4382831    2.72332126
  11.84142576  -1.35242112 171.40223679   1.46025306 -13.37642253
   9.74608155 -87.11663748  10.89699453  -7.19347411  14.45969347
 -19.16068297   7.02805441 -17.84811553   8.63368147 -24.89433911
  -2.50507562  -1.75163102  -9.30158116  14.24538927  36.19891968
   4.7086023    1.21187382  64.06177849 -33.98478399   4.07189104
  13.2031317  -37.42306106  55.27285789  63.93299444  -2.1169916
  27.33179043   4.61482961  -4.5281532   -1.39143774  -3.4755776
   5.46261453   0.38929774   6.07688621  -4.03666872  30.88035584]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.0045229650439
gradient value of function right now is: [-2.23951136e-03 -5.42786681e-02 -2.32825632e+00 -1.09460122e-02
  2.23951136e-03  5.42786681e-02  2.32825632e+00  1.09460122e-02
  2.73982147e-04  4.94048155e-04  1.01690904e-07  3.81583153e-05
 -3.47385380e-02  6.19317409e-02  7.60038301e-02  9.67986719e-02
  5.35462644e-02  9.85715521e-01 -1.10001171e-02 -1.36571263e-01
  1.47866075e-02  1.92569598e-02  4.18429941e-06  1.01833671e-03
 -3.49166220e-01 -5.85420039e-02  7.03941878e-01 -1.60779467e-04
  8.54096294e-01  1.49600325e-01  1.71459901e-01  9.73943847e-04
  5.90282325e-01  1.98591645e-01  2.59679572e-02  2.67479141e-01
 -4.56941974e-01 -1.83533955e-01 -1.14024130e-01 -1.59616912e-03
 -7.14550620e-02  4.33406458e-02 -9.54726492e-02 -6.10741241e-02
  1.10276818e-02  3.12594339e-01  2.60368779e-01  6.66342842e-03
 -1.26181904e-02 -3.86520038e-01 -9.22852188e-02 -6.28972541e-03
  8.43218365e-03  3.05783805e-02  1.04268660e+00  7.72948539e-03
 -4.84309965e-01  8.18783644e-01 -7.90021809e-02  2.11910142e+00
  5.91662999e-01 -1.67863312e+00 -1.79685349e-01  5.44937759e-01
 -2.02996100e+00]
supnorm grad right now is: 2.328256318972523
Weights right now are: 
[ 1.18437137e+00 -3.43942340e+00  2.16661585e+00  9.90377487e+00
 -9.29802662e-01  3.33073171e+00 -1.76767858e+00 -1.06198033e+01
  7.67754299e+01  2.57180801e+01  7.86533984e+01 -6.72696716e+00
  3.02921430e+01  1.97457151e+01 -2.13436226e+01 -1.54635457e+00
  6.83344516e+00 -1.48373274e+00  2.64342005e+01  2.30492107e+00
  5.55280653e+01  2.19673097e+01  6.18511793e+00  7.68729444e+00
  2.75147101e+00  1.22829977e+01 -9.07034334e-01  1.82615751e+02
  1.99106007e+00 -1.29453783e+01  1.05525971e+01 -8.39824977e+01
  1.12133537e+01 -7.26508001e+00  1.64060714e+01 -1.89535500e+01
  6.82556136e+00 -1.72878353e+01  8.12020440e+00 -2.80878880e+01
 -3.14725099e+00 -1.89499686e+00 -9.21925918e+00  1.31129138e+01
  3.68284194e+01  4.35933525e+00  1.67183314e+00  6.49710267e+01
 -3.29934176e+01  3.82513323e+00  1.45103526e+01 -3.72450786e+01
  5.65655247e+01  6.43787242e+01 -1.79948185e+00  2.74760154e+01
  4.68215577e+00 -4.43329431e+00 -1.39634170e+00 -3.74297989e+00
  5.18835713e+00  1.80054738e-01  5.94790770e+00 -4.43868857e+00
  3.08961266e+01]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.448800554656
gradient value of function right now is: [ 4.25332427e-04  2.31456854e-02 -6.83998412e-01  9.72573779e-04
 -4.25332427e-04 -2.31456854e-02  6.83998412e-01 -9.72573779e-04
  1.54265144e-05  1.14916025e-04  2.61565273e-08  1.73714215e-05
  2.35541266e-03  6.18673336e-02  3.96873874e-02  5.26051797e-02
 -7.19015307e-03  2.80844095e+00  1.03938726e-02  2.07460463e+00
 -4.76456783e-04 -3.59980289e-03 -9.83283819e-07 -4.18118993e-04
 -8.80568368e-02  2.86104550e-02 -4.50330765e-01  1.08471744e-05
 -1.93262227e-01 -1.14416635e-02 -4.59536752e-02  3.29786544e-04
 -7.67053502e-02 -1.80243526e-02 -4.52876307e-03  3.42408291e-02
 -9.48557722e-01 -3.28898652e-01 -1.15443194e-01 -9.67880075e-02
  2.61452521e-02 -7.90636294e-02  2.24994421e-01  2.92377614e-02
 -2.08107963e-02 -4.32302231e-01 -7.58667705e-01 -1.73659108e-02
  7.29792238e-05  3.07704592e-01  7.62228175e-02 -4.08993897e-03
 -1.53573612e-02 -9.03988028e-02 -5.76247325e-01 -1.68389081e-02
  5.24214481e-01 -1.46837271e+00  1.58191387e+00 -6.14462717e+00
 -1.90278509e-02 -1.20261035e-01  3.12123933e-01 -1.32486037e+00
 -5.53655536e+00]
supnorm grad right now is: 6.144627174515565
Weights right now are: 
[-5.68867299e-01 -3.22500542e+00  2.34869867e+00  8.80339811e+00
  8.23436010e-01  3.11631373e+00 -1.94976140e+00 -9.51942650e+00
  8.23669500e+01  2.82053691e+01  7.86801990e+01 -7.43076948e+00
  3.08999136e+01  2.01467289e+01 -2.10478766e+01 -1.50117740e+00
  6.59038749e+00 -1.19332600e+00  2.67112276e+01  2.77245383e+00
  5.56820634e+01  2.52191146e+01  6.35015605e+00  1.02721213e+01
  2.55388412e+00  1.34162754e+01 -1.21972390e+00  1.95579877e+02
  1.67145059e+00 -1.25515768e+01  1.02412353e+01 -8.72035741e+01
  1.08346042e+01 -7.01082860e+00  1.68315925e+01 -1.96370499e+01
  6.91072949e+00 -1.76280300e+01  8.27368271e+00 -2.67222642e+01
 -2.40414310e+00 -1.80727313e+00 -9.18881974e+00  1.40708170e+01
  3.63690399e+01  4.58427298e+00  1.37492897e+00  6.48420693e+01
 -3.43119878e+01  3.53081032e+00  1.42480068e+01 -3.99558084e+01
  5.78058672e+01  6.49620772e+01 -2.45047476e+00  2.82423526e+01
  4.30779078e+00 -4.61904261e+00 -1.45494324e+00 -3.79969051e+00
  5.15567179e+00 -8.69348122e-02  6.37718585e+00 -4.19651653e+00
  3.09857458e+01]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.4668837471422
gradient value of function right now is: [-1.64974008e-03 -1.71204165e-01 -4.02446501e+00 -1.94089640e-02
  1.64974008e-03  1.71204165e-01  4.02446501e+00  1.94089640e-02
  2.09945030e-05  4.51865047e-05  1.21634486e-08  1.19776126e-06
 -6.97002516e-02 -1.38040010e-01 -4.59460462e-02 -5.60182782e-02
  5.88637414e-01 -8.13157481e-02 -3.82357633e-03 -9.85566748e-01
  2.42003851e-02  4.05965079e-02  1.09728585e-05  1.36266560e-03
 -2.69699227e+00 -8.42194050e-02 -6.14758815e-01 -8.01632764e-04
  1.87946433e+00  1.19083090e-01  1.38549867e-01  4.25238694e-03
 -2.81994783e-02 -3.38113777e-02 -1.45067201e-02 -5.00138770e-02
  6.47586391e-01  1.68471949e-01  1.16988117e-02  9.04204561e-02
  2.43844266e-02  2.45347706e-01 -4.90759266e-03  1.53894490e-02
  4.31989801e-02  6.61743705e-01  1.05617947e+00  3.13411036e-02
 -3.39305583e-02 -5.56883325e-01 -2.10969044e-01 -2.10564217e-02
  3.35113251e-02  1.04060986e-01  1.18738480e+00  3.44111264e-02
 -1.18065614e+00  3.03262323e+00 -1.40765133e+00  6.19840821e+00
  7.84238032e-01 -1.32417099e+00 -9.53691198e-01  2.56501212e+00
  2.01788765e+01]
supnorm grad right now is: 20.17887651374764
Weights right now are: 
[ 2.49014776e-01 -3.20736333e+00  2.19513680e+00  9.97185718e+00
  5.55393504e-03  3.09867164e+00 -1.79619953e+00 -1.06878856e+01
  8.51639074e+01  3.26072983e+01  7.87007097e+01 -4.62299246e+00
  3.00262282e+01  2.01566287e+01 -2.12868177e+01 -1.99247192e+00
  6.81102505e+00 -1.39353327e+00  2.60375352e+01  2.51010493e+00
  5.49783831e+01  2.49127059e+01  6.39205413e+00  1.32649009e+01
  2.65355347e+00  1.38396255e+01 -1.11005821e+00  2.16650987e+02
  2.00608667e+00 -1.19004623e+01  1.10085149e+01 -8.29849007e+01
  1.09050703e+01 -7.66351216e+00  1.54082926e+01 -2.04470843e+01
  6.90220264e+00 -1.77144264e+01  7.84911731e+00 -2.67576856e+01
 -2.91311426e+00 -2.14248120e+00 -9.60374270e+00  1.36343660e+01
  3.69220011e+01  5.00962989e+00  1.37547624e+00  6.51941506e+01
 -3.35660986e+01  4.10313704e+00  1.51141587e+01 -4.06034764e+01
  5.86877267e+01  6.54595159e+01 -2.45458297e+00  2.83764703e+01
  4.83483527e+00 -4.25118383e+00 -1.20937325e+00 -3.82859414e+00
  4.86279066e+00  7.18836648e-01  6.41352236e+00 -4.02769691e+00
  3.11161234e+01]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.5515893995396
gradient value of function right now is: [ 1.05690724e-04  1.70751878e-02  7.53325901e-01  2.52008198e-03
 -1.05690724e-04 -1.70751878e-02 -7.53325901e-01 -2.52008198e-03
 -1.99104929e-05 -4.26136722e-05 -6.06104119e-09 -5.85335954e-06
  2.36884514e-02 -7.20312956e-02 -6.74622855e-02 -7.91191197e-02
 -2.95252623e-01  3.84927459e-01  7.57264695e-03  3.67285594e-01
 -5.10328973e-03 -3.20003222e-03 -2.26738275e-07 -2.31262759e-04
  1.03518515e+00  5.90403975e-03  7.89797757e-01  3.85285173e-05
 -3.91368961e-01 -8.42479144e-02 -5.83971353e-02 -1.91578944e-03
 -3.89181947e-01 -1.00919902e-01 -2.28948443e-03 -1.72771556e-01
 -2.23790014e-01  6.24676725e-02  7.47074168e-02 -8.80955075e-02
 -4.36021770e-02 -1.92785880e-01 -5.02999473e-02 -3.24681898e-02
 -1.52906790e-02  5.08182313e-02 -9.09373757e-01 -1.80637648e-02
  1.52373126e-02  7.29523957e-02  4.65350031e-02  1.20263792e-02
 -2.60767059e-02 -9.72084515e-02 -2.09652992e+00 -3.18383426e-02
  3.07193513e-01 -2.04586855e+00  5.26573406e-02 -5.85878339e+00
 -5.52900894e-01  2.13437715e+00  4.47900410e-01 -2.00106920e+00
 -7.14766010e+00]
supnorm grad right now is: 7.147660101284568
Weights right now are: 
[  1.81931258  -3.39785321   2.23855606  11.0942474   -1.56474387
   3.28916152  -1.83961879 -11.81027578  88.81239677  35.94979166
  78.70629029  -1.94645239  30.076039    20.49207528 -21.02644855
  -1.95078084   6.78716457  -1.48084618  24.47893043   2.29750473
  54.53741876  25.79485134   6.06206722  15.17095268   2.50002952
  14.59796853  -1.0563574  232.62642575   2.12576406 -11.96576619
  10.69535993 -84.30629948  11.47326733  -7.20326895  16.10639303
 -20.42666056   6.73772802 -17.60958894   8.23968141 -26.77202573
  -2.36594794  -2.72399704  -9.46406162  13.65943586  36.94523869
   4.99485023   1.07530696  65.59548804 -34.06429619   4.05544712
  15.95238619 -41.47975217  59.22296897  65.65177261  -2.29241553
  28.63521796   4.74362762  -4.69839838  -1.54350223  -3.80002015
   5.11557222   0.63403726   5.79316386  -4.39181301  31.02767024]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.047939118764
gradient value of function right now is: [ 2.80805400e-04  8.23882624e-02  1.62948256e+00  7.82702093e-03
 -2.80805400e-04 -8.23882624e-02 -1.62948256e+00 -7.82702093e-03
 -9.54110481e-05 -7.13275910e-05 -4.53626934e-09 -1.20636778e-06
  6.39250801e-02  2.17252781e-02 -4.58608325e-03 -2.82100568e-03
 -4.27924781e-01 -5.81164443e-01  2.11519389e-03 -2.68136720e-01
 -1.46301740e-02 -9.55372589e-03 -5.57468518e-07 -1.08139571e-04
  1.21780828e+00  2.16251984e-03  1.01164054e+00  3.64148464e-05
 -5.75837679e-01 -8.04135516e-02 -9.37344129e-02 -9.68869673e-04
 -5.83698922e-02 -4.44650905e-03  9.62205392e-03 -1.39204766e-02
  3.92188457e-01  2.06866116e-01  1.16583755e-01 -1.07151667e-02
 -1.11690729e-01 -3.53435869e-01 -1.51225506e-01 -8.89936184e-02
 -2.96591777e-03  1.84877294e-01  6.33403893e-03 -3.94116579e-03
  1.85927206e-02  1.51323475e-01  4.82408861e-02  1.45597946e-02
 -4.80739055e-03 -9.95478569e-03 -2.85160269e-01 -6.26234538e-03
  1.77062499e-01 -4.96934964e-01 -8.57598051e-01  1.42247952e-01
 -5.21727637e-01  8.08412688e-01  4.05464452e-01 -4.65003507e-01
 -2.45487049e+00]
supnorm grad right now is: 2.4548704937729484
Weights right now are: 
[ 2.45203852e+00 -4.18284985e+00  2.25450140e+00  1.15448551e+01
 -2.19746981e+00  4.07415816e+00 -1.85556413e+00 -1.22608835e+01
  9.07714966e+01  3.71570762e+01  7.87106635e+01 -1.18243597e+00
  2.95589746e+01  2.05849159e+01 -2.17260086e+01 -2.36461932e+00
  6.68357033e+00 -1.32717378e+00  2.68770959e+01  2.80398635e+00
  5.51925784e+01  2.48344786e+01  5.99270676e+00  1.67516211e+01
  2.87736440e+00  1.55483504e+01 -8.44577181e-01  2.49474245e+02
  1.62313044e+00 -1.15066673e+01  1.08824934e+01 -7.97460332e+01
  1.11463142e+01 -7.29005410e+00  1.76498084e+01 -2.04748877e+01
  7.13008506e+00 -1.75308809e+01  7.99346651e+00 -2.59051935e+01
 -2.12948636e+00 -2.48065894e+00 -9.66050841e+00  1.35063969e+01
  3.73919668e+01  5.11585930e+00  9.36320654e-01  6.67506963e+01
 -3.45908974e+01  4.32397822e+00  1.64904647e+01 -4.26771599e+01
  6.05697506e+01  6.62895614e+01 -2.51636940e+00  2.94469448e+01
  4.84837804e+00 -4.70484177e+00 -1.91157749e+00 -3.86517285e+00
  4.87945876e+00  1.06936438e-01  5.94501639e+00 -4.34333261e+00
  3.10573447e+01]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.9511647895663
gradient value of function right now is: [ 5.12962215e-04  1.24307005e-01  1.56557717e+00  1.37839868e-02
 -5.12962215e-04 -1.24307005e-01 -1.56557717e+00 -1.37839868e-02
 -1.48564442e-04 -2.32237889e-04 -4.91265170e-08 -1.51685966e-05
  7.16787006e-02  8.05465576e-02  2.62478846e-02  3.70228389e-02
 -5.64596781e-01  1.20400059e+00  2.07689984e-03  1.08689276e+00
 -2.40213374e-02 -2.71822993e-02 -5.11096702e-06 -1.25095892e-03
  2.25542875e+00  3.49453750e-02  1.23370558e+00  7.61881189e-05
 -5.35537728e-01  4.25346341e-02 -3.18171342e-02  7.37405501e-04
  8.46030514e-02  2.74529021e-02  2.01118101e-03  6.13885504e-02
 -6.48049264e-01 -3.01738029e-01 -1.18225736e-01 -2.63176394e-02
 -7.37609325e-02 -5.05129005e-01 -1.91129338e-02 -6.47234503e-02
 -1.39797198e-02 -4.46607648e-01 -3.87862510e-01 -1.64646989e-02
  2.16590615e-02  4.10454380e-01  1.36294766e-01  2.08320168e-02
 -9.82503358e-04 -2.31768168e-02  1.50690346e-01 -6.82526494e-04
  5.11264295e-01 -5.55650215e-01  7.57574436e-01 -2.03429902e+00
 -4.09790223e-01  1.08993265e-01  9.85869654e-01 -1.13257150e+00
 -1.30160261e+01]
supnorm grad right now is: 13.016026118273938
Weights right now are: 
[ 2.78519448e+00 -3.73596737e+00  2.34913564e+00  1.28271720e+01
 -2.53062577e+00  3.62727568e+00 -1.95019837e+00 -1.35432004e+01
  9.15573294e+01  3.96894174e+01  7.87134341e+01  1.06424707e+00
  2.96303942e+01  2.11561683e+01 -2.13796458e+01 -2.23127707e+00
  7.09552907e+00 -1.22992789e+00  2.68379601e+01  2.85905686e+00
  5.44049317e+01  2.50360625e+01  5.64425944e+00  2.07904254e+01
  2.84623442e+00  1.60681962e+01 -6.69352879e-01  2.68263084e+02
  1.63886982e+00 -1.13501497e+01  1.09685063e+01 -8.16934135e+01
  1.15357753e+01 -7.59839723e+00  1.60035368e+01 -2.08748644e+01
  6.89442810e+00 -1.75311552e+01  8.72085184e+00 -2.54332753e+01
 -8.04522719e-01 -2.06888354e+00 -9.38634304e+00  1.48813473e+01
  3.81314219e+01  4.91869404e+00  8.37568957e-01  6.75429795e+01
 -3.38953211e+01  4.04521058e+00  1.70846209e+01 -4.23839338e+01
  6.12689389e+01  6.66689158e+01 -2.04265906e+00  3.00809324e+01
  4.77221920e+00 -4.78046993e+00 -1.50628475e+00 -3.71136580e+00
  5.27205886e+00  5.93208467e-02  5.35618252e+00 -4.19896560e+00
  3.09241125e+01]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1367.8827857309807
gradient value of function right now is: [ 9.89380796e-05  1.10155955e-02  2.96243869e-01  5.17883945e-03
 -9.89380796e-05 -1.10155955e-02 -2.96243869e-01 -5.17883945e-03
  4.89162007e-05 -2.95187005e-04 -8.08330971e-08 -1.52149249e-05
  2.50543794e-02 -1.37691481e-01 -1.51311485e-01 -2.10100387e-01
 -3.17664335e-01  2.38256884e+00  2.30507847e-02  1.64432184e+00
 -1.02147376e-03 -3.43441060e-02 -9.36900025e-06 -1.59449101e-03
  1.15353995e+00  3.79984580e-02  7.47659384e-01 -1.71777700e-04
 -8.80723399e-01 -9.18126522e-02 -1.32787748e-01  1.57068199e-03
 -1.49001368e+00 -4.95761911e-01 -4.45976286e-02 -5.54483775e-01
 -7.89607572e-01 -1.82672330e-01  1.94753957e-02 -1.36337605e-01
 -1.08537733e-01 -2.94808333e-01  1.25714332e-01 -5.72113940e-02
 -2.97562755e-02 -6.81581126e-01 -2.01762628e+00 -3.74081894e-02
  7.99157055e-03  5.61572904e-01  8.34098727e-02  5.09781537e-04
 -4.37287519e-02 -2.27336388e-01 -4.50961523e+00 -7.72075275e-02
  8.90188067e-01 -3.61607408e+00  2.97631122e+00 -1.56830227e+01
 -1.40651380e+00  5.69804214e+00  9.95206247e-01 -4.43370117e+00
 -9.56832148e+00]
supnorm grad right now is: 15.683022741334325
Weights right now are: 
[  2.88341203  -4.83182659   2.12029713  12.51960877  -2.62884332
   4.7231349   -1.72135986 -13.23563715  92.89922447  39.82598401
  78.71230586   1.24211153  28.34593928  20.71765749 -22.43940006
  -3.02415973   7.48001781  -1.31781656  26.72663181   2.61740505
  55.35776576  24.88313643   5.58533637  21.44237113   2.86698263
  16.19939271  -0.76410721 286.40776214   1.85955481 -11.62258741
  11.13241524 -81.3624448   11.13164039  -7.27096776  15.38701781
 -22.04931955   7.03719197 -18.15763432   8.1747334  -23.08307376
  -1.59687554  -2.73016122 -10.05678024  14.57967397  39.48358469
   4.59466899   0.39822154  68.83653165 -33.83240016   4.2634517
  17.13184674 -42.43599938  62.71470211  66.72015496  -2.80978343
  30.90799784   4.70860429  -4.72038615  -1.49456761  -3.92488373
   5.31983717   0.81279703   6.66415108  -3.92116702  31.12247732]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.6447058620738
gradient value of function right now is: [ 1.11084230e-04  7.74404474e-02  8.88623444e-01  6.25254799e-03
 -1.11084230e-04 -7.74404474e-02 -8.88623444e-01 -6.25254799e-03
 -1.27186923e-05 -1.67529247e-05 -2.48495247e-09 -4.48137342e-07
  5.23262127e-02  5.44880520e-02  2.28683863e-02  3.12497851e-02
 -5.01124262e-01  3.30080206e-01  2.73633892e-04  5.39316805e-02
 -1.18399989e-02 -9.82979511e-03 -1.33773670e-06 -2.21438339e-04
  1.61359941e+00  1.02760746e-02  1.26576868e+00 -6.43630204e-06
 -2.43337824e-01  1.62836319e-02 -3.80675845e-02 -2.17372357e-04
  1.00295343e-01  4.82429589e-02  9.52130776e-03  5.61662551e-02
 -5.14761237e-02  5.55096800e-04  2.50796442e-02  7.68727527e-04
 -1.08899616e-01 -3.53474985e-01 -9.26030934e-02 -6.71191553e-02
 -5.77912082e-03 -6.24785342e-02 -1.84127570e-02 -4.04195023e-03
  2.47788376e-02  2.61901154e-01  5.00657747e-02  1.60251978e-02
  8.00302348e-04  5.93625873e-03  1.64103164e-01  2.05182872e-03
  3.56852326e-01 -1.80420036e-01 -3.15365484e-01  5.79688973e-01
 -3.09975613e-01 -2.35293827e-01  5.50942554e-01 -1.53545544e-01
 -1.29113095e+01]
supnorm grad right now is: 12.91130948458994
Weights right now are: 
[ 1.03566369e+00 -3.89881219e+00  2.23802505e+00  1.19393646e+01
 -7.81094978e-01  3.79012050e+00 -1.83908778e+00 -1.26553929e+01
  9.50746309e+01  4.40200082e+01  7.87171360e+01  2.68278514e+00
  2.96616825e+01  2.14115215e+01 -2.19534735e+01 -2.39728502e+00
  6.68201957e+00 -1.29912110e+00  2.69149559e+01  2.84482101e+00
  5.46419495e+01  2.68454015e+01  5.70093207e+00  2.40110330e+01
  2.66424862e+00  1.64363031e+01 -9.80178814e-01  3.02789725e+02
  2.00606066e+00 -1.18018888e+01  1.10581391e+01 -8.04828361e+01
  1.17258229e+01 -7.01582673e+00  1.68460072e+01 -2.11364108e+01
  7.46403339e+00 -1.69738527e+01  8.62830519e+00 -2.52420653e+01
 -2.03699187e+00 -2.21692164e+00 -1.00473177e+01  1.43867923e+01
  4.06961452e+01  4.48586802e+00  9.57927507e-01  6.96010421e+01
 -3.20255991e+01  4.24602908e+00  1.70518524e+01 -4.08651438e+01
  6.32155564e+01  6.69428103e+01 -2.58767087e+00  3.06119404e+01
  4.79481980e+00 -4.90389320e+00 -1.89349439e+00 -3.69593655e+00
  5.26174090e+00 -1.92436843e-01  6.51967460e+00 -4.08657431e+00
  3.08734935e+01]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.1962873243945
gradient value of function right now is: [-2.50330706e-05 -1.23333693e-02  8.35315066e-01 -1.49016117e-03
  2.50330706e-05  1.23333693e-02 -8.35315066e-01  1.49016117e-03
  1.76771642e-06  4.86124449e-06  7.82847837e-10  2.70663214e-07
 -5.04043269e-03 -7.93953850e-03  3.57141851e-03  6.12703976e-03
  5.40774910e-02 -1.96334961e+00 -7.19221573e-03 -1.42901437e+00
  2.07152127e-03  4.21980476e-03  7.66436650e-07  2.39413719e-04
 -3.17387612e-01 -1.90516403e-02  1.92517678e-01  7.70737152e-05
  3.60721616e-03 -8.11668842e-02 -1.05882302e-02 -3.21769491e-03
  2.10071936e-01  6.63428640e-02  1.20244075e-02  6.83175582e-02
  4.17702606e-01  2.35659933e-01  1.12405901e-01 -2.53589016e-03
 -3.82814109e-03  7.15625498e-02 -1.40570360e-01 -1.29401874e-02
  2.23725890e-03  3.67512181e-01  2.07013110e-01  1.54142045e-03
  7.22471260e-04 -2.99571115e-01 -3.07281915e-02  2.63443688e-03
 -3.78659532e-03  1.39804558e-02  4.08064848e-02 -6.55409435e-03
 -1.77809432e-01 -1.71301017e-01 -1.24763049e+00  1.80851252e+00
 -7.44779847e-02  4.14567196e-01 -3.13730381e-01 -2.87332172e-01
 -2.13959322e+00]
supnorm grad right now is: 2.139593215108327
Weights right now are: 
[  0.91695553  -3.81839729   2.27422683  11.80474054  -0.66238681
   3.7097056   -1.87528957 -12.52076893  96.87481732  44.38991515
  78.71837698   3.27351427  29.18323795  22.02861397 -21.96537763
  -2.3247634    6.91769995  -1.49505325  26.81593303   2.1512572
  55.87120335  26.56356374   5.50393714  25.44425776   2.69171736
  16.62519801  -0.98278042 316.59138387   1.84032083 -12.0309386
  10.6384525  -82.63270691  12.23784316  -7.3955208   17.11841228
 -21.09288826   6.85428744 -16.72468587   8.2079798  -26.83498468
  -2.45195713  -2.27548027  -9.82578578  13.98557713  41.01825911
   5.49817125   1.86407967  69.94943211 -34.37033038   4.15830218
  16.41107544 -45.30570458  63.09458615  67.41267261  -2.10406492
  29.60415423   4.89090961  -4.93566484  -1.48221587  -3.96560175
   4.57849475   0.35425091   5.34344308  -4.19450887  30.89927333]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.8666202584925
gradient value of function right now is: [ 1.66104189e-04  3.18796093e-02  1.32777887e+00  6.35495341e-03
 -1.66104189e-04 -3.18796093e-02 -1.32777887e+00 -6.35495341e-03
 -5.51921346e-06 -2.97189549e-05 -8.94607475e-09 -3.21818787e-06
  2.31688487e-02 -7.97249090e-02 -8.94370849e-02 -1.21073076e-01
 -2.43540096e-01 -1.12411559e-01  1.28173362e-02  3.23607982e-01
 -5.68033355e-03 -1.96340377e-02 -5.87078981e-06 -1.80599995e-03
  8.54942053e-01  2.33167898e-02  5.23414011e-01 -5.43099833e-05
 -7.15515177e-01 -1.04059441e-01 -1.00488318e-01 -1.69898385e-03
 -8.26018579e-01 -2.42084713e-01 -3.27122830e-02 -3.38694254e-01
  1.91089719e-01  1.13223387e-01  5.13151335e-02 -4.37553958e-02
 -3.60901670e-02 -2.12098017e-01  4.89075070e-02 -2.73335921e-02
 -6.23400179e-03 -2.70988043e-01 -4.82260179e-01 -8.41125235e-03
  7.36790606e-03  3.61012676e-01  5.46996275e-02  5.25454597e-03
 -1.82918027e-02 -9.33766951e-02 -2.26427265e+00 -3.20612718e-02
  3.48748607e-01 -1.39233446e+00  8.84885562e-01 -6.71487242e+00
 -9.08063289e-01  2.75979135e+00  4.84787688e-01 -1.48681129e+00
 -9.37487457e+00]
supnorm grad right now is: 9.374874565211769
Weights right now are: 
[  0.81409133  -4.22653281   2.26646281  12.57215202  -0.55952262
   4.11784111  -1.86752554 -13.28818041  98.46163304  48.6028122
  78.7196978    4.69011689  28.58060011  21.27730844 -22.82164459
  -3.48312975   7.11772262  -1.53389979  25.7116711    2.80886461
  56.02181126  26.53332107   5.37413974  29.27128177   2.53040268
  18.8349109   -0.99327934 329.78392847   2.11285562 -11.60300707
  11.84385981 -80.70529788  11.40523629  -8.01675795  17.91890734
 -22.18786565   6.96394058 -17.29343191   8.02798029 -26.50714925
  -2.17921955  -2.50164528  -8.9427539   13.30710199  40.46621562
   4.86949482   1.65214137  70.32625891 -35.61290512   4.42027791
  17.72897677 -47.40663458  64.27907296  68.16490378  -2.41582525
  30.37035342   4.92979567  -4.81671138  -1.32264199  -3.94624713
   4.90920017   0.59223778   5.58717844  -4.18489194  30.98376594]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1373.207662049906
gradient value of function right now is: [ 5.91859127e-06  6.48095443e-03  3.34922600e-01  6.29185834e-04
 -5.91859127e-06 -6.48095443e-03 -3.34922600e-01 -6.29185834e-04
  9.95825481e-08  4.13943101e-07  6.12184174e-11  6.78230379e-08
  7.41724305e-03 -1.85198978e-02 -2.01697005e-02 -2.29506119e-02
 -1.00468473e-01 -2.14918638e-01 -1.15510904e-03 -1.53225508e-01
 -1.20472334e-03 -1.58801389e-03 -1.40466346e-07 -1.64073409e-04
  3.81925699e-01  1.40595407e-04  2.52905831e-01 -5.00798429e-07
 -1.19508499e-01 -6.38971201e-03 -1.59317535e-02 -2.80527657e-04
 -3.07121876e-02 -2.11309497e-02 -7.75512509e-03 -2.66973940e-02
  1.20432243e-01  2.69178107e-02  6.83198947e-03  1.13512207e-02
 -5.09797525e-03 -7.72485582e-02 -7.31787244e-03 -1.51460002e-03
  7.26403570e-04  3.08757086e-02  7.84292283e-02  1.39139978e-03
  5.60640624e-03  6.28575371e-02  2.38900792e-02  4.61972505e-03
  1.68050977e-03  7.70217518e-03  7.68885890e-02  2.92147132e-03
  5.67724424e-02  1.07864443e-01 -1.92727436e-01  4.70612565e-01
 -1.26183629e-01  1.87038411e-01  9.96499000e-02  1.30756380e-01
 -1.36229538e+00]
supnorm grad right now is: 1.3622953846543975
Weights right now are: 
[ -2.7588351   -3.52308639   2.3048076   11.63168707   3.01340381
   3.4143947   -1.90587033 -12.34771545  97.99129611  49.79436415
  78.72012objective value function right now is: -1373.494885962787
gradient value of function right now is: [ 1.64657237e-01  4.55258420e-01  7.80189137e-03  4.41674968e-05
 -1.64657237e-01 -4.55258420e-01 -7.80189137e-03 -4.41674968e-05
  1.89520351e-01  8.44703018e-04  1.78321741e-03  3.15400600e-01
 -6.76423164e-04 -5.20715834e-02 -1.90531136e-01 -4.95370004e-01
 -1.27545822e-07  3.71142007e-02  6.44392569e-02  7.83891168e-04
 -9.93533459e-08 -2.92678495e-06 -2.11756626e-05 -1.09841997e-04
  8.30721211e-04  4.62077672e-02  1.90620039e-02  4.71701130e-01
  8.58593952e-03  4.92035000e-01  3.04114676e-01  2.45468814e-01
 -6.87630956e-04 -1.07465650e-01 -4.44111738e-02 -1.34524475e-01
  2.86996952e-03  2.34594013e-01  8.5794.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1373.241325879816
gradient value of function right now is: [ 6.37763948e-06  1.01612159e-02  3.14949815e-01  6.56857128e-04
 -6.37763948e-06 -1.01612159e-02 -3.14949815e-01 -6.56857128e-04
  3.72161159e-07  1.98468552e-06  2.09226011e-10  2.51191469e-07
  8.02207065e-03  3.60059262e-04 -5.87942691e-03 -4.15202588e-03
 -1.25523659e-01 -8.57341495e-02 -6.12227151e-04 -6.44933936e-02
 -1.06068146e-03 -1.83875802e-03 -1.11600122e-07 -1.47286934e-04
  4.77006745e-01  9.69199452e-05  4.11926973e-01  1.39003613e-06
 -1.14941280e-01 -7.27680752e-03 -1.41750174e-02 -3.91686501e-04
  1.62920121e-02  1.04482056e-02  5.88739241e-03  5.28086114e-03
  5.96180640e-02  1.29879946e-02  7.03830452e-03  5.46598505e-03
 -1.85886563e-02 -1.01843953e-01 -2.63989625e-02 -1.22816280e-02
 -8.84030920e-05  2.50539957e-02  2.98592546e-02  6.73740541e-05
  5.83031378e-03  5.18896480e-02  1.64197044e-02  4.58531401e-03
  7.24297538e-04  4.80398750e-03  6.14116279e-02  1.35456888e-03
  6.07076657e-02  2.22785010e-02 -1.87078589e-01  3.45802755e-01
 -5.64999847e-02  1.85037637e-02  1.30636484e-01 -2.19423782e-03
 -1.72028444e+00]
supnorm grad right now is: 1.720284436937459
Weights right now are: 
[-2.33363199e+00 -3.51454407e+00  2.29328074e+00  1.21715588e+01
  2.58820070e+00  3.40585238e+00 -1.89434347e+00 -1.28875871e+01
  1.01216104e+02  5.08851688e+01  7.87218210e+01  5.41892558e+00
  2.90803808e+01  2.28014260e+01 -2.20001880e+01 -2.33128686e+00
  7.05828361e+00 -1.51497712e+00  2.75901169e+01  2.78288139e+00
  5.49025634e+01  objective value function right now is: -1373.4811573453458
gradient value of function right now is: [ 1.63817717e-01  4.19160280e-01  7.31832611e-03  4.70669795e-05
 -1.63817717e-01 -4.19160280e-01 -7.31832611e-03 -4.70669795e-05
  1.91462412e-01  7.61055045e-04  1.60983512e-03  3.20512915e-01
 -6.34847570e-04 -4.02788404e-02 -1.12376625e-01 -5.68137552e-01
 -2.54134206e-07  3.61860303e-02  6.26524668e-02  7.92292399e-04
 -4.50235721e-08 -2.64998680e-06 -2.55162040e-05 -1.25830795e-04
  3.56515616e-04  4.17872241e-02  1.44646121e-02  4.60654997e-01
  8.19847155e-03  4.31804039e-01  2.68809286e-01  2.05374870e-01
 -1.25804288e-04 -9.53988177e-02 -3.54511831e-02 -1.14470980e-01
  2.60919913e-04  2.43792766e-01  7.96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1373.2415100163885
gradient value of function right now is: [ 4.19143080e-06  1.10945584e-02  2.90401453e-01  5.53852596e-04
 -4.19143080e-06 -1.10945584e-02 -2.90401453e-01 -5.53852596e-04
  2.35068613e-07  1.66383015e-06  1.60719930e-10  2.18888611e-07
  7.64333757e-03  8.09072811e-03  1.09750392e-03  4.05905959e-03
 -1.18409777e-01 -1.05047095e-01 -6.60966130e-04 -8.42179225e-02
 -9.45384982e-04 -1.55231325e-03 -8.21480915e-08 -1.26313760e-04
  4.45950448e-01 -2.78923881e-04  3.81779937e-01  1.40674989e-06
 -1.04292617e-01 -5.60295243e-03 -1.18262782e-02 -4.38371123e-04
  4.09242723e-02  1.89804112e-02  8.28067584e-03  1.92129047e-02
  7.76150522e-02  1.89730938e-02  8.16308426e-03  7.95664002e-03
 -1.50370847e-02 -8.81480967e-02 -2.74113206e-02 -1.00523369e-02
  4.25592543e-04  2.95523216e-02  6.22886105e-02  7.05964800e-04
  5.58117389e-03  4.48466580e-02  1.32770771e-02  4.46363538e-03
  1.28191437e-03  7.53178812e-03  1.36815313e-01  2.29097499e-03
  4.63211580e-02  7.98099654e-02 -2.02007466e-01  5.62899866e-01
 -2.51957169e-02 -1.04109572e-01  1.05068600e-01  6.40279653e-02
 -1.47513356e+00]
supnorm grad right now is: 1.4751335603597717
Weights right now are: 
[-6.44721746e-01 -3.91723018e+00  2.31288188e+00  1.23700613e+01
  8.99290457e-01  3.80853849e+00 -1.91394461e+00 -1.30860896e+01
  1.020931objective value function right now is: -1373.509137586401
gradient value of function right now is: [ 1.65127656e-01  4.22867383e-01  6.57667027e-03  6.07550683e-05
 -1.65127656e-01 -4.22867383e-01 -6.57667027e-03 -6.07550683e-05
  1.90150372e-01  7.68979201e-04  1.80352847e-03  3.15421287e-01
 -6.65803125e-04 -3.64472324e-02 -7.82933036e-02 -5.56484662e-01
 -2.46740128e-07  3.16936995e-02  5.60948541e-02  9.01016782e-04
 -7.10734280e-08 -3.89510753e-06 -3.42892309e-05 -1.72301217e-04
  3.36228835e-04  4.21677563e-02  1.45368007e-02  4.37946609e-01
  8.21840550e-03  3.89973244e-01  2.40231606e-01  1.80054492e-01
 -1.55098193e-04 -1.05741949e-01 -3.90391468e-02 -1.26065607e-01
  1.16632375e-03  2.37484618e-01  7.98501338e-02  3.47704088e-01
  9.87727320e-05 -2.17455490e-04  4.63625012e-04  8.33715707e-18
 -2.05330907e-01 -1.76384131e-01 -2.55256733e-01 -5.50573391e-03
 -2.64664183e-02  1.28486112e-01 -5.02285192e98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1373.2310968913714
gradient value of function right now is: [ 3.77860852e-06  1.26247989e-02  3.12645248e-01  6.05855775e-04
 -3.77860852e-06 -1.26247989e-02 -3.12645248e-01 -6.05855775e-04
  2.19584067e-07  9.31373154e-07  8.57047267e-11  1.01290756e-07
  7.85365250e-03  1.29467645e-02  5.11480837e-03  8.90463412e-03
 -1.18027422e-01 -1.43235711e-01 -6.59664405e-04 -1.10565510e-01
 -1.08918414e-03 -1.60935087e-03 -8.95853541e-08 -1.16711648e-04
  4.33751104e-01 -1.65333087e-04  3.66760156e-01  4.81877877e-06
 -1.04463326e-01 -8.38027337e-03 -1.49034318e-02 -4.80727198e-04
  5.40939377e-02  2.45463611e-02  1.04952542e-02  2.72030523e-02
  1.06213316e-01  3.05752815e-02  1.53721088e-02  1.01521303e-02
 -1.37313397e-02 -8.95699389e-02 -2.94121884e-02 -8.94440261e-03
  7.32845555e-04  3.44135151e-02  8.53073040e-02  1.14572216e-03
  5.60869209e-03  4.82288466e-02  1.09790182e-02  4.39536232e-03
  1.59738766e-03  9.40021579e-03  1.77177978e-01  2.86273912e-03
  4.38981472e-02  1.15520015e-01 -2.35577955e-01  7.34061461e-01
 -1.55839613e-02 -1.62323962e-01  9.58111374e-02  1.11993473e-01
 -1.33561374e+00]
supnorm grad right now is: 1.3356137415470253
Weights right now are: 
[-4.39747431e-01 -3.74890434e+00  2.21244094e+00  1.37867281e+01
  6.94316141e-01  3.64021265e+00 -1.81350367e+00 -1.45027565e+01
  1.032334objective value function right now is: -1373.5009780498235
gradient value of function right now is: [ 1.62291709e-01  3.99251813e-01  7.23600537e-03  6.10086970e-05
 -1.62291709e-01 -3.99251813e-01 -7.23600537e-03 -6.10086970e-05
  1.91539451e-01  7.21098852e-04  1.78386397e-03  3.15436852e-01
 -6.28353183e-04 -2.97877851e-02 -5.38416055e-02 -5.35994844e-01
 -2.95138208e-07  3.54085119e-02  6.08938417e-02  8.51836520e-04
 -5.10898688e-08 -3.82879096e-06 -3.67239853e-05 -1.79259599e-04
  1.20918421e-04  3.99553161e-02  1.26752569e-02  4.34166904e-01
  8.56541390e-03  3.78489924e-01  2.28696007e-01  1.62351236e-01
  8.57905628e-05 -1.03693243e-01 -3.66816509e-02 -1.21966664e-01
  4.29980705e-04  2.25695217e-01  7.52398099e-02  3.29650531e-01
  6.69845472e-05 -2.23917236e-04  2.08200156e-04  6.46440923e-18
 -2.06933543e-01 -1.71460934e-01 -2.55593939e-01 -5.27366181e-03
 -2.64169118e-02  1.33860563e-01 -4.93030473100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1373.2172532581185
gradient value of function right now is: [ 3.66301023e-06  1.24885357e-02  3.10612562e-01  6.32187061e-04
 -3.66301023e-06 -1.24885357e-02 -3.10612562e-01 -6.32187061e-04
  2.83490329e-07  1.14936756e-06  9.49274860e-11  1.08643744e-07
  7.51327561e-03  1.37491877e-02  5.51828887e-03  9.45747887e-03
 -1.13687995e-01 -1.33844246e-01 -6.20260779e-04 -9.86901744e-02
 -1.09065431e-03 -1.77172518e-03 -9.45840907e-08 -1.16861968e-04
  4.17706121e-01 -7.81103068e-05  3.41486500e-01  6.14961591e-06
 -1.08343339e-01 -8.06164910e-03 -1.48145173e-02 -5.00849676e-04
  5.48746092e-02  2.56228896e-02  1.05840374e-02  2.78531390e-02
  1.04552940e-01  2.79861050e-02  1.45688254e-02  1.09405174e-02
 -1.14425357e-02 -8.47330819e-02 -2.88899523e-02 -7.85592570e-03
  6.94928234e-04  3.18637390e-02  8.25402517e-02  1.14794356e-03
  5.53916989e-03  5.18036908e-02  9.77234731e-03  4.32734955e-03
  1.64824965e-03  9.39063110e-03  1.81120008e-01  3.00952166e-03
  4.78647388e-02  1.22208583e-01 -2.23132259e-01  7.33133767e-01
 -2.45719079e-03 -1.77627380e-01  8.97217483e-02  1.14165057e-01
 -1.23201596e+00]
supnorm grad right now is: 1.232015963831879
Weights right now are: 
[-3.69933399e+00 -3.83501650e+00  2.27371972e+00  1.31625996e+01
  3.95390270e+00  3.72632481e+00 -1.87478245e+00 -1.38786280e+01
  1.02323020e+02  5.78266807e+01  7.87250529e+01  8.55324389e+00
  2.90763474e+01  2.34372455e+01 -2.28976633e+01 -2.86261475e+00
  6.61769336e+00 -1.08168563e+00  2.75837879e+01  3.06555604e+00
  5.49513061e+01  2.87978076e+01  5.11399553e+00  3.38447207e+01
  2.86059832e+00  1.98289690e+01 -7.72301943e-01  3.90389417e+02
  1.72562327e+00 -1.32049445e+01  1.11767054e+01 -8.35247201e+01
  1.23346453e+01 -6.44137155e+00  2.19508668e+01 -2.23648203e+01
  6.96923198e+00 -1.72950739e+01  7.73494966e+00 -2.54073641e+01
 -1.88876228e+00 -1.98932163e+00 -1.05555483e+01  1.48776779e+01
  4.46993154e+01  4.96102260e+00  9.91596970e-01  7.39703975e+01
 -3.50991958e+01  3.90423453e+00  1.78041507e+01 -5.04330554e+01
  6.77090671e+01  6.94562326e+01 -2.66798498e+00  3.10401707e+01
  4.69064628e+00 -5.27089462e+00 -1.72889012e+00 -3.89605031e+00
  5.60665034e+00 -3.56944761e-01  6.37624064e+00 -4.45895532e+00
  3.11104877e+01]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1105.670171572186
W_T_median: 1061.8670277494964
W_T_pctile_5: 961.0109749496194
W_T_CVAR_5_pct: 930.9529015871105
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.4
F value: -1373.2172532581185
-----------------------------------------------
