/home/marcchen/Documents/constrain_factor/researchcode/exp_config_json_files/multi_portfolio_TEST1_EFs_OOS_test.json
Starting at: 
13-08-23_11:00

 numpy seed:  3  


 pytorch seed:  3  

Key parameters-------
paths: 256000
iterations: 10
batchsize: 10
remove neg:  False
w constaint activation:  yy_fix_jan29


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
192601                  0.0                NaN  ...     0.000561     0.023174
192602                  0.0                NaN  ...    -0.033046    -0.053510
192603                  0.0                NaN  ...    -0.064002    -0.096824
192604                  0.0                NaN  ...     0.037029     0.032975
192605                  0.0                NaN  ...     0.012095     0.001035

[5 rows x 16 columns]
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
202208                  NaN            -0.0020  ...    -0.036240    -0.011556
202209                  NaN            -0.0955  ...    -0.091324    -0.099903
202210                  NaN             0.0883  ...     0.077403     0.049863
202211                  NaN            -0.0076  ...     0.052365     0.028123
202212                  NaN            -0.0457  ...    -0.057116    -0.047241

[5 rows x 16 columns]


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_nom_ret', 'VWD_nom_ret']
############# End: defined asset  basket #################
               CPI_nom_ret  B10_nom_ret  VWD_nom_ret
My identifier                                       
192607           -0.011299     0.005383     0.031411
192608           -0.005714     0.005363     0.028647
192609            0.005747     0.005343     0.005787
192610            0.005714     0.005323    -0.028996
192611            0.005682     0.005303     0.028554
               CPI_nom_ret  B10_nom_ret  VWD_nom_ret
My identifier                                       
202208           -0.000354    -0.043289    -0.036240
202209            0.002151    -0.050056    -0.091324
202210            0.004056    -0.014968     0.077403
202211           -0.001010     0.040789     0.052365
202212           -0.003070    -0.018566    -0.057116
Indices constructed with column names:
Index(['date_for_plt', 'CPI_nom_ret_ind', 'B10_nom_ret_ind',
       'VWD_nom_ret_ind'],
      dtype='object')
############# Updated: defined asset basket #################
timeseries_basket['data_df_mean'] = 
B10_real_ret    0.001637
VWD_real_ret    0.006759
dtype: float64


timeseries_basket['data_df_stdev'] = 
B10_real_ret    0.019258
VWD_real_ret    0.053610
dtype: float64


timeseries_basket['data_df_corr'] = 
              B10_real_ret  VWD_real_ret
B10_real_ret      1.000000      0.090987
VWD_real_ret      0.090987      1.000000


timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names', 'data_df', 'data_df_mean', 'data_df_stdev', 'data_df_corr'])
############# End: updated: defined asset basket #################
-----------------------------------------------
Dates to be REMOVED due to missing values (should be at *start* only due to trading signals):
Int64Index([], dtype='int64')
-----------------------------------------------
Dates from available data for bootstrapping:
Start: 192607
End: 202212
-----------------------------------------------
Bootstrap block size: 18
-----------------------------------------------
Dates USED bootstrapping:
Start: 196307
End: 202212
-----------------------------------------------
0.0% of bootstrap sample done.
5.0% of bootstrap sample done.
10.0% of bootstrap sample done.
15.0% of bootstrap sample done.
20.0% of bootstrap sample done.
25.0% of bootstrap sample done.
30.0% of bootstrap sample done.
35.0% of bootstrap sample done.
40.0% of bootstrap sample done.
45.0% of bootstrap sample done.
50.0% of bootstrap sample done.
55.00000000000001% of bootstrap sample done.
60.0% of bootstrap sample done.
65.0% of bootstrap sample done.
70.0% of bootstrap sample done.
75.0% of bootstrap sample done.
80.0% of bootstrap sample done.
85.0% of bootstrap sample done.
90.0% of bootstrap sample done.
95.0% of bootstrap sample done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 1, 'itbound_SGD_algorithms': 10, 'nit_IterateAveragingStart': 9, 'batchsize': 10, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.0, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-0.4030,  1.1678],
        [-6.8287,  3.8069],
        [-5.2573,  4.9220],
        [-0.4030,  1.1677],
        [-1.5898,  3.2823],
        [11.9210,  0.5791],
        [-9.9683, -2.5887],
        [-0.4031,  1.1681],
        [-5.8509,  4.7247],
        [-0.4030,  1.1677]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-0.5880,  9.0886, 10.6310, -0.5880,  2.9584, -9.2299,  5.1571, -0.5885,
        10.3841, -0.5880], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ -0.0192,  -0.0135,  -0.0283,  -0.0192,  -0.0105,  -0.1134,  -0.3819,
          -0.0192,  -0.0217,  -0.0192],
        [ -0.0192,  -0.0135,  -0.0283,  -0.0192,  -0.0105,  -0.1134,  -0.3819,
          -0.0192,  -0.0217,  -0.0192],
        [  0.0879,  -5.1375,  -7.2192,   0.0880,  -0.7425, -10.0519,   3.4787,
           0.0836,  -6.7936,   0.0880],
        [  0.1705,   1.1327,   1.3636,   0.1705,   0.4571,   2.7333,  -1.4545,
           0.1700,   1.2814,   0.1705],
        [ -0.0192,  -0.0135,  -0.0283,  -0.0192,  -0.0105,  -0.1134,  -0.3819,
          -0.0192,  -0.0217,  -0.0192],
        [ -0.0192,  -0.0135,  -0.0283,  -0.0192,  -0.0105,  -0.1134,  -0.3819,
          -0.0192,  -0.0217,  -0.0192],
        [  0.0764,   2.3801,   3.3061,   0.0765,   0.1615,   5.1495,  -1.2279,
           0.0724,   3.1476,   0.0765],
        [  0.0569,   2.7377,   3.8095,   0.0570,   0.1957,   5.7165,  -1.3894,
           0.0521,   3.6337,   0.0570],
        [ -0.0192,  -0.0135,  -0.0283,  -0.0192,  -0.0105,  -0.1134,  -0.3819,
          -0.0192,  -0.0217,  -0.0192],
        [ -0.0192,  -0.0135,  -0.0283,  -0.0192,  -0.0105,  -0.1134,  -0.3819,
          -0.0192,  -0.0217,  -0.0192]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.4521, -0.4521,  2.7107, -1.4973, -0.4521, -0.4521, -1.9096, -2.0744,
        -0.4521, -0.4521], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-2.3264e-03, -2.3265e-03, -1.3537e+01,  2.8178e+00, -2.3264e-03,
         -2.3265e-03,  5.6286e+00,  6.6825e+00, -2.3265e-03, -2.3264e-03]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  9.6619,   1.8792],
        [-11.1275,  -9.3829],
        [ -0.7640,   2.3386],
        [-15.8987,  -2.1848],
        [  1.4464,  -3.7003],
        [ -1.3485,   7.0094],
        [-10.7953,  -3.4060],
        [-16.7390,  -7.4016],
        [-10.1062,   0.2398],
        [ 13.4483,   7.3263]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ -3.8265, -10.1456,  -1.7694,   3.1299,  -2.7526,   5.3468,   0.6017,
         -0.3599,  10.2350,   3.4509], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 2.8805e+00, -6.3897e+00, -1.1708e+00, -1.7793e+00,  5.2160e+00,
         -3.0916e+00,  1.7544e-01,  2.0189e+00, -9.8472e+00,  6.8385e+00],
        [-8.9578e-01, -4.1011e-01, -1.6003e-01, -4.8636e-01, -8.6138e-01,
         -7.5602e-01, -4.7527e-01, -4.2523e-01, -9.2097e-01, -1.0898e+00],
        [-8.9578e-01, -4.1011e-01, -1.6003e-01, -4.8635e-01, -8.6139e-01,
         -7.5601e-01, -4.7527e-01, -4.2523e-01, -9.2096e-01, -1.0898e+00],
        [-5.0507e+00, -3.2645e+00, -1.3763e-03, -7.3646e+00, -3.0815e-02,
         -1.1596e+00,  3.8202e+00,  2.4896e+00,  1.3829e-01, -1.5157e+00],
        [ 2.6932e+00, -8.9755e-01,  3.8636e-01, -3.2866e+00,  4.3133e+00,
         -3.9535e+00, -7.2974e-01,  1.3788e-01, -7.6137e+00,  3.1699e+00],
        [-8.9578e-01, -4.1011e-01, -1.6003e-01, -4.8636e-01, -8.6138e-01,
         -7.5602e-01, -4.7527e-01, -4.2523e-01, -9.2098e-01, -1.0898e+00],
        [-1.9890e+00, -1.1498e+01, -5.3293e-01, -1.0894e+01,  3.9499e-01,
         -8.9672e+00,  1.1597e+00,  7.7891e+00,  7.1118e+00, -5.1127e+00],
        [-8.9578e-01, -4.1011e-01, -1.6003e-01, -4.8636e-01, -8.6138e-01,
         -7.5602e-01, -4.7527e-01, -4.2523e-01, -9.2098e-01, -1.0898e+00],
        [-8.9578e-01, -4.1011e-01, -1.6003e-01, -4.8636e-01, -8.6138e-01,
         -7.5602e-01, -4.7527e-01, -4.2523e-01, -9.2097e-01, -1.0898e+00],
        [ 1.3516e+00,  9.9232e-01,  1.3979e-02,  8.2047e-01,  1.8862e+00,
          9.9480e-01,  9.0109e-01,  1.0626e+00,  7.7496e-01,  1.4912e+00]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([ 5.9072, -1.5580, -1.5580, -1.1519,  3.9101, -1.5580, -1.5415, -1.5580,
        -1.5580,  2.6740], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-4.0472,  0.0385,  0.0385, -2.8688, -0.4765,  0.0385, -8.7037,  0.0385,
          0.0385,  3.9330],
        [ 3.8148, -0.0385, -0.0385,  2.8672,  0.4400, -0.0385,  8.7405, -0.0385,
         -0.0385, -4.0820]], device='cuda:0'))])
loaded xi:  -521.0411
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 824.4862807977031
W_T_median: 581.747974404808
W_T_pctile_5: -274.08412294578267
W_T_CVAR_5_pct: -400.5783006953572
-----------------------------------------------
new min fval from sgd:  -1722.2546730219908
min fval:  -1722.2546730219908
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 214.73224195336448
W_T_median: 58.850895692786075
W_T_pctile_5: -511.8480103555864
W_T_CVAR_5_pct: -608.3152833145213
Average q (qsum/M+1):  56.538357642389116
Optimal xi:  [-521.0411]
Expected(across Rb) median(across samples) p_equity:  0.40505775494966656
obj fun:  tensor(-1722.2547, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.05
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -4.9996,  -5.0207],
        [ -4.2388,  -4.3007],
        [ -4.5433,  -4.4808],
        [ -7.6690,   4.8651],
        [  0.6540,  -1.2941],
        [-11.8681,   2.8184],
        [ -4.7561,  -4.9571],
        [ -4.9647,  -5.2582],
        [ -4.8669,  -4.8321],
        [ -9.1051,   4.5727]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-3.9124, -4.4252, -3.7929,  7.1633,  0.6226,  8.4996, -4.7069, -4.9971,
        -3.7386,  7.7022], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-7.9771e-02, -2.5696e-02, -6.1177e-02, -5.1995e-03, -5.2523e-01,
         -5.5381e-02, -3.5165e-02, -3.3351e-02, -8.1786e-02, -7.2078e-03],
        [ 3.1603e+00,  1.8193e+00,  2.3516e+00, -3.4929e+00, -1.9618e+00,
         -6.3941e+00,  2.6169e+00,  3.2755e+00,  2.9384e+00, -5.2699e+00],
        [-7.9771e-02, -2.5696e-02, -6.1177e-02, -5.1995e-03, -5.2523e-01,
         -5.5381e-02, -3.5165e-02, -3.3351e-02, -8.1786e-02, -7.2078e-03],
        [-4.0626e+00, -2.5755e+00, -3.0197e+00,  5.0336e+00,  3.2254e+00,
          8.5455e+00, -4.0632e+00, -4.4698e+00, -3.4702e+00,  7.2650e+00],
        [ 2.4231e+00,  1.3637e+00,  1.7360e+00, -2.0612e+00, -1.9267e+00,
         -5.5229e+00,  1.8104e+00,  2.3296e+00,  2.1971e+00, -3.6187e+00],
        [-7.9771e-02, -2.5696e-02, -6.1177e-02, -5.1995e-03, -5.2523e-01,
         -5.5381e-02, -3.5165e-02, -3.3351e-02, -8.1786e-02, -7.2078e-03],
        [-7.9772e-02, -2.5697e-02, -6.1178e-02, -5.1996e-03, -5.2524e-01,
         -5.5381e-02, -3.5166e-02, -3.3351e-02, -8.1786e-02, -7.2079e-03],
        [ 4.6490e-01,  2.4811e-01,  3.4819e-01, -4.3803e-01, -1.7183e+00,
         -1.5856e+00,  3.0376e-01,  3.3930e-01,  4.4267e-01, -6.6522e-01],
        [-2.9249e+00, -1.6287e+00, -2.1283e+00,  1.9328e+00,  1.9482e+00,
          5.4256e+00, -2.3820e+00, -2.7770e+00, -2.7905e+00,  3.6233e+00],
        [-7.9771e-02, -2.5696e-02, -6.1177e-02, -5.1995e-03, -5.2523e-01,
         -5.5381e-02, -3.5165e-02, -3.3351e-02, -8.1786e-02, -7.2078e-03]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.5717,  0.5510, -0.5717, -1.5421,  0.4680, -0.5717, -0.5717, -0.4780,
        -1.0344, -0.5717], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 8.8450e-03, -6.7529e+00,  8.8450e-03,  9.9278e+00, -5.2717e+00,
          8.8450e-03,  8.8452e-03, -1.3970e+00,  5.5192e+00,  8.8451e-03]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -7.8040,   0.9557],
        [  4.2154,  -4.9768],
        [ -1.2096, -10.2845],
        [-11.4141,   2.2034],
        [ -1.5276,  -0.6808],
        [ 17.3931,   8.0022],
        [-12.9890,  -3.6409],
        [  2.5210,   1.6282],
        [  8.6280,  -1.8883],
        [-13.0428,  -9.4733]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([  1.2134,  -8.9485,  -8.4620,   7.4546,  -5.0023,   4.8641,   0.1623,
         -3.5691, -11.6727,  -9.3435], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ -1.0473,  -0.1637,  -0.1333,  -0.3498,   1.0516,  -1.3947,  -2.2530,
          -5.1456,  -1.9083,   0.8584],
        [ -0.5791,  -0.3085,  -0.3350,  -7.7368,  -1.6411,  -3.2682,  -0.2366,
           2.4683,  -0.8855,  -1.1108],
        [  1.1443, -10.6033,  -5.3983,   1.3473,  -3.3343,  -2.9763,   1.2052,
          -1.2757,  -6.0244,  16.8958],
        [  5.3134,  -1.7129,   2.3942,  -0.3185,  -0.8934,  -8.4109,   0.4457,
          -0.0817,  -0.7418,  -3.3505],
        [ -3.2884,  -0.2240,  -0.0646,   0.2067,   1.1662,   0.2187,  -2.2144,
          -8.3054,  -1.9684,   1.7396],
        [  1.9452,   0.9135,  -0.2746,  -6.8251,  -4.8353,  -8.7382,   4.8302,
           2.1597,  -8.7561,  -0.1280],
        [ -0.8270,  -1.3333,   0.5282,  -2.0347,  -1.9498,  -4.9840,  -0.7622,
           4.4081,   0.2493,  -2.5716],
        [ -0.2774,  -0.2134,  -0.1439,  -0.7914,   0.4186,  -1.0172,  -1.4560,
          -2.7989,  -1.4518,   0.9198],
        [  0.5797,  -4.6976,   5.6426,   2.7800,   4.1874,  -2.5266,  -1.4811,
          -4.8494,  -0.3257,  -4.4556],
        [ -0.0537,  -0.3142,  -0.1904,  -0.9512,   0.0488,  -1.7595,  -0.9473,
          -0.5197,  -0.9891,   0.1335]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-2.0844,  0.1764, -1.0475, -2.0143, -2.4441,  3.0121,  0.2190, -3.3948,
        -3.4377, -3.5541], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ -2.5345,  -2.8745,  12.8243,  -5.0996,  -3.3384,  -5.7047,  -2.8315,
          -1.9167,  -7.9285,  -0.8136],
        [  2.5497,   2.8446, -12.8315,   5.0998,   3.3360,   5.7693,   2.8386,
           1.9110,   8.0046,   0.8158]], device='cuda:0'))])
loaded xi:  -298.042
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 824.4862807977031
W_T_median: 581.747974404808
W_T_pctile_5: -274.08412294578267
W_T_CVAR_5_pct: -400.5783006953572
-----------------------------------------------
new min fval from sgd:  -1650.6444073429948
min fval:  -1650.6444073429948
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 266.99660869229905
W_T_median: 47.04481978272918
W_T_pctile_5: -293.7552714931511
W_T_CVAR_5_pct: -371.7710952339637
Average q (qsum/M+1):  55.64619691910282
Optimal xi:  [-298.042]
Expected(across Rb) median(across samples) p_equity:  0.4242944557219744
obj fun:  tensor(-1650.6444, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.2
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-6.0617, -7.7444],
        [ 3.4359, -2.3887],
        [ 5.4774, -4.7696],
        [-0.5025,  1.1031],
        [ 5.4503, -5.9474],
        [ 4.2698, -5.4601],
        [-0.5028,  1.1037],
        [10.6503,  4.2752],
        [ 2.6495,  7.4435],
        [-5.1311,  6.5724]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-7.4821, -6.5593, -7.0787, -1.2810, -7.7782, -6.1220, -1.2816, -7.4998,
         6.6360,  7.3801], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-0.1490, -0.0189, -0.2497, -0.0287, -0.3052, -0.4634, -0.0287, -0.0713,
         -0.4426, -0.2562],
        [-0.1490, -0.0189, -0.2497, -0.0287, -0.3052, -0.4634, -0.0287, -0.0713,
         -0.4426, -0.2562],
        [-5.4818, -1.5415, -4.5402, -0.0589, -5.3482, -5.3686, -0.0593, -9.3721,
          6.7155,  6.4930],
        [-0.1490, -0.0189, -0.2497, -0.0287, -0.3052, -0.4634, -0.0287, -0.0713,
         -0.4426, -0.2562],
        [-0.1490, -0.0189, -0.2497, -0.0287, -0.3052, -0.4634, -0.0287, -0.0713,
         -0.4426, -0.2562],
        [ 2.9447,  0.9029,  3.1125, -0.0682,  4.3250,  4.6866, -0.0686,  4.0737,
         -6.8952, -7.8005],
        [ 2.8787,  0.9172,  3.1289, -0.0763,  4.2288,  4.3971, -0.0766,  3.8901,
         -6.8852, -7.9066],
        [-0.1490, -0.0189, -0.2497, -0.0287, -0.3052, -0.4634, -0.0287, -0.0713,
         -0.4426, -0.2562],
        [-0.1490, -0.0189, -0.2497, -0.0287, -0.3052, -0.4634, -0.0287, -0.0713,
         -0.4426, -0.2562],
        [-0.1490, -0.0189, -0.2497, -0.0287, -0.3052, -0.4634, -0.0287, -0.0713,
         -0.4426, -0.2562]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.8330, -0.8330,  1.3707, -0.8330, -0.8330, -2.5553, -2.2914, -0.8330,
        -0.8330, -0.8330], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 6.4461e-03,  6.4461e-03,  1.3152e+01,  6.4461e-03,  6.4461e-03,
         -7.1134e+00, -7.0085e+00,  6.4461e-03,  6.4461e-03,  6.4461e-03]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -9.2653,   0.2854],
        [  6.6556,  11.9399],
        [  6.8846,   6.0612],
        [-11.3674,  -2.4302],
        [  1.7267,  13.7816],
        [ -9.3475,   9.3309],
        [-17.8471,  -3.1645],
        [ -7.1805,   9.3478],
        [ -2.1959,  -0.7606],
        [-11.7675,  -2.1296]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ 8.0573, 11.5150,  5.8297,  1.9729, 14.7190,  7.6001, -0.2100,  9.5073,
        -5.6134,  1.0843], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 4.9067e+00, -7.3150e+00, -4.8458e+00,  4.4848e+00, -1.2756e+01,
         -7.6073e-01,  4.5962e+00, -3.2681e+00,  3.4907e-02,  5.3308e+00],
        [-1.0255e+00, -3.7538e-01, -1.2298e+00, -6.4848e-01, -5.7876e-02,
          1.2164e-02, -3.8130e-01,  8.3243e-03, -3.8649e-01, -4.2283e-01],
        [-1.0255e+00, -3.7538e-01, -1.2298e+00, -6.4848e-01, -5.7876e-02,
          1.2164e-02, -3.8130e-01,  8.3231e-03, -3.8649e-01, -4.2283e-01],
        [-8.0891e+00,  1.4618e+00, -8.9143e-01, -8.6670e-01,  2.3714e+00,
          6.7124e-01, -6.6993e-01,  2.3478e+00, -6.9857e-01, -7.3322e-01],
        [ 5.7364e+00,  4.6798e-02, -4.2270e+00,  9.0069e-01,  1.9912e-01,
          2.7094e+00,  4.5314e+00,  2.0399e+00, -6.1616e+00,  2.0210e+00],
        [-1.0259e+00, -3.7465e-01, -1.2316e+00, -6.4918e-01, -5.7399e-02,
          1.2118e-02, -3.8135e-01,  8.0234e-03, -3.8656e-01, -4.2295e-01],
        [-5.7047e+00,  3.7630e-02, -8.5234e-01, -8.3230e+00, -1.2478e+00,
         -2.1970e-01, -2.2774e-02, -5.1309e+00,  7.4497e-02, -4.4269e+00],
        [-1.2145e+00,  6.9862e-01, -8.3962e-01, -3.5437e+00,  2.0680e+00,
         -4.4853e+00, -1.5962e-03,  2.2971e+00, -1.0998e-01, -1.4903e+00],
        [ 5.0768e+00, -8.4670e+00, -1.5051e+01,  3.5024e+00, -3.9894e+00,
         -1.1392e+00,  1.4380e+01, -6.9578e-01, -8.2442e-02,  5.4505e+00],
        [ 2.0979e+00,  5.1322e+00, -3.7124e+00,  3.2651e+00,  6.2768e+00,
         -1.3677e+01,  2.5434e+00, -1.8964e+00,  1.0269e+01,  2.5233e+00]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([ -4.8879,  -4.0039,  -4.0039,  -5.0817,  -6.1701,  -4.0024,  -1.4440,
         -5.5791,  -9.3941, -12.2752], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-5.1494e+00, -1.2198e-02, -1.5256e-02, -1.7307e+00,  8.3421e-01,
         -8.9664e-03,  4.1743e+00, -1.6764e+00,  9.2457e+00, -4.5744e+00],
        [ 4.9032e+00,  1.5339e-02,  1.2280e-02,  1.6967e+00, -6.7148e-01,
          1.8311e-02, -4.3855e+00,  1.6762e+00, -9.4095e+00,  4.3752e+00]],
       device='cuda:0'))])
loaded xi:  -158.46225
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 824.4862807977031
W_T_median: 581.747974404808
W_T_pctile_5: -274.08412294578267
W_T_CVAR_5_pct: -400.5783006953572
-----------------------------------------------
new min fval from sgd:  -1561.8817059228886
min fval:  -1561.8817059228886
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 328.79337983098475
W_T_median: 63.98968998744408
W_T_pctile_5: -158.12851497795214
W_T_CVAR_5_pct: -237.16251186960835
Average q (qsum/M+1):  54.208511844758064
Optimal xi:  [-158.46225]
Expected(across Rb) median(across samples) p_equity:  0.4314635954797268
obj fun:  tensor(-1561.8817, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.5
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -9.0259,   1.6200],
        [  9.0716,   0.0578],
        [  7.1793,  -6.1605],
        [  7.5381,   3.2505],
        [  9.6693,  -5.0357],
        [ -1.3449,   0.3001],
        [  1.4948,  -2.5906],
        [ -6.5573, -10.0162],
        [  4.3191,  -8.2380],
        [  5.3129,  -8.5238]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ 7.3420, -8.4146, -6.0056, -8.9126, -4.1491, -2.2581, -5.7163, -7.4441,
        -7.8151, -8.4529], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-5.2406e-01, -1.7716e-01, -5.6921e-01, -4.3256e-02, -8.8757e-01,
         -1.0491e-02, -8.0224e-03,  1.3355e-01, -1.9132e-01, -2.1281e-01],
        [-5.2406e-01, -1.7716e-01, -5.6921e-01, -4.3256e-02, -8.8757e-01,
         -1.0491e-02, -8.0224e-03,  1.3355e-01, -1.9132e-01, -2.1281e-01],
        [-5.2406e-01, -1.7716e-01, -5.6921e-01, -4.3256e-02, -8.8757e-01,
         -1.0491e-02, -8.0224e-03,  1.3355e-01, -1.9132e-01, -2.1281e-01],
        [-5.2406e-01, -1.7716e-01, -5.6921e-01, -4.3256e-02, -8.8757e-01,
         -1.0491e-02, -8.0224e-03,  1.3355e-01, -1.9132e-01, -2.1281e-01],
        [-9.2020e+00,  5.4065e+00,  2.8772e+00,  4.8714e+00,  1.6951e+00,
          9.5674e-02,  2.6977e-01,  6.2889e+00,  6.2490e+00,  3.6956e+00],
        [ 1.0659e+01, -5.1375e+00, -5.5630e+00, -5.5762e+00, -4.6171e+00,
          1.2856e-01, -1.1658e+00, -6.2914e+00, -7.4374e+00, -5.2700e+00],
        [-5.2413e-01, -1.7724e-01, -5.6925e-01, -4.3312e-02, -8.8777e-01,
         -1.0492e-02, -8.0194e-03,  1.3355e-01, -1.9131e-01, -2.1281e-01],
        [-5.2406e-01, -1.7716e-01, -5.6921e-01, -4.3256e-02, -8.8757e-01,
         -1.0491e-02, -8.0224e-03,  1.3355e-01, -1.9132e-01, -2.1281e-01],
        [-8.7807e+00,  4.7062e+00,  2.8038e+00,  3.8880e+00,  1.8033e+00,
          1.4201e-01,  1.9636e-01,  6.0533e+00,  5.7920e+00,  3.4498e+00],
        [-8.5582e+00,  4.6390e+00,  2.6593e+00,  3.6119e+00,  1.8101e+00,
          1.4993e-01,  1.7458e-01,  5.8599e+00,  5.7528e+00,  3.3968e+00]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.9148, -0.9148, -0.9148, -0.9148, -3.4273,  4.5581, -0.9151, -0.9148,
        -3.4455, -3.4434], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 6.4029e-03,  6.4029e-03,  6.4029e-03,  6.4029e-03, -6.4204e+00,
          1.6896e+01,  6.4026e-03,  6.4029e-03, -5.7940e+00, -5.5530e+00]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  7.7801,   8.5117],
        [-12.8039,  -3.3197],
        [-14.0960,  -3.3781],
        [-10.3438,  13.1059],
        [ -6.7274,   3.2029],
        [ 11.3494,  -0.2092],
        [ 10.9206,   1.8935],
        [  6.0962,  -1.4135],
        [ -0.2963,  10.7227],
        [-11.1179,  -4.1613]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([  7.3157,  -1.9104,  -2.0167,  11.5895,   3.0902, -10.3992,  -3.2258,
        -11.9670,   9.7899,  -0.1907], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-1.1204e+00, -4.8217e-01, -1.2984e-01, -3.9602e+00,  2.8329e+00,
          4.0120e+00, -1.4919e-01,  2.1667e+00, -5.0218e-01, -1.3871e+01],
        [-1.3321e+00, -5.5194e-01, -4.4665e-01,  2.4663e+00, -5.7744e-01,
          8.3623e-01, -2.1840e+00,  1.8294e-02,  1.2065e+00, -2.0505e+00],
        [ 7.6812e-01,  3.7889e+00,  4.6433e+00, -6.0243e+00,  2.2376e-01,
         -6.6894e+00, -4.5433e+00, -4.5007e-02,  5.9901e+00, -4.0033e-01],
        [ 8.0559e-01, -3.0883e+00, -2.2335e+00,  6.0347e+00,  3.1022e+00,
         -1.0734e+01, -5.7229e+00, -2.3178e-02,  3.6155e+00, -7.1234e-01],
        [-1.8985e+01,  7.2784e+00,  1.0297e+01, -4.8164e+00,  8.6606e-01,
         -5.7802e+00, -6.1329e+00, -2.3282e+00, -4.0583e+00,  3.9973e+00],
        [-8.3172e+00,  7.8510e+00,  8.0024e+00, -1.6984e+01, -2.4242e+00,
         -8.1970e+00, -4.3623e+00, -4.1766e+00, -1.4006e+01,  5.7935e+00],
        [-1.0779e-01,  4.5688e-01,  3.0178e-01,  2.5827e+00,  2.1453e+00,
         -5.3619e+00, -2.7556e+00,  4.3528e-03,  5.2351e-01,  8.5108e-01],
        [-1.6100e+00,  3.8398e+00,  3.2810e+00, -1.0011e+01, -1.5281e+00,
         -4.8466e+00, -2.2404e+00,  6.6782e-01, -1.1001e+01,  8.8575e-01],
        [ 3.7104e+00,  7.5672e+00,  8.9019e+00, -1.6178e+01, -8.3096e-01,
         -1.7622e+00, -1.5875e+00,  5.6997e-01, -9.7621e-02, -8.4607e-01],
        [-1.1953e+01,  4.3930e+00,  6.1183e+00, -5.1416e+00, -3.5599e-01,
         -4.5375e+00, -4.5225e+00, -1.8014e+00, -2.6516e+00,  3.8139e+00]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-3.8622, -4.0911, -5.7102, -5.2697, -4.8399,  0.2404, -5.4978, -0.0417,
        -4.6828, -4.0470], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[  3.1935,  -1.0137,  -2.4010,   0.3391,  11.2912,  -6.6207,   1.0781,
          -3.5835,   2.2661,   6.5807],
        [ -2.8140,   1.0718,   2.4322,  -0.5105, -11.2830,   6.6898,  -0.9991,
           3.6558,  -2.4912,  -6.5667]], device='cuda:0'))])
loaded xi:  -34.98991
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 824.4862807977031
W_T_median: 581.747974404808
W_T_pctile_5: -274.08412294578267
W_T_CVAR_5_pct: -400.5783006953572
-----------------------------------------------
new min fval from sgd:  -1473.9279221805125
min fval:  -1473.9279221805125
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 426.6394078438367
W_T_median: 143.91835258642888
W_T_pctile_5: -34.99173281837602
W_T_CVAR_5_pct: -142.4545020766441
Average q (qsum/M+1):  52.141357421875
Optimal xi:  [-34.98991]
Expected(across Rb) median(across samples) p_equity:  0.3734800087908904
obj fun:  tensor(-1473.9279, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-13.0642,   1.5323],
        [ 12.6431,  -1.1906],
        [  8.9200,  -7.9015],
        [  9.3468,   2.8194],
        [ 13.0982,  -4.7256],
        [ -1.1368,   0.2529],
        [ -1.1368,   0.2529],
        [-13.4527, -11.3754],
        [  4.8189,  -9.9287],
        [  7.8612,  -9.7289]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ 10.1841, -10.7213,  -7.1193, -11.5018,  -4.1533,  -2.2075,  -2.2075,
         -7.9212,  -9.4853,  -9.2265], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-3.9944e-01, -3.6083e-01, -2.7668e-01, -1.5632e-01, -9.7704e-01,
         -1.4244e-02, -1.4244e-02,  2.2084e-03, -4.6983e-02, -1.2098e-01],
        [-3.9944e-01, -3.6083e-01, -2.7668e-01, -1.5632e-01, -9.7704e-01,
         -1.4244e-02, -1.4244e-02,  2.2084e-03, -4.6983e-02, -1.2098e-01],
        [-3.9944e-01, -3.6083e-01, -2.7668e-01, -1.5632e-01, -9.7704e-01,
         -1.4244e-02, -1.4244e-02,  2.2084e-03, -4.6983e-02, -1.2098e-01],
        [-3.9944e-01, -3.6083e-01, -2.7668e-01, -1.5632e-01, -9.7704e-01,
         -1.4244e-02, -1.4244e-02,  2.2085e-03, -4.6983e-02, -1.2098e-01],
        [-1.2169e+01,  7.9889e+00,  4.1903e+00,  3.7985e+00,  1.5319e-01,
          2.8441e-03,  2.8441e-03,  5.4058e+00,  8.9079e+00,  7.5658e+00],
        [ 1.3218e+01, -7.8270e+00, -6.3138e+00, -3.8408e+00, -4.7952e+00,
          4.6172e-02,  4.6171e-02, -6.1982e+00, -8.4926e+00, -7.4810e+00],
        [-3.9944e-01, -3.6083e-01, -2.7668e-01, -1.5632e-01, -9.7704e-01,
         -1.4244e-02, -1.4244e-02,  2.2084e-03, -4.6983e-02, -1.2098e-01],
        [-3.9944e-01, -3.6083e-01, -2.7668e-01, -1.5632e-01, -9.7704e-01,
         -1.4244e-02, -1.4244e-02,  2.2084e-03, -4.6983e-02, -1.2098e-01],
        [-8.9339e+00,  4.6124e+00,  2.9492e+00,  1.5555e+00,  1.3048e-01,
          1.9217e-02,  1.9217e-02,  4.4625e+00,  6.0922e+00,  5.6428e+00],
        [-3.9945e-01, -3.6084e-01, -2.7668e-01, -1.5633e-01, -9.7691e-01,
         -1.4241e-02, -1.4241e-02,  2.2105e-03, -4.6979e-02, -1.2098e-01]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.9976, -0.9976, -0.9976, -0.9976, -3.8370,  4.9134, -0.9976, -0.9976,
        -3.4187, -0.9981], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[  0.0184,   0.0184,   0.0184,   0.0184, -10.5320,  14.0892,   0.0184,
           0.0184,  -5.3386,   0.0184]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 1.1044e+01,  9.5937e+00],
        [-1.6936e+01, -4.2164e+00],
        [-1.8136e+01, -4.5055e+00],
        [-1.4413e+01,  1.1752e+01],
        [-2.9041e+00,  5.5249e+00],
        [ 1.4404e+01, -2.4874e-03],
        [ 1.1987e+01,  1.2122e+00],
        [-1.9580e+00, -1.0238e-01],
        [ 2.0744e+00,  1.3468e+01],
        [-1.5706e+01, -5.2833e+00]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([  7.3581,  -3.1712,  -2.4809,  11.1388,  -2.4996, -13.6870,  -7.8456,
         -4.5653,  12.2015,   0.0654], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-7.2597e-01,  1.1541e-03, -2.8803e-03, -2.2145e+00,  2.2668e+00,
          4.0204e+00,  1.2547e+00, -6.9057e-01, -1.7899e+00, -2.1420e+01],
        [ 4.9172e-01,  4.9069e-02,  6.7483e-02, -8.6906e-01,  2.2066e-01,
          4.7230e-01, -5.2333e-01, -8.1344e-04,  4.9630e-01, -2.8814e+00],
        [-5.1549e-01,  5.5848e+00,  6.1929e+00, -8.2516e+00, -2.2938e-01,
         -1.4812e+00, -4.1515e+00,  9.3438e-02,  1.1577e+01,  3.7180e+00],
        [ 9.6384e-01, -2.5930e+00, -4.2764e+00,  6.1344e+00,  3.3988e+00,
         -1.6516e+01, -5.2681e+00,  3.1101e-01,  3.4987e+00,  8.9152e-01],
        [-2.4888e+01,  9.2113e+00,  1.2279e+01,  2.0346e+00, -2.3485e-03,
         -1.1275e+01, -4.4131e+00, -6.5048e-01, -1.6144e+01,  5.4345e+00],
        [-6.7528e+00,  6.1765e+00,  7.7311e+00, -1.5078e+01, -1.4373e-02,
         -1.5416e+01, -7.1383e+00,  9.1411e-01, -1.4361e+01,  7.2360e+00],
        [-1.3674e-02,  4.7080e-03,  1.0665e-02, -4.9970e-01,  2.1409e-01,
          9.4456e-01, -3.1433e-01,  7.1149e-02, -3.0943e-01, -3.6817e+00],
        [-8.1926e-01,  5.8479e+00,  1.1164e+01, -1.2991e+01, -1.6185e-02,
         -7.6220e+00, -3.4096e+00,  9.7717e-01, -1.5286e+01,  3.2028e+00],
        [ 3.3245e+00,  9.4192e+00,  1.0729e+01, -1.4101e+01, -5.1100e-01,
          4.5775e-01, -1.3282e+00,  5.4061e-01,  7.5734e-01,  4.9870e-01],
        [-2.1960e+00, -9.8204e-02, -2.0610e-01, -1.0153e+00, -7.9997e-01,
         -1.4720e-03, -2.6184e-01,  7.5785e-02, -2.3987e+00, -1.5081e+00]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([ -5.0396,  -6.1471, -12.7174,  -5.6280,  -6.2336,  -1.7459,  -6.6468,
         -1.9269,  -5.5974,  -3.8198], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[  4.1267,   2.8141,  -2.9308,   0.2552,  16.2933,  -5.3410,   2.4158,
          -4.3208,   1.9190,  -2.0864],
        [ -3.8077,  -2.7910,   2.9557,  -0.4210, -16.2818,   5.3882,  -2.3964,
           4.3868,  -2.1340,   2.0864]], device='cuda:0'))])
loaded xi:  -34.99156
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 824.4862807977031
W_T_median: 581.747974404808
W_T_pctile_5: -274.08412294578267
W_T_CVAR_5_pct: -400.5783006953572
-----------------------------------------------
new min fval from sgd:  -1400.4793352715712
min fval:  -1400.4793352715712
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 464.77632422457907
W_T_median: 168.92339650137617
W_T_pctile_5: -34.99205153864853
W_T_CVAR_5_pct: -135.4173289249723
Average q (qsum/M+1):  51.729192918346776
Optimal xi:  [-34.99156]
Expected(across Rb) median(across samples) p_equity:  0.3820376808444659
obj fun:  tensor(-1400.4793, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.5
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-1.4095e+01,  1.4828e+00],
        [ 1.3241e+01, -9.6879e-01],
        [ 1.0360e+01, -5.7290e+00],
        [ 9.2642e+00,  2.4189e+00],
        [ 7.2567e+00, -3.2105e+00],
        [-1.3719e+00,  6.8569e-03],
        [-1.3719e+00,  6.8567e-03],
        [-7.7716e+00, -1.1853e+01],
        [ 5.2269e+00, -1.0569e+01],
        [ 9.0036e+00, -9.5951e+00]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([  9.5501, -10.9580,  -6.7208, -12.8180,  -7.9108,  -2.6551,  -2.6551,
         -9.2646,  -8.8604,  -8.6326], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-5.5339e-01, -5.4769e-01, -4.9619e-01, -1.1141e-01, -2.9662e-02,
         -1.9241e-02, -1.9241e-02, -5.7592e-02, -1.3095e-01, -2.3517e-01],
        [-5.5339e-01, -5.4769e-01, -4.9619e-01, -1.1141e-01, -2.9662e-02,
         -1.9241e-02, -1.9241e-02, -5.7592e-02, -1.3095e-01, -2.3517e-01],
        [-5.5339e-01, -5.4769e-01, -4.9619e-01, -1.1141e-01, -2.9662e-02,
         -1.9241e-02, -1.9241e-02, -5.7592e-02, -1.3095e-01, -2.3517e-01],
        [-5.5339e-01, -5.4769e-01, -4.9619e-01, -1.1141e-01, -2.9662e-02,
         -1.9241e-02, -1.9241e-02, -5.7592e-02, -1.3095e-01, -2.3517e-01],
        [-1.3198e+01,  8.0784e+00,  4.2881e+00,  4.2494e+00,  5.7234e-01,
         -1.1578e-01, -1.1578e-01,  9.3484e+00,  8.9983e+00,  7.9390e+00],
        [ 1.1768e+01, -8.7466e+00, -6.3017e+00, -4.7895e+00, -2.6329e+00,
         -6.8286e-02, -6.8286e-02, -1.0707e+01, -9.8367e+00, -8.1594e+00],
        [-5.5339e-01, -5.4769e-01, -4.9619e-01, -1.1141e-01, -2.9662e-02,
         -1.9241e-02, -1.9241e-02, -5.7592e-02, -1.3095e-01, -2.3517e-01],
        [-5.5339e-01, -5.4769e-01, -4.9619e-01, -1.1141e-01, -2.9662e-02,
         -1.9241e-02, -1.9241e-02, -5.7592e-02, -1.3095e-01, -2.3517e-01],
        [-1.0861e+01,  5.8828e+00,  3.4191e+00,  2.7543e+00,  3.0645e-01,
          7.8790e-02,  7.8790e-02,  8.1406e+00,  7.3332e+00,  6.7039e+00],
        [-5.2028e+00,  2.0456e+00,  1.2368e+00,  3.4645e-01, -6.1412e-02,
         -1.2815e-02, -1.2815e-02,  4.6324e-02,  6.7535e-01,  1.9050e+00]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-1.6973, -1.6973, -1.6973, -1.6973, -3.8611,  2.8324, -1.6973, -1.6973,
        -3.8084, -3.6931], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 3.9142e-03,  3.9142e-03,  3.9142e-03,  3.9142e-03, -1.0336e+01,
          1.3758e+01,  3.9142e-03,  3.9142e-03, -6.3906e+00, -1.6833e+00]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 10.0377,  10.1784],
        [-14.4470,  -3.9341],
        [-16.4146,  -4.5078],
        [-14.5495,  13.2109],
        [ -2.5324,   0.1239],
        [ 13.7790,  -0.8557],
        [ 12.7832,   2.6089],
        [ -2.4361,   0.2228],
        [  4.8160,  12.6250],
        [-16.0793,  -5.6681]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([  7.6410,  -3.3990,  -2.7479,  12.0901,  -4.5001, -13.9524,  -7.8478,
         -4.4505,  10.5293,   0.2127], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-1.0769e+00,  1.1569e-02,  7.5214e-03,  6.3525e-02, -2.6944e-01,
          2.7333e+00,  8.5426e-01, -1.3656e-01, -4.8259e-01, -2.5713e+01],
        [ 2.1604e-01, -1.4987e+00, -4.0272e-01, -1.2159e+00, -4.8228e-01,
         -1.7634e+00,  1.2862e+00, -2.4006e-01,  1.0851e+00, -5.7952e-01],
        [-1.7550e+00,  1.0221e-01,  1.3224e-01, -3.7320e-02,  1.2032e-03,
         -6.3090e-01, -7.9344e-01,  9.5926e-04, -6.8060e-01, -1.2575e-01],
        [ 9.1711e-02, -1.9103e+00, -4.9428e+00,  3.6400e+00,  5.1210e-01,
         -2.6328e+01, -1.7679e+00,  3.9185e-01,  1.6072e+00,  1.8349e+00],
        [-3.1090e+01,  7.4356e+00,  1.0517e+01,  1.0607e+00, -5.6045e-01,
         -1.1747e+01, -3.0856e-01, -5.6744e-01, -8.8143e+00,  6.3060e+00],
        [-9.7907e+00,  7.2116e+00,  1.1078e+01, -1.1065e+01,  4.5397e-01,
         -1.2956e+01, -1.0423e+01,  4.2053e-01, -1.9361e+01,  1.0729e+01],
        [-1.3808e+00,  1.8244e-02,  3.7178e-02, -7.0107e-02, -2.4507e-03,
         -5.9926e-01, -7.9087e-01, -2.6927e-03, -5.8077e-01, -5.3643e-01],
        [-8.7629e-02,  6.8676e+00,  9.6212e+00, -1.8942e+01,  6.7030e-02,
         -4.8739e+00, -3.7146e+00,  9.3540e-02, -9.8147e+00,  3.5154e+00],
        [ 3.2742e+00,  7.7088e+00,  9.6107e+00, -1.2114e+01,  4.6441e-01,
          1.0537e+00, -1.8883e+00,  2.6294e-01,  6.9994e-01,  1.2966e+00],
        [-1.8373e+00,  1.5003e-01,  8.3366e-02, -3.1708e-01,  9.4206e-03,
          1.9364e-01, -8.6022e-01,  1.0310e-02, -1.1506e+00,  2.2345e-01]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-4.0850, -5.7178, -5.7348, -5.7639, -7.9029, -4.6761, -5.8401, -2.2040,
        -6.4756, -5.5844], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[  4.7852,   4.3785,  -0.2455,   1.1511,  18.6943,  -6.3183,  -0.0902,
          -3.4661,   2.9100,  -0.7604],
        [ -4.4255,  -4.3313,   0.2467,  -1.3174, -18.6914,   6.3701,   0.0947,
           3.5349,  -3.1274,   0.7604]], device='cuda:0'))])
loaded xi:  -0.00029751108
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 824.4862807977031
W_T_median: 581.747974404808
W_T_pctile_5: -274.08412294578267
W_T_CVAR_5_pct: -400.5783006953572
-----------------------------------------------
new min fval from sgd:  -1218.4279204008667
min fval:  -1218.4279204008667
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 512.4681210134083
W_T_median: 205.11105952569207
W_T_pctile_5: 8.546113427030378e-05
W_T_CVAR_5_pct: -117.2289952363316
Average q (qsum/M+1):  50.648858839465724
Optimal xi:  [-0.00029751]
Expected(across Rb) median(across samples) p_equity:  0.3636113300919533
obj fun:  tensor(-1218.4279, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 3.0
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-14.4429,   1.2633],
        [ 13.9276,  -1.1060],
        [ 10.9351,  -5.4686],
        [  8.6807,   2.3756],
        [  8.3899,  -2.7201],
        [ -1.3398,  -0.0693],
        [ -1.3398,  -0.0693],
        [ -7.4402, -12.0715],
        [  5.2631, -10.7430],
        [ 10.4267,  -9.5375]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([  9.7828, -10.8536,  -6.9722, -13.7791,  -8.7332,  -2.7468,  -2.7468,
         -9.4120,  -9.1233,  -8.3662], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-5.8640e-01, -6.2482e-01, -4.1739e-01, -3.6787e-02, -1.6538e-02,
         -1.0385e-02, -1.0385e-02,  4.8713e-03, -8.9775e-02, -2.8871e-01],
        [-5.8640e-01, -6.2482e-01, -4.1739e-01, -3.6787e-02, -1.6538e-02,
         -1.0385e-02, -1.0385e-02,  4.8714e-03, -8.9775e-02, -2.8871e-01],
        [-5.8640e-01, -6.2482e-01, -4.1739e-01, -3.6787e-02, -1.6538e-02,
         -1.0385e-02, -1.0385e-02,  4.8713e-03, -8.9775e-02, -2.8871e-01],
        [-5.8640e-01, -6.2482e-01, -4.1739e-01, -3.6787e-02, -1.6538e-02,
         -1.0385e-02, -1.0385e-02,  4.8714e-03, -8.9775e-02, -2.8871e-01],
        [-1.3642e+01,  8.4209e+00,  5.1964e+00,  4.1510e+00,  9.7715e-01,
         -2.9232e-02, -2.9232e-02,  9.1743e+00,  9.7510e+00,  7.6559e+00],
        [ 1.1964e+01, -8.9623e+00, -7.0894e+00, -6.1757e+00, -2.8531e+00,
         -1.5924e-02, -1.5924e-02, -1.0834e+01, -1.0077e+01, -8.7415e+00],
        [-5.8640e-01, -6.2482e-01, -4.1739e-01, -3.6787e-02, -1.6538e-02,
         -1.0385e-02, -1.0385e-02,  4.8714e-03, -8.9775e-02, -2.8871e-01],
        [-5.8640e-01, -6.2482e-01, -4.1739e-01, -3.6787e-02, -1.6538e-02,
         -1.0385e-02, -1.0385e-02,  4.8714e-03, -8.9775e-02, -2.8871e-01],
        [-1.1773e+01,  6.5272e+00,  4.3795e+00,  2.6887e+00,  5.2463e-01,
          5.3223e-02,  5.3223e-02,  8.1271e+00,  8.4285e+00,  6.7940e+00],
        [-9.5688e+00,  4.5576e+00,  3.2172e+00,  1.0755e+00,  1.1788e-01,
          6.9770e-02,  6.9770e-02,  5.7136e+00,  6.5038e+00,  5.4810e+00]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-1.7721, -1.7721, -1.7721, -1.7721, -3.6907,  3.0627, -1.7721, -1.7721,
        -3.8140, -3.8325], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 2.4508e-03,  2.4508e-03,  2.4508e-03,  2.4508e-03, -1.0048e+01,
          1.3827e+01,  2.4508e-03,  2.4508e-03, -6.7566e+00, -3.9278e+00]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 11.1020,   9.6284],
        [-15.4245,  -4.4816],
        [-17.9226,  -5.0852],
        [-15.2602,  13.3461],
        [ -2.5911,   7.8324],
        [ 13.3786,  -1.0574],
        [ 14.3089,   2.4379],
        [ -1.8813,   2.3253],
        [  4.9755,  13.4658],
        [-15.8926,  -5.8588]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([  6.8882,  -4.5184,  -3.1627,  13.1419,   5.7201, -14.5681,  -6.8755,
         -3.7585,  11.1322,  -0.3855], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-9.8663e-01, -1.0372e-01, -1.1652e-01, -1.4970e-03, -3.9470e-01,
          4.4455e+00,  1.1562e+00, -1.6897e-01, -1.5733e+01, -2.4280e+01],
        [-1.8090e+00, -7.2845e-02, -1.2665e-01, -7.0406e-01, -6.7500e-01,
         -6.6227e-01, -1.7546e+00, -4.8182e-01, -4.0092e-01, -3.5102e-01],
        [-1.6948e-01,  1.2033e+00,  4.6523e+00, -6.5080e+00,  1.2062e+00,
          9.5186e-01, -1.1650e+00,  3.3647e+00,  4.9056e+00,  3.2208e+00],
        [ 4.6922e+00, -1.4431e+00, -5.7602e-01,  2.2340e+01,  1.5028e+01,
          4.7850e+00,  2.0023e+00, -6.4816e-02,  9.1145e+00, -5.4084e+00],
        [-3.2307e+01,  8.3791e+00,  1.3753e+01,  1.2361e+00, -3.4914e+00,
         -1.4271e+01, -7.2840e+00, -1.4929e-02, -1.6646e+01,  5.2927e+00],
        [-6.8517e+00,  3.8864e+00,  6.9228e+00, -6.9804e+00, -2.4275e+00,
         -1.3088e+01, -9.4302e+00,  1.6116e-01, -1.4783e+01,  8.1844e+00],
        [-1.7980e+00, -7.2876e-02, -1.2646e-01, -7.0364e-01, -6.8000e-01,
         -6.6859e-01, -1.7442e+00, -4.8516e-01, -3.9922e-01, -3.5323e-01],
        [-7.8295e-02,  7.5681e+00,  1.3576e+01, -9.3387e+00, -1.0893e+00,
         -5.3085e+00, -1.4285e+00,  3.0626e-01, -1.7115e+01,  4.2586e+00],
        [ 2.6413e+00,  4.9907e+00,  1.0992e+01, -6.1421e+00,  8.3531e-01,
          5.6043e+00, -1.7083e+00,  3.8218e+00,  1.6361e+00,  1.9798e+00],
        [-1.7927e+00, -7.2957e-02, -1.2658e-01, -7.0473e-01, -6.8310e-01,
         -6.6848e-01, -1.7386e+00, -4.8718e-01, -3.9842e-01, -3.5103e-01]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-5.4189, -5.8241, -8.5517, -6.1626, -6.9906, -2.4287, -5.8253, -2.1256,
        -8.0185, -5.8274], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[  4.1339,  -0.7820,   3.8608,   0.1281,  19.2846,  -6.0825,  -0.7772,
          -3.2843,   1.6990,  -0.7786],
        [ -3.7827,   0.7823,  -3.8433,  -0.2994, -19.2809,   6.1354,   0.7775,
           3.3534,  -1.9083,   0.7787]], device='cuda:0'))])
loaded xi:  -0.00064747484
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 824.4862807977031
W_T_median: 581.747974404808
W_T_pctile_5: -274.08412294578267
W_T_CVAR_5_pct: -400.5783006953572
-----------------------------------------------
new min fval from sgd:  -980.0418660654109
min fval:  -980.0418660654109
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 571.3473352178692
W_T_median: 253.77297698756556
W_T_pctile_5: 7.110778868621992e-05
W_T_CVAR_5_pct: -114.54352864616223
Average q (qsum/M+1):  50.089012884324596
Optimal xi:  [-0.00064747]
Expected(across Rb) median(across samples) p_equity:  0.39326810240745547
obj fun:  tensor(-980.0419, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 5.0
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-14.8713,   1.4155],
        [ 14.1887,  -1.2877],
        [ 11.1221,  -5.8101],
        [  9.5308,   2.3607],
        [ 10.7342,  -4.2544],
        [ -1.5163,  -0.0786],
        [ -1.5163,  -0.0786],
        [ -8.0776, -12.2118],
        [  6.2430, -10.6194],
        [ 10.4532,  -9.6971]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([  9.3319, -10.7756,  -6.6130, -14.2905,  -8.0770,  -3.1599,  -3.1599,
         -9.5040,  -9.1171,  -8.9469], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-6.8104e-01, -6.6100e-01, -6.4807e-01, -1.2160e-01, -2.0473e-01,
         -7.5314e-03, -7.5314e-03, -1.0194e-02, -1.0865e-01, -2.7439e-01],
        [-6.8104e-01, -6.6100e-01, -6.4807e-01, -1.2160e-01, -2.0473e-01,
         -7.5314e-03, -7.5314e-03, -1.0194e-02, -1.0865e-01, -2.7439e-01],
        [-6.8104e-01, -6.6100e-01, -6.4807e-01, -1.2160e-01, -2.0473e-01,
         -7.5314e-03, -7.5314e-03, -1.0194e-02, -1.0865e-01, -2.7439e-01],
        [-6.8104e-01, -6.6100e-01, -6.4807e-01, -1.2160e-01, -2.0473e-01,
         -7.5314e-03, -7.5314e-03, -1.0194e-02, -1.0865e-01, -2.7439e-01],
        [-1.3801e+01,  8.7670e+00,  4.0989e+00,  5.1417e+00,  2.1417e+00,
         -1.3125e-01, -1.3125e-01,  9.7377e+00,  9.5022e+00,  8.5834e+00],
        [ 1.1752e+01, -8.6766e+00, -7.2262e+00, -7.6193e+00, -4.9456e+00,
         -7.7586e-02, -7.7586e-02, -1.1800e+01, -9.7293e+00, -8.0544e+00],
        [-6.8104e-01, -6.6100e-01, -6.4807e-01, -1.2160e-01, -2.0473e-01,
         -7.5314e-03, -7.5314e-03, -1.0194e-02, -1.0865e-01, -2.7439e-01],
        [-6.8104e-01, -6.6100e-01, -6.4807e-01, -1.2160e-01, -2.0473e-01,
         -7.5314e-03, -7.5314e-03, -1.0194e-02, -1.0865e-01, -2.7439e-01],
        [-1.2386e+01,  6.9985e+00,  3.6679e+00,  3.8487e+00,  1.7650e+00,
          1.0081e-02,  1.0081e-02,  9.1314e+00,  8.5898e+00,  7.7864e+00],
        [-1.0986e+01,  5.6366e+00,  3.1381e+00,  2.5105e+00,  1.2089e+00,
          9.8986e-02,  9.8987e-02,  7.9549e+00,  7.5499e+00,  6.9444e+00]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-2.1654, -2.1654, -2.1654, -2.1654, -3.7836,  3.0089, -2.1654, -2.1654,
        -3.9664, -4.0794], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-1.1068e-02, -1.1069e-02, -1.1068e-02, -1.1069e-02, -1.0130e+01,
          1.4489e+01, -1.1068e-02, -1.1068e-02, -7.2395e+00, -5.1674e+00]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 11.9841,   9.8651],
        [-16.6293,  -3.6551],
        [-15.8524,  -4.5074],
        [-14.9160,  15.0153],
        [ -3.0853,   0.5587],
        [ 13.2388,  -1.5917],
        [ 14.8349,   2.3534],
        [ -3.0558,   0.5142],
        [  3.0097,  12.4757],
        [-15.7055,  -6.3214]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([  6.7443,  -3.4393,  -2.9351,  12.9034,  -5.3391, -15.5417,  -6.9275,
         -5.3540,  10.7622,  -1.2198], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-3.9823e-01, -4.6384e-03, -6.2005e-01, -3.7519e-01,  9.8562e-02,
          4.0482e+00,  1.3618e+00,  5.4693e-02, -7.3184e+00, -3.0399e+01],
        [-2.4421e+00, -9.6404e-02,  8.5986e-02, -1.4692e-01,  8.8891e-03,
         -1.1559e-02, -1.4867e+00,  1.0092e-02, -1.1584e-01,  2.3582e-01],
        [-2.4375e+00, -9.6479e-02,  8.6808e-02, -1.4623e-01,  8.9207e-03,
         -1.4363e-02, -1.4913e+00,  1.0127e-02, -1.1562e-01,  2.3753e-01],
        [-2.9195e-01, -5.5328e-01, -2.4086e+00,  6.5132e+00, -1.8427e-02,
         -1.0001e+00, -6.4843e+00, -1.7699e-02,  4.9538e-01, -2.8338e-01],
        [-4.0990e+01,  1.1001e+01,  1.3816e+01, -3.4971e+00, -6.9280e-02,
         -1.4982e+01, -8.2059e+00,  6.3658e-02, -1.2283e+01,  6.1620e+00],
        [-7.6346e+00,  4.4886e+00,  5.3974e+00, -6.1124e+00,  8.6874e-02,
         -1.1867e+01, -1.0372e+01, -1.2995e-02, -1.8547e+01,  9.0443e+00],
        [ 4.0891e+00,  5.3391e+00,  1.8226e+01, -9.2601e-01,  4.4855e-01,
          3.7886e+00, -8.8196e-01,  4.9948e-01,  2.9829e+00, -2.3282e+00],
        [-3.7724e-01,  6.7252e+00,  1.3736e+01, -2.8076e+01,  1.1475e+00,
         -6.1159e+00, -1.6283e+00,  1.0035e+00, -1.5009e+01,  4.4694e+00],
        [ 3.0907e+00,  5.8529e+00,  8.0407e+00, -1.0946e+01,  1.6023e-01,
         -1.2815e+00, -1.1425e+01,  3.8021e-01,  2.3257e+00,  1.9473e+00],
        [-2.5216e+00, -8.7712e-02,  9.9922e-03, -2.2453e-01,  5.2812e-03,
         -1.0787e-01, -9.0104e-01,  6.1356e-03, -2.2764e-01,  4.1944e-01]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-5.2872, -6.1993, -6.1988, -7.6750, -7.7866, -2.1617, -4.3589, -2.0506,
        -8.4666, -6.4482], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[  4.3582,  -1.0650,  -1.0636,   1.7085,  22.7529,  -7.3347,   0.3882,
          -3.6289,   3.5281,  -0.9368],
        [ -3.9918,   1.0660,   1.0638,  -1.7515, -22.7480,   7.3897,  -0.3093,
           3.6993,  -3.7320,   0.9375]], device='cuda:0'))])
loaded xi:  -0.0014491392
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 824.4862807977031
W_T_median: 581.747974404808
W_T_pctile_5: -274.08412294578267
W_T_CVAR_5_pct: -400.5783006953572
-----------------------------------------------
new min fval from sgd:  -407.35481647409114
min fval:  -407.35481647409114
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 530.0329519190609
W_T_median: 231.34968095005107
W_T_pctile_5: 4.0467287673706664e-05
W_T_CVAR_5_pct: -112.95180239450093
Average q (qsum/M+1):  49.576605027721776
Optimal xi:  [-0.00144914]
Expected(across Rb) median(across samples) p_equity:  0.3396866795917352
obj fun:  tensor(-407.3548, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 10.0
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-1.6022e+01,  2.8697e+00],
        [ 1.5104e+01, -5.4950e-01],
        [ 1.2535e+01, -7.1081e+00],
        [ 1.0356e+01,  1.9015e+00],
        [ 1.1559e+01, -7.0141e+00],
        [-1.2541e+00,  3.4584e-02],
        [-1.2541e+00,  3.4559e-02],
        [-5.7375e+01, -1.1743e+01],
        [ 5.0556e-01, -1.2460e+01],
        [ 1.2454e+01, -1.1179e+01]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([  7.7616, -10.8461,  -6.6200, -14.2737,  -3.1714,  -4.3094,  -4.3092,
         -9.1938,  -8.9516,  -8.9440], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-8.5096e-01, -6.1549e-01, -2.8715e-01,  2.3300e-02, -1.1024e+00,
         -6.4708e-03, -6.4716e-03,  7.7043e-02,  1.0651e-02, -5.2341e-02],
        [-8.5096e-01, -6.1549e-01, -2.8715e-01,  2.3300e-02, -1.1024e+00,
         -6.4708e-03, -6.4716e-03,  7.7043e-02,  1.0651e-02, -5.2341e-02],
        [-8.5096e-01, -6.1549e-01, -2.8715e-01,  2.3301e-02, -1.1024e+00,
         -6.4708e-03, -6.4716e-03,  7.7043e-02,  1.0651e-02, -5.2341e-02],
        [-8.5096e-01, -6.1549e-01, -2.8715e-01,  2.3300e-02, -1.1024e+00,
         -6.4708e-03, -6.4716e-03,  7.7043e-02,  1.0651e-02, -5.2341e-02],
        [-1.3102e+01,  1.1913e+01,  7.0784e+00,  8.5643e+00,  9.3724e-01,
         -1.4903e-01, -1.4884e-01,  8.4977e+00,  1.0530e+01,  9.9329e+00],
        [ 1.1873e+01, -1.1110e+01, -8.0274e+00, -9.4281e+00, -3.7254e+00,
         -9.2499e-02, -9.2358e-02, -1.0693e+01, -1.0620e+01, -9.7814e+00],
        [-8.5096e-01, -6.1549e-01, -2.8715e-01,  2.3301e-02, -1.1024e+00,
         -6.4708e-03, -6.4716e-03,  7.7043e-02,  1.0651e-02, -5.2341e-02],
        [-8.5096e-01, -6.1549e-01, -2.8715e-01,  2.3301e-02, -1.1024e+00,
         -6.4708e-03, -6.4716e-03,  7.7043e-02,  1.0651e-02, -5.2340e-02],
        [-1.2844e+01,  6.9718e+00,  5.8304e+00,  1.4157e+00,  1.0153e+00,
         -1.0548e-01, -1.0542e-01,  1.1989e+01,  9.7607e+00,  9.4407e+00],
        [-1.1744e+01,  4.9321e+00,  4.7680e+00,  3.4788e-01,  8.5367e-01,
         -5.2009e-02, -5.1967e-02,  1.1188e+01,  8.9974e+00,  8.5161e+00]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-2.2209, -2.2209, -2.2209, -2.2209, -2.8177,  2.8507, -2.2209, -2.2209,
        -3.4486, -3.4205], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[  0.0330,   0.0330,   0.0330,   0.0330, -11.8405,  15.8915,   0.0330,
           0.0330,  -8.9859,  -6.6425]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  9.5174,  11.0933],
        [-12.7787,  -5.6313],
        [-16.9009,  -4.9027],
        [-17.2960,  13.3743],
        [ -0.3182,  34.5333],
        [ 13.8430,  -0.5476],
        [ 13.2950,   2.0760],
        [ -4.1967,   4.7638],
        [ -0.2044,  12.8062],
        [-15.0723,  -4.2426]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([  7.5266,  -1.9682,  -4.6933,   9.7872,   2.5066, -13.9699,  -6.6714,
         -9.9006,  10.1424,  -3.7179], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-1.5255e+00, -2.1295e+01, -7.5825e-01, -1.9941e+00, -4.5878e+00,
          4.1768e+00,  1.2533e+00,  1.8205e+00, -6.0508e-01, -1.5467e+01],
        [-5.0017e+00,  6.6024e-01, -2.5542e+00, -1.5271e+00,  6.3654e-01,
         -6.6766e-01, -8.6927e-01, -1.2677e+00,  2.0065e-01,  1.1998e+00],
        [ 9.8568e-01,  4.2012e+00, -4.7788e+00, -2.4477e-01,  7.9590e-01,
         -1.3462e+01, -1.0009e+00, -4.7942e+00,  4.6853e+00,  8.9052e-01],
        [ 4.1825e+00, -2.6801e+00,  5.1688e+00,  2.0457e+01, -4.7800e+00,
          2.1476e+00, -1.2473e+00,  1.9234e-02,  5.1901e+00, -4.6503e+00],
        [-4.7274e+01,  8.0060e+00,  1.5389e+01,  3.2646e+00, -5.7322e-09,
         -2.2052e+01, -2.5618e+01, -3.9993e-03, -4.9532e+00,  5.0187e+00],
        [-1.2042e+01,  1.0423e+01,  5.3648e+00, -8.6706e+00, -6.2728e-07,
         -1.4507e+01, -1.3421e+01,  4.4698e-03, -1.4543e+01,  6.0238e+00],
        [-4.8933e+00,  5.6297e-01, -2.7378e+00, -1.4091e+00,  7.7967e-01,
         -5.4637e-01, -1.0173e+00, -1.3426e+00,  9.0287e-02,  1.2320e+00],
        [-1.9505e+00,  4.4731e+00,  1.2289e+01, -9.5554e+00, -1.8919e-03,
         -6.7627e+00, -1.4384e+00,  1.0479e-02, -1.6119e+01,  5.8074e+00],
        [-3.1411e-01,  8.6445e+00,  6.7561e+00,  4.8590e+00, -6.5766e-01,
          1.4299e+00, -2.1495e+00,  1.1160e+00, -4.3590e-01, -6.6326e-01],
        [-4.8220e+01,  7.5807e+00,  1.2107e+01,  5.4221e+00, -2.4899e-09,
         -2.2513e+01, -2.3253e+01, -1.9569e-03, -4.8742e+00,  3.8734e+00]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([ -4.9564,  -6.0126,  -8.1722,  -3.2337,  -8.4762,  -2.8946,  -5.8905,
         -1.4274, -10.8531,  -7.7812], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[  3.8160,  -4.4685,   3.2292,   0.1746,  22.6782, -11.4217,  -4.5882,
          -2.5421,   1.5203,  14.2365],
        [ -3.4377,   4.4734,  -3.1993,  -0.3460, -22.6706,  11.4862,   4.5943,
           2.6140,  -1.7348, -14.2241]], device='cuda:0'))])
loaded xi:  71.32302
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 824.4862807977031
W_T_median: 581.747974404808
W_T_pctile_5: -274.08412294578267
W_T_CVAR_5_pct: -400.5783006953572
-----------------------------------------------
new min fval from sgd:  3623.5774276868397
min fval:  3623.5774276868397
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 616.6139894546498
W_T_median: 346.4962295771926
W_T_pctile_5: 62.21782865587902
W_T_CVAR_5_pct: -101.20464172133914
Average q (qsum/M+1):  47.108051915322584
Optimal xi:  [71.32302]
Expected(across Rb) median(across samples) p_equity:  0.28736522495746614
obj fun:  tensor(3623.5774, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 50.0
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ 0.1266, -0.2107],
        [ 0.1266, -0.2107],
        [ 0.1266, -0.2107],
        [ 0.1266, -0.2107],
        [ 0.1266, -0.2107],
        [ 0.1266, -0.2107],
        [ 0.1266, -0.2107],
        [ 0.1266, -0.2107],
        [ 0.1266, -0.2107],
        [ 0.1266, -0.2107]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([0.2255, 0.2255, 0.2255, 0.2255, 0.2255, 0.2255, 0.2255, 0.2255, 0.2255,
        0.2255], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441,
         0.2441],
        [0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441,
         0.2441],
        [0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441,
         0.2441],
        [0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441,
         0.2441],
        [0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441,
         0.2441],
        [0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441,
         0.2441],
        [0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441,
         0.2441],
        [0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441,
         0.2441],
        [0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441,
         0.2441],
        [0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441, 0.2441,
         0.2441]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([0.3929, 0.3929, 0.3929, 0.3929, 0.3929, 0.3929, 0.3929, 0.3929, 0.3929,
        0.3929], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-1.7600, -1.7600, -1.7600, -1.7600, -1.7600, -1.7600, -1.7600, -1.7600,
         -1.7600, -1.7600]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  8.6737,   9.9699],
        [-12.5941,  -3.5108],
        [-13.8516,  -3.7829],
        [-10.8049,   3.9877],
        [  1.0291,   3.6940],
        [ 13.0524,  -0.6537],
        [ 13.2746,   1.1444],
        [ -2.1499,   0.3764],
        [  3.4990,  12.6715],
        [-14.5553,  -5.5122]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([  7.2202,  -3.1433,  -2.6997,   6.2471,  -4.3716, -14.2506,  -8.1413,
         -3.8783,   9.4859,  -0.1945], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-9.8210e-01,  1.3191e-02,  3.9174e-02,  3.6928e+00, -5.1761e+00,
          3.5581e+00,  2.2884e+00, -2.3969e-01, -1.4269e+00, -2.1788e+01],
        [-1.8268e+00, -1.3488e-04,  2.3844e-03, -2.2092e-01, -4.5445e-02,
         -2.6439e-01, -1.8137e+00,  6.5724e-03, -3.3526e-01, -3.8123e-01],
        [-1.8269e+00, -1.3456e-04,  2.3843e-03, -2.2092e-01, -4.5447e-02,
         -2.6439e-01, -1.8138e+00,  6.5726e-03, -3.3525e-01, -3.8125e-01],
        [ 3.2770e+00,  1.8040e+00,  2.7107e+00,  3.9916e+00, -3.7240e+00,
          6.7323e-03, -9.2841e-01,  3.6424e-02,  2.7354e+00, -2.5553e+00],
        [-1.6429e+01,  7.0531e+00,  9.2223e+00, -2.8431e+00, -4.1636e-02,
         -7.6666e+00, -9.8148e+00, -3.2593e-01, -6.8425e+00,  6.3096e+00],
        [-1.0742e+01,  2.3660e+00,  2.8555e+00, -1.0620e+00, -2.2978e-02,
         -1.1555e+01, -1.1920e+01,  1.1565e-02, -1.3422e+01,  1.0083e+01],
        [-1.8270e+00, -1.3319e-04,  2.3843e-03, -2.2095e-01, -4.5456e-02,
         -2.6437e-01, -1.8139e+00,  6.5734e-03, -3.3523e-01, -3.8133e-01],
        [-1.2956e+00,  3.7310e+00,  1.6941e+00,  1.6125e+00,  2.0791e-02,
         -5.9252e+00, -1.9589e+00, -3.7997e-04, -1.4187e+01,  3.0860e+00],
        [ 3.2386e+00,  5.7655e+00,  5.9248e+00,  3.1437e+00, -4.5989e+00,
          3.1521e+00, -1.0366e+00,  3.8667e-02, -9.2135e-01, -1.5867e+00],
        [-1.5396e+00, -2.8685e-03, -5.9037e-04, -2.7348e-01, -4.5300e-02,
         -2.6032e-01, -1.4026e+00,  5.3732e-03, -4.1666e-01,  2.3554e-01]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-4.9164, -4.9003, -4.9003, -4.5321, -7.7836, -3.2629, -4.9003, -1.4450,
        -6.9955, -5.2082], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[  3.6665,  -0.1919,  -0.1920,   0.3124,  16.7857,  -6.0951,  -0.1920,
          -2.4956,   1.9558,  -0.1420],
        [ -3.3341,   0.1920,   0.1920,  -0.4828, -16.7800,   6.1329,   0.1921,
           2.5607,  -2.1517,   0.1429]], device='cuda:0'))])
loaded xi:  74.05577
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 824.4862807977031
W_T_median: 581.747974404808
W_T_pctile_5: -274.08412294578267
W_T_CVAR_5_pct: -400.5783006953572
-----------------------------------------------
new min fval from sgd:  102.50549706828257
min fval:  102.50549706828257
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 1171.0609734758996
W_T_median: 837.2054369395721
W_T_pctile_5: 61.74181266946898
W_T_CVAR_5_pct: -101.74696105794122
Average q (qsum/M+1):  35.00000787550403
Optimal xi:  [74.05577]
Expected(across Rb) median(across samples) p_equity:  0.2947361022233963
obj fun:  tensor(102.5055, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:268: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 999.0
-----------------------------------------------
