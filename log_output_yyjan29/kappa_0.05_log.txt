Starting at: 
05-02-23_11:25

 Random seed:  2  

Key parameters-------
paths: 256000
iterations: 50000
batchsize: 1000
remove neg:  False


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
3.3333333333333335% of MC simulations done.
6.666666666666667% of MC simulations done.
10.0% of MC simulations done.
13.333333333333334% of MC simulations done.
16.666666666666664% of MC simulations done.
20.0% of MC simulations done.
23.333333333333332% of MC simulations done.
26.666666666666668% of MC simulations done.
30.0% of MC simulations done.
33.33333333333333% of MC simulations done.
36.666666666666664% of MC simulations done.
40.0% of MC simulations done.
43.333333333333336% of MC simulations done.
46.666666666666664% of MC simulations done.
50.0% of MC simulations done.
53.333333333333336% of MC simulations done.
56.666666666666664% of MC simulations done.
60.0% of MC simulations done.
63.33333333333333% of MC simulations done.
66.66666666666666% of MC simulations done.
70.0% of MC simulations done.
73.33333333333333% of MC simulations done.
76.66666666666667% of MC simulations done.
80.0% of MC simulations done.
83.33333333333334% of MC simulations done.
86.66666666666667% of MC simulations done.
90.0% of MC simulations done.
93.33333333333333% of MC simulations done.
96.66666666666667% of MC simulations done.
100.0% of MC simulations done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 5000, 'itbound_SGD_algorithms': 50000, 'nit_IterateAveragingStart': 45000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1576.8182150775267
W_T_median: 1136.7449346433505
W_T_pctile_5: -127.64084552288806
W_T_CVAR_5_pct: -295.72244238283764
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1712.5541546248533
Current xi:  [-57.566006]
objective value function right now is: -1712.5541546248533
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1728.5420214802475
Current xi:  [-185.33319]
objective value function right now is: -1728.5420214802475
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1735.974834745102
Current xi:  [-295.63727]
objective value function right now is: -1735.974834745102
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -1739.664752793264
Current xi:  [-382.19186]
objective value function right now is: -1739.664752793264
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1740.1754058282559
Current xi:  [-444.5097]
objective value function right now is: -1740.1754058282559
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [-455.28137]
objective value function right now is: -1740.0829796564676
14.000000000000002% of gradient descent iterations done. Method = Adam
new min fval:  -1740.76991825474
Current xi:  [-465.66345]
objective value function right now is: -1740.76991825474
16.0% of gradient descent iterations done. Method = Adam
new min fval:  -1740.9844164809483
Current xi:  [-475.8508]
objective value function right now is: -1740.9844164809483
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -1741.2029059832305
Current xi:  [-483.69858]
objective value function right now is: -1741.2029059832305
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [-486.79044]
objective value function right now is: -1740.0376348611992
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -1741.2263546678864
Current xi:  [-488.6622]
objective value function right now is: -1741.2263546678864
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [-489.9449]
objective value function right now is: -1741.1060367961604
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [-488.48636]
objective value function right now is: -1740.815713264002
28.000000000000004% of gradient descent iterations done. Method = Adam
new min fval:  -1741.3370690363681
Current xi:  [-489.2116]
objective value function right now is: -1741.3370690363681
30.0% of gradient descent iterations done. Method = Adam
new min fval:  -1741.4758674843238
Current xi:  [-489.53604]
objective value function right now is: -1741.4758674843238
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [-489.6708]
objective value function right now is: -1741.2615903421797
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [-490.5123]
objective value function right now is: -1741.4019476477042
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [-491.42316]
objective value function right now is: -1740.721006901102
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [-490.7067]
objective value function right now is: -1741.4321951262127
40.0% of gradient descent iterations done. Method = Adam
new min fval:  -1741.5043566031477
Current xi:  [-493.1105]
objective value function right now is: -1741.5043566031477
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [-493.13257]
objective value function right now is: -1741.2702822474182
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [-491.4029]
objective value function right now is: -1741.210518693702
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [-492.81458]
objective value function right now is: -1741.0851242176745
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [-491.1442]
objective value function right now is: -1741.4544363557873
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [-490.08096]
objective value function right now is: -1741.277083973291
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [-490.82693]
objective value function right now is: -1741.2921528747308
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [-496.1806]
objective value function right now is: -1733.9929872551343
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [-494.47223]
objective value function right now is: -1740.9521162269916
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [-491.31073]
objective value function right now is: -1741.4627530379425
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [-491.5481]
objective value function right now is: -1740.7605090770983
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [-491.2412]
objective value function right now is: -1741.224828693035
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [-493.06332]
objective value function right now is: -1741.2464309151894
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [-491.08536]
objective value function right now is: -1741.2392374590822
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [-491.57535]
objective value function right now is: -1741.3694304278324
70.0% of gradient descent iterations done. Method = Adam
new min fval:  -1741.5143636346772
Current xi:  [-490.9844]
objective value function right now is: -1741.5143636346772
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -1741.6592176116874
Current xi:  [-490.44452]
objective value function right now is: -1741.6592176116874
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -1741.699596710607
Current xi:  [-490.54138]
objective value function right now is: -1741.699596710607
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [-489.8766]
objective value function right now is: -1741.673182516266
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [-489.99292]
objective value function right now is: -1741.695840915289
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [-489.57062]
objective value function right now is: -1741.5084332688539
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [-489.258]
objective value function right now is: -1741.6235097894228
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [-489.65985]
objective value function right now is: -1741.6396029606249
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [-489.50662]
objective value function right now is: -1741.6306609962414
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [-488.9725]
objective value function right now is: -1741.6959590917284
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [-488.9164]
objective value function right now is: -1741.6708241539823
new min fval from sgd:  -1741.7038433331727
new min fval from sgd:  -1741.7103891225493
new min fval from sgd:  -1741.7157087849373
new min fval from sgd:  -1741.7202542205043
new min fval from sgd:  -1741.7210877632358
new min fval from sgd:  -1741.7230431028695
new min fval from sgd:  -1741.7262357884472
new min fval from sgd:  -1741.7289459961846
new min fval from sgd:  -1741.731346692474
new min fval from sgd:  -1741.7340509469734
new min fval from sgd:  -1741.734070525176
new min fval from sgd:  -1741.7353815848278
new min fval from sgd:  -1741.7366889903146
new min fval from sgd:  -1741.7377862905646
new min fval from sgd:  -1741.7379084641402
new min fval from sgd:  -1741.7387257344503
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [-488.7478]
objective value function right now is: -1741.681510561535
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [-488.6036]
objective value function right now is: -1741.5642884962117
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [-487.78665]
objective value function right now is: -1741.7113634962193
new min fval from sgd:  -1741.7402881886726
new min fval from sgd:  -1741.7461176365134
new min fval from sgd:  -1741.746254475872
new min fval from sgd:  -1741.7466048967246
new min fval from sgd:  -1741.746619455263
new min fval from sgd:  -1741.7467336526474
new min fval from sgd:  -1741.7467850686978
new min fval from sgd:  -1741.746882487359
new min fval from sgd:  -1741.747021195036
new min fval from sgd:  -1741.7473979713745
new min fval from sgd:  -1741.7474485474486
new min fval from sgd:  -1741.747703215872
new min fval from sgd:  -1741.7478930652346
new min fval from sgd:  -1741.7479888617447
new min fval from sgd:  -1741.7481438338689
new min fval from sgd:  -1741.748729611286
new min fval from sgd:  -1741.7490489475206
new min fval from sgd:  -1741.7493671690597
new min fval from sgd:  -1741.7493813075416
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [-487.55743]
objective value function right now is: -1741.732394136379
new min fval from sgd:  -1741.7500161687205
new min fval from sgd:  -1741.7512246272802
new min fval from sgd:  -1741.7517146526316
new min fval from sgd:  -1741.752015991739
new min fval from sgd:  -1741.7521115252437
new min fval from sgd:  -1741.7526228833688
new min fval from sgd:  -1741.7528036376416
new min fval from sgd:  -1741.7533308145569
new min fval from sgd:  -1741.7534665811381
new min fval from sgd:  -1741.7541029830782
new min fval from sgd:  -1741.7545416476853
new min fval from sgd:  -1741.7546183327015
new min fval from sgd:  -1741.7549105212397
new min fval from sgd:  -1741.7550791039137
new min fval from sgd:  -1741.7551204648094
new min fval from sgd:  -1741.7552436038852
new min fval from sgd:  -1741.7553113923075
new min fval from sgd:  -1741.755325757726
new min fval from sgd:  -1741.7554325985639
new min fval from sgd:  -1741.7555074473178
new min fval from sgd:  -1741.7557470828547
new min fval from sgd:  -1741.7557930021537
new min fval from sgd:  -1741.7560279526535
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [-487.7893]
objective value function right now is: -1741.7333595654575
min fval:  -1741.7560279526535
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-0.3326,  1.0926],
        [-0.3326,  1.0926],
        [-0.3326,  1.0926],
        [-0.3326,  1.0926],
        [14.6776,  1.8708],
        [-0.3326,  1.0926],
        [-0.3326,  1.0926],
        [-3.5706,  8.7115],
        [16.0192,  2.8793],
        [-5.3603,  5.9755]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-0.6438, -0.6438, -0.6438, -0.6438, -9.2890, -0.6438, -0.6438, 14.8394,
        -7.8870, 10.7411], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-3.8957e-02, -3.8957e-02, -3.8957e-02, -3.8957e-02,  4.1438e+00,
         -3.8957e-02, -3.8957e-02,  6.9471e+00,  4.0100e+00,  3.2844e+00],
        [ 7.7070e-03,  7.7070e-03,  7.7070e-03,  7.7070e-03, -5.3622e-02,
          7.7070e-03,  7.7070e-03, -1.0502e-01, -1.1294e-01, -3.2637e-02],
        [ 9.8677e-02,  9.8677e-02,  9.8677e-02,  9.8677e-02, -4.7089e+00,
          9.8677e-02,  9.8677e-02, -7.9125e+00, -4.7020e+00, -3.6644e+00],
        [ 7.7070e-03,  7.7070e-03,  7.7070e-03,  7.7069e-03, -5.3622e-02,
          7.7070e-03,  7.7070e-03, -1.0502e-01, -1.1294e-01, -3.2637e-02],
        [ 7.7070e-03,  7.7070e-03,  7.7070e-03,  7.7070e-03, -5.3622e-02,
          7.7070e-03,  7.7070e-03, -1.0502e-01, -1.1294e-01, -3.2637e-02],
        [ 7.7070e-03,  7.7070e-03,  7.7070e-03,  7.7070e-03, -5.3622e-02,
          7.7070e-03,  7.7070e-03, -1.0502e-01, -1.1294e-01, -3.2637e-02],
        [ 7.7070e-03,  7.7070e-03,  7.7070e-03,  7.7069e-03, -5.3622e-02,
          7.7070e-03,  7.7070e-03, -1.0502e-01, -1.1294e-01, -3.2637e-02],
        [-3.1647e-02, -3.1647e-02, -3.1647e-02, -3.1647e-02, -6.1121e-01,
         -3.1647e-02, -3.1647e-02, -8.3946e-01, -6.4688e-01, -6.3910e-01],
        [ 7.7070e-03,  7.7070e-03,  7.7070e-03,  7.7070e-03, -5.3623e-02,
          7.7070e-03,  7.7070e-03, -1.0502e-01, -1.1294e-01, -3.2637e-02],
        [ 1.3590e-01,  1.3589e-01,  1.3589e-01,  1.3589e-01,  2.0973e+00,
          1.3589e-01,  1.3589e-01,  4.4472e+00,  2.1175e+00,  2.4271e+00]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-4.9168, -0.5660,  5.4828, -0.5660, -0.5660, -0.5660, -0.5660, -0.3736,
        -0.5660, -3.5480], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[  9.0427,  -0.0600, -11.2549,  -0.0600,  -0.0600,  -0.0600,  -0.0600,
          -0.9246,  -0.0600,   5.3461]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -1.3336,   0.6736],
        [ -0.8325,  -7.2198],
        [ -1.3336,   0.6736],
        [ -2.1861,  -0.6965],
        [ -5.3359,   3.6483],
        [ -9.6955,   0.6954],
        [-13.2571,  -6.4992],
        [-11.9020,  -1.4838],
        [ -1.0355,  10.6281],
        [ 12.7541,   5.9519]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ -2.2058, -13.4521,  -2.2058,  -4.9873,   4.4110,   7.3534,  -4.2209,
          8.6554,   9.2240,  -0.1277], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-1.6164e-02, -5.4321e-01, -1.6164e-02, -4.0077e-01, -5.4772e-01,
         -3.3426e-01, -4.7669e-01, -1.2452e+00, -4.4204e-01, -1.5858e+00],
        [-1.6147e-02, -5.4343e-01, -1.6147e-02, -4.0088e-01, -5.4832e-01,
         -3.3455e-01, -4.7686e-01, -1.2455e+00, -4.4186e-01, -1.5855e+00],
        [ 6.3229e-03, -1.9926e+00,  6.3326e-03, -3.3936e+00, -7.4503e-01,
         -2.9296e+00, -2.7672e+00,  4.8334e+00, -1.9017e+00, -4.0793e+00],
        [-1.6157e-02, -5.4330e-01, -1.6157e-02, -4.0081e-01, -5.4795e-01,
         -3.3438e-01, -4.7675e-01, -1.2453e+00, -4.4197e-01, -1.5857e+00],
        [-1.6636e-02, -4.7502e-01, -1.6638e-02, -5.0373e-01,  1.0147e+00,
          3.8810e+00,  2.0952e+00, -1.0511e+00,  5.4387e+00, -2.6596e+00],
        [ 3.9565e-03, -7.9466e+00,  3.9626e-03, -8.7778e+00, -1.3138e+00,
         -6.4188e-01,  5.2903e+00,  2.9172e+00, -1.8447e+01, -8.4068e+00],
        [ 4.5755e-02, -2.3069e+00,  4.5749e-02, -2.4161e+00, -3.2194e+00,
          3.7869e-02, -2.5617e+00,  1.7993e+00, -2.0980e+00, -2.0408e+00],
        [-1.6160e-02, -5.4326e-01, -1.6160e-02, -4.0079e-01, -5.4784e-01,
         -3.3432e-01, -4.7672e-01, -1.2452e+00, -4.4200e-01, -1.5858e+00],
        [-2.2976e-01,  5.2498e-01, -2.2974e-01, -4.4899e+00, -8.0343e+00,
          8.9933e+00,  1.0096e+01, -3.9954e+00,  3.8239e-01, -1.7380e+00],
        [-1.6146e-02, -5.4344e-01, -1.6146e-02, -4.0088e-01, -5.4833e-01,
         -3.3455e-01, -4.7686e-01, -1.2455e+00, -4.4186e-01, -1.5855e+00]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-2.4780, -2.4782, -2.5220, -2.4781, -5.3474,  2.7548, -0.3620, -2.4780,
        -8.5006, -2.4782], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ -0.0755,  -0.0757,  -2.0834,  -0.0756,   0.9907,  -7.1723,  -1.4308,
          -0.0756,  13.6842,  -0.0757],
        [  0.0755,   0.0757,   2.0809,   0.0756,  -1.0688,   7.1906,   1.4566,
           0.0756, -13.6847,   0.0757]], device='cuda:0'))])
xi:  [-487.7575]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 266.6216472058908
W_T_median: 116.88343773098748
W_T_pctile_5: -488.00892926222934
W_T_CVAR_5_pct: -597.5138576026181
Average q (qsum/M+1):  57.14940618699597
Optimal xi:  [-487.7575]
Observed VAR:  116.88343773098748
Expected(across Rb) median(across samples) p_equity:  0.30175268997748694
obj fun:  tensor(-1741.7560, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
[0.0, 100.0, 200.0, 300.0, 400.0, 500.0, 600.0, 700.0, 800.0, 900.0, 1000.0, 1100.0, 1200.0, 1300.0, 1400.0, 1500.0, 1600.0, 1700.0, 1800.0, 1900.0, 2000.0]
[0.0, 100.0, 200.0, 300.0, 400.0, 500.0, 600.0, 700.0, 800.0, 900.0, 1000.0, 1100.0, 1200.0, 1300.0, 1400.0, 1500.0, 1600.0, 1700.0, 1800.0, 1900.0, 2000.0]
[0.0, 100.0, 200.0, 300.0, 400.0, 500.0, 600.0, 700.0, 800.0, 900.0, 1000.0, 1100.0, 1200.0, 1300.0, 1400.0, 1500.0, 1600.0, 1700.0, 1800.0, 1900.0, 2000.0]
/home/marcchen/Documents/testing_pyt_decum/researchcode/fun_Plot_NN_control_DataHeatmaps.py:157: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.05
-----------------------------------------------
