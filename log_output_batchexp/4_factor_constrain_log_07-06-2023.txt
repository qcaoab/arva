Starting at: 
06-07-23_13:16

 numpy seed:  2  


 pytorch seed:  2  

Key parameters-------
paths: 256000
iterations: 30000
batchsize: 1000
remove neg:  False
w constaint activation:  yy_fix_jan29


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor4
timeseries_basket['basket_desc'] = Factor4 portfolio for paper: Basic, size, value, vol, mom
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'B10_real_ret', 'VWD_real_ret', 'Size_Lo30_real_ret', 'Value_Hi30_real_ret', 'Vol_Lo20_real_ret', 'Mom_Hi30_real_ret']
############# End: defined asset  basket #################
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
192601                  0.0                NaN  ...     0.000561     0.023174
192602                  0.0                NaN  ...    -0.033046    -0.053510
192603                  0.0                NaN  ...    -0.064002    -0.096824
192604                  0.0                NaN  ...     0.037029     0.032975
192605                  0.0                NaN  ...     0.012095     0.001035

[5 rows x 16 columns]
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
202208                  NaN            -0.0020  ...    -0.036240    -0.011556
202209                  NaN            -0.0955  ...    -0.091324    -0.099903
202210                  NaN             0.0883  ...     0.077403     0.049863
202211                  NaN            -0.0076  ...     0.052365     0.028123
202212                  NaN            -0.0457  ...    -0.057116    -0.047241

[5 rows x 16 columns]


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor4
timeseries_basket['basket_desc'] = Factor4 portfolio for paper: Basic, size, value, vol, mom
timeseries_basket['basket_columns'] = 
['T30_nom_ret', 'B10_nom_ret', 'VWD_nom_ret', 'Size_Lo30_nom_ret', 'Value_Hi30_nom_ret', 'Vol_Lo20_nom_ret', 'Mom_Hi30_nom_ret']
############# End: defined asset  basket #################
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
192607                    0.0014              0.0154  ...     0.005383     0.031411
192608                    0.0319              0.0561  ...     0.005363     0.028647
192609                   -0.0173             -0.0071  ...     0.005343     0.005787
192610                   -0.0294             -0.0355  ...     0.005323    -0.028996
192611                   -0.0038              0.0294  ...     0.005303     0.028554

[5 rows x 8 columns]
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
202208                   -0.0020             -0.0164  ...    -0.043289    -0.036240
202209                   -0.0955             -0.0871  ...    -0.050056    -0.091324
202210                    0.0883              0.1486  ...    -0.014968     0.077403
202211                   -0.0076              0.0462  ...     0.040789     0.052365
202212                   -0.0457             -0.0499  ...    -0.018566    -0.057116

[5 rows x 8 columns]
Indices constructed with column names:
Index(['date_for_plt', 'Size_Lo30_nom_ret_ind', 'Value_Hi30_nom_ret_ind',
       'Mom_Hi30_nom_ret_ind', 'Vol_Lo20_nom_ret_ind', 'CPI_nom_ret_ind',
       'T30_nom_ret_ind', 'B10_nom_ret_ind', 'VWD_nom_ret_ind'],
      dtype='object')
############# Updated: defined asset basket #################
timeseries_basket['data_df_mean'] = 
T30_real_ret           0.000229
B10_real_ret           0.001637
VWD_real_ret           0.006759
Size_Lo30_real_ret     0.009939
Value_Hi30_real_ret    0.010052
Vol_Lo20_real_ret      0.003529
Mom_Hi30_real_ret      0.011386
dtype: float64


timeseries_basket['data_df_stdev'] = 
T30_real_ret           0.005227
B10_real_ret           0.019258
VWD_real_ret           0.053610
Size_Lo30_real_ret     0.082598
Value_Hi30_real_ret    0.072063
Vol_Lo20_real_ret      0.030737
Mom_Hi30_real_ret      0.061421
dtype: float64


timeseries_basket['data_df_corr'] = 
                     T30_real_ret  ...  Mom_Hi30_real_ret
T30_real_ret             1.000000  ...           0.055142
B10_real_ret             0.351722  ...           0.066570
VWD_real_ret             0.068448  ...           0.936115
Size_Lo30_real_ret       0.014412  ...           0.903222
Value_Hi30_real_ret      0.018239  ...           0.869469
Vol_Lo20_real_ret        0.081282  ...           0.482682
Mom_Hi30_real_ret        0.055142  ...           1.000000

[7 rows x 7 columns]


timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names', 'data_df', 'data_df_mean', 'data_df_stdev', 'data_df_corr'])
############# End: updated: defined asset basket #################
-----------------------------------------------
Dates to be REMOVED due to missing values (should be at *start* only due to trading signals):
Int64Index([], dtype='int64')
-----------------------------------------------
Dates from available data for bootstrapping:
Start: 192607
End: 202212
-----------------------------------------------
Bootstrap block size: 6
-----------------------------------------------
Dates USED bootstrapping:
Start: 196307
End: 202212
-----------------------------------------------
0.0% of bootstrap sample done.
5.0% of bootstrap sample done.
10.0% of bootstrap sample done.
15.0% of bootstrap sample done.
20.0% of bootstrap sample done.
25.0% of bootstrap sample done.
30.0% of bootstrap sample done.
35.0% of bootstrap sample done.
40.0% of bootstrap sample done.
45.0% of bootstrap sample done.
50.0% of bootstrap sample done.
55.00000000000001% of bootstrap sample done.
60.0% of bootstrap sample done.
65.0% of bootstrap sample done.
70.0% of bootstrap sample done.
75.0% of bootstrap sample done.
80.0% of bootstrap sample done.
85.0% of bootstrap sample done.
90.0% of bootstrap sample done.
95.0% of bootstrap sample done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      15  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      15  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 15)     True          15  
2     (15, 15)     True          15  
3      (15, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       7       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      15  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      15  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       7              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 15)     True          15  
2     (15, 15)     True          15  
3      (15, 7)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        7              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 7)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 600, 'itbound_SGD_algorithms': 30000, 'nit_IterateAveragingStart': 27000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        7              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 7)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0, 0.5, 0.1, 0.1, 0.1, 0.1, 0.1]
W_T_mean: 1080.663625928201
W_T_median: 808.5408506516229
W_T_pctile_5: -163.24259466603715
W_T_CVAR_5_pct: -300.4117296963052
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1644.6732591782707
Current xi:  [105.19105]
objective value function right now is: -1644.6732591782707
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1650.1930488918636
Current xi:  [106.88037]
objective value function right now is: -1650.1930488918636
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1695.6816668052875
Current xi:  [119.68956]
objective value function right now is: -1695.6816668052875
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -1701.3667918579508
Current xi:  [140.09248]
objective value function right now is: -1701.3667918579508
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1707.594219607669
Current xi:  [157.42827]
objective value function right now is: -1707.594219607669
12.0% of gradient descent iterations done. Method = Adam
new min fval:  -1714.7274585721623
Current xi:  [172.4722]
objective value function right now is: -1714.7274585721623
14.000000000000002% of gradient descent iterations done. Method = Adam
new min fval:  -1718.1779177036615
Current xi:  [186.16806]
objective value function right now is: -1718.1779177036615
16.0% of gradient descent iterations done. Method = Adam
new min fval:  -1722.3043292157108
Current xi:  [198.88644]
objective value function right now is: -1722.3043292157108
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -1724.9659104678453
Current xi:  [209.39215]
objective value function right now is: -1724.9659104678453
20.0% of gradient descent iterations done. Method = Adam
new min fval:  -1727.011736799853
Current xi:  [219.17215]
objective value function right now is: -1727.011736799853
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -1727.5104969862107
Current xi:  [227.87042]
objective value function right now is: -1727.5104969862107
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [236.48805]
objective value function right now is: -1726.7415011618361
26.0% of gradient descent iterations done. Method = Adam
new min fval:  -1731.4250519449245
Current xi:  [243.259]
objective value function right now is: -1731.4250519449245
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [249.88673]
objective value function right now is: -1728.9025217370051
30.0% of gradient descent iterations done. Method = Adam
new min fval:  -1732.4237236790016
Current xi:  [255.97763]
objective value function right now is: -1732.4237236790016
32.0% of gradient descent iterations done. Method = Adam
new min fval:  -1734.180995233498
Current xi:  [261.52692]
objective value function right now is: -1734.180995233498
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [265.9077]
objective value function right now is: -1733.1145934997112
36.0% of gradient descent iterations done. Method = Adam
new min fval:  -1735.9950806524866
Current xi:  [269.21313]
objective value function right now is: -1735.9950806524866
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [271.9354]
objective value function right now is: -1735.7944080362172
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [274.5663]
objective value function right now is: -1735.6958785095646
42.0% of gradient descent iterations done. Method = Adam
new min fval:  -1737.8351923856371
Current xi:  [276.45648]
objective value function right now is: -1737.8351923856371
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [279.0327]
objective value function right now is: -1737.3141569820716
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [279.55792]
objective value function right now is: -1734.4775084368011
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [281.1456]
objective value function right now is: -1736.7895991556009
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [282.30716]
objective value function right now is: -1735.0532883288279
52.0% of gradient descent iterations done. Method = Adam
new min fval:  -1738.1283832689435
Current xi:  [283.248]
objective value function right now is: -1738.1283832689435
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [284.23187]
objective value function right now is: -1735.8396217638244
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [278.10754]
objective value function right now is: -1722.7275411256055
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [278.62506]
objective value function right now is: -1734.9459223235876
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [279.56775]
objective value function right now is: -1734.3872166034057
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [280.3636]
objective value function right now is: -1735.669621428437
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [282.2234]
objective value function right now is: -1736.8305984093365
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [283.32898]
objective value function right now is: -1734.8782227771192
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [283.88593]
objective value function right now is: -1734.165446129512
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [284.49713]
objective value function right now is: -1735.6175611060091
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -1739.3077644164646
Current xi:  [284.54404]
objective value function right now is: -1739.3077644164646
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -1739.7068102822577
Current xi:  [284.8093]
objective value function right now is: -1739.7068102822577
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [285.30606]
objective value function right now is: -1739.600846942158
78.0% of gradient descent iterations done. Method = Adam
new min fval:  -1739.7830215179881
Current xi:  [285.62033]
objective value function right now is: -1739.7830215179881
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [285.8434]
objective value function right now is: -1739.3808563350128
82.0% of gradient descent iterations done. Method = Adam
new min fval:  -1740.303096243947
Current xi:  [286.13007]
objective value function right now is: -1740.303096243947
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [286.4543]
objective value function right now is: -1739.382381946095
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [286.76318]
objective value function right now is: -1740.0406616721737
88.0% of gradient descent iterations done. Method = Adam
new min fval:  -1740.4959817445772
Current xi:  [287.1137]
objective value function right now is: -1740.4959817445772
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [287.2922]
objective value function right now is: -1739.787247937177
92.0% of gradient descent iterations done. Method = Adam
new min fval:  -1740.6206670626423
Current xi:  [287.4427]
objective value function right now is: -1740.6206670626423
94.0% of gradient descent iterations done. Method = Adam
new min fval:  -1740.8510933596708
Current xi:  [287.61273]
objective value function right now is: -1740.8510933596708
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [287.908]
objective value function right now is: -1740.8435614494792
new min fval from sgd:  -1741.1949006619557
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [288.02924]
objective value function right now is: -1741.1949006619557
new min fval from sgd:  -1741.2032792150817
new min fval from sgd:  -1741.215778756142
new min fval from sgd:  -1741.2233509595274
new min fval from sgd:  -1741.2266193201044
new min fval from sgd:  -1741.2388946459014
new min fval from sgd:  -1741.2504470060705
new min fval from sgd:  -1741.2574014749487
new min fval from sgd:  -1741.265397693133
new min fval from sgd:  -1741.2851648035517
new min fval from sgd:  -1741.2880481178504
new min fval from sgd:  -1741.288327763831
new min fval from sgd:  -1741.295105135218
new min fval from sgd:  -1741.29996456638
new min fval from sgd:  -1741.3165998859533
new min fval from sgd:  -1741.3171193775333
new min fval from sgd:  -1741.317499138562
new min fval from sgd:  -1741.3190853868375
new min fval from sgd:  -1741.332671585428
new min fval from sgd:  -1741.3382710560957
new min fval from sgd:  -1741.3533466031947
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [288.06876]
objective value function right now is: -1741.3043476846722
min fval:  -1741.3533466031947
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[  8.2405,  -0.5745],
        [-13.0002,   4.2058],
        [ -1.0924,   0.8690],
        [ -2.6189,   4.8845],
        [ -1.0920,   0.8688],
        [ 10.6725,  -0.6109],
        [ -1.0921,   0.8764],
        [ -3.6490,   1.6449],
        [ -6.3734,  -7.1835],
        [ -1.0927,   0.8691],
        [  3.2368,   0.1066],
        [ -1.0830,   0.8540],
        [ -1.0851,   0.8627],
        [ -5.1195,   5.4678],
        [ 29.5825,  -6.6640]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ -9.4886,   6.0386,  -2.9461,   4.4589,  -2.9455, -10.0299,  -2.9445,
         -2.2484,  -4.0964,  -2.9465,   4.3585,  -2.9348,  -2.9315,   5.5150,
         -7.9496], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ 3.6660e-02,  7.6236e-01,  2.6710e-02,  9.0456e-01,  2.6716e-02,
          9.0538e-02,  2.6705e-02, -2.8103e-03,  3.4113e-01,  2.6711e-02,
          1.9957e+00,  2.6777e-02,  2.6826e-02,  8.1133e-01,  9.9957e-01],
        [ 3.3430e+00, -3.5722e+00, -1.4703e-02, -1.9854e+00, -1.3112e-02,
          1.0435e+01, -3.2894e-03,  8.1120e-01,  1.7700e+01, -1.6260e-02,
         -2.3986e+00,  8.4448e-04,  8.3084e-03, -3.5623e+00,  5.0079e+00],
        [-6.5790e-01,  2.0168e+00,  2.7543e-01,  9.2392e-01,  2.7640e-01,
         -7.8847e+00,  3.0452e-01, -5.3742e-01, -1.4950e+01,  2.7467e-01,
          1.6975e+00,  2.6499e-01,  2.9810e-01,  2.0788e+00, -4.3067e+00],
        [ 3.0942e+00, -2.9070e+00,  1.1877e-01, -1.6967e+00,  1.1626e-01,
          1.0413e+01,  1.3089e-01,  9.2432e-01,  1.8400e+01,  1.1777e-01,
         -2.2246e+00,  1.0134e-01,  1.0534e-01, -3.4857e+00,  4.9698e+00],
        [ 3.6385e-02,  7.5594e-01,  2.6386e-02,  8.9494e-01,  2.6391e-02,
          9.0437e-02,  2.6380e-02, -2.9745e-03,  3.3632e-01,  2.6386e-02,
          1.9732e+00,  2.6451e-02,  2.6500e-02,  8.0307e-01,  9.8655e-01],
        [-1.3321e-02, -2.3994e-01, -7.6721e-03, -4.5931e-01, -7.6775e-03,
         -4.1924e-02, -7.6579e-03, -7.2129e-03, -1.4719e-01, -7.6691e-03,
         -7.3202e-01, -7.8140e-03, -7.8014e-03, -4.1247e-01, -4.5212e-01],
        [ 3.1701e+00, -2.8080e+00,  1.4226e-01, -1.6856e+00,  1.4417e-01,
          1.0540e+01,  1.5229e-01,  9.3712e-01,  1.8494e+01,  1.4386e-01,
         -2.1708e+00,  1.2054e-01,  1.4089e-01, -3.6448e+00,  4.8866e+00],
        [-1.3321e-02, -2.3994e-01, -7.6721e-03, -4.5931e-01, -7.6775e-03,
         -4.1924e-02, -7.6579e-03, -7.2129e-03, -1.4719e-01, -7.6691e-03,
         -7.3202e-01, -7.8140e-03, -7.8014e-03, -4.1247e-01, -4.5212e-01],
        [-1.3321e-02, -2.3994e-01, -7.6721e-03, -4.5931e-01, -7.6775e-03,
         -4.1924e-02, -7.6579e-03, -7.2129e-03, -1.4719e-01, -7.6691e-03,
         -7.3202e-01, -7.8140e-03, -7.8014e-03, -4.1247e-01, -4.5212e-01],
        [-1.3321e-02, -2.3994e-01, -7.6721e-03, -4.5931e-01, -7.6775e-03,
         -4.1924e-02, -7.6579e-03, -7.2129e-03, -1.4719e-01, -7.6691e-03,
         -7.3202e-01, -7.8140e-03, -7.8014e-03, -4.1247e-01, -4.5212e-01],
        [-1.3321e-02, -2.3994e-01, -7.6721e-03, -4.5931e-01, -7.6775e-03,
         -4.1924e-02, -7.6579e-03, -7.2129e-03, -1.4719e-01, -7.6691e-03,
         -7.3202e-01, -7.8140e-03, -7.8014e-03, -4.1247e-01, -4.5212e-01],
        [-1.3321e-02, -2.3994e-01, -7.6721e-03, -4.5931e-01, -7.6775e-03,
         -4.1924e-02, -7.6579e-03, -7.2129e-03, -1.4719e-01, -7.6691e-03,
         -7.3202e-01, -7.8140e-03, -7.8014e-03, -4.1247e-01, -4.5212e-01],
        [ 2.5133e+00, -3.6865e+00,  5.0994e-02, -1.5727e+00,  5.1084e-02,
          9.8537e+00,  4.3898e-02,  8.1867e-01,  1.6542e+01,  5.1170e-02,
         -2.0490e+00,  7.0319e-02,  7.1372e-02, -3.1942e+00,  4.6399e+00],
        [-1.3321e-02, -2.3994e-01, -7.6721e-03, -4.5931e-01, -7.6775e-03,
         -4.1924e-02, -7.6579e-03, -7.2129e-03, -1.4719e-01, -7.6691e-03,
         -7.3202e-01, -7.8140e-03, -7.8014e-03, -4.1247e-01, -4.5212e-01],
        [-1.3321e-02, -2.3994e-01, -7.6721e-03, -4.5931e-01, -7.6775e-03,
         -4.1924e-02, -7.6579e-03, -7.2129e-03, -1.4719e-01, -7.6691e-03,
         -7.3202e-01, -7.8140e-03, -7.8014e-03, -4.1247e-01, -4.5212e-01]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([ 1.9995, -2.2029,  2.2114, -2.3601,  1.9770, -0.7370, -2.2291, -0.7370,
        -0.7370, -0.7370, -0.7370, -0.7370, -2.4334, -0.7370, -0.7370],
       device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 5.5567, -8.1208,  8.7008, -8.5848,  5.1704,  0.0102, -8.4413,  0.0102,
          0.0102,  0.0102,  0.0102,  0.0102, -6.5658,  0.0102,  0.0102]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -1.5169,   6.0086],
        [-10.7795,  -2.8910],
        [  4.2005,   6.0900],
        [ 10.6099,   0.0991],
        [-13.7208,  -4.0100],
        [-11.1364,  -3.7923],
        [  6.5004,   9.0193],
        [ -5.6465,   1.9623],
        [ -2.6159,  10.3684],
        [ 10.7317,   5.1405],
        [-11.8520,  -3.5506],
        [-12.5816,   7.2642],
        [  2.6097, -10.7967],
        [-12.8337,   3.7771],
        [ 11.9654,   3.9947]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-4.4537,  0.5573, -6.7415, -9.3172, -3.7525, -1.0751,  6.8816, -7.7058,
         7.6317,  4.5848, -2.5578,  6.9982, -7.8938,  7.5357, -0.3654],
       device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 9.0962e-04,  2.4062e+00,  1.0227e-03, -7.7678e+00,  5.6989e+00,
          4.2584e+00, -7.5630e+00, -4.1497e-04, -1.8315e+00, -8.2583e-02,
          6.0629e+00, -5.0497e+00, -2.1530e+00, -4.2255e+00, -5.6715e+00],
        [ 9.9065e-02,  1.0505e+00,  3.9400e-02,  1.7166e-01, -1.6046e-01,
          1.7241e+00, -8.2930e-01, -2.3648e-03, -5.3078e-01, -2.9877e+00,
          9.5922e-01, -2.0463e-01, -8.1256e-01, -1.5173e+00, -7.6161e-01],
        [-6.5900e-03, -2.5509e+00,  9.3704e-03,  1.7855e+00, -9.8957e-01,
         -3.9562e+00,  5.3552e+00, -6.7012e-03,  2.3022e+00,  4.4608e+00,
         -2.5447e+00,  2.5782e+00, -1.7518e+00, -2.1397e-02,  3.6393e+00],
        [ 3.2160e-03,  2.4613e+00,  6.2866e-04,  4.0357e-01,  1.3124e+00,
          3.6104e+00, -2.9855e+00,  2.3678e-03, -7.4821e-01, -8.4618e+00,
          2.3998e+00, -2.4974e+00,  1.9454e+00, -3.8834e+00, -2.2159e+00],
        [ 2.1692e-01, -1.9738e+00, -2.6990e-01, -1.0057e+01,  2.1829e+00,
          1.0428e-01,  2.6696e-01, -5.2410e-01,  6.0391e+00, -4.0818e-01,
          2.3289e+00,  3.4333e+00, -6.1943e+00,  1.0213e+00, -2.3771e+00],
        [ 3.8443e+00,  1.3528e-01,  1.0442e+01, -1.1654e+00, -3.4567e-03,
          3.7434e-02,  8.8656e-01,  6.0743e+00,  4.0977e+00,  2.9624e-01,
         -3.5424e-02, -4.7213e+00, -3.4874e+00, -1.1186e+01, -1.2469e+00],
        [ 2.3337e-02,  7.9483e+00,  8.0324e-03, -6.2469e+00,  7.2573e+00,
          1.0238e+01, -1.6352e+01,  1.6298e-02, -7.8919e+00, -1.8573e+00,
          1.1077e+01, -6.2453e+00,  1.8150e+00, -4.2008e+00, -3.9286e+00],
        [ 4.2168e-01,  9.4079e-01,  1.1885e+00, -2.0068e+00, -1.4556e+00,
          7.5898e-01,  1.5695e+00, -1.5276e-01, -1.7485e+00, -2.8537e+00,
         -2.4768e-03, -1.3849e-01,  1.9339e+00, -3.9286e-01, -2.4035e+00],
        [-1.8446e-02,  7.6384e+00,  5.5245e-04, -4.0983e+00,  2.8909e+00,
          1.0777e+01, -8.9683e+00, -1.0477e-02, -1.3346e+01, -2.0555e+00,
          7.2310e+00, -5.9017e+00,  7.2075e+00, -4.5409e+00, -5.0621e+00],
        [-6.3369e+00, -1.6777e+00, -5.9049e+00, -1.3502e+01, -2.9074e+00,
         -4.6890e+00,  3.9751e+00, -1.6079e+00,  2.9370e+00,  2.9017e+00,
         -1.8946e+00,  1.0499e+01, -7.2802e+00,  8.9529e+00, -4.5413e+00],
        [ 6.0233e-04,  2.4032e+00,  1.1601e-03, -7.9083e+00,  5.9070e+00,
          4.2689e+00, -7.9963e+00, -5.0778e-04, -1.9155e+00, -1.1534e-01,
          6.1588e+00, -5.1977e+00, -2.1490e+00, -4.2595e+00, -6.0254e+00],
        [-2.1631e-02,  3.2540e+00, -8.2619e-03, -2.9806e+00,  7.2108e+00,
          6.1417e+00, -8.6040e+00, -1.4145e-02, -2.4208e+00, -1.7503e+00,
          8.6819e+00, -6.8902e-01,  1.5413e+00, -8.8216e-01, -3.6395e+00],
        [ 8.9073e-02,  5.0539e-01,  2.9252e-04,  1.8107e+00, -6.9702e-01,
          1.5447e+00, -7.3341e-01, -6.1798e-03, -3.8365e-01, -6.1928e+00,
          7.8412e-01, -1.0550e-01,  5.9800e-01, -2.4826e+00, -2.6204e+00],
        [-3.5752e-01,  1.7763e+00, -9.7385e-01, -2.0624e+00,  5.7830e-01,
          2.0290e+00, -3.7078e-01, -1.7469e-03, -4.8127e-01, -6.4393e-01,
          1.4073e+00, -5.0788e-02,  3.9659e-01,  4.0302e-01, -1.9168e+00],
        [-3.2002e-03, -2.9661e+00, -4.0379e-03,  9.9895e-01, -1.6610e+00,
         -2.9209e+00,  2.5728e+00, -1.6502e-03,  6.3317e-01,  6.0081e+00,
         -2.7421e+00,  2.9758e+00, -1.3621e+00,  3.4092e+00,  6.6760e-01]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-3.2934, -2.7014,  0.7832, -0.4952, -3.3767, -2.9355,  0.1697,  0.1487,
         2.8921, -2.7946, -3.2864, -0.3281, -1.0308, -0.9266,  1.1663],
       device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ 2.4736e-03, -1.1797e-02,  7.6619e-01, -5.9177e-02,  3.3940e+00,
          1.0008e+00, -1.1294e+01,  3.2691e+00, -6.6576e+00,  8.1815e-01,
          2.2753e-03,  3.4770e-01,  2.7454e-02,  1.9502e-01,  2.5802e-01],
        [ 5.8806e+00, -3.8542e-01,  1.3285e+00,  2.9343e+00, -7.9987e-02,
          1.5295e+00, -4.4616e+00, -3.4263e-01, -8.3725e-01, -3.1610e-02,
          6.2949e+00, -8.5196e-01, -2.3067e+00,  1.8593e-01,  5.7850e-01],
        [-6.1646e+00,  3.8227e-01, -3.1103e+00, -1.3863e+00, -4.4049e+00,
          4.1660e+00,  4.9187e+00,  1.5921e-02,  2.6077e+00, -5.6834e-01,
         -6.5757e+00,  6.3759e-01,  2.9554e+00, -7.4671e-02,  1.0563e+00],
        [-6.5037e+00,  8.0696e-01,  1.3031e+00, -3.2875e+00, -1.3108e+01,
          4.7850e+00, -1.5588e+00, -5.2640e+00,  1.5496e+01, -5.6791e+00,
         -6.6103e+00, -9.7361e-01,  2.9548e+00, -3.2425e+00,  5.8158e+00],
        [-5.6273e+00,  1.0793e-01,  1.3892e+01, -3.2271e+00, -1.3839e+01,
          3.6147e+00,  4.0211e+00,  8.7519e-01,  7.0818e+00, -6.1380e+00,
         -5.7772e+00, -5.7674e+00,  1.3795e+00, -1.4035e+00,  4.5569e+00],
        [-1.4874e+00, -2.2646e-01,  1.0462e+01, -3.4557e+00, -1.1571e+01,
          5.8439e+00, -5.8697e+00, -3.4939e+00,  1.2963e+01, -8.1996e+00,
         -1.4341e+00, -5.6573e+00, -2.8201e-01, -3.7945e+00,  6.0118e+00],
        [-6.6610e+00,  4.9599e-01,  4.8682e+00, -2.7662e+00,  6.9799e-02,
          5.9626e-01,  1.2395e+00,  7.3192e-01,  2.4835e+00,  5.4128e-01,
         -6.8252e+00,  1.2465e+00,  2.2495e+00, -3.9224e-01,  7.1416e+00]],
       device='cuda:0'))])
xi:  [288.05273]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 456.2090004810219
W_T_median: 402.89917821846586
W_T_pctile_5: 288.09909691695947
W_T_CVAR_5_pct: 143.2980825075035
Average q (qsum/M+1):  51.550237840221776
Optimal xi:  [288.05273]
Expected(across Rb) median(across samples) p_equity:  0.21048864495630065
obj fun:  tensor(-1741.3533, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: Paper_FactorInv_Factor4
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
