Starting at: 
02-02-23_23:24

 Random seed:  2  

Key parameters-------
paths: 256000
iterations: 50000
batchsize: 1000
remove neg:  False


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
3.3333333333333335% of MC simulations done.
6.666666666666667% of MC simulations done.
10.0% of MC simulations done.
13.333333333333334% of MC simulations done.
16.666666666666664% of MC simulations done.
20.0% of MC simulations done.
23.333333333333332% of MC simulations done.
26.666666666666668% of MC simulations done.
30.0% of MC simulations done.
33.33333333333333% of MC simulations done.
36.666666666666664% of MC simulations done.
40.0% of MC simulations done.
43.333333333333336% of MC simulations done.
46.666666666666664% of MC simulations done.
50.0% of MC simulations done.
53.333333333333336% of MC simulations done.
56.666666666666664% of MC simulations done.
60.0% of MC simulations done.
63.33333333333333% of MC simulations done.
66.66666666666666% of MC simulations done.
70.0% of MC simulations done.
73.33333333333333% of MC simulations done.
76.66666666666667% of MC simulations done.
80.0% of MC simulations done.
83.33333333333334% of MC simulations done.
86.66666666666667% of MC simulations done.
90.0% of MC simulations done.
93.33333333333333% of MC simulations done.
96.66666666666667% of MC simulations done.
100.0% of MC simulations done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 5000, 'itbound_SGD_algorithms': 50000, 'nit_IterateAveragingStart': 45000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1576.8182150775267
W_T_median: 1136.7449346433505
W_T_pctile_5: -127.64084552288806
W_T_CVAR_5_pct: -295.72244238283764
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1494.1111706028507
Current xi:  [99.52969]
objective value function right now is: -1494.1111706028507
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1516.2903997414521
Current xi:  [89.58905]
objective value function right now is: -1516.2903997414521
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1516.7273751192913
Current xi:  [98.976746]
objective value function right now is: -1516.7273751192913
8.0% of gradient descent iterations done. Method = Adam
Current xi:  [100.37156]
objective value function right now is: -1515.6060700645708
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1540.973180792821
Current xi:  [105.655075]
objective value function right now is: -1540.973180792821
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [107.29115]
objective value function right now is: -1537.491553621967
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [109.6623]
objective value function right now is: -1538.0170075676162
16.0% of gradient descent iterations done. Method = Adam
new min fval:  -1548.642960827345
Current xi:  [110.85332]
objective value function right now is: -1548.642960827345
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [111.91965]
objective value function right now is: -1535.6644884366956
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [111.38414]
objective value function right now is: -1546.2528862636393
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -1551.6275508701012
Current xi:  [112.09652]
objective value function right now is: -1551.6275508701012
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [114.595276]
objective value function right now is: -1544.9774665519358
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [114.7092]
objective value function right now is: -1550.0799795132345
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [115.03185]
objective value function right now is: -1531.279039616616
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [115.47612]
objective value function right now is: -1545.8936799144133
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [116.102036]
objective value function right now is: -1548.7824712934198
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [115.67788]
objective value function right now is: -1551.07855942006
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [116.406845]
objective value function right now is: -1541.6386796376385
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [115.1445]
objective value function right now is: -1551.2674009685973
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [116.07731]
objective value function right now is: -1540.736974819613
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [115.68936]
objective value function right now is: -1544.1957836094289
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [115.89185]
objective value function right now is: -1546.4918733471327
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [104.048615]
objective value function right now is: -1543.094547178329
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [107.68599]
objective value function right now is: -1550.2271808788032
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [109.812485]
objective value function right now is: -1548.1460837532766
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [110.945755]
objective value function right now is: -1546.7547622967056
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [112.087715]
objective value function right now is: -1550.57071010992
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [113.401596]
objective value function right now is: -1545.5869296058202
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [113.34198]
objective value function right now is: -1457.2725022085208
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [94.78105]
objective value function right now is: -1540.1049649706222
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [96.27551]
objective value function right now is: -1543.4235632050586
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [99.14247]
objective value function right now is: -1541.515361707929
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [103.34416]
objective value function right now is: -1550.0291389487263
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [106.03462]
objective value function right now is: -1545.3023234634607
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [107.87805]
objective value function right now is: -1547.9602016700476
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -1552.6247228939428
Current xi:  [108.773544]
objective value function right now is: -1552.6247228939428
74.0% of gradient descent iterations done. Method = Adam
Current xi:  [109.34582]
objective value function right now is: -1552.4683086843713
76.0% of gradient descent iterations done. Method = Adam
new min fval:  -1552.7320353853904
Current xi:  [110.07401]
objective value function right now is: -1552.7320353853904
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [110.79632]
objective value function right now is: -1552.494680860082
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [111.03379]
objective value function right now is: -1552.36839341561
82.0% of gradient descent iterations done. Method = Adam
new min fval:  -1552.879250195352
Current xi:  [111.63283]
objective value function right now is: -1552.879250195352
84.0% of gradient descent iterations done. Method = Adam
new min fval:  -1553.0170727491322
Current xi:  [112.006424]
objective value function right now is: -1553.0170727491322
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [112.15832]
objective value function right now is: -1552.6905789010557
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [112.436134]
objective value function right now is: -1550.5661284058453
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [112.95145]
objective value function right now is: -1551.9283446354661
new min fval from sgd:  -1553.041948675897
new min fval from sgd:  -1553.2941767068544
new min fval from sgd:  -1553.3918214486396
new min fval from sgd:  -1553.4362689318425
new min fval from sgd:  -1553.447971175232
new min fval from sgd:  -1553.5011424204536
new min fval from sgd:  -1553.5580358491256
new min fval from sgd:  -1553.6389046495278
new min fval from sgd:  -1553.7866205864382
new min fval from sgd:  -1553.8435322327698
new min fval from sgd:  -1553.86607016578
new min fval from sgd:  -1553.8807700496372
new min fval from sgd:  -1553.9308987879208
new min fval from sgd:  -1553.9517114316347
new min fval from sgd:  -1553.9655167355147
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [113.73927]
objective value function right now is: -1553.0304474442867
new min fval from sgd:  -1554.0366857756226
new min fval from sgd:  -1554.0449115277934
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [113.998436]
objective value function right now is: -1550.1131333620815
new min fval from sgd:  -1554.0764137577787
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [114.176186]
objective value function right now is: -1553.581375379086
new min fval from sgd:  -1554.0946793155592
new min fval from sgd:  -1554.1013910188894
new min fval from sgd:  -1554.1188292223476
new min fval from sgd:  -1554.1468291198833
new min fval from sgd:  -1554.1730809190212
new min fval from sgd:  -1554.1999208670793
new min fval from sgd:  -1554.22642326984
new min fval from sgd:  -1554.2290520072347
new min fval from sgd:  -1554.2325192292544
new min fval from sgd:  -1554.2457710039932
new min fval from sgd:  -1554.260847357237
new min fval from sgd:  -1554.2721528186391
new min fval from sgd:  -1554.2800889023677
new min fval from sgd:  -1554.2892645033207
new min fval from sgd:  -1554.2955890763137
new min fval from sgd:  -1554.2981964229834
new min fval from sgd:  -1554.30016352523
new min fval from sgd:  -1554.3028595380347
new min fval from sgd:  -1554.3167777965841
new min fval from sgd:  -1554.318078112473
new min fval from sgd:  -1554.3205812321214
new min fval from sgd:  -1554.3337462695915
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [114.57337]
objective value function right now is: -1554.1178436360701
new min fval from sgd:  -1554.3375556090555
new min fval from sgd:  -1554.3485282551771
new min fval from sgd:  -1554.357412561668
new min fval from sgd:  -1554.3599939466856
new min fval from sgd:  -1554.3628656903466
new min fval from sgd:  -1554.3648363342259
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [114.66827]
objective value function right now is: -1554.127423472513
min fval:  -1554.3648363342259
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[  9.2418,  -6.2022],
        [ -0.9676,   0.4816],
        [-12.4919,   1.4921],
        [ -1.2446, -12.4030],
        [-48.6299,  -9.0765],
        [-12.0626,   2.2598],
        [  3.7730,  -9.8764],
        [ -0.9715,   0.4721],
        [  9.8982,   1.0425],
        [  3.4396,  -9.3434]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ -8.2767,  -2.5889,   9.4187,  -9.7366,  -8.4371,   7.9675,  -8.3218,
         -2.5786, -10.3435,  -7.9881], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-7.2719e+00,  7.5308e-02,  5.5575e+00, -1.2496e+01, -9.1990e+00,
          6.4004e+00, -7.4560e+00,  5.5196e-02, -6.2302e+00, -6.1106e+00],
        [-2.0718e-01, -2.8434e-02, -5.9090e-01, -6.4165e-02, -2.3699e-02,
         -3.8322e-01, -8.4011e-02, -2.8262e-02, -1.6639e-01, -7.3067e-02],
        [-2.0718e-01, -2.8434e-02, -5.9090e-01, -6.4165e-02, -2.3699e-02,
         -3.8322e-01, -8.4011e-02, -2.8262e-02, -1.6639e-01, -7.3067e-02],
        [-2.0718e-01, -2.8434e-02, -5.9090e-01, -6.4165e-02, -2.3699e-02,
         -3.8322e-01, -8.4011e-02, -2.8262e-02, -1.6639e-01, -7.3067e-02],
        [ 3.1645e-01,  4.3714e-02,  1.1689e+00, -1.5614e-03, -1.4164e-01,
          7.8370e-01,  1.1460e-01,  4.4888e-02,  4.9692e-01,  9.4778e-02],
        [ 5.4474e+00, -2.6061e-02, -7.8056e+00,  1.4773e+01,  9.9282e+00,
         -9.1944e+00,  8.2640e+00, -3.8354e-02,  6.7606e+00,  6.8619e+00],
        [-2.0718e-01, -2.8434e-02, -5.9090e-01, -6.4165e-02, -2.3699e-02,
         -3.8322e-01, -8.4011e-02, -2.8262e-02, -1.6639e-01, -7.3067e-02],
        [-2.0718e-01, -2.8434e-02, -5.9090e-01, -6.4165e-02, -2.3699e-02,
         -3.8322e-01, -8.4011e-02, -2.8262e-02, -1.6639e-01, -7.3067e-02],
        [ 2.3688e+00,  1.5426e-01, -7.8983e+00,  1.4756e+01,  9.1552e+00,
         -8.6389e+00,  7.7595e+00,  1.4541e-01,  7.1953e+00,  6.3885e+00],
        [-3.1594e-01, -8.5724e-02, -4.1936e+00,  1.0461e+00,  1.3741e-02,
         -3.8297e+00,  7.3588e-01, -9.1103e-02,  1.0440e+00,  5.2464e-01]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([ 0.0815, -1.4564, -1.4564, -1.4564,  3.0488,  0.1635, -1.4564, -1.4564,
        -0.1452, -0.9770], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 11.3670,  -0.0186,  -0.0186,  -0.0186,   3.4032, -10.1984,  -0.0186,
          -0.0186, -10.7679,  -2.2221]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  7.7975,   9.2671],
        [  0.9882,  13.4954],
        [-14.5956,  -4.1368],
        [-10.9213,  -3.2156],
        [-11.9948,  -0.3680],
        [ 12.3450,   3.1900],
        [  9.8949,   5.7624],
        [  3.9657,   1.7191],
        [  5.0835,  10.1537],
        [-12.1101,  -2.9258]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ 9.4050, 10.7907, -4.1003, -1.6236,  9.2676, -0.6779,  9.7913,  4.2733,
         7.9015, -3.7516], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-9.7809e-01, -5.2995e-01,  1.7279e-02,  1.0989e-03, -7.6648e-01,
         -1.2997e+00, -1.5531e+00, -1.3823e+00, -5.3545e-01,  7.6928e-03],
        [ 3.0417e+00, -8.3906e-02,  1.2325e-02, -1.2195e-01,  2.1302e+00,
          2.2982e-01,  2.8947e+00,  6.1206e-01,  2.7799e-01,  6.1262e-03],
        [-2.0486e+00, -2.0896e+01,  3.7477e+00,  1.0700e+01,  5.0306e+00,
         -2.0256e+00, -7.0509e-01, -1.1212e+00, -6.3476e+00,  3.1918e+00],
        [ 2.3973e+00,  2.7624e+01, -2.6183e+00, -8.6839e+00, -5.7973e+00,
          3.7152e+00,  2.7891e+00, -3.5649e-01, -1.0787e+00, -3.0593e+00],
        [ 6.9502e-01, -8.0879e+00, -6.4704e-02, -6.6856e-01,  2.5000e-02,
         -2.4668e-01, -1.0590e+00, -1.0641e+00, -8.9814e-01, -7.7463e-02],
        [-9.7320e-01, -5.2993e-01,  1.8142e-02,  1.0374e-03, -7.6913e-01,
         -1.3285e+00, -1.3994e+00, -1.4487e+00, -5.3625e-01,  8.4092e-03],
        [-9.9107e-01, -5.3297e-01,  1.9074e-02,  8.2535e-04, -7.7862e-01,
         -1.3447e+00, -1.4048e+00, -1.4904e+00, -5.2847e-01,  9.2984e-03],
        [ 2.7237e+00,  3.9319e+00,  5.9838e+00,  8.6449e-01,  4.4894e+00,
         -2.3836e+00, -2.7984e-01, -2.7559e+00, -7.3701e-01,  5.9245e+00],
        [-9.5877e-01, -5.2533e-01,  1.6509e-02,  2.3547e-04, -7.4749e-01,
         -1.3086e+00, -1.5905e+00, -1.2031e+00, -5.4104e-01,  6.9959e-03],
        [-1.1147e+01, -1.7500e+01,  4.4645e+00,  9.3376e+00,  5.3593e+00,
         -1.1621e+01,  1.9303e+00, -1.5973e-01, -1.0213e+01,  3.4668e+00]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-1.4803,  1.5785, -1.4864, -1.0665, -1.2558, -1.5412, -1.4715, -7.8680,
        -1.6286, -1.4067], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[  0.1118,  -1.3304,  -6.0371,   1.7149,  -1.3403,   0.1110,   0.1151,
           0.9778,   0.1084,  14.3802],
        [ -0.1117,   1.3741,   6.0389,  -1.7256,   1.3405,  -0.1130,  -0.1150,
          -1.0207,  -0.1078, -14.3827]], device='cuda:0'))])
xi:  [114.653595]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 626.4267254340193
W_T_median: 309.87801191519736
W_T_pctile_5: 114.73126647959685
W_T_CVAR_5_pct: -9.674007591316503
Average q (qsum/M+1):  50.609146610383064
Optimal xi:  [114.653595]
Expected(across Rb) median(across samples) p_equity:  0.2924201185504595
obj fun:  tensor(-1554.3648, device='cuda:0', dtype=torch.float64,
       grad_fn=<MeanBackward0>)
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.5
-----------------------------------------------
