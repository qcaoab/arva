Starting at: 
2022-06-20 18:03:38
tracing parameter entered from terminal:  0.8


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[ 0.10347998  0.18844875 -0.3666709   0.62803316 -0.89369922 -0.17398511
  0.93797695  0.78704989 -0.60791207 -0.16293226 -0.31685198  0.28094308
  0.0404241   0.17453202  0.0940472   0.01169373  0.2300954  -0.23784803
  0.78511084 -0.41859022  0.4809118  -0.01155852  0.07219357 -0.14482284
  0.4701344  -0.18827011 -0.8138637  -0.24629474  0.28361272  0.33354483
 -0.63777411 -0.25343004 -0.81551088 -0.26234589  0.20198453 -0.15135741
  0.25264285 -0.29817275  0.41496663 -0.58895503 -0.60305385 -0.63454123
  0.3979274   0.74701442  0.57452389 -0.67377327  0.6493153   0.07340044
 -0.29694484  0.52758424 -0.14347696  0.04319718 -0.28527617 -0.63077443
  0.13133703 -0.58713125  0.12759166  0.87507529 -0.19770888 -0.66759109
  0.25529887 -0.48501395  0.58877641 -0.72315372] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1260.6521530687958
W_T_median: 1222.3920506735662
W_T_pctile_5: 834.1581876304141
W_T_CVAR_5_pct: 746.6575474940535
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1814.9360059697983
gradient value of function right now is: [-2.21185998e+00 -1.80620360e-01  1.44015991e+00 -1.25298334e-01
  2.21185998e+00  1.80620360e-01 -1.44015991e+00  1.25298334e-01
  1.79852290e+00  1.68555333e+00  1.94754819e+00  1.79821068e+00
  3.53043783e-02  1.10689708e-01  5.26991478e-02  1.18893967e-01
 -1.04478419e+00  5.38367140e-01 -1.04748345e+00  6.71732891e-01
  1.39708308e-02  2.49161270e-03  1.49009687e-02  1.94477719e-03
  1.70034070e-01 -9.16481477e-02  1.56552794e-01  2.99967698e-01
 -1.71816676e-01 -3.24825575e-02 -1.47812876e-01 -3.35053814e-01
  1.82773007e-01 -2.95340170e-01  1.76898903e-01  1.81185863e-01
 -3.31393701e-01 -5.51129162e-02 -2.92213596e-01 -6.79972607e-01
  7.46732477e-01  1.65268611e-01  4.06616790e-01  2.12302915e-01
 -5.50645011e-01  4.49390998e-01 -3.47260733e-01  2.67794464e-01
  6.85689112e-01  1.61438204e-01  4.17467336e-01  2.10714336e-01
 -1.17894882e+00 -1.16779117e-01 -1.50307443e+00 -4.07136552e-01
  2.42938786e+00 -8.16330978e-02 -9.99293677e-01  3.45937869e-01
  4.55920997e-02  9.00941162e-03 -1.66859198e+00  2.92716822e-01
  5.62783029e+00]
supnorm grad right now is: 5.627830290411255
Weights right now are: 
[ 6.50240459e-01  4.42143211e-01 -4.61231772e-01  7.75503223e-01
 -1.44045970e+00 -4.27679573e-01  1.03253782e+00  6.39579825e-01
 -9.03479879e-01  1.30999254e+00 -8.98430355e-01  2.37644985e+00
  8.56774178e-01  2.59047710e+00  7.14831156e-01  2.92086753e+00
  1.57295302e+00  2.58773639e-02  2.39086748e+00 -7.04010602e-01
  1.99324878e+00  1.96392804e+00  1.62310565e+00  2.00462498e+00
 -9.86486366e-01  1.71971500e+00 -2.02788047e+00  1.27027547e+00
  2.50492133e+00 -8.26079857e-01  1.43915448e+00 -9.36744336e-01
 -2.35770414e+00  1.55479702e+00 -1.14094648e+00  1.02771443e+00
  2.09519797e+00 -1.35267820e+00  2.07811830e+00 -1.38756423e+00
 -1.30153337e+00  2.26069588e+00  3.46185398e+00  4.13453832e+00
  3.57836941e+00 -1.50998299e+00  1.25546588e+00 -8.04033584e-01
 -8.08688004e-01  3.47405907e+00  2.98728662e+00  3.21671515e+00
  2.13096569e+00 -8.11649769e-01  3.98106674e-01 -1.65796162e+00
 -7.45087998e-02  1.65077886e+00  2.14224276e+00 -2.01991301e+00
 -7.21081733e-01 -2.79822773e+00  1.43991246e+00 -2.13723222e+00
  2.99212734e+01]
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1818.291680193187
gradient value of function right now is: [ 3.52484470e+00  2.24606053e-01  4.13019388e+00  2.00689612e-01
 -3.52484470e+00 -2.24606053e-01 -4.13019388e+00 -2.00689612e-01
 -3.04619545e+00 -2.37758779e+00 -3.15676480e+00 -2.49111857e+00
 -5.29984933e-02 -7.04277789e-02 -5.52604807e-02 -7.43812844e-02
  2.56803958e+00  3.73527404e+00  2.62845206e+00  4.06903767e+00
 -4.96721716e-03 -5.93201595e-03 -5.13558358e-03 -6.38532000e-03
 -2.03577159e-01 -3.84976722e-01 -1.78879757e-01 -6.61342625e-01
  2.91232698e-01  2.26358725e-01  2.48767723e-01  4.10593657e-01
 -2.34617349e-01 -5.26747304e-01 -2.07444746e-01 -8.80163562e-01
  4.84969054e-01  4.03528102e-01  4.15219524e-01  7.47410848e-01
 -1.94780938e+00 -4.58909899e-01 -1.03396858e+00 -5.69250906e-01
  9.12849753e-01  9.67626242e-01  1.84168582e+00  1.42779047e+00
 -1.45346306e+00 -3.56719682e-01 -8.22603312e-01 -4.62745703e-01
  1.01195629e+00  7.68922157e-01  1.69921266e+00  1.21270312e+00
 -1.66574773e+00 -2.16677862e+00  9.54602950e-01  8.84358151e-01
  1.23774196e+00 -1.95278436e+00  9.62149344e-01 -2.81010735e-01
 -1.65361556e+01]
supnorm grad right now is: 16.536155599688534
Weights right now are: 
[ 0.61374514  0.3117547  -1.0684171   0.73987735 -1.40396438 -0.29729106
  1.63972315  0.6752057  -0.84724036  1.85005362 -0.88912762  2.93381915
  1.53758459  2.89743004  1.32682792  3.22579715  2.29618227 -0.37770366
  3.08563193 -1.17660352  2.47406969  2.47304119  2.05439866  2.52810167
 -1.70516573  2.49889521 -2.61965143  1.24687818  3.21359315 -1.02409983
  2.03255922 -0.50775315 -3.04389718  2.44450168 -1.73142862  1.11080753
  2.76335287 -1.66821319  2.64387728 -1.11724006 -1.6511814   1.82869096
  4.11084015  3.93181061  5.10107308 -2.82083979  2.05834099 -1.09285413
 -1.13325804  2.92809536  3.67099027  2.95243192  3.4655135  -1.56919679
  1.67092704 -1.41193413 -2.07744291  1.27089276  4.71693506 -1.59541224
 -2.45500899 -2.70455238  2.74612755 -2.25767749 29.66897768]
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1823.5123996153138
gradient value of function right now is: [ 1.34597490e-01  7.25356324e-03  2.02806477e+00  1.49352559e-02
 -1.34597490e-01 -7.25356324e-03 -2.02806477e+00 -1.49352559e-02
  5.16201155e-02  1.55422913e-01  3.29552551e-02  1.22839399e-01
 -9.22699830e-04 -1.85923852e-03 -9.05381435e-04 -2.45720645e-03
  6.04384960e-01  1.96224875e+00  6.65232390e-01  2.23352199e+00
 -7.50727391e-05 -4.66813270e-04 -9.27098008e-05 -5.52269056e-04
  3.83400187e-02 -2.61894437e-01  5.61102784e-02 -5.57206899e-01
  1.54751403e-02  1.35097866e-01 -8.03609402e-03  2.72945282e-01
  4.90849953e-02 -3.86344629e-01  7.29825686e-02 -7.94131172e-01
  1.38550365e-02  2.21504447e-01 -2.35531720e-02  4.77159295e-01
  1.80289389e-01 -5.25246619e-02  5.71408176e-01 -2.41789361e-03
  3.18824728e-01  8.78573210e-01  1.33750253e+00  1.19103442e+00
  4.06182198e-01 -3.96643725e-02  7.31235331e-01  2.58631558e-02
  3.71859408e-01  6.67852101e-01  1.22391925e+00  1.04443964e+00
 -5.53167651e-01 -2.30168827e+00  4.44158464e-01  1.02464822e+00
  3.46350267e-01 -1.08710935e+00 -5.23714557e-01 -3.65934036e-01
 -3.21346803e+00]
supnorm grad right now is: 3.2134680290407998
Weights right now are: 
[ 0.6689752   0.23968135 -1.34336663  0.7337629  -1.45919444 -0.22521771
  1.91467268  0.68132014 -0.7686318   2.38094897 -0.82723197  3.51066746
  2.21466497  3.27478227  1.96272964  3.60269193  2.29262076 -0.58302201
  3.12221825 -1.36622922  3.16119389  2.80229321  2.67262107  2.84762369
 -2.12021157  2.43877257 -3.02332967  1.08080721  3.68216906 -1.06942902
  2.45570268 -0.51825281 -3.49191875  2.37963406 -2.20660196  0.83174867
  3.20069992 -1.63050356  3.04190738 -1.15063489 -1.85289944  3.2906791
  3.8440271   5.77948134  5.76628581 -2.61267106  2.44672568 -0.64781058
 -1.47662671  4.5839595   3.3263077   4.97295832  3.43744632 -1.22809218
  1.56515676 -1.22365386 -2.26005865  1.38226804  4.78628974 -1.52575201
 -3.10884014 -2.38752097  2.6161534  -2.2109092  29.60879484]
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1820.010678646387
gradient value of function right now is: [ 2.90462466e+00  3.51688776e-02  3.56786978e+00  1.84213820e-02
 -2.90462466e+00 -3.51688776e-02 -3.56786978e+00 -1.84213820e-02
 -1.87922291e+00 -7.22535793e-02 -1.94006943e+00 -9.71671328e-02
 -1.17198013e-02 -2.67213603e-03 -1.20524316e-02 -3.17329053e-03
  1.36521913e+00  3.25008338e+00  1.50956618e+00  3.75282054e+00
  3.45446929e-04  4.86461622e-04  3.72633252e-04  5.74103177e-04
  7.25983014e-03 -2.45480652e-01  1.99193276e-02 -9.60755879e-01
  1.33214863e-01  1.46938239e-01  1.14336888e-01  4.68988516e-01
  2.95877389e-02 -3.90587415e-01  4.60582248e-02 -1.42102035e+00
  1.74634062e-01  2.04670285e-01  1.46551839e-01  7.65511251e-01
 -3.87593319e-01  5.16178726e-03  1.71627348e-01 -2.14694232e-03
  3.09842989e-01  9.37244575e-01  1.36493438e+00  1.06550406e+00
 -1.45471140e-01  4.40072563e-03  3.01593259e-01  5.08340554e-03
  7.55267580e-01  1.13622041e+00  2.24350565e+00  1.45624999e+00
 -1.16672652e+00 -3.17364829e+00  5.35962570e-01  1.33232027e+00
  8.02485785e-01 -1.87963055e+00  3.30286139e-01  6.93147436e-01
 -1.19002362e+01]
supnorm grad right now is: 11.900236211512377
Weights right now are: 
[ 0.71567164  0.2204778  -1.362747    0.68282945 -1.50589088 -0.20601416
  1.93405304  0.7322536  -0.53454535  2.98340922 -0.58838477  4.15028076
  2.60503884  3.64831575  2.33753788  3.97833683  2.35632876 -0.65431638
  3.20481729 -1.44169616  3.69931061  3.18261141  3.16001272  3.2233887
 -2.13988632  2.50992449 -3.0313057   1.35421642  3.60550391 -1.07602931
  2.28830163 -0.56259454 -3.6635107   2.4332504  -2.4046863   1.00859646
  3.10711939 -1.64975732  2.86380765 -1.36649103 -1.47006366  3.8814425
  4.36205111  6.2436383   6.45594954 -2.51051301  2.39492362 -0.61827256
 -1.12568003  5.29240667  3.78048107  5.41408244  3.66573452 -1.33970965
  1.17604362 -1.56020619 -1.90792003  1.46134193  4.08926308 -1.58466174
 -3.6353448  -2.77312158  2.82135033 -1.65937424 28.78103858]
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1806.4440934133636
gradient value of function right now is: [ 9.69031403e+00  5.75639428e-02  1.30625889e+00  1.50967138e-02
 -9.69031403e+00 -5.75639428e-02 -1.30625889e+00 -1.50967138e-02
 -9.79616978e+00 -2.92052572e+00 -1.00853900e+01 -2.86051465e+00
 -1.08488199e-02 -4.52038677e-03 -1.11899707e-02 -4.50419501e-03
  2.36796429e+00  2.68451634e+00  2.42723640e+00  2.81538623e+00
  1.57398552e-03  1.01452838e-03  1.61568786e-03  1.03699412e-03
 -1.97594049e-01 -1.97045905e-01 -2.71709307e-01 -4.74136930e-01
  9.31959989e-01  4.68788402e-02  1.24018570e+00  1.46442331e-01
 -2.01896048e-01 -2.59967093e-01 -2.82159765e-01 -6.11901417e-01
  1.26911839e+00  1.03784324e-01  1.68946802e+00  2.95196914e-01
 -7.54610146e+00 -4.85474382e-01 -6.25821359e+00 -7.76533928e-01
  3.16694749e-01  7.31213429e-01  1.17400163e+00  7.32275533e-01
 -8.14524421e+00 -4.91230405e-01 -7.11261455e+00 -8.02005368e-01
  4.49782465e-01  6.49259143e-01  1.19125160e+00  6.66143880e-01
 -2.74354746e+00 -1.90081029e+00  1.95255602e+00  2.07489958e-01
  3.76309312e+00 -2.87952652e+00  3.82514132e+00 -1.10380611e+00
 -3.45329298e+01]
supnorm grad right now is: 34.53292977929647
Weights right now are: 
[ 0.5748696   0.13351718 -2.17040753  0.6212652  -1.36508884 -0.11905354
  2.74171358  0.79381785 -0.49582495  3.07663746 -0.55890541  4.27053596
  3.01814039  3.9475837   2.73272177  4.29316659  3.3544947  -0.40278028
  4.21370258 -1.24023236  4.45316689  3.54805244  3.85481985  3.57390772
 -3.33894601  2.7906445  -4.30343667  1.40953111  4.32713734 -1.94768264
  3.01068396 -0.33488659 -5.04309258  2.83037068 -3.85404682  1.08900998
  3.83026598 -2.03858818  3.59537012 -1.16752021 -2.11418625  3.96219198
  3.74016343  6.36559816  7.47590773 -2.8871404   2.60220185 -0.90753108
 -1.91120733  5.46137052  2.99571212  5.51415185  4.94385852 -1.37171452
  1.67957223 -1.54439345 -2.84718018  1.91568175  5.0015402  -1.74959291
 -3.72522957 -3.16250221  3.86905757 -1.42906535 29.34708561]
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1818.4605022721228
gradient value of function right now is: [ 9.49454017e+00  1.00059986e-02 -1.20295927e+00 -1.54181846e-03
 -9.49454017e+00 -1.00059986e-02  1.20295927e+00  1.54181846e-03
 -7.34093886e+00 -6.27452187e-01 -7.56485101e+00 -6.15839557e-01
 -4.11936890e-03  9.16479966e-05 -4.19664010e-03  1.61121955e-04
 -1.29289273e+00 -2.43726025e+00 -1.45480583e+00 -2.89716670e+00
  5.37421929e-05 -4.02669739e-04  2.98409008e-05 -4.95026927e-04
 -8.04014090e-02  4.10861128e-02 -8.41146053e-02  9.81380255e-01
  5.77976768e-01 -1.13441742e-02  6.07835428e-01 -3.12080007e-01
 -5.14633330e-02  5.95968893e-02 -5.47445480e-02  1.39930789e+00
  7.67247488e-01 -2.36552975e-02  8.04022610e-01 -5.73027608e-01
 -3.75937359e+00 -2.49923325e-01 -1.86449631e+00 -2.72304685e-01
 -1.16056722e-01 -1.43175205e-01 -3.19618306e-01 -2.34285685e-01
 -3.16192144e+00 -1.95687642e-01 -1.60411550e+00 -2.14818932e-01
 -1.13314116e+00 -1.05541466e+00 -2.57884417e+00 -1.71000112e+00
  7.39743535e-01  2.87235357e+00  1.28668513e-01 -2.19141840e+00
  3.33544370e+00 -3.49640493e+00  3.72721281e-01 -2.76004930e+00
  5.76676410e-01]
supnorm grad right now is: 9.494540172178386
Weights right now are: 
[ 0.6920963   0.18903981 -2.51397341  0.54420329 -1.48231553 -0.17457617
  3.08527946  0.87087976 -0.49840574  3.70753515 -0.55019696  4.92359608
  3.61140717  4.54749237  3.31150244  4.89167007  3.05624433 -0.78487834
  3.91972614 -1.62318427  5.15711978  3.68669164  4.52114477  3.69711859
 -3.39145788  2.75413511 -4.37599533  2.16709137  4.34308422 -1.80164682
  2.81408921 -0.34028019 -5.49386236  2.76787855 -4.2979074   1.68527205
  3.84123123 -1.90064769  3.40828258 -1.46886663 -1.90087778  4.69167112
  4.33727585  7.00108112  7.55206908 -2.56677295  2.98060648 -0.52943211
 -1.65687533  6.36694937  3.56647535  6.35277134  4.25284792 -2.11252244
  0.98013958 -2.2875918  -2.2463389   2.06997854  4.89513818 -1.82049447
 -3.87147645 -3.6285328   3.31051212 -2.46808125 29.56786368]
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -1809.9146660353997
gradient value of function right now is: [-6.97250250e+00 -8.50377171e-03 -2.23298100e+00 -3.45305033e-03
  6.97250250e+00  8.50377171e-03  2.23298100e+00  3.45305033e-03
  7.08696191e+00  1.91463156e+00  7.32490747e+00  1.87546432e+00
  5.30712347e-04  2.25474185e-04  5.47415213e-04  2.27746109e-04
 -6.62278784e+00 -5.74264050e+00 -6.83369342e+00 -5.93544128e+00
 -1.09402653e-03 -8.13387967e-04 -1.13475940e-03 -8.46086064e-04
  1.59441498e-01  6.56251873e-02  2.94130623e-01  4.70570360e-01
 -5.64840961e-01 -2.13953313e-02 -8.74220152e-01 -2.04225890e-01
  1.80118085e-01  9.29390102e-02  3.42263829e-01  6.54745356e-01
 -7.54313913e-01 -4.02619873e-02 -1.17154869e+00 -3.43768044e-01
  5.18265371e+00  4.21956703e-01  4.12303760e+00  5.52428309e-01
 -1.25753402e-01 -4.12732697e-01 -5.67994249e-01 -5.06429349e-01
  6.97013090e+00  4.67976063e-01  6.36266999e+00  7.28286542e-01
 -4.59014582e-01 -5.64570066e-01 -1.00085629e+00 -7.17266011e-01
  2.56205784e+00  1.20168254e+00 -2.25830607e+00  5.84349851e-01
 -2.82458277e+00  2.36733403e+00 -4.38208801e+00  1.12712541e+00
  5.08863838e+01]
supnorm grad right now is: 50.88638375757134
Weights right now are: 
[ 0.65663845  0.04992908 -2.84861181  0.4159905  -1.44685769 -0.03546544
  3.41991786  0.99909255 -0.40829215  3.78181506 -0.44488912  5.04196145
  3.95030826  4.8695326   3.64059692  5.27539711  2.88507794 -0.90256993
  3.84792522 -1.63060989  5.43497124  3.86412004  4.8397447   3.93922243
 -4.02525888  2.79175858 -5.26573759  1.65686373  4.63185717 -2.64466169
  2.89933824  0.5956238  -6.48544125  2.98508917 -5.5650008   1.09123338
  4.12051077 -2.26456249  3.50557993 -0.71144201 -2.05470562  5.39877686
  4.29267967  7.87266611  9.02482805 -2.69247848  3.29545135 -0.58886013
 -1.91837887  7.51835542  3.19743614  7.4201025   4.70416231 -1.20956765
  1.72329083 -1.48206805 -2.31928781  1.80867208  4.21323028 -2.04671118
 -4.11910578 -3.48279513  3.09307152 -2.4581698  30.17529085]
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1818.9007987493746
gradient value of function right now is: [-1.42443542e+00 -1.48982088e-03 -1.35162171e+00 -1.01364558e-03
  1.42443542e+00  1.48982088e-03  1.35162171e+00  1.01364558e-03
  3.50009714e-01 -3.10725162e-01  2.93423583e-01 -2.84027207e-01
  4.24124556e-05  1.34259698e-05  4.32642141e-05  1.79346501e-05
 -1.89171896e+00 -2.73578060e+00 -2.07627458e+00 -3.32319673e+00
 -1.55910651e-04 -2.09527164e-04 -1.76498313e-04 -2.77366855e-04
 -1.67183818e-02  7.48836354e-02 -4.44877695e-02  8.52272448e-01
  1.71255070e-01 -3.55219956e-02  2.82102873e-01 -4.08894713e-01
 -1.64985584e-02  1.14709000e-01 -4.93813784e-02  1.25235698e+00
  2.22047108e-01 -6.28940303e-02  3.67059675e-01 -6.72854130e-01
 -1.45988739e+00 -6.53823867e-02 -9.07023177e-01 -8.64732990e-02
 -1.85145564e-01 -3.72256664e-01 -7.57825638e-01 -4.46042912e-01
 -1.67883991e+00 -5.06473109e-02 -1.24629602e+00 -7.56756643e-02
 -8.63624128e-01 -1.06648025e+00 -2.49929358e+00 -1.29242035e+00
  1.38334917e+00  2.42559543e+00 -4.22737226e-01 -1.52851489e+00
  1.45991890e+00 -1.52703373e+00 -8.56781265e-02 -1.67320465e+00
  4.02575071e+00]
supnorm grad right now is: 4.025750712203156
Weights right now are: 
[ 5.35228349e-01  3.98036572e-02 -2.77239591e+00  4.74333371e-01
 -1.32544759e+00 -2.53400192e-02  3.34370195e+00  9.40749677e-01
 -1.82746814e-01  3.66163164e+00 -2.20258741e-01  4.88121222e+00
  4.37787856e+00  5.25039740e+00  4.05424560e+00  5.69416160e+00
  2.78763252e+00 -1.04218423e+00  3.75926765e+00 -1.78580341e+00
  5.84985311e+00  4.46103769e+00  5.26451090e+00  4.54647612e+00
 -4.96657114e+00  3.16889006e+00 -5.93224086e+00  2.15223817e+00
  4.38671204e+00 -2.21683676e+00  2.47402653e+00  7.71009628e-01
 -7.83963299e+00  3.21638223e+00 -6.52360802e+00  1.50966340e+00
  3.87812825e+00 -2.10633699e+00  3.09757968e+00 -7.89124209e-01
 -1.84016041e+00  5.43032295e+00  4.55045229e+00  7.96179844e+00
  8.91172174e+00 -2.79479602e+00  3.02276537e+00 -7.91188418e-01
 -1.83693658e+00  7.33266081e+00  3.31746997e+00  7.18843573e+00
  4.63327471e+00 -1.59679945e+00  1.27483647e+00 -1.89780594e+00
 -1.14582788e+00  2.49561450e+00  3.48436367e+00 -2.33217723e+00
 -4.22683424e+00 -3.60628662e+00  2.79007906e+00 -2.34206035e+00
  2.87995744e+01]
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1816.3802531568383
gradient value of function right now is: [ 2.25539735e+00 -1.52037242e-04 -9.63517793e-01 -5.28885765e-04
 -2.25539735e+00  1.52037242e-04  9.63517793e-01  5.28885765e-04
 -2.45876327e+00 -3.60450560e-01 -2.50683796e+00 -3.43675191e-01
  3.39019827e-05 -3.00520672e-05  3.06915856e-05 -4.65775847e-05
 -3.33675787e-01 -1.47692289e+00 -4.99920366e-01 -2.17578596e+00
 -8.19899670e-05 -2.68505247e-04 -1.10374737e-04 -3.96553009e-04
 -1.71540477e-02  4.69384361e-02 -8.84573944e-02  7.91074286e-01
  1.50820036e-01 -2.39267793e-02  2.82362580e-01 -3.18809293e-01
 -1.77787806e-02  7.30295699e-02 -1.03386966e-01  1.17039016e+00
  1.93515764e-01 -4.35089743e-02  3.74929209e-01 -6.01581440e-01
 -1.30973675e+00 -1.08552621e-01 -6.66134707e-01 -1.31718134e-01
 -2.20504919e-01 -2.03830936e-01 -5.78214527e-01 -2.51016115e-01
 -2.17053593e+00 -1.14137047e-01 -1.82961694e+00 -1.61129309e-01
 -1.35885827e+00 -9.73944495e-01 -3.02270971e+00 -1.20864032e+00
  1.71240860e+00  2.29870841e+00 -4.90185229e-01 -1.65081317e+00
  6.61480713e-01 -1.15461387e+00 -3.55881953e-01 -2.06649310e+00
  3.66583325e+00]
supnorm grad right now is: 3.665833246483063
Weights right now are: 
[ 0.65862006 -0.09173812 -2.86848151  0.15321728 -1.44883929  0.10620176
  3.43978756  1.26186576 -0.2463581   4.12726772 -0.26784092  5.36755682
  4.81650884  5.63733645  4.49351081  6.19284653  3.02778182 -0.88610541
  3.96427743 -1.76331112  6.11583585  5.11571858  5.56104373  5.30288328
 -4.9766453   3.88984272 -6.52636116  2.93020764  4.9570519  -2.70802481
  2.42560695  0.80674508 -8.18989582  4.03739633 -7.37659733  2.19846095
  4.42324736 -2.7599163   3.06666583 -1.04650615 -1.77688037  5.38737435
  5.1924048   7.88570529  8.50174184 -3.80960773  2.65426163 -1.64544594
 -1.80721402  7.05720832  3.25848334  6.67607424  4.38986867 -2.48705315
  0.73317799 -2.74879527 -1.60639573  2.77937568  4.06476229 -2.4113431
 -5.15917924 -3.20570288  3.33435437 -2.38356546 28.83771194]
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1816.7125407021229
gradient value of function right now is: [ 7.64787913e+00 -9.61748172e-06 -7.47001731e-01 -5.85319809e-05
 -7.64787913e+00  9.61748172e-06  7.47001731e-01  5.85319809e-05
 -7.28896925e+00 -3.08675863e-01 -7.35709051e+00 -2.78443128e-01
  5.58169148e-05 -4.35725095e-05  5.40564348e-05 -5.16453161e-05
 -9.15567528e-01 -1.55650536e+00 -9.87308956e-01 -1.80237295e+00
  1.81376727e-06 -5.25806060e-05 -5.25510025e-07 -6.26048320e-05
 -4.27647033e-03  1.44760989e-01 -2.39468578e-04  3.29270158e-01
  2.97041438e-01 -5.58042089e-02  5.01732738e-01 -1.13612839e-01
  2.67744635e-03  2.08540935e-01  1.37573410e-02  4.68002406e-01
  3.73470136e-01 -1.00756305e-01  6.24527591e-01 -2.12900004e-01
 -2.09767841e+00 -1.24251189e-01 -7.78974015e-01 -1.73327985e-01
 -4.18997241e-01 -8.31754041e-01 -1.56619273e+00 -8.82094656e-01
 -1.90903270e+00 -8.88834972e-02 -6.68074546e-01 -1.27613463e-01
 -3.05446575e-01 -5.23023611e-01 -1.02604219e+00 -5.60191741e-01
  2.08497469e+00  3.06150583e+00 -7.83068154e-01 -2.56040542e+00
  1.81304064e+00 -2.54984684e+00 -1.14176945e-01 -2.72778655e+00
  7.16695327e+00]
supnorm grad right now is: 7.647879133929707
Weights right now are: 
[ 0.84928232 -0.26192597 -2.86333401  0.10469944 -1.63950156  0.27638961
  3.43464005  1.31038361 -0.39415088  3.81310815 -0.42131481  5.1036308
  5.71788574  5.54171846  5.35768369  5.80363953  3.12386635 -0.68111735
  4.1174841  -1.47286572  6.74274524  5.64022736  6.22479878  5.91135933
 -5.39024619  3.85991431 -6.3440586   2.32674525  4.90201611 -3.69316433
  2.90239962  1.41824643 -8.89318172  4.11708806 -7.24981616  1.64372834
  4.32735625 -3.26776924  3.4696048  -0.46628612 -1.83382287  6.39440573
  4.8614448   8.926595    9.77518789 -3.96058543  2.64229289 -1.92012377
 -2.02361713  8.16470308  3.18822573  7.83104046  6.03021194 -1.83184817
  1.5849853  -2.10226353 -1.74295872  2.91490601  3.17843632 -2.46025257
 -4.41695636 -3.61241339  2.58925352 -2.18836371 29.29329298]
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1823.8450018219282
gradient value of function right now is: [ 2.92910292e+00  5.86342359e-05  3.32627384e-01  3.01222646e-05
 -2.92910292e+00 -5.86342359e-05 -3.32627384e-01 -3.01222646e-05
 -2.97297635e+00 -2.21074795e-02 -2.98356665e+00 -1.66959536e-02
  1.68079120e-05  1.13952662e-05  1.72171459e-05  1.32216047e-05
  3.38827091e-01  7.19737425e-01  3.70061815e-01  9.03152169e-01
  1.65933768e-05  1.95706371e-05  1.72298198e-05  2.25533648e-05
  4.64548846e-03 -8.50165875e-02  5.04215658e-02 -2.78590587e-01
  1.33653076e-01  3.66474529e-02  2.07038548e-01  1.04278759e-01
  8.23133702e-03 -1.18213195e-01  6.88549494e-02 -3.80734283e-01
  1.61932234e-01  6.08873651e-02  2.34645821e-01  1.81999141e-01
 -8.72769101e-01 -8.09628168e-02 -1.56590515e-01 -7.23812503e-02
  1.66800048e-01  6.18587966e-01  7.83163957e-01  6.71591721e-01
  1.20334582e-01  1.05181607e-02  9.29188736e-01  7.89077524e-02
  1.50259626e-01  4.56597727e-01  6.17881792e-01  5.12503341e-01
 -4.36893248e-01 -1.49757214e+00 -1.52600517e-01 -4.76202774e-01
  5.55560788e-01 -1.43971028e+00 -5.59799754e-01 -8.54172158e-01
 -4.32246907e+00]
supnorm grad right now is: 4.3224690726819635
Weights right now are: 
[ 8.17250419e-01 -2.70891457e-01 -3.22259807e+00 -6.37423715e-03
 -1.60746966e+00  2.85355095e-01  3.79390412e+00  1.42145729e+00
 -3.21080295e-01  3.60501322e+00 -3.45401849e-01  4.88374009e+00
  6.24479996e+00  5.76859980e+00  5.90385689e+00  6.13460337e+00
  2.99066880e+00 -8.38777418e-01  4.03434598e+00 -1.58145039e+00
  7.13456291e+00  5.71569662e+00  6.65879526e+00  5.98624996e+00
 -6.60434873e+00  3.08821894e+00 -7.02014720e+00  1.83237276e+00
  5.13430145e+00 -3.22937017e+00  2.94991662e+00  1.93747736e+00
 -1.04346648e+01  3.39562052e+00 -8.01594436e+00  1.13638359e+00
  4.57442158e+00 -2.70369021e+00  3.55796497e+00  3.65189043e-02
 -1.78202742e+00  6.60545837e+00  5.25028926e+00  8.95868766e+00
  1.11202512e+01 -2.89467829e+00  3.70793204e+00 -9.29543553e-01
 -2.24488743e+00  8.23855941e+00  3.29097795e+00  7.86659163e+00
  6.36206936e+00 -9.44194337e-01  2.39292488e+00 -1.33720157e+00
 -2.14785180e+00  2.12874198e+00  3.28486015e+00 -2.34007086e+00
 -4.90181000e+00 -3.47164566e+00  2.45901503e+00 -2.56029011e+00
  2.91283885e+01]
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1823.089990811231
gradient value of function right now is: [ 1.97300741e+00 -1.77700810e-05 -5.14544872e-01 -9.62724735e-06
 -1.97300741e+00  1.77700810e-05  5.14544872e-01  9.62724735e-06
 -3.28253182e+00 -5.97666406e-01 -3.31782712e+00 -4.93252373e-01
 -3.51391210e-06 -4.48079854e-06 -3.66689995e-06 -4.97908947e-06
 -1.35282661e+00 -1.60967815e+00 -1.39148220e+00 -1.70983413e+00
 -4.04314753e-06 -5.35218560e-06 -4.25031991e-06 -5.93236280e-06
 -1.74558040e-03  4.93537033e-02 -4.66879392e-03  1.47859326e-01
  1.93633228e-01 -2.39708197e-02  7.85428528e-01 -6.31380766e-02
 -1.15850466e-03  7.11810049e-02  2.10473403e-03  2.09001195e-01
  2.14510520e-01 -3.79781300e-02  8.92711330e-01 -1.03553642e-01
 -1.65562858e+00 -1.33673035e-01 -8.01491954e-01 -1.70905574e-01
 -1.35676299e-01 -3.57538136e-01 -6.14083487e-01 -4.71422779e-01
 -2.46988974e+00 -9.77122310e-02 -1.40772503e+00 -1.27166776e-01
 -1.41055780e-01 -2.16325151e-01 -4.26495334e-01 -2.98703519e-01
  3.20407710e-01  2.00374879e+00  9.75332180e-02 -1.58081248e+00
  1.64113758e+00 -1.79397139e+00  5.83619091e-01 -1.73999308e+00
  1.27289563e+00]
supnorm grad right now is: 3.317827116539532
Weights right now are: 
[  0.75175669  -0.24349637  -3.55785836   0.15965875  -1.54197592
   0.25796      4.12916441   1.2554243   -0.25871521   3.58813283
  -0.28983622   4.80614076   6.53097388   6.09330623   6.22631723
   6.58041915   2.98236922  -1.06405567   4.04942347  -1.80370448
   7.4538013    6.06445706   7.07608342   6.48233022  -7.61304431
   3.80603278  -8.65677665   2.26602401   5.45193016  -3.96109548
   2.56744162   1.81809219 -11.76041121   4.07362204  -9.88598621
   1.43058857   4.86200575  -3.38445747   3.235198    -0.10161001
  -1.89050993   6.62227223   5.27785448   9.10176341  11.19027508
  -3.56193283   3.36424575  -1.42296709  -2.49697639   5.55308865
   3.19645101   5.33855468   6.03276965  -1.20957278   2.18427417
  -1.60583393  -2.31505515   2.28474825   4.38378022  -2.07686458
  -4.40684807  -4.19656501   2.95216921  -2.33433746  29.47834556]
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1820.0493408345221
gradient value of function right now is: [-7.81751023e+00 -2.30089687e-05  4.44239696e-01 -1.56962145e-05
  7.81751023e+00  2.30089687e-05 -4.44239696e-01  1.56962145e-05
  8.11165738e+00  1.43849413e-01  8.11275845e+00  1.04921773e-01
 -8.16964551e-06 -1.10423942e-06 -8.56657804e-06 -2.64450139e-06
  1.81702615e+00  1.65077174e+00  1.84336760e+00  1.61171888e+00
 -8.97321007e-06 -3.00387621e-06 -9.79104653e-06 -6.16902829e-06
 -9.54798607e-04  1.43456531e-02 -5.87475966e-02 -1.10451039e-04
 -1.85251694e-01 -6.29826185e-03 -4.21082031e-01 -1.12792838e-02
 -1.25903811e-03  2.41885229e-02 -7.66496956e-02  2.02658360e-02
 -1.92133626e-01 -1.34386008e-02 -4.25212543e-01 -2.22997432e-02
  1.04982961e+00  8.39031474e-03  3.17776594e-01  2.20739405e-02
 -3.63097063e-02 -1.32331117e-01 -2.02372634e-01 -1.71672231e-01
 -3.87077656e-01 -1.32836707e-01 -9.40929020e-01 -2.98575511e-01
  1.10887938e-01 -3.43862550e-02  9.89318786e-02 -7.35073582e-03
 -2.64463699e-01  1.88803492e-01  1.48178518e-01 -7.41466638e-02
 -9.53000994e-01  1.56077825e+00  5.29746773e-01  4.40956195e-01
 -8.26482575e-01]
supnorm grad right now is: 8.112758448631457
Weights right now are: 
[  0.52651421  -0.29849203  -3.56986347   0.06777628  -1.31673345
   0.31295567   4.14116951   1.34730677   0.07189705   4.56741676
   0.04341165   5.78306948   6.99297308   6.30843572   6.70478084
   6.89334168   3.06922782  -0.99064702   4.13463622  -1.75945629
   7.35402649   6.24627854   7.01396783   6.81016816  -8.20856218
   4.12003818  -9.52722624   2.91535425   5.746871    -3.55803798
   1.85554913   1.86309515 -12.56820476   4.27510258 -10.94608637
   1.96861475   5.12981718  -3.21475526   2.55846028  -0.26613142
  -1.58836262   7.15630577   6.42651401  10.16418327  11.47416894
  -3.71734749   3.39923124  -1.48294944  -2.15400661   5.13929458
   3.57348428   5.08241672   6.23931057  -1.85221944   1.88633905
  -2.06207455  -2.40550304   2.50629269   4.58917957  -2.44527372
  -4.96237543  -3.6607172    2.5311415   -2.45179288  28.79268753]
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -1820.0139826109116
gradient value of function right now is: [ 3.61955555e-01  6.25526598e-05  8.75087465e-01  4.76588753e-05
 -3.61955555e-01 -6.25526598e-05 -8.75087465e-01 -4.76588753e-05
  9.68027209e-01  7.09005471e-01  1.00188011e+00  6.08486809e-01
 -8.54743657e-06 -1.27440465e-05 -1.11695891e-05 -2.00946319e-05
  2.00887947e+00  2.23309136e+00  2.18731852e+00  2.61333349e+00
 -2.79066296e-06 -4.47320308e-06 -3.72619992e-06 -7.19120831e-06
  8.35188703e-04 -3.45548422e-02  9.68376413e-03 -5.02636995e-01
 -2.15869871e-02  1.71569308e-02 -7.85468325e-01  1.40511893e-01
  6.38463589e-04 -6.03757665e-02  3.81649805e-03 -7.54283829e-01
 -3.40554136e-02  3.30780390e-02 -9.27951584e-01  2.92291258e-01
  4.56041673e-01 -1.45913035e-02  6.48796517e-01 -1.40343438e-02
  8.42955217e-02  2.85003500e-01  4.25053042e-01  3.87823511e-01
  2.85103366e+00  1.66163553e-03  2.51341747e+00  3.10873468e-02
  4.53185678e-01  7.50149817e-01  1.45059278e+00  1.23075938e+00
 -6.14717854e-01 -3.03163928e+00  3.84013644e-01  1.38922926e+00
 -1.22094216e+00  3.79178338e-01 -4.51134674e-01  4.67528250e-01
  6.00987312e+00]
supnorm grad right now is: 6.009873120640134
Weights right now are: 
[  0.86934777   0.31043073  -3.15623484   0.83944322  -1.65956701
  -0.29596709   3.72754089   0.57563983  -0.29183673   5.17909048
  -0.31419295   6.49541844   7.44155036   6.97512748   7.25320702
   7.84804912   3.39439639  -0.64328451   4.49415028  -1.34004959
   7.87891467   7.07417853   7.66791357   7.90815747  -8.82889232
   3.70863459 -10.20970461   2.61155588   6.86187633  -3.38611405
   1.95788697   2.39875544 -13.29679022   3.76209774 -11.79834626
   1.48156334   6.21602746  -2.74082981   2.61427715   0.3777891
  -2.18595754   8.3531094    6.19356559  11.1908659   11.6438424
  -3.42271677   3.89518715  -0.91184236  -2.41022981   4.728314
   3.25095781   4.8727118    6.09319792  -2.31222631   2.18980572
  -1.60333447  -3.53834737   1.70742613   5.78393971  -1.56422505
  -4.46377888  -4.12921888   2.92390056  -2.34459267  29.6886883 ]
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1814.5220911182482
gradient value of function right now is: [ 1.07065600e+00  8.26590618e-05  1.31929245e+00  7.65639593e-05
 -1.07065600e+00 -8.26590618e-05 -1.31929245e+00 -7.65639593e-05
  9.15180682e-02  4.33681281e-01  9.00765600e-02  2.81116612e-01
 -7.89137781e-06 -1.48823201e-05 -1.27683499e-05 -2.52897251e-05
  2.49245316e+00  2.70454893e+00  2.80468128e+00  3.24992928e+00
 -5.39870677e-06 -1.07862406e-05 -8.88497341e-06 -1.84266636e-05
  9.47208133e-05 -9.50557477e-02 -1.67923168e-02 -6.49306669e-01
 -2.57393017e-02  4.83445504e-02 -8.29479576e-01  2.03125651e-01
  4.49050762e-05 -1.97852631e-01 -2.60569937e-02 -1.11331057e+00
 -2.78566701e-02  1.05823724e-01 -8.85993475e-01  4.41771906e-01
  2.84733378e-01  5.37785758e-02  8.32245176e-02  4.45918295e-02
  1.72501419e-01  9.63334783e-01  1.24694072e+00  1.07741617e+00
  1.66437836e+00 -1.85284269e-02  9.60541618e-01 -6.62582043e-02
  3.21819093e-01  8.22579209e-01  1.28672271e+00  1.00361287e+00
 -9.41311713e-01 -3.95623544e+00  5.14946501e-01  2.53940448e+00
 -5.12464046e-01  1.05165857e-01  2.27061366e-01  1.79861552e+00
 -1.24484421e+01]
supnorm grad right now is: 12.448442076805536
Weights right now are: 
[  0.95684269   0.30884437  -2.80693313   0.93773862  -1.74706193
  -0.29438073   3.37823918   0.47734443  -0.28886863   5.09435851
  -0.31562884   6.29657278   8.03148208   8.02614442   8.18487596
   9.65402447   3.37431708  -0.46730652   4.53272517  -1.0500914
   8.40482704   8.08042915   8.51588082   9.49983598 -10.39900094
   3.70181853 -10.15892074   2.62270044   6.42577894  -4.09586366
   1.63418434   3.13977568 -14.81114397   3.71362036 -11.78476055
   1.23231479   5.92334735  -3.04662133   2.46985282   1.14047159
  -1.42151145  10.22553361   6.73266324  13.32492684  12.00214286
  -3.44289678   3.97783162  -0.87045619  -2.4675117    5.40698381
   3.22547692   5.35648858   6.88452352  -2.20847371   2.22700721
  -1.67637377  -3.49839985   2.07996192   5.05966377  -1.86595239
  -4.61465415  -3.94145574   2.89339591  -1.90304458  29.12417705]
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1817.5327126627703
gradient value of function right now is: [ 5.82158959e+00  2.41736012e-07 -8.12844666e-01 -1.38004092e-10
 -5.82158959e+00 -2.41736012e-07  8.12844666e-01  1.38004092e-10
 -6.57797152e+00 -9.89132548e-02 -6.57578885e+00 -4.49625937e-02
 -3.41820611e-07  1.32942082e-07 -3.33912057e-07  1.41942344e-07
 -2.24505547e+00 -2.56651316e+00 -2.32783260e+00 -2.63276482e+00
 -1.20644521e-07  9.47202664e-08 -1.14872931e-07  1.00836751e-07
  5.99815059e-05  5.17922623e-02  1.59459359e-02  1.18509712e-01
  1.98904805e-01 -2.78730617e-02  4.89453090e-01 -5.93753903e-02
  3.80791578e-05  7.91379139e-02  2.22537229e-02  1.77419432e-01
  1.59327642e-01 -4.16760476e-02  3.69469945e-01 -8.96585908e-02
 -1.55077721e+00 -4.75183785e-02 -2.37880988e-01 -9.17590775e-02
 -4.56993664e-01 -3.58000895e-01 -9.28563243e-01 -5.99747918e-01
 -9.54220621e-02  5.84367197e-02  3.51615123e-01  1.23498490e-01
 -2.07968296e-01 -1.28281006e-01 -3.70187441e-01 -2.30025860e-01
  1.57270497e+00  1.92743512e+00 -6.82892624e-01 -1.41144746e+00
  7.61150791e-01 -1.71365003e+00 -4.28485106e-01 -1.91719646e+00
  2.33075420e+00]
supnorm grad right now is: 6.577971524486059
Weights right now are: 
[  0.9375908    0.36251237  -3.67987931   1.0074686   -1.72781004
  -0.34804873   4.25118536   0.40761445  -0.21464956   5.23383757
  -0.24255447   6.39456618   8.10575095   8.16840453   8.29041757
   9.81990669   2.64248114  -1.19809861   3.77473475  -1.79531296
   8.46826564   8.20597685   8.60812727   9.65025435 -10.67047329
   6.00609881  -9.59796549   3.33842576   6.72108741  -5.53387499
   1.36019202   2.83352694 -14.99112047   5.80231889 -11.22648173
   1.82231332   6.09667629  -4.41479481   2.32267922   0.87242906
  -1.21122949  11.29936961   7.17373371  14.49680755   9.88622871
  -5.73740198   2.28094951  -2.59452175  -1.97558035   6.0439311
   3.88232613   6.59434442   6.49459355  -2.84426949   1.72891875
  -2.20097727  -3.08406304   2.91823083   4.37659064  -2.44695339
  -4.90140871  -3.67386717   2.06420944  -2.22115951  28.43664854]
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1823.6147924536692
gradient value of function right now is: [ 2.08125862e+00  9.39667014e-07  9.06635002e-01  8.02785131e-07
 -2.08125862e+00 -9.39667014e-07 -9.06635002e-01 -8.02785131e-07
 -2.49697798e+00 -3.90283591e-01 -2.50816264e+00 -2.92715761e-01
 -2.56697474e-07 -3.60679850e-07 -2.76182002e-07 -3.85755766e-07
  2.55900482e+00  2.50232853e+00  2.64549262e+00  2.56476231e+00
 -1.60155326e-07 -2.74551188e-07 -1.74611101e-07 -2.95841401e-07
 -2.48322675e-04 -4.45884159e-02 -2.10137973e-02 -1.07240810e-01
  9.25744947e-02  2.97908222e-02  6.01108014e-01  5.45494127e-02
 -1.93086152e-04 -7.00953380e-02 -2.55128461e-02 -1.62904835e-01
  7.56227048e-02  4.43443290e-02  5.16508085e-01  8.23549572e-02
 -1.05213214e+00 -6.09702322e-02 -3.40302070e-01 -7.85711285e-02
  1.58760485e-01  3.52093598e-01  6.32068252e-01  5.53921140e-01
 -1.73214272e+00 -5.24172572e-02 -9.81861614e-01 -1.56599468e-01
  1.61750967e-02  1.27840742e-02  4.48472824e-02  3.49733579e-02
 -6.60248353e-01 -1.63042075e+00  6.18097779e-01  2.72529030e-01
  1.15838437e+00 -1.87422014e+00  8.45831776e-01 -9.29490530e-01
 -1.30144699e+01]
supnorm grad right now is: 13.014469922861029
Weights right now are: 
[  0.72467159   0.40615605  -3.3022109    1.04735724  -1.51489082
  -0.39169241   3.87351695   0.3677258   -0.34406784   4.36242771
  -0.37524455   5.58109895   8.09914335   8.15305079   8.28028782
   9.80116634   2.55400558  -0.98781424   3.74891391  -1.52554658
   8.46292917   8.19318926   8.60016925   9.63512634 -11.63625785
   4.73077866  -9.4879756    2.52452541   7.58591336  -3.72847316
   2.37060172   4.16617909 -16.02261006   4.38936893 -11.18669708
   0.9059528    6.91878618  -2.62141872   3.37957008   2.05404411
  -1.71082543  11.16163626   7.39166624  14.06719843  11.16178593
  -4.28113668   3.82281501  -1.20930097  -2.46921989   6.69859777
   3.5801655    6.61204092   7.29803063  -1.85550785   2.75894871
  -1.31922342  -4.17843329   1.9586108    5.55904563  -1.66738162
  -4.86217386  -3.869105     2.98863092  -2.28914908  28.9521937 ]
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1815.8460116458425
gradient value of function right now is: [ 1.76185248e+00 -5.63558181e-07 -5.54573438e-01 -3.34749576e-07
 -1.76185248e+00  5.63558181e-07  5.54573438e-01  3.34749576e-07
 -6.03414655e+00 -2.11235025e+00 -6.06226904e+00 -1.12472844e+00
  3.02728688e-07  4.48849286e-08  3.04430287e-07  5.19613216e-08
 -1.00306894e+00 -1.74940737e+00 -1.04689986e+00 -1.82015979e+00
  1.36063009e-07  3.33696238e-08  1.37251007e-07  3.63608760e-08
 -1.80999270e-05  9.13467639e-02 -1.68145940e-02  5.93178498e-02
  3.65909102e-04 -4.60159095e-02  4.05324085e+00 -2.62777094e-02
 -1.05833525e-05  1.35427683e-01 -1.13655149e-02  8.72803494e-02
  5.88604807e-04 -6.78365569e-02  2.89454780e+00 -4.07711628e-02
 -1.70856618e-01 -1.85230198e-02 -1.71075351e-01 -3.31831891e-02
 -6.82857691e-01 -7.53789098e-01 -1.50145692e+00 -7.57049904e-01
 -7.12934077e+00 -2.44454511e-01 -6.36293526e+00 -6.20958944e-01
 -8.63960448e-02 -7.40807509e-02 -1.58462369e-01 -7.64181646e-02
  3.09780380e-01  2.25660254e+00  2.20744081e-01 -1.63882941e+00
  1.31533394e+00 -6.90342780e-01  2.07835063e+00 -1.31459541e+00
  3.67639259e+00]
supnorm grad right now is: 7.12934077088458
Weights right now are: 
[  0.72398977   0.33325785  -3.67492364   0.97501012  -1.51420901
  -0.31879422   4.24622968   0.44007293  -0.31746586   4.37929342
  -0.3533386    5.47133755   8.10405786   8.18656461   8.28874772
   9.83838811   2.69808459  -1.20020622   3.88788856  -1.77118589
   8.46871627   8.21981425   8.60879117   9.66470208 -12.20849774
   6.07870765 -10.58251177   3.2931409    8.16594939  -5.03202696
   2.01366753   3.48716765 -16.55354927   5.72642317 -12.38724447
   1.64474592   7.1043831   -4.04162392   3.39983199   1.34255455
  -1.66264735  11.72960142   7.8965586   15.77054655  10.10065859
  -5.42462683   2.60274671  -2.33662755  -3.2818678    6.06882834
   2.50790219   6.02641012   6.98752854  -1.94156718   2.45317886
  -1.56284613  -2.85832643   3.20544253   4.09787216  -2.88940585
  -3.95689684  -3.8299549    2.98366193  -2.0058338   29.70807461]
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1815.210598368907
gradient value of function right now is: [-2.35243011e+00 -4.83678616e-07  5.74852219e-01 -2.99015449e-07
  2.35243011e+00  4.83678616e-07 -5.74852219e-01  2.99015449e-07
  1.82305108e+00 -4.12041270e-01  1.80279237e+00 -3.03501601e-01
  2.41186995e-07  1.67461780e-08  2.47348905e-07  2.48928651e-08
  2.49101191e+00  1.96809025e+00  2.53320136e+00  1.90290744e+00
  9.35565767e-08  2.36046329e-08  9.84797191e-08  2.92526372e-08
 -4.60319767e-05  2.12135449e-02 -7.99027545e-02  4.85434186e-03
  1.68902005e-02 -7.57575590e-03  4.81949251e-01 -7.96406257e-04
 -5.00607810e-05  3.70126193e-02 -1.01276027e-01  1.33793530e-02
  9.27141449e-03 -1.69236533e-02  4.50927317e-01 -6.31941207e-03
 -2.27175649e-01 -2.49295607e-02 -2.42304592e-02 -3.74296265e-02
 -1.08493450e-01 -2.48797698e-01 -3.56475683e-01 -2.51626718e-01
 -2.76300558e+00 -3.23956760e-01 -2.56658321e+00 -4.77342296e-01
  1.85336807e-02 -1.83431987e-02  1.59094588e-03 -1.52378827e-02
 -1.70751210e-01  6.01397409e-01  9.28058306e-01 -6.29074404e-01
  1.50160246e-01 -1.87599610e-01  1.46320103e+00 -6.75707070e-01
 -1.38534898e+01]
supnorm grad right now is: 13.85348978344015
Weights right now are: 
[ 5.99206650e-01  3.20027376e-01 -3.41936411e+00  9.58465102e-01
 -1.38942589e+00 -3.05563738e-01  3.99067016e+00  4.56617946e-01
  1.07033406e-02  4.87419892e+00 -2.35239742e-02  6.00895284e+00
  8.10099557e+00  8.19694309e+00  8.28619063e+00  9.84918498e+00
  2.80873556e+00 -8.95667828e-01  3.99037847e+00 -1.46228063e+00
  8.46888074e+00  8.22696075e+00  8.60931455e+00  9.67218934e+00
 -1.24992743e+01  6.12863943e+00 -9.56203080e+00  3.65566703e+00
  8.55550917e+00 -4.41708925e+00  1.72696352e+00  3.66608031e+00
 -1.67387912e+01  5.73141599e+00 -1.14271334e+01  1.96846869e+00
  7.32607934e+00 -3.59097588e+00  3.18351385e+00  1.35617289e+00
 -1.62945071e+00  1.19908789e+01  8.93183190e+00  1.55755907e+01
  1.14971075e+01 -5.37012361e+00  3.05693802e+00 -2.38017310e+00
 -2.81416035e+00  7.63303179e+00  3.14381432e+00  6.94901112e+00
  7.13800569e+00 -2.31662103e+00  2.27446954e+00 -1.98967069e+00
 -2.92127156e+00  3.64014885e+00  3.32413928e+00 -3.34528962e+00
 -5.15989175e+00 -3.28062314e+00  2.50528669e+00 -2.82578647e+00
  2.83845211e+01]
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1822.6246066088697
gradient value of function right now is: [-5.68772548e+00 -7.44827677e-07  3.42985134e-01 -3.50791321e-07
  5.68772548e+00  7.44827677e-07 -3.42985134e-01  3.50791321e-07
  5.40084279e+00 -8.58136995e-02  5.39373411e+00 -8.43537137e-02
  5.09130233e-07 -2.63816797e-08  5.09533188e-07 -2.80597760e-08
  1.31916818e+00  1.16278742e+00  1.32939402e+00  1.15292733e+00
  1.91763880e-07 -1.35897396e-08  1.92138776e-07 -1.45705486e-08
 -3.55060979e-06  2.73734362e-02 -2.28680628e-02 -1.18481984e-03
 -3.19329660e-02 -1.10243680e-02 -3.97016891e-02  5.96367970e-05
 -3.91200229e-06  4.46987853e-02 -2.83350989e-02 -9.61389453e-04
 -1.81456019e-02 -1.89750534e-02  3.63296542e-02  4.98950155e-05
  2.10236715e-01  1.16167459e-03  2.81143245e-02  2.68748294e-03
 -6.40714926e-03 -2.72610735e-01 -3.17306641e-01 -2.72431039e-01
 -7.18421043e-01 -8.72793315e-02 -7.61137491e-01 -1.16294943e-01
  3.25830205e-03  7.66263493e-04  3.59544791e-03  8.27416254e-04
  8.87172323e-02  5.00339260e-01  2.68284037e-01 -2.80493132e-01
 -7.67649791e-02  1.79494294e-01  4.22725552e-01 -3.08784724e-02
 -3.80918098e+00]
supnorm grad right now is: 5.687725483822788
Weights right now are: 
[ 5.67657893e-01  3.32018986e-01 -3.33677783e+00  9.63998661e-01
 -1.35787713e+00 -3.17555348e-01  3.90808388e+00  4.51084387e-01
  1.12140659e-03  4.96464551e+00 -3.33149420e-02  6.09041810e+00
  8.09331975e+00  8.19916241e+00  8.27829747e+00  9.85132006e+00
  2.72781343e+00 -8.07960216e-01  3.95007126e+00 -1.38864692e+00
  8.46623716e+00  8.22796616e+00  8.60651685e+00  9.67313721e+00
 -1.26764932e+01  5.16973020e+00 -9.83608426e+00  2.72950412e+00
  8.89774995e+00 -3.55043270e+00  1.76398112e+00  4.36515672e+00
 -1.70391375e+01  4.73321004e+00 -1.16890134e+01  1.01986936e+00
  7.52416329e+00 -2.59367493e+00  3.34122383e+00  2.17640640e+00
 -1.42234935e+00  1.40810953e+01  9.21911583e+00  1.70462903e+01
  1.28755366e+01 -4.29394433e+00  4.14597601e+00 -1.46333799e+00
 -3.03251252e+00  8.39228596e+00  2.95244935e+00  7.28816817e+00
  8.35161405e+00 -8.48274770e-01  3.50221350e+00 -7.19779806e-01
 -3.01688036e+00  3.38689683e+00  2.95818198e+00 -2.74424990e+00
 -4.56262197e+00 -4.10215288e+00  2.47855291e+00 -2.49981261e+00
  2.88223376e+01]
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1823.0558202969526
gradient value of function right now is: [ 1.55253860e+00  1.14899981e-08 -6.92554272e-01 -3.72110818e-08
 -1.55253860e+00 -1.14899981e-08  6.92554272e-01  3.72110818e-08
 -1.67514804e+00  5.48454505e-03 -1.67381194e+00  1.41377307e-02
 -6.58372781e-08  5.36766562e-08 -6.47455417e-08  5.46464730e-08
 -2.33201868e+00 -2.29962937e+00 -2.35814392e+00 -2.27261074e+00
 -1.37098350e-08  3.22584892e-08 -1.29947502e-08  3.25252842e-08
  2.71151775e-05  2.01131307e-02  2.16349461e-02  2.01492935e-03
  8.35424934e-02 -7.68891754e-03  1.36318585e-01 -7.16526342e-04
  1.65217925e-05  3.19913578e-02  3.21049709e-02  3.21383908e-03
  5.13724959e-02 -1.09229208e-02  4.23548913e-02 -1.13678337e-03
 -9.52924227e-01 -5.69767440e-02 -1.42354877e-01 -5.39198036e-02
 -2.81212663e-02 -2.01742728e-01 -2.47134307e-01 -2.33279071e-01
  5.21536823e-01  1.00870824e-01  6.57409699e-01  1.67813887e-01
 -8.88297835e-04 -2.71358051e-03 -2.95638129e-03 -2.95453894e-03
  3.55197111e-01  6.46581488e-01 -3.26736951e-01 -9.12309198e-01
  3.24111977e-01 -9.68657749e-01 -3.46766409e-01 -8.39109303e-01
  1.14349174e+00]
supnorm grad right now is: 2.3581439219422404
Weights right now are: 
[  0.73770359   0.35973393  -3.42056475   0.98364394  -1.52792283
  -0.34527029   3.99187079   0.43143911  -0.14858812   6.10218426
  -0.17836981   7.32189704   8.08234349   8.19840602   8.26647761
   9.84955047   2.42806944  -0.93393433   3.66578064  -1.5109
   8.46233992   8.22652323   8.60198175   9.67088041 -12.63600163
   5.07932832  -9.70917217   3.0153387   10.38585255  -2.79867755
   1.13500731   4.59528562 -17.0226115    4.48405079 -11.91082184
   1.16027285   8.91379821  -1.98330871   2.64882648   2.318387
  -2.21024461  14.02758572  10.00755989  16.82828749  13.01225768
  -4.10322625   4.41479342  -1.43645325  -2.32722586   7.59989932
   3.79086611   6.48922781   8.20211282  -0.54478797   3.73602993
  -0.44620685  -3.57679141   3.09203863   3.65323792  -2.75404409
  -4.77944985  -4.27563811   2.69695722  -3.09108918  28.8002736 ]
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1825.780531965876
gradient value of function right now is: [-2.74672543e+00 -2.56755935e-07  3.91074593e-01 -9.21375164e-08
  2.74672543e+00  2.56755935e-07 -3.91074593e-01  9.21375164e-08
  2.22291974e+00 -3.01724903e-02  2.21872802e+00 -3.81704913e-02
  2.26505168e-07 -4.57171492e-08  2.26630961e-07 -4.45639521e-08
  1.26835677e+00  1.27032697e+00  1.27773847e+00  1.26385578e+00
  7.55675293e-08 -2.60505185e-08  7.57036743e-08 -2.56600186e-08
 -3.53543669e-06 -1.60410274e-03 -8.88278281e-03 -3.71938179e-03
  3.63423095e-02  8.28591756e-04  1.24611861e-03  1.33498809e-03
  1.33851226e-06 -9.61025414e-04 -1.01005912e-02 -5.38249372e-03
  1.56123192e-02  2.32004198e-03  5.86530445e-03  2.12731017e-03
 -4.31406370e-01 -4.94212144e-02 -5.30182289e-02 -4.23547289e-02
  4.35997842e-02  2.25941676e-03  5.08731832e-02  1.52122986e-02
 -1.77780391e-01 -6.37868566e-02 -1.11165088e-02 -8.35929536e-02
  1.67566155e-03  4.09702706e-03  7.56247869e-03  5.56099889e-03
 -2.37281842e-01 -1.47515444e-01  3.47223392e-01 -5.23151221e-01
 -9.10472489e-02 -2.82759478e-01  3.74381425e-01 -4.73882436e-01
 -3.31878206e+00]
supnorm grad right now is: 3.318782063758883
Weights right now are: 
[  0.70082111   0.36432524  -3.37828692   0.98309313  -1.49104034
  -0.3498616    3.94959297   0.43198992  -0.22273211   5.33484312
  -0.25169021   6.64658754   8.0760694    8.20211629   8.26015597
   9.85327943   2.63631399  -0.77320923   3.88441202  -1.37330626
   8.46042638   8.2288584    8.60004053   9.67320228 -13.36047746
   4.89489304  -9.92449044   3.04090638  10.46581716  -2.73380206
   1.93115576   4.59589472 -17.60364449   4.29289148 -12.21715234
   1.17517878   9.13688499  -2.0038884    3.67736037   2.25907783
  -2.28238223  14.07979538  10.41496464  16.69763604  12.77883258
  -4.07940593   4.70933512  -1.43016827  -3.03387243   7.57117596
   3.0301024    6.30945635   8.01977498  -0.35330442   3.97976653
  -0.23587025  -4.04329034   2.64442563   4.53011469  -2.25367149
  -4.75318927  -4.18963209   3.69795731  -2.7626062   29.390872  ]
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1821.864394580596
gradient value of function right now is: [-1.28815033e+00  1.97164490e-07  8.58255054e-01  2.04538500e-07
  1.28815033e+00 -1.97164490e-07 -8.58255054e-01 -2.04538500e-07
  1.02655947e+00 -6.30008741e-02  1.03124452e+00 -4.51835585e-02
  7.69281441e-09 -1.57340711e-07  7.03740327e-09 -1.54663584e-07
  2.72664187e+00  2.72804988e+00  2.74724959e+00  2.71836412e+00
 -3.03131447e-08 -8.59651142e-08 -3.05262064e-08 -8.51214174e-08
  2.06263481e-06 -1.89339764e-02 -1.79853792e-02 -3.27877140e-03
  5.36020163e-02  2.38256009e-03  1.46928781e-01  7.91711662e-04
  7.30081019e-06 -2.08910181e-02 -2.60445187e-02 -4.51803690e-03
  2.16256918e-02  4.19897952e-03  2.10732380e-02  1.42810508e-03
 -6.47022032e-01 -3.17775163e-02 -1.07562881e-01 -4.05077802e-02
  1.66177520e-01  1.16240010e-01  3.26628572e-01  1.74099069e-01
 -3.73686790e-01 -4.62384639e-02 -2.98607157e-01 -8.64236969e-02
  2.54487057e-03  2.10598457e-03  5.91918406e-03  3.21054308e-03
 -5.98829028e-01 -7.22859476e-01  5.34369325e-01 -7.49364938e-02
  3.54566583e-01 -7.82150566e-01  5.99979682e-01 -3.30401487e-01
 -9.73457240e+00]
supnorm grad right now is: 9.734572398461294
Weights right now are: 
[  0.71586426   0.37131432  -3.12043422   0.98367368  -1.5060835
  -0.35685068   3.69174026   0.43140937  -0.16989064   5.06136502
  -0.20489332   6.03746355   8.06774521   8.20581051   8.25190931
   9.85689596   2.90955406  -0.55056311   4.12137083  -1.11349338
   8.45792318   8.23112389   8.59757598   9.6754227  -14.03057496
   6.05674024  -8.81398848   2.97176402  10.64051826  -3.17311224
   1.7590995    5.47613222 -18.26099197   5.34000474 -11.06388476
   1.01419021   9.39578898  -2.69232559   3.78204264   2.91265007
  -2.02941612  14.86603104  11.25910421  17.52480287  11.48633101
  -5.30118086   3.75157022  -2.57147494  -2.22412486   8.67001962
   3.90759177   7.36858399   7.93508279  -0.44637315   3.90967119
  -0.3611415   -4.07108565   3.27919531   4.07474134  -2.31125264
  -4.55643016  -4.22738645   2.83897661  -2.38273972  28.81858218]
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1815.433760404891
gradient value of function right now is: [-3.91267714e+00 -3.85713984e-07  3.89126735e-01 -1.77123811e-07
  3.91267714e+00  3.85713984e-07 -3.89126735e-01  1.77123811e-07
  4.91967096e+00  4.30557663e-01  4.91982175e+00  1.02756802e-01
  2.97439455e-07 -6.36888834e-09  2.98488755e-07 -1.92293041e-08
  1.74137495e+00  1.46408058e+00  1.75749230e+00  1.45587923e+00
  9.64639926e-08 -3.53378231e-10  9.73231657e-08 -5.05947025e-09
  5.77273871e-06  4.86437906e-02 -4.22466421e-02  4.22626025e-04
 -3.13029605e-01 -1.98489982e-02 -1.58183252e+00 -8.30490233e-04
  1.01164399e-06  7.73460268e-02 -5.86526241e-02  7.17172294e-04
 -8.87874496e-02 -3.48213006e-02 -5.07006331e-01 -4.69588999e-04
  2.88696993e+00  1.00373734e-01  1.31215351e-01  1.52961002e-01
 -2.65341161e-01 -3.53616445e-01 -7.26284081e-01 -5.09716805e-01
 -4.14739357e-01 -6.23652971e-02 -8.67286070e-01 -1.73038070e-01
  4.51499789e-03 -7.16899018e-04 -4.84413460e-04 -6.49085149e-04
  9.31432220e-01  1.06891184e+00 -6.14932305e-01  1.17834242e+00
 -3.38290707e-01  1.50257890e+00 -1.40019615e-01  2.79605853e+00
  2.23086089e+00]
supnorm grad right now is: 4.919821754122605
Weights right now are: 
[  0.57158354   0.37626108  -3.36695017   0.98254749  -1.36180277
  -0.36179745   3.93825621   0.43253556   0.07395707   6.00135386
   0.03497481   6.44069256   8.05974935   8.21084532   8.24394621
   9.86192405   2.77517951  -0.81142301   3.99710789  -1.39600234
   8.45601962   8.23384126   8.59568001   9.67814928 -14.24655002
   6.9945618   -9.51596161   3.25561435   9.98063126  -3.2430172
   0.5650672    5.3489984  -19.09673615   6.09305206 -11.73304874
   1.22353159   8.33499174  -2.91506597   2.91677102   2.84254689
  -0.81050785  17.45704337  12.21890074  20.02093219  10.03855293
  -6.06281514   2.7942488   -3.30145199  -2.22238227   8.11668274
   3.92760557   7.17085456   7.88562322  -0.32955925   3.59410584
  -0.35546272  -3.25102309   4.11755398   3.07779211  -2.51306516
  -4.21324956  -4.08991396   1.4898646   -2.39075896  28.28627378]
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1818.611216208069
gradient value of function right now is: [ 3.08874251e+00  6.09423825e-08 -1.97070517e+00 -5.53965913e-08
 -3.08874251e+00 -6.09423825e-08  1.97070517e+00  5.53965913e-08
 -3.42625261e+00 -2.00651762e-01 -3.43540253e+00 -5.05429319e-02
 -1.53326493e-07  1.05356377e-07 -1.51626737e-07  1.06894253e-07
 -6.63332250e+00 -6.66266712e+00 -6.73675585e+00 -6.61248030e+00
 -3.11376149e-08  5.78906751e-08 -3.01644421e-08  5.81583822e-08
  5.83511197e-06  4.36015433e-02  7.67073622e-02  5.94528490e-04
  4.21727252e-02 -2.72998236e-02  4.10855053e-01 -4.52732491e-04
  4.98832029e-06  7.02802126e-02  1.27454506e-01  9.30496611e-04
  3.75310197e-03 -4.07596860e-02  1.67595327e-01 -5.92000075e-04
 -4.73596308e-01 -2.77703820e-03 -1.20435314e-01 -1.52538123e-02
 -1.68200210e-01 -3.73060789e-01 -5.99392927e-01 -4.44926117e-01
  1.17369658e+00  6.07035122e-01  1.07365013e+00  8.55116590e-01
  1.52688108e-03  9.79331727e-04  1.41659520e-03  1.15644226e-03
  1.01698965e+00  1.39093336e+00 -1.23924850e+00 -9.78601360e-01
  5.45217050e-01 -8.21153999e-01 -1.10091253e+00 -1.19654941e+00
  1.60913408e+01]
supnorm grad right now is: 16.091340763163725
Weights right now are: 
[  0.9417257    0.36762232  -3.93479146   0.96710656  -1.73194494
  -0.35315868   4.50609751   0.44797649  -0.29798      5.27748616
  -0.33729667   5.6502491    8.05247446   8.22222912   8.23681265
   9.87328954   2.21807223  -1.280651     3.49329817  -1.91972482
   8.4547257    8.24146242   8.59453357   9.68564753 -14.19923184
   5.49606778 -10.09553209   2.59210842  11.32337929  -1.89008821
   1.15616775   5.8976396  -19.21191244   4.57296159 -12.44096466
   0.54072935   9.49636242  -1.68286631   4.0992579    3.33419913
  -1.96827715  15.99483161  12.02095586  19.02720901  11.62329442
  -4.47752615   4.16856472  -1.78350394  -3.10068157   7.79465794
   2.90871019   6.35730214   8.03233873   1.29909525   4.82422304
   1.18858582  -4.32117465   3.02574278   4.28933177  -2.23773978
  -4.26453018  -4.40668517   2.89976043  -2.31137192  29.42372365]
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1826.0592660097384
gradient value of function right now is: [-3.51278213e+00 -5.38286355e-07  6.92742251e-02 -2.80682054e-07
  3.51278213e+00  5.38286355e-07 -6.92742251e-02  2.80682054e-07
  3.44323245e+00  1.52157114e-02  3.43850883e+00 -3.84986206e-02
  3.45561888e-07  2.86755796e-08  3.51828646e-07  2.63654251e-08
  3.93544057e-01  2.87748141e-01  3.78724784e-01  2.78554271e-01
  1.22174808e-07  1.50033098e-08  1.26269104e-07  1.44050748e-08
  3.78809866e-06  4.65702404e-02 -6.15079781e-03 -4.18901122e-05
 -3.60252713e-02 -1.60200354e-02 -2.85982053e-01 -2.13603954e-04
  1.70221288e-06  7.83911804e-02 -6.60652382e-03 -3.61105998e-06
 -8.78726751e-03 -2.89413607e-02 -1.04124413e-02 -1.07210314e-04
  3.60765795e-01  4.52894996e-02 -1.60576058e-02  4.73996160e-02
 -8.96799584e-03 -3.31197569e-01 -4.64480772e-01 -3.78912448e-01
 -2.17638118e-01  7.01242892e-02 -7.12516319e-01  2.55241836e-02
  1.34998408e-03  3.86832928e-04  3.31279774e-04  4.45448121e-04
 -9.79332380e-02  1.29052823e-01 -1.01763219e-02  4.10907005e-01
  1.72674293e-01 -3.64909069e-02  2.97151593e-01  9.69636529e-01
  1.27064903e+00]
supnorm grad right now is: 3.512782132331349
Weights right now are: 
[  0.78911195   0.36815755  -3.47287665   0.96714408  -1.57933118
  -0.35369392   4.04418269   0.44793896  -0.2001141    5.30149253
  -0.23613891   6.2503772    8.05162869   8.22473032   8.2357124
   9.8758928    2.61343407  -0.80221802   3.90591971  -1.45272386
   8.45533957   8.24212914   8.59496063   9.68634386 -14.40003164
   5.19353856 -10.46928341   2.84837949  11.45933014  -1.13223984
   1.63533176   5.78392857 -19.66637874   4.16330592 -12.97407777
   0.74022452   9.93437779  -1.03345585   4.21830282   3.28868254
  -1.96287858  15.7880095   12.35372316  18.83179549  12.06334133
  -4.14408237   4.51653084  -1.67050929  -3.13233846   7.95740184
   2.88397774   6.42010255   8.11306158   1.09170016   4.61909969
   1.01169228  -3.83305789   3.47059385   4.41211846  -2.1289982
  -4.11192217  -4.41362177   3.24221588  -2.04198264  29.48565692]
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1814.0649607003509
gradient value of function right now is: [ 5.20059484e+00 -7.82703493e-10 -8.57133812e-01 -3.40490601e-07
 -5.20059484e+00  7.82703493e-10  8.57133812e-01  3.40490601e-07
 -4.67896394e+00  3.52869493e-01 -4.65568189e+00  2.05194771e-01
 -3.44301541e-07  2.62331860e-07 -3.28829982e-07  2.74516943e-07
 -2.31479697e+00 -2.61130118e+00 -2.47260091e+00 -2.56495180e+00
 -7.38611548e-08  1.57404449e-07 -6.46932792e-08  1.65481102e-07
  2.11813120e-04  1.52325346e-01  9.03387428e-02  2.24315910e-03
  1.67793277e-02 -5.50815127e-02 -4.51564413e-01 -8.14527044e-04
  1.33060157e-04  2.46565100e-01  1.14920875e-01  3.50276241e-03
 -3.52141577e-03 -1.02498290e-01 -4.08084917e-01 -1.42555483e-03
 -3.51602402e-02 -7.25803610e-03  1.06202667e-01 -8.63114298e-03
 -4.23755967e-01 -7.42085677e-01 -2.02326760e+00 -1.17098224e+00
  3.23811305e+00  9.81872358e-02  2.30241812e+00  2.47558236e-01
  1.17054176e-04 -1.02828547e-03 -3.82726844e-03 -2.11004872e-03
  1.77020677e+00  1.91333361e+00 -1.67506904e+00 -1.52065538e+00
 -1.77838485e+00  1.95651486e+00 -1.80055496e+00 -7.96784190e-01
  2.07176288e+01]
supnorm grad right now is: 20.717628847351182
Weights right now are: 
[  0.90887262   0.31889638  -3.41022011   0.90821494  -1.69909186
  -0.30443274   3.98152616   0.50686811  -0.22941718   6.01327658
  -0.25936902   7.38218518   8.04579299   8.25664528   8.23135357
   9.90774727   2.7883345   -0.6064784    4.01059516  -1.18273439
   8.45597136   8.26371699   8.5965916    9.70792301 -13.68503846
   6.59797657  -8.83062091   3.62763036  11.01463063  -1.38362013
   1.23670471   5.92666818 -17.7436874    5.45886792 -11.81528775
   1.37011449  10.00845442  -1.95340683   3.62410408   3.2377935
  -1.64047329  15.43336789  12.55998531  19.25522081   9.98999202
  -5.63382136   3.35079781  -2.96398037  -1.73947967   7.62985628
   4.45242637   6.49781265   7.58555636   1.24070258   4.15050881
   0.61797857  -2.90561955   4.72021726   4.24083434  -2.72090955
  -4.73504262  -3.96943095   2.44400886  -2.42571019  28.96431313]
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -1824.9128218127526
gradient value of function right now is: [ 2.81554362e-01  1.34347150e-07 -1.03459122e-01  1.56891324e-07
 -2.81554362e-01 -1.34347150e-07  1.03459122e-01 -1.56891324e-07
 -1.42887371e-01  1.34296128e-01 -1.34732999e-01  5.92007248e-02
 -7.63193073e-09 -4.09085500e-08 -4.62284951e-09 -5.22380416e-08
 -6.33774638e-01 -4.50862578e-01 -6.76297984e-01 -3.85656074e-01
  2.02970550e-09 -3.04739645e-08  3.30269392e-09 -3.81223893e-08
  2.80427918e-06  9.88880031e-03  2.90563095e-02 -4.62390914e-05
  3.18756204e-02  7.68265320e-03 -1.56335768e-01  7.94096100e-05
  2.10647041e-06  1.74501449e-02  3.75493343e-02 -6.57390173e-05
  4.31989144e-03  9.34994465e-03 -1.55015789e-01  2.86584659e-05
 -3.53557576e-01 -2.22018115e-02 -1.78055107e-02 -2.64192363e-02
  1.79424701e-02 -8.13827214e-02 -8.79770883e-02 -1.06551001e-01
  1.15397639e+00  1.74137842e-02  1.04295717e+00  9.41151614e-02
 -4.40554132e-04 -5.24454263e-05  5.21958102e-05 -4.33129449e-05
  6.28239062e-02  1.84930590e-03 -9.94738350e-02 -5.38380920e-01
 -5.48018295e-01  2.43572646e-01 -3.36419692e-01 -5.15122240e-01
 -4.84691737e-01]
supnorm grad right now is: 1.1539763948738724
Weights right now are: 
[  0.75452411   0.2894084   -3.48665272   0.86053739  -1.54474335
  -0.27494476   4.05795877   0.55454565  -0.1361024    5.90223061
  -0.15855678   7.38478473   8.03457226   8.27642808   8.21938445
   9.93270099   2.30836077  -0.68786246   3.58937819  -1.22451612
   8.45254134   8.27792045   8.59272468   9.72598042 -15.53048385
   5.37179858  -8.78464815   2.94286507  10.80852822  -0.60580121
   1.36535228   6.42473056 -20.5229642    4.19079054 -12.06788722
   0.61809103  10.34780159  -1.1956972    4.364113     4.18306973
  -1.35901536  14.88220911  13.81125647  18.81582523  11.30978738
  -4.42264785   4.75962436  -1.80866873  -2.44417285   7.01177933
   4.46938594   6.39290595   7.71810123   2.08736538   5.19127355
   1.72455411  -3.24716762   3.78142864   5.14515327  -2.42780472
  -4.62834044  -3.83775276   2.80243458  -2.62028652  28.72900454]
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -1814.0948372270705
gradient value of function right now is: [-9.01862563e+00 -7.02658832e-07 -5.57508775e-02 -3.48970724e-07
  9.01862563e+00  7.02658832e-07  5.57508775e-02  3.48970724e-07
  1.55795510e+01  3.45142135e+00  1.55872297e+01  3.01172820e-01
  2.67079190e-07  4.68861137e-08  2.68208936e-07  1.60725848e-08
 -2.73932462e-01 -2.28358077e-02 -2.77547817e-01  1.01586369e-01
  3.68894215e-08  8.68359540e-09  3.72210883e-08  4.68676499e-09
  5.05379140e-06  4.51533747e-02 -1.05696720e-02  3.50557165e-05
 -4.38525531e-01 -1.65784156e-02 -1.14223329e+01 -5.99834412e-04
  6.29362794e-07  7.48303055e-02 -1.61832313e-02  6.67873071e-05
 -2.70623800e-02 -3.07479180e-02 -1.39701399e+00 -9.71125241e-05
  4.65917936e+00  2.26309491e-01  6.00746303e-01  4.77608709e-01
 -7.75081866e-02 -3.96535929e-01 -5.41953146e-01 -3.68092118e-01
  3.91481885e+00  1.32551550e-01  2.02782158e+00  2.53543332e-01
  2.81505237e-03  7.03334087e-05  4.50751516e-04  2.77274239e-04
  8.74328146e-02 -2.45794212e-01 -4.78519997e-01  2.99357465e+00
 -3.83266185e+00  6.29124736e+00 -1.39641019e+00  7.68420987e+00
  3.30628541e+01]
supnorm grad right now is: 33.062854097882564
Weights right now are: 
[  0.84180916   0.21106316  -3.78417062   0.76892364  -1.6320284
  -0.19659952   4.35547667   0.64615941  -0.12431314   6.02672481
  -0.15477689   6.81194509   8.03253958   8.3046764    8.21911824
   9.9647814    2.66724158  -0.70959529   3.9874596   -1.36069227
   8.4534129    8.29207349   8.59453561   9.74215263 -15.29302213
   5.71547862 -10.21943899   4.05306451  12.07274638  -1.43084703
   0.97186684   4.74863235 -20.64013674   4.72999295 -13.5823934
   1.69480277  10.55639082  -2.20218947   4.82687486   3.0816698
  -2.02958245  14.31776308  14.67279209  18.33581544  11.21268665
  -4.67583085   4.64152025  -2.02612238  -3.36599086   7.06026532
   2.87982884   5.71755557   9.03899731   1.98335048   4.70487358
   1.23900697  -4.1105199    2.93647962   5.64561542  -2.27506793
  -4.00927088  -4.05103335   3.93528072  -1.58585958  29.7785419 ]
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1823.0535801390504
gradient value of function right now is: [ 6.06516969e+00  6.91382411e-07  1.85958151e-01  3.12261765e-07
 -6.06516969e+00 -6.91382411e-07 -1.85958151e-01 -3.12261765e-07
 -6.60271150e+00 -3.89609245e-01 -6.60838470e+00 -4.19963329e-02
 -2.88167048e-07 -1.12984986e-08 -2.87828972e-07 -4.13152186e-09
  9.40884715e-01  6.31107485e-01  9.65181564e-01  5.69675737e-01
 -3.53174385e-08 -1.67284228e-09 -3.52195675e-08 -8.34630899e-10
 -3.31579318e-06  1.28203279e-02 -2.31026234e-02 -9.97924106e-06
  1.92918823e-01 -3.97783136e-03  1.65504728e+00  8.82197173e-05
  1.90502387e-07  2.15348079e-02 -2.76249346e-02 -1.41347249e-05
  1.19264673e-02 -7.98756679e-03  1.24260090e-01  8.92128888e-07
 -2.08426934e+00 -6.64169680e-02 -3.93870066e-01 -1.73170270e-01
 -1.05146698e-02 -1.32403247e-01 -1.45927337e-01 -1.27495491e-01
 -7.87502094e-01 -4.19300417e-02 -6.90567173e-01 -1.88435417e-01
 -4.50892778e-04  3.18490278e-05 -8.93104115e-05  8.24802471e-06
 -3.56980940e-01  8.31914237e-02  5.59233387e-01 -4.51827118e-01
  2.57242575e+00 -2.68427935e+00  1.62448842e+00 -1.45769289e+00
 -1.06163334e+01]
supnorm grad right now is: 10.616333371907004
Weights right now are: 
[  0.95469413   0.21719096  -3.88833751   0.76466444  -1.74491337
  -0.20272732   4.45964355   0.65041861  -0.33008603   6.12194595
  -0.3579757    7.06078825   8.02626177   8.30805554   8.21304242
   9.96855915   2.47642941  -0.85338281   3.80471275  -1.51190895
   8.45287444   8.29301431   8.59405945   9.74321086 -16.21331938
   5.54876451  -9.74394048   3.81342482  12.51610804  -0.98435923
   0.91909099   5.40291699 -21.1284905    4.56251538 -13.42889977
   1.38435138  10.53164749  -1.8667299    4.84865647   3.68872836
  -2.61081739  14.19239418  14.20797377  18.51444053  12.06753703
  -4.46761494   5.02465789  -1.80120115  -3.18543784   6.3072552
   3.26555434   5.4411063    9.01990939   2.5318831    4.88470106
   1.6785804   -4.10742048   2.46668466   5.47341037  -2.25726999
  -3.00345732  -5.07048902   3.23861296  -1.81233082  29.51785779]
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1824.924217892346
gradient value of function right now is: [ 8.23230206e-01  6.61963499e-07 -4.44497925e-01  4.79096413e-07
 -8.23230206e-01 -6.61963499e-07  4.44497925e-01 -4.79096413e-07
  1.58234526e+00  1.00827501e+00  1.60264063e+00  1.90437070e-01
 -1.69678031e-07 -5.93951240e-08 -1.78053629e-07 -8.21854374e-08
 -2.47846861e+00 -1.83931578e+00 -2.54798942e+00 -1.61581451e+00
 -2.51516228e-08 -2.04491370e-08 -2.77014349e-08 -2.56814135e-08
  1.52319030e-05 -6.12579739e-02  6.11073276e-02 -1.33702781e-05
 -1.49176001e-01  3.81249634e-02 -3.02600915e+00 -4.32107941e-04
  9.66266757e-07 -1.12751234e-01  8.07638022e-02 -3.09448273e-05
 -1.59726474e-02  6.29221827e-02 -7.01813547e-01 -7.09218095e-05
  1.54532382e+00  1.45438447e-01  3.24722049e-02  2.32322645e-01
  4.87951192e-02  5.72289055e-01  6.46398155e-01  6.03532725e-01
  3.70432954e+00  4.47298613e-01  2.55784910e+00  1.13498377e+00
  2.38427694e-03  3.40803356e-04  1.95543071e-04  4.95569117e-04
  3.11855997e-01 -1.19363357e+00 -5.24555659e-01  2.65813174e+00
 -3.69775449e-01  8.24843502e-01 -2.00166848e+00  3.82983678e+00
  8.13404456e+00]
supnorm grad right now is: 8.134044557687565
Weights right now are: 
[  0.95618878   0.23174481  -3.98033835   0.77429701  -1.74640802
  -0.21728117   4.55164439   0.64078603  -0.37108674   6.05035628
  -0.39208229   7.80947481   8.02276883   8.30762962   8.20914218
   9.96800108   2.16340308  -0.96441201   3.5292914   -1.6013564
   8.45258277   8.29289876   8.59366503   9.74307601 -16.08680557
   5.04110564  -9.67716193   4.30039752  11.64567652  -0.07949725
   1.2951275    5.44434511 -21.14386283   3.88684131 -13.97729414
   1.8030173   10.24174717  -0.99303837   4.79015488   3.7157343
  -1.71511449  13.56745262  15.39389329  18.76269671  12.08641667
  -3.96901147   5.61540788  -1.26953759  -3.00205251   5.6932893
   3.36864933   5.14113721   9.19602906   2.06787379   5.4852401
   1.42389455  -4.38276885   1.90218381   5.69753441  -1.81763294
  -3.4197357   -3.83066627   1.93612066  -1.61487578  29.39456859]
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1822.647418343758
gradient value of function right now is: [-7.84468903e+00 -1.33754036e-06 -1.52804161e-01 -6.67773287e-07
  7.84468903e+00  1.33754036e-06  1.52804161e-01  6.67773287e-07
  6.06763898e+00 -1.28568081e-01  6.06309786e+00 -2.69102077e-02
  4.38481553e-07  2.64383184e-08  4.40931817e-07  3.03219918e-08
 -3.80399033e-01 -4.24358828e-01 -4.12669049e-01 -4.55737381e-01
  2.19901768e-08  2.81004541e-09  2.22489863e-08  3.12490574e-09
 -9.68031499e-07  6.03842422e-02  1.48385401e-03  2.06755042e-05
  2.22401400e-02 -2.12300797e-02  3.23198779e-01  1.76206670e-05
 -1.48822100e-09  1.01932399e-01  4.81700364e-03  3.39793357e-05
  1.60833371e-03 -4.25219169e-02  7.49132882e-02 -1.30369013e-05
 -2.49596480e-01 -1.82867981e-02 -3.29167730e-02 -3.39049288e-02
 -9.86380754e-02 -5.81172503e-01 -7.02440170e-01 -6.15157833e-01
 -3.00541626e-01  1.80877072e-02 -1.28804004e-01 -7.09247906e-03
 -1.53527147e-04 -4.50560155e-05 -7.88607072e-05 -5.78459081e-05
  3.68897984e-01  1.34230095e+00 -1.55195729e-01 -8.14624494e-01
  1.79155966e-01 -2.70545795e-01  1.01047039e-01 -6.51307651e-01
  1.01867282e+01]
supnorm grad right now is: 10.186728234478613
Weights right now are: 
[  0.63569816   0.18699492  -3.84827184   0.72797216  -1.4259174
  -0.17253128   4.41957789   0.68711088  -0.1972856    5.72217597
  -0.22328662   7.24098431   8.025783     8.31798009   8.21283911
   9.98025546   2.63368417  -0.69494214   3.98363884  -1.41453741
   8.45323257   8.29558388   8.59449791   9.74625919 -16.08185123
   5.56118276  -9.80674092   4.42830171  12.8156638   -0.83238709
   1.61035811   5.78708871 -21.12447134   4.40995943 -14.05827152
   1.8092302   11.48142936  -1.72309801   5.36506146   3.8263793
  -2.79487003  12.28017305  14.93270772  17.66675341  12.07370848
  -4.32216426   5.07605147  -1.96611482  -3.33884129   6.37537942
   2.96875513   4.8694377    9.35289296   2.56897594   5.41684391
   1.21814301  -3.52999275   2.69958124   4.90602139  -2.90515129
  -2.8976293   -4.50980068   2.63736327  -2.45082711  29.80921476]
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1817.8748669343283
gradient value of function right now is: [ 7.32063063e+00  9.01867796e-07  6.75169863e-01  6.07641109e-07
 -7.32063063e+00 -9.01867796e-07 -6.75169863e-01 -6.07641109e-07
 -1.14046430e+01 -2.31677493e+00 -1.14421378e+01 -3.79827031e-01
 -2.00319303e-07 -1.01260644e-07 -2.02026206e-07 -9.47565575e-08
  2.49127449e+00  2.43215367e+00  2.53672854e+00  2.41157917e+00
 -9.78119519e-10 -7.23955097e-10 -9.91154493e-10 -7.48976333e-10
 -8.04169058e-06 -4.83123937e-02 -2.57310668e-02 -4.30669258e-05
  1.06537047e-01  1.22382083e-02  6.43274578e+00  9.39920131e-05
 -3.49218200e-07 -7.36006404e-02 -2.56057508e-02 -6.28072557e-05
  8.52185171e-03  2.90154174e-02  1.27631551e+00  3.36076115e-05
 -1.22737835e+00 -6.37210370e-02 -2.02410595e-01 -1.28307574e-01
  1.23134401e-01  4.29311571e-01  5.76907668e-01  4.54787683e-01
 -6.35925032e+00 -3.88729321e-01 -4.19235170e+00 -9.55061433e-01
 -4.06343799e-04  5.24826241e-05  4.80664922e-05  3.63814206e-05
 -1.02471115e+00 -7.06844531e-01  1.20940028e+00 -6.77683132e-01
  2.86360910e+00 -3.06469763e+00  2.65728130e+00 -2.23872851e+00
 -2.71796698e+01]
supnorm grad right now is: 27.179669775225825
Weights right now are: 
[  0.93264524   0.17551975  -3.7051846    0.70964435  -1.72286448
  -0.16105611   4.27649065   0.7054387   -0.36193549   5.75702126
  -0.38547681   7.60018029   8.02341879   8.32432254   8.21077192
   9.98718331   2.99251081  -0.42552269   4.3491048   -1.18430155
   8.45350584   8.29656186   8.59482972   9.74735498 -15.66552221
   5.70899916 -10.16319026   4.16022885  12.40922274  -0.33394986
   1.69799647   5.11007212 -21.12774402   4.54780347 -14.53658753
   1.53972857  10.91872967  -1.57589637   5.473911     4.10842936
  -2.15084587  13.26037976  15.88454925  18.35172397  13.32095248
  -4.42677374   5.1923631   -2.03060733  -3.27261668   7.01917357
   3.00533449   5.40864167  10.26781585   2.74539912   5.55893722
   1.44777976  -3.65390966   2.62778775   4.635204    -2.48908375
  -3.29701864  -4.09603315   2.44533984  -2.10168624  29.2833363 ]
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1825.3800685340386
gradient value of function right now is: [ 3.13864945e+00  1.09790514e-07 -3.96166257e-04  4.41788836e-08
 -3.13864945e+00 -1.09790514e-07  3.96166257e-04 -4.41788836e-08
 -5.53590097e+00 -1.41715349e+00 -5.56783982e+00 -2.67164410e-01
 -3.46845760e-08 -4.41266099e-09 -3.47881091e-08  1.50022716e-09
  2.99959270e-01 -4.26158971e-02  3.36939002e-01 -1.58621340e-01
  2.49404167e-09  2.30486821e-10  2.49900661e-09 -2.08303191e-10
 -2.54566634e-06 -6.10307653e-04 -3.01803867e-02  1.27403438e-05
  5.72371810e-02  5.14295898e-04  3.41257895e+00  7.84115012e-05
  4.25919978e-08 -6.15828771e-04 -2.74575146e-02  1.94193538e-05
  3.53451233e-03  5.78617538e-04  7.95292821e-01 -3.08383506e-06
 -6.65357649e-01 -4.50043369e-02 -1.01702205e-01 -7.91174699e-02
  4.63426391e-03  1.47680446e-03  1.51660631e-02  1.32439015e-02
 -4.49389667e+00 -1.47506536e-01 -3.69021793e+00 -7.30540586e-01
 -4.81139918e-04 -3.95945187e-05 -1.18179251e-04 -6.99457261e-05
 -6.65589776e-01 -1.78581447e-01  8.10446514e-01 -2.45752192e-01
  1.14572199e+00 -1.34577637e+00  2.02762354e+00 -5.19410062e-01
 -9.89811313e+00]
supnorm grad right now is: 9.898113126814545
Weights right now are: 
[  0.92687695   0.1543733   -4.30485128   0.68262802  -1.71709619
  -0.13990966   4.87615732   0.73245502  -0.36794842   5.82771191
  -0.39598292   7.25169093   8.02287852   8.32985937   8.21043349
   9.99393777   2.53477089  -0.91886522   3.91936824  -1.70613633
   8.45372422   8.29654397   8.59505387   9.74736259 -15.82664434
   5.68796469 -10.63241994   4.26081435  12.88838093  -0.78797111
   1.55423762   5.87502026 -21.16416429   4.58004738 -15.10512405
   1.61936354  11.82997675  -1.88285322   5.53881209   4.83696656
  -2.48422677  12.48048164  15.96849086  17.99333131  13.36690043
  -4.52443345   5.29975017  -1.9463084   -3.34782241   6.80487668
   3.1180758    4.89443927   9.53503745   2.16293418   5.65963898
   1.20638177  -4.78986478   2.15527544   5.86292354  -2.13870264
  -3.72643469  -4.0668941    3.05886136  -2.06092558  29.60738447]
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1821.1873183275554
gradient value of function right now is: [-3.13101011e-01  3.01976818e-07  6.88482067e-01  3.17978941e-07
  3.13101011e-01 -3.01976818e-07 -6.88482067e-01 -3.17978941e-07
  5.31108521e-02 -9.48862741e-02  5.78924237e-02  9.26237422e-03
 -9.62136400e-09 -6.70338059e-08 -1.14979951e-08 -6.94353862e-08
  2.40264861e+00  2.62108280e+00  2.43200049e+00  2.67294511e+00
  4.41202102e-09  1.25832804e-08  4.82279327e-09  1.35719416e-08
 -6.88116853e-07 -7.45284820e-02  1.49370558e-03 -4.75219825e-05
  9.94874935e-02  2.29096152e-02  5.99355013e-01  4.04608447e-05
  2.46874176e-08 -1.19886179e-01  3.24877953e-04 -7.30737289e-05
  7.04404885e-03  4.87714033e-02 -5.46079394e-03  2.73077119e-05
 -1.14791646e+00 -6.44437458e-02 -2.10205767e-01 -1.10195446e-01
  1.33714345e-01  7.14201263e-01  8.96611084e-01  8.48338414e-01
  7.57069504e-02 -3.78504197e-02  2.48041152e-01 -1.52000204e-02
 -1.62359150e-04 -2.87279523e-05 -4.49738431e-05 -3.92173505e-05
 -5.41319632e-01 -1.91484119e+00  4.16731976e-01  4.08276328e-01
  1.21821391e+00 -1.38955866e+00  4.33870727e-01 -1.05428428e+00
 -8.65981383e+00]
supnorm grad right now is: 8.65981382700646
Weights right now are: 
[ 8.35694685e-01  1.54139619e-01 -4.02445769e+00  6.75351401e-01
 -1.62591392e+00 -1.39675981e-01  4.59576374e+00  7.39731647e-01
 -7.20097039e-03  6.26505529e+00 -2.67871395e-02  7.97769559e+00
  8.02104578e+00  8.33234189e+00  8.20869267e+00  9.99666022e+00
  2.76452587e+00 -6.11842188e-01  4.15941043e+00 -1.38296249e+00
  8.45417876e+00  8.29617764e+00  8.59549492e+00  9.74695822e+00
 -1.61980942e+01  5.54791267e+00 -1.02446869e+01  3.29340566e+00
  1.36209379e+01 -4.63409062e-01  1.27135514e+00  5.83896776e+00
 -2.14368902e+01  4.45613725e+00 -1.52094776e+01  6.17768042e-01
  1.24552443e+01 -1.66547281e+00  5.36435821e+00  5.94032301e+00
 -3.20095475e+00  1.30710826e+01  1.54995722e+01  1.83519907e+01
  1.37620284e+01 -4.37961622e+00  5.64304356e+00 -1.79566086e+00
 -2.96546185e+00  5.77594266e+00  3.90029711e+00  5.15590230e+00
  9.98315154e+00  2.20444799e+00  6.02398330e+00  1.22277798e+00
 -4.50707459e+00  2.24591639e+00  5.70891410e+00 -2.23976148e+00
 -2.74588084e+00 -5.28580135e+00  2.44268030e+00 -2.66233858e+00
  2.94131856e+01]
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1822.7935237631896
gradient value of function right now is: [ 1.55235936e+00  5.59213959e-07  3.08783535e-01  2.79635106e-07
 -1.55235936e+00 -5.59213959e-07 -3.08783535e-01 -2.79635106e-07
  6.96867888e-01  1.41852703e+00  7.38774649e-01  2.09801934e-01
 -1.56055948e-07 -1.32424615e-08 -1.55041498e-07 -1.85267208e-08
  1.02197152e+00  1.23951319e+00  9.71360549e-01  1.35075397e+00
  1.74102737e-08  2.56652256e-09  1.72164038e-08  3.04373030e-09
  3.74781941e-06 -8.99158757e-03  3.81507704e-02 -5.52035333e-06
 -4.12713314e-02  1.18861156e-03 -3.63221955e+00 -9.04128702e-06
  2.45592616e-07 -8.96571042e-03  3.90522940e-02 -8.16635649e-06
 -2.14178291e-03  1.37904098e-03 -6.22612739e-01  1.04317693e-06
  5.01839923e-01 -2.98127510e-03  1.52671269e-01  8.64800434e-03
  8.64137292e-02  7.38296718e-02  1.56774036e-01  9.92560160e-02
  3.87223816e+00  1.05188349e-01  2.70431200e+00  4.21060961e-01
  6.00500422e-05  4.76453191e-06  2.23079770e-05  7.62791352e-06
  5.16879156e-02 -4.22065555e-01 -3.43706050e-01  1.83322583e-01
 -2.80183439e+00  3.73324276e+00 -1.47529372e+00  5.74972322e-01
  6.37973326e+00]
supnorm grad right now is: 6.379733259197325
Weights right now are: 
[  1.03645076   0.16219753  -4.06062107   0.67136293  -1.82667
  -0.14773389   4.63192712   0.74372012  -0.22666498   6.2857137
  -0.24894606   7.57902634   8.01616327   8.33495114   8.20394685
   9.99947874   2.81846866  -0.61616633   4.19662452  -1.40408122
   8.45484429   8.29570326   8.59613307   9.74642981 -15.92012991
   6.14288339  -9.68310968   3.43034624  12.74801205  -1.15504515
   1.11886033   5.1050144  -21.40785159   5.0721243  -14.80274654
   0.76283264  11.41489809  -2.34157188   5.66703119   5.96127635
  -1.93020805  13.31181131  17.61277422  19.09466402  13.49876443
  -5.04880937   5.16716779  -2.31061864  -2.86631596   7.13972745
   3.92911593   5.74207568  10.76902849   2.43444199   6.81674223
   1.6939201   -3.9412566    2.52955831   4.54667397  -2.40957921
  -4.33504995  -3.4805939    2.02188068  -2.22422065  29.1288096 ]
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1820.8914106191025
gradient value of function right now is: [ 1.67096609e-01 -1.02820389e-07 -6.32699589e-01 -1.04473963e-07
 -1.67096609e-01  1.02820389e-07  6.32699589e-01  1.04473963e-07
  1.22034923e-01  1.88037887e-01  1.27975552e-01  4.34285699e-02
  4.19715660e-09  2.73132614e-08  4.92178119e-09  2.68692863e-08
 -2.41040231e+00 -2.50285848e+00 -2.46121810e+00 -2.49223665e+00
 -2.47374003e-09 -5.42738535e-09 -2.62502503e-09 -5.42644196e-09
  3.36348724e-06  4.51139389e-02  1.35463650e-02  1.68863502e-05
  1.80995551e-03 -1.85171208e-02 -4.41781207e-01 -7.59740718e-06
  2.04550950e-07  7.23537813e-02  2.01998703e-02  2.64804908e-05
 -4.89386947e-04 -3.36841212e-02 -1.77214873e-01 -1.23608736e-05
 -3.39944725e-02 -3.16947248e-03  1.09457914e-02 -6.15834581e-03
 -2.56610863e-01 -3.98879264e-01 -7.58546103e-01 -4.65471347e-01
  1.05627115e+00  8.76941347e-02  7.36542226e-01  2.01026468e-01
  4.28866995e-06 -2.54876719e-06 -4.14307487e-06 -3.28030993e-06
  9.96096724e-01  1.27355581e+00 -7.60183253e-01 -8.51533332e-01
 -4.44001998e-01  6.24069518e-01 -7.98199777e-01 -5.42016003e-01
  6.36099199e+00]
supnorm grad right now is: 6.360991986825877
Weights right now are: 
[  0.80759067   0.16377889  -4.37422675   0.66833013  -1.59780991
  -0.14931525   4.9455328    0.74675291  -0.12542072   6.21209208
  -0.13515798   8.8926977    8.01523125   8.33660708   8.20297537
  10.00128291   2.50724117  -0.92166976   3.87511777  -1.68921883
   8.45524292   8.29539009   8.59654199   9.74609749 -16.58584181
   7.23309471  -9.26821767   4.05013673  12.76217319  -2.09891252
   1.6350827    4.79797862 -21.74238073   6.09848089 -15.13005083
   1.55454125  12.03324209  -3.27533926   5.16578116   5.68661257
  -1.92394705  13.47096334  17.70111172  19.15689261  11.90568906
  -6.10784476   4.05878125  -3.34282218  -2.31903384   6.76523123
   4.37399109   5.43469885  11.23134349   2.37947286   5.95389936
   1.67749856  -3.02863649   3.42378145   4.28322663  -2.83669504
  -4.21506847  -3.68091276   2.25034952  -1.94363902  28.5626098 ]
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1823.1165532153095
gradient value of function right now is: [-5.57528574e+00 -1.10756656e-06 -4.86119810e-01 -5.39909159e-07
  5.57528574e+00  1.10756656e-06  4.86119810e-01  5.39909159e-07
  5.43647952e+00  8.08478635e-02  5.44099580e+00  2.33594716e-02
  3.28151392e-07  2.54356748e-08  3.29528665e-07  2.55927818e-08
 -2.05999378e+00 -1.81722492e+00 -2.12357284e+00 -1.79322203e+00
 -3.36658580e-08 -4.66889009e-09 -3.39408644e-08 -4.77414502e-09
  2.37637694e-06  1.85941409e-02  2.07170371e-02  1.42861429e-06
 -1.74780845e-03 -6.99510361e-03 -1.75635332e-01 -1.22400266e-06
  4.80056413e-07  3.29204753e-02  3.26130523e-02  2.29759958e-06
 -5.17512782e-04 -1.47029549e-02 -9.55977718e-02 -1.38175643e-06
  7.10068608e-03  2.45017792e-03 -2.89217956e-03  2.13959744e-03
 -4.37674393e-02 -1.76152787e-01 -2.54288800e-01 -2.06302908e-01
  1.02480717e+00  1.13649753e-01  8.62633873e-01  2.57935728e-01
  7.39707614e-06  2.33540471e-06  3.42707955e-06  2.97276473e-06
  2.75175456e-01  4.28786305e-01 -3.40672257e-01 -3.15027033e-01
 -2.69234032e-01  2.33284009e-01 -5.90877630e-01 -2.62433592e-01
  6.30587687e+00]
supnorm grad right now is: 6.305876866437043
Weights right now are: 
[ 5.68020194e-01  1.67812527e-01 -4.20676106e+00  6.71094848e-01
 -1.35823943e+00 -1.53348889e-01  4.77806711e+00  7.43988199e-01
 -1.41980728e-02  5.92903521e+00 -1.49883554e-02  9.30789372e+00
  8.01528251e+00  8.33713676e+00  8.20289381e+00  1.00017872e+01
  2.41845020e+00 -8.07277015e-01  3.80704799e+00 -1.53373183e+00
  8.45557174e+00  8.29552179e+00  8.59690341e+00  9.74626082e+00
 -1.59268257e+01  6.51879544e+00 -9.14085080e+00  3.12485906e+00
  1.31101492e+01 -7.67611968e-01  2.22565830e+00  5.23095388e+00
 -2.17220991e+01  5.22608658e+00 -1.54171825e+01  4.71578046e-01
  1.22925297e+01 -2.01404722e+00  5.55955236e+00  6.56626965e+00
 -2.14089369e+00  1.39825702e+01  1.76956271e+01  1.91842176e+01
  1.29390478e+01 -5.40096732e+00  4.89886642e+00 -2.73424022e+00
 -2.46215773e+00  6.98731500e+00  4.55061140e+00  5.60153660e+00
  1.13578575e+01  3.11567689e+00  6.86502862e+00  2.52906318e+00
 -3.83925937e+00  3.03605401e+00  5.00297201e+00 -2.33256929e+00
 -4.01126395e+00 -4.19856332e+00  2.63342130e+00 -2.15649298e+00
  2.89336861e+01]
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1802.6471543816622
gradient value of function right now is: [-1.18663082e+01 -1.20299625e-06  2.61353860e-02 -4.34047742e-07
  1.18663082e+01  1.20299625e-06 -2.61353860e-02  4.34047742e-07
  1.68927359e+01  2.41700395e+00  1.69477667e+01  4.61076374e-01
  1.84660659e-07  4.08928501e-09  1.84828019e-07 -1.05960491e-08
 -5.99541356e-01  2.73761064e-01 -6.45497309e-01  4.92848338e-01
 -1.71001498e-07  9.41614670e-09 -1.70893875e-07  2.87642801e-08
  5.93666647e-06 -1.37915538e-02  3.47577657e-02 -9.38429318e-07
 -1.92312807e-01  5.02434560e-03 -7.65083584e+00 -1.61104469e-05
  1.24675776e-07 -2.08786062e-02  1.94856944e-02 -1.53468292e-06
 -2.36910873e-02  9.66004721e-03 -2.10134344e+00 -3.08291170e-06
  2.47864048e+00  1.73390193e-01  4.10833706e-01  2.29703693e-01
  4.29659480e-02  1.23428673e-01  1.91700619e-01  1.44149107e-01
  9.36348954e+00  4.44259046e-01  6.01562237e+00  7.19056482e-01
  9.31966960e-05  1.25054455e-05  1.37171295e-05  1.49523035e-05
  3.80104130e-01 -1.47756570e+00 -6.37157883e-01  2.59178710e+00
 -5.81014508e+00  7.32751625e+00 -1.49854375e+00  3.91859398e+00
  5.32377971e+01]
supnorm grad right now is: 53.2377970756934
Weights right now are: 
[  0.74388278   0.07834751  -4.13884031   0.55584824  -1.53410201
  -0.06388387   4.71014636   0.85923481  -0.10316502   6.50098584
  -0.0997761    9.82578145   8.01060973   8.35066064   8.19916145
  10.02166349   2.62824771  -0.67536702   4.11233992  -1.43559464
   8.45480623   8.28761861   8.59529399   9.73561541 -14.77800034
   5.78315521 -10.38167181   3.17163193  13.96307762   0.05595268
   1.80445635   5.04810058 -21.69363369   4.53620197 -17.1665446
   0.53158474  12.62543807  -1.36237586   5.28114789   6.4464348
  -2.71333667  12.48790617  18.55555069  17.95248526  14.08988177
  -4.51774002   5.74835043  -1.94829273  -3.02148828   5.44162811
   3.66688776   4.11056436  12.18043072   3.19303682   7.10794504
   2.61875482  -4.33004173   2.1451073    5.85879066  -1.86494758
  -4.07924448  -4.13181599   3.7539516   -1.86213116  30.05082426]
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1823.9247941798321
gradient value of function right now is: [-1.53041144e-01 -2.00244988e-07 -4.64163941e-01 -9.43163368e-08
  1.53041144e-01  2.00244988e-07  4.64163941e-01  9.43163368e-08
 -1.44790297e+00 -9.53306551e-01 -1.47907356e+00 -1.99650351e-01
  2.13672221e-08  1.60719477e-09  2.12441511e-08  2.11054551e-09
 -1.26963713e+00 -1.86209027e+00 -1.24009640e+00 -2.11642403e+00
 -3.29427658e-08 -3.70094632e-09 -3.25525486e-08 -3.65837873e-09
  2.73166684e-07  2.95262294e-03 -2.75968038e-02  1.68814573e-06
 -4.93419405e-02 -6.69087079e-04  1.91692904e+00  4.23283486e-06
 -7.83078342e-10  4.30196832e-03  5.43002934e-04  2.90465223e-06
 -1.70105818e-03 -1.31260263e-03  7.34127756e-01 -6.53441423e-07
  4.95688570e-01  1.31385118e-02  5.24947681e-02  2.00088634e-02
 -1.01265105e-02 -2.97548314e-02 -4.24212426e-02 -3.54392376e-02
 -4.15142101e+00 -3.84831840e-02 -3.40254105e+00 -4.17726910e-01
 -2.25074255e-05 -1.55038554e-06 -1.05929415e-06 -2.35333970e-06
 -5.85294370e-01  4.66993660e-01  3.29531022e-01 -3.08545502e-01
  1.73060886e-01  3.85925575e-01  1.07791498e+00  1.24283583e-01
 -5.50678820e+00]
supnorm grad right now is: 5.506788202520405
Weights right now are: 
[  0.88277988   0.06498792  -4.76239929   0.52500916  -1.67299911
  -0.05052428   5.33370534   0.89007389  -0.2419456    6.3366104
  -0.24349572   8.94255863   8.00857469   8.35380205   8.19734907
  10.02554314   2.16931428  -1.30055823   3.7095362   -2.11691036
   8.45645781   8.28113071   8.59641517   9.72746012 -14.51344
   5.48052118 -10.96999807   3.27183318  12.67167282  -0.07357554
   1.61547797   5.01491176 -21.71000393   4.31820091 -17.61914832
   0.70289377  11.29080176  -1.42275637   5.88890326   6.55948985
  -1.38690948  13.32261393  19.62444263  19.47562567  14.72196139
  -4.16359646   6.12237763  -1.6280638   -3.53294136   4.54658438
   3.52604486   3.91250392  11.99766896   2.82754539   7.10803826
   2.25710168  -3.99258647   2.11687898   5.24671479  -2.17956897
  -4.19369218  -4.05582666   3.03462996  -2.13250595  29.2697552 ]
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1815.7735115133257
gradient value of function right now is: [ 1.02341740e+01  5.88785678e-07  3.02116194e-01  2.88211924e-07
 -1.02341740e+01 -5.88785678e-07 -3.02116194e-01 -2.88211924e-07
 -1.61670938e+01 -3.21154667e+00 -1.62377645e+01 -7.02855879e-01
 -5.35882716e-08 -1.06081630e-08 -5.38411980e-08 -5.71298045e-09
  1.49742015e+00  1.22140625e+00  1.56188577e+00  1.15468334e+00
  9.98868379e-08  2.45169952e-08  1.00473010e-07  1.56928103e-08
 -1.53664175e-06 -1.36762934e-02 -4.33892245e-02 -6.11747117e-07
  1.36171070e-02  2.87730244e-03  8.82969072e+00  6.05598336e-06
 -8.59624055e-09 -2.00109066e-02 -3.35629812e-02 -9.15585205e-07
  1.66631303e-03  6.28171601e-03  3.01110252e+00  1.74117159e-06
 -1.95854126e-01 -1.72604702e-02 -3.46199137e-02 -3.13420963e-02
  6.37878405e-02  1.28780935e-01  2.22274570e-01  1.34832439e-01
 -1.53829200e+01 -9.61376636e-01 -1.23499840e+01 -1.92103615e+00
 -3.20565964e-05 -5.24063956e-06 -6.75749976e-06 -7.67937067e-06
 -1.87665774e+00 -1.83189896e-01  1.65363598e+00 -6.32975720e-01
  2.90580235e+00 -2.65745140e+00  3.16911219e+00 -1.25411865e+00
 -2.62879750e+01]
supnorm grad right now is: 26.28797497664265
Weights right now are: 
[  1.05285481   0.0569606   -4.26048666   0.51102663  -1.84307404
  -0.04249696   4.8317927    0.90405642  -0.5667337    6.27400811
  -0.56476923   9.66751325   8.00843679   8.35493686   8.19726489
  10.02691011   2.89163776  -0.69129238   4.41581689  -1.53796023
   8.4566061    8.2775795    8.59638539   9.72322785 -14.50908866
   6.72941104 -11.01125269   3.21687665  13.73120291  -1.23342156
   2.23585473   4.65788354 -21.70996959   5.58034971 -18.17995041
   0.62038877  11.55589613  -2.66711283   5.61655955   6.5374099
  -2.13673472  13.39363549  19.38610937  19.12822483  13.42403663
  -5.57492621   4.96374047  -2.82625456  -3.42398821   5.17108451
   3.35457073   4.28234771  12.80165132   3.22373848   7.39745737
   2.70334651  -4.27213857   2.32193058   5.4873132   -1.93936587
  -4.60899177  -4.0963301    3.58948987  -1.51237586  29.71277738]
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1819.146922024553
gradient value of function right now is: [-2.81640092e+00 -1.71346141e-07  9.36992613e-01  5.87670709e-08
  2.81640092e+00  1.71346141e-07 -9.36992613e-01 -5.87670709e-08
  3.39142985e+00  1.02474747e-01  3.39810987e+00  3.11016566e-02
  3.98888576e-08 -1.94647477e-08  3.97777513e-08 -2.00277047e-08
  3.44652464e+00  3.71539750e+00  3.47422145e+00  3.76488990e+00
 -3.40079695e-08  5.45651652e-08 -3.37249254e-08  5.59161906e-08
  2.88855835e-05 -5.40334024e-02  1.03080194e-03 -3.74362669e-06
 -1.47638219e-02  1.64051920e-02 -2.33666084e-01  6.19891644e-07
  1.14185026e-06 -8.28617005e-02 -3.34668686e-03 -5.77782489e-06
 -8.10338236e-03  3.12872721e-02 -1.27951903e-01  1.87489689e-06
  2.56015346e-01  2.95608418e-02  1.13021412e-02  4.42022880e-02
  1.89558530e-01  4.03784557e-01  8.43267238e-01  5.05168988e-01
  5.38881860e-01 -1.37343534e-03  7.82238755e-02  2.99152242e-03
  2.37307673e-06  1.42865608e-07 -5.58805749e-09  2.36500057e-07
 -8.50421376e-01 -1.77176378e+00  5.32768432e-01  1.60011651e+00
 -2.51681151e-01  3.85485319e-01  2.21829698e-01  1.52279656e+00
 -9.51730487e+00]
supnorm grad right now is: 9.517304868769227
Weights right now are: 
[  0.67289878   0.06328715  -4.12029508   0.51346426  -1.46311801
  -0.04882351   4.69160112   0.90161879   0.07199039   6.95569715
   0.07239594   9.93982652   8.00832316   8.35516234   8.19715964
  10.0270972    2.64936706  -0.66037603   4.07444542  -1.43354709
   8.45761695   8.27734744   8.59739747   9.72311926 -14.00236288
   6.72970563  -8.8744324    3.35416142  14.22048608  -0.83572789
   1.55848311   4.51661043 -21.60502202   5.49569148 -16.4604715
   0.815085    11.56472393  -2.35784996   4.95858101   6.43601862
  -2.45495301  13.73930616  19.69185023  19.00800575  13.6728873
  -5.43073623   4.61264029  -2.69841366  -1.71080547   6.74997989
   4.74338582   5.91631284  13.27446839   3.31968921   7.49685386
   2.85146453  -3.082495     2.97101043   4.21298958  -1.97904849
  -5.00303178  -4.13240716   2.47097989  -1.57672815  28.20332889]
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1823.3824145614565
gradient value of function right now is: [-2.36500318e+00 -4.96546834e-07 -1.70792392e-02 -2.78457549e-07
  2.36500318e+00  4.96546834e-07  1.70792392e-02  2.78457549e-07
  2.07422586e+00 -3.18727737e-03  2.07710975e+00  6.64478008e-03
  1.92811842e-08  2.27724854e-09  1.94389469e-08  2.86823717e-09
  2.42971906e-01  4.26418922e-02  2.66052169e-01 -1.96535060e-02
 -8.83950427e-08 -2.60843409e-08 -9.02074872e-08 -3.14520719e-08
 -5.70751659e-06  4.64381461e-02 -1.71337312e-02  1.78497125e-06
  1.87998956e-02 -1.54305636e-02  1.10442016e-01 -1.30596011e-07
  1.21871730e-07  7.78794788e-02 -1.95521919e-02  2.92271283e-06
  3.38718718e-03 -3.34611125e-02 -6.29532864e-03 -1.11888642e-06
 -2.69814766e-01 -1.72387962e-02 -2.80888028e-02 -2.94905747e-02
 -1.33954375e-01 -4.43628548e-01 -7.51963128e-01 -4.08337693e-01
 -3.82952739e-01 -2.09949950e-02 -3.22085858e-01 -4.31137285e-02
 -2.36046516e-06  3.11501803e-07  6.73706728e-07  1.31848954e-07
  7.40682325e-01  1.44940906e+00 -4.61218743e-01 -1.26098538e+00
  3.05547235e-02 -2.62624991e-01 -8.97210965e-02 -1.02758325e+00
  6.89451123e-01]
supnorm grad right now is: 2.365003176981128
Weights right now are: 
[ 6.62694119e-01  3.03946838e-02 -4.25521622e+00  4.74927976e-01
 -1.45291336e+00 -1.59310458e-02  4.82652227e+00  9.40155072e-01
 -1.42896292e-01  6.36141788e+00 -1.37011123e-01  9.70124129e+00
  8.00897994e+00  8.35728944e+00  8.19797267e+00  1.00297132e+01
  2.65789534e+00 -7.20527290e-01  4.11978795e+00 -1.53108199e+00
  8.45542819e+00  8.26913630e+00  8.59454205e+00  9.71316117e+00
 -1.37570561e+01  7.21786451e+00 -9.18522949e+00  3.54398395e+00
  1.39999848e+01 -7.76958013e-01  2.31479264e+00  4.55877385e+00
 -2.16510472e+01  5.98622079e+00 -1.71702490e+01  1.11511521e+00
  1.20346626e+01 -2.56913670e+00  5.71274609e+00  6.41016442e+00
 -2.35297556e+00  1.34379388e+01  2.03557779e+01  1.85064171e+01
  1.40252296e+01 -5.67133536e+00  4.29985461e+00 -3.09787088e+00
 -2.52169340e+00  7.42848234e+00  4.18214062e+00  6.08336782e+00
  1.27865532e+01  3.02118499e+00  7.27989405e+00  2.52818447e+00
 -2.57511475e+00  3.27844724e+00  3.52962437e+00 -2.51472709e+00
 -4.73683434e+00 -4.40559866e+00  2.87434662e+00 -1.89965963e+00
  2.88656640e+01]
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1809.859713175656
gradient value of function right now is: [ 4.78332838e+00  5.54327385e-06  1.14681188e+00  6.25854065e-06
 -4.78332838e+00 -5.54327385e-06 -1.14681188e+00 -6.25854065e-06
 -5.99993021e+00 -9.64963985e-01 -6.05089384e+00 -1.96293256e-01
 -4.82993923e-08 -1.15188697e-07 -5.42571654e-08 -1.89696436e-07
  3.86368552e+00  4.00900606e+00  4.01065055e+00  4.11339377e+00
  3.03489962e-07  1.12591556e-06  3.61574196e-07  1.94586731e-06
 -1.57485142e-05 -1.30418896e-01 -4.10716238e-02 -1.55035395e-04
  1.04861785e-02  2.08707071e-02  2.49529882e+00  1.94009049e-05
 -1.67337606e-07 -2.16878903e-01 -4.26938181e-02 -2.39465480e-04
  1.44447095e-03  8.15404106e-02  5.97799901e-01  6.36858472e-05
 -1.57935341e-01 -7.05156637e-03 -3.99148287e-02 -1.08090275e-02
  1.78308383e-01  1.19920063e+00  1.66361935e+00  1.05573363e+00
 -4.87872178e+00 -4.34592967e-01 -2.45868760e+00 -6.38161457e-01
  7.88416290e-05  3.67034193e-04  6.24512637e-04  3.16892610e-04
 -1.14717339e+00 -2.52768285e+00  1.51820900e+00  1.08084912e+00
  2.08117192e+00 -2.80357409e+00  1.50185187e+00 -4.76002513e-02
 -2.89878055e+01]
supnorm grad right now is: 28.987805490652946
Weights right now are: 
[ 8.40654787e-01  3.87531496e-02 -3.69037674e+00  4.69250279e-01
 -1.63087402e+00 -2.42895116e-02  4.26168279e+00  9.45832769e-01
 -4.39334907e-01  5.75239256e+00 -4.41628236e-01  8.63833777e+00
  8.00850954e+00  8.35819648e+00  8.19744835e+00  1.00323602e+01
  2.96700150e+00 -2.49177418e-01  4.43623052e+00 -1.02211381e+00
  8.45954013e+00  8.27100671e+00  8.59930659e+00  9.71003648e+00
 -1.36467458e+01  6.37904657e+00 -8.93244855e+00  4.09159294e+00
  1.33374601e+01  8.26534833e-01  2.65020714e+00  4.91615215e+00
 -2.20958249e+01  4.98264544e+00 -1.70146322e+01  2.01558526e+00
  1.17070517e+01 -1.07078937e+00  6.46300672e+00  6.40761470e+00
 -1.49973215e+00  1.42278325e+01  2.12399511e+01  1.91710975e+01
  1.50814738e+01 -4.57655816e+00  5.31369700e+00 -2.14607995e+00
 -2.76884347e+00  7.20505947e+00  4.12883737e+00  5.67481975e+00
  1.32803314e+01  2.32269093e+00  5.53502797e+00  1.69237926e+00
 -3.42062974e+00  2.60763074e+00  4.38841326e+00 -1.84636633e+00
 -4.69958392e+00 -4.47381261e+00  3.61345929e+00 -1.33439704e+00
  2.87855100e+01]
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1823.7948589630926
gradient value of function right now is: [ 4.74342448e-01  1.35221535e-06  4.51679029e-01  3.05285762e-06
 -4.74342448e-01 -1.35221535e-06 -4.51679029e-01 -3.05285762e-06
 -1.06474571e+00 -2.42686268e-01 -1.07274018e+00 -3.93029228e-02
  1.93544130e-08  7.53805234e-07 -7.01747413e-08  2.35017963e-06
  2.07867910e+00  1.84502702e+00  2.16480799e+00  1.78017626e+00
 -8.77686351e-08  2.27466132e-06 -3.10217836e-07  7.16193911e-06
 -3.73688777e-06  1.18572302e-02 -3.48341410e-02 -1.11967839e-03
  3.74873719e-02 -2.46061520e-03  9.14694962e-01  4.71069818e-04
 -1.69354439e-08  2.69977146e-02 -4.08427567e-02  5.69390113e-05
  3.86424399e-03 -5.82896365e-03  1.55818480e-01  1.01626143e-03
 -5.09271817e-01 -3.01734034e-02 -5.09889880e-02 -4.53714712e-02
  3.42596146e-03 -1.38829055e-01 -1.83375463e-01 -1.16507993e-01
 -1.57959580e+00 -2.44089331e-01 -1.11772278e+00 -2.87390916e-01
  1.45901777e-02 -8.03877953e-03  5.61628345e-03 -6.11506559e-03
 -3.29203686e-01  2.02626865e-01  5.08210167e-01 -7.55261617e-01
  4.17859945e-01 -1.00605479e+00  5.51394791e-01 -9.42183915e-01
 -1.08907988e+01]
supnorm grad right now is: 10.890798776830358
Weights right now are: 
[  0.77013441  -1.11698368  -4.08609366  -0.8247193   -1.56035365
   1.13144731   4.65739971   2.23980235  -0.20024251   6.63429235
  -0.19443612   9.23616333   8.02369384   8.20414715   8.21959343
   9.67543347   2.7365868   -0.62720123   4.306506    -1.48485273
   8.49022077   7.78820808   8.64654063   8.76873076 -13.38562399
   7.03018573 -10.00607513   6.96362388  14.13600031   0.22665462
   2.06573378   2.82411422 -22.2900011    5.42269518 -18.57863252
   4.75911633  11.79122967  -1.80045486   5.79174538   3.75340038
  -1.88480057  14.6484251   21.95483365  18.99168029  14.95784505
  -4.99539485   4.68981395  -2.57062607  -2.76042479   7.05060526
   3.8141548    5.41103253  11.716933    -0.46862476   2.82541809
  -1.03820651  -2.88624274   3.44890842   4.03796649  -2.67885684
  -4.73872625  -4.45993521   3.70526179  -2.16854395  28.87402152]
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1825.1595519734335
gradient value of function right now is: [-6.76188592e-02 -2.37297986e-07  2.70209888e-01 -2.66255957e-07
  6.76188592e-02  2.37297986e-07 -2.70209888e-01  2.66255957e-07
 -4.01820058e-01 -1.78962803e-01 -4.06899293e-01 -2.50467578e-02
 -1.58288838e-07 -3.04545977e-07 -2.54730025e-07 -9.60426864e-08
  1.35440501e+00  1.18130763e+00  1.39219651e+00  1.12659367e+00
 -3.27051812e-07 -1.01108765e-06 -6.66680757e-07  2.77582419e-07
 -3.15950932e-06  1.88007971e-02 -1.88904494e-02  8.29322579e-04
  3.56610962e-02 -6.46946023e-03  6.67100806e-01 -4.91246937e-04
  4.31445427e-08  3.91058294e-02 -2.32113275e-02  3.38214189e-03
  2.68431531e-03 -1.65893484e-02  8.84120324e-02 -1.50463012e-03
 -4.79601877e-01 -3.55545343e-02 -4.53478041e-02 -4.54352549e-02
 -1.93402293e-02 -2.05021051e-01 -3.02341787e-01 -1.88288429e-01
 -9.24101542e-01 -1.61199580e-01 -7.05557575e-01 -1.78683955e-01
  9.40301981e-03 -1.64850552e-02 -1.15257815e-02 -1.45751734e-02
 -2.16049897e-01  3.07296813e-01  4.03892115e-01 -7.56020422e-01
  3.60978651e-01 -7.65497222e-01  4.70737168e-01 -8.03087872e-01
 -3.86293808e+00]
supnorm grad right now is: 3.8629380825266133
Weights right now are: 
[  0.69484938  -1.2917447   -4.06585839  -1.20057186  -1.48506862
   1.30620834   4.63716444   2.61565491  -0.12884971   6.97827359
  -0.12147232   9.30047511   8.05054206   8.08075428   8.25283919
   9.30906226   2.91354554  -0.5227409    4.47713062  -1.42281959
   8.49020351   7.47903851   8.68260609   7.77783072 -13.36684116
   7.92352154 -10.00407335   7.11049458  14.62605854  -0.44999561
   1.83904993   2.88506105 -22.38499103   6.18094001 -18.95823884
   4.85502953  12.40091431  -2.64364026   5.85853927   3.61561127
  -2.33090411  15.26786854  21.46945669  18.88730948  14.67121154
  -5.74103378   3.84925922  -3.3142994   -2.57035163   7.87123051
   3.5614142    6.30912531  11.9722019   -0.58388289   2.7884958
  -1.31290056  -2.20730239   3.96819333   3.41508657  -2.89626318
  -4.11506954  -5.23666327   3.33110497  -2.4869031   28.91882661]
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1821.2995934397009
gradient value of function right now is: [ 1.04539759e-01 -4.05598518e-07  5.20136841e-03 -8.23005162e-07
 -1.04539759e-01  4.05598518e-07 -5.20136841e-03  8.23005162e-07
 -5.22426501e-01 -1.62810683e-01 -5.30172256e-01 -2.71403048e-02
 -3.21634282e-07 -4.86313851e-07 -3.90873864e-07 -4.56164058e-07
  5.30813180e-01  1.71468124e-01  5.61077968e-01  7.09561867e-02
 -9.77508512e-07 -1.83703709e-06 -1.28182199e-06 -1.21924107e-06
 -1.06096041e-05  5.18418382e-02 -2.78653548e-02  9.50182225e-03
  5.03763279e-02 -1.68255530e-02  6.10075212e-01 -2.49760431e-03
  4.28472512e-08  9.24446244e-02 -2.78303641e-02  1.67471607e-02
  5.43093735e-03 -3.88668805e-02  1.01897191e-01 -6.25342067e-03
 -6.89671984e-01 -3.70723296e-02 -8.46602638e-02 -4.81499032e-02
 -1.66954139e-01 -4.99877339e-01 -9.06947796e-01 -4.65724886e-01
 -1.21768568e+00 -9.47163782e-02 -8.84881589e-01 -1.12473326e-01
 -1.73804151e-02 -6.17908798e-02 -1.15166721e-01 -5.73127366e-02
  8.84025431e-01  1.64048356e+00 -2.41296456e-01 -1.51831373e+00
  9.09249598e-01 -1.35307372e+00  1.00607765e-01 -1.31888687e+00
 -2.18691026e+00]
supnorm grad right now is: 2.186910256741862
Weights right now are: 
[  0.34855313  -1.32728776  -4.68687027  -1.35375912  -1.13877237
   1.3417514    5.25817632   2.76884217   0.18407099   6.80190852
   0.19551027   9.61658609   8.03674897   8.04431832   8.2410102
   9.23027193   2.29942222  -1.08197348   3.77950501  -1.96080601
   8.42097919   7.27786408   8.63462501   7.28823602 -12.22859973
   9.20996961  -7.95504085   7.85979242  14.11633186  -1.89962935
   2.13662223   1.28796475 -21.25594124   7.32231443 -17.51384995
   5.55802973  12.2358381   -3.87406396   5.91946332   2.44592634
  -2.08324881  15.2786831   21.63914943  18.75461158  12.70626948
  -6.9562095    2.50702355  -4.62376745  -1.91456697   8.40460566
   4.25225331   6.77456367  10.61601012  -1.13548116   2.1247197
  -1.91590114  -0.87375773   4.91157461   2.38684154  -3.63446226
  -4.67500036  -5.19853685   2.34684365  -3.14610601  28.16556785]
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1819.359181115026
gradient value of function right now is: [-2.43021496e-01 -4.02443444e-07 -4.43444018e-02 -8.63220003e-07
  2.43021496e-01  4.02443444e-07  4.43444018e-02  8.63220003e-07
  1.99736355e-03 -7.68966444e-02 -1.84972728e-03 -1.37070201e-02
 -4.33543621e-07 -4.57464728e-07 -4.89090571e-07 -4.29214741e-07
  3.44927110e-01 -3.15613717e-02  4.22493205e-01 -1.39112103e-01
 -1.47683500e-06 -2.08606177e-06 -1.82339807e-06 -1.23109483e-06
 -1.84943596e-05  4.82504857e-02 -3.87047098e-02  8.47674245e-03
  4.86888452e-02 -1.64788718e-02  3.19081284e-01 -2.24233904e-03
 -6.15627395e-07  8.58166812e-02 -4.69460626e-02  1.48052593e-02
  7.65300247e-03 -3.68278272e-02  7.37021217e-02 -5.57709909e-03
 -6.66917241e-01 -3.12749413e-02 -7.19026353e-02 -4.22232244e-02
 -1.69433030e-01 -4.55755335e-01 -8.72766113e-01 -4.25801437e-01
 -1.43370153e+00 -7.95673654e-02 -1.14627327e+00 -1.00526373e-01
 -1.78230624e-02 -5.23518201e-02 -1.04451966e-01 -4.88608549e-02
  1.04013675e+00  1.53187901e+00 -3.18493175e-01 -1.41957941e+00
  9.11779428e-01 -1.29232006e+00  5.31140654e-02 -1.26554883e+00
 -1.75992898e+00]
supnorm grad right now is: 1.7599289844246313
Weights right now are: 
[ 9.52735755e-01 -1.97755655e+00 -3.88817858e+00 -4.23308549e+00
 -1.74295499e+00  1.99202019e+00  4.45948462e+00  5.64816854e+00
 -2.99273152e-01  7.01012181e+00 -2.89261030e-01  9.52202045e+00
  8.14923980e+00  7.50258761e+00  8.33087213e+00  7.92058262e+00
  2.72484124e+00 -4.49069520e-01  4.20697088e+00 -1.27486228e+00
  9.14765579e+00  4.96675492e+00  9.45704008e+00  3.60669783e+00
 -1.09272148e+01  7.15513403e+00 -7.55084230e+00  6.89556527e+00
  1.34740328e+01  5.48481850e-01  1.93688124e+00  2.42299327e+00
 -1.94958379e+01  5.07698196e+00 -1.75618158e+01  4.43843637e+00
  1.20232454e+01 -1.70571464e+00  5.65832689e+00  3.57136750e+00
 -1.81585702e+00  1.66396555e+01  2.11590042e+01  1.97860843e+01
  1.50698022e+01 -4.71714292e+00  4.67783224e+00 -2.38312591e+00
 -1.56161546e+00  7.64768819e+00  4.55744689e+00  6.15944233e+00
  1.19633798e+01 -2.42859134e-02  3.21958788e+00 -7.84058869e-01
 -2.45502561e+00  3.62809255e+00  3.59480439e+00 -2.61272689e+00
 -5.10109976e+00 -5.35863649e+00  3.37332197e+00 -2.26809721e+00
  2.83462462e+01]
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1820.9975474134915
gradient value of function right now is: [-8.25749224e-01 -5.54678655e-07  5.58412793e-02 -4.19335099e-06
  8.25749224e-01  5.54678655e-07 -5.58412793e-02  4.19335099e-06
  6.37063125e-01 -4.37130540e-02  6.35727068e-01 -5.83255072e-03
 -6.89962540e-07 -6.85436480e-07 -7.88421950e-07 -6.71007566e-07
  6.05859531e-01  3.38119456e-01  6.90092959e-01  2.49002425e-01
 -9.42918365e-06 -1.82620549e-05 -1.31884004e-05 -9.16962428e-06
 -1.71807741e-05  3.25209033e-02 -3.51408083e-02  3.64203451e-03
  4.15959087e-02 -1.09919933e-02  2.29144264e-01 -8.51025388e-04
 -2.51820984e-07  5.95364362e-02 -4.28510141e-02  6.52085236e-03
  5.87508972e-03 -2.58864364e-02  3.88300213e-02 -2.41222452e-03
 -5.57718719e-01 -2.79354819e-02 -5.56648618e-02 -3.62445933e-02
 -1.07828615e-01 -3.22060560e-01 -5.69055923e-01 -3.08066172e-01
 -1.15012129e+00 -7.44515575e-02 -9.79297723e-01 -9.16710687e-02
 -6.64607231e-03 -2.38806744e-02 -4.38062022e-02 -2.28847192e-02
  4.73698932e-01  9.67969332e-01 -2.05740193e-02 -1.02607983e+00
  5.41783380e-01 -9.01367410e-01  1.85883529e-01 -9.59861318e-01
 -2.08041772e+00]
supnorm grad right now is: 2.080417716767961
Weights right now are: 
[  0.77264527  -2.24531565  -4.53582546  -6.98798153  -1.5628645
   2.25977929   5.10713151   8.40306458  -0.15265707   6.58699818
  -0.15731917   8.03004923   8.16469202   7.17060865   8.37200831
   7.16880635   2.18426821  -1.10981724   3.7514003   -1.9936716
   7.45590485   2.17382535   7.66932752   0.81792072 -10.84231585
   7.15270218  -8.38317391   6.09132111  12.89986089   0.84970099
   1.62034204   3.32365352 -19.54042581   5.01752081 -18.17059205
   3.68726709  12.18417818  -1.55993801   6.7802263    4.24889252
  -1.12178545  16.99496195  23.17344805  19.6883869   14.97113842
  -4.96944117   4.85005601  -2.63864263  -2.55008666   7.75588578
   3.90163828   6.26739639  12.51041708   0.45232429   4.06932624
  -0.40957115  -3.91398318   2.94785914   4.657479    -2.30641892
  -5.95337396  -4.39231932   4.22055266  -2.55230892  28.72644401]
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1822.4585011958536
gradient value of function right now is: [-5.09962145e-01 -4.99422281e-07  2.41291518e-02 -9.34761103e-07
  5.09962145e-01  4.99422281e-07 -2.41291518e-02  9.34761103e-07
  3.19503507e-01 -5.08522888e-02  3.17695632e-01 -6.69596487e-03
 -6.88191642e-07 -8.17830555e-07 -8.54659276e-07 -4.77020442e-07
  4.38505753e-01  1.92839762e-01  5.16300569e-01  1.06068727e-01
 -3.17032346e-05 -2.86746282e-05 -4.58767012e-05  5.11205734e-05
 -1.89558858e-05  2.93636121e-02 -3.27155990e-02  2.77956270e-03
  4.30526381e-02 -1.05603739e-02  2.54885309e-01 -8.29660560e-04
 -1.26839714e-07  5.51962659e-02 -3.73900349e-02  5.11334435e-03
  4.98906767e-03 -2.43433216e-02  3.87378728e-02 -2.04290535e-03
 -5.59296242e-01 -3.02135847e-02 -5.10121095e-02 -3.54907699e-02
 -7.49589334e-02 -2.74089395e-01 -4.92045456e-01 -2.87895985e-01
 -1.08114930e+00 -5.18645073e-02 -8.87806039e-01 -6.80232419e-02
 -3.46230079e-03 -1.72423188e-02 -3.09378646e-02 -1.82883077e-02
  4.49443239e-01  9.74896200e-01 -1.00665618e-01 -1.15407943e+00
  4.42172836e-01 -8.36689398e-01  1.34967686e-01 -1.00490479e+00
 -3.18811341e+00]
supnorm grad right now is: 3.1881134055484956
Weights right now are: 
[  0.78167278  -2.09355923  -3.96663485  -6.28190389  -1.57189201
   2.10802287   4.5379409    7.69698694  -0.21350313   6.68692983
  -0.21835692   8.29841922   8.44132499   7.67831446   8.7915911
   7.44973617   2.53553008  -0.68899439   4.12709418  -1.53332555
   7.78160797   2.80059133   8.16691921   1.46068522 -10.74041564
   6.54541331  -8.52959536   5.88101843  13.46868486   2.28701528
   2.13120566   3.92222187 -19.57862217   4.14223982 -18.68336691
   3.33923865  12.27326103  -0.26001761   6.18926792   4.80343111
  -1.5071004   16.96730619  23.20383535  19.93935408  14.8284346
  -4.35191038   5.45511472  -1.87169908  -2.57230181   7.56413916
   3.75817552   6.15982087  12.28896153   0.5412619    4.26826245
  -0.09381147  -4.40858989   2.35077246   4.91372845  -1.85366424
  -5.26400199  -4.65653975   3.98742875  -2.51561586  28.88750127]
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1336.7590453519842
W_T_median: 1142.769643782311
W_T_pctile_5: 825.7752853320976
W_T_CVAR_5_pct: 753.1754348012212
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.8
F value: -1822.4585011958536
-----------------------------------------------
