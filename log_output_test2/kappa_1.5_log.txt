Starting at: 
2022-06-20 18:03:38
tracing parameter entered from terminal:  1.5


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[ 0.10347998  0.18844875 -0.3666709   0.62803316 -0.89369922 -0.17398511
  0.93797695  0.78704989 -0.60791207 -0.16293226 -0.31685198  0.28094308
  0.0404241   0.17453202  0.0940472   0.01169373  0.2300954  -0.23784803
  0.78511084 -0.41859022  0.4809118  -0.01155852  0.07219357 -0.14482284
  0.4701344  -0.18827011 -0.8138637  -0.24629474  0.28361272  0.33354483
 -0.63777411 -0.25343004 -0.81551088 -0.26234589  0.20198453 -0.15135741
  0.25264285 -0.29817275  0.41496663 -0.58895503 -0.60305385 -0.63454123
  0.3979274   0.74701442  0.57452389 -0.67377327  0.6493153   0.07340044
 -0.29694484  0.52758424 -0.14347696  0.04319718 -0.28527617 -0.63077443
  0.13133703 -0.58713125  0.12759166  0.87507529 -0.19770888 -0.66759109
  0.25529887 -0.48501395  0.58877641 -0.72315372] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1260.6521530687958
W_T_median: 1222.3920506735662
W_T_pctile_5: 834.1581876304141
W_T_CVAR_5_pct: 746.6575474940535
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2812.2731676058393
gradient value of function right now is: [ 5.53491317e-03  3.31076207e-02  4.10525029e-02  4.14927490e-02
 -5.53491317e-03 -3.31076207e-02 -4.10525029e-02 -4.14927490e-02
  8.40058121e-04  5.44708837e-03  2.22244933e-04  5.43437086e-03
  2.22178833e-03  1.47867460e-02  5.15824936e-04  1.47626328e-02
  7.54150744e-04  5.27377500e-03  1.27218284e-04  5.27187100e-03
  3.64926429e-04  2.44882814e-03  8.10198863e-05  2.44533925e-03
 -1.37262041e-05 -2.16244387e-04 -1.40283816e-04 -2.39693438e-04
 -1.61140273e-04  2.96553062e-04  7.18923571e-05  1.04163826e-04
  5.31596921e-05 -7.10867231e-04 -3.95218948e-04 -6.66345922e-04
 -1.96323029e-04  4.67577448e-04  1.52130292e-04  2.36501274e-04
 -1.91568563e-04  5.47725052e-05 -3.24957976e-05  6.01420517e-05
 -2.26989810e-04  2.13203866e-04  7.81894969e-05  2.31279728e-04
 -3.81971597e-04  4.42979989e-04  1.81961859e-04  4.66058297e-04
 -8.36481984e-04  3.72772922e-05 -2.89752439e-04  5.09296042e-05
 -1.01398596e-04 -4.49712125e-05  6.36799325e-05  9.91900222e-05
 -2.43695626e-05  2.64327433e-04  6.46510010e-05  7.10673192e-05
 -3.17907564e+00]
supnorm grad right now is: 3.1790756419814836
Weights right now are: 
[-9.53789008e-01 -9.97844073e-01 -1.95165688e+00 -9.43312547e-01
  1.63569772e-01  1.01230771e+00  2.52296292e+00  2.35839560e+00
  3.05569602e-01  6.73930828e-01  6.05511654e-01  1.12715669e+00
  4.80406858e-01 -5.95884264e-01  7.18531674e-01 -7.72100699e-01
 -9.04638732e-01 -1.57016607e+00 -2.99564537e-01 -1.77625542e+00
 -9.78655982e-01 -1.80614684e+00 -1.26809860e+00 -1.96784155e+00
  1.37034543e+00  7.32815939e-01  1.17417885e-01  7.10831670e-01
 -5.56690864e-01 -1.27701808e+00 -1.75273957e+00 -1.79311249e+00
  8.20913924e-02  8.34099634e-01  1.18497008e+00  9.71231928e-01
 -6.06690066e-01 -1.56309375e+00 -5.76011876e-01 -1.87761846e+00
  3.69942593e-01  2.47077663e-01  1.35044473e+00  1.64622910e+00
  2.04997382e+00 -1.54997469e+00 -1.30020367e-02 -9.61161144e-01
  1.13798560e+00  2.26017787e-01 -2.06134033e-01 -4.92554592e-01
  5.21830951e-01 -2.03900055e+00 -8.85857148e-01 -2.07045985e+00
  1.20464810e+00  2.53087145e+00  2.09887495e-01 -2.05800095e+00
 -1.93792823e-01 -2.64963682e-01 -2.43282741e-01 -2.28805616e+00
  2.47582221e+01]
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2812.686562940729
gradient value of function right now is: [ 1.66470653e-03  1.01922410e-02  1.08266585e-02  1.09292496e-02
 -1.66470653e-03 -1.01922410e-02 -1.08266585e-02 -1.09292496e-02
  2.23446261e-04  1.71596746e-03 -9.91899084e-06  1.71467306e-03
  1.95322687e-04  2.17128851e-03 -1.45779190e-04  2.18220118e-03
  1.18197651e-04  1.28187928e-03 -8.16375742e-05  1.28790626e-03
  5.91873881e-05  5.58354512e-04 -2.38182945e-05  5.59873389e-04
 -9.18877199e-06  5.77278588e-05  3.48515667e-05  5.39178591e-05
 -1.22090228e-04  5.25159081e-05 -2.62851824e-05 -3.16712069e-05
  3.25339387e-05 -1.10965214e-04 -5.92512334e-05 -9.47378732e-05
 -1.38614458e-04  9.29128765e-05 -7.03680695e-06 -7.00609042e-07
 -9.42588747e-05  1.06063629e-06 -2.04507275e-05  1.91052035e-06
 -1.22188491e-04  3.51561936e-05  3.77758164e-06  3.84574613e-05
 -1.97626766e-04  8.08697168e-05  2.55283646e-05  8.53047607e-05
 -3.96652080e-04  2.21269020e-06 -8.74001605e-05  6.01898790e-06
 -2.31417360e-05 -2.51805968e-05  1.20606018e-05  4.29007800e-05
 -6.26830953e-06  7.38813940e-05  1.44225924e-05  3.33483145e-05
 -4.56217824e-01]
supnorm grad right now is: 0.4562178243538034
Weights right now are: 
[-0.97233701 -1.15441939 -2.11992458 -1.1127057   0.18211777  1.16888302
  2.69123062  2.52778875  0.29346852  0.58313463  0.60402726  1.03797548
  0.42230387 -1.07003829  0.71916352 -1.24034162 -0.91073973 -1.62120595
 -0.29899246 -1.82613261 -0.99535661 -1.91702784 -1.26835428 -2.07363838
  1.37152705  0.73201797  0.11739773  0.7110798  -0.49934676 -1.32984291
 -1.75288326 -1.79259175  0.07732134  0.86752073  1.20242181  0.99010427
 -0.58324166 -1.59620243 -0.58199111 -1.88322489  0.47072651  0.23933079
  1.36849785  1.63570089  2.27407886 -1.6303881  -0.03332251 -1.04564686
  1.34332322  0.11095607 -0.25350053 -0.6230201   1.01314392 -2.04905906
 -0.73002023 -2.08633183  1.42260307  2.72058317  0.06206653 -2.1864232
 -0.14964074 -0.69777415 -0.3183995  -2.38548151 24.93859978]
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2812.1720951699044
gradient value of function right now is: [ 7.34679056e-04  4.10933361e-03  4.17839838e-03  4.20772310e-03
 -7.34679056e-04 -4.10933361e-03 -4.17839838e-03 -4.20772310e-03
  9.34520506e-05  7.91198858e-04 -2.94875576e-05  7.88101803e-04
 -1.21015227e-05  5.77407854e-04 -1.42399938e-04  5.80120822e-04
  4.28088774e-06  4.50038609e-04 -9.02672625e-05  4.51332455e-04
  5.97772809e-06  1.85335672e-04 -3.08219341e-05  1.85610264e-04
 -8.23589811e-06  2.90817514e-05  1.82234281e-05  2.89073036e-05
 -8.92579067e-05  1.76764214e-05 -2.00453854e-05 -4.40010432e-06
  1.74901192e-05 -4.03399962e-05 -2.30447939e-05 -3.97405441e-05
 -9.53206226e-05  3.10125207e-05 -1.25032864e-05  8.51395966e-06
 -5.05917341e-05 -4.52632366e-07 -6.70158693e-06 -1.84095399e-07
 -5.59025003e-05  1.39008350e-05  6.48933841e-06  1.50675125e-05
 -1.02116925e-04  2.86403605e-05  1.38445898e-05  3.01580658e-05
 -1.60961741e-04  5.63447854e-06 -1.41742071e-05  7.09765989e-06
 -2.03675167e-05  9.50971596e-07  9.74317987e-06  1.00244802e-05
  1.34933216e-06  1.22136093e-05  1.09868899e-05  6.94025664e-06
 -3.66811238e+00]
supnorm grad right now is: 3.668112376685639
Weights right now are: 
[-0.99019616 -1.30344543 -2.26491774 -1.25818279  0.19997693  1.31790907
  2.83622379  2.67326584  0.28443213  0.48833633  0.6086389   0.94466088
  0.42425144 -1.2991358   0.76487794 -1.46925466 -0.91099149 -1.6593665
 -0.29194975 -1.86375867 -0.99866043 -1.99656422 -1.25468948 -2.15008519
  1.37652124  0.71185647  0.10620653  0.69898086 -0.34930305 -1.35303898
 -1.69844868 -1.76585235  0.06815346  0.88871959  1.21227954  1.00142378
 -0.5257443  -1.61506266 -0.56720242 -1.87640107  0.65571889  0.24102658
  1.39637075  1.6367002   2.68949035 -1.68380808 -0.03050026 -1.10254933
  1.72890005  0.03345709 -0.27029327 -0.71146344  1.81624077 -2.04906736
 -0.57232019 -2.09288426  1.62397924  3.18520254 -0.04554508 -2.37572354
 -0.09788843 -1.06065267 -0.38037962 -2.54611255 24.7125855 ]
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2809.986833345247
gradient value of function right now is: [ 3.62343389e-04  1.71930628e-03  1.71381285e-03  1.72262660e-03
 -3.62343389e-04 -1.71930628e-03 -1.71381285e-03 -1.72262660e-03
  4.79301451e-05  3.91348248e-04 -1.70854800e-05  3.87626119e-04
 -2.94080254e-05  1.88619517e-04 -8.61032109e-05  1.85864635e-04
 -1.16697972e-05  1.74872029e-04 -5.66005075e-05  1.72651793e-04
 -3.33567331e-06  6.77596110e-05 -2.01606288e-05  6.69270472e-05
 -3.99591233e-06  9.84295973e-06  6.49415013e-06  1.02376044e-05
 -4.77804034e-05  1.01741439e-05 -4.57589240e-06  8.15574530e-06
  8.84158870e-06 -1.88205721e-05 -1.21667231e-05 -2.03457524e-05
 -4.97028928e-05  1.45740870e-05 -1.68655138e-06  1.28011657e-05
 -1.68912829e-05  1.48353986e-08 -1.32492110e-06  8.42395590e-08
 -1.74218170e-05  7.31708314e-06  6.09819843e-06  7.74950466e-06
 -3.78106867e-05  1.27689786e-05  9.28442844e-06  1.33021093e-05
 -4.16548676e-05  6.06467594e-06  3.44866758e-06  6.60010721e-06
 -1.77417552e-05  1.06571581e-05  7.71934726e-06 -1.52561819e-06
  1.72999307e-06  1.58243684e-06  8.34645056e-06 -2.39099946e-06
 -7.92898454e+00]
supnorm grad right now is: 7.928984538023306
Weights right now are: 
[-1.01066157 -1.45515424 -2.40750672 -1.40079379  0.22044234  1.46961787
  2.97881277  2.81587684  0.27511929  0.37474543  0.61734106  0.83348122
  0.45987024 -1.44446747  0.84246633 -1.61350724 -0.90655319 -1.69258775
 -0.27910698 -1.89623396 -0.99159993 -2.06199629 -1.22886157 -2.21254903
  1.3840888   0.69001159  0.09343551  0.68502888 -0.12226994 -1.37013498
 -1.62846441 -1.7499929   0.05649655  0.90961729  1.2229376   1.01430394
 -0.44251749 -1.63000231 -0.5472383  -1.87449368  0.85426542  0.2443538
  1.41932119  1.63987711  3.14734273 -1.73326946 -0.03907745 -1.1542858
  2.17848444 -0.03525892 -0.29211058 -0.78927666  2.56008613 -2.06123006
 -0.4840211  -2.10964357  1.90278267  3.57261204 -0.18814844 -2.52656962
 -0.10049301 -1.25836529 -0.45961793 -2.67460842 24.30991846]
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2812.6141183861937
gradient value of function right now is: [ 1.06076198e-04  4.77410991e-04  4.26543645e-04  4.19332384e-04
 -1.06076198e-04 -4.77410992e-04 -4.26543645e-04 -4.19332384e-04
 -1.35267423e-06  1.45642922e-04 -3.48650549e-05  1.41868168e-04
 -7.58035438e-05 -7.26852211e-06 -1.07491521e-04 -1.38722013e-05
 -4.57971448e-05  1.48887623e-05 -6.92909705e-05  1.04273536e-05
 -1.71730462e-05  5.42007425e-06 -2.59443930e-05  3.75339167e-06
 -1.81977169e-06 -1.69389139e-07 -4.55190930e-07 -2.93695581e-07
 -4.51707587e-05  2.04177255e-06 -6.32466883e-06  4.55126008e-07
  1.16768180e-05 -8.34341852e-06 -4.60878505e-06 -8.56459852e-06
 -4.67977107e-05  3.22919924e-06 -5.65649477e-06  1.61431617e-06
  2.04560356e-06  6.40765193e-08  2.12057698e-07  5.90633237e-08
 -1.41374857e-05  2.52473162e-06  1.37903079e-06  2.60751559e-06
 -2.58297695e-05  4.38062876e-06  2.16877839e-06  4.50858385e-06
 -2.65084568e-05  1.61264118e-06 -3.73293784e-07  1.72526010e-06
 -6.27255589e-06  7.70415677e-07  2.10777263e-06  1.22801752e-06
  7.74831971e-08  3.17314394e-06  2.23043766e-06  1.21064499e-06
 -1.61697669e+00]
supnorm grad right now is: 1.6169766879813934
Weights right now are: 
[-1.03512033 -1.61393799 -2.54979424 -1.54187799  0.2449011   1.62840163
  3.12110029  2.95696103  0.2691854   0.22700055  0.63828037  0.69029584
  0.58036091 -1.50722439  1.01891271 -1.66858577 -0.88886045 -1.71677212
 -0.24992023 -1.91861612 -0.95595312 -2.10759179 -1.16755955 -2.25393779
  1.39432909  0.67665672  0.08620221  0.67650086  0.30558714 -1.39412839
 -1.54083257 -1.7454063   0.03162496  0.93862677  1.23840057  1.03300092
 -0.28767668 -1.64661822 -0.52069405 -1.87696849  0.99669165  0.24675079
  1.43257047  1.64222929  3.72550301 -1.79560895 -0.06548914 -1.21898652
  2.76900584 -0.11550137 -0.3290686  -0.8796759   3.32794895 -2.08420998
 -0.43119819 -2.13719083  2.81097173  3.38144856 -0.53031449 -2.63273321
 -0.15645302 -1.43614785 -0.65379999 -2.76543693 24.88127863]
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2812.422645957503
gradient value of function right now is: [-8.55050188e-02 -3.49947605e-02 -1.45428661e-01 -1.57424614e-01
  8.55050188e-02  3.49947605e-02  1.45428661e-01  1.57424614e-01
 -1.01233089e-02 -9.30666434e-04 -4.45276825e-02 -8.92036137e-03
 -1.66582952e-02 -8.69902050e-04 -7.39439525e-02 -1.39907659e-02
 -5.83526642e-02 -9.16345227e-03 -2.54001320e-01 -5.48243676e-02
 -4.39469380e-02 -6.90176419e-03 -1.91283654e-01 -4.12950058e-02
 -5.25456143e-03 -4.05226760e-04 -3.92617767e-04 -4.49439619e-04
 -2.99939629e-02  4.36765963e-04  1.28814223e-04  5.66434120e-04
  9.25464731e-02 -2.03378962e-04  6.43971381e-04 -2.18554995e-04
 -1.21037339e-01 -6.88111933e-06 -1.06265107e-03 -1.06907474e-07
  2.64588014e-02 -5.24999425e-04 -3.44167950e-04 -5.97536292e-04
 -1.11985049e-03  4.35563615e-04  3.51251713e-04  4.15492587e-04
 -2.10264584e-03  3.00373005e-04  2.44298922e-04  2.95127995e-04
 -1.69558629e-03  5.87601060e-04  4.75544349e-04  5.59984130e-04
 -3.98068030e-03  8.45552758e-04  6.85496484e-04 -3.72638412e-04
  2.12527624e-04  3.54706460e-04  9.30528530e-04 -1.75233006e-04
  3.97446500e+00]
supnorm grad right now is: 3.9744650001233732
Weights right now are: 
[-9.63012257e-01 -1.65380856e+00 -2.41485844e+00 -1.38090023e+00
  1.72793020e-01  1.66827220e+00  2.98616449e+00  2.79598328e+00
  3.68327229e-01  6.53388942e-02  8.90901243e-01  6.25380885e-01
  1.48034169e+00 -1.18878002e+00  2.41797366e+00 -8.16713609e-01
 -6.06216107e-01 -1.61422936e+00  2.62647129e-01 -1.61119043e+00
 -2.36295417e-01 -1.81786566e+00 -1.10094261e-01 -1.55829662e+00
  1.70103196e+00  7.49685356e-01  1.50524764e-01  7.27828644e-01
  3.65218035e+00 -1.38779481e+00 -1.27143209e+00 -1.71799283e+00
 -7.57727891e-01  9.90369991e-01  1.24276273e+00  1.06451946e+00
  1.73009381e+00 -1.61008733e+00 -3.45335809e-01 -1.83690687e+00
 -2.58716352e+00  1.54055139e-01  1.21046694e+00  1.56564087e+00
  5.25601714e+00 -1.91758530e+00 -1.39114717e-01 -1.34360939e+00
  4.29260462e+00 -2.46896121e-01 -4.11943579e-01 -1.02764929e+00
  5.00385741e+00 -2.13595695e+00 -4.01409526e-01 -2.19466704e+00
  3.81304590e+00  3.50896619e+00 -7.67762220e-01 -3.08814417e+00
 -1.71961056e-02 -2.88372172e+00 -8.25387885e-01 -3.39759787e+00
  2.52560752e+01]
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -2835.9787430093356
gradient value of function right now is: [ 4.45996365e-02  4.13184271e-02  1.55154974e-01  1.33887751e-01
 -4.45996365e-02 -4.13184271e-02 -1.55154974e-01 -1.33887751e-01
 -5.51539720e-03 -6.51595552e-03 -4.16036471e-02 -1.26884911e-02
  2.04875625e-02  1.14621014e-02  7.49371620e-02  1.86979891e-02
  6.35615797e-02  3.15039759e-02  2.55546344e-01  6.11795498e-02
  2.57431471e-02  1.28233546e-02  1.02095927e-01  2.43840692e-02
 -1.47310180e-01 -2.82876867e-02 -1.69731621e-02 -3.42890771e-02
  1.03137434e-01  1.62122162e-02  9.57362493e-03  1.99272921e-02
 -2.43839693e-01 -4.12051797e-02 -2.45303580e-02 -5.02831012e-02
  8.79199455e-02  1.60021702e-02  9.59179513e-03  1.94024861e-02
 -3.33552285e-01 -4.22012437e-02 -5.54065123e-02 -4.43323093e-02
  2.35482786e-01  2.93731409e-02  3.86400200e-02  3.08511865e-02
  9.14869866e-02  1.07938581e-02  1.45122841e-02  1.14638520e-02
  2.89111807e-01  3.64209276e-02  4.77644921e-02  3.82031519e-02
 -3.77421295e-01  1.31918687e+00  8.89887459e-02 -5.04391375e-01
  1.42862020e-01 -6.71892983e-01  1.37096754e-01 -6.90750855e-01
 -8.39310194e+00]
supnorm grad right now is: 8.393101936115398
Weights right now are: 
[ 0.29913093 -3.07193153 -1.13621903  0.03278636 -1.08935017  3.08639517
  1.70752508  1.38229669  1.97278646  3.54558134  2.50872618  4.16709661
  3.8064522  -2.49721324  5.1887986  -0.21903491  1.87167817 -2.8272829
  3.20914323 -1.28278124  2.57806994 -2.44830552  3.08076636 -0.62041722
  0.0823644   3.78214195  2.23937278  3.68331902  5.06219039 -3.64019229
 -2.68939846 -4.06130075 -3.08232499  2.99544408  2.27733794  3.09852868
  3.90108906 -3.74385687 -1.36506616 -4.00972742 -3.0479873   3.05120038
  4.22999988  4.94667402  4.69861445 -5.71820115 -4.33323299 -5.69309515
  4.87598041 -3.0730714  -3.79969227 -4.45296149  4.50023967 -5.80838722
 -4.30181796 -6.36423059  6.19736277  2.4644462  -3.27538535 -2.54614332
 -3.53178091 -2.32042215 -3.88038791 -2.60817057 25.11343114]
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2831.364282015892
gradient value of function right now is: [-9.80158839e-02 -6.49147828e-02 -8.28421723e-01 -4.87019494e-01
  9.80158839e-02  6.49147828e-02  8.28421723e-01  4.87019494e-01
  1.79246247e-02  1.36870926e-03  6.13769620e-02  1.04157644e-02
 -8.75410021e-02 -2.57884683e-02 -3.73977022e-01 -1.34480558e-01
 -6.28362573e-01 -1.02099472e-01 -2.39892480e+00 -6.19793397e-01
 -2.57763011e-01 -4.69168384e-02 -9.99102475e-01 -2.74187219e-01
  1.36110813e+00  1.01407979e-01  7.30901565e-02  1.17890460e-01
 -2.83550786e-01 -4.87203742e-02 -3.42104520e-02 -5.55730153e-02
  1.50964868e+00  1.95103687e-01  1.38352635e-01  2.23523686e-01
 -6.99704650e-01 -8.13822586e-02 -5.78380548e-02 -9.34832140e-02
  9.58961502e-01  6.13706075e-02  1.15340166e-01  8.64961279e-02
 -9.16114166e-01 -5.35896098e-02 -1.01887616e-01 -7.58412489e-02
 -4.54004613e-01 -2.55026726e-02 -4.94593836e-02 -3.65888116e-02
 -1.07277206e+00 -6.30025603e-02 -1.19359037e-01 -8.89136766e-02
  2.07373608e+00 -7.90271465e+00 -3.03342538e-01  1.25231389e+00
 -5.56207053e-01  2.21882510e+00 -5.45161908e-01  2.18195386e+00
  1.07377505e+01]
supnorm grad right now is: 10.737750519739135
Weights right now are: 
[-8.71693645e-03 -3.84672770e+00 -1.84580481e+00 -6.85446250e-01
 -7.81502300e-01  3.86119134e+00  2.41711085e+00  2.10052930e+00
  2.41468493e+00  4.92856161e+00  3.06741045e+00  6.26598908e+00
  3.46349282e+00 -1.83962390e+00  4.91912487e+00  4.87199434e-01
  1.93068613e+00 -2.60556598e+00  2.49855465e+00 -1.69299332e+00
  2.81023495e+00 -1.86828921e+00  2.68992472e+00 -5.34666453e-01
  3.54542960e-01  5.43655388e+00  3.82342019e+00  5.33754356e+00
  5.32023399e+00 -2.88576088e+00 -2.04452859e+00 -3.30825201e+00
 -2.66875640e+00  2.88316565e+00  2.23508434e+00  2.99015809e+00
  2.87506963e+00 -4.12217108e+00 -1.79957166e+00 -4.39190298e+00
 -3.01576997e+00  3.07091760e+00  4.25257092e+00  5.00168716e+00
  4.76376468e+00 -5.59742256e+00 -4.23329835e+00 -5.61434980e+00
  5.01418014e+00 -2.84022623e+00 -3.59436105e+00 -4.26215601e+00
  4.57171221e+00 -5.68886370e+00 -4.20290049e+00 -6.28650465e+00
  6.85723206e+00  2.18728157e+00 -3.26269272e+00 -2.94170707e+00
 -3.63890887e+00 -2.57098664e+00 -3.99532964e+00 -2.87317433e+00
  2.58218895e+01]
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2832.1390935397108
gradient value of function right now is: [ 8.73106714e-02  3.93944681e-02  6.45870368e-01  3.21799046e-01
 -8.73106714e-02 -3.93944681e-02 -6.45870368e-01 -3.21799046e-01
  3.76865845e-03  1.19454840e-03  9.48410937e-02  9.54451667e-03
  5.82086516e-03  3.89051311e-02  1.60287330e-01  8.00523043e-02
  4.97027123e-02  7.59929526e-02  1.68782687e+00  3.79271029e-01
  2.54774131e-02  3.49871622e-02  6.39403186e-01  1.41927397e-01
 -1.47048520e-01 -4.13577291e-02 -1.81323017e-02 -5.09892823e-02
  7.48145499e-02  4.59906736e-02  2.39890878e-02  5.26525222e-02
 -6.89485994e-01 -3.10748724e-01 -1.49505505e-01 -3.61267112e-01
 -6.43248704e-02 -2.11626646e-02 -1.04599100e-02 -2.47371752e-02
 -4.84891861e-01 -1.24817012e-01 -1.48338956e-01 -1.55342186e-01
  3.02317608e-01  5.87500448e-02  6.96751929e-02  7.18635254e-02
  9.11500166e-02  1.65049571e-02  2.02589749e-02  2.13353075e-02
  3.65019956e-01  7.08884620e-02  8.38222844e-02  8.62457485e-02
 -1.58429545e+00  2.50511796e+00  3.82024884e-01 -6.50796590e-01
  4.44560158e-01 -7.26762560e-01  6.41752538e-01 -1.03826717e+00
 -2.56284726e+00]
supnorm grad right now is: 2.5628472633386563
Weights right now are: 
[-0.99558917 -3.94554697 -1.5315743  -0.57081069  0.20536994  3.9600106
  2.10288035  1.98589374  2.64547846  5.54954707  3.60851079  7.52464877
  3.7647338  -2.30616956  6.22405116  1.27880614  1.70116151 -1.51578342
  2.62814145 -0.43781397  2.6723848  -1.02378519  3.15703387  1.03635064
  0.82151974  6.36290009  4.33622237  6.317702    6.94155186 -1.41467211
 -0.6142013  -1.85732125 -4.1071075   1.67919193  0.88117413  1.82831127
  4.19798758 -2.29811094  0.37593533 -2.65052681 -4.02951864  2.62736734
  3.61521731  4.36987527  5.74565409 -5.16329306 -3.57068448 -4.95029877
  6.43059156 -2.05865886 -2.56276879 -3.23928692  5.4998979  -5.30391927
 -3.59425952 -5.67418865  5.85413532  3.66621223 -2.3289403  -4.09288945
 -2.54876351 -3.95392229 -3.02035031 -4.18393044 26.24110862]
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2837.8498043719806
gradient value of function right now is: [ 1.64392401e-02 -2.20828225e-03  7.77593279e-02  5.21491271e-02
 -1.64392401e-02  2.20828225e-03 -7.77593279e-02 -5.21491271e-02
  6.39428742e-04  8.95229563e-06  2.77781979e-02  7.12331591e-04
  1.57603226e-03 -1.90432100e-03  7.40086594e-03 -2.16824178e-02
  3.99535477e-03 -9.71291864e-03  4.92101485e-01 -4.70466738e-02
  1.57247259e-02 -4.03651603e-03  2.30406016e-01 -2.51729133e-02
 -2.93620846e-01 -4.58283235e-02 -1.55316826e-02 -5.87780074e-02
 -1.50045957e-02 -1.78497944e-02 -8.25983743e-03 -1.97070424e-02
 -4.24545857e-02  8.32157776e-02  4.64924133e-02  8.73821106e-02
  2.12825658e-03 -3.44052023e-03 -2.33671309e-03 -3.48959157e-03
 -5.00570837e-03  1.52608674e-02  1.68942388e-02  1.92692456e-02
  2.79594177e-01  1.52250812e-02  1.52127215e-02  1.27073982e-02
  5.45782543e-02  3.10335159e-04  1.98866181e-04 -3.16874766e-04
  3.66662682e-01  2.25559091e-02  2.26817748e-02  1.94817644e-02
 -3.50820116e-01  1.08081542e+00 -4.54323598e-02 -9.66557262e-02
 -6.10965453e-02 -3.48087272e-02 -8.49109020e-02 -3.34587722e-02
  5.69599290e+00]
supnorm grad right now is: 5.695992904362842
Weights right now are: 
[-1.32614043 -3.82764151 -2.21408046 -1.23379525  0.53592119  3.84210515
  2.78538651  2.64887829  3.98555987  5.76452904  4.1454775   7.06381452
  4.29876268 -2.42181699  6.04221928  1.42267459  3.81793753 -1.73339135
  2.19679791 -1.16032706  4.550444   -1.09276137  2.71784949  0.75116935
 -0.69634038 10.20952938  6.80350704 10.39274469  7.36815465 -1.02866751
 -0.10496899 -1.47564987 -3.65217049  1.8892477   1.08876935  2.04528953
  4.55406966 -2.00675961  0.1637594  -2.30101604 -3.78806072  2.97228442
  3.93355445  4.68694091  4.64948014 -5.99736515 -4.3467321  -5.69160225
  5.90811775 -2.51487893 -2.90014627 -3.5009833   4.32562814 -6.21425583
 -4.44769085 -6.4941226   6.49469535  3.23925259 -2.69471838 -3.82141549
 -2.80420343 -3.81403589 -3.27486411 -4.03422957 26.31400344]
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2833.1228783942584
gradient value of function right now is: [ 5.21042595e-02  9.20464550e-02  1.10326906e+00  5.34221265e-01
 -5.21042595e-02 -9.20464550e-02 -1.10326906e+00 -5.34221265e-01
  8.12403225e-04  3.57743231e-04  3.35139431e-02  3.46921837e-03
  1.22750707e-03  9.76167788e-02  1.57794471e-01  1.60377354e-01
  4.65620221e-02  9.60524889e-02  2.77054829e+00  5.61583918e-01
  1.62981925e-02  6.52445406e-02  9.97482561e-01  2.30519483e-01
 -2.70604067e-01 -3.41476703e-02 -9.36252865e-03 -4.42069299e-02
  6.97811218e-02  1.63227473e-01  1.24317836e-01  1.68275204e-01
 -1.30697447e+00 -1.31225868e+00 -7.87792583e-01 -1.40675071e+00
  7.63208311e-02  5.43731549e-02  1.94389967e-02  6.08394080e-02
 -6.52707639e-01 -2.00451370e-01 -1.96390065e-01 -2.17533216e-01
  3.60262357e-01  5.34084773e-02  5.19758252e-02  5.62792586e-02
  9.84881367e-02  2.11269504e-02  2.06389469e-02  2.32212904e-02
  4.30398129e-01  5.80539408e-02  5.64103848e-02  6.10483702e-02
 -1.49588450e+00  3.64939593e+00  4.23684690e-01 -1.01291598e+00
  4.27856046e-01 -9.92405032e-01  6.35089749e-01 -1.42038588e+00
 -1.38628265e+01]
supnorm grad right now is: 13.862826474214865
Weights right now are: 
[-7.66188917e-01 -3.06135209e+00 -1.69317507e+00 -6.22116206e-01
 -2.40303191e-02  3.07581573e+00  2.26448111e+00  2.03719925e+00
  4.99922125e+00  6.54079171e+00  5.13191553e+00  7.71149832e+00
  4.65217265e+00 -2.89080680e+00  7.01704741e+00  1.53700553e+00
  5.20468103e+00 -1.44639054e+00  2.74977769e+00 -9.06911226e-01
  5.65827510e+00 -1.03530224e+00  3.34671188e+00  1.21161358e+00
 -1.55910210e+00  1.16991142e+01  7.89780438e+00  1.19164826e+01
  8.42196694e+00 -5.22336919e-01  3.88091852e-02 -9.04258405e-01
 -4.46028060e+00  1.09033104e+00  7.20658398e-01  1.22084980e+00
  5.21115639e+00 -1.36386345e+00  9.73345905e-01 -1.70007147e+00
 -4.30869183e+00  2.52060274e+00  3.56551796e+00  4.28210775e+00
  4.37070279e+00 -6.78628636e+00 -5.17722459e+00 -6.46772779e+00
  6.05587219e+00 -2.23465731e+00 -2.75187481e+00 -3.30780637e+00
  4.02027598e+00 -7.26050986e+00 -5.51755479e+00 -7.50661366e+00
  7.62546985e+00  2.52676878e+00 -2.46937236e+00 -3.87010936e+00
 -2.53512095e+00 -3.93457707e+00 -3.09000283e+00 -4.05856251e+00
  2.53073677e+01]
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2839.445558400171
gradient value of function right now is: [-8.54974781e-03 -1.00421459e-02 -1.19302796e-01 -6.29506759e-02
  8.54974781e-03  1.00421459e-02  1.19302796e-01  6.29506759e-02
 -7.53647554e-04 -3.39207389e-04 -6.21549461e-03 -9.47035678e-04
 -6.42321331e-04 -3.40602601e-03 -2.79174109e-02 -7.21059929e-03
 -8.34783858e-02 -1.35776666e-02 -3.02258946e-01 -4.02282015e-02
 -1.57090856e-02 -6.60433203e-03 -1.14435891e-01 -1.86972429e-02
  1.61812102e-01  6.10697681e-04  2.09900882e-03 -3.61470523e-03
 -2.08602760e-02 -2.73112222e-02 -1.39607961e-02 -2.94323964e-02
  2.64639145e-01  2.89795728e-01  1.42551427e-01  3.14323532e-01
 -6.87189160e-03 -6.26758584e-03 -2.80298704e-03 -6.80870884e-03
  1.27602695e-01  3.93505307e-02  3.57371911e-02  4.48139224e-02
 -8.69289084e-03  1.15347270e-03  1.15675309e-03 -1.89943524e-03
 -3.44300193e-02 -7.74362819e-03 -6.98660908e-03 -8.96468824e-03
  2.69343718e-02  7.89460081e-03  7.27463063e-03  3.86941640e-03
  5.89038843e-01 -1.11574029e+00 -1.39142917e-01  1.15249628e-01
 -1.28373593e-01  1.32015217e-01 -2.03518020e-01  2.47942903e-01
  7.21254843e+00]
supnorm grad right now is: 7.212548431403266
Weights right now are: 
[-1.11234675 -3.32711486 -2.69545775 -1.36736806  0.32212751  3.3415785
  3.2667638   2.78245111  4.93382747  7.41970538  5.25912664  8.4398365
  4.63417745 -3.69202577  7.31383217  1.02617951  5.11935019 -1.75697704
  1.87778521 -1.17539171  5.5231137  -1.41607628  2.90828626  1.01415038
 -1.28431745 11.96971644  7.9436591  12.33148212  9.12407    -0.8083192
 -0.79466035 -1.10262008 -4.48208103  1.47314117  1.40701536  1.60404365
  5.50898686 -0.72693629  1.75004924 -1.17654618 -4.66066235  2.73920841
  3.71878466  4.48269804  4.27948253 -7.74356751 -6.03800925 -7.1510574
  6.84047929 -1.90967856 -2.35381825 -2.91694616  3.75460742 -8.51271585
 -6.67024605 -8.47126822  7.50008933  2.86241858 -2.00090088 -3.86877172
 -2.08035387 -4.0285885  -2.79685972 -4.1742361  26.28538878]
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2838.5213434979487
gradient value of function right now is: [-3.99955305e-03 -5.14168121e-03 -2.34426206e-01 -9.54296743e-02
  3.99955305e-03  5.14168121e-03  2.34426206e-01  9.54296743e-02
 -2.55717173e-04 -1.19029638e-04 -2.72792895e-03 -1.84351871e-05
 -9.44166427e-04 -8.00097994e-03 -3.23773711e-02 -3.15907408e-04
 -6.71069990e-02 -7.66281872e-02 -1.02311772e+00 -7.53807895e-03
 -1.55933991e-02 -3.12036767e-02 -3.11019858e-01 -2.44375642e-03
  2.77923265e-01  2.71478596e-02  7.58643895e-03  3.49613660e-02
 -2.07913443e-01 -1.57028720e-01 -6.28705359e-02 -1.88596180e-01
  2.36821314e-01  1.53846251e-01  6.26707070e-02  1.83455351e-01
 -2.02013121e-04  1.40577712e-04  5.63507087e-05  1.68998108e-04
  2.86676635e-01  4.67391175e-02  4.06852509e-02  5.22317791e-02
 -2.29044203e-01 -1.36984900e-02 -1.15912785e-02 -1.67243488e-02
 -8.01950666e-02 -8.52474386e-03 -7.26372722e-03 -9.82248518e-03
 -2.53907997e-01 -7.74632479e-03 -6.19024174e-03 -1.17160967e-02
  1.28779653e+00 -3.21750629e+00 -2.12894610e-01  4.23645068e-01
 -1.71127411e-01  3.47676001e-01 -2.83172701e-01  5.98878628e-01
  8.58950704e+00]
supnorm grad right now is: 8.589507039546474
Weights right now are: 
[-7.55912391e-01 -4.13940099e+00 -2.75390787e+00 -1.35758493e+00
 -3.43068455e-02  4.15386463e+00  3.32521392e+00  2.77266798e+00
  5.27511000e+00  8.17260160e+00  5.86093362e+00  9.34686636e+00
  4.74014499e+00 -6.10353464e+00  7.28003566e+00  9.65112129e-01
  6.35914844e+00 -3.27764342e+00  1.84994650e+00 -6.18451305e-01
  6.27968867e+00 -3.14804311e+00  3.01550657e+00  1.67365190e+00
 -1.68706910e+00  1.22837295e+01  8.09757926e+00  1.28060224e+01
  8.33624510e+00 -2.84653050e+00 -2.83982064e+00 -3.07265852e+00
 -4.65749732e+00  1.31614192e+00  1.35711914e+00  1.38954892e+00
  5.73341326e+00  5.98549672e-01  3.86661242e+00  1.50438444e-02
 -4.51228154e+00  3.16407121e+00  4.12624307e+00  4.93619203e+00
  4.23535221e+00 -8.30424956e+00 -6.59697687e+00 -7.72629124e+00
  6.90135823e+00 -2.62600360e+00 -3.07801937e+00 -3.71341034e+00
  3.50716901e+00 -9.70616107e+00 -7.87256774e+00 -9.65056430e+00
  7.92127656e+00  2.79260303e+00 -1.89020289e+00 -3.49736582e+00
 -1.99988128e+00 -3.69368174e+00 -2.85943641e+00 -3.78337369e+00
  2.61645737e+01]
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -2839.87308003496
gradient value of function right now is: [-2.16120237e-03 -3.81635063e-03 -1.31292469e-01 -5.30360375e-02
  2.16120237e-03  3.81635062e-03  1.31292469e-01  5.30360375e-02
 -5.28431832e-05 -1.27385478e-04 -1.73252533e-03 -1.54177168e-05
 -2.22136786e-04 -4.26061805e-03 -2.03932902e-02 -2.21576314e-04
 -1.24989024e-02 -3.66754634e-02 -5.14456789e-01 -4.58215663e-03
 -2.52706444e-03 -1.49578411e-02 -1.61516180e-01 -1.49041270e-03
 -1.04670707e-02  3.89959242e-03  3.64853629e-03 -4.75693690e-03
 -1.16577406e-01 -7.48870489e-02 -3.01891934e-02 -8.87757959e-02
  2.24561952e-01  1.28277161e-01  5.01527590e-02  1.50849611e-01
 -5.74072877e-05  8.67881703e-05  3.38407468e-05  1.17389051e-04
  1.60371767e-01  1.66495080e-02  1.55970107e-02  2.05287294e-02
 -2.36601753e-02 -2.02741065e-04 -5.42415730e-04 -3.12138335e-03
 -4.74746891e-02 -2.85689967e-03 -2.65260439e-03 -3.94102783e-03
  8.16550166e-02  8.59809256e-03  7.32884100e-03  4.53839221e-03
  8.08832425e-01 -1.73594883e+00 -6.00415749e-02 -1.72997340e-03
 -5.59853418e-02  2.55827629e-02 -1.04435338e-01  1.16495368e-01
  3.95334518e+00]
supnorm grad right now is: 3.9533451802131823
Weights right now are: 
[ -0.89174299  -4.10252448  -2.97420437  -1.51815633   0.10152375
   4.11698812   3.54551041   2.93323937   5.69901981   7.82953482
   6.36958224   9.42420869   5.35828292  -5.62803148   7.38763023
   0.98824003   6.67833575  -3.48270563   1.74315106  -0.63317291
   6.65748366  -3.07568714   3.09386475   1.72358083  -1.68716515
  12.46336291   8.35888219  13.0795763    8.31944313  -2.8778238
  -3.38903326  -3.04121674  -4.29102217   1.78055298   1.93191703
   1.85550313   5.79207672   0.61931      3.91415011   0.02868524
  -4.48712152   3.3543745    4.33929236   5.0464105    4.14397609
  -9.09902082  -7.45669244  -8.32227878   7.29995273  -1.75154974
  -2.28173088  -2.97298879   3.36152792 -10.41651465  -8.64873686
 -10.20455229   8.04919434   2.96832658  -0.98553716  -3.8469851
  -1.2055316   -4.02316346  -2.27699445  -4.16869462  25.96048931]
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2840.2014781869552
gradient value of function right now is: [-2.38328247e-03 -1.54059121e-03 -2.35837697e-01 -7.01291955e-02
  2.38328247e-03  1.54059121e-03  2.35837697e-01  7.01291955e-02
 -1.74473081e-04 -9.54379285e-05 -2.56098642e-03 -1.00392973e-05
 -2.39561440e-04 -7.75361082e-04 -5.92524282e-03 -3.09914344e-05
 -1.26427259e-01 -2.18988664e-02 -1.20025709e+00 -4.03814494e-03
 -1.87131838e-02 -7.82060234e-03 -2.57937472e-01 -9.53205426e-04
  5.18802014e-01  2.50981206e-02  2.51599042e-03  6.17102105e-02
 -8.19025096e-02 -4.25662156e-02 -1.21559867e-02 -6.12261104e-02
  2.45639781e-01  9.86483110e-02  2.50096971e-02  1.50598734e-01
 -1.36423734e-03 -2.40237370e-04 -4.71984093e-05 -4.41484649e-04
  1.31849392e-01  1.42557527e-02  1.16848515e-02  1.16859193e-02
 -2.66640658e-01 -1.07476558e-02 -8.52329517e-03 -8.53295394e-03
 -4.25493445e-02 -3.58318995e-03 -2.87269327e-03 -2.91259254e-03
 -5.80190418e-01 -9.93330231e-03 -7.38531404e-03 -7.97033149e-03
  7.60742545e-01 -1.97944538e+00 -1.64521709e-01  3.63698321e-01
 -1.15074185e-01  2.49240564e-01 -1.24891040e-01  2.76993349e-01
  2.92132516e+00]
supnorm grad right now is: 2.9213251603563477
Weights right now are: 
[ -1.06682415  -2.84512659  -3.29734728  -1.66875277   0.27660492
   2.85959023   3.86865332   3.08383582   5.77885211   8.20730072
   6.89006651   9.5193469    5.21620153  -3.68782014   8.38361797
   1.165818     6.45943272  -4.17298183   1.5134756   -0.82511406
   6.50720336  -2.97625587   3.08470178   1.68024407  -1.36545639
  12.41738229   7.55299456  13.61343957   8.34704601  -2.98687439
  -4.45746071  -3.07236145  -4.31614831   2.16187666   2.83491432
   2.23435816   6.06819944   0.82370999   4.18327525   0.2294323
  -4.96475017   3.20151512   4.17169706   4.94869152   4.18703556
  -9.40282227  -7.72616436  -8.43913618   7.6810774   -2.27229542
  -2.77155108  -3.34444924   2.72631707 -12.02905511 -10.20182798
 -11.35148776   8.23880739   3.10967052  -1.21174138  -3.27099164
  -1.41508975  -3.57180452  -2.33917636  -3.97703618  25.83896568]
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2838.5823460832617
gradient value of function right now is: [ 2.02448704e-03  1.37549935e-04  3.51403835e-01  7.49334924e-02
 -2.02448704e-03 -1.37549936e-04 -3.51403835e-01 -7.49334924e-02
  1.87988461e-06 -9.63708720e-07 -3.45815421e-04 -3.10568673e-07
 -5.91941342e-05 -2.90831209e-03  1.05876239e-03 -5.24988436e-06
 -1.85922239e-02  2.63698152e-04  1.60762994e+00  1.39563863e-03
 -1.23148899e-03 -4.84275529e-03  2.21602449e-01  1.83560052e-04
  1.51828054e-02 -6.00658355e-03 -3.43880818e-04 -2.31643234e-02
  2.22244830e-02 -1.26924793e-02 -1.20393871e-02 -2.29418011e-03
 -3.16339141e-01 -8.79921176e-02 -1.06395480e-02 -1.81996600e-01
 -8.86601924e-05 -9.05343929e-06  2.40078740e-06 -3.13506347e-05
 -1.00215110e-01 -4.38481927e-03 -4.05872854e-03 -2.65768543e-03
  1.46927851e-01  1.20332999e-02  1.19696352e-02  1.27082142e-02
  1.52517472e-02 -5.96997149e-04 -7.73956576e-04 -1.79656154e-03
  2.73444406e-01  1.94006137e-02  1.93404699e-02  2.12341710e-02
 -2.24430384e-01  7.86906987e-01  3.06273789e-02 -2.64761912e-01
  2.28149515e-02 -2.24816567e-01  1.50178378e-02 -2.57594577e-01
 -6.71202477e+00]
supnorm grad right now is: 6.712024773603031
Weights right now are: 
[ -0.29983885  -2.44405191  -2.41295925  -0.85482967  -0.49038038
   2.45851555   2.98426529   2.26991272   6.46385692   8.84594905
   8.09858822   9.68198739   5.35606342  -3.49947291   8.81555017
   1.21600431   6.48848735  -4.10521174   2.36417714  -0.21541289
   6.78083056  -2.57999316   4.08937654   2.1786015   -1.05998076
  12.88349522   8.76243546  13.81531272   8.62857829  -2.98900329
  -4.37155721  -3.0644048   -4.7407575    2.08767549   2.81098789
   2.11132167   7.08792398   1.2179066    4.51798044   0.92272649
  -4.89126477   3.47651405   4.47483395   5.33851824   4.26936683
  -9.36080695  -7.76489695  -8.64913044   7.39851348  -2.86708533
  -3.40509464  -3.91067861   2.75973193 -11.97142232 -10.35805856
 -11.83128227   8.70473035   2.91766225  -1.15073562  -3.93586638
  -1.49811911  -3.98781282  -2.58883565  -4.01533932  25.44629364]
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2840.0529569240985
gradient value of function right now is: [-3.32245092e-04 -5.66493007e-04  6.85972920e-02 -2.54323605e-04
  3.32245092e-04  5.66493006e-04 -6.85972920e-02  2.54323604e-04
  9.97237099e-06 -1.97264002e-05 -1.18190940e-04 -2.39179940e-07
  3.72619760e-05 -3.04860164e-04 -1.39707543e-03 -2.72763486e-06
  1.26659896e-01 -7.03191836e-03  5.89800400e-01  1.77251021e-04
  8.14808316e-03 -1.92818704e-03  2.15181601e-02 -1.56015314e-05
 -7.98153002e-01 -2.90226727e-02 -1.90422905e-03 -1.37729442e-01
 -1.56596436e-02 -1.22572667e-02 -5.99175223e-03 -1.55609632e-02
  4.55173651e-02  4.38323807e-02  2.05988890e-02  5.12912695e-02
  9.15984936e-05  1.69913579e-05  6.69416620e-06  3.33565934e-05
  1.06427213e-02  4.42780448e-03  4.31996257e-03  4.84416889e-03
  2.54031823e-01  3.52837264e-03  2.96097984e-03  2.01646810e-03
  1.92903313e-03 -1.01863627e-03 -9.95292479e-04 -1.17884652e-03
  1.23286266e+00  2.72904437e-02  2.38335330e-02  1.92945232e-02
 -3.96137195e-01  1.44019960e+00  4.49081119e-02 -3.56810107e-01
  3.02401214e-02 -2.66346719e-01  2.07811964e-02 -2.30079771e-01
 -5.99378017e+00]
supnorm grad right now is: 5.993780168367514
Weights right now are: 
[-8.00137607e-01 -2.28544139e+00 -3.35894151e+00 -1.29662656e+00
  9.91837056e-03  2.29990502e+00  3.93024755e+00  2.71170960e+00
  6.40002396e+00  9.52823695e+00  8.85635819e+00  9.72275652e+00
  5.71138229e+00 -2.94065060e+00  9.32303115e+00  1.24220430e+00
  7.12406580e+00 -3.26528971e+00  1.22488680e+00 -3.57656562e-01
  7.19207910e+00 -1.44316806e+00  3.51116212e+00  2.23011766e+00
 -1.51048081e+00  1.26067135e+01  8.40723509e+00  1.37791603e+01
  9.52414480e+00 -2.02344879e+00 -3.54097393e+00 -2.00379602e+00
 -4.71496072e+00  1.99364225e+00  2.53334875e+00  1.98061466e+00
  7.42038453e+00  1.37173050e+00  4.59264032e+00  1.09111375e+00
 -5.37393262e+00  3.48849124e+00  4.42340988e+00  4.95890320e+00
  4.81966555e+00 -9.19775077e+00 -7.54359460e+00 -8.20515264e+00
  8.52264037e+00 -1.66913443e+00 -2.19398949e+00 -2.53073259e+00
  2.81305549e+00 -1.31895252e+01 -1.15978544e+01 -1.28009422e+01
  8.36392889e+00  3.37009557e+00 -3.12030210e-01 -3.87892305e+00
 -5.66634611e-01 -4.06223798e+00 -1.44762200e+00 -4.41954013e+00
  2.55004062e+01]
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2837.396690026443
gradient value of function right now is: [ 2.25765574e-03  2.44475549e-03  7.87139615e-01  7.39208794e-02
 -2.25765574e-03 -2.44475549e-03 -7.87139615e-01 -7.39208794e-02
  1.68656912e-04 -1.81468990e-04 -6.31345823e-03 -2.82232792e-07
 -4.50882479e-05  1.30255671e-03  3.85662748e-03  1.08478535e-06
 -2.17719419e-01  3.91781003e-02  3.27965097e+00  3.28412622e-05
 -3.11918672e-03  2.97886010e-03  9.90610229e-02  3.87945819e-06
  1.17783869e+00  6.84139200e-03 -1.41281252e-04  1.84640362e-01
  5.57337007e-02  8.33679105e-02  1.27939957e-02  9.92578796e-02
 -3.89505533e-01 -4.39583705e-01 -3.98369336e-02 -5.65876767e-01
 -4.19249390e-06 -1.55176931e-06 -3.07982002e-07 -1.74720263e-06
 -3.53069507e-01 -1.41869966e-01 -1.33161097e-01 -1.27609369e-01
 -7.92908369e-02  1.02220681e-02  9.93314396e-03  1.04885730e-02
  1.48576649e-02  6.15899958e-03  5.65139537e-03  5.76560625e-03
 -2.40714143e+00 -4.52275357e-02 -3.27501525e-02 -1.53059523e-02
 -1.04090887e+00  1.61523681e+00  2.00427807e-01  6.75958789e-01
  2.26145465e-01  3.01426483e-01  2.74699524e-01 -4.98932465e-02
 -3.32602441e+00]
supnorm grad right now is: 3.3260244142872164
Weights right now are: 
[  1.31102438  -2.96353267  -2.71138741  -0.11401706  -2.10124361
   2.97799631   3.28269345   1.52910011   6.37867184   9.92267494
   8.49536418  10.06579955   5.47987983  -3.9499116   10.66512074
   0.57832618   7.19044501  -2.65993302   1.65790366  -0.05253372
   7.31290895  -1.21794973   4.62399669   2.49339358  -1.32152689
  12.61249244   7.74179245  14.46395521  10.52580848  -1.35168133
  -2.62743044  -1.08784743  -5.66222991   1.08266968   1.3725193
   1.19059974   8.16663796   2.79298058   5.10739919   2.42124595
  -6.04914834   3.52594877   4.48728624   4.9584654    4.81108035
  -9.11257584  -7.4473439   -8.02994836   9.94560104  -0.45612255
  -1.13597615  -1.61247592   2.19611883 -15.39266858 -13.90477401
 -15.1970567    7.12602436   4.34486645  -0.27627291  -2.87112047
  -0.43335942  -3.10454932  -1.11822399  -3.63797733  25.84059596]
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2839.6840626883445
gradient value of function right now is: [-5.22250711e-03 -4.51568950e-03 -4.20382981e-01 -4.37715144e-02
  5.22250711e-03  4.51568949e-03  4.20382981e-01  4.37715144e-02
  2.64790575e-06  2.56347921e-04  3.14599783e-03  2.93479370e-06
 -1.75271222e-06 -5.21357935e-04 -4.53463557e-03 -6.10854413e-06
 -5.14130224e-02 -2.32568890e-03 -1.92719570e+00 -3.29658708e-04
 -6.25438525e-04 -3.07105512e-04 -5.95397186e-02 -1.62739405e-05
  1.60070423e-01  4.73088084e-03 -1.29445634e-04  4.13532200e-02
 -4.67983762e-03 -8.04449782e-03 -8.23847409e-04 -9.73543124e-03
  2.01412876e-01  1.30000043e-01  1.04405225e-02  2.18008882e-01
 -3.15556261e-05 -1.31476422e-05 -9.51470513e-07 -2.25376440e-05
  1.12507345e-01  2.14596901e-02  2.19492683e-02  2.22001070e-02
 -1.11455462e-01 -1.29795142e-02 -1.30845758e-02 -1.26082071e-02
 -6.47261477e-04 -3.08196327e-04 -3.25765372e-04 -3.52574129e-04
 -4.17916384e-01 -2.50223998e-02 -2.48315391e-02 -2.26970564e-02
  5.86059800e-03 -5.48607701e-02 -2.07780685e-01  6.20565260e-01
 -1.97294112e-01  5.75240414e-01 -2.08062122e-01  5.91312390e-01
  4.93672872e+00]
supnorm grad right now is: 4.93672872367269
Weights right now are: 
[  0.92177016  -2.51979787  -3.61964016  -0.58678589  -1.71198939
   2.53426151   4.1909462    2.00186894   6.51002431   8.8122097
  10.54661764  10.41476931   5.76061049  -3.07014802  12.05494846
   0.5966212    7.40403927  -2.38241047   0.93423901  -0.16476085
   7.33657915  -0.66626791   4.57452033   2.52510864  -1.71749228
  13.00563991   7.90914669  14.07033832  11.36789675  -0.84802159
  -1.54216398  -0.41386824  -4.7003499    1.90133995   0.49805027
   2.23045956   8.20961272   2.62259533   5.00870124   2.25401781
  -4.81732254   4.96767799   5.78134701   5.97083939   4.57364974
  -9.94864482  -8.21967125  -8.64608424  10.41800854  -0.48915722
  -0.84060583  -0.87783394   3.00912119 -14.9459641  -13.55497147
 -15.17244015   8.01186123   3.63122645  -1.48026761  -3.27474971
  -1.69303657  -3.3461331   -2.27649094  -3.60693813  25.96631338]
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2840.8354139382036
gradient value of function right now is: [-1.88994976e-03 -4.74385582e-03 -2.30495381e-02 -1.97145149e-02
  1.88994976e-03  4.74385582e-03  2.30495381e-02  1.97145149e-02
  8.88225313e-06  3.91382874e-04  1.97620271e-03  4.13025830e-07
 -1.32839976e-05 -3.48326918e-03 -1.03124523e-02 -2.51883395e-06
 -8.15873375e-02 -1.48585969e-02  6.40801633e-02 -1.40073387e-05
 -6.98077031e-04 -2.67719161e-03 -1.07161384e-02 -2.58638975e-06
  3.75308855e-01  6.87701588e-03 -1.42092915e-04  5.55476461e-02
 -2.47638456e-02 -4.51286450e-02 -9.36840072e-03 -6.03564490e-02
  4.07521752e-02  1.30208569e-01  2.03004001e-02  1.57490796e-01
  6.96594927e-07  1.87457102e-06  3.54917251e-07  2.47233681e-06
  9.71669180e-02  3.32386392e-02  3.27939042e-02  3.22001803e-02
 -1.01042522e-01 -9.04536326e-03 -8.81178620e-03 -8.42459379e-03
 -5.30701711e-04 -4.26864435e-04 -4.23879088e-04 -4.26733884e-04
 -5.99738054e-01 -1.32640805e-02 -1.21987982e-02 -9.99543101e-03
  2.35780483e-01 -6.00017051e-01 -2.58483126e-01  6.18729587e-01
 -2.43805077e-01  5.65300571e-01 -2.36398124e-01  5.34833905e-01
  2.90763959e+00]
supnorm grad right now is: 2.907639593806654
Weights right now are: 
[  1.14844873  -3.81561355  -2.81604354  -0.32136793  -1.93866796
   3.83007719   3.38734959   1.73645097   6.72253977   9.60871241
  10.60972799  10.69753163   5.76086623  -5.14170166  11.60211641
   0.54870738   7.74052677  -3.112705     1.75340261  -0.05407893
   7.43974469  -1.50880325   5.59743645   2.50565211  -1.65793159
  13.44571543   8.75984417  14.69482992  11.82484242  -1.55750324
  -1.47623037  -0.83244065  -5.8684237    2.00294426  -0.11890938
   1.73979382   9.38541145   3.35192066   5.19774999   3.24680431
  -4.61162942   6.53228592   7.2066981    7.22533129   4.76754569
  -9.64806097  -7.84769922  -8.2148209   10.8880772    0.17407756
  -0.13020029  -0.13273854   2.68106322 -15.82712322 -14.42750644
 -16.0491694    8.56268709   3.37195203  -1.41650081  -3.12460425
  -1.60063755  -3.24259576  -2.13095352  -3.5500631   25.89603519]
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2840.1940705267716
gradient value of function right now is: [-8.04081638e-04 -1.79905907e-03 -7.42844914e-02 -6.26226008e-03
  8.04081638e-04  1.79905907e-03  7.42844914e-02  6.26226008e-03
 -1.20678925e-05  2.54281586e-04  1.08139821e-03  1.31932843e-07
  2.53661413e-06 -1.67709735e-03 -3.32729822e-03 -5.41811694e-07
  9.86746136e-02 -5.91975611e-03 -1.41020012e-01 -5.95865418e-06
  6.46090352e-05 -2.94890689e-04 -1.84214463e-03 -1.58862548e-07
 -5.71492086e-01 -2.49668484e-02 -9.05389811e-04 -1.17122494e-01
 -9.52831907e-03 -1.82473403e-02 -1.23369637e-03 -2.62591675e-02
  5.03998509e-02  5.68102332e-02  4.05295888e-03  9.23138827e-02
 -2.12915947e-07  4.14787150e-07  5.88594128e-08  8.18914965e-07
  1.23593899e-02  1.43833513e-02  1.53928277e-02  1.79096977e-02
  1.58158303e-01 -9.97705754e-04 -1.19353720e-03 -1.79041118e-03
  2.27271262e-03 -3.75906007e-04 -4.09343408e-04 -4.95500069e-04
  8.90408651e-01  2.42868562e-02  2.43819830e-02  2.35399599e-02
 -7.22903272e-01  2.00048061e+00  1.84041984e-02 -2.79883292e-01
  8.22997427e-03 -2.40796971e-01  7.89200472e-03 -2.59637096e-01
 -4.05666080e-03]
supnorm grad right now is: 2.000480610932964
Weights right now are: 
[  1.59035318  -3.50401165  -3.16836596   0.29804941  -2.38057241
   3.51847529   3.73967201   1.11703364   6.11001718   9.37172728
  10.41473787  10.69374093   7.00911753  -5.31309436  12.30077652
   0.6309303    8.54505631  -3.18691732   1.19675401   0.15122548
   7.83134519  -1.04092709   6.65862087   2.65203517  -2.38884024
  13.21001688   8.28403178  14.27432192  12.20757338  -1.51426343
  -1.91926608  -0.63716881  -6.06586138   2.04378632   0.43303928
   1.64111042  10.14084561   3.7527654    5.40654706   3.84611183
  -4.99178441   6.45373097   7.10684222   7.12459702   5.74893823
  -9.03614729  -7.23767761  -7.64415735  12.44539953   1.16879615
   0.88226493   0.83762694   3.42988929 -15.57463878 -14.23434297
 -15.97453955   8.69378596   3.58426131  -1.4041437   -3.93813871
  -1.6276736   -3.97588656  -2.25366222  -4.13721088  25.9393299 ]
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2838.9062154755475
gradient value of function right now is: [-3.18293573e-03 -3.35162490e-03 -9.44119224e-02 -1.09776261e-02
  3.18293573e-03  3.35162490e-03  9.44119224e-02  1.09776261e-02
 -2.25273380e-06  1.42056101e-04  1.98945641e-03  8.24015290e-08
  2.42410650e-06 -4.56401354e-04 -5.13800468e-03 -2.25029826e-07
  8.04012858e-02 -1.56412434e-03 -2.44899718e-01 -6.29918139e-06
  9.24720199e-05 -1.75539762e-04 -5.56550064e-03 -1.79639720e-07
 -4.09804247e-01 -9.01229173e-03 -8.31302110e-05 -7.23392252e-02
 -4.17503331e-03 -4.12005065e-03 -1.34222226e-03 -6.49602609e-03
  7.60097284e-02  4.68769346e-02  1.15761549e-02  8.17095170e-02
 -6.43428825e-07 -3.84106180e-07 -6.02467802e-08 -7.62620932e-07
 -1.85080328e-02  3.23762698e-03  3.75352389e-03  4.39421400e-03
  6.19963010e-02 -1.32535755e-03 -1.59604321e-03 -1.99422293e-03
 -9.17101153e-04 -2.23871986e-04 -2.56385910e-04 -2.91580535e-04
  6.49945246e-01  1.56642374e-02  1.57532413e-02  1.37105750e-02
 -2.41709003e-01  9.66456728e-01 -1.88183541e-03 -2.02879835e-01
 -7.59106112e-03 -1.78274391e-01 -1.50843272e-02 -1.61879870e-01
 -5.42169459e+00]
supnorm grad right now is: 5.421694587440075
Weights right now are: 
[  1.05731668  -4.05009739  -3.54814281  -0.20173806  -1.84753591
   4.06456103   4.11944886   1.61682111   6.68687473   8.77099739
  11.4109905   10.7434997    6.93391312  -5.77675049  12.27206245
   0.55979457   8.56356725  -3.26890398   1.02317897  -0.14957886
   7.7591994   -0.60355347   6.73913581   2.67204502  -2.42293729
  13.02606419   8.82012475  14.23740866  12.22174374  -1.50632057
  -1.68897671  -0.64964706  -4.82836362   3.00940681   1.17811781
   2.75091898  11.35403615   4.46728865   5.70900749   4.80278335
  -3.91896286   7.51909975   8.17519369   8.12423629   5.94724005
  -9.78779742  -8.00702699  -8.40631688  12.76773796   1.67970439
   1.41004212   1.41592887   3.41974175 -16.52757353 -15.23970913
 -16.97218848   9.46329578   3.33673136  -1.44106175  -3.68534926
  -1.68742504  -3.7037013   -2.28468036  -3.90555635  25.41551416]
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2838.003863864333
gradient value of function right now is: [-1.22726571e-03 -3.04168440e-03 -2.49515695e-01 -1.08145701e-02
  1.22726571e-03  3.04168440e-03  2.49515695e-01  1.08145701e-02
  6.48288358e-06  2.99816604e-04  1.98133827e-03  8.89055602e-08
 -6.56225387e-06 -2.46820982e-03 -8.33807748e-03 -5.60822977e-07
 -6.02890422e-02 -2.14639138e-02 -8.88778873e-01 -1.32414656e-05
 -8.57779591e-05 -1.07647559e-03 -8.84821521e-03 -3.57883598e-07
  3.27450207e-01  2.51453090e-03 -1.20858494e-05  8.07252631e-02
 -6.38023982e-02 -1.92129452e-02  2.46408449e-04 -1.11830184e-01
  2.11325382e-01  4.85658972e-02 -5.57293898e-04  3.19024749e-01
  6.31861184e-06  8.01844831e-07 -1.89157428e-08  6.56357663e-06
  6.29844267e-01  5.86297936e-02  5.96087908e-02  8.18836947e-02
 -1.59487447e-01 -1.35736536e-02 -1.38471276e-02 -1.94302230e-02
  2.10207992e-04 -1.53283815e-06  7.17480491e-07  3.19424520e-05
 -9.33426794e-01 -3.17841967e-02 -3.17305631e-02 -4.37706185e-02
  3.68471288e-01 -1.37631473e+00 -3.83389136e-01  1.61251508e+00
 -3.79305416e-01  1.57384374e+00 -5.59254931e-01  2.27803718e+00
  6.71870026e-01]
supnorm grad right now is: 2.2780371821348098
Weights right now are: 
[  1.47684985  -3.74333948  -2.60018921  -0.21805893  -2.26706909
   3.75780312   3.17149525   1.63314198   6.88534552  10.13105129
  11.34465056  10.78485377   6.96870184  -5.25648099  11.99793316
   0.63875406   8.22210833  -5.52253627   2.1379541    0.70519616
   7.73644168   0.13082953   7.76654785   2.71050212  -2.0288058
  13.05361442   8.88022091  14.56316488  10.72564736  -3.4469222
  -4.03875425  -2.3627599   -5.68505041   3.19416972   1.03666059
   3.00061454  11.33172645   4.41942549   5.72874025   4.872042
  -3.38678993   8.9065116    9.51604062   9.59456487   5.94750092
 -10.68820221  -8.84844147  -9.42308763  12.96374996   0.96216245
   0.74038489   0.34331473   2.85743958 -17.71214265 -16.34467813
 -18.12999393   9.65028053   3.40465343  -2.44720215  -2.74962328
  -2.74260749  -2.81153333  -3.68959794  -2.79418824  25.46398596]
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2837.3066373252163
gradient value of function right now is: [-2.16078781e-03  4.98864011e-03 -7.49585057e-01 -3.94622190e-03
  2.16078781e-03 -4.98864011e-03  7.49585057e-01  3.94622190e-03
  3.24120526e-05  9.96879005e-04  5.19393756e-03  1.11689000e-07
 -2.69205298e-07  1.68195935e-03 -1.88901530e-03  1.72614581e-07
 -1.99356796e-01 -1.45872012e-02 -3.39347535e+00 -1.45401753e-05
  1.91183937e-05 -1.21711034e-03  3.01440918e-03 -8.63212739e-08
  1.22846413e+00  2.14202872e-02  5.72218293e-04  2.90940930e-01
 -2.32213038e-02 -3.69840132e-02 -1.21469609e-02 -5.74909069e-02
  2.61861732e-02  1.36701999e-02  3.99596116e-03  3.14357351e-02
  4.56288012e-06  4.99826257e-07  9.45825747e-08  1.93574751e-06
  1.22946605e-01  1.21035427e-02  1.23087734e-02  1.74844114e-02
 -1.66456990e-01 -3.38088516e-03 -3.36156108e-03 -4.74406356e-03
 -3.94969668e-03 -7.54131105e-04 -7.96071999e-04 -1.37136952e-03
 -2.34989541e+00 -3.18395742e-02 -3.02826205e-02 -3.81579752e-02
  1.18637913e+00 -3.79281173e+00 -2.36073614e-01  9.13916537e-01
 -2.17651384e-01  8.24800025e-01 -3.22517228e-01  1.17325446e+00
  7.07905089e+00]
supnorm grad right now is: 7.079050891837332
Weights right now are: 
[  2.84859297  -2.24581626  -3.47107437   1.46997003  -3.63881221
   2.2602799    4.04238041  -0.05488699   6.82831198   8.31090729
   9.86933176  10.76155429   6.97821353  -2.74500136  14.29295682
   0.7060157    8.92954059  -3.65667526   0.41298934   0.44620255
   7.79487571   1.03372886   8.6692652    2.72371074  -2.0950709
  13.52668682   8.96716085  15.42394614  12.70637793  -1.63043792
  -2.79183477  -0.20180403  -6.43054652   2.10761319   0.42860789
   1.674484    11.79347212   4.55338366   5.74837832   5.08013937
  -4.67844565   7.42508024   8.0100932    7.73200646   6.70108122
  -9.13525283  -7.28656993  -7.56096192  13.73688057   2.3963536
   2.14876877   1.92820217   2.52693619 -19.16823398 -17.83556499
 -19.68680736   9.79413999   3.31651522  -1.36892395  -3.61400022
  -1.6271923   -3.712196    -2.52582201  -3.75387088  25.78344696]
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2837.241297842012
gradient value of function right now is: [ 3.18374274e-03  7.90297896e-04  1.57640510e+00  5.52471258e-03
 -3.18374274e-03 -7.90297897e-04 -1.57640510e+00 -5.52471258e-03
 -1.44498035e-04 -1.14968060e-03 -2.07353746e-02 -1.29069178e-07
  4.19857127e-06  1.17088504e-03  6.06232916e-03  3.33784635e-08
  7.25422595e-02  6.45671226e-02  5.76763872e+00  1.43323245e-05
 -6.65444900e-05 -7.68773820e-04 -1.10819114e-02 -7.18673679e-08
 -5.68377361e-01 -1.03788303e-02 -6.32131346e-04 -1.55434829e-01
  7.04709572e-02  1.40834469e-01  5.09999760e-02  1.99538556e-01
 -2.05402193e-01 -2.84869459e-01 -9.35983853e-02 -4.51330141e-01
 -1.09645735e-05 -6.02644469e-06 -1.43778835e-06 -1.17690278e-05
 -2.57624248e-01 -1.00714599e-01 -9.24591248e-02 -1.67544306e-01
  1.07056138e-01  1.78100354e-02  1.62827764e-02  2.90723671e-02
  4.32974101e-03  2.48776317e-03  2.20917083e-03  6.85478167e-03
  1.22401080e+00  2.60603933e-02  2.09197502e-02  3.31357922e-02
 -1.10431346e+00  2.52551127e+00  3.57238123e-01 -9.43500811e-01
  3.10704792e-01 -7.82627159e-01  7.28597139e-01 -1.55557699e+00
 -9.34807979e+00]
supnorm grad right now is: 9.348079789117481
Weights right now are: 
[  3.87913872  -6.4906479   -2.13934564   2.05698048  -4.66935795
   6.50511154   2.71065168  -0.64189743   7.29658832   7.93236677
   8.85687167  10.74687671   6.96941381  -6.73876023  12.87332963
   0.03350448   9.75241134  -3.3267519    1.58411882   1.33245584
   7.83926448   3.34968759   8.37838      2.73214247  -2.50906973
  13.91788657   9.17980271  15.65047093  14.19532428  -1.76225129
  -2.80583197  -0.04769626  -8.02884494   1.54419381  -0.36161146
   1.01901543  11.59828689   4.63699739   5.8214627    4.918005
  -6.25332579   5.93373045   6.49737458   6.49489795   7.29748989
  -7.97519536  -6.07046232  -6.40342463  14.06508858   2.62555272
   2.49668559   2.35479355   2.74038786 -20.5387307  -19.16186316
 -20.92024517   9.4171703    3.7701747   -0.93363169  -4.00216604
  -1.11614797  -4.25863393  -2.39343262  -4.12972458  25.67392684]
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2841.031181840617
gradient value of function right now is: [-2.50416451e-04 -6.89163109e-04 -3.61140840e-01 -4.83212628e-04
  2.50416451e-04  6.89163110e-04  3.61140840e-01  4.83212628e-04
  3.47862965e-06  1.82816251e-04  1.21111796e-03  8.62933545e-09
 -5.44273870e-07 -2.17290963e-03 -3.58521549e-03 -5.09038748e-08
 -1.05309541e-02 -2.43903456e-02 -1.48949920e+00 -2.36358230e-06
  8.84411158e-07  1.06537681e-04  4.40541376e-04  4.10182019e-09
  7.50533327e-02 -9.25714453e-04 -1.30063637e-04  3.88695570e-02
 -3.54417403e-02 -6.09327647e-02 -8.91439477e-03 -9.94897524e-02
  3.64543983e-02  5.46710921e-02  8.48907486e-03  9.27467154e-02
  2.03674972e-06  8.26477352e-07  5.21851289e-08  2.20847636e-06
  1.03115492e-01  4.20378507e-02  4.20140022e-02  6.11837684e-02
 -2.06923302e-02 -9.60811510e-03 -9.58202498e-03 -1.38292519e-02
 -3.43350204e-03 -1.78394495e-03 -1.81605114e-03 -3.38263704e-03
 -2.84589641e-01 -1.06270246e-02 -9.94360734e-03 -1.40820455e-02
  2.24736350e-01 -4.69831429e-01 -2.17739683e-01  5.27956975e-01
 -2.09146978e-01  4.99620901e-01 -3.21045008e-01  7.61502120e-01
  2.37461424e+00]
supnorm grad right now is: 2.374614236979625
Weights right now are: 
[  3.33458011  -6.24101034  -2.84265547   1.50008594  -4.12479935
   6.25547398   3.41396151  -0.08500289   8.85637336   8.29486217
  10.05303076  10.74864607   6.83286503  -6.38617698  13.30663958
   0.06829927   9.619797    -4.35867057   1.07490637   1.28796828
   8.69246716   3.34957295   9.92073423   2.73653978  -2.35331775
  14.14473656   9.95063939  15.83122806  13.35647458  -2.51956323
  -4.17664534  -0.83521331  -7.64231864   1.93369855   0.76875931
   1.33814116  11.60124133   4.80173708   5.87008949   5.05276817
  -6.59882453   6.10095772   6.71982921   6.82384643   7.66925835
  -7.92641566  -6.07662843  -6.34744728  13.96798682   1.34243267
   1.16572303   1.00709586   2.5959607  -21.8689304  -20.57106182
 -22.12715577   9.73944639   3.71385069  -1.70470022  -3.50916215
  -1.99323014  -3.65198968  -3.23126493  -3.7764833   25.86296911]
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2838.040989709908
gradient value of function right now is: [ 2.18062814e-04 -1.40769395e-04  3.96062571e-01  2.46594007e-04
 -2.18062814e-04  1.40769395e-04 -3.96062571e-01 -2.46594007e-04
 -2.63419307e-05 -2.20348305e-05 -1.61510441e-03 -1.14661477e-08
  8.53670449e-07 -1.80297729e-03 -1.11947065e-03  3.02294676e-08
  2.20415758e-02  1.52483149e-02  1.72604556e+00  1.21005069e-05
 -5.85940735e-06 -6.55011830e-06 -3.89775095e-04 -2.78584699e-09
 -1.74671928e-01 -9.07973375e-03 -1.72019176e-03 -6.07464933e-02
  9.70432139e-02  2.67724664e-02  1.04794504e-02  9.31978073e-02
 -4.22092625e-02 -7.42023196e-03 -1.15732858e-03 -4.04252629e-02
 -1.48381406e-05 -3.23163192e-06 -1.18244249e-06 -9.57344942e-06
 -2.10433712e-01 -1.90142642e-02 -1.95282766e-02 -2.56788672e-02
  8.03842041e-02  3.57817420e-03  3.70498802e-03  5.19395624e-03
  1.46477563e-02 -1.98999709e-04 -2.68837708e-04 -9.75454719e-04
  3.78580284e-01  1.17370305e-02  1.20053657e-02  1.73050319e-02
 -7.34052866e-01  1.95197796e+00  7.49789293e-02 -3.32339303e-01
  7.59955594e-02 -3.30582837e-01  1.29318049e-01 -5.19572483e-01
 -4.22947804e+00]
supnorm grad right now is: 4.229478041880064
Weights right now are: 
[  3.37442925  -5.55711139  -1.90005327   1.52045311  -4.16464849
   5.57157503   2.47135932  -0.10537006   8.31539786   8.3657211
   9.98173721  10.74875789   6.95958489  -5.46344233  14.06836068
   0.1047432   10.43433014  -6.37535428   2.32260943   1.69928657
   8.47829764   3.33221245   9.92883808   2.7364417   -3.14781166
  12.99215983   9.53135648  14.88246091  10.97644697  -4.30183088
  -6.14466021  -2.865932    -7.76014909   2.12209635   1.46120892
   1.48236155  11.06811544   4.93796808   5.88458109   5.04823159
  -4.56282393   7.70071607   8.33578539   8.50463989   6.96127489
  -9.29986102  -7.4661005   -7.92459116  11.68480763  -0.77147686
  -1.11775029  -0.73745855   3.54260995 -21.38780284 -19.9079443
 -21.13260782  10.17482265   3.62625538  -1.10624027  -4.05566088
  -1.57075809  -4.13020263  -3.41685389  -4.17764612  25.76829357]
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -2838.9974102905167
gradient value of function right now is: [-2.62127363e-06 -3.75724329e-04 -1.03701293e-01 -1.05614490e-05
  2.62127363e-06  3.75724332e-04  1.03701293e-01  1.05614491e-05
  1.58540847e-06  3.45415948e-06  1.66338611e-05  9.04139492e-10
 -1.08547099e-07 -3.61577291e-03 -2.06175744e-03 -2.00410974e-08
 -5.56211586e-03 -4.75352194e-02 -2.28184956e-01 -4.05624860e-06
  4.33139517e-07  3.87279123e-06  1.23209114e-05  2.70813841e-10
  3.47508221e-02  5.50042544e-03  1.69528832e-03  1.60283151e-02
 -1.25659850e-01 -7.76414005e-02 -4.25934283e-02 -1.67448745e-01
  2.23543947e-02  1.82602416e-02  9.83099673e-03  3.45446322e-02
  5.58950872e-06  7.82445807e-07  3.18323570e-07  2.77768910e-06
  1.20703660e-01  1.15222248e-02  1.27751233e-02  3.58897410e-02
 -6.74950692e-02 -4.50172663e-03 -4.94496135e-03 -1.35815804e-02
 -3.93303573e-02 -2.59293132e-03 -2.90249817e-03 -9.64912444e-03
  6.14888501e-02  4.39537045e-03  3.81800822e-03  3.61815152e-04
  8.41354378e-01 -1.97022919e+00 -6.13789949e-02  4.08896440e-02
 -6.99230754e-02  7.21554700e-02 -2.55374505e-01  4.69316009e-01
  7.44545820e+00]
supnorm grad right now is: 7.445458197866943
Weights right now are: 
[  3.09925773  -5.58584445  -2.55507972   1.35692319  -3.88947697
   5.60030809   3.12638576   0.05815986   8.99430546   8.36909449
  10.49634297  10.74918022   6.8998989   -5.15160859  14.4748661
   0.09666642   9.73157881  -6.30023687   1.60407055   1.71438428
   8.70423791   3.35064487  10.17178931   2.73655418  -2.50002414
  12.79726707   9.96762735  15.39220226  11.02747145  -4.61249714
  -7.51421879  -2.44452517  -7.79887672   2.17645543   2.07069057
   1.22005014  11.24042541   5.05001001   5.95172637   5.16338436
  -5.42739354   6.82421305   7.4717466    7.7666471    7.9307938
  -8.475994    -6.65247032  -7.19343461  10.82775166  -0.93546716
  -1.4016605   -1.43829111   2.71134169 -22.95157336 -21.46889443
 -22.69072799  10.73694114   3.5238576   -0.95639673  -4.16056806
  -1.45061374  -4.28258335  -3.61402145  -4.21088433  26.17360179]
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -2839.0833531183807
gradient value of function right now is: [ 7.08906515e-05 -3.63306129e-04  2.86987157e-01  1.13237518e-04
 -7.08906515e-05  3.63306130e-04 -2.86987157e-01 -1.13237518e-04
 -9.64805544e-06 -3.18006533e-06 -4.96278623e-04 -1.31913660e-09
  9.41444690e-08 -5.14362251e-03 -2.13246036e-03 -3.96072464e-08
  2.81093244e-02 -2.86141407e-03  1.45422159e+00  3.82519416e-06
 -3.81870861e-06 -7.15506561e-07 -1.89494734e-04 -4.63156375e-10
 -2.28835227e-01 -1.92587572e-03 -5.43447033e-04 -7.34608262e-02
  1.38736903e-02 -1.01506029e-02 -7.19505920e-03  1.10647982e-02
 -2.44049732e-02  8.87086011e-03  6.94380668e-03 -1.81720237e-02
 -5.47685140e-06 -5.97775244e-07 -3.08722871e-07 -3.65700345e-06
 -9.80382312e-02 -1.30308749e-02 -1.22742733e-02 -9.69275952e-03
  1.86184561e-02  1.12668223e-03  9.17916884e-04 -2.82356071e-04
 -2.55784463e-03 -9.12837822e-04 -1.03771176e-03 -2.18420444e-03
  5.54941977e-01  1.44260576e-02  1.34392794e-02  1.35345533e-02
 -1.58884039e-01  7.10732707e-01  4.81855199e-02 -3.49962668e-01
  4.03036117e-02 -3.05851577e-01  2.43452337e-02 -2.80599601e-01
 -5.05141865e+00]
supnorm grad right now is: 5.051418651328265
Weights right now are: 
[  3.17909587  -4.70205262  -2.32303366   1.592893    -3.96931511
   4.71651626   2.89433971  -0.17780995   8.69123569   8.07536181
  10.56353673  10.74910607   6.92418804  -3.53005681  15.85610141
   0.10699758  10.41767014  -6.62970035   1.82184143   1.80404003
   8.61335196   3.28272939  10.10931784   2.73650833  -2.91634812
  13.05968223  10.52267725  15.03974276  10.5581268   -5.13009871
  -8.02582612  -2.88699083  -6.95500793   2.02159963   2.22888154
   1.8517698   11.11536984   5.25325702   6.09018569   5.26671079
  -4.96772176   7.26654986   7.90319916   8.29849403   7.92529242
  -8.6299233   -6.82383538  -7.57864736  10.28875729  -1.46340052
  -1.97537549  -2.01428987   2.82778228 -24.30531821 -22.61531555
 -22.87489039  11.14201954   3.5646131   -0.21812543  -3.97520501
  -0.84857413  -4.15737369  -3.07686856  -4.52089158  25.56129093]
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2837.7981476829295
gradient value of function right now is: [ 2.26425606e-05 -5.57452413e-05  2.33941924e-01  3.98526912e-05
 -2.26425606e-05  5.57452418e-05 -2.33941924e-01 -3.98526911e-05
 -1.97136777e-06 -2.00707978e-06 -1.06120747e-04 -5.40738335e-10
  4.63879088e-08 -6.50944032e-04 -2.56371249e-04 -7.53205362e-09
  4.69554121e-02  4.95674711e-03  1.08148891e+00  3.33951148e-06
 -2.21140531e-07  3.12032034e-07 -1.12017944e-05 -5.68967640e-11
 -3.57966525e-01 -2.48915382e-03 -4.33914206e-04 -9.30585417e-02
  1.90859564e-02  1.69120120e-03  1.57022973e-03  2.34314678e-02
 -5.19120573e-02 -1.76572785e-03 -1.27347409e-03 -5.76891957e-02
 -3.82284776e-06 -2.79770643e-07 -1.10672791e-07 -2.01412907e-06
 -1.49231010e-01 -1.50691383e-02 -1.57414640e-02 -1.59461261e-02
  2.19029491e-02  6.02327224e-04  5.11271174e-04  2.18780988e-04
  3.73291325e-03 -4.67397479e-05 -5.52901047e-05  9.70241237e-05
  8.60711121e-01  1.18769382e-02  1.39289081e-02  2.19519813e-02
 -3.47441211e-01  1.06933861e+00  4.90135504e-02 -4.11967306e-01
  5.88884491e-02 -4.62533108e-01  1.49050366e-01 -8.08021871e-01
 -9.19926159e+00]
supnorm grad right now is: 9.199261589628437
Weights right now are: 
[  2.34218008  -5.30077017  -2.65100713   0.83554078  -3.13239931
   5.31523381   3.22231317   0.57954227   8.92845221   7.9389793
  11.75236801  10.74932849   6.92208372  -3.30528321  16.43442592
   0.12766978   9.54817521  -6.27253997   1.46530928   1.41115847
   8.76368435   3.48316075  11.10384979   2.7364906   -2.17840264
  13.48176688  11.32021882  15.27604304  11.17794464  -4.36689769
  -6.66104587  -3.02032445  -6.53664465   2.06631413   1.47869718
   2.69618954  11.51845101   5.40588314   6.1165911    5.80147872
  -4.33594607   8.31346279   9.04565308   9.66470079   7.84654744
  -9.88708007  -8.15472672  -8.90738847  11.15047345  -2.24480614
  -2.88069732  -2.83744431   2.67099089 -24.64240282 -23.15651339
 -23.88153747  10.76230818   3.89140538  -1.63388236  -3.6171572
  -2.4669691   -3.58986161  -4.61038958  -3.58121802  25.17571323]
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2839.5520194698597
gradient value of function right now is: [-2.92752574e-04 -4.26986740e-04 -2.37536338e-01 -5.43593373e-04
  2.92752574e-04  4.26986740e-04  2.37536338e-01  5.43593373e-04
 -1.39544829e-07  4.96523434e-05  3.01149829e-04  2.31658541e-09
  1.01997744e-07 -6.07857655e-04 -1.53094616e-03 -2.11615604e-08
  4.68344565e-02 -7.91561337e-03 -9.03728270e-01 -1.10851403e-06
  1.17683109e-07 -6.00802075e-05 -2.74772553e-04 -2.47764150e-09
 -2.84473436e-01 -2.68820992e-03 -6.41158816e-04 -4.28072933e-02
 -2.71101736e-02 -8.35707917e-03 -2.52296526e-03 -3.90205761e-02
  7.71089055e-02  1.04736555e-02  2.55838771e-03  8.84545020e-02
  9.65229152e-07  1.77100849e-07  5.48790654e-08  1.36885068e-06
  8.49151477e-02  9.93977159e-03  1.09855010e-02  1.55165743e-02
  1.36101873e-03 -1.48388801e-03 -1.70173190e-03 -2.63802173e-03
 -3.94629240e-04 -2.60386578e-04 -3.21093133e-04 -6.14342560e-04
  4.69343961e-01  4.04249991e-03  2.57217246e-03 -1.19830187e-03
 -1.35938431e-01  3.95187288e-01 -6.13155835e-02 -1.83620426e-02
 -7.41018179e-02  4.24583582e-02 -1.25455280e-01  1.94385532e-01
  1.28840008e+00]
supnorm grad right now is: 1.2884000806338343
Weights right now are: 
[  0.95201027  -6.47086905  -3.37093432  -0.05874698  -1.74222951
   6.48533268   3.94224036   1.47383003   8.95052617  10.12478688
  13.02860324  10.74960924   6.92754534  -4.30948736  15.55288931
   0.12167169  10.07047306  -6.00011921   0.78444469   1.31310616
   8.76524921   3.04571019  12.55836802   2.73698449  -2.54437225
  13.87279866  12.15349288  15.13608096  11.5050379   -4.11923224
  -6.34548964  -2.83460311  -5.83730749   2.21040497   1.23868716
   3.71339348  11.63019132   5.44346922   6.12389776   5.89804287
  -4.30102245   8.45001041   9.29522352   9.98276354   7.96477679
 -10.1863615   -8.44934699  -8.98994423  11.40633944  -2.31908454
  -2.93241259  -2.63633864   2.93405162 -25.65051818 -23.90076371
 -23.91060736  10.66853982   4.29922879  -1.26487642  -3.54617561
  -2.00924524  -3.72804144  -3.97460138  -4.15460343  25.75238056]
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2831.68034172846
gradient value of function right now is: [ 2.60484497e-04  6.06362170e-04  8.97754707e-01  1.67493855e-04
 -2.60484497e-04 -6.06362171e-04 -8.97754707e-01 -1.67493855e-04
 -5.65739128e-06 -9.60698947e-05 -1.09246348e-03 -2.26534361e-08
  2.32953815e-08 -1.82951796e-03 -5.54059086e-04  7.43644944e-08
  4.60917034e-02  5.19650073e-02  3.37798788e+00  6.70517226e-06
 -5.46362708e-07 -1.22167688e-04 -2.14781755e-04 -1.44490401e-08
 -3.73194604e-01 -1.03483746e-02 -6.07413983e-03 -1.34001619e-01
  1.28010650e-01  8.28995629e-02  6.54142588e-02  1.69393065e-01
 -2.52661602e-01 -9.07527511e-02 -6.16904729e-02 -3.18673320e-01
 -5.91646256e-06 -1.12131251e-06 -6.09618758e-07 -5.45474964e-06
 -2.90800246e-01 -5.20280703e-02 -5.55788382e-02 -8.34625002e-02
  7.96849435e-02  6.85396344e-03  7.61399653e-03  1.36902030e-02
  5.67329563e-02  3.04569175e-03  3.88868814e-03  1.10069283e-02
  6.66158536e-01  2.03638463e-02  2.06238697e-02  2.93141708e-02
 -1.90764044e+00  3.07874110e+00  2.12599134e-01 -5.08473478e-01
  2.39635601e-01 -5.30788277e-01  5.15040921e-01 -9.42216233e-01
 -2.47788217e+00]
supnorm grad right now is: 3.3779878788157447
Weights right now are: 
[  2.68525145  -4.4668489   -2.0763746    2.1603251   -3.47547069
   4.48131254   2.64768064  -0.74524205   8.95638452   8.08577723
  11.59574306  10.74601321   6.92343276  -2.44586665  17.95015869
   0.19431391  10.46144905  -5.19742492   2.01037235   1.37360259
   8.7665487    3.20594799  13.22669569   2.73465149  -3.20557835
  13.7751142   13.44337376  14.2141495   12.43978134  -3.65498058
  -6.95412419  -1.19623177  -6.96702106   1.48366906   2.10256615
   2.21132538  11.64660356   5.48640456   6.14567708   5.88315176
  -6.39866437   6.08068468   6.90432319   7.63938207  10.10104332
  -7.05680038  -5.37393166  -6.19127994  11.77738989  -1.02213509
  -1.80340458  -2.10692969   3.64228425 -25.02646233 -23.24883787
 -23.07253456   9.95524899   5.20711847   0.33561781  -4.87140981
  -0.39713271  -5.12924747  -2.57850156  -5.60110293  26.39342325]
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2839.713890962661
gradient value of function right now is: [-1.94094334e-03 -1.41414208e-03 -3.31954274e-01 -1.80547571e-03
  1.94094334e-03  1.41414208e-03  3.31954274e-01  1.80547571e-03
  3.41010921e-07  4.67086406e-04  2.30991615e-03  2.86220552e-08
 -2.15769180e-08 -1.78081823e-03 -3.74762072e-03 -5.92304492e-08
 -3.22484073e-02 -1.78179927e-02 -1.15989204e+00 -1.91503051e-06
  2.29552380e-08  1.28666901e-04  4.92380301e-04  6.79949377e-09
  2.46709857e-01 -3.29336903e-04 -2.21947888e-04  7.88786323e-02
 -5.73105386e-02 -1.23728008e-02 -4.13626969e-03 -1.06814156e-01
  1.37998440e-01  1.98357014e-02  6.56812033e-03  1.94656957e-01
  1.39096148e-06  4.70573699e-08 -7.24512868e-10  1.36614431e-06
  2.73211356e-01  2.55380937e-02  3.77807340e-02  5.30833025e-02
 -2.87166492e-02 -2.65594363e-03 -4.26606180e-03 -6.62252141e-03
 -1.42446836e-02 -1.25497344e-03 -2.18354807e-03 -3.72347116e-03
 -8.20771896e-01 -1.80979469e-02 -2.46928124e-02 -2.35490898e-02
  4.14103710e-01 -1.19266818e+00 -2.06562027e-01  9.00876379e-01
 -3.11495836e-01  1.24791731e+00 -4.17512257e-01  1.43419019e+00
  2.41645877e+00]
supnorm grad right now is: 2.416458768383457
Weights right now are: 
[  1.53537282  -5.03374579  -2.63794628   1.19332329  -2.32559206
   5.04820943   3.20925233   0.22175976   9.0120717    9.1444775
  13.1543006   10.74973192   6.9219762   -2.59633732  17.6320688
   0.189903    10.02991509  -6.2439246    1.64633762   1.12668066
   8.76881349   4.21577598  14.52178393   2.7367276   -2.57897584
  15.65235638  15.40802349  15.44490675  11.57339229  -4.54463953
  -7.7819545   -2.47417019  -6.08770419   1.93075854   2.3317467
   3.82415243  11.83526136   5.5070509    6.14467528   6.11025873
  -4.41133603   7.71459181   8.69642755   9.66486619   8.62324705
  -7.68331037  -6.06808005  -7.09448694  10.29661265  -2.12352421
  -2.95951011  -3.27477845   2.65322468 -27.55549454 -25.92856472
 -25.34448674  11.54634942   3.99500037  -0.60515134  -2.97366323
  -1.63050332  -2.94188909  -4.1717749   -3.52329396  25.66120772]
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2838.0204297327646
gradient value of function right now is: [-1.17125241e-05 -1.04303183e-04 -2.47056223e-01 -1.72735386e-05
  1.17125241e-05  1.04303183e-04  2.47056223e-01  1.72735386e-05
 -5.10034959e-08  7.40601266e-06  2.74371240e-05  3.15046533e-10
  1.98413479e-09 -1.04540861e-03 -3.76033962e-04 -9.93732673e-09
  1.89850580e-02 -2.28436784e-02 -9.20716485e-01 -3.74454589e-06
 -4.33899531e-09  6.16632428e-06  8.73609806e-06  3.11099937e-10
 -1.27368299e-01  5.11930816e-03  3.37581940e-03 -2.45210071e-02
 -7.61426167e-02 -3.37945622e-02 -2.82749914e-02 -6.55313344e-02
  5.15486759e-02  1.95282263e-02  1.57274249e-02  3.76921001e-02
  2.74400080e-06  4.53134750e-07  3.45348718e-07  1.31965075e-06
  6.04945217e-02  3.03095861e-04  1.06233459e-03  4.95762650e-03
 -4.79895840e-02 -5.99517967e-04 -8.59335785e-04 -2.17428654e-03
 -4.75058312e-02 -7.76778589e-04 -1.07852611e-03 -2.64594465e-03
  4.05953942e-01  1.19478991e-02  1.13510006e-02  8.53398703e-03
  6.97661259e-01 -1.86429824e+00  1.67208421e-02 -2.93393190e-01
  6.18212623e-03 -2.42265579e-01 -4.13135336e-02 -8.45374591e-02
 -3.70820754e+00]
supnorm grad right now is: 3.708207544060204
Weights right now are: 
[  1.54400465  -4.85166864  -3.06909068   1.35460423  -2.33422389
   4.86613228   3.64039672   0.06047882   9.00895559   9.15087785
  13.23124257  10.74954937   6.92240889  -2.20254964  18.19675389
   0.2028227    9.94749376  -6.15846929   0.88483166   0.98384721
   8.76943496   4.18791119  14.69721782   2.73665036  -2.70877356
  16.90371958  16.85743854  15.14405708  11.56666912  -4.86264812
  -8.26374268  -2.38975032  -6.44047251   2.20125251   3.01668583
   3.17537701  11.99839555   5.53651376   6.16656443   6.12551008
  -4.68703615   7.86351444   8.79462728   9.50491415   8.3413865
  -7.37367417  -5.83048684  -6.80799436   9.57300239  -1.90577026
  -2.92573188  -3.3876834    3.05020983 -27.35763186 -25.47806352
 -24.98006413  12.17560592   3.56855847   0.59212699  -3.74475478
  -0.43929995  -3.87838197  -3.44305189  -4.32535925  25.34430396]
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2835.9569968245187
gradient value of function right now is: [ 1.36315297e-04  7.08129291e-04  1.17621904e+00  2.51150797e-05
 -1.36315297e-04 -7.08129291e-04 -1.17621904e+00 -2.51150797e-05
 -1.97095324e-05 -5.46348152e-05 -9.78160020e-04 -1.73739253e-07
  3.40664122e-09  5.46346863e-03  1.29625773e-03  2.98266225e-07
  1.38676270e-01  9.53415006e-02  3.78431611e+00  7.03326721e-05
 -9.09376300e-07 -2.22973444e-05 -6.79561720e-05 -3.77414857e-08
 -1.07969612e+00 -6.78443226e-03 -3.74466630e-03 -2.83198736e-01
  8.94620816e-02  1.20254823e-01  9.64026520e-02  2.17641130e-01
 -3.87112926e-02 -5.64765702e-02 -3.77014965e-02 -1.06158617e-01
 -4.52049617e-05 -2.52351454e-05 -4.76554847e-06 -1.48766777e-04
 -8.34041253e-02 -4.91066032e-02 -4.01269245e-02 -6.25518559e-02
  5.45231818e-02  9.47564948e-03  7.89414314e-03  1.18245148e-02
  3.73358957e-02  1.64798289e-02  1.30013637e-02  2.34293080e-02
  2.00926009e+00  3.42119538e-02  2.30778389e-02  1.38274563e-02
 -1.78439244e+00  3.14942397e+00  4.22701719e-01 -1.01076876e+00
  3.00648684e-01 -6.72361227e-01  3.53245539e-01 -5.39032420e-01
 -5.47122240e+00]
supnorm grad right now is: 5.471222401562538
Weights right now are: 
[  3.6258195   -5.99759557  -2.25041817   2.65078504  -4.41603874
   6.01205921   2.82172422  -1.23570199   9.18300306   7.9737461
  10.51682342  10.74686151   6.92266379  -2.62653602  20.2523787
   0.33148668  10.42053069  -3.263959     0.71118717   2.30922137
   8.78659534   5.31403037  12.95574493   2.7465605   -2.73614797
  16.99199479  17.02916201  15.68148176  14.19774693  -2.67824605
  -6.53686229   0.79393471  -8.61970838   0.20571414   2.05290841
   0.52607555  10.95220032   4.65375232   5.86414407   4.90236495
  -7.45395445   4.58568767   5.72338391   6.22102739  10.65462256
  -3.89566573  -2.59113544  -3.49053888  12.142578     0.29468677
  -1.26397228  -1.33666801   2.67110763 -29.24280947 -27.30540579
 -25.90923298  10.09654955   5.36335242   0.86752132  -4.06657401
   0.97874984  -4.48808061  -1.18224869  -5.80809257  26.08942414]
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2837.774600556333
gradient value of function right now is: [-3.40715533e-05 -1.29822886e-04 -8.45264154e-01 -1.99289397e-05
  3.40715533e-05  1.29822885e-04  8.45264154e-01  1.99289397e-05
  6.73123578e-07  1.77466022e-05  1.22922441e-04  1.48382270e-09
 -2.61259421e-09 -9.10083298e-04 -4.71699107e-04  6.50407412e-09
 -8.00957515e-02 -3.17379104e-02 -3.08581514e+00 -4.02120731e-06
  4.87552877e-08  1.03961638e-05  2.33472314e-05  6.74976107e-10
  6.07588139e-01  7.86755147e-03  3.63837249e-03  1.66753494e-01
 -5.23011610e-02 -5.02086671e-02 -4.44588320e-02 -8.03164804e-02
  1.41088042e-02  1.20447464e-02  1.01187921e-02  2.22494358e-02
  2.84925731e-06  3.14083188e-07  1.95882920e-07  1.39721806e-06
  4.91660089e-02  8.17423181e-03  8.41354275e-03  1.39813086e-02
 -7.37495603e-02 -2.05920203e-03 -2.12211104e-03 -3.39564213e-03
 -4.04058014e-02 -2.70952338e-03 -2.80899024e-03 -5.29033155e-03
 -1.06908921e+00 -1.04010346e-02 -1.06598599e-02 -8.85738311e-03
  1.07640179e+00 -2.85821789e+00 -1.09728068e-01  3.66985171e-01
 -1.15185998e-01  3.70999317e-01 -1.42438335e-01  3.72732715e-01
  9.73350077e+00]
supnorm grad right now is: 9.73350077214323
Weights right now are: 
[  2.27272817  -6.51577225  -3.0147697    1.88455361  -3.06294741
   6.53023589   3.58607575  -0.46947056   9.43178133   9.60317881
  12.34102182  10.78361246   6.92236563  -3.35799515  19.31832047
   0.31128656   9.58782116  -4.05084523   0.23317727   0.85915458
   8.79908656   5.85387166  14.24120109   2.75302929  -2.13071791
  18.98788255  19.27862129  16.05413755  13.87528758  -3.23772793
  -6.93650125   0.0415236   -8.15182804   1.40576473   2.96149321
   1.63005106  11.88709415   5.18066014   6.11637409   6.09451648
  -6.524637     5.7563489    7.06383672   7.70452209   8.880299
  -5.3636297   -4.32010322  -5.17160399  10.55085887  -1.39740613
  -3.35954068  -3.10426249   2.57177438 -29.65685607 -28.17523291
 -26.85125846  11.6007095    4.21314847   0.6208881   -3.95065091
   0.55881913  -3.94162238  -2.10213767  -4.84312575  26.11581292]
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2835.398069175895
gradient value of function right now is: [-8.62367129e-06  1.06159518e-05 -1.03112892e+00 -1.31054652e-06
  8.62367129e-06 -1.06159521e-05  1.03112892e+00  1.31054652e-06
  2.19058505e-06  2.94372862e-07  4.92846919e-05  6.55978196e-11
 -2.21268186e-09 -6.12655404e-05 -3.73194463e-05  6.35973915e-10
 -4.19903284e-01 -2.66910214e-02 -4.10385181e+00 -7.09240062e-06
  1.71118949e-07 -3.76985599e-09  3.45536108e-06  3.61994651e-12
  2.59070097e+00  6.51034593e-03  1.26703170e-03  4.32562582e-01
 -4.49657618e-02 -4.46280885e-02 -3.99149867e-02 -6.47342482e-02
 -7.83888720e-05  4.53602677e-05  4.45445683e-04  1.59652069e-04
  3.74071455e-06  1.38764305e-07  8.65475195e-08  9.22517214e-07
  3.04966852e-02  3.67535358e-03  3.56835592e-03  7.09642579e-03
 -7.02068390e-02 -1.00543064e-03 -9.71412487e-04 -1.75254909e-03
 -1.64608205e-02 -1.44166013e-03 -1.39155286e-03 -3.17045027e-03
 -4.34999756e+00 -1.88767446e-02 -1.77909095e-02 -1.04998628e-02
  1.47760032e+00 -4.37760319e+00 -1.39175965e-01  6.57411541e-01
 -1.28986272e-01  5.93439089e-01 -1.10665441e-01  3.76212516e-01
  1.31752974e+01]
supnorm grad right now is: 13.175297428542713
Weights right now are: 
[ 2.47601699e+00 -6.17670914e+00 -3.09365751e+00  2.01515502e+00
 -3.26623623e+00  6.19117278e+00  3.66496356e+00 -6.00071974e-01
  9.54855869e+00  9.53694695e+00  1.21503782e+01  1.07845416e+01
  6.92213902e+00 -2.72727141e+00  2.05246892e+01  3.14223535e-01
  8.97494675e+00 -4.16938519e+00 -1.38507547e-02  5.59400178e-01
  8.80639554e+00  5.76316351e+00  1.40963510e+01  2.75334128e+00
 -1.62479008e+00  1.88463320e+01  1.86576613e+01  1.64913768e+01
  1.42069940e+01 -3.31425509e+00 -7.39333765e+00  3.23687780e-01
 -9.26380031e+00  2.52363402e-01  2.22701605e+00  2.67540876e-01
  1.18045961e+01  5.21921725e+00  6.07159319e+00  6.36095279e+00
 -7.06325411e+00  6.17070733e+00  7.49206042e+00  7.39899110e+00
  9.15433437e+00 -5.83773341e+00 -4.81136178e+00 -4.67569236e+00
  1.22273927e+01 -1.18018283e+00 -3.10763418e+00 -2.22463445e+00
  2.43566471e+00 -2.97011472e+01 -2.81878872e+01 -2.70666310e+01
  1.15404179e+01  4.27089117e+00  1.01450284e+00 -4.21539639e+00
  9.88816242e-01 -4.27237865e+00 -1.67883911e+00 -5.28855943e+00
  2.61160716e+01]
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2838.2183709192827
gradient value of function right now is: [-3.27839379e-06 -4.01129775e-05 -4.07759735e-01 -7.07477834e-07
  3.27839379e-06  4.01129767e-05  4.07759735e-01  7.07477832e-07
 -3.90815761e-07  8.01550568e-08  1.69623448e-05 -6.69238313e-12
  1.62017403e-09 -4.87155960e-04 -1.53736229e-04 -4.54745491e-09
  7.15200789e-02 -2.55357001e-02 -1.48961019e+00 -1.50805449e-06
 -4.98702205e-08  1.03405049e-07  1.67761550e-06 -6.32640461e-12
 -4.58592632e-01 -1.31521969e-03  8.95629385e-05 -8.42031842e-02
 -6.01793174e-02 -4.66701921e-02 -4.00922888e-02 -6.31108767e-02
  5.50231221e-03  4.75251196e-03  3.85545719e-03  5.08938312e-03
  9.02281570e-07  2.21310497e-07  1.75439633e-07  2.20631987e-07
 -1.26465972e-02 -3.12385736e-03 -3.05590575e-03  3.83734664e-04
  1.44733017e-02 -1.64983995e-04 -1.89077381e-04 -1.24880493e-03
 -9.95343446e-03 -1.37044905e-03 -1.41214089e-03 -3.14440652e-03
  7.62130315e-01  9.70447869e-03  9.71161289e-03  7.06085390e-03
 -2.87123944e-01  9.93924652e-01  3.66113282e-02 -2.48437765e-01
  3.11494900e-02 -2.32142082e-01 -1.70768607e-03 -1.30935721e-01
  6.85755931e+00]
supnorm grad right now is: 6.8575593115343585
Weights right now are: 
[  2.17884126  -6.74846377  -2.83341499   1.91625207  -2.96906049
   6.76292741   3.40472104  -0.50116902   9.56256666   9.68400252
  12.6895595   10.78462115   6.92210135  -3.31292684  20.0677142
   0.3065671    9.8277213   -5.46146932   0.71892278   0.66026457
   8.80596911   5.87378621  14.2655844    2.75336649  -2.56362747
  18.22534089  18.29375966  15.59561992  13.26044401  -4.35708154
  -8.43086624  -0.69935215  -9.0243829    1.13744101   2.58650184
   0.93256408  11.53283352   5.28757132   6.06081702   6.58579356
  -6.15265181   7.4733038    8.81887636   8.39261751   9.51352076
  -7.5170166   -6.52100208  -5.90424516  12.48669136  -1.44765579
  -3.35866498  -2.47327832   3.27932809 -29.88692767 -28.39167185
 -27.40786514  11.42804529   4.71982286   0.97475423  -4.32512147
   0.90649288  -4.33774623  -1.75465075  -5.1992198   26.3503199 ]
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2840.250975359495
gradient value of function right now is: [ 2.14841241e-06 -5.28137527e-04 -9.36197483e-02 -4.80814226e-07
 -2.14841241e-06  5.28137528e-04  9.36197483e-02  4.80814230e-07
  3.83984732e-07  9.43238734e-07 -1.38497036e-05 -1.02781537e-10
 -1.06894664e-09 -6.30622534e-03 -1.89228487e-03 -5.87408537e-08
 -1.62212153e-02 -5.79125976e-02  8.07985160e-02  5.06527985e-07
  5.46914663e-08  2.54277815e-06 -1.11587678e-07  7.13775797e-11
  7.15603128e-02  1.63498925e-04 -2.34594393e-05  1.60107986e-02
 -9.20518433e-02 -8.94265717e-02 -6.84475852e-02 -1.43538906e-01
  1.27612660e-02  2.79469568e-02  1.89365790e-02  3.78222859e-02
  5.83208823e-08  3.71685846e-08 -1.48768826e-08 -7.11425956e-07
  3.40121587e-02  8.26311899e-03  8.47668163e-03  1.62982075e-02
 -2.30107643e-02 -4.98989349e-03 -5.03057571e-03 -6.68738451e-03
 -2.15626508e-02 -4.63914517e-03 -4.70533341e-03 -7.47378378e-03
 -1.05395765e-01 -1.32829123e-03 -1.33600219e-03 -1.59176821e-03
  3.86466285e-01 -7.17116134e-01 -1.07080167e-01  1.88731800e-01
 -1.19049759e-01  2.06880302e-01 -1.55770347e-01  2.73020089e-01
  7.36121048e+00]
supnorm grad right now is: 7.361210479264407
Weights right now are: 
[  2.81072528  -6.75671058  -2.09013344   2.40995704  -3.60094451
   6.77117423   2.66143949  -0.99487399   9.60307773   9.22097814
  12.13079313  10.78428912   6.92193453  -3.20999457  20.09109746
   0.29367977   8.96924353  -5.40922642   1.37616437   0.95680519
   8.81164247   5.75635778  13.77992548   2.75328615  -2.00712801
  18.14165281  18.26622268  16.01061804  13.53745305  -4.4034136
  -8.26278969  -0.88976373  -9.25592718   1.18474549   2.76244001
   0.86280923  11.51006119   5.37539037   6.09134861   6.89622313
  -5.06331002   8.86578088  10.25143247   9.32070521   9.41873382
  -9.16762484  -8.22900099  -7.10924511  12.5781577   -2.36342707
  -4.32010703  -3.10536784   2.86464062 -30.97515889 -29.47175925
 -28.22127524  11.82634342   4.42372403   0.56727143  -3.58051635
   0.47665245  -3.61333356  -2.11155674  -4.63840824  26.22621313]
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2839.752516336653
gradient value of function right now is: [-6.41705698e-06 -6.21063151e-05 -1.34574451e-01 -5.86749882e-06
  6.41705698e-06  6.21063135e-05  1.34574451e-01  5.86749882e-06
 -7.01576235e-07  8.31737529e-06  2.52355627e-05  1.65074075e-09
  4.19691790e-09 -6.46637297e-04 -3.88666823e-04  2.47708190e-08
  8.57739043e-02 -7.02512636e-03 -3.30878713e-01 -1.41814427e-07
 -1.54260716e-07  5.80457839e-06  1.09878067e-05  7.96616872e-10
 -5.53506139e-01 -6.79518180e-04 -3.23260117e-05 -1.09255235e-01
 -1.07643550e-02 -1.06645196e-02 -7.21550145e-03 -2.13754297e-02
  5.07946028e-03  5.56528947e-03  4.50783783e-03  8.40285336e-03
 -2.56668312e-07  1.24336880e-07  4.58637715e-08  3.89844293e-07
 -7.20872476e-03  2.65522737e-03  2.61318327e-03  3.41576106e-03
  6.01927612e-03 -9.20741668e-04 -9.04469570e-04 -1.08874258e-03
 -2.23609687e-03 -9.76049658e-04 -9.55745736e-04 -1.33437365e-03
  1.11467352e+00  1.88399312e-02  1.77225800e-02  8.54307343e-03
 -3.24405073e-01  1.07031434e+00  7.75425499e-02 -5.90023493e-01
  6.66268863e-02 -5.25016612e-01  2.41796662e-02 -2.30361310e-01
 -5.68759615e+00]
supnorm grad right now is: 5.68759615457435
Weights right now are: 
[  2.95533208  -8.24065488  -2.61612414   2.60918098  -3.74555131
   8.25511852   3.18743018  -1.19409793   9.64575608   8.86724051
  12.45042427  10.7841025    6.9222067   -4.31300659  19.33695231
   0.29528819   9.7758684   -4.40391819   0.48125826   1.00204544
   8.81176078   6.31899246  13.68390036   2.75324032  -2.49626316
  18.03894556  18.10193376  16.02687151  14.49754969  -3.7211628
  -7.55871451  -0.10411792  -9.31228231   1.96436777   3.57212372
   1.21678737  11.55721958   5.39297268   6.08286663   6.98846467
  -5.936494     8.36941757   9.74872891   8.90483617  10.09306135
  -8.78483947  -7.85572986  -6.7665534   13.06262428  -2.69231202
  -4.65696372  -3.52800205   3.08121842 -31.91918218 -30.45525496
 -29.29326856  11.86614609   4.39795778   0.66137968  -3.70576128
   0.58068684  -3.77424759  -1.92181455  -4.86196512  25.490338  ]
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2834.2358978578563
gradient value of function right now is: [ 9.72437169e-05  7.57338781e-04  2.53894559e+00  1.65135246e-05
 -9.72437169e-05 -7.57338780e-04 -2.53894559e+00 -1.65135246e-05
 -7.31479302e-06 -2.50588575e-05 -7.16434990e-04 -3.66534924e-09
  3.70294645e-09  9.39601492e-03  3.13827428e-03  2.50962145e-09
  1.21660077e-01  2.15356873e-01  7.33448045e+00  1.62884325e-05
 -4.97145196e-07 -5.86178542e-06 -5.32967026e-05 -5.01080530e-10
 -9.21131591e-01 -2.59113353e-03 -8.78915679e-04 -2.12098548e-01
  3.40055656e-01  3.47920108e-01  3.11623715e-01  5.14770432e-01
 -1.40222842e-01 -1.45884052e-01 -1.24548890e-01 -2.43335486e-01
 -1.17609532e-05 -2.80610589e-06 -1.07690791e-06 -1.54505229e-05
 -1.70014409e-01 -5.93628141e-02 -5.70118186e-02 -9.32757768e-02
  5.31740248e-02  1.39975701e-02  1.34457621e-02  2.24695747e-02
  4.31152324e-02  1.37418634e-02  1.30571988e-02  3.06862431e-02
  1.85078530e+00  2.20999726e-02  1.90210884e-02  9.98035049e-03
 -1.57097767e+00  3.12199796e+00  3.21283507e-01 -9.45905745e-01
  3.24171888e-01 -8.60543217e-01  5.17136570e-01 -8.50878193e-01
 -1.31806728e+01]
supnorm grad right now is: 13.1806728122044
Weights right now are: 
[  3.48472493  -7.43178358  -1.79022236   2.52089043  -4.27494416
   7.44624722   2.36152841  -1.10580738   9.63519859   9.35811987
  11.69357947  10.78538895   6.92221448  -3.59898099  20.43008765
   0.37454399   9.45311158  -4.37979513   1.22691644   1.38369312
   8.80425131   6.83058022  13.76977665   2.75409078  -1.98068495
  17.94483451  17.89656848  16.41159471  14.67643374  -3.84331676
  -7.91853184   0.32411328  -9.71547197   1.85368214   3.98347591
   0.25991318  11.16780162   5.33916617   6.03882138   6.8415671
  -7.15214581   7.4782978    8.8505626    7.94776195  11.47420636
  -7.2972676   -6.36480489  -5.37358465  14.32028565  -2.08607715
  -4.07037234  -3.23411708   2.60613327 -32.64059952 -31.22175511
 -30.01328176  11.49438741   4.69669575   1.75462343  -4.10839439
   1.62276898  -4.29328437  -1.31855954  -5.55539573  25.53283042]
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2839.7559200590413
gradient value of function right now is: [-6.08522621e-06 -1.15976317e-04 -6.49739918e-01 -1.63167558e-06
  6.08522621e-06  1.15976315e-04  6.49739918e-01  1.63167558e-06
  5.67408384e-07  5.51981925e-07  3.99705133e-05  1.70499424e-11
 -1.06045553e-09 -1.40720302e-03 -5.14158639e-04  2.35760926e-09
 -4.46560245e-02 -8.12115373e-03 -2.47189901e+00 -1.85457456e-06
  6.82098523e-08  4.99770355e-07  4.81079783e-06  1.00857422e-12
  3.93522619e-01  1.66325596e-03  6.38687307e-04  1.28998852e-01
 -2.28124722e-02 -1.49178244e-02 -1.23650311e-02 -2.54986246e-02
  7.49926315e-03  5.47058146e-03  4.49601677e-03  1.00799398e-02
  1.59906743e-06  3.57259126e-08  2.42024585e-08  5.13437430e-07
  8.65841162e-03 -3.87050321e-03 -3.77516084e-03  1.90189519e-04
 -1.66812557e-02 -1.17703772e-04 -1.46036582e-04 -1.76825645e-03
 -1.34384953e-02 -7.70166006e-04 -8.06630973e-04 -3.10179165e-03
 -1.04091950e+00 -1.88624147e-02 -1.81898537e-02 -1.83207729e-02
  4.99007965e-01 -1.34048820e+00 -1.36939988e-01  7.92920764e-01
 -1.32094120e-01  7.41010898e-01 -2.28998405e-01  8.49748388e-01
  2.03568762e+00]
supnorm grad right now is: 2.471899014237812
Weights right now are: 
[  2.93170759  -7.63325938  -2.63945025   2.3168689   -3.72192682
   7.64772302   3.21075629  -0.90178585   9.62624479   9.62866619
  12.56666782  10.78573495   6.92226254  -3.83065846  20.17989514
   0.36813255  10.11148909  -5.86870621   0.56985935   0.87926847
   8.80126716   6.9306547   14.06004243   2.75416645  -2.37558942
  18.11955557  18.22548787  16.32366893  13.30963172  -5.35521963
  -9.35722441  -1.41235759  -8.84131411   2.98505066   5.08097327
   1.26372733  11.26900708   5.44098089   6.05065779   7.62457099
  -6.62308545   8.11557624   9.47691183   9.04084021  10.63407638
  -8.244225    -7.30108236  -6.8167807   12.9245816   -3.06740431
  -5.04790322  -5.3618968    2.74818849 -34.1801334  -32.87064002
 -31.50532274  12.28869485   4.30856981   0.86503718  -3.14822131
   0.65673844  -3.21294947  -3.11137375  -3.98269759  25.64344953]
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2839.508658075943
gradient value of function right now is: [ 3.67928169e-06 -4.77954796e-04  2.14158792e-01  7.91029900e-07
 -3.67928169e-06  4.77954797e-04 -2.14158792e-01 -7.91029900e-07
 -5.85567379e-07  1.33802154e-07 -2.35690724e-05 -2.44241194e-11
  1.54056954e-10 -6.32328320e-03 -1.34594041e-03 -6.21651914e-09
  2.99515115e-02 -9.50896540e-03  1.08639663e+00  1.35381936e-06
 -8.90199676e-08  8.38063959e-07 -2.94259684e-06 -3.40496937e-12
 -2.45873632e-01 -2.61939877e-03 -1.44601774e-03 -7.19493676e-02
 -1.01299970e-02 -1.57188211e-02 -1.39698093e-02 -4.63127360e-03
  4.03681943e-03  1.58443363e-02  1.26827832e-02  2.00136446e-02
 -8.33163495e-07 -6.96946982e-08 -4.00155942e-08 -6.83172069e-07
 -6.44433769e-02 -1.47079932e-02 -1.43974565e-02 -7.33926164e-03
  1.54905073e-02  4.21741500e-04  3.64486369e-04 -2.14549329e-03
  1.42322850e-04 -1.45200855e-03 -1.52232768e-03 -5.81162795e-03
  4.71823465e-01  8.07735309e-03  7.71102163e-03  8.13106683e-03
 -3.61617757e-01  9.79612440e-01  5.38272489e-02 -3.11953147e-01
  4.74852991e-02 -2.89130652e-01  1.99210931e-02 -2.28059362e-01
  4.17532123e+00]
supnorm grad right now is: 4.175321233394913
Weights right now are: 
[  2.7895783   -7.14059769  -1.95553857   2.1683298   -3.57979754
   7.15506133   2.52684462  -0.75324675   9.55127039   9.68159746
  12.83434625  10.78573717   6.92239005  -1.98095927  22.49878181
   0.37033904  10.90138096  -6.04393746   1.19760258   0.89289427
   8.79162814   7.31648935  14.0976588    2.75416526  -3.1177247
  17.38251997  17.6207174   15.66638644  12.75720357  -5.71741127
  -9.59007604  -1.71548063  -9.49589427   1.90201978   3.7280586
   0.27612522  11.23958895   5.46743457   6.07223027   7.6440855
  -6.58185026   8.24042937   9.58647592   8.99685973  11.06388723
  -8.91378064  -7.96061934  -7.05958905  12.69906972  -3.89001235
  -5.85467381  -5.27136718   3.28136938 -34.32921978 -33.0168499
 -31.52831337  11.85298419   4.93752722   1.08969344  -3.39819566
   0.87052081  -3.48901045  -2.7988705   -4.38366544  26.27302151]
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2840.3734661132244
gradient value of function right now is: [ 1.26698733e-06  7.82987618e-04  1.97435884e-01  1.11296005e-06
 -1.26698733e-06 -7.82987619e-04 -1.97435884e-01 -1.11296005e-06
 -3.18860180e-07 -3.26750561e-07 -7.16939699e-06 -9.43638514e-12
  3.00222634e-11  4.22020479e-03  6.06704736e-05  1.60412110e-10
  4.95376313e-02 -4.24817932e-03  9.05328498e-01  1.36030495e-06
 -7.83530061e-08 -1.58450280e-06 -1.49996999e-06 -2.18554344e-12
 -3.87861533e-01 -2.53115485e-03 -1.55664913e-03 -1.01861479e-01
  2.91221474e-04 -4.35699179e-03 -2.20338903e-03 -7.74325068e-03
  1.60911084e-04 -2.24726319e-03 -1.29486128e-03 -2.06459892e-03
 -9.45112971e-07 -3.19844291e-08 -2.39627053e-08 -4.70567991e-07
 -3.94244474e-02 -6.35741736e-03 -6.03295135e-03  5.62222074e-04
  1.08700269e-02 -1.00794548e-03 -9.31227936e-04 -3.06325469e-03
  5.79619182e-03 -3.02059043e-04 -2.31085010e-04 -2.48467985e-03
  7.82645703e-01  9.58234099e-03  7.81160114e-03  1.32330676e-02
 -5.76444554e-01  1.47511815e+00  6.93883867e-02 -3.97952908e-01
  5.17811145e-02 -3.13833055e-01  1.29182712e-01 -5.11544210e-01
 -4.07068057e+00]
supnorm grad right now is: 4.070680571253606
Weights right now are: 
[  2.56462348  -6.65956041  -2.08949045   2.10803995  -3.35484272
   6.67402405   2.6607965   -0.69295691   9.57386055   9.65623998
  13.41847785  10.78573937   6.92238482  -0.96295574  24.14505396
   0.39259232  10.62670568  -6.30307099   0.90888767   0.83865654
   8.79538195   7.29382374  14.26357731   2.75416248  -2.86304671
  17.40945209  17.79499489  15.92061382  12.69782855  -6.50201759
 -10.2829413   -2.18834992  -9.85253679   1.0233836    3.71380003
  -0.90284549  11.2810152    5.47284971   6.07644307   7.65561857
  -6.31681493   8.3709876    9.69807823   9.80857988  10.92864184
  -8.70488144  -7.73109583  -7.90516114  12.18640929  -4.53362695
  -6.51684077  -6.63219005   2.99692866 -35.219961   -33.91622018
 -31.75964169  12.11748527   4.92462652   1.01290916  -3.3177338
   0.80312519  -3.52697012  -3.54615063  -4.2080554   25.68483855]
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2840.783839525223
gradient value of function right now is: [ 1.24724413e-06  3.72726762e-04  1.81086534e-01  9.98966233e-07
 -1.24724413e-06 -3.72726763e-04 -1.81086534e-01 -9.98966233e-07
 -1.91401936e-07 -2.20740086e-07 -6.94085820e-06 -5.09097328e-12
  1.70810944e-11  5.39019559e-03  1.00904426e-03  3.27766363e-10
  4.53912812e-02 -1.34001590e-02  1.04067892e+00  1.27643867e-06
 -5.85442253e-08 -7.65133901e-07 -2.00148050e-06 -1.59142290e-12
 -3.43478276e-01 -5.92073637e-04 -4.08830135e-04 -8.33905733e-02
 -2.39645210e-02 -2.00249864e-02 -2.20800267e-02  7.38880876e-03
 -1.30842347e-03 -1.66703570e-02 -1.40228826e-02 -2.01000417e-02
 -9.28611684e-07 -5.25032246e-08 -1.80500565e-08 -8.12166819e-07
 -6.18264108e-02 -2.26127559e-02 -2.16701982e-02 -2.59314961e-02
  1.13073133e-02  4.43170139e-03  4.26415520e-03  4.63237652e-03
  1.19609997e-03  3.42908032e-03  3.34011566e-03  4.20899070e-03
  7.38659248e-01  1.06944268e-02  8.97150874e-03  6.99075664e-03
 -1.17826198e-01  5.49458153e-01  8.07500749e-02 -4.32726975e-01
  7.32716943e-02 -3.70687917e-01  6.00835044e-02 -2.76193191e-01
  1.05514404e-01]
supnorm grad right now is: 1.0406789188279362
Weights right now are: 
[  2.45213421  -8.47753301  -1.59755544   2.00653444  -3.24235344
   8.49199665   2.16886148  -0.59145139   9.57950554   9.67522866
  13.77254102  10.78573878   6.92238347  -1.91535132  24.69951169
   0.39263753   9.89995166  -5.88857835   0.7949742    1.0590739
   8.797746     7.44840226  14.34361819   2.75416228  -2.47631334
  16.77168363  17.2083432   15.60374429  12.92875715  -6.85398569
 -10.93530739  -1.47476428 -11.43030411   0.9819511    3.66519312
  -1.24150566  11.1318368    5.47345354   6.07960653   7.56275599
  -7.11849555   7.42837694   8.74796161   8.70774189  11.87455301
  -7.89819031  -6.87287295  -6.84391387  12.71881225  -4.26432187
  -6.24569587  -5.73741993   2.76642039 -35.3952411  -34.20917898
 -31.61752389  12.5477369    4.55201279   1.71097663  -3.83525516
   1.54696252  -4.03761645  -2.51082452  -4.94991934  25.98650329]
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2840.842017358497
gradient value of function right now is: [ 6.68091111e-07 -2.08031946e-04  2.09864698e-01  4.24590324e-07
 -6.68091111e-07  2.08031946e-04 -2.09864698e-01 -4.24590324e-07
 -3.76600349e-08  2.44874877e-08 -3.70404840e-06 -1.39828854e-12
  5.79372573e-12 -4.07212575e-03 -1.17844232e-03 -2.94807101e-09
  2.19826688e-02 -8.71635992e-03  8.04264518e-01  6.92446509e-07
 -1.23386413e-08  1.26600534e-07 -1.06356125e-06 -8.85175436e-13
 -1.86997489e-01  8.53072755e-04  5.93296950e-04 -2.92006304e-02
 -1.03599296e-02 -1.31736348e-02 -1.48175259e-02  7.94847408e-03
  5.23308829e-03  1.33023849e-02  1.24581446e-02  1.81747475e-02
 -6.45800667e-08 -8.47663665e-08 -4.15465563e-08 -8.18993360e-07
 -4.32241501e-02 -1.62954836e-02 -1.56301443e-02 -1.31057639e-02
  1.32716448e-03  2.63379521e-03  2.54321995e-03  1.88237255e-03
 -1.77378355e-03  1.08966410e-03  1.13979170e-03 -5.73469759e-04
  5.43568252e-01  7.61074526e-03  6.17852154e-03  3.30329412e-03
  1.35414730e-01 -2.10119204e-01  2.44834841e-02 -3.17641937e-01
  2.15731073e-02 -2.62039870e-01 -1.91597189e-02 -1.00522405e-01
 -4.30633400e+00]
supnorm grad right now is: 4.3063340018883025
Weights right now are: 
[ 2.31163364e+00 -1.03400734e+01 -1.71164655e+00  1.80016707e+00
 -3.10185288e+00  1.03545370e+01  2.28295260e+00 -3.85084026e-01
  9.58049490e+00  9.75712700e+00  1.43406728e+01  1.07857343e+01
  6.92238914e+00 -3.56473994e+00  2.35120487e+01  3.86740062e-01
  9.96853383e+00 -4.81691563e+00  5.46046788e-01  1.52693937e+00
  8.79662991e+00  7.80674568e+00  1.45508750e+01  2.75416078e+00
 -2.10094755e+00  1.71790473e+01  1.76256245e+01  1.61566047e+01
  1.40289423e+01 -5.93288324e+00 -9.99292156e+00 -3.52898011e-01
 -1.12814570e+01  2.36405867e+00  4.94414453e+00 -2.66450573e-03
  1.09730859e+01  5.44913287e+00  6.06816335e+00  7.24454331e+00
 -7.80890373e+00  7.44581961e+00  8.72666045e+00  8.44165488e+00
  1.23548911e+01 -8.29979382e+00 -7.28249261e+00 -6.84616921e+00
  1.30508877e+01 -6.19515646e+00 -8.25602785e+00 -6.45267925e+00
  2.81895103e+00 -3.48216128e+01 -3.36168729e+01 -3.21119074e+01
  1.28973403e+01  4.03123482e+00 -1.29701496e-01 -4.49113174e+00
 -8.32809302e-02 -4.71319348e+00 -2.72933758e+00 -5.03620832e+00
  2.56728836e+01]
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2840.754028162882
gradient value of function right now is: [ 5.87670297e-07 -1.76983390e-04  2.70081646e-01  5.00013583e-07
 -5.87670297e-07  1.76983392e-04 -2.70081646e-01 -5.00013582e-07
 -7.68054524e-08 -7.66389715e-09 -3.13418728e-06 -7.60003808e-12
  9.35232762e-11 -3.56756246e-03 -1.08195057e-03  1.75750628e-08
  4.39775161e-02 -1.49315353e-02  9.52606810e-01  1.73474718e-06
 -3.25872099e-08  3.46615872e-08 -1.12885293e-06 -4.33003602e-12
 -3.31971855e-01 -5.19164644e-05 -3.94223112e-05 -6.97133501e-02
 -2.86812873e-02 -2.21162006e-02 -2.20719592e-02 -2.45327911e-02
  9.01948366e-03  1.25936513e-02  1.31871663e-02  1.36572385e-02
 -1.39812600e-06 -1.36037549e-07 -8.13406431e-08 -1.63713963e-06
 -3.08300358e-02 -1.32861130e-02 -1.30485887e-02 -7.81782554e-03
  2.21369476e-03  2.17514573e-03  2.18310082e-03  2.79579202e-04
 -2.99092148e-03  1.28271983e-03  1.36924770e-03 -1.97242759e-03
  7.51657548e-01  1.03647825e-02  8.98308650e-03  8.60191877e-03
  3.35227740e-02  2.13086295e-01  3.90137413e-02 -3.58301401e-01
  3.11587800e-02 -3.04266306e-01 -2.92719175e-02 -1.79045049e-01
 -3.34223079e+00]
supnorm grad right now is: 3.342230794326808
Weights right now are: 
[  2.22524802 -11.12149615  -1.99358502   1.91873333  -3.01546725
  11.13595979   2.56489106  -0.50365028   9.57558366   9.56373697
  15.28588626  10.78567376   6.92241401  -4.67863657  22.26506362
   0.38417347  10.66172391  -5.97749001   0.6573046    2.09848044
   8.79480723   7.7505619   15.06653378   2.75413175  -2.98316127
  15.03934769  15.41852302  14.7940898   12.8472417   -7.16015321
 -11.21139309  -1.40602981  -9.18860234   4.00619406   6.55800297
   1.98418452  10.21047013   5.44540366   6.06409696   6.97250823
  -6.91946261   8.42464338   9.69538497   9.94520161  12.52259743
  -9.79095313  -8.78972843  -8.7481786   12.6189821   -8.34529333
 -10.48635195  -8.6425899    3.79456429 -33.79359066 -32.60120522
 -31.28227767  12.44212049   4.9238503   -0.71475899  -4.99999533
  -0.99596856  -5.05677111  -4.2023918   -4.63848842  26.10800135]
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2840.867720841489
gradient value of function right now is: [ 7.00892776e-07 -3.91692780e-04  4.09140441e-01  6.69084007e-07
 -7.00892776e-07  3.91692780e-04 -4.09140441e-01 -6.69084007e-07
 -7.14382554e-08 -4.04393999e-08 -3.71231202e-06 -1.26200121e-11
  1.18418365e-10 -8.00771702e-03 -2.69534818e-03  2.01701554e-08
  4.32911095e-02 -3.98706015e-03  1.26450644e+00  2.40923744e-06
 -3.43802553e-08  4.58069258e-08 -1.59759439e-06 -8.46682989e-12
 -3.40084983e-01 -3.08290907e-04 -2.51362789e-04 -7.28678680e-02
 -5.42574316e-03 -7.61188867e-03 -8.41912685e-03  2.94958552e-03
  1.79466150e-02  2.36397205e-02  2.38494493e-02  2.91696589e-02
 -2.55514508e-06 -2.28321035e-07 -1.69889874e-07 -2.23821236e-06
 -4.79898633e-02 -1.73351268e-02 -1.68911215e-02 -1.28637005e-02
  9.68326065e-03  3.62977052e-03  3.55488469e-03  1.38327238e-03
  7.53347195e-03  3.63266848e-03  3.58147248e-03 -9.19331431e-04
  7.55009253e-01  7.90621275e-03  6.92849133e-03  1.08756030e-02
 -1.12813564e-01  5.24404818e-01  4.11791424e-02 -3.05320534e-01
  3.67748560e-02 -2.69131590e-01 -4.21642128e-02 -2.27170905e-01
 -2.33196512e+00]
supnorm grad right now is: 2.3319651166109816
Weights right now are: 
[  2.56569536 -12.2915175   -1.33206241   2.2707233   -3.35591459
  12.30598114   1.90336845  -0.85564026   9.57849743   9.47949534
  14.28282079  10.7856699    6.92247283  -5.91978717  20.79576045
   0.38190024   9.59837475  -4.47153307   1.32481007   2.04135719
   8.79553393   7.81432738  14.3602513    2.75413026  -1.53683268
  15.61217702  16.03002404  16.67403309  14.85203493  -5.89170438
  -9.97616699   1.15382042 -10.96975834   3.7134468    6.30000601
   0.17975864  10.66923025   5.43705417   6.06188636   6.68414244
  -9.45752232   6.95872048   8.21768      6.97201353  14.51230897
  -8.62253952  -7.60985482  -6.18225789  14.84714574  -7.10996628
  -9.23805391  -6.08430713   2.27552325 -34.90201274 -33.72274113
 -34.13928592  11.62782018   5.67264617  -0.26396974  -5.081167
  -0.4312053   -5.31619622  -3.62031609  -4.67746455  25.93063353]
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2840.717369159828
gradient value of function right now is: [ 6.54942450e-07 -2.80865527e-04  3.81185034e-01  6.04030364e-07
 -6.54942450e-07  2.80865526e-04 -3.81185034e-01 -6.04030364e-07
 -9.92223107e-08  2.37870484e-08 -3.54346004e-06 -1.31417372e-11
  4.43362637e-10 -5.51557501e-03 -2.21465602e-03  3.48088828e-09
  6.87978811e-02 -1.11116712e-02  1.24449067e+00  3.34421676e-06
 -5.23234216e-08  1.19558306e-07 -1.58319183e-06 -6.78762102e-12
 -5.20160434e-01 -5.78700511e-04 -4.72557134e-04 -1.05335577e-01
 -2.04070513e-02 -2.01798224e-02 -2.05789389e-02 -1.84822239e-02
  1.20777519e-02  1.66441494e-02  1.64661197e-02  2.34323917e-02
 -4.19712439e-06 -2.54672756e-07 -1.87576083e-07 -2.94227926e-06
 -3.52091488e-02 -1.39216255e-02 -1.36061796e-02 -7.49870765e-03
  7.10162975e-03  2.60567163e-03  2.56521619e-03 -7.87973020e-04
  4.01317881e-03  2.69357886e-03  2.67461054e-03 -3.76592148e-03
  9.95876170e-01  7.00975342e-03  6.11078439e-03  1.25020051e-02
 -2.44069291e-01  8.84123602e-01  3.45119190e-02 -2.55892076e-01
  2.97021940e-02 -2.21914710e-01 -2.54608408e-02 -2.78518731e-01
 -2.65759843e+00]
supnorm grad right now is: 2.6575984285659104
Weights right now are: 
[ 2.44878017e+00 -1.44261673e+01 -2.60310243e+00  2.10360256e+00
 -3.23899940e+00  1.44406310e+01  3.17440848e+00 -6.88519515e-01
  9.58405041e+00  9.76279448e+00  1.48234972e+01  1.07856768e+01
  6.92205993e+00 -7.71268520e+00  1.82063684e+01  3.79418954e-01
  9.80837249e+00 -3.96719673e+00 -8.52817348e-02  1.92036137e+00
  8.79926438e+00  8.26486870e+00  1.48633055e+01  2.75413569e+00
 -1.56426378e+00  1.71228908e+01  1.74699343e+01  1.71975037e+01
  1.53789179e+01 -5.47300681e+00 -9.54998948e+00  1.61926854e+00
 -1.07108981e+01  4.45989183e+00  7.06128886e+00  5.19343851e-01
  1.09147012e+01  5.46544422e+00  6.08548863e+00  7.09089170e+00
 -9.46888748e+00  7.54566231e+00  8.83120735e+00  6.70963322e+00
  1.42887607e+01 -9.45244376e+00 -8.49257982e+00 -5.86897163e+00
  1.48264583e+01 -7.98035696e+00 -1.01697264e+01 -5.76522780e+00
  2.88096345e+00 -3.43823813e+01 -3.32886016e+01 -3.48076127e+01
  1.28431157e+01  4.02120162e+00  1.19450427e-02 -5.93039898e+00
 -2.12036346e-01 -6.07102920e+00 -3.57030827e+00 -4.89397629e+00
  2.60689507e+01]
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2840.5835988642266
gradient value of function right now is: [ 3.99568038e-07 -2.00307488e-04  2.90300682e-01  2.62601211e-07
 -3.99568038e-07  2.00307484e-04 -2.90300682e-01 -2.62601212e-07
 -8.09631988e-08  1.92893311e-07 -2.12243459e-06 -2.53817525e-11
  1.26896807e-09 -3.53556437e-03 -1.82950820e-03  8.10638210e-09
  7.62122248e-02 -1.01244277e-02  9.86936761e-01  3.11792148e-06
 -4.00360259e-08  2.72733819e-07 -7.68666177e-07 -1.57091017e-11
 -5.67325752e-01 -5.82858795e-04 -4.76435156e-04 -1.12441211e-01
 -2.21431978e-02 -1.93611696e-02 -1.95054387e-02 -2.25673974e-02
  1.21393388e-02  1.39318382e-02  1.40806286e-02  1.53312125e-02
 -4.38731479e-06 -1.99974649e-07 -1.47023098e-07 -2.43751666e-06
 -2.52188222e-02 -1.07250711e-02 -1.05153701e-02 -6.00156159e-03
  6.31185146e-03  2.36484974e-03  2.32824430e-03 -3.72580399e-04
  3.76221564e-03  2.61134283e-03  2.57952121e-03 -2.44569996e-03
  1.05785185e+00  7.05372435e-03  6.25636318e-03  1.49166329e-02
 -3.02752572e-01  1.01978417e+00  3.87439425e-02 -2.47873455e-01
  3.38303054e-02 -2.17289325e-01  1.65280866e-02 -3.78388419e-01
 -2.93404643e+00]
supnorm grad right now is: 2.934046433508563
Weights right now are: 
[  2.35147037 -15.16483532  -2.3903558    2.00493706  -3.1416896
  15.17929896   2.96166185  -0.58985401   9.58129556  10.84675929
  14.96460876  10.78576794   6.91787597  -8.95337501  17.67448749
   0.37888794   9.83748866  -4.13696352   0.18587587   2.00695283
   8.79863205   9.83843835  15.56236795   2.75424581  -1.97614603
  17.43189173  17.85017308  16.43780138  15.11807418  -5.94487409
 -10.02201848   1.27351404  -9.98327638   5.11359653   7.72053003
   1.30155638  10.75441773   5.51087313   6.127046     7.18323366
  -8.66747868   8.98353556  10.27931986   7.5380036   13.82669852
 -10.92933059  -9.97861291  -6.56056513  14.42566654  -9.34889911
 -11.54793604  -6.34601467   3.5741147  -34.3111073  -33.23599195
 -34.07973721  12.07213428   5.03337052   0.36757107  -6.01769501
   0.09414587  -6.11267364  -2.68155591  -5.73304001  25.52847392]
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1515.0522587563423
W_T_median: 1355.0739754329743
W_T_pctile_5: 672.7887134468032
W_T_CVAR_5_pct: 568.2250314626741
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.5
F value: -2840.5835988642266
-----------------------------------------------
