Starting at: 
2022-06-20 18:03:38
tracing parameter entered from terminal:  0.9


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[ 0.10347998  0.18844875 -0.3666709   0.62803316 -0.89369922 -0.17398511
  0.93797695  0.78704989 -0.60791207 -0.16293226 -0.31685198  0.28094308
  0.0404241   0.17453202  0.0940472   0.01169373  0.2300954  -0.23784803
  0.78511084 -0.41859022  0.4809118  -0.01155852  0.07219357 -0.14482284
  0.4701344  -0.18827011 -0.8138637  -0.24629474  0.28361272  0.33354483
 -0.63777411 -0.25343004 -0.81551088 -0.26234589  0.20198453 -0.15135741
  0.25264285 -0.29817275  0.41496663 -0.58895503 -0.60305385 -0.63454123
  0.3979274   0.74701442  0.57452389 -0.67377327  0.6493153   0.07340044
 -0.29694484  0.52758424 -0.14347696  0.04319718 -0.28527617 -0.63077443
  0.13133703 -0.58713125  0.12759166  0.87507529 -0.19770888 -0.66759109
  0.25529887 -0.48501395  0.58877641 -0.72315372] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1260.6521530687958
W_T_median: 1222.3920506735662
W_T_pctile_5: 834.1581876304141
W_T_CVAR_5_pct: 746.6575474940535
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1936.4417716440485
gradient value of function right now is: [ 4.19392920e+00  2.81932825e-01  2.26772941e+00  8.38955514e-01
 -4.19392920e+00 -2.81932825e-01 -2.26772941e+00 -8.38955514e-01
 -1.66196133e+00 -3.78343170e-01 -2.09167773e+00 -3.94557003e-01
 -3.70213120e-02 -1.12806724e-02 -4.63576406e-02 -1.16398312e-02
  1.26364921e+00  4.89155894e-01  1.58882576e+00  4.71062547e-01
  6.60970965e-02  2.69722398e-01  8.80293907e-02  2.75237920e-01
 -5.52540343e-01 -7.86452655e-02 -3.46678572e-01 -1.07705883e-01
  4.75228068e-01  6.68119469e-02  2.94807586e-01  8.29646781e-02
 -6.29242578e-01 -7.18081350e-02 -3.84043475e-01 -5.28028195e-02
  7.37191902e-01  8.83231494e-02  4.57607766e-01  1.20391086e-01
 -1.09185685e+00 -1.20785259e-02 -4.37595686e-02 -7.94011495e-03
  3.81366195e-01 -2.13015344e-02 -1.36745103e-01 -4.74798738e-02
 -6.57828101e-01 -1.85765874e-02 -5.52436831e-02 -2.01024867e-02
  4.50981150e-01 -3.63544802e-02 -8.76090669e-02 -5.00829805e-02
 -5.57178312e-01  2.13596742e+00 -1.74523056e-01 -8.82486880e-02
 -8.50460024e-04 -7.86421804e-01 -2.84470238e-01 -1.93973145e-01
 -8.98982981e+00]
supnorm grad right now is: 8.98982981315913
Weights right now are: 
[ 0.29743095  0.11151951 -1.72324071  0.41251331 -1.08765019 -0.09705588
  2.29454675  1.00256974 -0.34704555  1.60951773 -0.65580884  2.34345002
  1.75784541  2.34377365  1.78508908  2.24050904  1.25147815 -1.02478864
  2.43460946 -1.54823859  2.34103791  0.49219259  2.30589408  0.2351351
 -1.01691018  2.30755412 -1.27409341  1.59579431  2.70757349 -1.47588582
  1.00000984 -1.17909074 -2.63004132  1.72645006 -0.591541    1.15667731
  2.3670409  -1.87532759  1.67696227 -1.4013004  -1.98252564  1.42210217
  2.78150744  3.31498332  3.00152289 -1.26247546 -0.19370953 -0.84428006
 -0.30297922  2.83900234  2.46639329  2.34278897  2.36343191 -1.29145405
 -0.67748626 -2.54594037  3.25351523  1.45205447 -0.4643171  -2.92460387
 -1.79398599 -2.16338307 -0.81190172 -2.78535744 26.27718307]
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1938.5929546748612
gradient value of function right now is: [-1.86739192 -0.17557641 -3.2972564  -0.96699762  1.86739192  0.17557641
  3.2972564   0.96699762  1.15697999  0.72167368  1.57388776  0.77902218
  0.02139401  0.01480259  0.02767266  0.01585342 -4.15286039 -5.15513915
 -5.18717778 -5.47273945 -0.64749887 -0.9816183  -0.80402363 -1.04185872
  0.89768878  1.16259526  0.67150618  1.40711992 -0.84312832 -0.61120445
 -0.59006965 -0.76745996  1.37685491  1.83987352  1.03777083  2.23392246
 -1.24739816 -0.93397241 -0.87618311 -1.16650077  2.73101634  0.23487366
  2.08132306  0.45962102 -1.63749097 -0.62055384 -3.79878299 -1.1704433
  1.13974984  0.09774227  0.90961403  0.1960989  -1.16713307 -0.38333396
 -2.41037094 -0.7288305   4.81758466 -8.45840429 -1.26090908  1.24735435
 -1.92528484  5.3143376  -2.10210181  2.89241389 13.53477811]
supnorm grad right now is: 13.53477811274466
Weights right now are: 
[ 0.34544268  0.14490043 -2.151554   -0.29188833 -1.13566192 -0.13043679
  2.72286004  1.70697138  0.10844421  2.5225838  -0.23740911  3.25633317
  2.38736363  2.73536134  2.45034526  2.63296009  1.74642902 -0.80919255
  2.94606482 -1.31476252  3.71054299 -0.46772751  3.53223476 -0.69701486
 -1.0021733   2.38102916 -1.18914129  1.40286883  2.98669374 -1.43068336
  1.2378855  -0.90273484 -2.63392062  1.86489976 -0.61187608  0.95698493
  2.532349   -1.77599016  1.80526346 -1.12581514 -1.57809807  2.46506692
  3.67862452  4.32945163  3.94058728 -1.89621615  1.2354823  -0.69423151
 -0.26087645  3.80482482  3.49154043  3.31572914  3.16354441 -0.75833057
  1.13936782 -1.42994948  3.81036467  1.44909723  1.28336325 -2.66257463
 -2.52322003 -1.98741537  0.2935321  -2.38156911 26.9429224 ]
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1954.5204117134072
gradient value of function right now is: [ 6.36615578e+00  5.05245236e-02 -3.16986338e-01 -2.00074733e-01
 -6.36615578e+00 -5.05245236e-02  3.16986338e-01  2.00074733e-01
 -4.81492558e+00 -4.48045706e-01 -5.77141164e+00 -4.71445812e-01
 -1.92584418e-02 -1.54329838e-03 -2.33321867e-02 -1.59138058e-03
  2.08428463e-01 -7.76951706e-01  2.72142053e-01 -8.56353463e-01
 -1.54861123e-01 -4.56709866e-01 -1.67779528e-01 -4.95074787e-01
 -1.73678425e-01  4.63154843e-01 -1.28825928e-01  4.33322112e-01
  4.67261303e-01 -6.17348282e-02  3.29628357e-01 -3.63540486e-02
 -2.87847950e-01  5.87669731e-01 -2.09002249e-01  5.46223008e-01
  6.02564669e-01 -1.19465776e-01  4.24339918e-01 -8.47844466e-02
 -2.02995839e+00 -2.03540376e-01 -9.59362536e-01 -2.24566505e-01
 -9.92984631e-02 -8.96727237e-01 -1.70477522e+00 -1.24970727e+00
 -1.10289477e+00 -1.03977657e-01 -5.16649983e-01 -1.17022361e-01
 -1.78045384e-02 -4.36801263e-01 -8.21895984e-01 -6.11982983e-01
 -6.29695123e-01  1.84951376e+00 -8.42057916e-01 -2.65033179e+00
  1.38394876e+00 -2.53563000e+00 -1.58121060e-01 -2.10409616e+00
 -1.37143625e-01]
supnorm grad right now is: 6.366155775759229
Weights right now are: 
[ 0.75744969  0.27610785 -2.17908565 -1.24065388 -1.54766893 -0.26164422
  2.75039169  2.65573693 -0.0682806   3.25691935 -0.60222561  3.94203108
  3.1298154   3.52755356  3.08347768  3.42651951  2.3848593  -0.62828325
  3.62118486 -1.15776068  5.17539754 -0.66325232  4.78217924 -0.96273766
 -0.97246876  2.41110708 -1.30556431  1.28907918  4.18270559 -1.15870777
  2.29465773 -0.52384405 -3.17196974  2.20788069 -1.29602976  1.08772716
  3.69987843 -1.57860021  2.85734334 -0.82955578 -2.09026998  4.61769828
  3.81348977  6.07214182  3.83134047 -3.48855614  2.94073893 -1.43026824
 -0.9748299   5.90963398  3.16661788  4.84689017  3.283613   -2.27996804
  2.94873407 -2.07976581  2.90215925  2.18679296  3.35819535 -2.26252744
 -3.58600344 -2.62947132  2.33755762 -2.47222739 28.29937203]
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1954.588022347089
gradient value of function right now is: [-8.83256626e-01 -5.20423730e-04 -6.90365901e-01 -1.69583418e-01
  8.83256626e-01  5.20423730e-04  6.90365901e-01  1.69583418e-01
  5.70306366e-01 -1.60464198e-01  7.52359306e-01 -1.64972656e-01
  2.46965042e-04 -3.43833854e-05  2.35043216e-04 -2.53365228e-05
 -6.58608409e-01 -1.45885798e+00 -6.11981878e-01 -1.55253000e+00
 -2.22945967e-01 -4.39685100e-01 -2.28179739e-01 -4.69751422e-01
 -1.17083728e-01  4.16767860e-01 -7.64247973e-02  3.27849514e-01
  1.45474849e-01 -1.27683546e-01  8.76349722e-02 -9.61078018e-02
 -8.92669630e-02  5.57606350e-01 -5.97455929e-02  4.39821492e-01
  1.84990476e-01 -1.94977465e-01  1.11468444e-01 -1.48402014e-01
 -9.78298848e-01 -6.67231415e-02 -6.60594555e-01 -7.23351719e-02
 -2.98086199e-01 -6.72755229e-01 -2.20731665e+00 -1.05947971e+00
 -4.33407362e-01 -3.07456548e-02 -3.27902671e-01 -3.30563000e-02
 -1.29702499e-01 -2.95251206e-01 -9.46045966e-01 -4.61460765e-01
 -1.09619850e-01  9.91389248e-01 -1.01078388e+00 -1.48349030e+00
  1.23002530e+00 -1.47111552e+00 -6.53803458e-01 -1.27018526e+00
  4.23832820e+00]
supnorm grad right now is: 4.238328203453134
Weights right now are: 
[ 0.5726355   0.17121156 -2.46525644 -1.69254006 -1.36285473 -0.15674792
  3.03656248  3.10762311  0.36469448  3.83843642 -0.15352617  4.54507814
  3.79203465  4.04580262  3.77470892  3.94719879  2.31940574 -0.92348401
  3.65472725 -1.46130557  5.43264568 -0.69188007  5.08376385 -1.02721665
 -0.7427406   2.75867999 -1.13438599  1.49209767  4.22310961 -1.30862823
  2.32325789 -0.57761342 -3.7165212   2.61093795 -1.73170933  1.33761911
  3.77782615 -1.82083323  2.92118701 -0.95773703 -1.98022011  5.79269938
  3.88251066  6.91376283  4.99142451 -3.84116461  2.80940412 -1.66566987
 -0.91417889  7.18401228  3.52405038  5.74925758  4.32937487 -2.5301638
  3.07539684 -2.17423033  2.67657567  2.57762087  3.83788215 -2.24093148
 -3.67588972 -2.78621475  2.7837664  -2.553466   28.11057875]
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1950.1985654741532
gradient value of function right now is: [-3.16429734e+00  1.75202364e-03  2.70302660e+00  2.36404460e-01
  3.16429734e+00 -1.75202364e-03 -2.70302660e+00 -2.36404460e-01
  2.55091127e+00 -2.37332220e-01  3.60375109e+00 -2.44513566e-01
  1.95349303e-04 -8.02303913e-04  4.86317757e-04 -8.34497910e-04
  4.99828402e+00  5.56463315e+00  5.21801433e+00  5.78159603e+00
  3.99728652e-01  5.06495541e-01  4.15928919e-01  5.46281763e-01
 -4.20804388e-01 -5.70626195e-01 -3.43195700e-01 -3.57946857e-01
  4.57991414e-02  1.67542975e-01  2.73663349e-02  1.08907191e-01
 -1.52991333e-01 -8.28432100e-01 -1.55946240e-01 -5.17977853e-01
  7.62266094e-02  2.78988361e-01  5.28708585e-02  1.79073549e-01
 -7.28410298e-01 -1.21771046e-01 -9.75873197e-01 -1.64905044e-01
  4.46797954e-01  7.26819322e-01  3.43800047e+00  8.93399690e-01
 -3.98663488e-01 -6.92037772e-02 -7.15526888e-01 -9.67374838e-02
  1.55475794e-01  2.32443317e-01  1.08439783e+00  2.84086489e-01
 -1.24266585e+00  9.53248588e-02  1.71151207e+00  7.74393904e-01
  2.53799176e-01 -8.95621902e-01  1.32681692e+00  1.64918241e-01
 -1.53482602e+01]
supnorm grad right now is: 15.34826015380246
Weights right now are: 
[ 0.53285211  0.11797509 -2.15696767 -1.70324625 -1.32307135 -0.10351145
  2.72827372  3.1183293   0.57704059  4.38244632  0.03078318  5.09829923
  4.19747062  4.4101881   4.23716935  4.31554195  2.55962764 -0.70042384
  3.98193697 -1.24479014  5.97154592 -0.24709103  5.6471621  -0.62716615
 -0.35725168  2.78955484 -1.13943608  1.48580491  4.51666423 -0.52570657
  2.65124131  0.14144894 -4.46230514  2.6288884  -2.42681937  1.31075998
  4.09940911 -1.29982751  3.28609901 -0.45860907 -1.92974107  5.64746684
  4.13364043  6.86576888  5.51321511 -4.08550145  3.28122072 -1.74993914
 -0.93837872  7.30293223  3.69573995  5.96369228  4.98758095 -2.627271
  3.69516917 -2.09272013  2.82062198  2.67615657  4.4361169  -2.46224935
 -4.19165954 -2.72361278  3.64909893 -2.17629446 27.84896585]
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1950.3250343590266
gradient value of function right now is: [ 4.90135484e+00  3.22235948e-03 -2.90077084e+00 -7.47139332e-02
 -4.90135484e+00 -3.22235948e-03  2.90077084e+00  7.47139332e-02
 -4.31577703e+00 -2.25133972e-01 -7.37704805e+00 -2.27291508e-01
  1.46332857e-04 -3.08110668e-05  2.78691454e-04 -3.20407913e-05
 -5.44864198e+00 -6.10021839e+00 -5.47705923e+00 -6.31823689e+00
 -1.97413269e-01 -2.24545814e-01 -2.03869015e-01 -2.34698913e-01
  2.05954938e-01  3.01926193e-01  1.82879426e-01  2.02678662e-01
  4.85674972e-01 -1.96934693e-01  2.70125160e-01 -1.30973468e-01
  1.41558707e-01  5.17357343e-01  1.27555982e-01  3.48145337e-01
  5.56170922e-01 -2.73638174e-01  3.03828067e-01 -1.82247604e-01
 -2.21286876e+00 -5.76707071e-02  4.03216457e-01 -3.18202527e-02
 -2.48761388e-01 -4.21266388e-01 -2.28594747e+00 -6.74437536e-01
 -1.25304841e+00 -4.14999212e-02  2.81546498e-01 -2.54857297e-02
 -9.94256210e-02 -1.58213094e-01 -8.72265871e-01 -2.55188093e-01
  4.95309270e-01  1.14783193e+00 -6.51309771e-01 -1.69922123e+00
  1.89312319e+00 -3.43306177e+00 -6.71000573e-01 -1.54580179e+00
  6.86169770e+00]
supnorm grad right now is: 7.377048051956227
Weights right now are: 
[ 8.20373441e-01 -4.75208913e-02 -2.69251434e+00 -2.22695572e+00
 -1.61059268e+00  6.19845293e-02  3.26382039e+00  3.64203877e+00
  3.55493412e-01  4.97755501e+00 -1.02221855e-02  5.73856792e+00
  4.76890721e+00  4.66893215e+00  5.00271122e+00  4.57551031e+00
  1.90628051e+00 -1.45342029e+00  3.55123328e+00 -1.99154505e+00
  5.89871601e+00 -1.23800123e-01  5.62257331e+00 -6.79485759e-01
  1.46648431e-01  2.94107858e+00 -8.33040163e-01  1.78159325e+00
  4.52861543e+00 -5.98507153e-02  2.87020195e+00  3.25020047e-01
 -5.81394422e+00  2.81781992e+00 -3.25122995e+00  1.63684935e+00
  4.12941912e+00 -1.14514444e+00  3.50983327e+00 -5.29871064e-01
 -2.06620049e+00  5.82316540e+00  3.96338914e+00  6.98277265e+00
  5.89556136e+00 -3.59792124e+00  3.38009352e+00 -1.29611858e+00
 -1.12398902e+00  7.87113497e+00  3.94617667e+00  6.54172102e+00
  5.61929223e+00 -2.31755922e+00  3.78248441e+00 -1.79847112e+00
  2.63359562e+00  3.05221251e+00  4.89100308e+00 -2.12622479e+00
 -4.06030099e+00 -2.75617550e+00  3.75975325e+00 -2.31660689e+00
  2.82000716e+01]
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -1945.4910073655237
gradient value of function right now is: [-1.98768813e+00 -3.51728582e-04 -3.00064903e+00 -1.16430822e-01
  1.98768813e+00  3.51728582e-04  3.00064903e+00  1.16430822e-01
  1.97540535e+00  4.46154549e-01  4.09944827e+00  4.38415536e-01
 -2.81826108e-04 -2.79013190e-04  1.38616107e-04 -3.10710162e-04
 -5.35821231e+00 -5.58427951e+00 -6.48270391e+00 -5.96419385e+00
 -2.38457459e-01 -3.54892986e-01 -2.53622264e-01 -4.21107236e-01
  1.43973085e-01  6.10332580e-01  1.22252529e-01  1.94219442e-01
 -8.85913999e-01 -2.42311904e-01 -6.57693597e-01 -7.97298179e-02
  2.64991888e-01  9.51186092e-01  2.17924775e-01  3.04931971e-01
 -1.01205720e+00 -3.96246187e-01 -7.54089759e-01 -1.28206964e-01
  5.43866348e+00  1.86959263e-01  3.37680847e+00  3.82670706e-01
 -4.71859710e-01 -1.46080154e+00 -4.27063489e+00 -1.36864038e+00
  3.73383735e+00  1.13173877e-01  2.35559010e+00  2.42538345e-01
 -9.36188421e-02 -2.68780571e-01 -7.69448189e-01 -2.51559092e-01
  1.81672582e+00 -9.42865673e-01 -3.26078139e+00 -7.51294114e-01
 -3.00867143e+00  6.69341647e+00 -2.73029875e+00  2.70388984e+00
  3.44977671e+01]
supnorm grad right now is: 34.49776713229084
Weights right now are: 
[ 8.63562840e-01 -2.43601137e-01 -2.41795406e+00 -2.65384336e+00
 -1.65378208e+00  2.58064775e-01  2.98926010e+00  4.06892641e+00
  2.95825541e-01  6.26014349e+00  1.93197228e-01  7.05066498e+00
  6.07463630e+00  4.55565092e+00  7.01410577e+00  4.18503015e+00
  2.31260297e+00 -1.13884352e+00  4.12992846e+00 -1.72355948e+00
  6.56180259e+00  2.69264740e-01  6.19366791e+00 -6.34950428e-01
  1.62456821e+00  3.39553664e+00  3.57695890e-01  1.87605400e+00
  4.81604443e+00  8.59382930e-03  3.40839903e+00  7.36970029e-01
 -7.03440593e+00  3.29448500e+00 -4.77379644e+00  1.72365520e+00
  4.41128555e+00 -1.39841458e+00  4.06191965e+00 -4.26343967e-01
 -1.54623367e+00  8.40924259e+00  3.60206920e+00  9.25458621e+00
  6.14143157e+00 -4.28630980e+00  3.33016184e+00 -1.80702192e+00
 -9.68884708e-01  1.09622007e+01  3.36143014e+00  8.99607398e+00
  6.03500622e+00 -2.69893036e+00  4.24383463e+00 -1.97312225e+00
  2.43367478e+00  3.30516972e+00  3.93378805e+00 -2.91035772e+00
 -4.51865478e+00 -2.45614093e+00  3.26840389e+00 -2.03642601e+00
  2.87243643e+01]
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1952.741746920828
gradient value of function right now is: [-4.02697359e+00 -8.99208559e-03 -1.38972447e+00 -2.46607037e-02
  4.02697359e+00  8.99208559e-03  1.38972447e+00  2.46607037e-02
  2.65358355e-02 -6.75116562e-02  4.82102339e+00 -6.77186892e-02
 -1.03399996e-03 -2.06457475e-04 -1.95399348e-02  3.28519734e-05
 -2.07223791e+00 -2.32303523e+00 -3.16563718e+00 -2.51768813e+00
 -4.17409646e-02 -4.88298866e-02 -1.37608516e-01 -4.90738928e-02
  1.02731450e-01  1.81665911e-01  9.51774510e-02  7.18168719e-02
  1.08930375e-01 -1.15775608e-01  6.68865217e-02 -4.67924584e-02
  5.60157476e-03  3.23573792e-01  5.72144274e-03  1.28827608e-01
  1.29099445e-01 -1.65185231e-01  7.95891444e-02 -6.50128450e-02
 -7.78932571e-01  2.01412696e-03 -3.44486491e-01 -1.36643752e-03
 -1.48982905e-01 -4.68633729e-01 -1.46399355e+00 -5.86525089e-01
 -5.18801400e-01 -8.86296504e-03 -2.17975028e-01 -1.12989295e-02
 -3.70108412e-02 -1.07670263e-01 -3.35017766e-01 -1.35013753e-01
 -8.82039462e-02  6.52469922e-01 -6.57166187e-01 -1.15255277e+00
  8.83341150e-01 -9.88705123e-01 -3.36871258e-01 -8.03768066e-01
  7.16238565e+00]
supnorm grad right now is: 7.162385649396493
Weights right now are: 
[ 0.56751316 -1.05896524 -2.63691779 -2.8512707  -1.3577324   1.07342888
  3.20822384  4.26635375 -0.05451582  5.91053913  0.61493405  6.71428691
  7.10691084  4.40399931  6.9521804   2.9499606   2.01049199 -1.40794448
  3.90722637 -1.99404238  7.00106354  0.86033249  6.48284145 -0.37871264
  2.45298772  3.24471455  1.41246128  1.98334389  5.30628248  0.39957938
  3.85284574  1.05049249 -7.69390907  3.2528742  -5.13044661  1.89477606
  4.89479956 -1.31120095  4.48553945 -0.57663583 -2.16773171  7.87685783
  3.66346619  8.48053981  6.74373758 -3.8872681   3.54787314 -1.48635376
 -1.46661859 10.89747587  3.51799286  8.58126193  6.68398063 -2.60736316
  4.41186464 -1.94791602  2.40095437  3.33936043  4.51957876 -2.50473908
 -4.40198391 -3.24821267  3.67577983 -2.39882106 28.17369274]
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1957.1835472044993
gradient value of function right now is: [ 1.00748050e+00 -2.21218134e-03  5.45554142e-01 -4.42882968e-03
 -1.00748050e+00  2.21218134e-03 -5.45554142e-01  4.42882968e-03
 -5.20906825e-01 -1.34929910e-01 -2.23492357e+00 -1.36520934e-01
 -1.50509486e-03 -4.14366167e-03  5.22582121e-04 -8.87473885e-03
  1.20971025e+00  1.11395538e+00  1.58988805e+00  1.10735533e+00
 -1.82372365e-03 -1.03597149e-02  4.09667208e-03 -2.57081866e-02
 -4.83419345e-02  2.00933127e-02 -3.50867859e-02  9.00795558e-03
  2.87546752e-01  1.13517234e-02  1.90607845e-01  4.75365387e-03
 -3.57835511e-02  1.25155726e-02 -3.06394184e-02  6.44626231e-03
  3.35624872e-01 -5.27810063e-03  2.22587597e-01 -2.28068557e-03
 -1.65612177e+00 -8.57001414e-02 -9.14593009e-01 -1.24353514e-01
  1.69213353e-02 -1.12312271e-01  1.31967130e-02 -1.21020624e-01
 -1.10409708e+00 -5.36787254e-02 -6.38042519e-01 -7.86428775e-02
  9.60119387e-04 -4.11116570e-02 -2.61756426e-02 -4.55249363e-02
 -5.46186882e-01  7.16657462e-01  1.85315821e-01 -1.18084169e+00
  1.26398811e+00 -2.34441046e+00  4.31921408e-01 -1.26518907e+00
 -6.91509912e+00]
supnorm grad right now is: 6.915099116431638
Weights right now are: 
[ 1.02796924 -2.73253634 -2.39180239 -3.47021594 -1.81818847  2.74699997
  2.96310843  4.88529899  0.11921635  6.54579404  0.52985353  7.37517895
  8.00934731  3.57845361  7.4965693  -0.70240437  2.05979527 -1.30207027
  4.1773549  -1.91076274  7.42752707  1.40259697  7.17477661 -0.66232723
  2.37338627  3.29553621  1.41679435  2.21381212  5.23356663  1.23257759
  3.91510876  2.06453638 -8.27282772  3.32451862 -5.61836563  2.07003739
  4.80979158 -1.02554514  4.5355919  -0.4703398  -1.87198216  7.8803025
  4.0711637   8.57051296  6.85761632 -4.11936287  3.70192848 -1.768424
 -1.1888447  11.52475208  3.74588176  9.16903067  7.01699932 -2.97854945
  4.59153942 -2.31903804  2.52422028  2.86321912  4.38626157 -2.48815155
 -5.12305408 -3.18716168  3.42792467 -2.28750396 27.92246253]
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1951.5656962260705
gradient value of function right now is: [ 4.70695954e+00 -1.13520222e-02 -1.32562834e+00 -2.42134986e-02
 -4.70695954e+00  1.13520222e-02  1.32562834e+00  2.42134986e-02
 -6.73475785e-01 -1.00468249e-01 -1.12134129e+01 -9.61458100e-02
 -1.83738739e-02 -2.78755273e-02 -8.16883418e-03 -5.39644226e-02
 -2.20579360e+00 -2.36152833e+00 -2.00579734e+00 -2.77430499e+00
 -5.56456148e-02 -7.82938420e-02 -2.47079161e-02 -1.36768641e-01
 -1.53451537e-02  3.41105947e-01 -1.82408684e-02  1.14789292e-01
  4.21021902e-01 -1.02864105e-01  2.94593420e-01 -3.30811585e-02
  5.85997777e-02  6.06827683e-01  3.45965545e-02  2.02720721e-01
  4.51534875e-01 -2.61466334e-01  3.14668186e-01 -8.72970785e-02
 -1.49686526e+00  2.30403499e-03 -1.95755480e-01 -5.44497041e-03
 -1.63220487e-01 -1.14211440e+00 -2.31441592e+00 -1.27330647e+00
 -1.34744743e+00 -3.13602113e-02 -3.27446234e-01 -4.58959244e-02
 -3.30820602e-02 -2.69702318e-01 -5.18909596e-01 -2.98081790e-01
  2.36672782e-01  1.21685154e+00 -1.49004531e+00 -2.89381139e+00
  1.14634463e+00 -1.85652692e+00 -7.48512879e-01 -2.05222622e+00
  1.27995574e+01]
supnorm grad right now is: 12.799557430177881
Weights right now are: 
[ 1.54658966e+00 -3.71889265e+00 -2.26307403e+00 -3.75345867e+00
 -2.33680890e+00  3.73335629e+00  2.83438008e+00  5.16854172e+00
 -2.54546026e-02  7.38491888e+00  3.11321135e-01  8.28142159e+00
  8.70994932e+00  3.95468155e+00  8.57382676e+00 -1.39440904e+00
  2.14986492e+00 -1.27417297e+00  4.73203784e+00 -1.87249517e+00
  7.69161403e+00  1.61281006e+00  7.68051251e+00 -7.91064488e-01
  2.69781914e+00  3.23573621e+00  1.65177806e+00  2.12923556e+00
  4.75749432e+00  1.49364255e+00  3.87886415e+00  2.49087542e+00
 -1.05365478e+01  3.24063909e+00 -7.37224175e+00  1.92926993e+00
  4.36420807e+00 -9.13788933e-01  4.54242354e+00 -3.26543158e-01
 -2.05996057e+00  8.57833685e+00  3.03388465e+00  9.06996944e+00
  7.32561366e+00 -4.02356785e+00  3.95172011e+00 -1.64255035e+00
 -1.47787977e+00  1.32995218e+01  2.87782725e+00  1.03763091e+01
  8.01445408e+00 -2.89024290e+00  4.96130391e+00 -2.17022273e+00
  1.69826828e+00  2.93431658e+00  4.03714965e+00 -2.75575853e+00
 -4.71980615e+00 -3.16593259e+00  3.22557228e+00 -2.48093365e+00
  2.90423851e+01]
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1958.0254824995413
gradient value of function right now is: [ 1.71553182  0.00747478 -0.36141955  0.00866549 -1.71553182 -0.00747478
  0.36141955 -0.00866549 -0.19142032 -0.02213845 -4.43880429 -0.02522708
  0.00940639  0.01124015  0.01504663  0.03090107 -1.2895501  -1.21122046
 -1.35916902 -1.00663305  0.01189927  0.01410822  0.02195235  0.03665509
  0.04284468 -0.14124424  0.02481559 -0.03915981  0.11972014  0.05873813
  0.04821346  0.01451559  0.0683287  -0.28730853  0.03578712 -0.07769725
  0.13945406  0.13886872  0.05463355  0.03771626 -0.20488133 -0.02366225
  0.85187153  0.05789372  0.0824101   0.60893538  0.90494905  0.84864925
 -0.22072925 -0.02915677  0.3408207   0.00563342  0.00915377  0.10326046
  0.14292088  0.13644831  0.30121914 -0.45318144  0.31960353  0.23873001
 -0.11665299 -0.49435304 -0.6759173  -0.27824246 -0.65172753]
supnorm grad right now is: 4.4388042878053415
Weights right now are: 
[  1.53589482  -4.42819435  -2.34581644  -3.90689462  -2.32611406
   4.44265799   2.91712248   5.32197767   0.191621     7.65855242
   0.58352904   8.5869729    8.75463394   4.11910401   8.72241035
  -1.83771341   1.81900601  -1.55575972   4.68566332  -2.09331144
   7.93269135   1.96535242   8.14679115  -0.7726965    2.52492789
   3.13597369   1.63037548   2.00068842   4.62782345   2.12792999
   3.81028747   3.2437141  -11.28558235   3.03415491  -7.58798971
   1.67571327   4.22635534  -0.67848095   4.46074891  -0.06954252
  -2.27815842   7.88915392   3.63311592   8.75168517   7.35019272
  -3.99189565   4.51037857  -1.36286342  -1.35556323  13.83438251
   3.63332195  11.16052831   8.58617585  -2.79377067   5.6368849
  -1.85451223   1.54157298   2.23123416   4.71781837  -2.2446315
  -5.39526932  -2.84481269   2.26529175  -3.00789639  28.14336878]
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1958.2479389675236
gradient value of function right now is: [-0.82973368 -0.00315991 -0.38584683 -0.00419331  0.82973368  0.00315991
  0.38584683  0.00419331 -0.08339246 -0.04162383  2.12607463 -0.04474018
 -0.00507366 -0.0079725  -0.00836475 -0.01485888 -0.51035385 -0.5867003
 -0.48176451 -0.70350273 -0.00712182 -0.01066087 -0.01243455 -0.01881964
 -0.00735515  0.07339018 -0.00746179  0.0167585   0.13259415 -0.03733519
  0.06321907 -0.00891719 -0.01914722  0.16005398 -0.01370654  0.03712051
  0.16550207 -0.07697394  0.07924258 -0.0177208  -0.70568641 -0.03192958
 -0.52999912 -0.0335867  -0.02572464 -0.20524729 -0.65378563 -0.52948742
 -0.47257693 -0.02949953 -0.35319592 -0.03189757 -0.00374028 -0.03125777
 -0.09571812 -0.07820645 -0.29746672  0.55280974 -0.17327368 -1.19823936
  0.52526497 -0.85134838  0.08865107 -0.70377087  1.6794087 ]
supnorm grad right now is: 2.1260746265562562
Weights right now are: 
[  1.45267787  -4.52201361  -2.38060509  -3.79730306  -2.24289711
   4.53647725   2.95191113   5.21238611   0.4562174    7.57334261
   1.00783956   8.56870335   8.9595971    4.34286305   9.10551997
  -1.77064115   1.82410893  -1.52954071   4.87309633  -2.12938979
   8.11689188   2.25675217   8.58889829  -0.56489691   3.4541069
   3.57571561   2.69175544   2.3251975    4.87431888   1.64739123
   4.44903849   2.76222417 -12.00229045   3.58231219  -8.2748532
   2.12588201   4.40878382  -1.11114659   5.05826083  -0.42062528
  -2.22109407   7.97163087   3.35656035   8.42524847   7.89992116
  -4.46659451   4.20453937  -1.72247969  -1.51159749  14.70313124
   3.40448652  11.35709185   8.67782623  -3.15735879   5.59525838
  -1.88264254   2.14809596   2.46886684   5.21000374  -2.09704505
  -5.4117217   -3.43418856   2.78380512  -2.98539113  28.43625459]
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1950.500228083296
gradient value of function right now is: [-2.42530637e+00 -7.96706096e-04  2.39712909e+00 -8.42069098e-04
  2.42530637e+00  7.96706096e-04 -2.39712909e+00  8.42069098e-04
 -4.17366623e-02 -3.77219852e-02  5.92302692e+00 -4.14035506e-02
  8.17827453e-04  2.15499399e-04 -5.74592691e-03 -6.59492358e-04
  4.73931220e+00  4.88447840e+00  5.08791017e+00  5.11272388e+00
  3.67371253e-03  3.13353422e-03 -8.59459914e-03  2.34743486e-03
 -7.26048224e-02 -1.34429260e-01 -3.22007325e-02 -1.54551622e-02
  1.24137057e-01  1.00048116e-01  4.47558205e-02  1.12891503e-02
 -1.56560284e-01 -3.38741068e-01 -6.97207199e-02 -3.87512067e-02
  1.70829337e-01  1.42500766e-01  6.28851450e-02  1.63782856e-02
 -9.93894994e-01 -1.02532203e-01 -1.90957042e+00 -2.16264583e-01
  1.73474067e-01  2.98552992e-01  1.70015130e+00  6.04317690e-01
 -3.83418773e-01 -2.52865412e-02 -7.33848039e-01 -6.01306977e-02
  8.33448340e-03  1.40078720e-02  8.99093084e-02  2.99819284e-02
 -1.09897663e+00  2.84400812e-01  9.64062131e-01  2.27603358e-01
  5.35715301e-01 -7.63542193e-01  1.49245171e+00 -7.23439598e-02
 -1.24584380e+01]
supnorm grad right now is: 12.458438010324013
Weights right now are: 
[  1.1366685   -4.12503408  -2.28022971  -3.44519548  -1.92688773
   4.13949772   2.85153576   4.86027853   0.53707353   7.38751186
   1.43973171   8.37495993   9.43974153   4.96045991   9.65479421
  -1.25007197   1.88467361  -1.40841017   4.77588516  -2.03998628
   8.47621844   2.78204734   9.00651541  -0.1055479    4.86814775
   3.90387385   4.11792256   2.40225329   5.10628593   1.49837054
   4.58008898   2.83044203 -11.44213384   3.93282722  -7.54440183
   2.20271153   4.59597618  -1.20172398   5.15438185  -0.28819898
  -2.35395776   7.75621261   3.76831395   8.17972712   7.29951503
  -5.14455667   4.1643507   -2.11917085  -1.55876857  15.14163202
   3.92535773  11.89810742   8.45478209  -3.42841335   5.98340902
  -1.85474947   2.58863256   2.97427579   5.35787566  -2.65634347
  -5.51821054  -3.55105929   3.2905996   -2.51448496  27.86796755]
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -1952.4073633767389
gradient value of function right now is: [ 2.47491806e+00  4.78588367e-04 -3.93770935e+00  3.57473457e-04
 -2.47491806e+00 -4.78588367e-04  3.93770935e+00 -3.57473457e-04
 -1.72860589e-02 -6.93628314e-03 -8.24747757e+00 -1.11662337e-02
 -2.62947120e-04 -2.23011552e-04  1.56555537e-03  6.58452322e-04
 -7.51022728e+00 -7.50496603e+00 -9.14913488e+00 -7.65582923e+00
 -5.62366895e-04 -5.27853172e-04  1.78456006e-03  1.58332831e-04
  1.22105106e-01  4.93264589e-02  8.41238035e-02  8.48475356e-03
 -6.69526217e-03 -6.55979546e-02 -1.77453735e-02 -1.12858067e-02
  3.35000212e-01  1.64917876e-01  2.33566126e-01  2.83844361e-02
 -1.31454359e-02 -8.42709685e-02 -2.61918838e-02 -1.43200471e-02
  4.49446025e-01  9.76021461e-02  4.08435609e+00  2.17521333e-01
 -1.00759997e-01 -1.18928696e-01 -6.07628866e-01 -1.62550992e-01
 -7.15904802e-02  1.71963929e-03  2.46403853e+00  4.68821010e-02
 -6.62402730e-03 -5.02737398e-03 -3.25456384e-02 -7.64131908e-03
  1.48362927e+00 -2.87018261e-01 -4.20798096e-01 -2.72915187e-01
 -2.16510704e-01 -4.53857576e-01 -1.61726733e+00 -5.93078548e-01
  1.65806102e+01]
supnorm grad right now is: 16.580610191069102
Weights right now are: 
[  1.91883744  -4.55810593  -2.3575042   -3.39559421  -2.70905667
   4.57256957   2.92881024   4.81067726   0.51150073   7.41018031
   0.87040594   8.43901932  10.08489274   5.59474746  10.58022786
  -1.32469996   1.36736257  -1.76797831   4.57406117  -2.28879976
   9.30915417   3.64644404  10.21112331   0.17638151   5.34372266
   3.78677861   4.38966599   2.45752679   5.34177856   2.46976159
   5.17181599   3.81429843 -11.60694396   3.65738698  -8.12533523
   2.09835993   4.77671356  -0.63947612   5.75136365   0.09994443
  -2.24949692   9.22523626   3.73727593   9.24552116   7.74479557
  -4.89454019   4.73617451  -1.69261137  -1.80134979  16.43000332
   3.76478681  12.36671532   8.22804345  -3.72475628   6.38669597
  -1.68156286   2.89154236   2.59801317   6.37063297  -2.24197292
  -6.09915048  -3.5765312    4.13081544  -2.08070994  28.60751661]
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1956.3866855981569
gradient value of function right now is: [ 7.50952721e-01  2.85506500e-02  1.76348827e+00  1.79544876e-02
 -7.50952721e-01 -2.85506500e-02 -1.76348827e+00 -1.79544876e-02
 -4.09392174e-02 -3.83775337e-02 -2.82590029e+00 -4.46161758e-02
  6.83118511e-03  2.18637253e-02  6.76471136e-03  1.04470342e-01
  2.10334639e+00  2.28423815e+00  2.04488150e+00  2.63505723e+00
  4.33181813e-03  1.31690154e-02  4.45587613e-03  6.04389336e-02
  4.08272558e-02 -2.17985529e-01  2.68358196e-02 -2.17667244e-02
  1.49672031e-01  3.95146275e-02  7.39373101e-02 -3.91620773e-03
  2.59726661e-02 -5.37366154e-01  2.68858876e-02 -4.84879372e-02
  1.91535766e-01  2.69248802e-01  9.30505087e-02  2.34939999e-02
 -6.57434051e-01 -3.00784910e-02  1.40331057e-01 -6.16173575e-02
  3.44418092e-02  7.00281430e-01  1.89373638e+00  1.11660837e+00
 -5.43928475e-01 -2.23347406e-02  9.73748657e-02 -3.89623148e-02
  1.05443066e-03  1.14801691e-01  1.71690964e-01  1.34993520e-01
 -1.36164261e-01  2.02635008e-01  1.03453413e+00  1.69921000e+00
  3.95856297e-01 -1.16680247e+00  6.99939944e-01  3.87512346e-01
 -8.21239334e+00]
supnorm grad right now is: 8.212393337328583
Weights right now are: 
[  1.9531881   -3.73981165  -2.0375964   -2.43674252  -2.74340734
   3.75427529   2.60890245   3.85182557   1.67976719   8.42214127
   1.09011085   9.46505942  10.97890889   6.97583448  11.58526258
  -0.20087864   1.48467597  -1.59843093   4.84033286  -2.16425291
   9.97208917   4.82669062  11.03054943   1.26450238   5.06838506
   3.73965771   4.2649234    2.53020342   4.84675762   1.98229019
   4.94245802   3.27988713 -12.31193114   3.79856343  -8.7094162
   2.40189566   4.26479756  -0.52926469   5.52313913  -0.05812252
  -2.03068387   8.60747817   3.84168481   8.86672281   7.29161973
  -4.73393085   4.67057814  -1.94174683  -1.32450564  17.58403693
   3.9171978   13.06910758   8.91133436  -3.27048155   6.61669052
  -1.63408223   3.78972792   2.77007489   6.38613817  -2.09663088
  -6.12611314  -3.774525     4.22718377  -2.06264301  28.02937204]
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1955.832437933846
gradient value of function right now is: [ 2.36715995e+00 -4.93798777e-03 -9.32960203e-01 -2.69511920e-03
 -2.36715995e+00  4.93798777e-03  9.32960203e-01  2.69511920e-03
 -5.36265780e-02 -4.40488165e-02 -9.31717067e+00 -5.07728052e-02
 -5.73678596e-03 -1.06907544e-02 -5.52749344e-03 -3.06580773e-02
 -1.06879362e+00 -1.18233986e+00 -7.84869629e-01 -1.44818356e+00
 -2.66892637e-03 -4.85674599e-03 -2.26646107e-03 -1.34760101e-02
  5.41221448e-02  9.98258680e-02  3.28551725e-02  2.43418813e-02
  1.94952291e-01 -6.78963727e-02  1.31536953e-01 -1.41422395e-02
  3.83561342e-03  2.87199246e-01 -1.41566827e-02  6.77446540e-02
  2.48764581e-01 -1.52506455e-01  1.66683831e-01 -3.54980099e-02
 -8.87506824e-01  3.54376270e-03 -2.62571780e-01 -2.12006970e-02
 -1.29153587e-01 -4.14584565e-01 -1.27632142e+00 -5.38733458e-01
 -9.59063048e-01 -2.34727096e-02 -3.99435446e-01 -6.00519973e-02
 -2.59453069e-02 -6.79041315e-02 -1.64813481e-01 -8.10669765e-02
  2.32801147e-02  4.56230577e-01 -7.18893707e-01 -1.58049919e+00
  4.26810070e-01 -1.10671228e+00 -1.99325817e-01 -1.77765354e+00
  2.36891710e+00]
supnorm grad right now is: 9.317170665775715
Weights right now are: 
[  2.24624376  -5.58611056  -2.07753265  -3.5678104   -3.036463
   5.60057419   2.6488387    4.98289344   1.93357536   8.77928061
   0.96312331   9.86819924  11.48955449   7.23784699  12.2253653
  -1.48792131   1.38677892  -1.6852219    4.97533082  -2.24535649
  10.60123208   5.32994474  11.83971141   0.48311267   5.43493619
   4.49053455   4.2208127    3.29938125   4.97089983   2.06650372
   5.5488666    4.74790638 -12.69307385   4.52685569  -9.99886039
   2.71983269   4.33284341  -0.93345934   6.11781431  -0.14297697
  -1.41913155   9.10260857   3.50665148   9.70296898   7.57032118
  -5.26308575   4.02496994  -2.84604408  -0.97271383  20.1234988
   2.84295999  14.80526839   7.33919584  -5.2343629    6.00103751
  -3.15743103   4.13800018   2.82713598   4.84249285  -2.91995537
  -6.49990261  -3.72479028   3.37799915  -2.29155696  28.09390353]
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1957.267931574021
gradient value of function right now is: [ 1.69003381e-01 -3.38314118e-03 -3.86743723e-01 -1.96217228e-03
 -1.69003381e-01  3.38314118e-03  3.86743723e-01  1.96217228e-03
 -7.51506942e-02 -4.49404036e-02 -8.00777077e-01 -4.56613948e-02
 -4.46417053e-03 -6.63518078e-03 -5.04649306e-03 -2.19643534e-02
 -1.51319220e-01 -2.50374069e-01  4.74767503e-01 -4.96423091e-01
 -2.23335196e-03 -3.26691934e-03 -2.49546916e-03 -1.04010790e-02
  1.56653225e-02  4.69647637e-02  2.34996168e-04  3.82328345e-02
  1.13570332e-01 -3.38668447e-02  1.55278755e-01 -2.91205666e-02
 -4.57355700e-02  1.50135103e-01 -1.16400304e-01  1.23607414e-01
  1.37327134e-01 -8.00327295e-02  1.89767799e-01 -6.48337969e-02
 -5.17595841e-01  3.76378491e-02 -1.31891730e+00  2.20949130e-02
 -1.27940818e-01 -2.82180074e-01 -6.19401655e-01 -3.46893905e-01
 -1.01234574e+00 -2.63271911e-02 -2.17977128e+00 -6.35825510e-02
 -1.03153537e-01 -1.70182615e-01 -3.66380737e-01 -2.01571726e-01
 -4.71929715e-01  7.22928900e-01 -7.22974229e-02 -9.30734911e-01
  8.81820308e-01 -1.23272338e+00  5.07699279e-01 -8.34267759e-01
  5.98089765e-01]
supnorm grad right now is: 2.17977128476538
Weights right now are: 
[  2.09700348  -6.01476791  -2.00548025  -4.0591027   -2.88722272
   6.02923155   2.57678629   5.47418574   1.56636009   8.15357168
   1.2517979    9.30928105  11.84258464   7.550454    12.67514895
  -1.49623295   1.25316663  -1.68083785   5.00766113  -2.2386851
  10.89330646   5.60791229  12.2392385    0.3931786    5.74158463
   4.6431937    4.31174149   4.25459071   5.55974215   2.49135643
   6.29579441   4.60513361 -12.4667931    4.55821474 -10.11227047
   3.60491177   4.88938898  -0.61974      6.82463975  -0.66618615
  -1.58007741  10.31017094   3.43684766  10.36842342   7.63696498
  -5.16851536   4.37537551  -2.87981647  -1.67614187  21.39907721
   2.64402191  15.07474633   6.86129679  -6.00272811   5.75332788
  -3.85221786   3.46815123   3.22790336   5.54188556  -2.48108143
  -6.3270551   -3.80828728   4.31471457  -2.28325844  28.31987211]
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1954.8271663409403
gradient value of function right now is: [-1.48702414e+00 -4.58236893e-03 -9.25421510e-02 -2.99311675e-03
  1.48702414e+00  4.58236893e-03  9.25421510e-02  2.99311675e-03
  1.44943179e-01  7.06098662e-02  6.02961541e+00  8.60082494e-02
 -4.88376024e-03 -1.07260588e-02 -5.63221479e-03 -2.73800731e-02
  3.53072793e-01  2.94242511e-01  1.95965751e-01  1.88118112e-01
 -2.72435665e-03 -5.81739559e-03 -3.34261993e-03 -1.44377905e-02
 -1.89037296e-01  4.44580652e-02 -1.40343018e-01  1.16740563e-02
 -3.17176256e-01 -6.38976460e-03 -1.93225043e-01 -1.69394269e-03
 -1.74840071e-02  1.09787815e-01 -4.77345881e-02  2.93289341e-02
 -4.43327608e-01 -6.42870767e-02 -2.70523428e-01 -1.67014914e-02
  1.82790003e+00  8.09637059e-02 -3.70381202e-01  1.37564328e-01
 -4.14593392e-02 -2.54255877e-01 -4.92475881e-01 -3.17857378e-01
  1.87647823e+00  4.73133488e-02 -5.06029075e-01  9.14879589e-02
 -1.17817287e-02 -5.38192209e-02 -1.12785856e-01 -6.46005823e-02
 -5.73103694e-02 -1.42031651e-01 -5.74992665e-01  1.34920291e+00
 -1.51387266e-01  7.24581370e-01 -2.18372860e-01  3.01283317e+00
  4.84706433e+00]
supnorm grad right now is: 6.0296154092842205
Weights right now are: 
[  1.97992442  -5.74533098  -1.97769004  -3.80753196  -2.77014366
   5.75979462   2.54899609   5.22261501   2.61668649   9.27805749
   1.57884565  10.55115631  11.57916427   7.08795953  12.4234333
  -1.51720282   1.2540667   -1.67606821   5.23306788  -2.23271471
  10.68503438   5.16132941  12.0993987    0.29044917   4.15515753
   4.98946115   3.69316388   3.84740559   4.38432572   2.19616812
   5.49383717   4.54937223 -13.08245912   4.90874512 -10.28868601
   3.22687644   3.65622628  -0.66666093   5.98821735  -0.05367158
  -1.33914472  10.49852427   3.69626858  10.92763844   8.91103528
  -5.15167152   3.93903605  -2.92559567  -1.21150289  23.43884104
   3.01862949  17.07471383   8.89973531  -5.23200627   5.90582416
  -3.24357514   3.3992942    3.25048523   4.66693799  -2.53122466
  -6.08056947  -3.88116824   3.12244614  -2.01363654  27.97102031]
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1950.2836581578554
gradient value of function right now is: [-1.05673978e+00 -2.24448379e-03  3.07255374e+00 -1.41559301e-03
  1.05673978e+00  2.24448379e-03 -3.07255374e+00  1.41559301e-03
 -1.06103418e-02 -1.04371623e-02  4.37812939e+00 -1.22053713e-02
 -1.93108463e-03 -3.60901554e-03 -2.36040045e-03 -1.11748411e-02
  4.06579935e+00  4.10090998e+00  5.25276329e+00  4.31247714e+00
 -9.50648583e-04 -1.80315142e-03 -1.24648010e-03 -5.60915070e-03
 -2.85935934e-02 -5.71685345e-02 -5.63884857e-02 -1.07747880e-02
  8.75016077e-02  1.23865001e-01  8.86798985e-02  2.82148365e-02
 -1.38212017e-01 -3.14794166e-01 -2.03861312e-01 -6.61333727e-02
  1.13682323e-01  1.38984073e-01  1.16662249e-01  2.93716814e-02
 -5.54514405e-01 -7.70170226e-02 -2.09381931e+00 -1.50295684e-01
  1.08314713e-01  2.12219171e-01  1.35209353e+00  3.34697025e-01
 -4.89809729e-01 -6.32598877e-02 -2.99725516e+00 -1.45601468e-01
  1.64323097e-02  1.30210899e-02  8.32419557e-02  1.47540026e-02
 -7.31492274e-01  8.90044190e-02  1.36012460e+00 -4.49427984e-01
  1.15897545e-01 -2.81935169e-01  2.53267723e+00 -4.79684828e-01
 -1.67339677e+01]
supnorm grad right now is: 16.733967696180827
Weights right now are: 
[  2.08892896  -5.93188649  -1.65239432  -3.87358034  -2.87914819
   5.94635013   2.22370036   5.28866339   2.81601278   9.57954109
   1.63304097  10.78434906  12.29455531   7.95006853  13.12406124
  -1.17128972   1.08258938  -1.76792028   5.30362613  -2.24783065
  11.42397337   6.08611052  12.82585842   0.7232076    4.82422722
   4.97447571   3.8550452    3.87937939   4.87447429   2.72389146
   5.77973865   5.11884839 -13.8907096    4.83149949 -11.52891599
   3.18660179   4.22334292   0.24511846   6.38595085   0.6306272
  -1.66157789  10.60888052   3.39989178  10.97879135   9.9275195
  -4.60215787   3.96047949  -2.41788075  -1.54455678  22.71986162
   2.46185797  16.20780262   9.11699384  -5.25895723   6.02660109
  -3.02788869   3.97138708   2.72322128   5.2046901   -2.98335027
  -6.90140191  -3.2573934    3.76785968  -2.84873947  27.7479558 ]
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1955.3892675198726
gradient value of function right now is: [-1.22845827e+00  1.06366277e-04  1.35566789e+00  7.11170199e-05
  1.22845827e+00 -1.06366277e-04 -1.35566789e+00 -7.11170199e-05
  1.14944523e-03  4.79623483e-03  5.62037394e+00  1.19286511e-02
  7.36462033e-05  9.58424629e-05  9.36635885e-06  3.77499203e-04
  1.68538897e+00  1.74065563e+00  2.14248379e+00  1.84750758e+00
  5.39103779e-05  6.95228327e-05 -9.67308333e-06  2.29884860e-04
 -3.28322244e-02 -3.42359935e-02 -1.66555508e-02 -4.62371155e-03
 -3.39165555e-02  6.21268103e-02  3.67945185e-02  8.02854765e-03
 -7.01950851e-02 -1.77855840e-01 -7.40102263e-02 -2.35957590e-02
 -8.17986081e-02  8.15752601e-02  2.75998559e-02  1.08455865e-02
  1.88948817e-01  5.42598119e-02 -1.49980204e+00 -7.62636567e-03
  6.22257129e-02  2.07143046e-01  7.70774832e-01  3.64951095e-01
 -4.01946142e-02  1.99239174e-02 -1.53239203e+00 -3.21357389e-02
  4.39250545e-03  1.48992135e-02  4.23026947e-02  2.25660338e-02
 -8.64722129e-01  1.51070247e-02  6.58661839e-01  1.79546525e+00
  5.17124283e-01 -5.94413619e-01  1.61293140e+00  1.28119131e+00
 -4.98779146e+00]
supnorm grad right now is: 5.620373940938925
Weights right now are: 
[  2.33532008  -6.19825677  -1.6120254   -4.10657681  -3.12553932
   6.2127204    2.18333145   5.52165986   2.46721391   9.40462076
   1.60433937  10.83670198  13.23078579   8.62682012  14.11382766
  -0.93756691   1.02489098  -1.76647866   5.38506457  -2.22080497
  12.43396802   6.85762188  13.89229418   1.02467746   5.04402729
   4.96668393   4.71878214   3.57723168   4.64169468   2.6776858
   6.0878846    4.74271043 -14.39642358   4.97735375 -11.58942698
   3.12957919   3.76975871   0.36946453   6.54290527   0.75329007
  -1.75772718  10.77613472   2.87703277  10.72308897  11.04386857
  -4.1763217    4.20417587  -2.30606051  -1.67589882  24.50800634
   2.3645206   17.44943501   9.72443264  -4.89421486   6.78416086
  -2.51475708   2.34837414   2.8114234    5.39063058  -2.22320968
  -6.07220959  -4.21633879   3.50887234  -2.39751624  28.37214097]
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1954.4939230350537
gradient value of function right now is: [-2.01287367e-01 -2.99688509e-03 -1.63354805e+00 -1.73405474e-03
  2.01287367e-01  2.99688509e-03  1.63354805e+00  1.73405474e-03
 -1.83927062e-02 -2.15945137e-02  8.96862643e-01 -2.48126330e-02
 -2.78983986e-03 -6.40122444e-03 -2.81319546e-03 -1.98506700e-02
 -1.55885784e+00 -1.70709358e+00 -1.48486420e+00 -1.95495689e+00
 -1.41339576e-03 -3.16581718e-03 -1.42985086e-03 -9.51083124e-03
  1.48532846e-02  3.48429236e-02  8.08300071e-03  3.27629800e-02
  7.44051957e-02 -5.98178787e-02  5.82431153e-02 -4.61276657e-02
  8.77563443e-03  1.73597375e-01 -9.99375090e-03  1.49732664e-01
  1.00570890e-01 -1.01451099e-01  7.55511660e-02 -8.78617624e-02
 -3.90452726e-01  2.10361506e-02 -6.50272361e-02  3.07704621e-02
 -4.84633137e-02 -1.40545601e-01 -9.22296696e-01 -2.68032825e-01
 -5.62010736e-01 -7.85938566e-03 -3.23141421e-01 -1.43759238e-02
 -1.08822779e-01 -1.50301865e-01 -6.06536497e-01 -2.32653326e-01
 -1.39722584e-02  4.71227093e-01 -6.89442969e-01 -7.61885708e-01
  5.59183293e-01 -9.70226224e-01 -7.41069841e-01 -9.75152848e-01
  2.39366062e+00]
supnorm grad right now is: 2.3936606183766878
Weights right now are: 
[  2.36761283  -6.52909696  -1.92704721  -4.52914112  -3.15783207
   6.5435606    2.49835326   5.94422416   2.47751178   9.22290098
   1.74346623  10.63262028  13.37868383   9.04863638  14.30554966
  -0.83028026   0.76934782  -1.99891912   5.01460302  -2.49575791
  12.51811563   7.18020164  14.03021054   1.00464196   5.63384729
   5.46161937   5.1787169    5.22966627   4.73338959   2.02557589
   5.79647317   4.26023777 -13.73909112   5.59815428 -10.97508506
   5.09060246   3.96234887  -0.07230887   6.36124736  -0.6369677
  -1.73384254  10.36669929   3.95247309  10.82429735  10.53231781
  -5.16336256   3.77448599  -2.72507597  -1.45906997  24.66706741
   3.23755081  18.13206448   7.25027827  -6.75292375   4.97963121
  -4.13437446   4.22271526   3.09294222   4.88186841  -3.01544071
  -6.70019843  -3.81291098   3.0986497   -2.54256133  27.65593343]
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1955.893362663436
gradient value of function right now is: [ 1.54202584e-01 -1.70562434e-03  1.30712923e-01 -1.05033469e-03
 -1.54202584e-01  1.70562434e-03 -1.30712923e-01  1.05033469e-03
 -1.13642003e-02 -1.62978679e-02 -8.22252782e-01 -2.10434509e-02
 -1.21989126e-03 -2.40980941e-03 -1.38928375e-03 -8.86637752e-03
  6.31855868e-02  7.86616663e-02  1.67910672e-02  1.02156104e-01
 -6.24181231e-04 -1.23562687e-03 -7.08780091e-04 -4.53217667e-03
  1.32537125e-02  3.19722114e-03  9.37808258e-03  4.11526895e-03
  6.80119493e-02  1.80224627e-02  2.35656662e-02  1.31473256e-02
  7.82403880e-03 -1.74475612e-02  2.14922697e-02 -6.74175799e-03
  1.01145178e-01  1.04932737e-02  3.84103524e-02  5.85347825e-03
 -3.89623572e-01 -2.00562061e-02  1.01334398e-01 -3.36671149e-02
  6.45457712e-03 -3.43395635e-03  4.23699264e-02 -1.69847922e-02
 -3.08584137e-01 -1.73080173e-02  2.70135532e-01 -2.88350962e-02
 -7.80755348e-04 -1.48791918e-02 -3.07551276e-02 -3.25889702e-02
  7.73992268e-02 -4.30908553e-03 -1.60888052e-02 -7.04431134e-01
 -9.69218670e-02 -2.16122565e-01  1.02252669e-01 -7.42055666e-01
 -6.03989524e+00]
supnorm grad right now is: 6.039895239565854
Weights right now are: 
[  2.5890457   -6.51367338  -1.61418233  -4.47880086  -3.37926493
   6.52813702   2.18548837   5.89388391   2.43350204   9.03538274
   1.64142126  10.49532291  13.91114853   9.61558528  14.7610256
  -0.58652045   0.71103935  -1.97192406   4.99449577  -2.37733201
  13.08447231   7.78314366  14.5150081    1.25173508   6.06836953
   5.22081087   5.77755431   4.88640174   5.09661667   2.50092105
   6.20582094   4.97228411 -13.53537848   5.15513619 -10.6887729
   4.40578434   4.26113702   0.67562806   6.77639531   0.36244075
  -1.86507073  10.30074943   4.34114639  10.74871619  10.27037307
  -4.96892273   4.37373857  -2.47126675  -1.60444677  25.46153743
   3.61308479  18.56556883   7.97625794  -6.38233274   5.73259851
  -3.65315082   5.04598583   2.58907567   5.44119048  -3.10137177
  -7.3621143   -3.45716219   3.53284837  -2.83934682  27.40723569]
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1947.953824122469
gradient value of function right now is: [-7.06231874e-01  1.21207120e-02  6.85534769e+00  8.68638823e-03
  7.06231874e-01 -1.21207120e-02 -6.85534769e+00 -8.68638823e-03
 -3.14879934e-03 -6.70165204e-03  3.72243670e+00 -1.12289427e-02
  7.89509985e-03  1.88165624e-02  6.26221798e-03  4.68533834e-02
  5.96350575e+00  6.34949530e+00  6.26547415e+00  6.74724105e+00
  4.49549022e-03  1.06733154e-02  3.56946405e-03  2.66682214e-02
 -6.65840923e-03 -2.20982239e-01 -1.21336152e-02 -6.17106710e-02
  3.65536691e-02  1.84276725e-01  3.75932048e-02  2.94816865e-02
 -5.30588407e-02 -8.06902705e-01 -7.61285175e-02 -1.93550920e-01
  4.76317332e-02  3.87921009e-01  4.86353591e-02  9.60400848e-02
 -1.99861427e-01 -2.73182543e-02 -7.59910745e-01 -6.27138714e-02
  1.43293200e-01  1.44911377e+00  3.73410359e+00  1.97507891e+00
 -1.92817752e-01 -1.88994556e-02 -1.09288484e+00 -5.60037985e-02
  2.95049651e-02  3.33258071e-01  6.16655390e-01  4.03195113e-01
 -4.32019277e-01 -5.60383446e-01  2.01842596e+00  3.21969403e+00
  1.48563616e-02 -3.29102302e-01  1.92196869e+00  1.50238570e+00
 -1.90589992e+01]
supnorm grad right now is: 19.058999187862288
Weights right now are: 
[  2.73633868  -6.14914442  -1.2070268   -4.08535233  -3.52655791
   6.16360806   1.77833284   5.50043538   2.21257247   8.87213712
   1.68290471  10.32091217  15.54603468  10.47857063  16.51338647
   0.11173284   0.97407335  -1.68423089   5.20316529  -2.05222321
  14.81385846   8.74104038  16.36216803   2.00658791   6.70235762
   4.78713273   6.38203318   3.61259953   5.19836639   2.23926923
   6.88228736   4.51881101 -13.40393109   5.31179068 -10.99714897
   3.74202672   4.2363339    0.89375164   7.40461294   1.21879678
  -1.42252852  10.96123475   4.1077353   11.29963959  11.34788882
  -4.17551531   4.63451563  -2.07089324  -1.74823411  26.63266109
   3.07378515  18.87916083   9.21491114  -4.87333886   6.81785116
  -2.44290206   5.05010405   2.62626988   5.69321239  -2.41226457
  -7.16425977  -4.04012177   3.88653123  -2.26405719  27.82098917]
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1951.798057285628
gradient value of function right now is: [-1.18181114e+00 -1.31233426e-04  4.07407385e+00  1.44902584e-06
  1.18181114e+00  1.31233426e-04 -4.07407385e+00 -1.44902585e-06
  3.25675073e-02  5.34428144e-02  6.33138175e+00  7.05236321e-02
  9.80212859e-04  1.10918824e-03  8.86263368e-04  3.43582231e-04
  3.32667863e+00  3.54043017e+00  3.25265690e+00  3.80223920e+00
  5.64585734e-04  6.23822774e-04  5.10626544e-04  1.24061681e-04
 -4.30473447e-02 -9.06490203e-02 -3.27408584e-02 -1.47695780e-02
 -2.31660664e-01  1.70406608e-01 -1.69643563e-01  2.56008827e-02
 -2.70614258e-02 -4.89027547e-01 -2.41856437e-02 -7.52764452e-02
 -3.66539038e-01  2.18348744e-01 -2.66505747e-01  3.44321441e-02
  9.18139674e-01  9.12068272e-04 -2.44540914e-01 -6.06132697e-03
  1.75590258e-01  3.97899820e-01  2.29851137e+00  7.77850842e-01
  1.55743741e+00  1.81302953e-02 -1.68801578e-01  3.45011255e-02
  3.29601190e-02  5.61250284e-02  1.85917994e-01  7.90320521e-02
 -4.12052338e-01 -6.18023188e-01  5.67947900e-01  1.17994416e+00
 -4.15442601e-01  8.69757970e-01  1.08043873e+00  2.12373128e+00
 -8.14567095e+00]
supnorm grad right now is: 8.145670951326313
Weights right now are: 
[  2.56146874  -6.67738372  -1.11034808  -4.59371667  -3.35168798
   6.69184736   1.68165413   6.00879972   2.72837001   9.5413871
   2.02152251  11.10762299  15.66610004  10.06853288  16.84360138
  -0.30242      0.92647459  -1.69239659   5.28522018  -2.04215347
  14.98302827   8.40945095  16.72373585   1.65344397   5.73091883
   5.59732569   5.54342077   4.01879101   4.12560314   3.26470057
   6.21546495   4.91201675 -14.0273447    6.07208623 -11.341763
   4.26542407   3.16537038   1.33348647   6.71046542   1.20526051
  -1.02084325   9.90335709   4.20265233  10.85244182  11.04203826
  -4.78599047   3.64099848  -2.62490415  -0.90311219  28.56110878
   3.07201687  20.74145419   9.34688486  -5.40337573   6.21781511
  -3.04058476   4.72168288   2.69148998   4.85943172  -2.90633125
  -6.86235372  -3.95978804   2.37551896  -2.36787514  27.63272458]
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1949.3483011347605
gradient value of function right now is: [ 1.67506970e+00 -1.19008584e-02 -2.37293618e+00 -8.35621519e-03
 -1.67506970e+00  1.19008584e-02  2.37293618e+00  8.35621519e-03
 -9.61048023e-02 -9.95026779e-02 -1.01283727e+01 -1.08525210e-01
 -6.68786503e-03 -2.18586791e-02 -4.44209525e-03 -5.24005430e-02
 -1.28997505e+00 -1.58922082e+00 -2.77564454e-01 -1.86649769e+00
 -4.01468708e-03 -1.30059448e-02 -2.67590080e-03 -3.10443582e-02
  1.65187609e-02  1.22649375e-01  1.09780546e-02  1.08323325e-02
  1.96844850e-01 -8.74712857e-02  2.79435669e-01 -1.87450948e-03
 -2.16941302e-02  4.70013957e-01 -1.21193471e-01  3.48465782e-02
  2.82404464e-01 -2.85764553e-01  3.72362270e-01 -2.03618276e-02
 -7.31613921e-01  1.42016361e-02 -1.01989951e+00 -7.99093587e-03
 -1.80977998e-01 -5.87938829e-01 -2.26300961e+00 -7.31085962e-01
 -1.52738278e+00 -5.49023250e-02 -3.39281109e+00 -1.43483810e-01
 -2.01317424e-02 -6.55519038e-02 -1.87121343e-01 -7.49418324e-02
 -5.56629828e-01  1.42915657e+00 -6.48009058e-01 -2.10573943e+00
  1.22343671e+00 -1.75747678e+00  6.56199783e-01 -2.60997650e+00
  6.51465021e+00]
supnorm grad right now is: 10.128372702474952
Weights right now are: 
[  3.1689039   -6.50156248  -1.51661249  -4.6254688   -3.95912314
   6.51602612   2.08791853   6.04055184   1.0163097    8.29636571
   1.56230994  10.14112302  15.93553152  10.44396013  17.17609079
   0.35749017   0.60059569  -1.98317428   5.18404779  -2.33824045
  15.16258968   8.70293497  16.97746377   2.23111061   6.8761032
   5.75384991   6.36749562   4.03669529   5.10439462   2.99642907
   7.70763558   3.97611647 -14.65560319   6.58300628 -12.09372444
   5.07783032   4.08490323   1.06388721   8.20689363   0.14616834
  -1.45539397   9.77140508   3.39677785  10.42338082   8.87935359
  -5.38334508   3.43362763  -3.14174891  -1.93727769  28.81916013
   1.87190168  20.17232891   9.37147861  -5.32570551   6.37736714
  -3.07667879   5.13434241   3.02671037   4.53148704  -3.54434936
  -6.56619349  -4.40364755   3.43248843  -2.80522456  28.39048229]
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1953.2896347210485
gradient value of function right now is: [-1.44253264e+00 -1.65314156e-02 -1.24830819e-01 -1.30866461e-02
  1.44253264e+00  1.65314156e-02  1.24830819e-01  1.30866461e-02
  1.40761785e-02  2.22511888e-02  7.75332005e+00  2.63410535e-02
 -5.46634024e-03 -2.54889073e-02 -2.47577028e-03 -5.00326771e-02
  4.80379541e-01  4.25622267e-01  2.47106920e-01  3.78162731e-01
 -3.64415337e-03 -1.69528796e-02 -1.65559099e-03 -3.31104988e-02
 -3.37291650e-03  9.23753751e-02 -6.84852126e-03  1.30102808e-02
 -2.66710016e-02  1.64079487e-01 -4.43262858e-02  2.66295919e-02
 -6.71876030e-03  6.93677569e-02 -1.72877553e-02  9.74645453e-03
 -3.41821470e-02 -4.44187737e-02 -5.57186895e-02 -2.78089396e-03
  1.44705423e-01  4.28200063e-03 -5.96860804e-02  9.74435703e-04
 -2.13740910e-02 -2.80965146e-01 -4.24351670e-01 -4.13521334e-01
  2.65449653e-01 -2.23483518e-04 -8.89779524e-02 -7.48304869e-03
 -1.03938121e-02 -9.06643032e-02 -1.71413582e-01 -1.23215021e-01
  1.54875662e-01 -1.93691848e-01 -5.83690377e-01 -7.38900589e-01
 -3.02068449e-01  5.46828838e-01 -8.69215233e-02 -3.35959149e-01
  6.37174847e+00]
supnorm grad right now is: 7.753320045331052
Weights right now are: 
[  2.54883328  -5.77707511  -1.25259945  -3.96117303  -3.33905252
   5.79153875   1.8239055    5.37625608   1.43863285   8.35698381
   2.32490036  10.15699233  16.8513327   11.39667445  18.1433103
   1.41762336   0.76352917  -1.7838714    5.12018496  -2.10559644
  16.06866371   9.64817008  17.9366189    3.28192483   7.37941854
   5.29353967   6.62361766   3.81811191   4.91873833   2.49109245
   7.09120612   3.61052778 -13.64745231   6.49594979 -11.23180773
   5.39813376   4.00364785   1.51114146   7.63118702   0.70430146
  -0.94716968  10.78320484   4.32569879  11.15903614   8.41049316
  -5.40691373   3.84676656  -3.07630524  -1.96825716  29.894511
   2.99099153  20.78746308   9.07543344  -5.35311255   6.65478863
  -3.03324207   4.99025299   2.74660132   4.63561849  -3.3224556
  -6.78700197  -3.95731005   2.95937404  -3.06396169  28.09284658]
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1948.1162612848534
gradient value of function right now is: [ 1.32900107e+00 -1.33524803e-02 -8.65412817e+00 -1.12606194e-02
 -1.32900107e+00  1.33524803e-02  8.65412817e+00  1.12606194e-02
  3.30304541e-02  5.48138289e-02 -8.37207306e+00  5.90090055e-02
 -4.75638336e-03 -2.42421127e-02 -2.05237542e-03 -4.21861323e-02
 -6.54160429e+00 -7.08587106e+00 -7.72115362e+00 -7.27318617e+00
 -3.56328635e-03 -1.79828478e-02 -1.54815589e-03 -3.10740846e-02
 -4.15853942e-03  1.17571033e-01 -6.13437493e-03  8.83153879e-03
 -1.59370434e-01 -1.65434694e-01 -2.44391441e-01  2.78302374e-04
  1.35661864e-01  6.85185155e-01  2.17512095e-01  3.63643633e-02
 -1.88408678e-01 -4.07214460e-01 -2.87238463e-01 -2.08067645e-02
  8.87118571e-01  5.91157017e-02  1.86300689e+00  1.43438491e-01
 -2.17892063e-01 -4.04917929e-01 -3.04827649e+00 -7.35206428e-01
  1.25590212e+00  2.95757132e-02  3.63424267e+00  1.21075258e-01
 -1.70941207e-02 -6.24397555e-02 -2.04455956e-01 -8.99305991e-02
  1.28809809e+00 -1.79809335e+00 -1.61583030e+00  9.83321462e-02
 -2.29990961e+00  4.56561237e+00 -3.09129334e+00  1.93477535e+00
  1.92866521e+01]
supnorm grad right now is: 19.286652070726873
Weights right now are: 
[  3.45097491  -6.24850998  -1.3935761   -4.65995741  -4.24119414
   6.26297362   1.96488215   6.07504046   2.37230991   9.70348609
   1.5718068   11.52012413  17.31805375  11.80884416  18.90874211
   2.0428607    0.2755187   -2.19830737   4.9282692   -2.44695029
  16.47720033  10.0022093   18.66312105   3.86028286   6.82377144
   5.36798293   6.4871339    3.7558179    4.22235066   2.43001585
   6.62205865   3.63919719 -13.73527658   6.75216848 -11.1626241
   5.50067932   3.34107703   1.60101625   7.12910087   0.32615703
  -0.63392313  10.83519585   4.77726652  11.36656224   8.23462957
  -5.54245796   3.67277363  -3.13041104  -1.36395361  31.22177313
   3.49104064  21.85465172   8.98074135  -5.49476623   6.91896488
  -2.88204409   5.72183386   2.28544145   4.56984924  -3.13390933
  -6.78901936  -3.31321621   2.68528468  -2.53477759  27.71297022]
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -1952.0178084626793
gradient value of function right now is: [-8.24637514e-03 -2.13493494e-02 -2.11774634e+00 -2.01433283e-02
  8.24637514e-03  2.13493494e-02  2.11774634e+00  2.01433283e-02
 -3.26080338e-03 -4.45800515e-03 -1.68608232e-02 -3.14334455e-03
 -1.13933181e-02 -4.15133101e-02 -5.39351334e-03 -6.56327746e-02
 -7.42977924e-01 -9.25110539e-01 -6.92053553e-01 -9.90934020e-01
 -9.81128170e-03 -3.55533472e-02 -4.66358334e-03 -5.60305081e-02
  4.24298321e-03  1.76636252e-01  4.12159934e-03  3.33615986e-02
  3.04726475e-02  1.80184261e-01  3.02405382e-02  4.88036397e-02
  6.13931262e-03  3.04390218e-01  3.27210888e-03  3.94554236e-02
  4.38410907e-02 -8.67377683e-02  4.30771487e-02 -3.59540605e-03
 -1.32343384e-01 -7.24403096e-04  6.60901675e-02  5.13172050e-03
 -1.13242627e-01 -3.63627160e-01 -2.08561808e+00 -8.20710891e-01
 -2.06561838e-01 -5.19491458e-03 -3.11892102e-02 -6.38168992e-03
 -3.43775590e-02 -1.39283505e-01 -5.52369786e-01 -2.76372798e-01
  4.30739349e-01  5.02987132e-02 -1.28922439e+00 -5.93641269e-01
  4.02673582e-01 -5.74098259e-01 -1.61498528e+00 -5.81314770e-01
  7.65297787e+00]
supnorm grad right now is: 7.65297787296257
Weights right now are: 
[  3.11978198  -7.4987901   -0.96190062  -6.01056944  -3.91000121
   7.51325374   1.53320667   7.42565249   2.6289207   10.4762748
   1.9702989   12.17786275  17.04763539  11.77640239  18.54926638
   1.99157392   0.4169445   -2.00595531   5.13999966  -2.21719973
  15.99770153   9.85669318  18.13963615   3.71142254   7.52676067
   5.7527796    6.95292923   4.62210426   4.85864844   2.64756391
   7.32892857   5.19139803 -14.04098114   7.18229788 -11.4789031
   6.19089206   3.90881158   2.22210004   7.83438116   1.58490422
  -0.71690739  11.46249722   4.33639078  11.50130009   9.39650581
  -5.35071252   2.9162965   -3.62997917  -1.56256327  31.81066656
   3.37069041  22.74473575  11.08501989  -6.49321863   5.68866769
  -4.13161449   5.43506659   2.1958685    3.17524885  -3.59795889
  -6.23296694  -4.31157926   1.1624223   -3.15325812  27.80341038]
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -1955.2608525399312
gradient value of function right now is: [ 9.56510600e-01  2.10051302e-02  2.12283199e-01  2.25169835e-02
 -9.56510600e-01 -2.10051302e-02 -2.12283199e-01 -2.25169835e-02
 -1.46768098e-02 -4.38774211e-02 -6.23417069e+00 -4.30239348e-02
  9.26324170e-03  2.94012028e-02  1.36134860e-03  2.74914447e-02
 -1.10949439e+00 -9.66774114e-01 -1.68776520e+00 -1.01640508e+00
  9.13690892e-03  2.88728562e-02  1.36184059e-03  2.68767561e-02
  6.91653460e-03 -1.71810456e-01  7.71142498e-03 -4.88034835e-02
  2.00915974e-02 -2.09268888e-04  2.97229135e-02 -2.16947606e-02
  5.89483295e-02 -1.59223290e-01  5.43226466e-02 -2.70365406e-02
  3.29146895e-02  2.38538227e-01  4.45299969e-02  4.66692581e-02
  4.87061342e-02  2.25451041e-02  6.69771741e-01  4.89856529e-02
  5.36429459e-02  3.97879559e-01  6.07220545e-01  4.99140739e-01
 -2.64802322e-01 -1.25280444e-03  7.06012172e-01  9.28129435e-03
  2.35711571e-02  1.92874848e-01  2.67127107e-01  2.05032179e-01
  3.52039614e-02 -4.13459444e-01  1.50448527e-01  4.71523955e-01
 -5.14712523e-01  3.14189161e-01 -3.25592562e-01  5.36111118e-01
 -2.55915420e+00]
supnorm grad right now is: 6.23417069497736
Weights right now are: 
[  3.60423994  -6.28278638  -0.62723574  -4.77760902  -4.39445918
   6.29725002   1.19854179   6.19269207   2.55367918  10.14201647
   1.60342327  11.76479494  18.93143667  13.75822871  19.5876852
   3.94726877   0.13280897  -2.14829719   4.88392868  -2.33023236
  17.82632777  11.86574599  19.02688235   5.7243991    7.59562315
   4.03352445   7.36919918   3.18159208   4.86537624   1.50813747
   7.62374238   4.11589052 -13.96494264   6.80042178 -11.12614389
   6.01411144   3.90372627   2.57883896   8.1429376    1.35547232
  -0.60761822  11.93090937   4.65456584  11.72367711   8.84315725
  -4.40646286   4.07432063  -2.45678902  -1.72898631  32.36442672
   4.09610058  23.07707241  10.93519138  -5.6956699    7.27809355
  -3.06078452   4.89277549   2.22887316   4.57601334  -2.78436602
  -6.86994874  -4.00775164   2.41540549  -2.56347911  27.75892917]
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1956.2752566013537
gradient value of function right now is: [-6.23045599e-01 -1.13982510e-02  4.49575305e+00 -1.09259466e-02
  6.23045599e-01  1.13982510e-02 -4.49575305e+00  1.09259466e-02
  1.35578433e-02  3.40038698e-02  4.14789414e+00  4.61114764e-02
  1.63709183e-03 -5.74406925e-03  6.97745037e-04 -8.68300883e-03
  1.18811201e+00  1.49927029e+00  8.78951576e-01  1.45704985e+00
  2.29910748e-03 -2.40775861e-03  8.28433976e-04 -5.43590990e-03
 -1.50228623e-02 -4.52366606e-02 -1.09546931e-02  3.89563208e-03
 -1.40171553e-01  3.76681760e-01 -1.07205858e-01  6.25204347e-02
 -4.66392095e-03 -3.47750884e-01  5.61719642e-03 -1.75835028e-02
 -2.22006962e-01  2.72939669e-01 -1.64838605e-01  2.54233016e-02
  7.04093873e-01  5.57546769e-03  7.72252008e-02  5.44233420e-04
  1.36657450e-01  1.18579422e-01  1.67935039e+00  3.81288669e-01
  1.20754437e+00  2.03582690e-02  3.29455821e-01  3.28078185e-02
  5.60051820e-03 -8.95082788e-02 -1.68563473e-01 -1.53141753e-01
 -1.02463461e-01 -2.61739435e-01  5.71477495e-03  4.92457167e-01
 -6.69410604e-01  1.32306696e+00  3.96102386e-01  1.13253731e+00
 -2.60293655e+00]
supnorm grad right now is: 4.495753052093057
Weights right now are: 
[  3.40334755  -6.72341103  -0.50965765  -5.33208236  -4.19356679
   6.73787466   1.08096369   6.74716541   3.29400945  11.26895577
   1.8771941   12.83757446  18.07538331  13.19595954  19.20402755
   3.84100135   0.42742128  -1.81778375   5.39754005  -1.97742205
  16.85261528  11.12172498  18.53902718   5.47174712   7.06359112
   4.92990009   6.82054504   4.39405552   4.3549401    1.86876057
   7.20331614   4.60996097 -15.22982179   7.72855729 -11.8281386
   7.38634557   3.25521368   2.3970255    7.69042398   1.69342903
  -1.07318852  10.46542896   4.31674566  10.47028904   7.80907449
  -5.75654321   2.86619242  -2.98903805  -1.33087861  32.94948407
   4.06735561  23.54531397   7.29148509  -6.95569195   6.81143249
  -3.68583505   4.89558579   3.61825295   5.46993788  -2.77535861
  -6.79955321  -3.77175447   2.74422664  -2.66848954  27.99864979]
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1953.9323156646778
gradient value of function right now is: [-2.75671996e-01 -9.62889282e-03 -4.67999950e-01 -9.26705370e-03
  2.75671996e-01  9.62889282e-03  4.67999950e-01  9.26705370e-03
  1.03527106e-01  1.32038855e-01  2.18099267e+00  1.40854911e-01
 -1.82801078e-03 -1.85794942e-02 -1.12044190e-04 -2.85627159e-02
  2.82935539e-01  1.83538447e-01  1.73839729e-01  1.63966551e-01
 -1.65410270e-03 -1.63534779e-02 -1.09023031e-04 -2.49075312e-02
 -8.58317038e-02  5.14225766e-02 -1.10191864e-01  9.62120581e-03
 -4.00341425e-01  1.74089854e-01 -4.63566297e-01  4.73249778e-02
  4.55572765e-03  1.65157256e-02 -4.86661965e-03  3.75693530e-03
 -4.94548783e-01  1.63385969e-02 -5.56748916e-01  1.28209221e-02
  2.81319774e+00  4.78797419e-02  2.92207634e-01  1.37351552e-01
  2.15652075e-02 -1.19139966e-01 -6.03019444e-02 -2.39443550e-01
  5.33548040e+00  6.11066717e-02  8.89874588e-01  2.06432639e-01
 -1.53336162e-02 -1.21219048e-01 -2.50507382e-01 -1.68986831e-01
  2.18833635e-03 -2.76620775e-01 -8.27304672e-01  2.21872999e+00
 -1.34210616e+00  3.97693327e+00 -1.15700455e+00  7.46717023e+00
  5.51658792e+00]
supnorm grad right now is: 7.467170229250882
Weights right now are: 
[  3.57934071  -7.10894293  -1.0803269   -5.6336003   -4.36955995
   7.12340657   1.65163294   7.04868335   3.48873199  11.40157106
   1.80692975  13.03065247  18.4497167   13.33778389  19.32215152
   3.67072903   0.66070116  -1.87061497   5.99437052  -1.98592216
  17.14955574  11.21707252  18.61984483   5.3318197    6.54488656
   4.89196887   5.95827974   4.2217517    4.21462161   1.32252525
   7.1456446    4.81097114 -15.33180257   8.16843983 -13.65843395
   9.55386701   3.34410529   1.28090141   7.73215537   1.99098719
  -0.34171217  10.62184564   4.22959009  11.70925546   7.13277815
  -5.98528212   3.08670162  -3.02635056  -1.18677445  33.10517402
   2.98784737  24.21631361   7.44047177  -7.38707524   6.97236895
  -3.65413936   4.52665295   3.88504119   5.47634004  -2.74007883
  -7.22686295  -3.21152899   2.72320631  -1.94637388  27.88373555]
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1951.1708431392688
gradient value of function right now is: [-6.05545983e-01 -3.05727136e-03  6.12866974e+00 -2.70667246e-03
  6.05545983e-01  3.05727136e-03 -6.12866974e+00  2.70667246e-03
 -1.45638330e-02 -3.10765799e-02  3.88584585e+00 -3.66246777e-02
  1.07672609e-03  1.21970051e-03  6.14850686e-04 -3.22514089e-04
  2.57339320e+00  2.93825269e+00  2.74839278e+00  2.92196821e+00
  1.35798346e-03  2.20764272e-03  7.14554611e-04  8.68441024e-04
  7.71099206e-04 -3.94515312e-02  6.72862073e-04 -3.30733056e-03
  9.67661872e-02  1.97725081e-01  6.96595671e-02  5.00115553e-02
 -4.82547125e-02 -4.03303813e-01 -4.29340518e-02 -6.25786296e-02
  1.41933691e-01  2.01334193e-01  9.10520565e-02  4.25744413e-02
 -6.91484822e-01 -4.28778207e-02 -9.38539612e-01 -1.12983049e-01
  1.03405487e-01  1.44688367e-01  2.23494966e+00  4.66825549e-01
 -6.77474363e-01 -1.64521530e-02 -1.06602111e+00 -6.17352238e-02
  3.59478749e-03 -1.77970094e-02  1.21426870e-01 -7.56518765e-03
 -7.26122111e-01  6.36451741e-01  6.61641836e-01 -2.47531787e-01
  6.02395086e-01 -9.66860870e-01  1.57115118e+00 -6.51694793e-01
 -1.07247213e+01]
supnorm grad right now is: 10.724721278104944
Weights right now are: 
[  3.20608913  -7.65422733  -0.61022461  -6.17026425  -3.99630837
   7.66869097   1.18153065   7.5853473    1.50943369   9.81615821
   2.19880164  11.56973312  17.4648083   13.25821551  19.16713703
   3.52255878   0.35982184  -1.90626302   5.33136888  -1.95653395
  16.2303733   11.14959953  18.53157545   5.20152081   8.56938064
   5.44127772   8.01592604   6.26905508   5.6718872    1.70958977
   8.09624356   6.13181706 -14.86347573   7.61692385 -12.01247812
   8.27259436   4.66424867   2.31411896   8.65063481   4.04939582
  -2.33650805   9.23514401   4.59986694  10.28228125   6.41749808
  -6.51277206   3.44715354  -2.31444866  -2.59144663  31.85881453
   3.65114953  23.75945311   5.17001485  -8.7551006    6.39886975
  -4.39307492   5.24896684   4.75251777   6.22582269  -3.59522725
  -6.31173223  -4.23662724   3.39705548  -2.93177514  28.04504014]
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1955.4791523071742
gradient value of function right now is: [-2.90817554e-01 -3.60520794e-03 -1.00479397e+00 -3.81123049e-03
  2.90817554e-01  3.60520794e-03  1.00479397e+00  3.81123049e-03
  1.39577142e-02  4.05433738e-02  2.03627619e+00  4.24425832e-02
 -7.55269060e-04 -7.42964437e-03 -9.69457786e-05 -8.32628748e-03
 -8.10541348e-02 -2.15323933e-01  5.35769909e-02 -1.96322043e-01
 -7.34197177e-04 -7.07350731e-03 -9.84549742e-05 -7.86101075e-03
 -5.52328922e-03  1.61789680e-02 -7.43088753e-03  4.70524836e-03
 -8.26725831e-02 -9.23038978e-03 -1.35410542e-01  1.65766005e-02
 -1.72262119e-02  1.16090486e-01 -1.07165201e-02  9.16988374e-03
 -1.00448754e-01 -7.00128612e-02 -1.76201872e-01 -2.29768661e-03
  2.71163598e-01 -1.59171926e-02  1.41010614e-01 -3.29027001e-02
 -1.88823717e-02 -4.82025330e-02 -6.98070722e-01 -1.75976752e-01
  1.26651681e+00 -5.98156189e-03  6.74077464e-01 -1.05605595e-02
 -3.06230478e-02 -4.80225232e-02 -1.31434867e-01 -9.00778086e-02
 -9.36709551e-02  1.22905962e-01 -1.93391075e-01 -4.95988309e-01
 -1.20583435e+00  3.10059678e+00 -2.60816843e-01 -5.36622875e-01
 -2.32489568e-01]
supnorm grad right now is: 3.10059678048456
Weights right now are: 
[  3.44638722  -7.05564879  -1.01924971  -5.58438223  -4.23660645
   7.07011242   1.59055575   6.99946528   1.996588    10.82292191
   2.06590866  12.70112262  17.97549734  13.92711262  19.44153226
   4.2565675    0.13509814  -2.1412415    5.4340096   -2.18310814
  16.71795813  11.81816007  18.76231901   5.93286092   8.08977974
   5.30033589   7.55723823   6.07418096   4.0280504    1.22434345
   6.86042677   5.45728262 -15.61782239   8.55483317 -12.71960844
   9.15285206   2.91407519   1.88150554   7.45044171   2.77607726
  -1.72762046   8.70107341   4.89790608  10.05395051   6.56905446
  -7.00854302   2.83011184  -2.55974324  -1.57883702  33.20724689
   3.92815758  24.82751603   5.5480981   -8.5802819    6.69469722
  -3.93601928   4.37592603   5.35153031   6.45835633  -3.43098123
  -7.43416491  -2.7244102    3.01010628  -2.86008701  27.54159389]
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1957.4755229778084
gradient value of function right now is: [ 1.28432657e+00  3.71557720e-03  1.21783311e-01  4.57927549e-03
 -1.28432657e+00 -3.71557720e-03 -1.21783311e-01 -4.57927549e-03
 -4.82861928e-04 -3.58905562e-02 -9.44062905e+00 -6.13667655e-02
  5.90303156e-04  5.15368904e-03  2.74601611e-05  1.55557939e-03
  2.16695035e-02  3.98061625e-02  1.80034633e-01  3.81464496e-02
  7.56648864e-04  6.99280467e-03  3.25988812e-05  2.73884337e-03
  1.14326929e-04 -1.49217483e-02  4.48559315e-04 -2.55219061e-04
  2.06190997e-01 -1.85743115e-02  8.59540506e-02  1.57031734e-02
 -1.21333696e-02  3.76335641e-02  5.10065842e-03  2.56916928e-03
  4.79095399e-01  1.58286736e-02  1.96562441e-01  6.67743689e-03
 -9.15458885e-01 -2.62683912e-02 -3.18996016e-01 -8.48108370e-02
  6.07568628e-03 -6.78535524e-03 -2.67229038e-01 -1.75342711e-02
 -1.48052367e+00 -1.47955614e-02 -3.68732968e-01 -6.50222470e-02
 -2.77984604e-02 -4.34827830e-02 -3.54555320e-02 -2.28932471e-02
 -1.00896004e-01  2.32489584e-01  2.41406406e-01 -3.23691440e-01
  8.91169058e-01 -1.87741031e+00  4.29417407e-01 -1.80170985e+00
 -4.10310809e+00]
supnorm grad right now is: 9.440629049444738
Weights right now are: 
[  3.9295202   -6.20828484  -0.87183602  -4.74337429  -4.71973943
   6.22274848   1.44314206   6.15845734   1.70870314  10.53128188
   1.6530033   12.50091934  19.14941293  14.94004929  20.13687493
   5.46873079   0.21113894  -1.95579159   5.60063821  -1.9842028
  17.94676762  12.81724467  19.51627213   7.17232852   9.49311958
   4.44413221   8.16502654   5.53577794   4.08588388   0.83987018
   7.3494983    5.09005917 -16.57934769   8.69417359 -12.61052624
   8.97519114   2.77497798   2.28519183   7.8590083    2.69747272
  -2.48010802   8.00878359   4.25873121   9.276087     7.43417057
  -6.53178726   3.00707103  -2.05854089  -1.793632    33.80437977
   3.94087987  25.4401421    5.98086774  -8.43577229   7.26267324
  -3.41378389   4.71752472   5.23011267   7.37894169  -3.08902915
  -6.76722304  -3.66585154   3.46908943  -2.24335892  28.16268208]
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1949.8035753007257
gradient value of function right now is: [-1.23267507e+00  2.03880245e-02  2.61522767e+00  2.02656497e-02
  1.23267507e+00 -2.03880245e-02 -2.61522767e+00 -2.02656497e-02
 -1.70545453e-03 -1.39574677e-02  8.05553345e+00 -1.15412249e-02
  8.83792743e-04  1.70047230e-02  2.40830924e-05  2.55004463e-02
  1.52407404e+00  1.90066133e+00  1.92121107e+00  1.88481649e+00
  8.53968622e-04  1.58641646e-02  2.49955108e-05  2.32714427e-02
 -2.35760469e-04 -2.54430779e-02 -2.05658323e-04 -8.97462488e-03
  1.91441411e-02 -8.83082611e-02  4.86866655e-02 -8.88783971e-02
 -6.39874791e-02 -1.85542070e-01 -7.20436692e-02 -4.22744222e-04
 -5.73179215e-02  3.18594442e-02  4.19025708e-02 -4.72884484e-02
 -2.14920821e-01 -3.81912747e-03 -1.19198202e+00 -6.04923035e-02
 -3.44337643e-03  1.18598784e-01  1.32833485e+00  3.54600153e-01
 -2.04994391e-01  3.59412309e-03 -1.63106149e+00 -3.13361681e-02
 -1.20363649e-02  2.00836380e-01  2.92609816e-01  2.20843402e-01
 -5.95162039e-01  3.83603514e-01  6.29830161e-01  1.64057098e+00
  4.68239783e-01 -3.99398381e-01  1.51833046e+00  8.55486046e-01
 -3.12797612e+00]
supnorm grad right now is: 8.055533452431893
Weights right now are: 
[  3.02347413  -6.1176245   -1.1281972   -4.71315815  -3.81369337
   6.13208813   1.69950325   6.1282412    1.70795258  10.43189072
   2.69570597  12.07167943  19.79283681  15.30974181  21.51950624
   6.39885652   0.05742369  -2.04811349   5.45932339  -2.03760883
  18.46885926  13.08813574  20.74764284   8.00252343  12.53910157
   4.49082415  11.2341573    5.14533253   4.52445406   0.64884943
   8.11469291   4.52516679 -16.27530226   8.3749021  -13.20952279
   8.40906362   2.83259111   1.54875567   8.3307399    1.39753707
  -2.70425084   9.21828025   3.95961329  10.42096763   8.25495436
  -5.51953292   3.68087272  -1.37165714  -2.43763385  35.22748255
   3.01385662  25.87705955   6.26126948  -7.77972427   8.13069304
  -2.51275845   4.43359883   5.53828185   8.02833221  -2.74382254
  -5.85834873  -4.55696022   4.15784753  -1.92239278  28.26702622]
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1958.2950561661185
gradient value of function right now is: [ 4.93719587e-01 -6.02598888e-04  1.26455063e+00 -3.48082182e-04
 -4.93719587e-01  6.02598888e-04 -1.26455063e+00  3.48082182e-04
  2.01367857e-03  8.10832403e-03 -3.81347851e+00  5.15257110e-03
 -3.57269310e-05 -7.28158527e-04  4.41219795e-06 -3.21438957e-03
  6.18398670e-01  7.62716245e-01  5.94548877e-01  7.53610284e-01
  3.71862343e-05 -1.38898665e-04  2.46033669e-05 -2.31181307e-03
 -8.62093867e-04 -5.19176476e-03 -1.25282921e-03  2.14469887e-03
  3.24683316e-02  7.43781735e-02 -1.13430914e-02  1.74010747e-02
 -8.77128259e-03 -1.15158925e-01  8.70961544e-04 -3.10348480e-03
  5.62669919e-02  7.33980299e-02  5.10799204e-03  1.12329492e-02
 -1.62026053e-01 -6.88616531e-03 -4.10664174e-02 -3.01245970e-02
  2.87914563e-02  3.87524534e-02  6.99465408e-01  1.73323301e-01
  6.17767120e-02 -6.82795105e-03  3.60316366e-01 -3.33398721e-02
 -2.10742852e-02 -4.78617660e-02 -5.15959684e-02 -3.95816063e-02
  3.83324408e-02 -1.39052835e-01  2.51474637e-01 -2.81430621e-02
 -3.56145659e-01  4.29642009e-01  3.98118819e-01 -6.64386449e-01
 -4.33216838e+00]
supnorm grad right now is: 4.332168382934274
Weights right now are: 
[  4.09281236  -6.80622065  -1.02355882  -5.45692836  -4.8830316
   6.82068429   1.59486486   6.8720114    3.00466687  11.75688996
   1.79385397  13.0677043   18.43829001  14.29619085  19.93662398
   5.46043047   0.16664682  -2.02899925   5.37017033  -2.00697526
  17.08128557  12.0303186   19.12876865   7.00916943  14.6762355
   6.16828397  12.1441703    6.57689779   4.01519455   1.53816961
   7.18968255   5.60677851 -15.4826452    8.65713626 -13.36009238
   8.17017152   2.8665949    2.00817913   7.68049086   2.63169296
  -1.19509297  10.58266833   4.47317043  11.78846732   8.86417457
  -5.77799533   3.02181165  -1.6516446   -1.69217036  35.56732827
   3.50612355  25.68303925   6.53119525  -8.95989168   7.26402338
  -3.4027224    4.98461344   4.20082596   7.82462053  -3.34106327
  -7.11592393  -3.24609616   3.95085182  -2.41745395  27.92413812]
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1958.031477597063
gradient value of function right now is: [-1.17719720e-01  3.74178248e-03 -1.49040763e+00  3.95155854e-03
  1.17719720e-01 -3.74178248e-03  1.49040763e+00 -3.95155854e-03
  5.55264500e-04 -4.65484925e-03  8.93843414e-01 -8.19380262e-03
  3.69705278e-05  5.15085216e-03  1.09583276e-05  6.69308109e-03
 -1.32636487e+00 -1.61181504e+00 -1.80977700e+00 -1.59556362e+00
  4.03046144e-05  5.32967918e-03  1.20918129e-05  6.80042151e-03
  1.06255942e-03  6.10656192e-03  3.18043820e-03 -7.93180900e-05
  3.70051128e-02 -9.75954872e-02 -5.31074474e-03 -2.05388310e-02
  2.09294467e-02  1.26196237e-01  6.52696679e-02  2.37178408e-03
  5.88861985e-02 -6.22021301e-02  8.24986639e-03 -9.37046125e-03
 -1.50578829e-01 -2.58742033e-03  3.22202970e-01 -4.79176098e-04
 -1.28681814e-02  7.67123620e-03 -9.71464264e-01 -1.02745329e-01
 -1.33895782e-01 -7.76658479e-03  1.16236822e+00 -9.91430446e-04
 -2.65234002e-04  4.74277162e-02  7.16638704e-02  6.96770517e-02
  4.15258124e-01 -3.20121228e-01  1.06348426e-01 -4.49297470e-02
 -1.94256928e-01 -2.93596341e-03 -5.35897452e-01 -4.90915564e-01
  1.23959836e+00]
supnorm grad right now is: 1.8097769977061728
Weights right now are: 
[  3.91772212  -7.00586527  -1.32913407  -5.69295222  -4.70794135
   7.02032891   1.90044012   7.10803527   3.52418516  11.84961586
   2.05482617  13.20109579  17.92298776  14.48310297  19.07550281
   5.68274873   0.30045734  -1.99020622   5.31120974  -1.97204748
  16.44765691  12.07414785  18.09598373   7.14954972  18.94461303
   7.36040907  14.0831011    6.82950775   4.18434766   0.59466467
   7.52676491   5.04373437 -15.07288617   8.46085457 -13.12109254
   7.90484516   3.15840861   1.11429096   8.1222771    2.42380324
  -1.72489856  10.03484766   5.23766338  11.45735352  10.40240219
  -4.87522542   3.32081959  -1.61287654  -2.21577827  35.89042084
   3.71189356  26.12430629   7.5383823   -8.18200977   8.16033622
  -2.6196133    5.36494294   3.68281943   8.27841631  -3.20926273
  -7.04494676  -3.61640649   3.62323406  -2.77447219  27.93369458]
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1958.2488892702397
gradient value of function right now is: [-4.02991773e-01 -5.60921348e-04  1.70651575e+00 -4.15126703e-04
  4.02991773e-01  5.60921348e-04 -1.70651575e+00  4.15126703e-04
  3.73877877e-04 -9.31391625e-03  3.09653783e+00 -1.23231325e-02
  6.73170921e-05  1.81872771e-04  4.62324078e-05 -1.00464970e-03
  1.28172492e+00  1.60764156e+00  1.50199511e+00  1.60183919e+00
  7.53695723e-05  5.21659099e-04  5.02367661e-05 -4.76263746e-04
 -1.31034921e-03 -1.30005686e-02 -1.97482838e-03 -7.62499349e-04
  5.65864035e-02  7.03990211e-02  5.27210506e-02  9.16482872e-03
 -2.04812948e-02 -1.80664660e-01 -2.87996367e-02 -9.00406317e-03
  8.08607006e-02  7.19171032e-02  7.09440138e-02  8.03718321e-03
 -2.88366064e-01 -9.21453775e-03 -3.25511574e-01 -3.88703389e-02
  3.78102738e-02  6.65043147e-02  1.29154720e+00  3.57326807e-01
 -5.33215547e-01 -8.81174039e-03 -6.06182220e-01 -4.75889150e-02
  2.06477747e-03 -1.06910844e-02  4.16995086e-02  5.77257942e-03
 -2.13432570e-01  1.99380212e-01  2.58952555e-01 -1.33616963e-01
  1.91228803e-01 -5.29710268e-01  8.90896148e-01 -5.88408388e-01
 -4.99384479e+00]
supnorm grad right now is: 4.9938447938678365
Weights right now are: 
[  3.93173626  -7.36291216  -1.19741793  -6.10335811  -4.7219555
   7.3773758    1.76872398   7.51844116   2.60227903  11.5268824
   2.13068542  13.06989719  17.79222848  13.8938745   19.37837417
   5.29435372   0.35537997  -1.85075986   5.45000024  -1.83177871
  16.37940106  11.4153675   18.48213875   6.70709631  18.76909695
   7.87565913  14.27323741   7.14279749   3.81719178   1.18956443
   7.97189464   5.34838685 -15.75814564   8.23375095 -13.3620987
   9.36161912   2.72655966   1.54227951   8.44525523   2.6137651
  -1.63006632   9.305338     4.72825002  11.05276719   9.52215321
  -4.86754318   3.46492635  -1.67046933  -2.22285545  37.13206522
   3.20633857  26.90085532   6.93500018  -8.81249482   7.45006503
  -3.26606869   5.72861278   4.08428687   7.99396929  -3.41204595
  -6.73747929  -3.52758347   3.51398442  -2.76560638  28.10293638]
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1950.7901024834002
gradient value of function right now is: [-5.86187695e-01  5.36512856e-02 -6.36787467e+00  5.12547078e-02
  5.86187695e-01 -5.36512856e-02  6.36787467e+00 -5.12547078e-02
  2.63335873e-04  4.81909319e-02  4.83041253e+00  6.12524446e-02
  1.96876753e-06  2.42539252e-02 -2.85376003e-06  6.88510250e-02
 -3.96366708e+00 -5.29286861e+00 -5.43152745e+00 -5.24106830e+00
 -1.70460047e-06  2.23684426e-02 -5.63834190e-06  6.13289033e-02
  6.34552506e-04  4.26682942e-03  6.52073054e-04 -4.00196240e-05
 -3.37519104e-01 -6.94930269e-01 -2.59275295e-01 -2.66569323e-01
  9.17394506e-02  5.48465223e-01  9.58234362e-02  6.92025654e-03
 -5.74346923e-01 -6.86052001e-01 -4.35504850e-01 -3.02209940e-01
  1.49128570e+00  4.36867497e-02  1.16129250e+00  2.21747603e-01
 -1.84531528e-01 -1.52394069e-01 -3.91655047e+00 -5.80651465e-01
  3.00498195e+00  2.58789476e-02  1.88415854e+00  2.56280750e-01
 -9.02926968e-03  4.01845397e-01  4.05318844e-01  3.76718646e-01
  1.01362588e+00 -9.09472223e-01 -4.96384742e-01  1.35032305e+00
 -7.47731743e-01  1.50158325e+00 -3.26204266e+00  7.46635943e+00
  1.77832064e+01]
supnorm grad right now is: 17.783206350925088
Weights right now are: 
[ 3.82071346e+00 -6.31724781e+00 -1.23399440e+00 -5.02347359e+00
 -4.61093270e+00  6.33171145e+00  1.80530044e+00  6.43855664e+00
  1.67527258e+00  1.14836418e+01  2.35321321e+00  1.30687369e+01
  1.89350432e+01  1.51828568e+01  2.03643029e+01  6.87256423e+00
  3.87675614e-02 -2.06132766e+00  5.17766212e+00 -2.02313150e+00
  1.74988487e+01  1.25938353e+01  1.94506820e+01  8.24526360e+00
  1.99041897e+01  8.13643039e+00  1.47510550e+01  6.14325992e+00
  3.24905325e+00  6.24286888e-01  7.81360241e+00  3.87949850e+00
 -1.55487814e+01  8.69168754e+00 -1.30415167e+01  1.00824735e+01
  1.99048407e+00  1.10713254e+00  8.13977728e+00  1.30379109e+00
 -1.05348287e+00  9.98453627e+00  4.86053229e+00  1.14645609e+01
  9.27920569e+00 -5.12367003e+00  3.14970595e+00 -2.09540798e+00
 -1.86308594e+00  3.89682650e+01  3.60304162e+00  2.78972268e+01
  9.03904839e+00 -7.38377213e+00  8.30783535e+00 -2.40050393e+00
  5.79035266e+00  3.96665652e+00  7.23923327e+00 -3.33511646e+00
 -6.40656436e+00 -4.06913974e+00  3.33251325e+00 -1.88873229e+00
  2.80281499e+01]
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1952.1020431330837
gradient value of function right now is: [ 1.53826581e-01 -7.45814404e-03  4.87544431e+00 -7.55295130e-03
 -1.53826581e-01  7.45814404e-03 -4.87544431e+00  7.55295130e-03
  3.19382403e-04  4.67753036e-02 -1.22366128e+00  4.87923702e-02
  4.30470340e-04 -4.14207121e-03  4.63568686e-04 -3.65760540e-03
  1.51132296e+00  2.06803110e+00  1.35851742e+00  1.98305451e+00
  6.29122893e-04 -8.46798957e-04  6.53841509e-04 -1.08351732e-03
 -7.06901260e-05 -2.54830486e-02  7.78122436e-04 -1.49608984e-03
 -1.15382208e-01  2.52237203e-01 -1.75886631e-01  5.85271170e-02
  1.05653661e-03 -3.79663093e-01  2.07261925e-02 -2.25021854e-02
 -1.33944804e-01  1.77525645e-01 -2.03694277e-01  2.57591225e-02
  3.49685357e-01 -5.19705822e-03  2.23664501e-01 -1.34391916e-02
  1.43368096e-01  2.65410335e-01  2.29842984e+00  6.60250296e-01
  1.22543699e+00 -4.80104917e-05  9.86982887e-01  1.51611329e-02
  1.25087835e-02 -9.60516312e-02 -9.72541266e-02 -9.14943275e-02
  1.73855505e-01 -1.08889046e+00  2.75460089e-01 -1.29461436e-01
 -1.41110091e+00  2.88375607e+00  3.69356216e-01  7.56076926e-01
 -2.22183708e+00]
supnorm grad right now is: 4.875444308158028
Weights right now are: 
[  4.37342876  -8.08309201  -0.48709529  -6.64209564  -5.163648
   8.09755565   1.05840134   8.05717869   1.44971034  12.57797122
   1.8239314   13.748889    18.98586355  14.79992683  20.21938402
   6.43761369   0.27677901  -1.55531867   5.65217034  -1.55316409
  17.46001189  12.2656243   19.18915041   7.94027132  21.52690466
   8.79395383  14.55043766   6.02337647   3.3090641    1.70263029
   7.10647231   5.13461318 -15.76237242   8.38340952 -13.60015361
   9.70927763   2.27005898   2.70814866   7.65401836   3.23456282
  -1.20004293   9.68830873   4.97768232  11.07125612  10.14142527
  -4.95819341   3.31094219  -2.52804667  -1.4812561   38.78614023
   3.65028953  27.90141764   9.61512227  -8.13692217   7.62426686
  -3.32812799   5.77422569   3.03987795   6.06316099  -4.5875507
  -7.19038286  -3.40021124   2.68227122  -2.61035253  28.09618205]
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1947.0066621820658
gradient value of function right now is: [ 7.35198982e-02 -1.20045245e-03  3.72400060e+00 -1.50446464e-03
 -7.35198982e-02  1.20045245e-03 -3.72400060e+00  1.50446464e-03
 -2.80356526e-04 -2.89997284e-02 -6.24367856e-01 -3.52246130e-02
  5.78235173e-05 -2.96426993e-03 -8.79286020e-06 -2.11428033e-03
  1.71885373e+00  2.71673878e+00  2.66274912e+00  2.65997817e+00
  9.09823088e-05 -3.37675151e-03  2.01147605e-05 -2.37269046e-03
 -7.46520029e-04 -9.09134613e-03 -1.13442158e-03 -7.56863087e-04
  1.24043280e-01  2.10667916e-01  1.48467279e-01  1.15630584e-02
 -4.42857791e-02 -4.57588306e-01 -7.16027852e-02 -2.19775428e-02
  1.62650953e-01  1.85325153e-01  1.84827531e-01  1.03741656e-02
 -5.73762488e-01 -1.56855996e-02 -5.79315338e-01 -8.35258429e-02
  1.81842770e-01  6.65485701e-02  2.59076986e+00  3.29229020e-01
 -1.08365770e+00 -7.24171382e-03 -1.41486711e+00 -8.74287490e-02
  4.18709106e-02  1.29225350e-02  1.17828670e-01  2.87760574e-02
 -1.11681307e+00  1.32804024e+00  2.81682321e-01 -3.66346054e-01
  8.88529856e-01 -1.75753146e+00  2.00931803e+00 -2.27879686e+00
 -1.75942208e+01]
supnorm grad right now is: 17.5942208045025
Weights right now are: 
[  3.84944611  -8.41239157  -1.05937213  -7.12855454  -4.63966535
   8.4268552    1.63067817   8.54363759   2.73965005  12.68624982
   2.37554685  13.64119864  17.07163528  13.80792843  18.61791245
   5.54047382   0.11192024  -1.76848456   5.40140552  -1.7632188
  15.5452177   11.20853981  17.56167342   6.96410876  22.42117392
  10.82041182  16.01887599   8.07730522   3.707235     2.53853442
   7.48283535   5.56261355 -15.18713463   8.69620103 -13.58210922
  11.63911937   2.46825729   3.28259115   8.01820038   3.51308535
  -1.11879109  10.23520567   5.25338944  11.74520967   8.99098289
  -6.09315642   2.79409473  -3.59979539  -1.77669114  40.83956507
   3.34454134  28.80483596   7.31450766  -8.8981609    6.89872736
  -4.14177501   6.00694009   3.11105779   4.65269297  -5.44738039
  -6.86195226  -4.07794294   2.07166057  -3.04497134  26.87054648]
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1951.3927094972667
gradient value of function right now is: [-2.21621540e-01 -6.28346364e-03 -2.12076719e-01 -7.84225586e-03
  2.21621540e-01  6.28346364e-03  2.12076719e-01  7.84225586e-03
  4.25175467e-05 -3.88785055e-03  1.71195757e+00 -4.50828234e-03
 -5.88479917e-04 -1.70459457e-02 -1.55446676e-03 -1.53554062e-02
  1.49010225e-01  1.50597978e-01  4.37718097e-01  1.55746374e-01
 -7.35302709e-04 -2.02514399e-02 -1.95843529e-03 -1.81178419e-02
 -4.33867853e-04  5.79936786e-03 -1.45939199e-03  2.42998483e-03
  1.44639668e-02  9.23513216e-02  3.26021588e-02  1.85259186e-02
 -1.25355397e-02  4.25928544e-02 -3.85126260e-02  1.46424718e-02
  1.59628125e-02  1.58493577e-02  3.32722560e-02  4.06285607e-03
 -1.38929594e-01 -1.14026143e-03 -1.27841430e-01 -1.58636750e-02
 -1.13750113e-02 -9.40794396e-02 -4.18542707e-01 -1.36732418e-01
 -4.74722222e-01 -3.11870369e-03 -6.46358066e-01 -3.95634480e-02
 -1.04143085e-01 -5.64176216e-02 -2.16259159e-01 -8.97851487e-02
 -2.25552183e-01  3.71133647e-01 -5.23300328e-01 -9.10097421e-02
  3.32445717e-01 -6.39551682e-01  1.41232676e-02 -1.03281612e+00
 -9.77392707e-01]
supnorm grad right now is: 1.7119575709634278
Weights right now are: 
[  3.85488166  -8.88924011  -1.20546186  -7.57642247  -4.6451009
   8.90370375   1.77676791   8.99150552   3.38430734  13.49995487
   2.42329286  14.52412769  15.96444318  13.39410848  17.45117957
   5.02582846   0.28449232  -1.68510367   5.32060323  -1.664606
  14.57805129  10.80566561  16.49779213   6.46198437  24.77717176
  12.35871101  17.54647268  11.80718026   3.48589929   2.89797566
   7.93454721   6.30862062 -14.51784895   8.7120058  -13.73042427
  13.44149007   2.2789717    3.690719     8.46669201   4.17843512
  -0.0833318   11.38468871   5.3077157   12.98249489   7.71186837
  -7.80752919   2.54174658  -4.53661351  -1.62601922  42.44766559
   3.23856212  29.97774803   4.51250546 -10.17046197   5.883513
  -5.45109995   6.21396309   3.5668198    2.96963977  -5.63685341
  -7.14765954  -3.65974199   2.09021976  -2.68203747  27.17955534]
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1953.0651922476547
gradient value of function right now is: [-5.39341669e-01  6.76624019e-03 -1.51541253e+00  7.73050048e-03
  5.39341669e-01 -6.76624019e-03  1.51541253e+00 -7.73050048e-03
 -1.30459419e-05 -7.57898973e-03  4.23149908e+00 -6.09322612e-03
 -2.58286130e-06  4.13261203e-03 -1.19242539e-05  1.15816947e-03
  7.27351901e-02 -5.06491952e-01  1.65050008e-01 -3.24766907e-01
 -6.39029850e-06  5.23022725e-03 -2.93732885e-05  1.28377191e-03
 -7.09969730e-04  6.87146693e-03 -1.32592237e-03 -5.36518844e-05
  1.99900933e-02 -2.92655116e-01  2.39262790e-02 -2.15978461e-02
 -1.38849956e-02  1.65397624e-01 -2.74105954e-02 -4.14004989e-04
  2.47811874e-02 -1.65785084e-01  2.68207857e-02 -3.07844043e-03
 -2.15294656e-01 -1.05386718e-02 -1.19104215e-01 -2.16594443e-02
  3.41410735e-02 -2.22630753e-02 -1.13012987e+00 -1.05167672e-01
 -3.45090986e-01 -5.15722965e-03 -4.67575679e-01 -1.55969594e-02
  1.01204459e-02  4.17843267e-02  7.02825320e-02  4.34700802e-02
 -2.38045331e-01  4.32351140e-01 -5.88633401e-02 -2.28589555e-01
  1.90936186e-01 -3.92533851e-01 -2.73140680e-01 -5.79714641e-01
 -1.99910822e+00]
supnorm grad right now is: 4.231499076524799
Weights right now are: 
[  3.71253177  -6.37272309  -1.18888319  -5.143377    -4.50275101
   6.38718673   1.76018924   6.55846005   3.05570684  12.67555798
   2.72344936  13.79843273  16.2376417   15.4940797   17.94226531
   6.8732406    0.43415553  -1.71675593   5.40883793  -1.58976849
  14.79997704  12.67682185  16.91736321   8.15143473  26.79497828
  13.22983619  18.35386761  12.86562718   4.33715457   0.28301835
   8.54894956   4.52529019 -14.84410595   9.3352423  -13.8299415
  12.1902879    3.08384285   1.88641394   9.15619244   3.45488234
  -0.92240235  10.7280294    5.03019486  12.4465716    8.61384382
  -6.79961481   2.1567646   -4.50929024  -1.99285938  42.99507104
   3.23520397  29.72474615   6.03037218  -7.64827771   8.08406285
  -3.00678087   5.98071898   3.73808097   4.84421731  -4.06475514
  -7.5172207   -3.60314402   2.77342019  -3.05517694  27.40009066]
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1943.2491564868583
gradient value of function right now is: [-9.88142362e-02  1.53280783e-01  1.43945741e+01  2.97145097e-01
  9.88142362e-02 -1.53280783e-01 -1.43945741e+01 -2.97145097e-01
 -1.75043904e-04 -4.01699821e-01  2.65601868e+00 -4.17395778e-02
  5.32332471e-05  3.03822723e-01  7.38482443e-04  2.10854102e-02
  7.65514615e-01  3.84982350e+00  1.45131321e+00  2.15241980e+00
  2.14313303e-04  6.85182800e-01  2.53106294e-03  5.34453635e-02
  6.29080768e-04  1.64649022e-02  4.94049524e-04  3.23073624e-04
  4.12085199e-02 -4.11650809e+00  5.36736938e-02 -4.09343375e-01
 -1.54739411e-02 -6.19410499e-01 -1.42475251e-02 -7.74779183e-03
  4.98877066e-02  2.88529176e-01  6.38102798e-02  1.04629124e-03
 -2.64963949e-01 -1.37162955e-02 -1.57712342e-01 -3.10850273e-02
  1.77773660e-01  1.96453967e-01  2.94968290e+00  4.76546965e-01
 -5.08300310e-01 -1.05331285e-02 -3.13865035e-01 -3.32871730e-02
  7.82457692e-02  9.19869347e-01  1.48349587e+00  1.11725815e+00
 -5.73378351e-01  4.45190222e-01  1.64650005e+00  1.67304361e+00
  1.42379907e-01 -7.02200956e-01  1.51628568e+00 -2.93337810e-01
 -2.37748241e+01]
supnorm grad right now is: 23.774824123527544
Weights right now are: 
[  4.14709373  -5.80159971  -0.50050168  -4.75790963  -4.93731297
   5.81606334   1.07180773   6.17299268   3.04638415  12.97528202
   2.40292111  13.83593416  16.47758478  15.51790635  17.71340856
   6.57303236  -0.31890148  -1.3415154    4.77097256  -1.47533131
  15.46321031  11.98942548  16.41639356   7.20712093  28.86534677
  14.35673095  20.99780865  12.59912003   4.3121186    0.7899613
   8.93158377   4.49331661 -13.72278352   8.72763738 -12.67683941
  11.86962808   2.92115054   4.22647146   9.51446295   3.32563494
  -0.32650586  12.2136684    5.8771333   13.32972541   9.49001277
  -6.23013465   2.09783884  -4.09377788  -1.97400704  44.66239187
   4.15338002  30.40004385   6.64595127  -7.48639493   8.55154763
  -2.67131893   6.80811803   2.88504801   5.4185581   -3.47611342
  -7.26205462  -4.06827897   2.82214532  -2.88455068  27.03155073]
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1952.982193135846
gradient value of function right now is: [-3.31542062e-01 -1.45931270e-03  7.86786586e+00  1.12443441e-02
  3.31542062e-01  1.45931270e-03 -7.86786586e+00 -1.12443441e-02
  1.42899938e-05 -5.70522897e-02  2.82230333e+00 -1.23186635e-02
 -1.65465100e-05  2.96309297e-02  2.26982734e-04  1.66049741e-03
  3.74842869e-01  2.24273215e+00  8.56371380e-01  1.28601406e+00
  3.13425646e-05  8.60461835e-02  9.34673578e-04  7.38146530e-03
  4.50081622e-04  1.57497468e-02  2.57280522e-04  1.31294142e-03
  3.28869142e-02 -6.58879531e-02  3.13702054e-02  3.17565737e-02
 -7.93558354e-03 -4.37220780e-01 -4.52358059e-03 -1.82074057e-02
  4.09273319e-02  1.70690483e-01  3.77973346e-02  1.24205232e-02
 -2.17865425e-01 -1.04636338e-02 -1.20068781e-01 -2.48996854e-02
  8.95205316e-02  6.92492093e-02  2.11224535e+00  2.44355317e-01
 -3.48860210e-01 -9.87962979e-03 -1.38974902e-01 -2.96475758e-02
  1.70309266e-03 -3.11858563e-02  4.91290160e-02 -5.23609457e-02
 -2.67480174e-01  2.20209928e-01  1.27689554e-01 -6.49545588e-01
 -4.63759831e-02 -2.20380564e-01  8.11185281e-01 -7.31413617e-01
 -7.31902331e+00]
supnorm grad right now is: 7.867865863330537
Weights right now are: 
[  4.20746022  -7.39699372  -0.29624942  -5.34729371  -4.99767945
   7.41145736   0.86755547   6.76237676   3.2090801   13.15809832
   2.27189684  14.22440869  15.98959344  15.99485786  17.47219423
   6.74331136  -0.46327832  -0.91399849   5.01231309  -1.21443951
  15.00842071  12.86350589  16.24984657   7.56574396  30.45459114
  16.17910347  22.37940191  14.53853738   4.8790705    0.28580965
   9.24357561   7.02304926 -14.14251889   8.5250758  -13.69483304
  12.34003574   3.70532014   4.81011985   9.98484347   4.66362556
  -1.14100687  11.92209985   5.68296327  12.84151839   8.56864224
  -6.70947077   2.15847697  -4.20362705  -2.67351403  44.74795547
   3.9451241   30.31828295   5.17450874 -10.26263139   6.94714522
  -4.94204568   6.68535872   3.65295796   5.81353499  -4.16856917
  -6.88041308  -3.97966319   3.23680116  -3.35330015  27.97053056]
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1956.276617173736
gradient value of function right now is: [-1.81621225e-01 -3.33350838e-03  1.96778496e+00 -1.53392617e-03
  1.81621225e-01  3.33350838e-03 -1.96778496e+00  1.53392617e-03
  6.77274492e-05 -2.72682153e-02  1.53115174e+00 -8.07556530e-03
 -5.18377742e-05 -4.88760304e-04 -2.43228312e-04 -2.22227717e-03
  1.58436230e-01  1.03241782e+00  3.92125152e-01  5.12541538e-01
 -6.72943589e-05  1.45821973e-02 -2.78009491e-04 -2.31773872e-03
  3.62118136e-04  8.74445304e-03  3.27380332e-04  3.94956316e-04
  3.39186406e-02  1.51848821e-01  5.29466864e-02  6.27592752e-02
 -6.47659509e-03 -1.85750577e-01 -4.65280250e-03  8.07743219e-04
  3.73087325e-02  6.76806542e-02  5.59005591e-02  3.68243849e-03
 -2.07173287e-01 -5.98799613e-03 -8.79737079e-02 -1.86541406e-02
  3.78438320e-02  1.80674506e-02  9.41044773e-01  7.55541726e-02
 -4.78675918e-01 -7.85142566e-03 -1.62253500e-01 -3.20009470e-02
 -1.22417714e-01 -1.04366440e-01 -1.67206182e-01 -1.28350303e-01
 -1.50583766e-01  2.23970160e-01 -1.24429924e-02 -4.42516547e-01
  1.28068085e-01 -4.61754177e-01  4.45986634e-01 -8.07262719e-01
 -3.38781752e+00]
supnorm grad right now is: 3.3878175192112536
Weights right now are: 
[  4.22755248  -7.22020176  -0.67182793  -5.06084385  -5.01777172
   7.2346654    1.24313397   6.4759269    3.28059954  13.08450159
   2.38807794  14.75029472  12.95688556  16.59466664  15.88626512
   5.92170429  -0.32103922  -0.60635062   5.3611155   -0.75670705
  13.06886871  13.23272511  15.57526422   7.20888595  31.48869215
  16.81861735  24.15705927  16.12831922   3.67555547  -0.329968
   8.40806511   6.66274095 -13.94079931   8.088455   -14.40725501
  12.32441541   2.540414     5.95642533   9.20038865   6.68155374
   0.05429047  12.52121545   5.93178695  13.47192808   8.37244005
  -7.21201537   2.32663433  -4.37959425  -1.91002022  46.13265958
   3.79813264  31.31941901   4.18568638 -10.04952806   7.72264441
  -4.54547774   6.43774309   3.64171555   5.7364694   -4.7388097
  -7.18759415  -3.99609827   3.46314016  -3.08472003  27.56554733]
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1956.4174745409239
gradient value of function right now is: [-1.52779907e-01 -1.09148294e-02  1.28151684e+00 -1.50399949e-02
  1.52779907e-01  1.09148294e-02 -1.28151684e+00  1.50399949e-02
  5.30255634e-05 -2.31581675e-03  1.16487928e+00 -1.01242160e-02
 -4.95869793e-05 -1.79864936e-02 -2.65682727e-04 -1.43809150e-03
  2.09298163e-01  8.97667825e-01  5.19592823e-01  5.53597438e-01
 -6.80336127e-05 -1.26293240e-02 -3.14254289e-04 -1.65122647e-03
  3.47094376e-04  7.80259586e-03  7.21210329e-04  4.92316909e-04
  2.95079356e-02  3.01456080e-01  7.47912587e-02  1.02152493e-01
 -5.92011348e-03 -1.85598554e-01 -1.51818106e-02  8.02914265e-04
  2.86492048e-02  4.75519875e-02  6.94934216e-02  3.18979099e-03
 -1.78105229e-01 -4.09693974e-03 -8.23917677e-02 -1.48152287e-02
  5.73658732e-02  1.24063002e-02  9.59962676e-01  6.65211431e-02
 -6.67062816e-01 -7.20505753e-03 -3.65704944e-01 -3.71085171e-02
 -1.25041674e-01 -1.97271180e-01 -4.07094980e-01 -2.45007348e-01
 -2.79970446e-01  3.65229086e-01 -2.66501524e-01 -6.57619803e-01
  2.40491159e-01 -5.71959031e-01  3.61874074e-01 -1.10847462e+00
 -2.93445875e+00]
supnorm grad right now is: 2.934458754695786
Weights right now are: 
[  3.91064149  -8.6322164   -1.18020301  -7.31939495  -4.70086073
   8.64668004   1.75150906   8.734478     1.11896861  15.35256206
   2.67394484  15.08568619  14.15932436  14.11338646  15.01147128
   5.01713338  -0.57755424  -0.72210824   5.52117994  -0.64536706
  14.21125087   9.70078417  14.53250843   5.85609616  30.57642298
  17.99762528  25.29689985  16.74199083   3.0056749    2.27812264
   8.19704517   7.56688694 -13.17827266   8.27822864 -15.04271401
  10.8947142    1.88250892   6.7609735    8.98276666   8.45840058
   1.34598617  13.63265628   6.18973769  14.86757524   8.81464938
  -9.38515305   1.82404026  -6.74775597  -1.37110691  48.20788074
   3.34281328  32.48729023   4.72786026 -10.73279855   6.7782139
  -5.26761296   6.53219987   4.32141977   4.45874177  -5.28629609
  -6.89342322  -3.8698284    1.95855403  -3.29417586  27.64556895]
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1954.9277552282492
gradient value of function right now is: [-1.74275776e-01 -1.48425753e-02  1.77972229e-01 -3.01104838e-02
  1.74275776e-01  1.48425753e-02 -1.77972229e-01  3.01104838e-02
  2.50878581e-05  2.19567993e-02  1.30822792e+00 -7.42762719e-03
 -5.66087947e-05 -3.97092931e-02 -3.95446497e-04 -1.57579471e-03
  1.76399532e-01  3.49675723e-01  4.11449187e-01  3.58106139e-01
 -9.72081571e-05 -7.43549930e-02 -7.73669969e-04 -2.99968011e-03
  3.82107855e-04  4.94884883e-03  1.14641490e-03  7.46592807e-04
  1.64779540e-02  6.31343195e-01  5.67860553e-02  8.33705562e-02
 -5.05519855e-03 -6.80235380e-02 -1.78309786e-02 -1.01959088e-03
  1.57220683e-02  1.70343563e-02  5.21259832e-02  3.00898815e-03
 -1.21516024e-01 -2.47061857e-03 -5.54237406e-02 -1.02990703e-02
  4.73764151e-02 -9.32429680e-03  2.85737433e-01  1.34314773e-03
 -6.18437774e-01 -4.92187342e-03 -3.61195826e-01 -3.10023245e-02
 -7.95339168e-02 -1.44028987e-01 -4.36516878e-01 -2.31431525e-01
 -2.74212219e-01  3.58230612e-01 -5.04640151e-01 -6.19902084e-01
  2.42893553e-01 -5.35714631e-01 -3.68456270e-02 -1.13507535e+00
 -1.77296812e+00]
supnorm grad right now is: 1.7729681205121568
Weights right now are: 
[  4.44338269  -7.37990299  -0.68871651  -6.42203025  -5.23360193
   7.39436662   1.26002255   7.8371133    1.32962308  15.22430223
   2.26177266  15.36774055  14.20121546  14.83013884  15.09242133
   5.1865989   -0.70812668  -0.45987731   5.1778687   -0.84205061
  14.89933969   9.9960668   14.96857509   6.28764783  30.69084312
  17.48046268  25.42233908  16.61752219   3.44753634   1.99178868
   8.76373711   7.5929588  -12.60237553   8.15133002 -14.6925604
  11.55445002   2.11093084   7.74555358   9.34793415   8.19067904
   1.29215181  14.44713582   6.13654803  15.3867446    8.87773381
  -9.47484773   1.81967346  -6.37878382  -1.31871387  49.59499281
   4.14946141  33.10994656   4.31342231 -11.01748257   6.59644418
  -5.50986527   6.55709429   3.70612966   4.34160108  -5.06439821
  -7.23929026  -4.17494399   2.00870061  -3.33533948  27.18656753]
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1955.1242077011746
gradient value of function right now is: [-2.10066592e-01 -1.76692762e-02  6.62593368e-01 -3.48538288e-02
  2.10066592e-01  1.76692762e-02 -6.62593368e-01  3.48538288e-02
  5.30578321e-05  2.35179621e-02  1.60857669e+00 -7.01436426e-03
 -9.62550305e-05 -4.31505222e-02 -6.53986426e-04 -2.68673640e-03
  1.97496748e-01  6.34949446e-01  4.72916899e-01  4.88996133e-01
 -1.44951153e-04 -7.67982495e-02 -1.02316041e-03 -4.39004806e-03
  4.05871580e-04  9.13029965e-03  1.06591961e-03  9.89227341e-04
  1.62929835e-02  6.92463887e-01  5.37371324e-02  8.98511882e-02
 -4.76087877e-03 -1.48674886e-01 -1.39186651e-02  2.77767937e-03
  1.59761089e-02  4.33600264e-02  5.10763653e-02  4.56497810e-03
 -1.10916726e-01 -2.36011408e-03 -5.57262916e-02 -9.45090870e-03
  2.85265874e-02 -1.49683768e-02  6.19772169e-01  1.50963708e-02
 -6.04897508e-01 -5.41708408e-03 -3.05725709e-01 -3.09431097e-02
 -1.34863175e-01 -1.60139304e-01 -4.73727100e-01 -2.50609614e-01
 -2.26697042e-01  2.70780968e-01 -4.57123290e-01 -5.88851821e-01
  2.26120986e-01 -5.38520020e-01  9.56647352e-02 -1.10250333e+00
 -2.21544364e+00]
supnorm grad right now is: 2.215443644084316
Weights right now are: 
[  4.60957744  -6.81612756  -0.7645991   -5.3385178   -5.39979667
   6.8305912    1.33590515   6.75360085   0.86665725  14.84964594
   2.21028494  15.70627719  15.89860467  16.27417601  17.57102032
   7.93348702  -0.47703776  -0.63439186   5.33772489  -1.09534735
  16.86912283  11.51401211  17.28072958   9.05021288  33.13634284
  14.62973658  27.03409347  17.28346428   2.57574582   0.87522188
   8.8357654    7.55898883 -14.5551921    8.44187564 -15.56962964
   9.89717316   1.14382948   4.6683055    9.32630491   8.30414031
  -0.07873855  13.71188379   5.74389689  14.21968193   9.36212327
  -8.46497178   2.44574505  -5.13895302  -1.46755861  50.6191495
   4.51333575  33.10781597   5.210802   -10.88698158   7.28540939
  -5.28608013   6.83031674   3.91155749   6.27653395  -3.98335474
  -7.80954335  -3.72201697   3.85889322  -3.25473376  27.94997332]
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1954.913740672417
gradient value of function right now is: [-1.67485165e-01 -1.81483317e-02  7.55350116e-01 -3.71174646e-02
  1.67485165e-01  1.81483317e-02 -7.55350116e-01  3.71174646e-02
  6.86478209e-05  2.37815744e-02  1.25954432e+00 -6.32267367e-03
 -1.31065917e-04 -4.47705761e-02 -9.62859258e-04 -3.70868851e-03
  2.06228408e-01  7.03298701e-01  5.13027890e-01  5.43660309e-01
 -1.80515277e-04 -8.44397305e-02 -1.51836239e-03 -6.29351245e-03
  4.23217481e-04  1.16930027e-02  1.00956725e-03  1.29258783e-03
  1.68188597e-02  6.99233112e-01  5.06680560e-02  8.18700459e-02
 -5.02901588e-03 -1.74392406e-01 -1.29685220e-02  4.97767643e-03
  1.68531729e-02  5.61645501e-02  4.94893873e-02  6.16879257e-03
 -1.05921374e-01 -2.31178832e-03 -5.76549834e-02 -9.03083594e-03
  1.42967609e-02 -2.49154518e-02  6.89603624e-01 -2.93756613e-03
 -5.85070526e-01 -5.71060495e-03 -2.83297903e-01 -3.01721568e-02
 -1.63856676e-01 -1.43035072e-01 -4.50064061e-01 -2.31747430e-01
 -1.88182607e-01  2.11779144e-01 -4.12379933e-01 -5.11318828e-01
  2.05082357e-01 -5.20671238e-01  9.73454933e-02 -1.06240630e+00
 -2.16209687e+00]
supnorm grad right now is: 2.1620968678966976
Weights right now are: 
[  4.81090681  -6.79549492  -0.86616818  -5.71545669  -5.60112604
   6.80995856   1.43747422   7.13053974   0.80962502  15.48887987
   2.09819583  15.72174295  16.17966458  15.8645428   17.55402435
   7.80076553  -1.05868944  -0.82677571   4.87286448  -1.31542898
  17.49386878  10.88097392  17.83483074   8.85247468  32.36503908
  15.19732482  26.62806861  16.32080994   2.19261432   1.69305251
   8.84041378   7.78984689 -13.30720441   8.19628217 -15.34203822
   9.85996728   0.72317403   5.66850964   9.39582692   8.0010987
   1.00550897  14.60992229   6.70919121  15.61887157   8.73121601
  -9.13096083   2.50553462  -5.77066713  -1.49117063  52.49395423
   4.89543173  34.54585893   5.30538677 -11.42248847   6.31023442
  -5.63897318   7.48613873   4.12182231   5.25936871  -4.71035198
  -7.80370283  -3.56444775   2.9593481   -3.38688378  27.01016135]
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1423.6677877197355
W_T_median: 1202.571356342516
W_T_pctile_5: 760.6387433203989
W_T_CVAR_5_pct: 673.686454992416
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.9
F value: -1954.913740672417
-----------------------------------------------
