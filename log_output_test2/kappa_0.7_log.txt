Starting at: 
2022-06-20 18:03:38
tracing parameter entered from terminal:  0.7


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[ 0.10347998  0.18844875 -0.3666709   0.62803316 -0.89369922 -0.17398511
  0.93797695  0.78704989 -0.60791207 -0.16293226 -0.31685198  0.28094308
  0.0404241   0.17453202  0.0940472   0.01169373  0.2300954  -0.23784803
  0.78511084 -0.41859022  0.4809118  -0.01155852  0.07219357 -0.14482284
  0.4701344  -0.18827011 -0.8138637  -0.24629474  0.28361272  0.33354483
 -0.63777411 -0.25343004 -0.81551088 -0.26234589  0.20198453 -0.15135741
  0.25264285 -0.29817275  0.41496663 -0.58895503 -0.60305385 -0.63454123
  0.3979274   0.74701442  0.57452389 -0.67377327  0.6493153   0.07340044
 -0.29694484  0.52758424 -0.14347696  0.04319718 -0.28527617 -0.63077443
  0.13133703 -0.58713125  0.12759166  0.87507529 -0.19770888 -0.66759109
  0.25529887 -0.48501395  0.58877641 -0.72315372] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1260.6521530687958
W_T_median: 1222.3920506735662
W_T_pctile_5: 834.1581876304141
W_T_CVAR_5_pct: 746.6575474940535
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1690.6299383482258
gradient value of function right now is: [-4.27089997 -1.18168687 -3.16003453 -0.58429765  4.27089997  1.18168687
  3.16003453  0.58429765  2.33602571  2.78031717  2.46706425  3.77754118
  0.3554284   0.52394038  0.38840295  0.71576603 -0.87541658 -0.93430892
 -0.91594701 -1.26598773  0.03681295  0.04362021  0.03912373  0.0593653
  0.21370563  0.14161001  0.25278298  1.06398928 -0.20621691 -0.1341206
 -0.23947237 -0.92683031  0.23031804  0.15680473  0.27682074  1.16981763
 -0.42194355 -0.26632067 -0.48142185 -1.88647282  0.67599222  0.19126999
  0.4486423   0.26404165  0.26970202  0.0868829   0.19521486  0.11773847
  0.69745984  0.22031937  0.51498771  0.30364646 -1.2340699  -0.61252164
 -1.49909822 -0.87097188  1.57949324 -0.07833974 -1.97855235  0.1124676
 -2.43225537  0.18347315 -3.32995601  0.14508867 12.09953421]
supnorm grad right now is: 12.099534205403991
Weights right now are: 
[ 0.59304397  0.47688507 -0.13521831  0.79363223 -1.38326321 -0.46242143
  0.70652436  0.62145082 -0.96620712  0.88664396 -0.84018169  1.85513837
  0.22518723  1.81969467  0.10613882  2.25615124  1.30876637  0.21715882
  1.97240685 -0.29819984  1.69665546  1.7494671   1.23628261  2.0308033
 -0.88856158 -0.8001028  -2.04904095  1.66814871  2.26812449  1.81718629
  1.29494277 -0.56726815 -2.12932835 -0.8467978  -1.00643197  1.51537736
  1.94205092  0.69136542  1.97819496 -1.77644785 -1.21749152  2.79144899
  3.84582878  4.79214202  0.18646937  2.81070408  4.04600099  3.76790067
 -0.97514345  3.81555713  3.03241637  3.77765865  1.55125169 -1.58930739
 -0.20426171 -2.1909079   0.8846063   2.450707    1.8670279  -2.67168622
  0.554123   -2.8593785   1.40890988 -2.70203667 30.33215396]
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1689.1563440917516
gradient value of function right now is: [ 13.33225463   2.21730258   1.42411895   0.4599002  -13.33225463
  -2.21730258  -1.42411895  -0.4599002   -6.27656073  -3.12528941
  -6.32586294  -3.86161763  -1.13209022  -0.3570096   -1.1402813
  -0.44966987   0.41620116   0.64380557   0.43264665   0.7905499
  -0.06440254  -0.02695766  -0.06498735  -0.03364054  -0.49642543
  -0.31529156  -0.65859987  -0.99555976   0.47491408   0.30109591
   0.62767066   0.78170292  -0.46764344  -0.2974844   -0.62221633
  -1.03597485   1.00430566   0.63463509   1.31786011   1.57072972
  -2.43134852  -0.37031082  -1.1459649   -0.46889525  -1.00889563
  -0.15356888  -0.48310534  -0.19487131  -2.75442402  -0.44501617
  -1.38706903  -0.56350923   2.4971075    0.71332436   1.56696224
   0.83041044  -1.8982222    1.21220171   1.45926948  -1.26217917
   2.61027141  -1.74484087   2.15111949  -1.7922049  -25.74889367]
supnorm grad right now is: 25.74889367420017
Weights right now are: 
[ 0.81056287  0.43879013 -0.20777985  0.82534806 -1.60078211 -0.42432649
  0.7790859   0.58973499 -1.28892238  1.17905241 -1.16914898  2.27650468
  0.7397935   2.18531753  0.5882641   2.69829238  2.40671903  0.67288875
  3.02373478  0.08573409  2.10051042  2.39537598  1.63077361  2.79663922
 -1.28486559 -1.16183035 -2.48612234  2.01609214  2.7593998   2.21810927
  1.77669269 -0.8831661  -2.46180464 -1.21093361 -1.43751277  1.83189355
  2.41640934  1.02240046  2.39485792 -1.93713896 -1.31457915  3.15683144
  4.20719311  5.13529804  0.07026307  2.83746656  3.98755453  3.74822255
 -0.99977205  4.03813535  2.47469545  3.83883277  1.88192796 -2.84201508
  2.07021378 -2.42872423  0.46864276  1.73094077  3.43898019 -2.74565324
  0.14044448 -2.69561335  2.8138728  -2.60403981 30.49487559]
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1697.41177290705
gradient value of function right now is: [-5.09318843e+00 -2.21349565e-01  6.11664398e-01 -6.05853365e-02
  5.09318843e+00  2.21349565e-01 -6.11664398e-01  6.05853365e-02
  4.52318062e+00  3.77521779e+00  4.41031713e+00  4.05566424e+00
  3.36596947e-02  6.80042219e-02  3.09517640e-02  7.40289550e-02
 -1.74604377e-01  6.09646039e-01 -1.58954191e-01  7.78496369e-01
  4.80827452e-03  4.23037642e-03  4.64305897e-03  4.51186159e-03
  1.81509942e-01  1.07995594e-01  3.84003608e-01  1.95877843e-01
 -1.45477534e-01 -8.91868778e-02 -3.21437609e-01 -4.48174113e-01
  1.74899840e-01  1.04345560e-01  3.68202825e-01  9.47331035e-02
 -3.07871740e-01 -1.84620819e-01 -6.49873900e-01 -7.13971745e-01
  1.01165500e+00  1.04100276e-01  5.14278141e-01  1.31496003e-01
  3.46076054e-01  4.02924973e-02  2.38082599e-01  5.32379505e-02
  1.42828058e+00  1.80415006e-01  1.56933770e+00  2.67065690e-01
 -1.69287844e+00 -3.46217305e-01 -2.22216504e+00 -5.26056030e-01
  1.37681241e+00 -5.11531916e-01 -1.43564629e+00  5.74251434e-01
 -7.78691725e-01  9.21776707e-01 -2.05108213e+00  7.83573825e-01
  2.27790325e+01]
supnorm grad right now is: 22.779032468934197
Weights right now are: 
[ 0.8110971   0.27983117 -0.50407203  0.79630507 -1.60131633 -0.26536753
  1.07537807  0.61877798 -1.40906869  1.35688236 -1.30859082  2.59072935
  1.47019373  2.52563154  1.29866697  3.07908549  3.56087571  0.6990258
  4.13347268  0.03324666  2.7520318   2.98697432  2.26193252  3.4575489
 -1.55957857 -1.19147984 -2.46342636  2.63712944  3.10828432  2.37004759
  1.99914295 -1.12963843 -2.63819533 -1.17301407 -1.3469573   2.48947318
  2.85974895  1.22903751  2.6184723  -2.42198918 -1.19976973  4.63031305
  5.58387852  6.71932213  0.41969266  4.24551058  4.95672255  5.22794002
 -0.39359775  5.73998079  2.42275593  5.45754751  2.02278289 -3.44069814
  2.98750077 -2.76729993  0.85432979  1.67299938  3.29276336 -2.91706476
 -0.8559908  -2.6176313   2.58244137 -2.87134296 30.5999309 ]
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1697.1588471911516
gradient value of function right now is: [ 6.09620062e+00  2.52313269e-01  1.26257736e+00  4.87913910e-02
 -6.09620062e+00 -2.52313269e-01 -1.26257736e+00 -4.87913910e-02
 -1.97170079e+00 -1.24503745e+00 -2.06404488e+00 -1.76265536e+00
 -9.41197704e-02 -3.63991759e-02 -9.56414312e-02 -4.95028871e-02
  3.85432907e-01  1.33665780e+00  4.03821608e-01  1.87578795e+00
 -9.27513518e-03 -5.19910656e-03 -9.44863774e-03 -7.08321187e-03
 -1.98340035e-01 -8.91784960e-02 -8.26765009e-02 -9.42314892e-01
  1.69581732e-01  7.58318229e-02  5.85761745e-02  2.52945680e-01
 -1.87205518e-01 -8.42333413e-02 -7.73575756e-02 -1.05472784e+00
  3.55544918e-01  1.59218547e-01  1.43810955e-01  6.66558587e-01
 -1.43052949e+00 -1.66901074e-01 -4.82893346e-01 -2.11794769e-01
 -3.83698015e-01 -4.36813180e-02 -1.05038350e-01 -5.52524174e-02
 -7.58984416e-01 -9.89224566e-02  4.22507618e-01 -1.07106681e-01
  1.40936584e+00  1.55211162e+00  2.42799060e+00  1.73803729e+00
 -7.00030321e-01  5.87675427e-01  9.66190711e-01 -2.45171199e-01
  4.98295025e-01 -2.03160568e+00  9.19155525e-01 -9.05414588e-01
 -1.47193684e+01]
supnorm grad right now is: 14.719368375843613
Weights right now are: 
[ 0.83550408  0.30680194 -0.83600006  0.87944037 -1.62572331 -0.2923383
  1.40730611  0.53564268 -1.47188746  1.60819781 -1.40192192  2.92250137
  1.82029958  2.73847605  1.63613211  3.28277102  3.95002175  0.52757796
  4.52329312 -0.04908357  3.01810694  3.41909782  2.51091358  3.91110691
 -2.42091411 -1.48737085 -2.38277461  2.81094098  3.45195188  2.33932699
  1.84124184 -0.55168408 -3.48266512 -1.45075956 -1.20946903  2.70994473
  3.40683793  1.33618861  2.50363349 -2.58008539 -1.81131588  4.79259516
  6.62254046  7.09402953  0.19559686  4.49298548  5.77160347  5.64589035
 -0.03238254  6.49964557  2.19901016  6.090265    2.17164069 -3.06487025
  3.4606085  -2.30699999  1.66540785  1.78913641  3.81131986 -2.49809203
 -1.53540354 -2.89490228  2.91444827 -2.4399252  30.27944319]
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1693.8291781700457
gradient value of function right now is: [-7.04496496e-01  2.20106518e-02  1.02072022e+00  7.46128816e-03
  7.04496496e-01 -2.20106518e-02 -1.02072022e+00 -7.46128816e-03
 -2.24742279e+00 -2.57710975e+00 -2.19866514e+00 -3.15823559e+00
  5.51797118e-03 -7.10515773e-03  5.70935114e-03 -9.85883850e-03
  7.82494642e-01  1.37311151e+00  7.92795953e-01  2.61085525e+00
  1.35973379e-04 -3.76495897e-04  1.43533463e-04 -5.55322206e-04
 -3.74157812e-02 -2.13668611e-02 -1.00993562e-01 -1.26427457e+00
  5.05689765e-02  2.69692508e-02  1.05732381e-01  2.10326029e-01
 -4.06849376e-02 -2.27019640e-02 -1.01061005e-01 -1.37897697e+00
  9.78369113e-02  5.22823727e-02  2.10149043e-01  6.73336952e-01
 -5.44863487e-01 -9.38094662e-02 -2.69497889e-01 -1.13420718e-01
 -1.20466710e-01 -2.42877421e-02 -8.01869716e-02 -2.99315140e-02
 -6.32442935e-01 -1.34031204e-01 -4.44298780e-01 -1.73358915e-01
  8.95754115e-01  3.41116451e+00  4.68429360e+00  3.57840754e+00
 -6.40689193e-01 -5.25703770e-01  1.15654152e+00  9.32241892e-01
  2.23038292e-01 -1.28399498e+00  1.11585128e+00  3.51677009e-01
 -2.28565865e+01]
supnorm grad right now is: 22.85658650967165
Weights right now are: 
[ 0.45005882  0.10614887 -1.92940082  0.73344738 -1.24027805 -0.09168523
  2.50070687  0.68163566 -1.37927597  1.63300727 -1.28678385  3.10611132
  2.44028963  3.33647641  2.24322493  4.06603548  5.26107345  0.1876744
  5.76683877 -0.75931872  3.62355111  4.24085851  3.09794435  4.9560017
 -2.9195018  -1.68369753 -2.72541434  3.15572873  3.71156     2.54122495
  2.59832696  1.00281986 -3.90189217 -1.58460832 -1.49074743  3.09483309
  3.68672806  1.484387    3.07440738 -2.51619367 -1.82912267  5.08943239
  7.27789358  7.54107547  0.23702471  4.88632865  6.07397156  6.12475548
  0.06293737  7.13466419  1.47350704  6.34001502  3.75013203 -2.76833106
  3.86743364 -2.08649263  1.97488446  2.21126618  4.01302252 -2.5993179
 -1.67376701 -3.07353976  3.2454258  -2.51560975 29.8362125 ]
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1697.6204166825648
gradient value of function right now is: [ 1.08945967e+01  5.68001922e-02 -9.87980887e-02  7.83469453e-03
 -1.08945967e+01 -5.68001922e-02  9.87980887e-02 -7.83469453e-03
 -5.15366800e+00 -1.94592527e+00 -4.89550054e+00 -2.31703220e+00
 -1.33462148e-02 -3.06547196e-03 -1.28255257e-02 -3.54953107e-03
  3.56722182e-01  6.31165039e-02  3.39500314e-01 -3.17014433e-01
 -6.03967531e-04 -1.51273839e-04 -5.77300493e-04 -1.67108898e-04
 -1.77591946e-01 -9.13764427e-02 -3.69144605e-01  6.79826272e-02
  1.74783682e-01  9.08986090e-02  3.92033547e-01  1.80914414e-01
 -1.77577490e-01 -9.33636645e-02 -3.81342746e-01  1.05162077e-01
  3.88096565e-01  2.00316007e-01  8.19657972e-01  3.34279629e-01
 -1.65068863e+00 -2.18655592e-01 -7.47788613e-01 -2.58124750e-01
 -4.36388169e-01 -5.32638187e-02 -2.48099942e-01 -6.49744927e-02
 -1.31790126e+00 -1.96722746e-01 -1.78116815e+00 -2.67744450e-01
  6.23042538e-01 -4.57842625e-01  5.26237339e-01 -4.13303915e-01
 -1.25790656e+00  1.17938201e+00  1.11611462e+00 -1.61201729e+00
  2.17796034e+00 -2.43722144e+00  1.63729011e+00 -1.81245650e+00
 -2.00471940e+01]
supnorm grad right now is: 20.047194000484776
Weights right now are: 
[ 0.67329144  0.13975668 -2.14565343  0.74387918 -1.46351068 -0.12529304
  2.71695947  0.67120387 -1.24989905  2.0644996  -1.17724976  3.75581614
  2.96228725  3.84078533  2.73877588  4.63587986  4.64270704 -0.05102198
  5.14932581 -0.88721653  4.2553654   4.6376562   3.69776632  5.43005208
 -3.50744711 -1.82212553 -2.41597349  3.34541237  4.52797282  3.02358922
  2.94450382  0.77632911 -4.25350661 -1.53314815 -1.07506011  3.26354074
  4.4538394   1.91576518  3.25404252 -3.11013023 -2.26973778  4.92614623
  7.92983986  7.46937124 -0.06740505  5.17264038  6.76633485  6.51476282
  0.39925445  7.85656347  1.07082054  6.71116227  4.20812976 -3.02778159
  3.60724691 -2.35957989  2.68073951  2.42555034  4.06065737 -2.58217072
 -1.55480581 -3.64979643  3.37687301 -2.56641104 30.03888444]
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -1692.4967098987856
gradient value of function right now is: [-1.65714915e+01 -4.17042208e-02 -1.19434221e+00 -5.92493291e-03
  1.65714915e+01  4.17042208e-02  1.19434221e+00  5.92493291e-03
  6.52644591e+00  1.93597696e+00  6.22913525e+00  2.52793577e+00
  2.24996878e-03  6.21094527e-04  2.15599094e-03  9.05321960e-04
 -9.60843208e-01 -1.23460403e+00 -9.41082254e-01 -2.64717693e+00
  1.76827260e-04  6.36619230e-05  1.67472679e-04  9.63307957e-05
  1.43222464e-01  6.35653345e-02  4.19160675e-01  9.08832308e-01
 -1.55387166e-01 -6.96312919e-02 -4.61026196e-01 -1.77502021e-01
  1.28045436e-01  5.86891596e-02  4.13650186e-01  1.03335382e+00
 -3.47824780e-01 -1.57958030e-01 -1.03977905e+00 -5.90612713e-01
  1.52448603e+00  1.79894544e-01  4.34404274e-01  2.05582752e-01
  3.96844991e-01  4.10219397e-02  1.73346155e-01  5.04413509e-02
  1.10197546e+00  1.94649932e-01  2.71551639e+00  3.20198606e-01
 -6.76493552e-01 -1.43908202e+00 -3.75211544e+00 -1.76875250e+00
  1.00506160e+00 -2.93147271e-01 -2.26853549e+00 -5.04062943e-01
 -9.52640432e-01  1.80166993e+00 -2.85999246e+00  2.66015387e-01
  3.24893330e+01]
supnorm grad right now is: 32.48933301803158
Weights right now are: 
[ 0.44040747  0.05250965 -1.66673486  0.73023158 -1.2306267  -0.03804602
  2.23804091  0.68485147 -0.97746258  2.21741685 -0.87286469  4.15099926
  3.56405144  4.37086634  3.30178461  5.32646841  4.21622016  0.22619499
  4.71664914 -0.43743472  4.93294189  5.19011944  4.30894292  6.23559092
 -3.86987304 -1.910172   -2.21985916  3.49241407  4.70454517  3.18027463
  3.4022818   1.47608546 -4.51775276 -1.61295014 -0.87072476  3.35457747
  4.71420277  2.12093078  3.55539249 -3.37064157 -1.94697919  5.82089828
  8.61706596  8.3569187   0.19502816  6.04672923  7.18008639  7.37313453
  0.56611058  8.51617927  1.02067081  7.25000614  4.9430929  -3.42848193
  3.20426908 -2.73921153  3.17871256  3.56392884  4.06483371 -2.50615981
 -0.92826488 -3.43997935  3.20335671 -2.55280459 30.19475113]
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1696.6077297538457
gradient value of function right now is: [-2.25584336e+01 -1.47983010e-02  1.01537508e+00 -1.67859491e-03
  2.25584336e+01  1.47983010e-02 -1.01537508e+00  1.67859491e-03
  5.39217888e+00  1.44692003e+00  4.97648698e+00  1.84226877e+00
  3.32456556e-03  4.25625840e-04  3.08309237e-03  1.48769899e-04
 -5.67927548e-02  1.81183212e-01 -2.61845347e-02  1.92656468e+00
  2.89347612e-04  3.97912832e-05  2.64615040e-04  3.56362485e-06
  1.02474216e-01  5.50268828e-02  4.60554308e-01 -1.55838914e-01
 -5.17610419e-02 -2.90620751e-02 -2.94206682e-01 -2.32036908e-01
  1.11793540e-01  5.91569760e-02  4.57503497e-01 -2.48501154e-01
 -1.59267736e-01 -9.44556939e-02 -9.58663042e-01 -3.72566641e-01
  7.97075379e-01  7.08453750e-02  2.88254387e-01  8.46083502e-02
  1.92097831e-01  1.66941283e-02  1.27006433e-01  2.10942740e-02
  8.00583748e-01  1.77388626e-01  2.64078788e+00  2.45699459e-01
 -1.55355024e-01  1.84913176e-01 -8.55959357e-01  1.54486805e-01
  6.99392070e-01 -5.11178350e-01 -1.25157474e+00  4.77328500e-01
 -9.92930913e-01  1.25084672e+00 -1.52883457e+00  6.74173379e-01
  1.86059553e+01]
supnorm grad right now is: 22.558433605203223
Weights right now are: 
[ 0.39015409  0.12838955 -1.26311006  0.79665754 -1.18037333 -0.11392591
  1.8344161   0.6184255  -1.30951274  1.54503313 -1.19840914  3.89779983
  4.11754518  4.9534343   3.80246382  6.74533886  4.52602435  0.67066929
  5.02359603  0.10536126  5.48337893  5.90280728  4.81783645  8.4875147
 -4.18808367 -1.80153356 -2.14736739  3.56970474  4.87661388  3.23260083
  4.04009187  2.31046295 -4.66388305 -1.33720927 -0.72376563  3.4063243
  4.86122619  2.08932474  4.0798548  -3.12377881 -2.03033073  5.99355328
  9.43075871  8.5567076   0.31925162  6.23198688  7.38257034  7.58869809
  0.23895721  9.23048664  0.9523596   7.54500718  6.20982311 -3.31831505
  3.2380446  -2.58396594  4.12481616  3.69259075  4.00678711 -2.79015367
 -1.05295993 -3.01696767  3.49460028 -2.65112633 30.26474523]
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1699.725994653813
gradient value of function right now is: [ 1.57829704e+00 -9.91229169e-04 -1.15461401e+00 -1.91972944e-04
 -1.57829704e+00  9.91229169e-04  1.15461401e+00  1.91972944e-04
 -9.60801352e-01 -4.51248747e-01 -9.29831761e-01 -4.74944933e-01
  7.35087269e-05  2.16780084e-06  5.37190340e-05  7.17188738e-05
 -2.09753713e-01 -4.79102100e-01 -2.39833125e-01 -2.95899658e+00
  7.52885931e-06  8.43650992e-07  5.77252788e-06  7.64688805e-06
 -2.56601386e-02 -3.02341689e-03 -6.37173924e-02  6.03617813e-01
  2.31305256e-02  6.69828063e-03  6.87736438e-02  1.30051460e-01
 -2.28883453e-02 -1.26896685e-03 -5.35857063e-02  7.32403647e-01
  6.96003932e-02  1.61523831e-02  1.88188459e-01 -2.02462058e-02
 -5.25523701e-01 -7.65922270e-02 -1.34346141e-01 -8.89126345e-02
 -6.86496564e-02 -1.14843492e-02 -9.85526527e-03 -1.35161011e-02
 -4.01623359e-01 -1.13461603e-01 -8.65349094e-01 -1.44184709e-01
 -1.97518199e-01 -1.38513310e+00 -1.73568003e+00 -1.40271934e+00
  1.55962357e-01  5.43179810e-01 -7.00592024e-03 -1.73621140e+00
  1.24363965e-01 -3.15552652e-01  1.98467218e-01 -1.60512135e+00
  1.56307216e+01]
supnorm grad right now is: 15.630721611343667
Weights right now are: 
[ 0.67079511  0.07875715 -2.05141838  0.74037639 -1.46101435 -0.06429351
  2.62272443  0.67470666 -1.50596799  1.44465057 -1.4141714   4.21847601
  4.65888682  5.54948675  4.29330039  7.89305052  4.32697718  0.47646916
  4.79844497 -0.43378088  6.06455621  6.4122074   5.34719254  9.41051765
 -4.98355288 -1.983018   -2.02999029  3.94508201  5.51560254  3.28629751
  4.40020693  2.71364781 -5.43413834 -1.55337101 -0.6006009   3.77976332
  5.46346437  2.09487619  4.27151245 -3.82556935 -2.41057717  5.93672969
 10.05437391  8.51300401  0.19118743  6.18041863  7.70247547  7.59008506
  0.19835164  8.88124949  0.78733789  7.13734161  6.63887986 -3.45330559
  3.23857087 -2.75939641  3.97382424  2.98116575  4.3808586  -2.67854978
 -1.65545689 -3.19132663  3.92690266 -2.53085947 30.59149044]
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1698.932805820917
gradient value of function right now is: [-4.81041752e+00 -6.35892392e-04  4.79610759e-01 -8.34494759e-05
  4.81041752e+00  6.35892392e-04 -4.79610759e-01  8.34494759e-05
  3.59544180e+00  1.72484184e+00  3.17026821e+00  1.88982177e+00
  1.90714477e-04  5.87700821e-05  1.63668845e-04  4.03720561e-05
  1.32911974e-01  2.95462601e-01  1.65935641e-01  1.40219791e+00
  2.07427221e-05  6.11692372e-06  1.78117151e-05  3.81931786e-06
 -3.02636785e-03  1.42570402e-02  4.79335162e-01 -4.04823018e-01
  7.29064084e-03 -6.95270001e-03 -2.75698112e-01 -1.66579430e-01
 -1.34029184e-03  1.43323966e-02  4.60224132e-01 -5.11539555e-01
  2.21749425e-02 -2.88385793e-02 -1.09821794e+00 -1.90281434e-01
 -2.80779874e-01 -4.98585455e-02  3.99468027e-02 -4.10158731e-02
  2.59601508e-02  2.64339829e-03  7.61527766e-02  4.59872815e-03
  7.15795886e-01  2.01276415e-01  4.19930649e+00  3.25600546e-01
 -1.08893397e-01  1.05394588e+00  4.09729476e-01  1.15120880e+00
  4.05315073e-01 -2.78884207e-01 -1.17169710e+00  6.27217296e-01
 -6.67920117e-01 -1.18761645e-01 -1.75048594e+00  2.34865372e-01
  1.78391907e+01]
supnorm grad right now is: 17.839190673164765
Weights right now are: 
[ 0.72680489  0.22325791 -1.49800056  0.88299735 -1.51702412 -0.20879427
  2.06930661  0.5320857  -1.49276248  1.23259525 -1.35262947  4.24618786
  5.2837399   5.8922182   4.94357734  8.40582123  4.6015123   0.93084433
  5.06648872  0.34675498  6.68620982  6.68215084  5.99493249  9.99684555
 -5.30005161 -2.22776087 -2.23979501  3.04555739  5.85581514  3.44116797
  4.68648912  2.15526752 -5.73038173 -1.85584649 -0.85981234  2.83096977
  5.74739491  2.28166932  4.59406359 -4.08832743 -2.674329    5.26249926
 10.64725228  8.01345746  0.84271307  6.39143733  7.46120365  7.9730958
  0.52148916  9.24489461  0.92877969  7.57311401  6.5066221  -2.81750567
  3.58915367 -2.12767843  3.61652576  3.80801209  4.14222438 -1.91196751
 -1.59887366 -3.27294949  3.43326775 -2.30272598 30.64993841]
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1701.0102997087847
gradient value of function right now is: [-8.70657895e-01  7.21135155e-05  5.31348667e-01  1.09592226e-05
  8.70657895e-01 -7.21135155e-05 -5.31348667e-01 -1.09592226e-05
  7.80996013e-01  3.10489146e-01  7.23421761e-01  1.63440001e-01
 -2.83954521e-06  1.33693713e-07 -2.35919021e-06 -1.65986570e-06
  4.84661094e-01  5.99602127e-01  5.17684149e-01  2.02332373e+00
  6.35570889e-07 -1.04487734e-08  5.44532120e-07  5.83159814e-07
  1.89447559e-02 -7.94262593e-03  1.04584924e-01 -5.57938910e-01
 -1.25847970e-02  1.51304928e-03 -5.14026425e-02 -8.96475793e-02
  1.65503773e-02 -9.40419568e-03  8.95582679e-02 -6.42345036e-01
 -5.68157036e-02  1.07723034e-02 -2.85506289e-01  8.28921549e-02
  4.83629001e-01  1.21175391e-01 -4.84475970e-02  1.07819531e-01
 -5.92176422e-03  1.19639892e-02 -1.94810276e-02  8.27922805e-03
 -8.84439728e-02  6.12299381e-02  1.65737111e+00  9.26484445e-02
  2.04494864e-01  1.79164400e+00  2.53195693e+00  2.07053946e+00
 -1.67812853e-01 -4.40830717e-01  4.77588711e-01  2.31514434e+00
  4.77772017e-01 -6.68395738e-01  8.84762571e-02  1.84238172e+00
 -7.23730782e+00]
supnorm grad right now is: 7.23730781681795
Weights right now are: 
[ 6.65325662e-01  4.24827567e-02 -2.51120820e+00  6.50155610e-01
 -1.45554490e+00 -2.80191187e-02  3.08251424e+00  7.64927438e-01
 -1.41537059e+00  9.78852192e-01 -1.27042948e+00  4.43512612e+00
  5.72457560e+00  6.28963663e+00  5.34867368e+00  8.90969297e+00
  4.45070894e+00  7.98972825e-01  4.89535851e+00 -3.64378174e-01
  7.26043867e+00  6.94739834e+00  6.52138535e+00  1.02288900e+01
 -5.42215667e+00 -2.71459828e+00 -1.95978523e+00  3.48928101e+00
  5.22331389e+00  3.82266455e+00  5.02074478e+00  3.03472742e+00
 -5.86119685e+00 -2.25525156e+00 -5.55745868e-01  3.31365144e+00
  5.23745095e+00  2.77801594e+00  4.62213092e+00 -4.85858489e+00
 -1.97240851e+00  6.07103544e+00  1.14707984e+01  8.85955123e+00
  6.01770437e-01  5.89012846e+00  6.91423570e+00  7.53320116e+00
 -4.21045344e-01  8.47389918e+00  1.57919243e+00  7.10999083e+00
  7.54937916e+00 -2.69960804e+00  3.43186732e+00 -1.97393961e+00
  3.19193113e+00  3.25238387e+00  4.31920284e+00 -1.63786898e+00
 -1.41247835e+00 -3.24274856e+00  3.43407998e+00 -1.77059488e+00
  3.01048460e+01]
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1702.1258155451533
gradient value of function right now is: [-2.64830599e+00  6.31971299e-05 -5.48158610e-01  1.25097208e-05
  2.64830599e+00 -6.31971299e-05  5.48158610e-01 -1.25097208e-05
  1.40313044e-02  1.30545881e-01  1.85181864e-01 -2.30922989e-02
 -2.43488351e-05 -7.27435682e-06 -1.91285692e-05 -5.91475055e-06
 -2.87544591e-01 -4.08075727e-01 -3.30260628e-01 -2.13281623e+00
 -6.40897199e-06 -1.58633103e-06 -5.22640396e-06 -8.31425055e-07
  3.39628624e-02 -2.67644003e-03 -2.13245547e-01  5.05485016e-01
 -1.24209476e-02  2.32514224e-04  5.17612844e-02  4.06110202e-02
  3.39712869e-02 -1.82467894e-03 -2.01095876e-01  5.95525125e-01
 -6.83589258e-02  6.83908860e-03  4.25646835e-01  5.71519342e-02
  5.63237463e-01  1.10728998e-01  4.12701643e-02  1.03697759e-01
  5.28321788e-02  1.24473957e-02 -5.35696869e-02  9.28404015e-03
  4.05470780e-02 -1.70617090e-03 -1.79929681e+00 -6.81666631e-02
 -2.38790173e-01 -1.38294573e+00 -1.35435733e+00 -1.51359065e+00
 -7.21603046e-02  4.09378968e-01  1.37288831e-01 -6.73579743e-01
  1.85004464e-01  6.63192162e-01  5.69358942e-01 -1.32656135e-01
  1.25687217e+01]
supnorm grad right now is: 12.568721657689247
Weights right now are: 
[ 0.61090679  0.30717061 -2.80109237  1.06817528 -1.40112603 -0.29270698
  3.37239842  0.34690776 -1.4165641   0.84546249 -1.21793139  4.55605098
  6.58317396  6.82768905  6.2166833   9.54738748  4.22723666  0.23876835
  4.59570236 -0.58354534  7.90779298  7.25186784  7.21211967 10.71998772
 -5.79970147 -3.06190092 -2.39208536  3.60027792  5.49046612  4.186238
  5.66937388  3.32471474 -6.27544332 -2.57529378 -0.96356204  3.42700815
  5.62802531  3.44407352  5.30963903 -5.01693124 -2.03639113  5.32345189
 11.24072737  8.15643955  0.96896367  5.20618197  6.67437096  7.01334228
 -0.31213895  8.18087942  0.86501696  6.84280083  6.94017536 -3.16736788
  3.40846302 -2.37464152  4.11931418  3.3605423   4.27286699 -1.77843088
 -1.4559386  -3.18874429  3.51405536 -1.94617129 30.41967842]
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1690.9713270156471
gradient value of function right now is: [ 1.65621312e+01  1.50904037e-04  1.69802412e-01  3.61250320e-05
 -1.65621312e+01 -1.50904037e-04 -1.69802412e-01 -3.61250320e-05
 -8.93342503e+00 -3.99057690e+00 -8.18890274e+00 -5.82554086e+00
  3.35984892e-05  9.41318138e-06  2.93778812e-05  1.31674933e-05
  1.19167144e+00  7.67721903e-01  1.11309808e+00  2.97808346e-01
  1.21870213e-05  3.44292544e-06  1.06191974e-05  4.57788673e-06
 -5.75805683e-02 -2.88455069e-02 -1.00036330e+00 -2.06264641e-01
  2.02640157e-03  7.57472590e-04  2.00606140e-02  1.07287244e-02
 -5.72081761e-02 -2.88509697e-02 -9.84254444e-01 -1.65525844e-01
  1.31047910e-01  6.00931369e-02  2.03943549e+00  7.11247961e-01
 -9.75629661e-01 -1.80682911e-01 -4.07528847e-01 -1.79550482e-01
 -1.32643007e-01 -2.43554737e-02 -1.44964746e-01 -2.75226510e-02
 -1.82215249e+00 -5.36406028e-01 -7.71191517e+00 -7.72963565e-01
  7.78390171e-01  3.03985032e-01  4.61159709e+00  5.28540453e-01
 -2.03111723e+00  9.57660252e-01  3.06795946e+00 -1.28674602e+00
  5.10856096e-01 -1.97384589e+00  4.09340855e+00 -1.22253140e+00
 -3.33091672e+01]
supnorm grad right now is: 33.30916722597605
Weights right now are: 
[ 0.66357931 -0.17386563 -2.77555961  0.43660944 -1.45379854  0.18832926
  3.34686566  0.97847361 -1.39238574  0.11550968 -1.2750536   4.44034286
  7.05106729  7.14837609  6.67461196 10.39163871  4.38269167  0.30965432
  4.71483166 -0.42557438  8.22721914  7.34542815  7.5127906  11.26066865
 -6.7461481  -2.62523818 -2.10619046  3.71652233  6.89948453  4.19424864
  5.92985871  4.47254961 -7.185202   -2.14198752 -0.69822112  3.55560382
  6.63952147  3.00120935  5.114124   -5.51832001 -2.96918632  4.56711506
 11.45103619  7.49395315  1.12882825  4.59822521  7.2625365   6.63590535
  0.0391979   8.01898666  0.98346291  6.96676571  7.27909908 -3.20685713
  3.35905703 -2.40915523  4.11270829  3.35057881  4.15861285 -2.17065769
 -2.45854083 -3.15272619  3.37509455 -2.47507851 29.87539185]
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -1703.4750307000832
gradient value of function right now is: [ 1.57460629e+00  2.06277958e-05  5.91730997e-01  8.78153782e-06
 -1.57460629e+00 -2.06277958e-05 -5.91730997e-01 -8.78153782e-06
 -1.19193920e+00 -4.40982524e-01 -1.14020636e+00 -8.00510010e-01
 -2.06932787e-07 -4.81996774e-08 -1.93993726e-07 -5.64710104e-07
  2.73367466e-01  1.70442938e-01  2.86663281e-01  1.79483063e+00
  1.09616559e-07  2.52338163e-08  1.04085993e-07  4.16978711e-07
 -2.91079331e-02 -6.91778930e-03 -6.00476856e-02 -3.67756090e-01
  3.82047459e-03  7.98737145e-04  6.44856943e-03  5.54580411e-03
 -2.71717046e-02 -6.58154344e-03 -5.79479368e-02 -4.28241208e-01
  9.55825134e-02  2.06785777e-02  1.67615636e-01  8.40507479e-02
 -7.49421521e-01 -1.01820928e-01 -1.77445757e-01 -1.00039229e-01
 -7.03037199e-02 -8.49875931e-03 -2.95241341e-02 -9.09116807e-03
 -7.16788169e-01 -7.77462200e-02 -1.13944221e-01 -7.99054484e-02
  2.30407594e-01  4.96081820e-01  9.66280921e-01  5.78904888e-01
 -3.36348064e-01  1.22715864e-01  5.64549167e-01 -4.66042069e-01
  4.78556798e-01 -1.20798354e+00  5.26721773e-01 -6.66364400e-01
 -9.13537992e+00]
supnorm grad right now is: 9.135379917023782
Weights right now are: 
[ 6.81156276e-01  3.61549519e-02 -1.99687791e+00  6.89202364e-01
 -1.47137551e+00 -2.16913139e-02  2.56818396e+00  7.25880684e-01
 -1.18364625e+00  2.52507822e-01 -1.05603779e+00  4.67623615e+00
  7.50750077e+00  7.29638412e+00  7.11198303e+00  1.08859142e+01
  4.50377478e+00 -1.54579121e-02  4.77884835e+00  2.24655833e-01
  8.47748124e+00  7.39320202e+00  7.73460974e+00  1.15291463e+01
 -6.56234628e+00 -2.85895202e+00 -2.05021961e+00  3.39165973e+00
  7.43065131e+00  4.82627460e+00  7.47140369e+00  5.24905177e+00
 -7.06304470e+00 -2.46059006e+00 -6.89711554e-01  3.20696116e+00
  6.41900584e+00  3.11119309e+00  5.17858970e+00 -5.50002032e+00
 -2.38072329e+00  6.19138135e+00  1.18817464e+01  8.99802820e+00
  1.44071495e+00  5.59723121e+00  7.05338289e+00  7.56144708e+00
  1.62317437e-01  8.61584238e+00  1.12715432e+00  7.36335514e+00
  6.47676971e+00 -3.36521496e+00  3.36313653e+00 -2.57087369e+00
  3.13844134e+00  3.95775878e+00  3.98804516e+00 -2.01219257e+00
 -2.13142389e+00 -3.35425795e+00  3.25656537e+00 -2.27892995e+00
  3.01539354e+01]
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1702.207254185963
gradient value of function right now is: [ 7.21531187e+00  7.74646972e-06  6.26295520e-02  4.64445429e-06
 -7.21531187e+00 -7.74646972e-06 -6.26295520e-02 -4.64445429e-06
 -4.02103271e+00 -1.23125640e+00 -3.77292806e+00 -2.28349971e+00
 -6.21110409e-07 -1.36238120e-07 -5.61709453e-07 -2.86813250e-07
  3.83924467e-01  2.23757290e-01  3.57816957e-01  6.12497028e-04
  3.42087612e-07  7.54972410e-08  3.08930315e-07  1.61078298e-07
 -4.13316071e-02 -9.08127376e-03 -3.02920041e-01  2.19636091e-02
 -5.25020358e-03 -9.74764387e-04 -2.70622135e-02 -8.51275554e-03
 -4.06860845e-02 -8.88584258e-03 -2.95638548e-01  4.10620427e-02
  1.11409025e-01  2.30958413e-02  7.35313568e-01  2.09087792e-01
 -1.00297933e+00 -1.83141144e-01 -2.55552679e-01 -1.49686468e-01
 -6.72935014e-02 -1.16422755e-02 -4.07497647e-02 -1.17466108e-02
 -1.57601637e+00 -3.00467636e-01 -1.99337756e+00 -3.86904041e-01
  4.27450415e-01 -1.71545091e-02  1.12556811e+00  7.03212414e-02
 -8.44913093e-01  5.35083103e-01  1.21307945e+00 -1.44471204e+00
  4.31286371e-01 -1.42343222e+00  1.54526648e+00 -1.34685717e+00
 -7.31217174e+00]
supnorm grad right now is: 7.312171742174021
Weights right now are: 
[ 0.8279256   0.07319096 -2.41649505  0.64489742 -1.61814484 -0.05872732
  2.98780109  0.77018562 -1.26741785 -0.38735763 -1.17429166  4.61839199
  8.62068973  7.51846167  8.12280225 11.36514967  4.41748936 -1.02241401
  4.63376672 -0.03785096  9.14344007  7.49955957  8.31170177 11.72099838
 -6.92355371 -2.53026577 -1.96662805  3.32908181  8.81487171  6.21758355
  9.19945518  6.15184382 -7.25279895 -1.99585621 -0.55697387  3.16275872
  7.12569396  3.15796241  5.30718592 -6.6754539  -2.60489246  5.82025193
 12.41079683  8.95748819  1.74079863  5.09272462  7.18589869  7.34133031
 -0.19860566  7.77679557  1.00659512  6.75917335  6.46817249 -3.27389584
  3.19446322 -2.17634039  3.57759376  4.41203862  4.51208596 -1.57670711
 -2.32638016 -3.1773253   3.32071004 -2.33808895 30.41295955]
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1699.588826699678
gradient value of function right now is: [ 4.58141070e+00  1.88122607e-05  1.75687671e-01  1.34400881e-05
 -4.58141070e+00 -1.88122607e-05 -1.75687671e-01 -1.34400881e-05
 -3.21175430e+00 -3.78419669e-01 -2.85639747e+00 -1.45094109e+00
 -3.24132681e-06 -2.55162706e-07 -2.78984218e-06 -1.79680695e-06
  4.21552218e-01  1.76672329e-01  3.81258251e-01  2.49929929e-01
 -1.07604095e-06 -8.46211883e-08 -9.26059100e-07 -6.14766536e-07
 -2.77639588e-02 -1.00862838e-02 -3.58763480e-01  5.22710331e-02
  8.88337040e-04  3.52781270e-04  1.90645721e-02  2.07825767e-02
 -2.61087922e-02 -9.70935647e-03 -3.42306752e-01  6.68440312e-02
  9.90269815e-02  2.92978520e-02  1.00099673e+00  2.08450839e-01
 -7.41685017e-01 -9.24695857e-02 -1.84814883e-01 -8.69581877e-02
 -7.20928332e-02 -8.01931515e-03 -6.05613049e-02 -8.83166597e-03
 -1.36880866e+00 -2.16994514e-01 -3.27727375e+00 -2.90933633e-01
  2.97731235e-01 -3.34701770e-01  7.32822616e-01 -3.92201234e-01
 -7.66426674e-01  6.63407743e-01  1.01358477e+00 -1.81819531e+00
  5.19612784e-01 -1.28941080e+00  1.57019322e+00 -1.56526183e+00
 -1.50497160e+01]
supnorm grad right now is: 15.04971603109507
Weights right now are: 
[ 0.60271039  0.16965853 -2.5672752   0.7863602  -1.39292963 -0.15519489
  3.13858125  0.62872285 -0.96451673  0.09195823 -0.8232383   5.11383186
  9.10500712  7.54789585  8.53096915 11.58531469  4.32311414 -1.7686355
  4.49963055 -0.04526776  9.50525009  7.52335115  8.61261721 11.84468973
 -7.30769599 -2.77013399 -2.01426106  3.27382255  9.49649133  7.61438357
 11.11394707  6.82311381 -7.76536325 -2.23972516 -0.61852076  3.12384533
  6.92507728  3.43256586  5.60851081 -6.87460454 -2.30745034  6.28279345
 12.9305742   9.60511421  2.16734487  5.2489871   7.06997337  7.59690299
 -0.10602845  8.5584372   0.90943871  7.64182634  5.67762182 -3.55397164
  3.39436224 -2.31693799  4.07543128  3.68392173  3.59610111 -2.36110984
 -2.67946362 -3.37176721  2.88854295 -2.67598412 29.57609883]
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1702.5995523320732
gradient value of function right now is: [-1.74591430e+00  5.89490262e-06  5.81457635e-01  4.66497968e-06
  1.74591430e+00 -5.89490262e-06 -5.81457635e-01 -4.66497968e-06
  2.22664377e+00  1.03868870e+00  2.18190907e+00  1.45519467e+00
 -2.40130129e-08  1.03092438e-08 -3.22245757e-08 -9.18589514e-07
  1.06829404e-01 -2.14051394e-02  1.26922304e-01  2.15011451e+00
 -6.07948793e-09  2.75966958e-09 -8.24786691e-09 -2.40292104e-07
  4.85139496e-02  3.23913296e-03  6.95209463e-02 -5.31665064e-01
 -4.54498195e-03 -3.81279874e-04 -9.67713629e-03  1.51591003e-02
  4.42262377e-02  3.02858619e-03  6.55787697e-02 -5.98594829e-01
 -2.02904314e-01 -1.24864523e-02 -2.53760250e-01 -4.12795546e-02
  1.70496299e+00  2.69692792e-01  1.71695806e-01  2.66847673e-01
  4.96434752e-02  8.28589278e-03  8.13077418e-03  8.43831681e-03
  1.10499361e+00  2.22188634e-01  5.00496861e-01  2.42421574e-01
 -1.69697156e-01  4.89211564e-01  7.34281392e-01  5.43388802e-01
  5.80716798e-02 -2.98486020e-01 -2.71221915e-01  2.84115818e+00
 -2.91094415e-01  1.40463730e+00 -4.47331898e-01  3.00755797e+00
  2.52657484e+00]
supnorm grad right now is: 3.0075579679374544
Weights right now are: 
[ 0.8398016   0.09967157 -2.07566707  0.7473626  -1.63002084 -0.08520794
  2.64697311  0.66772045 -1.04916753  0.19695852 -0.9513663   5.0759486
  9.48534885  7.56176366  8.85373919 11.70512491  4.90734988 -1.26949978
  5.04474317  0.47681085  9.7571984   7.53388949  8.8254781  11.92717841
 -7.7375122  -2.52787817 -1.72781651  3.26190427  9.15672336  9.09920008
 13.18168319  7.6823124  -8.42031144 -2.11080202 -0.37330564  3.1156453
  6.83338302  3.08583979  5.54920443 -6.59282188 -1.96332434  7.60538782
 13.59861815 10.83384794  2.54486661  6.22390636  7.50141118  8.43948999
  0.12748355  8.67221665  0.93689949  7.40457381  6.40113843 -3.8231972
  3.48393877 -2.58387518  3.50394655  4.36013038  4.15213559 -1.8053411
 -2.43078135 -3.46324623  3.48344504 -1.91553354 30.22061407]
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1694.9073516829578
gradient value of function right now is: [ 1.22110877e+01  4.59795061e-05  4.16766838e-01  4.10097701e-05
 -1.22110877e+01 -4.59795061e-05 -4.16766838e-01 -4.10097701e-05
 -8.33852342e+00 -3.93794210e-01 -7.31925064e+00 -3.50356628e+00
 -4.66565019e-06 -1.24439460e-07 -3.96537343e-06 -2.18277928e-06
  3.14657891e-01  4.77259262e-02  3.02637294e-01  1.27731252e+00
 -2.54176648e-06 -6.72976053e-08 -2.15956174e-06 -1.16641824e-06
 -2.91592668e-02 -8.95662660e-03 -9.74850617e-01 -4.50484105e-01
 -8.59433044e-05  4.44180679e-05  8.13728465e-03  1.48885182e-02
 -3.09118928e-02 -8.95748595e-03 -9.49799635e-01 -4.78658128e-01
  6.35962370e-02  2.12460117e-02  2.52661216e+00  3.99054653e-01
 -6.70093165e-01 -4.42937903e-02 -1.86405639e-01 -5.23565344e-02
 -4.19861764e-02 -4.00149225e-03 -3.83542646e-02 -4.94329920e-03
 -3.43158824e+00 -5.46309055e-01 -7.90582387e+00 -7.27267804e-01
  6.01402592e-01  5.88087467e-01  3.07067886e+00  6.94323121e-01
 -1.61595921e+00  6.13492832e-01  3.30969984e+00 -7.95168763e-01
  6.66631759e-01 -1.54176742e+00  3.69028653e+00 -1.04138584e+00
 -2.56977491e+01]
supnorm grad right now is: 25.697749101693436
Weights right now are: 
[ 1.03295397  0.10463715 -1.86578474  0.76848269 -1.8231732  -0.09017351
  2.43709079  0.64660036 -1.18437706  0.06857096 -1.10798646  4.85884576
  9.83082468  7.57712178  9.14718213 11.87342029  5.16163361 -1.62722701
  5.26192128  0.75026807 10.03358392  7.54736591  9.06027224 12.04813632
 -7.77060692 -1.85925637 -1.53923773  3.3192567  11.02412745 11.17523408
 15.67322021  7.9561106  -8.44308826 -1.49066797 -0.19592076  3.16642899
  6.99620296  2.64330626  5.74762129 -6.66280732 -1.80809822  7.96958417
 14.34117261 11.20469937  3.00611438  6.44538028  7.87401488  8.66649115
 -0.18111039  8.46755658  0.73402356  7.11346232  5.99523588 -3.84644824
  3.65590627 -2.6825189   3.45265441  4.32291239  4.27657906 -1.80018435
 -2.2575288  -3.5241147   3.71151956 -1.94345226 30.30797697]
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1690.62491017737
gradient value of function right now is: [ 1.35312795e+01  6.23340079e-05  7.32465505e-01  5.73404828e-05
 -1.35312795e+01 -6.23340079e-05 -7.32465505e-01 -5.73404828e-05
 -8.71443829e+00 -7.18178733e-01 -7.64576194e+00 -3.77794903e+00
 -4.90943752e-05 -1.04992408e-06 -4.11588079e-05 -2.21364225e-05
  4.90764278e-01  1.22082079e-01  4.73090409e-01  2.43485322e+00
 -4.39236043e-05 -9.36655264e-07 -3.68201282e-05 -1.96348068e-05
 -3.89125362e-02 -7.72513436e-03 -8.71261158e-01 -5.62940373e-01
  9.29794659e-05  3.06266689e-05  4.50171849e-03  2.04384831e-02
 -3.84635012e-02 -7.36189700e-03 -8.13749433e-01 -5.92570758e-01
  1.09417118e-01  2.02560520e-02  2.41716968e+00  4.01390231e-01
 -1.12897214e+00 -1.15194414e-01 -2.38847118e-01 -1.05396832e-01
 -5.01424932e-02 -5.51428386e-03 -4.90936306e-02 -5.74768430e-03
 -3.52349664e+00 -6.17926737e-01 -8.23671295e+00 -7.09684450e-01
  6.79183249e-01  6.29568494e-01  3.22521241e+00  7.06591005e-01
 -1.28681415e+00  5.53306082e-01  3.88948752e+00 -1.77809652e+00
  3.68029047e-01 -1.88813068e+00  3.99128460e+00 -1.76577771e+00
 -3.57970627e+01]
supnorm grad right now is: 35.79706273727314
Weights right now are: 
[ 7.26686972e-01  7.26715769e-01 -2.21569715e+00  1.40572339e+00
 -1.51690621e+00 -7.12252131e-01  2.78700319e+00  9.35965633e-03
 -9.93489230e-01 -1.09256614e-02 -8.79926633e-01  4.98324198e+00
  9.96854287e+00  7.57694990e+00  9.26679750e+00  1.21881742e+01
  5.41360199e+00 -1.37469239e+00  5.44918304e+00  4.96635398e-01
  1.01580673e+01  7.54702720e+00  9.16773457e+00  1.22938361e+01
 -7.97787055e+00 -2.30803239e+00 -1.52009860e+00  3.55692157e+00
  1.40676065e+01  1.26098064e+01  1.63922519e+01  8.55078551e+00
 -8.52236058e+00 -1.86980071e+00 -1.23067085e-01  3.42897523e+00
  7.53548655e+00  3.44423328e+00  6.11669970e+00 -6.86663176e+00
 -1.99991291e+00  7.54944967e+00  1.45798268e+01  1.08548473e+01
  3.16576720e+00  6.55577940e+00  7.26768144e+00  8.93076955e+00
 -6.68297544e-02  9.01647384e+00  5.59982485e-01  7.78828279e+00
  5.83835841e+00 -3.90512665e+00  3.67809836e+00 -2.83124745e+00
  3.76990100e+00  4.64373073e+00  3.58577704e+00 -2.52007539e+00
 -2.52215248e+00 -3.37819093e+00  3.23465418e+00 -2.77471840e+00
  2.96478665e+01]
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1702.2444000218982
gradient value of function right now is: [-2.91435059e+00  5.65427302e-06  6.08753586e-01  5.33774542e-06
  2.91435059e+00 -5.65427302e-06 -6.08753586e-01 -5.33774542e-06
  1.04373046e+00  1.86868050e-01  1.07170980e+00 -5.50311653e-02
 -1.34760174e-06 -6.29158566e-08 -1.22665281e-06 -3.20013633e-06
  2.66360328e-01  6.18044997e-02  2.75532050e-01  2.39033727e+00
 -1.30324219e-06 -6.08707898e-08 -1.18562923e-06 -3.01342035e-06
  1.82139675e-02  8.66406092e-04 -1.94284216e-02 -5.76247293e-01
 -9.24043085e-04 -7.45558513e-05 -2.72512916e-03  1.99095524e-02
  1.92434115e-02  9.73694473e-04 -1.31420943e-02 -6.08287179e-01
 -4.19169478e-02 -1.29720150e-03  1.12873590e-01  4.61369469e-02
  4.29546276e-01  4.85939992e-02  7.01029772e-02  4.16321775e-02
  1.44569662e-02  1.52202102e-03 -3.29431781e-03  1.25759486e-03
  2.71946738e-01  5.23037463e-02 -7.32889711e-01  3.73073756e-02
  1.04386100e-01  9.13799278e-01  1.55026535e+00  1.03020705e+00
 -1.80703337e-01 -2.91622996e-01  4.15218179e-01  1.10329568e+00
 -3.67476711e-01  4.61919025e-01  3.45870238e-01  8.49267490e-01
 -7.05262616e+00]
supnorm grad right now is: 7.052626158994016
Weights right now are: 
[ 7.03002421e-01  4.53381081e-01 -2.39011964e+00  1.15719195e+00
 -1.49322166e+00 -4.38917443e-01  2.96142568e+00  2.57891101e-01
 -9.40211925e-01  2.42716105e-01 -8.66979834e-01  5.02262116e+00
  1.04632866e+01  7.57940180e+00  9.69087699e+00  1.24666578e+01
  5.64325602e+00 -1.50771373e+00  5.64956034e+00  3.98324086e-01
  1.06138246e+01  7.54917717e+00  9.55695825e+00  1.25447416e+01
 -8.23238203e+00 -2.71207623e+00 -1.13373538e+00  3.65146806e+00
  1.55270083e+01  1.35575389e+01  1.75235663e+01  9.44069068e+00
 -8.81965221e+00 -2.24342654e+00  2.43491889e-01  3.54908235e+00
  7.57243155e+00  4.07706913e+00  6.14608781e+00 -6.95265937e+00
 -1.81741431e+00  8.12871987e+00  1.52115080e+01  1.14474057e+01
  3.36294550e+00  7.27446101e+00  6.41666455e+00  9.54639978e+00
  5.70800960e-03  9.28618763e+00  8.32478006e-01  8.04559686e+00
  6.14024741e+00 -3.67770720e+00  4.01000013e+00 -2.63005766e+00
  2.64425336e+00  3.94972713e+00  3.76558743e+00 -2.16293435e+00
 -2.59147986e+00 -3.61106681e+00  3.25069663e+00 -2.53405923e+00
  3.00183077e+01]
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1700.7724494342988
gradient value of function right now is: [ 4.51431480e+00  2.00819980e-06  8.33771536e-01  1.82446988e-06
 -4.51431480e+00 -2.00819980e-06 -8.33771536e-01 -1.82446988e-06
 -2.14631072e+00 -7.65531825e-02 -2.03139438e+00 -7.86118338e-01
  1.34331694e-06 -3.96524538e-08  7.24952477e-07 -5.96263524e-06
  1.74106231e-01  2.95488496e-02  1.82395725e-01  2.71190964e+00
  1.34545096e-06 -3.97700314e-08  7.26992197e-07 -5.72910656e-06
 -3.45914265e-02 -1.59248282e-03 -1.00562138e-01 -4.44207900e-01
 -5.27693109e-04 -2.43570353e-05 -1.03731319e-03  1.19086268e-02
 -3.79959563e-02 -1.91151317e-03 -1.07893903e-01 -4.84677051e-01
  9.07769722e-02  5.37227551e-03  3.00912400e-01  7.80669617e-02
 -9.70359392e-01 -1.21247101e-01 -1.83152424e-01 -1.07587948e-01
 -2.21342376e-02 -2.81132137e-03 -5.93601656e-03 -2.70756996e-03
 -7.67437904e-01 -1.09669988e-01 -5.01273294e-01 -1.07558067e-01
  2.47983452e-01  3.22258163e-01  8.76949229e-01  3.61024614e-01
 -2.96978229e-01  3.72141693e-01  7.78283029e-01 -6.80885755e-01
  5.46608135e-01 -1.41918541e+00  7.31804374e-01 -8.14780547e-01
 -1.40902285e+01]
supnorm grad right now is: 14.090228469127059
Weights right now are: 
[ 8.05908592e-01  6.92928786e-01 -1.77233748e+00  1.40016091e+00
 -1.59612783e+00 -6.78465148e-01  2.34364353e+00  1.49221351e-02
 -9.94278515e-01 -3.40196850e-01 -1.00549034e+00  4.75863384e+00
  1.13684243e+01  7.58149969e+00  1.04081889e+01  1.29285979e+01
  5.39000758e+00 -2.47280748e+00  5.35978868e+00  9.70762841e-01
  1.14860317e+01  7.55108028e+00  1.02478605e+01  1.29804118e+01
 -8.57999128e+00 -2.22112956e+00 -4.33272218e-01  3.70497414e+00
  1.50637173e+01  1.48845746e+01  1.91355655e+01  9.13844202e+00
 -9.04286335e+00 -1.73759556e+00  9.52617928e-01  3.57585546e+00
  8.49151972e+00  3.91912807e+00  5.93974946e+00 -7.34752896e+00
 -2.32112764e+00  7.26413859e+00  1.50525421e+01  1.06915965e+01
  3.60479236e+00  7.42493343e+00  7.01527512e+00  9.83279113e+00
 -1.36253453e-01  8.82640987e+00  1.09204184e+00  7.63872148e+00
  5.36500160e+00 -4.29836489e+00  3.70156482e+00 -3.09669245e+00
  4.60289724e+00  4.44673472e+00  3.97564036e+00 -2.26051374e+00
 -2.28692392e+00 -3.87372320e+00  3.64873195e+00 -2.58868067e+00
  3.00107305e+01]
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1702.5443479634557
gradient value of function right now is: [ 6.31739568e-01 -2.27310442e-05 -2.83302360e-01 -2.26023804e-05
 -6.31739568e-01  2.27310442e-05  2.83302360e-01  2.26023804e-05
 -6.64517633e-01 -8.38354905e-01 -8.88382174e-01 -1.27124902e+00
  2.22911128e-05  3.96346649e-08  1.75615045e-05  7.12520761e-06
  1.84169132e-01  2.71324405e-01  1.89424732e-01 -1.32460339e+00
  2.23912570e-05  3.95913703e-08  1.76399290e-05  7.12585800e-06
 -6.35403632e-03  7.51587041e-03  1.88894002e-01  3.75029134e-01
 -1.08047112e-03 -2.44219367e-05 -3.34826035e-03  1.81047338e-03
 -5.50899614e-03  7.70387512e-03  1.90283154e-01  3.84971392e-01
  4.16530025e-02 -1.10831286e-02 -2.93200316e-01  1.20549451e-01
 -3.89990901e-01 -6.45620859e-02 -1.67277214e-02 -6.15425890e-02
  2.28743968e-02  4.57138280e-04  3.48528464e-02  5.98987260e-04
  3.20591198e-02 -4.16454898e-02  7.23343953e-01 -3.86844109e-02
  2.36553303e-01 -4.71486323e-01 -1.50767129e-01 -5.01136668e-01
 -1.20803108e-01 -2.10780847e-03 -7.09359256e-02 -1.22304158e+00
 -6.38314396e-01  3.97758961e-03  9.25359387e-03 -9.50117793e-01
  1.41827555e-02]
supnorm grad right now is: 1.3246033876759042
Weights right now are: 
[ 0.75830014  0.96582125 -2.82321362  1.67538139 -1.54851938 -0.95135761
  3.39451966 -0.26029834 -0.9457468  -1.05092451 -0.97950737  4.50029259
 11.28978184  7.57744702 10.40486759 13.29929721  5.74475387 -3.3994743
  5.64165237  0.13933861 11.41118325  7.54700725 10.24877799 13.33950299
 -8.65681433 -2.53472245 -0.25100689  3.95460388 18.03842986 18.15853911
 21.33783365  8.73218205 -9.15887636 -2.02817527  1.13378483  3.88340978
  8.0126715   4.10323781  5.94196874 -7.53562343 -1.90554944  7.7955567
 15.28209823 11.17292969  4.31856168  8.90399297  6.53828288 11.26647075
  0.13302893  8.65366666  1.01968036  7.5522293   7.28847612 -3.83155644
  4.16356701 -2.74135415  3.98712967  3.60700853  3.56083295 -2.61220761
 -2.83429166 -4.12997548  3.31473067 -2.74522329 30.25946113]
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1698.8011459479435
gradient value of function right now is: [-7.63190731e-01 -1.12168777e-04 -5.92332522e-02 -1.11331793e-04
  7.63190731e-01  1.12168777e-04  5.92332522e-02  1.11331793e-04
  7.59862460e-01  8.59827694e-02  2.60344387e-01 -1.02287789e-01
  1.35778584e-04 -5.05012668e-08  9.77802464e-05  2.47168072e-05
 -4.56898267e-02  3.33682615e-02 -1.37672146e-02 -1.45768300e-01
  1.35689302e-04 -5.08497183e-08  9.77174527e-05  2.47024634e-05
  2.44975165e-02  1.99584033e-02  4.75717720e-01  7.07656327e-02
 -1.14269001e-04  3.36461710e-06  3.57235822e-04  2.66638872e-02
  3.20481032e-02  1.96484605e-02  4.67930183e-01  7.00949383e-02
 -2.03843187e-02 -1.83364309e-02 -3.49415466e-01  2.29455551e-02
  4.13380521e-01  6.02843330e-02  5.40839081e-02  4.88759226e-02
  3.55857735e-02  4.67674330e-04  8.06110631e-02  6.73095656e-04
  3.93084341e-02 -7.58017509e-02  3.31050129e-01 -1.19200351e-01
 -8.42069893e-02 -8.70957541e-02  8.21917738e-02 -6.50400116e-02
  3.16594750e-01 -3.45024778e-01  6.31770841e-01  4.65851503e-01
 -4.67437841e-01  4.46608965e-01  6.35702274e-01  6.60163265e-01
  1.97090900e+01]
supnorm grad right now is: 19.709089982450326
Weights right now are: 
[ 0.90841955  1.14712025 -2.95474969  1.85574916 -1.69863879 -1.13265661
  3.52605574 -0.44066611 -0.9872259  -0.18071995 -1.04156364  4.82130693
 11.46009528  7.5747949  10.59024988 13.44346335  5.77458089 -4.35371629
  5.63882785  0.13288231 11.58105869  7.54434693 10.43387805 13.47914694
 -8.40688808 -2.71198664 -0.15364444  3.85016547 18.01586351 18.52205093
 22.69994384  9.06913256 -8.79391893 -2.17229663  1.28504709  3.79830333
  8.54735736  4.41970756  6.26684032 -8.51070259 -1.87549111  7.60450613
 15.37785758 10.87455291  4.42034784  8.98340974  6.49521184 11.33037983
 -0.87573366  7.52397851  0.86637831  6.50225835  7.35470383 -3.75222732
  4.28109244 -2.56775718  4.27254214  4.02799273  4.55633011 -1.68460762
 -2.38856688 -4.22892077  4.10574918 -2.02100281 30.74108488]
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1703.2191654564317
gradient value of function right now is: [-2.50773577e+00  5.98803539e-06  4.77549499e-01  5.95910053e-06
  2.50773577e+00 -5.98803539e-06 -4.77549499e-01 -5.95910053e-06
  1.06715366e+00 -4.55122528e-02  1.08714874e+00  1.93185241e-01
 -1.73834029e-05  2.10348428e-07 -1.35434052e-05 -4.77582551e-06
  3.03715240e-01  1.79510302e-01  3.10760214e-01  2.05341592e+00
 -1.74136820e-05  2.10767402e-07 -1.35691002e-05 -4.64669768e-06
  1.84739638e-03 -1.80334073e-03  6.82711289e-03 -4.08763569e-01
  6.24349277e-05  3.01618337e-05  2.94724371e-03  1.04112953e-01
  3.63852942e-03 -1.86588460e-03  4.58160411e-03 -4.03594639e-01
  9.54514691e-03  1.73403473e-03 -8.70433601e-02 -3.33590677e-02
 -7.33368954e-02 -1.52396298e-02 -3.15005991e-02 -1.50517877e-02
 -1.98877926e-02 -7.99186700e-04  8.29224804e-03 -5.49158108e-04
 -3.62586995e-01  7.52423315e-03  8.21753833e-01  2.36616992e-02
  1.08956899e-01  4.94786002e-01  2.17803070e-01  4.95934156e-01
 -2.18370275e-02  9.00630619e-03 -2.71177425e-01 -2.34502152e-01
  3.19053300e-01 -4.15286412e-01 -3.00391544e-01 -2.06851265e-01
 -4.85979462e+00]
supnorm grad right now is: 4.859794621992442
Weights right now are: 
[ 0.63959457  2.60132522 -2.71225125  3.30752771 -1.4298138  -2.58686158
  3.2835573  -1.89244467 -0.77215519 -0.96683367 -0.73560907  4.8086506
 10.13345118  7.57503472  9.44016141 13.30185528  5.72853809 -4.9433605
  5.52186769  0.3211515  10.25426296  7.54457453  9.28416343 13.33514417
 -8.72701233 -3.67337962 -0.72451943  3.77842468 21.24275987 20.68408164
 24.4987652   8.34792078 -9.50534383 -3.1648441   0.69363649  3.73010671
  7.9618009   5.01556058  6.07737252 -9.69632433 -1.57745411  8.28858516
 16.66122835 11.59310014  3.36255125  9.63369225  5.85347226 11.84181561
 -0.58652931  7.71382709  1.22347801  6.81533686  7.70669107 -3.53467505
  4.25108885 -2.47375309  4.11564461  4.47060065  3.15029336 -2.12309629
 -1.88264471 -4.05727972  2.89405305 -2.34163187 29.99767494]
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1701.6079628374105
gradient value of function right now is: [-1.48193452e-01  7.39044148e-06  3.66370390e-01  7.36273541e-06
  1.48193452e-01 -7.39044148e-06 -3.66370390e-01 -7.36273541e-06
  6.10211340e-01  4.08165093e-01  7.25111244e-01  5.09697863e-01
 -2.07753723e-05  8.13550295e-08 -1.71686518e-05 -7.66033355e-06
  4.31162334e-01  1.41613017e-01  4.32957592e-01  2.11820976e+00
 -2.07450498e-05  8.24511955e-08 -1.71433602e-05 -7.62926386e-06
  1.29270223e-02 -2.46832905e-03 -6.05676050e-02 -7.29243557e-01
  3.73994039e-03  6.03803118e-05  4.85720803e-03  1.01181484e-01
  9.78391439e-03 -2.43738759e-03 -5.87327554e-02 -7.07968467e-01
 -1.11723771e-01  6.66088917e-03  1.55367357e-01  4.93454823e-02
  9.31884685e-01  2.27230440e-01  1.66928006e-02  2.10786543e-01
 -9.79712568e-03  1.38043460e-04 -3.21146807e-02  5.42485030e-05
  2.97066631e-01  6.97726180e-02 -7.98939964e-01  6.31196356e-02
 -8.35815445e-02  1.62432205e+00  2.67144567e+00  1.69462636e+00
 -2.23699892e-02 -1.86650480e-01  6.99374570e-01  3.13265517e+00
  3.72698029e-01 -1.36758469e-01  5.02171751e-01  2.84785817e+00
 -6.56934059e+00]
supnorm grad right now is: 6.569340592213319
Weights right now are: 
[  0.84452328   2.62940254  -3.31211424   3.33447453  -1.63474252
  -2.61493891   3.88342029  -1.91939148  -0.83312425  -0.55296149
  -0.7762565    5.16919632  10.21027656   7.5412993    9.57767116
  13.86264791   6.53717881  -4.41353219   6.30082185   0.04958729
  10.33387569   7.51064953   9.42462673  13.88902651  -9.8314884
  -3.83623361  -0.89841714   3.68233601  20.52462751  21.29339278
  25.6773925    9.41964383 -10.62414711  -3.26657363   0.52396623
   3.65728983   8.39296444   5.57479034   6.28658131 -10.05915374
  -2.1457237    7.55908224  16.86079711  10.8704142    3.69891555
   9.63562534   5.52188244  11.80507292   0.58291506   8.30849213
   0.6710334    7.28067656   7.0743992   -3.64803121   4.65709917
  -2.57569105   4.13480516   5.41080294   3.36466448  -1.66473536
  -1.96551288  -4.26360902   3.30708829  -1.79616278  30.11551574]
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1700.6166616901025
gradient value of function right now is: [ 8.37605275e+00  3.03538444e-05 -4.17157168e-01  3.02442713e-05
 -8.37605275e+00 -3.03538444e-05  4.17157168e-01 -3.02442713e-05
 -5.21781195e+00 -6.80735896e-02 -4.53823386e+00 -2.11183989e+00
 -8.03861446e-05 -3.67787635e-07 -6.70005617e-05 -2.41246520e-05
 -1.03808355e-01 -1.01017757e-01 -1.38489881e-01 -2.43247264e+00
 -8.02023824e-05 -3.67626346e-07 -6.68503219e-05 -2.40955270e-05
 -1.00848275e-02 -1.63699689e-02 -6.67782276e-01  6.38084772e-01
 -1.65858245e-04 -9.91295744e-06  3.96974321e-04 -9.51536598e-02
 -9.37529334e-03 -1.54250163e-02 -6.40557438e-01  6.17109973e-01
  3.57230848e-02  3.81021787e-02  1.55021027e+00  1.54667732e-01
 -4.32964482e-01 -6.49602347e-02 -5.44172972e-02 -6.29279968e-02
 -7.77246198e-02 -2.48875365e-02 -2.75916802e-01 -2.44315677e-02
 -1.68243196e+00 -5.78612033e-01 -5.79359664e+00 -5.70111660e-01
  1.41025907e-01 -1.02602974e+00  3.48645765e-02 -1.04102294e+00
 -6.83949245e-01  4.24894596e-01  2.56787442e+00 -2.02070859e+00
 -5.59597716e-02 -3.51653645e-01  2.27371921e+00 -1.73248398e+00
 -3.36622783e+00]
supnorm grad right now is: 8.376052751080335
Weights right now are: 
[ 8.08829286e-01  2.38291876e+00 -3.42138345e+00  3.08676849e+00
 -1.59904852e+00 -2.36845512e+00  3.99268949e+00 -1.67168544e+00
 -1.10267911e+00 -3.89808363e-01 -1.06241104e+00  4.90484421e+00
  1.05471072e+01  7.51784991e+00  9.93396360e+00  1.40874535e+01
  5.78719452e+00 -5.61865923e+00  5.52841576e+00 -1.76008228e-02
  1.06720461e+01  7.48712425e+00  9.78217705e+00  1.41145326e+01
 -9.35064719e+00 -4.92893761e+00 -9.03055267e-01  3.74314111e+00
  1.97100357e+01  2.06461177e+01  2.48663830e+01  8.60957282e+00
 -1.01243980e+01 -4.41559134e+00  4.93554635e-01  3.71665845e+00
  8.43344841e+00  6.70796782e+00  6.67226049e+00 -1.09808687e+01
 -1.94811360e+00  7.48030726e+00  1.77910244e+01  1.07364430e+01
  3.01459421e+00  9.05228748e+00  4.88872381e+00  1.12263673e+01
 -4.78152662e-02  7.39470054e+00  6.03443526e-01  6.36103328e+00
  8.09979449e+00 -3.88401002e+00  4.35553932e+00 -2.84737485e+00
  4.24034241e+00  4.86051209e+00  3.40997259e+00 -2.35288771e+00
 -2.46058095e+00 -3.97035182e+00  3.42247521e+00 -2.41480050e+00
  3.04888987e+01]
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1697.159397567616
gradient value of function right now is: [-8.49108324e+00 -1.37250612e-05  8.79404379e-02 -1.36234489e-05
  8.49108324e+00  1.37250612e-05 -8.79404379e-02  1.36234489e-05
  6.04259079e+00  4.29401330e-01  5.41647019e+00  3.37845802e+00
  3.22269599e-05  3.02045053e-07  2.64319795e-05  1.59813851e-05
 -1.53884769e-01  3.01473450e-02 -1.11152451e-01  9.21242362e-01
  3.20357631e-05  3.01898947e-07  2.62791121e-05  1.58962114e-05
  1.16518001e-02  4.78445444e-02  4.61324673e-01 -2.46357290e-01
 -4.78301975e-04 -5.44868534e-04 -3.02566610e-02  1.27790525e-01
  1.35407255e-02  4.83884329e-02  4.58240786e-01 -2.34434150e-01
 -3.60786936e-02 -1.95729660e-01 -1.89695178e+00 -4.19070447e-01
  2.38606630e-01  4.04558942e-02  9.08975911e-02  3.93196769e-02
  2.36693363e-01  4.93839506e-02  6.77857092e-01  4.81798091e-02
  1.14893923e+00  4.65385691e-01  5.18652457e+00  4.60030821e-01
 -5.32544684e-01  8.75632560e-02 -2.51300467e+00  9.34269353e-02
  2.42879796e+00 -2.10906233e+00 -2.76024814e+00  1.66821160e+00
 -4.59815053e-01  8.58572646e-01 -2.41884660e+00  1.52703088e+00
  1.84404806e+01]
supnorm grad right now is: 18.440480583338157
Weights right now are: 
[ 6.60277332e-01  2.25739596e+00 -3.71988550e+00  2.96109494e+00
 -1.45049657e+00 -2.24293233e+00  4.29119154e+00 -1.54601189e+00
 -6.50652083e-01  2.04298251e-01 -6.67729795e-01  5.68890639e+00
  1.07628512e+01  7.51529706e+00  1.02278354e+01  1.46476132e+01
  6.48350232e+00 -5.41060036e+00  6.21491931e+00  1.93708791e-02
  1.08893340e+01  7.48453078e+00  1.00770771e+01  1.46712498e+01
 -1.01015730e+01 -4.88654805e+00 -1.69453355e-01  3.64131290e+00
  1.99304652e+01  2.27780507e+01  2.68617665e+01  9.59057933e+00
 -1.08195467e+01 -4.25408960e+00  1.23589178e+00  3.63385268e+00
  9.19646791e+00  6.44694776e+00  5.72893132e+00 -1.21832509e+01
 -2.46794954e+00  7.33588077e+00  1.83325708e+01  1.05568716e+01
  2.66272784e+00  1.01516031e+01  5.46896304e+00  1.23071938e+01
 -2.19845790e-01  7.52805645e+00  1.60571550e+00  6.40438168e+00
  8.74024133e+00 -3.78657761e+00  4.42621990e+00 -2.78411425e+00
  5.14142937e+00  3.19261881e+00  3.41855194e+00 -1.95045468e+00
 -2.82608938e+00 -4.19465643e+00  3.40997499e+00 -2.00262696e+00
  2.99181676e+01]
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -1701.791827529712
gradient value of function right now is: [ 7.67341200e+00  2.69908937e-05 -2.41625525e-02  2.68611525e-05
 -7.67341200e+00 -2.69908937e-05  2.41625525e-02 -2.68611525e-05
 -4.84803188e+00 -2.90558933e-01 -4.29832904e+00 -1.90105057e+00
 -8.45252721e-05 -2.90316067e-07 -6.97365880e-05 -2.05992249e-05
  4.17995659e-01  2.67798028e-01  4.04660840e-01 -1.74796311e-01
 -8.41592530e-05 -2.89904185e-07 -6.94404150e-05 -2.05277083e-05
 -2.26227544e-02 -3.33007347e-02 -4.00680182e-01  1.08922661e-01
 -4.27212691e-05  2.97017180e-04  1.10269590e-02  7.09000964e-02
 -2.48426272e-02 -3.35747127e-02 -4.03455528e-01  1.03800176e-01
  5.53454940e-02  8.43363385e-02  1.09057541e+00  1.16204664e-01
 -7.51088280e-01 -1.08008976e-01 -1.06605657e-01 -1.04951085e-01
 -2.75130459e-01 -4.55660504e-02 -5.12502283e-01 -4.49988779e-02
 -1.72514174e+00 -4.06155066e-01 -3.18470428e+00 -4.03066347e-01
  1.60987164e-01 -2.86390588e-01  6.43483292e-01 -2.90621490e-01
 -7.77929553e-01  5.12936384e-01  1.97353767e+00 -1.65726934e+00
  1.26832372e+00 -1.67394587e+00  1.80213868e+00 -1.63379458e+00
 -1.48489780e+01]
supnorm grad right now is: 14.848977970271907
Weights right now are: 
[  0.81421161   2.71352662  -4.03073275   3.4153032   -1.60443085
  -2.69906298   4.6020388   -2.00022015  -0.92623522   0.21762333
  -0.90935566   5.36733001  10.26599393   7.50711965   9.7688791
  14.31241708   6.69064192  -5.00925757   6.39000245  -0.31640487
  10.39248205   7.4763338    9.61851873  14.3369327  -10.06817669
  -5.45299372  -0.52060545   4.04137585  20.91668975  25.17661728
  27.59544504   9.04503716 -10.85577635  -4.66842      0.91561567
   4.03825162   9.10095444   7.61831316   6.43055665 -11.57829385
  -2.26913773   7.69906925  18.86103765  10.86171279   2.39018451
   9.76338554   4.1453842   11.89376559  -0.65958492   7.52120578
   1.39611477   6.36458314   9.6964703   -3.96182774   4.50359683
  -2.96646653   4.20830709   4.12366532   3.83386452  -1.91384401
  -2.68208958  -4.22050018   3.82324772  -1.9662384   30.09492321]
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -1690.2162020312328
gradient value of function right now is: [-1.39287679e+01 -7.24592619e-05 -4.32458753e-04 -7.19048562e-05
  1.39287679e+01  7.24592619e-05  4.32458753e-04  7.19048562e-05
  1.16702515e+01  6.77784810e-01  1.03046053e+01  5.38066090e+00
  2.07407909e-04  5.02484430e-07  1.66425487e-04  5.48369379e-05
 -8.88455822e-02  1.06680364e-01 -5.72104116e-02  2.96871357e-01
  2.05798762e-04  5.01480515e-07  1.65156096e-04  5.44668089e-05
  1.14249820e-01  6.51416775e-02  1.15880920e+00 -1.02140185e-01
 -3.05977168e-03 -2.47286984e-04 -3.20841429e-02  6.83151115e-02
  1.26101545e-01  6.73300987e-02  1.20432522e+00 -9.52836833e-02
 -3.77012768e-01 -1.46294388e-01 -3.26699704e+00 -6.47163645e-02
  5.02924353e+00  9.91508856e-01  3.85360532e-01  9.13177932e-01
  3.37783932e-01  5.48012961e-02  9.79134072e-01  5.43422119e-02
  6.28795053e+00  1.54078871e+00  7.78443382e+00  1.47617081e+00
 -2.14651718e-01  2.25760074e-01 -4.54555707e-01  2.37894904e-01
  8.01060478e-01 -1.30362003e+00 -3.38999075e+00  1.07542165e+01
 -2.72699418e+00  6.21398469e+00 -3.27162078e+00  1.11994280e+01
  4.07273345e+01]
supnorm grad right now is: 40.72733451988991
Weights right now are: 
[  0.85261712   2.66933662  -2.68400508   3.36946042  -1.64283636
  -2.65487298   3.25531113  -1.95437737  -1.04670199   0.43883934
  -1.09546062   5.4936293   10.70986346   7.5011213   10.26803141
  14.71453455   6.33579207  -6.16504231   6.0054769    0.74653209
  10.83769897   7.47031135  10.11877095  14.73855358 -10.30599803
  -4.98450836  -0.03538462   3.15973128  23.4297134   27.77654349
  29.92016257   8.37961577 -11.16071567  -4.28714258   1.38792345
   3.16800655   9.01597393   7.19183724   6.12627665 -12.45556837
  -2.07179448   8.10724205  19.528074    11.19467352   2.82789233
  11.34252555   4.39649507  13.40026839  -0.50755861   7.30061807
   1.20330631   6.12150109   9.38929596  -2.99672919   5.37294448
  -2.01211901   4.84850682   3.89182917   4.26100178  -1.30895473
  -2.96321504  -4.0020528    4.17227379  -1.44363556  30.61380244]
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1698.8168367198734
gradient value of function right now is: [ 9.12203747e+00  3.57395618e-05  5.05532666e-01  3.55532345e-05
 -9.12203747e+00 -3.57395618e-05 -5.05532666e-01 -3.55532345e-05
 -5.75081138e+00 -1.78576644e-01 -4.98867339e+00 -2.39180286e+00
 -9.53883008e-05 -1.70776650e-07 -7.75060478e-05 -2.56847398e-05
  9.09924309e-01  3.94866742e-01  8.77434605e-01  2.57967953e+00
 -9.49290085e-05 -1.70467469e-07 -7.71398018e-05 -2.55763745e-05
 -1.77983994e-02 -4.67636389e-02 -7.05247785e-01 -7.28910517e-01
 -1.49336532e-04  4.02107891e-04  1.54568356e-02  2.71523925e-01
 -1.96623360e-02 -4.67662487e-02 -7.09606076e-01 -6.88564784e-01
  3.67167550e-02  1.03161407e-01  1.71735267e+00  9.26243482e-02
 -5.46728177e-01 -7.92599614e-02 -7.97831838e-02 -7.70559057e-02
 -2.27409639e-01 -5.51938314e-02 -7.43083648e-01 -5.67590138e-02
 -1.69869666e+00 -5.39043823e-01 -5.09472669e+00 -5.55340407e-01
  1.54902808e-01  1.45253619e+00  2.54797073e+00  1.47801745e+00
 -8.57497957e-01  3.83664636e-01  2.96560887e+00 -5.14473240e-01
  1.28865389e+00 -1.57186994e+00  2.72323752e+00 -8.56046112e-01
 -2.43050907e+01]
supnorm grad right now is: 24.30509071183722
Weights right now are: 
[  0.87205329   2.53322983  -3.33137764   3.23463151  -1.66227253
  -2.51876619   3.90268369  -1.81954846  -1.03939421   0.95077716
  -1.06907651   5.57088263  11.12676678   7.49651752  10.66129315
  14.74483839   6.00699423  -6.39778184   5.65872397   0.14230746
  11.25306685   7.46569707  10.51048801  14.76748508 -10.44222367
  -5.29749763   0.0694489    3.78817447  25.34516905  28.0370389
  30.28925859   7.54552962 -11.43033745  -4.67531098   1.45135189
   3.79046285   8.84087958   7.63996161   6.34116222 -12.89180707
  -1.92078911   8.25578993  20.08143592  11.35880457   3.01493155
  11.81014324   3.85769894  13.82275093  -0.67677006   7.26503654
   1.15529184   6.15560081  10.71235875  -3.44548685   5.1336826
  -2.46670175   4.3338816    3.54263665   3.64899333  -1.7767249
  -2.56326094  -4.01147261   3.57111618  -1.84330136  30.09133147]
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1703.4986533967203
gradient value of function right now is: [ 1.18217229e+00  5.74918658e-06  1.80744396e-01  5.70669063e-06
 -1.18217229e+00 -5.74918658e-06 -1.80744396e-01 -5.70669063e-06
  2.89296225e-01  1.21466633e-01  2.99763449e-01  9.26514863e-01
 -1.47133410e-05  8.05843561e-08 -1.12485118e-05 -2.30865761e-06
  4.62827278e-01  3.59484385e-01  4.65993720e-01  1.25622434e+00
 -1.46133266e-05  8.06747627e-08 -1.11714894e-05 -2.28730609e-06
 -2.04582788e-03 -1.09005165e-02  1.55309840e-02 -3.50057274e-01
 -8.54143240e-04 -4.80543855e-04 -1.76801298e-02  1.86850247e-01
 -3.19825259e-03 -1.20528318e-02  1.23176207e-02 -3.32820795e-01
 -2.18146757e-03  5.57767046e-03 -2.34634659e-01 -2.18405196e-03
  2.24684522e-02  2.55082897e-02 -1.28035470e-02  2.38105177e-02
 -4.67901806e-02  6.49413132e-03  1.07619547e-01  7.95699950e-03
  5.45556503e-01  2.50814081e-01  1.17154592e+00  2.62573833e-01
  1.68192973e-02  6.47712066e-01  9.59604046e-01  6.81351654e-01
  2.63240735e-02 -2.84384472e-01 -1.43056829e-01  1.55803067e+00
  2.34111932e-01 -3.93714186e-01 -2.32528353e-01  1.20586199e+00
 -1.94631166e+00]
supnorm grad right now is: 1.946311657288397
Weights right now are: 
[  0.83443367   2.43812117  -3.90743528   3.13971061  -1.62465291
  -2.42365753   4.47874133  -1.72462756  -0.85461035   1.1987136
  -0.93624008   5.72290508  11.49392099   7.49837922  11.02473267
  14.89033017   6.86965239  -5.32939639   6.52071407  -0.24193137
  11.61989108   7.46755287  10.87359803  14.91273321 -10.31516844
  -5.74705646   0.8479103    4.15642914  28.77987433  27.9224531
  31.27119002   8.17725955 -11.40053093  -5.11726227   2.21326381
   4.16208066   8.83629694   8.57339034   5.88478861 -12.6472303
  -2.15487384   7.68379691  20.69747399  10.74927142   3.54513102
  13.59886911   3.21316772  15.51169025  -0.57876014   7.2596353
   1.493668     6.18679818  10.35628107  -4.02560054   5.17021485
  -2.98661659   4.97290009   3.35360945   3.65921393  -1.61147743
  -2.34241408  -4.15648355   3.431859    -1.64578376  30.10472399]
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1701.703653402091
gradient value of function right now is: [-1.64605160e+00 -3.27285945e-04 -4.28171056e-01 -3.21914425e-04
  1.64605160e+00  3.27285945e-04  4.28171056e-01  3.21914425e-04
  1.81465104e-01 -5.50415293e-02 -3.85511007e-02 -6.33699527e-01
  1.38767638e-03 -2.47151721e-07  8.40646208e-04  6.70249158e-06
 -5.51317762e-02  1.35892428e-03 -5.01408059e-02 -1.89615656e+00
  1.36602876e-03 -2.47771198e-07  8.27099175e-04  5.78641808e-06
  7.73103626e-03  3.34877740e-02  1.11846353e-01  4.38869837e-01
  4.31359835e-06  3.21627378e-05  5.87339347e-03 -1.01784995e-01
  1.35013667e-02  3.42173989e-02  1.19937961e-01  4.07985557e-01
  1.15779536e-02 -1.50252519e-02  3.49379692e-01  2.56889678e-02
 -4.70466901e-02 -4.19104488e-02  2.82890486e-02 -4.16264180e-02
  1.48583031e-01 -1.83721311e-03  1.37889129e-01 -1.77130863e-03
 -9.06326849e-01 -2.77384604e-01 -9.89854112e-01 -2.82675689e-01
  2.67138253e-02 -7.75106707e-01 -9.29472803e-01 -7.86138601e-01
 -3.06035691e-01  2.89931675e-01  1.30041817e-01 -1.52310263e+00
 -8.18778710e-01  6.51078215e-01  1.37588060e-01 -1.25858412e+00
  8.11089329e+00]
supnorm grad right now is: 8.1108932909032
Weights right now are: 
[  0.74957501   3.89197906  -2.92361772   4.59459982  -1.53979425
  -3.87751543   3.49492377  -3.17951678  -0.79509229   1.66239792
  -0.87993566   5.28372306  10.47284379   7.4944461   10.0700938
  13.91469891   7.10170246  -5.35817323   6.66808677   0.15201301
  10.59672033   7.46360542   9.91722472  13.93675759 -10.38733821
  -5.19562277   0.6457631    4.52614766  29.86099124  29.64934309
  32.85377028   6.54840477 -11.34991634  -4.4304513    2.19247885
   4.54151203   9.26295657   8.44386649   6.25691392 -12.59086074
  -2.32042024   7.66503195  20.96650268  10.68098613   3.28728723
  13.29993993   3.5426821   15.21846217  -1.01204194   6.4218996
   0.94085117   5.2681922   11.35049989  -4.30927519   4.82790356
  -3.32484488   4.5078614    4.20769595   3.72612186  -2.52676243
  -2.60860414  -4.25955193   3.65126869  -2.54204268  30.50045589]
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1699.3700862358232
gradient value of function right now is: [ 5.90807546e+00  1.09287950e-04  2.57641397e-01  1.07936641e-04
 -5.90807546e+00 -1.09287950e-04 -2.57641397e-01 -1.07936641e-04
 -2.55233500e+00 -6.25003321e-02 -2.24264100e+00 -2.43884161e-01
 -4.08283595e-04 -1.76223137e-08 -3.03534010e-04 -9.64729341e-05
  2.39000937e-02  2.55552134e-02  1.84112910e-02  7.13801792e-01
 -4.02883459e-04 -1.79029947e-08 -2.99551403e-04 -9.52145339e-05
 -2.58991928e-02 -2.45601685e-02 -2.02773531e-01  8.51328692e-02
  3.28818744e-05 -4.64077176e-05 -5.25529261e-04 -1.73634089e-02
 -3.45197477e-02 -2.79139739e-02 -2.36404634e-01  8.01015117e-02
  5.43752947e-02  3.86033584e-02  4.02037830e-01 -3.56452049e-02
 -8.38199624e-01 -8.44445466e-02 -1.11505768e-01 -8.89117235e-02
 -2.29287790e-01 -1.72674904e-02 -1.29219943e-01 -1.83265245e-02
 -8.86669668e-01 -1.00848766e-01  2.45837477e-01 -1.06406089e-01
  8.30544217e-02 -3.35540361e-01 -1.07302486e+00 -3.24931859e-01
 -1.72711402e-01  2.18021049e-01 -4.16779074e-01 -1.67199311e+00
  1.18439478e+00 -1.63136569e+00 -1.98748569e-01 -1.66432657e+00
 -9.71730150e+00]
supnorm grad right now is: 9.717301497716164
Weights right now are: 
[  0.75523756   3.86601519  -2.020393     4.56290014  -1.5454568
  -3.85155155   2.59169904  -3.14781709  -0.81560857   1.09917392
  -1.00088207   5.16386936  10.47648758   7.41835854  10.20585105
  14.79714793   6.80140961  -5.7028824    6.34436614   0.77931508
  10.60562016   7.38788435  10.05842469  14.82343854 -10.76480188
  -5.84465868   1.22931257   4.50773866  31.15918092  30.92600507
  33.79467618   6.96681512 -11.92271785  -5.21595859   2.74279221
   4.53624775   8.8715753    8.59919867   5.53782288 -12.28228727
  -1.95721915   8.66786786  21.43605644  11.69767014   2.65344276
  13.92683669   3.93981663  15.76573318  -0.16630914   6.80683186
   1.32249065   5.61858592  12.17195468  -4.50500537   4.13823515
  -3.53895502   4.47501674   4.54391972   3.16182457  -2.74664185
  -2.14036929  -4.37101451   3.14467939  -2.65744937  29.91719068]
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1700.6973692240153
gradient value of function right now is: [ 7.98275660e+00  1.04243444e-04 -4.29671096e-01  1.02944053e-04
 -7.98275660e+00 -1.04243444e-04  4.29671096e-01 -1.02944053e-04
 -3.64471287e+00 -8.61810105e-02 -3.17838893e+00 -1.50851889e+00
 -4.72688597e-04 -2.72692449e-07 -3.53297258e-04 -2.95850881e-05
  7.51373423e-02  2.71714661e-02  6.22450717e-02 -1.81668200e+00
 -4.65770678e-04 -2.69639583e-07 -3.48091236e-04 -2.97884406e-05
 -3.53543980e-02 -8.90287272e-03 -3.46546597e-01  3.80816604e-01
  3.74512669e-05  8.46827987e-05  1.76936517e-02 -3.50328380e-02
 -5.08151959e-02 -1.74080372e-02 -4.25722542e-01  3.35829107e-01
  4.51737747e-02  1.11008497e-03  7.57165416e-01  9.09063692e-02
 -9.40169409e-01 -1.24335830e-01 -1.32298396e-01 -1.20617969e-01
 -1.96785332e-01 -2.87513868e-02  5.63561678e-02 -2.89023205e-02
 -6.79196977e-01 -3.10819928e-01 -1.62452911e+00 -3.21479430e-01
  1.04900355e-01 -5.44409847e-01 -2.33874984e-02 -5.55415629e-01
 -4.96015642e-01  6.95810173e-01  1.25258444e+00 -1.48876926e+00
  6.40269343e-01 -1.45477808e+00  1.21907072e+00 -1.46619407e+00
 -7.05953567e+00]
supnorm grad right now is: 7.982756602483845
Weights right now are: 
[  0.85687594   4.20119168  -2.78318679   4.89734324  -1.64709518
  -4.18672804   3.35449284  -3.48226019  -0.95156906   2.6672406
  -1.22698429   4.97425504  10.4191984    7.39404468  10.26828771
  15.15854459   7.14322779  -5.5483877    6.63227567   0.09266386
  10.54981439   7.3638714   10.12239709  15.18468213 -11.09839804
  -5.78308464   1.43676937   4.54069791  33.63975341  32.06965204
  34.34933415   7.42032744 -12.14423141  -5.07993852   3.07580365
   4.57878128   9.80005024   8.76652497   5.65379431 -11.95432534
  -2.05039315   8.47231337  21.3746259   11.44664283   2.14393564
  14.22074397   4.68863469  16.0070728   -0.69250392   6.77777787
   1.05880426   5.56531628  10.24818616  -4.61432027   4.52874122
  -3.68457381   5.37155233   4.32205255   4.39090392  -2.21306028
  -1.61744042  -4.56409104   4.30067621  -2.30132865  30.30143069]
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1699.7604673264912
gradient value of function right now is: [ 3.47955751e+00  3.80230944e-04  8.10568355e-01  3.74116801e-04
 -3.47955751e+00 -3.80230944e-04 -8.10568355e-01 -3.74116801e-04
 -2.32222809e+00 -1.60646436e-01 -1.90423664e+00 -1.68560492e+00
 -1.22037924e-03 -6.17413499e-07 -9.17904922e-04 -5.83161952e-04
  5.12738633e-01  1.83718358e-01  4.69713491e-01  2.85280047e+00
 -1.19962799e-03 -6.06257591e-07 -9.01673772e-04 -5.71387882e-04
 -5.51277708e-03  2.92714425e-03 -3.73116527e-01 -6.14227480e-01
  1.15505189e-05  9.17491451e-05  1.83610131e-02  1.36510759e-01
 -5.50875315e-03  8.11293028e-03 -3.83715698e-01 -5.37447412e-01
  1.90472105e-02  2.83187418e-02  1.04238984e+00  5.82076494e-02
 -3.05753527e-01 -4.50757185e-02 -2.45131946e-02 -4.45441289e-02
 -1.90672448e-02 -2.55563396e-02 -2.26062844e-01 -2.59554189e-02
 -8.18110230e-01 -3.28588276e-01 -2.24212098e+00 -3.34090388e-01
  1.10701316e-01  9.09811244e-01  1.60189272e+00  9.16840062e-01
 -4.65903918e-01  2.52777822e-02  1.46510578e+00 -2.24706750e-01
 -1.89750169e-01 -3.52502310e-01  1.30165390e+00 -3.61764241e-01
 -2.09588704e+01]
supnorm grad right now is: 20.958870443199697
Weights right now are: 
[  0.73630855   4.42808866  -2.24323498   5.11942946  -1.52652779
  -4.41362502   2.81454103  -3.70434641  -0.80929996   2.89034759
  -1.11357209   5.10749069  10.62471962   7.37465382  10.70767647
  15.04736838   6.91570812  -6.46219163   6.25026198   0.58570232
  10.76084168   7.34474915  10.56761207  15.07611513 -10.28280507
  -6.411672     1.80650772   4.0430259   35.35253447  32.77456448
  34.06962505   7.78369775 -11.57789963  -5.65722334   3.50917779
   4.12088621   9.56514894   9.24245022   5.83151784 -11.81232623
  -1.82323257   8.73545492  23.26755257  11.68969758   2.12711539
  15.15483886   4.2129808   16.89491985  -0.52396131   7.37721482
   0.76836968   6.20012906  11.62444016  -4.01782748   5.20767291
  -3.14337651   4.79907142   3.30593591   3.71121316  -2.65963549
  -2.64437803  -3.90498825   3.65933955  -2.68614703  29.96511315]
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1702.9668912816762
gradient value of function right now is: [ 7.74346603e-01 -2.49418689e-03  1.84924986e-01 -2.43675922e-03
 -7.74346603e-01  2.49418689e-03 -1.84924986e-01  2.43675922e-03
 -4.22425552e-01 -1.42922580e-01 -7.94133385e-01 -4.43246369e-01
  9.81186261e-03 -2.46208510e-07  5.70578526e-03  2.29761454e-03
  5.44589050e-02  1.19654308e-01  9.72965443e-02  7.38050574e-01
  9.56631106e-03 -2.42012716e-07  5.56325181e-03  2.24271481e-03
 -6.12911647e-04  7.27178401e-02  2.86565609e-01 -3.66729810e-03
  1.61109832e-06  9.85678712e-06  9.03626564e-03  4.87473636e-02
 -8.56233100e-04  7.60307335e-02  2.56153249e-01 -7.29879055e-03
  1.38559463e-02 -7.61254494e-02 -2.10149151e-01 -9.40840563e-03
 -2.36055243e-01 -3.93875791e-02  2.81817309e-03 -4.02357004e-02
  1.89139204e-01  1.67830694e-02  5.16643153e-01  1.84500352e-02
 -3.46480162e-01 -1.49787863e-01 -2.44528614e-01 -1.53817609e-01
  2.42776082e-02  2.73700837e-02 -6.94532038e-02  2.81291609e-02
  1.39628551e-01 -2.54338881e-01  1.36887576e-02 -4.06125585e-01
 -6.81237924e-01  2.88043312e-01 -5.85578221e-02 -3.70435069e-01
 -5.81579402e+00]
supnorm grad right now is: 5.815794021245812
Weights right now are: 
[  0.82952876   5.21262855  -2.17626208   5.90345436  -1.619748
  -5.19816491   2.74756812  -4.48837132  -0.69447783   1.7644945
  -1.11483683   5.14876947  10.11816535   7.35559172  10.32105015
  15.03634518   7.26005992  -6.0318071    6.5503187    0.52027008
  10.25453136   7.32591945  10.18144399  15.06567481 -11.27196267
  -5.98056738   2.20251189   4.6851292   37.41237635  34.66083089
  35.52706113   6.53119681 -13.20437099  -5.18363501   3.96232451
   4.79412729   9.42316644   8.85031337   5.39750753 -11.93733753
  -2.13198734   9.54852178  23.54357793  12.41199928   2.06805472
  16.39949548   4.20727291  18.09620134  -0.63591668   6.84686202
   0.78380088   5.66709915  11.47054233  -4.34045366   4.887361
  -3.48544655   5.46893668   3.06403194   3.54136884  -2.4981811
  -2.61231447  -3.95509701   3.44389296  -2.47169884  30.06138287]
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1701.9826881771826
gradient value of function right now is: [ 5.96554349e+00  5.59488433e-04 -1.24439962e-01  5.47107441e-04
 -5.96554349e+00 -5.59488433e-04  1.24439962e-01 -5.47107441e-04
 -2.40906064e+00  7.97149127e-02 -2.21254635e+00 -9.17197418e-02
 -2.23829895e-03  2.42552586e-08 -1.41679377e-03 -6.51855146e-04
  2.13739950e-02 -1.31546658e-02 -1.38010963e-03 -5.73160800e-01
 -2.18617174e-03  2.44032681e-08 -1.38297494e-03 -6.35121597e-04
 -1.92391627e-02 -6.34789195e-03 -1.79563610e-01  1.21221444e-01
 -1.73451316e-04  4.24627802e-05 -9.59470099e-03  9.17362501e-03
 -3.32355734e-02 -1.10179657e-03 -1.97361023e-01  9.88072009e-02
  3.17595813e-02  2.95098530e-02  3.43878904e-01  2.13277892e-02
 -6.12204518e-01 -9.40309119e-02 -7.55665463e-02 -8.66046473e-02
 -1.46692894e-01 -3.52613948e-02 -9.47218277e-02 -3.39192762e-02
  2.26914868e-01  9.60305800e-02 -2.54686210e-01  9.01518172e-02
  1.87083426e-02 -3.25506129e-01 -2.23756637e-01 -3.39701088e-01
 -2.32712541e-01  4.44054225e-01  4.61100924e-01 -8.61932157e-01
  3.36003861e-01 -1.00006650e+00  5.11629917e-01 -8.94460867e-01
  5.33682456e+00]
supnorm grad right now is: 5.965543488535231
Weights right now are: 
[  1.02268114   5.36346883  -3.01070127   6.05212079  -1.81290038
  -5.34900519   3.58200731  -4.63703774  -0.74324503   3.02101072
  -1.22149618   5.90073808  10.18310638   7.38408395  10.45172899
  14.93651146   7.09931166  -6.67911073   6.25357417  -0.08103052
  10.32209004   7.35392255  10.31383995  14.9640974  -11.49237423
  -6.12372648   2.11259358   4.53439137  37.62119893  35.25577938
  35.71072438   7.39073664 -13.44141568  -4.83980682   4.11158558
   4.64821522  10.69007702   9.98890456   5.69024226 -11.88062542
  -3.00473843   9.04445684  23.25300656  11.88093021   1.58888782
  15.90704352   3.29169522  17.55732924  -1.02523996   7.29472989
   1.01251895   6.15498762  11.78458429  -4.21431731   5.35646897
  -3.37107153   5.11103573   3.00212046   4.38524286  -2.08566699
  -2.248187    -4.51383665   4.34420164  -2.24365841  30.43120114]
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1703.9981780709595
gradient value of function right now is: [-2.70777428e+00 -6.92507967e-04  4.48631441e-02 -6.71527840e-04
  2.70777428e+00  6.92507967e-04 -4.48631441e-02  6.71527840e-04
  8.95499923e-01 -6.78731912e-02  6.81807330e-01 -3.18293317e-01
  2.90660385e-03 -1.23811346e-07  1.64967974e-03  6.97019118e-04
  2.07183107e-01  1.72339254e-01  2.37829090e-01  3.37410724e-01
  2.80530214e-03 -1.20655832e-07  1.59336575e-03  6.75134113e-04
  1.58459938e-02  3.91445086e-02  1.91673406e-01 -4.36914606e-02
 -1.55514488e-06  3.95658641e-05  1.71200544e-02  1.00184320e-01
  2.58624248e-02  3.83228012e-02  1.76606755e-01 -4.32488872e-02
 -1.10006385e-02 -3.07624224e-02 -1.45913823e-01  7.20578421e-03
  3.90211475e-01  5.99940859e-02  2.33219394e-02  5.87330192e-02
  8.03396312e-02  1.32939479e-02  1.59375659e-01  1.35485492e-02
  1.29295385e-01 -1.22227181e-01 -1.02123260e+00 -1.33926382e-01
 -5.39763077e-02  2.55015719e-02  3.50122134e-01  3.18156801e-02
  2.69188727e-01 -3.75844043e-01  4.95984324e-01  1.42693242e+00
 -1.14874477e-01  2.58685994e-01  3.85210708e-01  1.43780393e+00
 -1.97456944e+00]
supnorm grad right now is: 2.707774283313652
Weights right now are: 
[  0.71902784   5.39795669  -2.91769009   6.07909961  -1.50924708
  -5.38349305   3.48899614  -4.66401656  -0.60629218   2.00629129
  -1.0168593    5.86521996  10.25948871   7.3638562   10.83627121
  16.12849563   6.73787767  -7.61123484   5.75131294  -0.0968743
  10.40686592   7.33402989  10.7057952   16.15340829 -11.61268521
  -6.54974758   2.25783945   4.7762574   37.837395    36.14020212
  37.9592933    7.20979272 -14.25952674  -5.21949047   4.14687361
   4.92025593   9.21608674   9.97566767   5.32938939 -12.07971257
  -2.49486397  10.76932974  23.71187494  13.598527     1.28069978
  16.97214613   3.16424512  18.51676769  -1.68869834   6.41682375
   0.94610684   5.26243504  11.58421933  -4.49270283   5.21663533
  -3.64653273   5.86838802   3.23198845   4.43433693  -1.8794976
  -2.11905133  -4.47204108   4.33410601  -1.91315613  30.22395325]
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1696.5982186853405
gradient value of function right now is: [-1.66139253e+01 -5.50066907e-02 -2.26584260e-01 -5.36168438e-02
  1.66139253e+01  5.50066907e-02  2.26584260e-01  5.36168438e-02
  7.26876217e+00 -6.55698213e-03  4.92044810e+00  1.77332367e+00
  1.48178534e-01  2.85971255e-07  6.94644285e-02  2.21796088e-02
 -7.20843470e-01  2.94241742e-01 -1.65319660e-01  1.88768969e+00
  1.43791175e-01  2.77840110e-07  6.74062828e-02  2.15566540e-02
  2.06139037e-01  1.57875506e-01  2.65134326e+00 -6.34092385e-01
 -1.98471204e-07 -4.45920314e-04 -6.35854554e-03  1.85217856e-01
  2.55589328e-01  1.53959765e-01  2.09236438e+00 -5.20108211e-01
 -5.53013423e-02 -2.25208147e-01 -2.54632253e+00 -4.17735814e-02
  4.21310173e+00  5.37288327e-01  2.80297961e-01  5.51320287e-01
  6.55492465e-01  1.13566442e-01  2.30777662e+00  1.25122263e-01
 -1.29184862e+00 -3.79683287e-02  2.38482866e+00 -3.11992102e-02
 -5.82558295e-02  1.27498805e+00  1.10637560e+00  1.27790107e+00
  3.21391552e-01 -7.65167222e-01 -1.89602488e+00  5.05024377e+00
 -2.85036418e+00  4.70482026e+00 -2.36348746e+00  6.21407064e+00
  2.35910268e+01]
supnorm grad right now is: 23.591026807357633
Weights right now are: 
[  0.69580625   4.87677503  -2.87682883   5.55692821  -1.48602549
  -4.8623114    3.44813488  -4.14184516  -0.62501212   3.61814701
  -0.99547435   6.44185344  10.93967997   7.3679255   11.68225777
  16.6703244    7.31189344  -7.2615067    6.28631084   0.22068315
  11.08969208   7.33798958  11.55384274  16.69365691 -11.24675871
  -6.93816346   2.62527849   4.06173213  38.04893986  36.72221347
  37.78840544   8.39496095 -14.05062738  -5.7258905    4.47498792
   4.17641395   9.51172562  10.71030605   5.28169265 -11.32633954
  -2.33921847  10.97391425  24.46246122  13.83830367   1.45934528
  17.49411232   3.04767549  18.99489842  -2.46181999   6.19264288
   1.54536545   5.16510856  12.82809981  -4.02602206   6.14716963
  -3.20273567   4.87702327   3.24765088   4.6793763   -1.82029722
  -1.90902557  -4.32828876   4.50981126  -1.79956937  30.33172107]
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1700.1532324084792
gradient value of function right now is: [ 9.82900333e+00  1.63386375e-02  1.84040030e-01  1.58682971e-02
 -9.82900333e+00 -1.63386375e-02 -1.84040030e-01 -1.58682971e-02
 -5.14010033e+00 -3.39994784e-02 -3.61947899e+00 -1.84318836e+00
 -5.78264048e-02 -4.89477570e-07 -2.54483866e-02 -9.13604740e-03
  7.12219956e-01  9.45455741e-02  4.60679591e-01  3.27535975e-02
 -5.59646557e-02 -4.75620691e-07 -2.46265696e-02 -8.84970724e-03
 -1.76329972e-02 -1.32046627e-01 -1.39984726e+00  1.85480880e-02
  5.86886793e-08  1.38408791e-04  1.35746681e-02  2.88066276e-02
 -1.83989145e-02 -1.24451206e-01 -1.16154179e+00  5.04856918e-03
  6.21047569e-03  2.13748589e-01  2.20092200e+00  1.15540996e-01
 -3.83464557e-01 -5.48737680e-02 -3.47159329e-02 -5.61024424e-02
 -1.61085482e-01 -1.00213783e-01 -2.24642848e+00 -1.09717003e-01
 -4.65034606e-01 -3.76776778e-01 -2.78515726e+00 -3.96971498e-01
  1.21444564e-01 -1.93159607e-01  7.79406127e-01 -1.86024518e-01
 -8.07325743e-01  7.80955283e-01  2.23553917e+00 -1.06490122e+00
  5.77950816e-01 -6.03057381e-01  2.36613930e+00 -1.15244094e+00
 -1.06956423e+01]
supnorm grad right now is: 10.695642256308068
Weights right now are: 
[  1.02269772   5.93505995  -3.62554801   6.61546076  -1.81291696
  -5.92059631   4.19685406  -5.20037771  -0.90114114   4.48920424
  -1.34233314   6.10730512  10.07632783   7.36256033  10.94348616
  16.06444944   7.72684012  -7.4098312    6.40424093  -0.63524769
  10.22758198   7.33279696  10.81580843  16.08222455 -11.99417315
  -6.78774684   2.12003322   4.54820717  38.159525    37.41447099
  37.34438065   8.52067685 -15.3253947   -5.57544642   4.23125444
   4.63743063   8.90300245  10.3892148    5.64502943 -12.271223
  -2.89542929  10.77844361  24.81381048  13.57472353   1.25125382
  18.16933607   2.85973036  19.59315985  -2.73827692   6.07796792
   1.08652144   5.14086339  12.62963146  -4.43430002   5.9180399
  -3.62281003   6.03661324   3.18257924   4.46771182  -2.08800806
  -1.94552262  -4.04234645   4.32357228  -2.08341151  30.47467337]
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1698.6448144760686
gradient value of function right now is: [ 1.13094664e+01  8.24171064e-04  6.94926711e-02  7.95339857e-04
 -1.13094664e+01 -8.24171064e-04 -6.94926711e-02 -7.95339857e-04
 -5.49999783e+00  9.06010170e-03 -3.98242656e+00 -1.40679522e+00
 -4.71020344e-03 -7.66656735e-07 -2.34853824e-03 -1.21694591e-03
  1.52525672e-01 -1.17222382e-01  4.25419296e-02  1.63059469e-01
 -4.53325383e-03 -7.47645241e-07 -2.26117513e-03 -1.17384178e-03
 -2.83401358e-02 -6.69712039e-02 -5.24288726e-01 -1.04688382e-01
 -1.11250069e-04  2.95522515e-04  3.54374327e-03  7.72927327e-02
 -1.02620907e-01 -1.26388552e-01 -9.48493122e-01 -1.27160954e-01
  6.81147670e-02  1.36780896e-01  1.42883286e+00  9.64101186e-02
 -1.11787370e+00 -2.67264937e-01 -1.65949943e-01 -2.59084954e-01
 -1.03107080e-01 -5.46160067e-02 -9.78676121e-01 -6.04824412e-02
  1.25047117e-01 -1.93195709e-02 -2.26147648e+00 -4.88243153e-02
  1.08173256e-01  9.61624752e-02  8.53584741e-01  1.05345684e-01
 -1.19134413e+00  1.33338164e+00  2.22913681e+00 -1.26149201e+00
  1.47999438e+00 -1.89796849e+00  2.48072032e+00 -1.57102409e+00
 -1.45716092e+01]
supnorm grad right now is: 14.571609244534056
Weights right now are: 
[  0.98928468   6.278735    -3.38300931   6.96497178  -1.77950392
  -6.26427136   3.95431536  -5.54988873  -0.52501352   5.96636841
  -1.75830445   5.9336846   10.05758562   7.29679305  10.76599009
  15.54287843   7.57166646  -8.03730745   5.88408986  -0.80159333
  10.20032827   7.26883721  10.62956812  15.55675375 -13.79486192
  -5.6168133    1.6010739    4.59452164  39.0774059   38.72823566
  35.45107797   7.7886208  -16.86100206  -3.66400736   4.68002346
   4.87530093   9.16020328   9.52467197   5.80485126 -12.9537515
  -3.85080702  10.43657047  23.2634803   13.02024993   1.70045658
  19.15350248   3.28173758  20.49223022  -2.03759783   7.0711808
   1.05903826   6.19217933  14.30491164  -3.95288504   6.1403513
  -3.12281867   5.42953814   2.85621349   4.34157578  -1.45392247
  -1.19181182  -5.29883149   4.15644813  -1.58392373  30.27925712]
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1702.679389299394
gradient value of function right now is: [ 6.56197648e+00  3.66292552e-03  5.14166232e-02  3.53277553e-03
 -6.56197648e+00 -3.66292552e-03 -5.14166232e-02 -3.53277553e-03
 -3.26701357e+00 -5.63089992e-02 -1.76888640e+00 -7.84058174e-01
 -1.63388621e-02 -1.79651002e-07 -4.96722773e-03 -2.07520771e-03
  4.72462868e-01  1.31563615e-01  2.86204593e-01 -1.20998035e-01
 -1.57464065e-02 -1.77801409e-07 -4.78994969e-03 -2.00645243e-03
 -2.08530581e-02 -4.55040098e-02 -6.86314189e-01  1.11483218e-01
  1.10621830e-07  9.81727451e-05  2.35877274e-02  8.16689193e-03
 -6.73364856e-02 -7.21691068e-02 -8.38201952e-01  6.57061053e-02
  9.71923921e-03  4.75171745e-02  8.69120385e-01  3.83808153e-02
 -8.01079584e-01 -1.20788783e-01 -9.07565278e-02 -1.21861968e-01
 -1.79536693e-01 -3.69520048e-02 -2.11199627e-01 -3.98489478e-02
 -1.27361228e-01 -2.66873149e-01 -1.11271458e+00 -2.86146404e-01
  5.06546827e-02 -3.78404379e-01 -2.63083664e-01 -3.84948361e-01
 -6.83490502e-01  7.52830887e-01  1.05872508e+00 -1.34164017e+00
  7.87621070e-01 -1.25277835e+00  1.14969173e+00 -1.43080923e+00
 -8.63745779e+00]
supnorm grad right now is: 8.637457790844497
Weights right now are: 
[  0.79647766   5.34224991  -3.55155495   6.0409361   -1.5866969
  -5.32778627   4.12286099  -4.62585306  -0.42129188   4.92245195
  -1.72717742   6.27156976  11.25781639   7.33111286  11.35693458
  15.5600119    7.97974894  -7.92924727   6.22169928  -0.81718298
  11.3877007    7.30232681  11.21103498  15.56841146 -12.45416646
  -6.01080475   1.27705855   4.71657203  38.62406684  39.5035096
  36.59229834   8.3895055  -16.83333287  -4.33572862   4.61405286
   4.94129188   8.289391     9.52536914   5.58104084 -12.09646583
  -3.23428485  11.3561674   23.77418972  13.87625149   0.6834088
  18.92690325   3.32213758  20.18267641  -2.92048485   5.93027763
   1.39235729   5.15299932  15.16585234  -4.58365507   6.03071246
  -3.7314833    4.78608162   3.08391741   4.53282921  -2.00488526
  -1.6982559   -5.01787947   4.34665673  -2.04811652  30.26235313]
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1701.4849104770221
gradient value of function right now is: [-2.32046435e+00 -8.08488656e-03 -5.85782635e-01 -7.87424126e-03
  2.32046435e+00  8.08488656e-03  5.85782635e-01  7.87424126e-03
  1.26787129e+00 -4.94152689e-03  4.11162225e-01  9.70088954e-01
  2.45465329e-02  2.04593459e-07  8.42956865e-03  7.24415774e-03
 -9.42278897e-01  1.71509592e-01 -3.57694392e-01 -1.29362115e+00
  2.39077796e-02  2.00874959e-07  8.21318312e-03  7.06175493e-03
  1.81227786e-02  1.02161354e-01  1.66895509e+00  3.90318001e-01
 -5.32124737e-06 -1.62857186e-05  1.89555903e-03 -1.22160797e-01
 -3.33244045e-02  3.14731333e-02  9.41836322e-01  2.80547246e-01
 -1.13271862e-02 -9.29152898e-02 -1.73062198e+00 -1.92498652e-02
 -5.83365516e-02  2.09291114e-02  2.63464247e-02  2.09440515e-02
  2.72845256e-01  6.85064504e-02  8.43810716e-01  6.85671267e-02
 -1.91491337e-01 -7.02594201e-02 -5.38948090e-01 -7.01877441e-02
 -4.52471631e-02 -9.99686235e-01 -1.57469789e+00 -9.97169271e-01
  2.26782238e-02  4.12443972e-01 -1.24917761e+00 -1.09423497e+00
 -3.32165475e-01  2.23682641e-01 -1.22606546e+00 -7.92068609e-01
  6.93067914e+00]
supnorm grad right now is: 6.9306791410722255
Weights right now are: 
[  0.64515783   4.81286884  -3.45022591   5.51280325  -1.43537706
  -4.7984052    4.02153196  -4.0977202   -0.07722655   5.51477579
  -1.74305827   6.85089101  11.90893263   7.32999286  12.08520913
  15.99625093   7.69125421  -7.78838266   6.08145942  -0.74497695
  12.04058143   7.30117556  11.93962095  16.00518479 -12.43781275
  -5.90201942   2.59068051   4.80967336  38.81597091  41.07235236
  36.63674515   7.90612185 -16.57033237  -4.61081509   5.72615837
   5.0994175    7.36831054   9.57806668   4.64007897 -11.7180653
  -2.85039152  11.81978935  24.35093907  14.28345606   1.41837127
  19.65864703   3.52864971  20.82347301  -1.79828051   6.71762235
   0.82509267   5.91353942  17.12281375  -4.40773296   6.09034836
  -3.59931801   3.62327563   2.65527459   3.60106859  -2.24349129
  -1.72132119  -4.5236224    3.60165625  -2.2322852   29.89748297]
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1696.0082315559569
gradient value of function right now is: [ 1.46142740e+01  3.60150826e-03  1.19634251e-01  3.47485479e-03
 -1.46142740e+01 -3.60150826e-03 -1.19634251e-01 -3.47485479e-03
 -8.52349734e+00 -1.01878004e-02 -4.03510238e+00 -1.80201284e+00
 -1.77989878e-02 -2.51986322e-07 -6.37251337e-03 -2.62514841e-03
  5.49926582e-01 -5.85230503e-02  2.07645120e-01 -1.93147019e-01
 -1.71648269e-02 -2.47917676e-07 -6.15123753e-03 -2.54196549e-03
 -2.53732071e-02 -2.11136910e-01 -1.53800113e+00  7.96166866e-02
 -2.42451587e-06  8.51065325e-05  9.81037534e-03 -9.37752365e-02
 -7.93644987e-02 -3.14134713e-01 -2.13343608e+00  2.40415918e-02
  2.67166743e-02  2.84383205e-01  2.76631766e+00  7.73322672e-02
 -9.76901523e-01 -1.68405936e-01 -1.28041045e-01 -1.55256103e-01
 -4.18492299e-01 -1.71278705e-01 -2.92587749e+00 -1.73636908e-01
 -1.01610340e-01 -3.00931564e-01 -2.60675147e+00 -3.21925542e-01
  1.16635662e-01 -1.92997950e-01  4.62643252e-01 -2.07270290e-01
 -1.24803607e+00  1.09553467e+00  3.55121195e+00 -1.78324995e+00
  1.56480544e+00 -1.81524634e+00  3.68127062e+00 -1.84584428e+00
 -2.30927660e+01]
supnorm grad right now is: 23.092765988827875
Weights right now are: 
[  0.99965153   5.37276083  -3.21925309   6.07366385  -1.78987077
  -5.35829719   3.79055914  -4.6585808   -0.54007452   6.16496952
  -1.90992881   6.60934231  11.45999189   7.34349289  11.73352922
  15.58300927   8.02031851  -8.04251285   6.06754032  -0.94962902
  11.59021958   7.31472803  11.58502849  15.58801408 -13.30604102
  -6.36376411   1.3860942    5.18548084  40.32774424  41.2284923
  36.70777748   7.00007279 -16.21121746  -4.68428785   4.90957862
   5.54769608   7.61857534  10.6482456    5.69051177 -11.9842081
  -3.22598233  11.1030791   24.34074369  13.65912649   1.09472564
  19.08104744   2.33766609  20.16439767  -2.17370253   6.49784793
   0.62205605   5.70686462  15.83379386  -4.49123889   6.3013435
  -3.65141221   4.96540743   2.9947629    4.45606723  -1.55458172
  -1.53989676  -4.65559534   4.38599977  -1.72242035  30.37118745]
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1703.4243122074022
gradient value of function right now is: [-7.06041219e+00 -7.09828551e-04  2.38031473e-01 -6.72848415e-04
  7.06041219e+00  7.09828551e-04 -2.38031473e-01  6.72848415e-04
  3.49439729e+00  5.00163310e-03  2.44531718e+00  5.49894335e-01
  4.59943886e-03  5.03827735e-07  1.51409643e-03  6.01540053e-04
  4.79830137e-01  5.03828762e-01  5.15930252e-01  1.05793578e+00
  4.34362302e-03  4.89342112e-07  1.43424366e-03  5.75063384e-04
  3.80482216e-03  2.12318016e-02  1.58231056e-01 -2.51938597e-01
 -2.39790575e-05 -4.18875281e-05 -4.69567207e-03  2.06243016e-01
  1.62768865e-02  6.53954561e-02  3.12188669e-01 -1.73254482e-01
 -1.28843914e-02 -5.00672037e-02 -6.32213797e-01  3.46968760e-03
  1.53533669e-01  2.97212252e-02  4.15866442e-02  2.63930965e-02
  8.38789591e-02  1.84775081e-02  3.97373328e-01  2.12306016e-02
  6.26952740e-01  2.24622025e-01  7.06682071e-01  2.01825774e-01
 -8.99055842e-03  4.26172330e-01  6.40339060e-01  5.11229789e-01
  2.74617902e-01 -5.31152844e-01 -2.15847736e-01  1.80880300e+00
 -5.77705188e-01  5.86888168e-01 -3.78406931e-01  1.42154601e+00
  5.38148566e+00]
supnorm grad right now is: 7.060412193704829
Weights right now are: 
[  0.67886636   6.24854308  -2.86172046   6.93649538  -1.4690856
  -6.23407944   3.4330265   -5.52141233  -0.24096914   7.44296295
  -1.29819256   6.84243158  10.37294728   7.34845116  11.06225227
  15.16192551   8.45789173  -7.93646877   6.23743964  -0.73650739
  10.52004744   7.32005328  10.92629612  15.17188354 -14.11202204
  -6.250839     1.34759978   4.86090717  40.75239814  42.10805612
  36.00332492   7.43129361 -16.58302972  -4.43341543   5.23139194
   5.28152848   7.72827104  10.19270208   5.5402791  -11.41130291
  -3.59970872  10.90526536  24.39145376  13.58781074   0.9405835
  19.55383518   2.81084013  20.59041476  -2.08957357   6.88867589
   0.95652191   6.21011235  14.70279232  -4.36174308   6.83480254
  -3.40870105   5.58463112   3.27325543   4.46414285  -1.61878375
  -1.97828201  -4.55591006   4.1083184   -1.97885965  30.15666748]
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1704.4734973957986
gradient value of function right now is: [ 1.51338610e+00  2.61254977e-03  1.56928679e-02  2.52041984e-03
 -1.51338610e+00 -2.61254977e-03 -1.56928679e-02 -2.52041984e-03
 -1.08979589e+00 -2.59336410e-02 -4.78338721e-01 -4.41908740e-01
 -1.10609493e-02 -2.47651982e-07 -3.18945271e-03 -1.83881563e-03
  1.69145400e-01 -1.18995544e-02  8.58484165e-02 -1.89858881e-01
 -1.06545954e-02 -2.43718234e-07 -3.07325887e-03 -1.77544712e-03
 -1.17123780e-02 -5.48111411e-03 -2.56769048e-01  1.18076721e-01
  1.51025456e-07  3.73251356e-05  2.21118855e-02 -6.74707490e-02
 -5.22137173e-02 -1.21260307e-02 -3.54948508e-01  7.12336713e-02
  1.07845571e-02  1.01321132e-02  4.42356331e-01  1.19895432e-02
 -6.87058857e-01 -1.12536943e-01 -6.72217838e-02 -9.86059592e-02
 -2.13751999e-02 -6.80070161e-03 -8.77614411e-02 -7.95011449e-03
  7.82323958e-02 -1.43135291e-01 -1.06733095e+00 -2.00496434e-01
  2.13918585e-03 -2.49154600e-01 -2.01916871e-01 -2.77743193e-01
 -2.19353875e-01  3.70860746e-01  7.12319968e-01 -7.36640097e-01
  4.21119135e-01 -9.06863771e-01  9.01531968e-01 -5.58763473e-01
 -7.06575639e+00]
supnorm grad right now is: 7.065756390328247
Weights right now are: 
[  0.63700593   5.44332482  -2.25266757   6.14240377  -1.42722517
  -5.42886118   2.82397361  -4.72732072  -0.19252482   7.64753797
  -1.67382767   6.5160066   11.61411433   7.32331408  12.45492414
  15.61468873   7.83717352  -8.64089748   5.58534974  -0.67593039
  11.75010188   7.29562906  12.30412255  15.61061164 -14.03556569
  -5.06924227   1.58474099   5.21953744  41.94459291  42.22638499
  36.72749047   7.27616034 -17.25689404  -4.66454211   5.31912355
   5.6848423    7.61714593   9.46845896   5.43439432 -11.86647297
  -3.60304762  11.04670186  24.4079885   13.82127153   1.98228491
  21.21100404   3.3223926   22.08447609  -2.53602199   6.1840694
   0.52669065   5.63442959  15.82335617  -4.73147351   6.39853444
  -3.7269358    5.04160118   4.35626726   4.49377892  -1.47024475
  -1.22379668  -4.44310994   4.15359152  -1.50820269  29.58179489]
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1704.2396111926762
gradient value of function right now is: [ 1.70163206e+00  1.37739470e-03 -4.54072744e-02  1.32413986e-03
 -1.70163206e+00 -1.37739470e-03  4.54072744e-02 -1.32413986e-03
 -1.00931153e+00 -9.07620098e-03 -3.46981200e-01 -9.11076224e-02
 -6.27067136e-03 -1.30283218e-08 -1.78823352e-03 -9.57352427e-04
  9.13928118e-02  1.42278511e-02  3.84731948e-02 -3.74150922e-01
 -6.02054737e-03 -1.29892603e-08 -1.71732653e-03 -9.21626737e-04
 -9.29090241e-03 -1.69675077e-02 -1.80892949e-01  1.84965199e-01
 -7.22778086e-07  3.99396232e-06  1.04445678e-02 -1.00914719e-01
 -5.70309078e-02 -3.28279410e-02 -3.05199216e-01  1.12979448e-01
  1.44222878e-02  2.16369483e-02  2.22624278e-01  7.55098523e-03
 -6.93799826e-01 -1.05285943e-01 -8.09544270e-02 -9.76848037e-02
 -5.47077160e-02 -8.35431401e-03 -7.88146480e-02 -8.93980523e-03
  1.72664301e-01 -3.53154440e-02 -2.59455511e-01 -5.90462222e-02
 -1.79013983e-03 -4.10579982e-01 -4.99106608e-01 -4.45993084e-01
 -2.38770930e-01  5.01872610e-01  3.66708774e-01 -1.01542336e+00
  6.13648452e-01 -1.07885872e+00  4.94738069e-01 -9.11792316e-01
 -5.63836323e+00]
supnorm grad right now is: 5.638363225898636
Weights right now are: 
[  0.49290629   4.92330426  -2.3949459    5.62470576  -1.28312553
  -4.90884062   2.96625195  -4.20962271  -0.16486435   8.19024448
  -1.37944001   6.9748096   12.11309597   7.33037276  12.75464997
  15.74453845   8.43158527  -7.89203914   6.12275487  -0.50046443
  12.24831764   7.30256808  12.6025352   15.73666186 -14.13674334
  -5.54803425   1.56584121   4.64470594  42.48192736  43.4627685
  35.85012379   8.55502089 -16.61746321  -5.71053207   5.31718213
   5.0465629    9.21675428   9.29448454   5.41999608 -11.53529081
  -3.60505929  10.62027658  24.39295505  13.37727495   1.11049381
  21.10943292   3.16235728  21.92866879  -2.38643922   7.44304081
   1.21369772   6.90644453  16.81808352  -4.62329109   6.67302232
  -3.55390019   5.62804975   3.4950204    4.47405971  -1.79081376
  -0.96324972  -4.84161174   4.08168636  -1.92256441  30.38087614]
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1704.2437500587341
gradient value of function right now is: [ 1.38141255e+00  1.40828260e-03 -1.07604336e-02  1.35267804e-03
 -1.38141255e+00 -1.40828260e-03  1.07604336e-02 -1.35267804e-03
 -9.02180931e-01 -5.57290698e-03 -1.97503063e-01 -5.75399924e-02
 -6.48602918e-03  9.63199748e-09 -1.82449048e-03 -9.84653297e-04
  2.39158215e-01  1.60863310e-01  1.84907107e-01 -2.20164934e-01
 -6.22152914e-03  9.43064857e-09 -1.75062963e-03 -9.47080452e-04
 -8.35783745e-03 -1.94994701e-02 -1.75750906e-01  1.57770896e-01
 -1.67575298e-06 -7.18742071e-06  7.19796660e-03 -3.74510543e-02
 -5.70605220e-02 -3.71775352e-02 -3.04316030e-01  8.85705089e-02
  1.36138323e-02  2.82340948e-02  2.21717634e-01  1.37402070e-02
 -6.66283802e-01 -9.60634982e-02 -7.59239551e-02 -9.19366737e-02
 -6.60934863e-02 -1.08840642e-02 -1.03915181e-01 -1.20199570e-02
  2.03975615e-01 -1.56498662e-02 -1.50506012e-01 -3.20774064e-02
  5.54133418e-03 -4.39862891e-01 -5.15211120e-01 -4.69902494e-01
 -2.61053005e-01  4.79229874e-01  3.23682645e-01 -1.05507061e+00
  5.86939507e-01 -1.04364493e+00  4.50416710e-01 -9.77235919e-01
 -5.41013053e+00]
supnorm grad right now is: 5.410130527254215
Weights right now are: 
[  0.69037802   5.29340462  -2.03999116   5.99113332  -1.48059726
  -5.27894099   2.61129721  -4.57605027  -0.22569437   9.58674642
  -1.83486826   6.943607    11.84216633   7.32927802  12.7511043
  16.28689586   8.13267317  -8.31122266   5.68271119  -0.47953842
  11.98024452   7.3017328   12.59882807  16.27273205 -13.78936465
  -5.20526496   1.55812978   4.72332984  43.12700049  43.35522261
  34.86104066   8.66925847 -16.39782155  -4.64190592   5.85280716
   5.23096859   8.54027828   8.60268328   5.67347925 -11.85450397
  -3.40565149  11.2306755   24.87389158  13.98379054   1.66406925
  21.46085165   3.38635419  22.13164734  -2.62854966   7.99925066
   1.00362772   7.4464757   18.75420603  -4.71441955   6.41125753
  -3.69181223   5.43621853   1.96833116   3.78871351  -2.41226515
  -1.41905625  -4.72292474   3.55230669  -2.44249965  29.79853155]
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1704.4908188317954
gradient value of function right now is: [ 1.19838427e+00  1.40952075e-03  3.33468104e-02  1.34964893e-03
 -1.19838427e+00 -1.40952075e-03 -3.33468104e-02 -1.34964893e-03
 -8.10407546e-01 -2.16969727e-03 -1.35516533e-01 -4.17839006e-02
 -6.67159997e-03  1.90417359e-08 -1.75258787e-03 -1.00497540e-03
  2.74787480e-01  1.97321206e-01  2.22984198e-01 -4.62957047e-02
 -6.37687039e-03  1.87200729e-08 -1.67579833e-03 -9.63306878e-04
 -7.82731291e-03 -1.59046353e-02 -1.57298028e-01  9.88726366e-02
 -1.21782184e-06 -1.04763355e-05  3.98631977e-03  7.80883185e-03
 -5.22482356e-02 -2.79311741e-02 -2.65152657e-01  4.71133498e-02
  1.14695765e-02  2.54889798e-02  2.05870179e-01  1.40740436e-02
 -5.86886831e-01 -8.42011675e-02 -6.26373185e-02 -8.19473033e-02
 -5.26414095e-02 -1.03977499e-02 -1.01103516e-01 -1.13929560e-02
  1.77153024e-01 -6.18702431e-03 -7.16206345e-02 -1.47159155e-02
  1.39219316e-02 -3.36858282e-01 -3.78967611e-01 -3.57579493e-01
 -2.31702699e-01  3.66496289e-01  2.29418231e-01 -9.61196495e-01
  4.43189952e-01 -9.02506470e-01  3.31980396e-01 -9.27488482e-01
 -4.74075710e+00]
supnorm grad right now is: 4.740757100820651
Weights right now are: 
[  0.79513113   6.65841527  -2.340864     7.33412753  -1.58535036
  -6.64395164   2.91217005  -5.91904448  -0.51159556   9.8710554
  -1.41077486   7.39119794  10.28342071   7.35328147  11.84787365
  15.98757829   8.97398506  -7.36291509   6.42208898  -0.77124123
  10.44752745   7.32441339  11.7204454   15.98615811 -15.61569841
  -6.7882041    1.43642898   5.07859052  43.23163952  43.91723766
  35.84152088   8.43003888 -15.56918693  -4.74157479   6.30183689
   5.65464524  10.24281976   9.80155777   5.47486731 -10.88586869
  -3.78285246  10.67369499  24.42012078  13.41875474   1.2776902
  21.46890807   2.92467179  22.04079509  -2.72872638   7.66823867
   0.65619398   7.12109197  18.50773483  -4.99403829   6.38925188
  -4.00247015   5.79947988   2.34236366   4.01014856  -2.45109852
  -0.94453705  -4.85850373   3.90858894  -2.47881855  30.06699783]
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1704.5838588222168
gradient value of function right now is: [ 1.42914196e+00  1.51400542e-03  1.58578324e-01  1.44532180e-03
 -1.42914196e+00 -1.51400542e-03 -1.58578324e-01 -1.44532180e-03
 -8.74416140e-01 -1.16975431e-03 -1.94873364e-01 -3.57271151e-02
 -7.34087309e-03  2.41040613e-08 -1.83955792e-03 -1.08416522e-03
  3.53793405e-01  2.42140170e-01  2.94144748e-01  3.92050063e-01
 -6.99222054e-03  2.35514988e-08 -1.75274198e-03 -1.03555886e-03
 -8.12230831e-03 -1.70050926e-02 -1.54771129e-01 -5.69534749e-02
 -1.59719422e-06 -7.44504109e-06  2.62701735e-03  8.93558129e-02
 -5.10501665e-02 -2.58319443e-02 -2.47850316e-01 -5.26014385e-02
  1.15811786e-02  2.75580818e-02  2.01357052e-01  1.70886222e-02
 -5.69311607e-01 -8.21123734e-02 -5.86471886e-02 -8.03191825e-02
 -5.16226822e-02 -1.11225156e-02 -1.15037501e-01 -1.21251953e-02
  1.94895172e-01  7.46876457e-03 -4.41004390e-02  1.50587069e-03
  2.56208777e-02 -1.68961601e-02  9.15228325e-02 -1.67333712e-02
 -2.49883042e-01  2.23006242e-01  3.59694383e-01 -4.98408145e-01
  4.03962334e-01 -9.08891706e-01  4.15266504e-01 -6.02015149e-01
 -5.44700596e+00]
supnorm grad right now is: 5.447005957578476
Weights right now are: 
[ 3.41883107e-01  5.50322313e+00 -2.28169859e+00  6.19395503e+00
 -1.13210234e+00 -5.48875949e+00  2.85300463e+00 -4.77887198e+00
  2.88445524e-02  9.03105486e+00 -1.66096237e+00  6.91598499e+00
  1.18802966e+01  7.33934976e+00  1.32850323e+01  1.64184082e+01
  8.50855999e+00 -8.09888411e+00  5.84004354e+00 -1.10239997e+00
  1.20337861e+01  7.31088206e+00  1.31401159e+01  1.64051451e+01
 -1.33917576e+01 -6.09381984e+00  2.12022635e+00  5.86519869e+00
  4.30511445e+01  4.45738996e+01  3.74114683e+01  7.22987795e+00
 -1.65385964e+01 -5.11839005e+00  6.76132605e+00  6.56395050e+00
  8.46259950e+00  9.20762050e+00  5.03751153e+00 -1.03967408e+01
 -3.36441783e+00  1.19815325e+01  2.54402292e+01  1.46505737e+01
  1.66399161e+00  2.20108896e+01  3.69103447e+00  2.25133853e+01
 -3.16020456e+00  6.28800776e+00  4.52538862e-01  5.80293442e+00
  1.96190399e+01 -5.59142975e+00  5.77656920e+00 -4.61021841e+00
  4.67021409e+00  2.64160710e+00  3.22458104e+00 -3.54006241e+00
 -1.74218314e+00 -4.54730708e+00  3.25371305e+00 -3.37551560e+00
  2.91494665e+01]
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1199.9715942291432
W_T_median: 1085.2895445867503
W_T_pctile_5: 907.3739269447894
W_T_CVAR_5_pct: 864.7993256143939
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.7
F value: -1704.5838588222168
-----------------------------------------------
