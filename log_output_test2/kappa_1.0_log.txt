Starting at: 
2022-06-20 18:03:38
tracing parameter entered from terminal:  1.0


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[ 0.10347998  0.18844875 -0.3666709   0.62803316 -0.89369922 -0.17398511
  0.93797695  0.78704989 -0.60791207 -0.16293226 -0.31685198  0.28094308
  0.0404241   0.17453202  0.0940472   0.01169373  0.2300954  -0.23784803
  0.78511084 -0.41859022  0.4809118  -0.01155852  0.07219357 -0.14482284
  0.4701344  -0.18827011 -0.8138637  -0.24629474  0.28361272  0.33354483
 -0.63777411 -0.25343004 -0.81551088 -0.26234589  0.20198453 -0.15135741
  0.25264285 -0.29817275  0.41496663 -0.58895503 -0.60305385 -0.63454123
  0.3979274   0.74701442  0.57452389 -0.67377327  0.6493153   0.07340044
 -0.29694484  0.52758424 -0.14347696  0.04319718 -0.28527617 -0.63077443
  0.13133703 -0.58713125  0.12759166  0.87507529 -0.19770888 -0.66759109
  0.25529887 -0.48501395  0.58877641 -0.72315372] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1260.6521530687958
W_T_median: 1222.3920506735662
W_T_pctile_5: 834.1581876304141
W_T_CVAR_5_pct: 746.6575474940535
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2083.3592995794384
gradient value of function right now is: [ 2.92354841e+00  2.05926000e-01  7.95017319e-01  5.35209396e-01
 -2.92354841e+00 -2.05926000e-01 -7.95017319e-01 -5.35209396e-01
 -1.05888473e+00 -2.21755027e-01 -1.52279773e+00 -2.32768390e-01
  6.86065070e-03  4.44854437e-03  1.00980992e-02  4.50707258e-03
  9.16377468e-01  1.71721646e-01  1.35835409e+00  1.76356387e-01
  2.20161200e-01  6.08749765e-02  3.19424238e-01  5.91591790e-02
 -5.28760283e-01 -1.02425878e-01 -2.20950537e-01 -1.30094913e-01
  4.02139333e-01  5.74819324e-02  1.66294683e-01  7.88944925e-02
 -6.59171953e-01 -7.93108888e-02 -2.77257435e-01 -1.14718205e-01
  5.49011050e-01  8.10995262e-02  2.25264247e-01  1.10522636e-01
 -9.58902504e-01 -5.68221650e-02 -1.43837646e-01 -5.61897520e-02
  5.30771515e-01  1.24391939e-02  3.15441502e-02  1.00108743e-02
 -3.20642928e-01 -2.07459403e-02 -6.03044592e-02 -2.13796985e-02
  4.37440874e-01  1.64604592e-02  4.15037102e-02  1.51274463e-02
 -1.03077559e+00  3.00337387e+00 -1.99212465e-02 -2.18946990e-01
  1.81635308e-01 -8.63665931e-01 -3.10659479e-02 -3.26142163e-01
 -9.83077184e+00]
supnorm grad right now is: 9.830771838363132
Weights right now are: 
[ 0.16934135 -0.03363164 -1.68042428 -0.47883443 -0.95956059  0.04809528
  2.25173033  1.89391748  0.10284902  1.6978139  -0.36430153  2.23909303
  2.00279405  1.23349308  2.73326555  0.95901208  1.3081478  -1.35546817
  2.72907456 -1.71427544  2.48037057 -1.00660333  2.97273373 -1.32653636
 -1.13102551  2.84894913 -0.90437865  1.94334533  3.3661597  -2.08557506
  0.92008801 -1.5245566  -3.09833584  2.46008821 -0.24231198  1.69127028
  3.05166419 -2.31576023  1.64564378 -1.55788598 -2.57426292  1.62732376
  2.57826151  3.47491232  3.50050275 -2.41965166 -1.10501725 -2.00270042
  0.39482047  3.10990224  2.88634644  2.47736196  2.9987219  -1.88341877
 -0.65048009 -3.04001899  3.88479014  1.62219663 -1.03034236 -3.06262837
 -2.45649903 -2.35070497 -1.27775454 -3.07083787 25.8992829 ]
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2085.891261559929
gradient value of function right now is: [-0.49339477 -0.11464566 -0.81725643 -0.45729692  0.49339477  0.11464566
  0.81725643  0.45729692  0.19891916  0.18987427  0.50921606  0.20579117
 -0.01902598 -0.01687004 -0.03733677 -0.01882606 -0.82687455 -0.88289367
 -1.62186417 -0.96488647 -0.39062821 -0.49482855 -0.78691668 -0.54112399
  0.80329431  0.42579801  0.44307988  0.44526023 -0.74910035 -0.38858096
 -0.41831046 -0.40783756  1.266781    0.77639614  0.68316587  0.80075731
 -0.96732231 -0.50042786 -0.54317286 -0.52550383  1.44316817  0.07431626
  0.89009767  0.10426397 -1.09352048 -0.08437168 -0.7721241  -0.11225797
  0.3347929   0.00856197  0.18000865  0.01394638 -0.77917087 -0.05689551
 -0.52801596 -0.07585027  3.47749548 -7.02705552 -0.17001887  0.2435152
 -1.58096845  2.88491757 -0.34735202  0.512931    5.91245275]
supnorm grad right now is: 7.027055521657027
Weights right now are: 
[ 4.40484559e-01 -2.42550616e-01 -2.00650834e+00 -1.06150050e+00
 -1.23070380e+00  2.57014254e-01  2.57781438e+00  2.47658354e+00
  1.89515428e-01  3.11763850e+00 -3.58093085e-03  3.70056822e+00
  3.00987628e+00  6.39252920e-01  3.52059679e+00  3.70641166e-01
  1.68187613e+00 -1.31229819e+00  2.86285493e+00 -1.67648064e+00
  2.78001843e+00 -1.07424733e+00  3.23846001e+00 -1.34046841e+00
 -8.59174703e-01  3.11147155e+00 -7.44823776e-01  2.15644974e+00
  3.15430120e+00 -1.96863247e+00  8.74328979e-01 -1.43396628e+00
 -2.82696577e+00  2.04649517e+00 -7.79490593e-02  1.25672408e+00
  2.73213985e+00 -2.27266550e+00  1.51665762e+00 -1.53583823e+00
 -1.88851620e+00  1.45074881e+00  2.67864162e+00  3.21679511e+00
  3.60830777e+00 -1.39268407e+00 -1.55660974e-01 -8.56284333e-01
  3.80152516e-01  3.79251809e+00  4.05014185e+00  3.10204278e+00
  3.17746375e+00 -7.93997358e-01  2.74120242e-01 -1.84088712e+00
  4.12039465e+00  1.58384599e+00  5.74083013e-01 -3.47586239e+00
 -2.17045406e+00 -2.41684092e+00  2.29330644e-01 -3.31637298e+00
  2.64237052e+01]
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2087.51389154905
gradient value of function right now is: [ 0.40014409  0.09797313  0.64970572  0.31700579 -0.40014409 -0.09797313
 -0.64970572 -0.31700579 -0.32509877 -0.19955488 -0.57436083 -0.22928206
  0.01089858  0.06123116  0.02062015  0.06332272  0.79813801  0.6985248
  1.18898354  0.7589972   0.21144643  0.34380987  0.32469804  0.36156967
 -0.42508486 -0.18110132 -0.12250312 -0.1935611   0.42962006  0.13208223
  0.12304366  0.13723367 -0.50425024 -0.367582   -0.13331445 -0.39148173
  0.57322133  0.1731315   0.16392242  0.17966912 -1.5769938  -0.258056
 -1.05001523 -0.31863736  0.61099125  0.15980563  0.15447892  0.13651497
 -0.26153276 -0.03007292 -0.18058357 -0.03984317  0.37538699  0.11315971
  0.1221936   0.10081007 -1.81416302  2.8711504   0.05867928 -0.437967
  1.4730425  -2.15659732  0.25647931 -0.82162844 -8.9749858 ]
supnorm grad right now is: 8.974985796648422
Weights right now are: 
[ 5.25545958e-01 -4.86739938e-01 -1.79688473e+00 -1.23553313e+00
 -1.31576519e+00  5.01203576e-01  2.36819078e+00  2.65061618e+00
  5.33453867e-01  4.70925841e+00  3.82964839e-01  5.33043606e+00
  4.72186678e+00  3.98900070e-01  5.24355856e+00  2.96488996e-01
  2.53516630e+00 -7.13426963e-01  3.69722874e+00 -1.05639467e+00
  3.86584431e+00 -4.83037955e-01  4.35684446e+00 -6.84374994e-01
 -1.19768822e+00  2.62851851e+00 -1.02065679e+00  1.68661698e+00
  3.62619316e+00 -1.72309707e+00  1.40533668e+00 -1.18218660e+00
 -3.52828115e+00  1.56979126e+00 -7.57292860e-01  8.13355740e-01
  3.19079258e+00 -2.10765144e+00  2.04465792e+00 -1.35991002e+00
 -2.01055692e+00  2.26566852e+00  3.33140893e+00  4.05320415e+00
  4.35475901e+00 -1.48861977e+00  4.92711873e-01 -7.78049399e-01
 -1.71690783e-02  5.32391799e+00  5.30234754e+00  4.64200492e+00
  4.08354117e+00 -7.78653399e-01  9.85151422e-01 -1.66580462e+00
  4.06207177e+00  2.25270072e+00  8.30107217e-01 -3.54315224e+00
 -2.46104118e+00 -2.71867506e+00  3.46574268e-01 -3.33136106e+00
  2.67208071e+01]
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2091.89494705327
gradient value of function right now is: [-4.81944862e-01 -8.43284312e-02 -8.81993818e-01 -3.34585034e-01
  4.81944862e-01  8.43284312e-02  8.81993818e-01  3.34585034e-01
  7.73787834e-01 -5.99138518e-02  8.47315865e-01 -6.90089226e-02
 -7.04397460e-02 -1.29369934e-01 -7.91113074e-02 -1.38988906e-01
 -7.29476335e-01 -1.62403095e+00 -7.61438101e-01 -1.73280820e+00
 -4.58073465e-01 -8.67444224e-01 -5.06828352e-01 -9.29770692e-01
 -1.54504083e-01  5.48507177e-01 -9.19266863e-02  4.28277238e-01
  5.31441218e-02 -1.89058839e-01 -7.40539748e-03 -1.43377705e-01
 -1.20914440e-01  8.21500294e-01 -7.04426483e-02  6.43692367e-01
  7.72724669e-02 -2.35002401e-01 -3.22307453e-03 -1.78003929e-01
 -6.27825769e-01 -7.95882060e-03 -1.24986924e-01 -8.86097135e-03
 -3.30149214e-01 -3.66692045e-01 -2.22109785e+00 -5.37312993e-01
 -1.39955180e-01 -1.11738221e-02 -1.15638192e-01 -1.49265083e-02
 -1.92622467e-01 -2.19673566e-01 -1.24941096e+00 -3.16086833e-01
  5.85573000e-01  3.99523838e-01 -7.58480191e-01 -5.54738082e-02
  1.65239149e+00 -1.85563598e+00 -7.82233412e-01 -1.63629580e-01
  5.92874103e+00]
supnorm grad right now is: 5.928741033529659
Weights right now are: 
[ 0.75824056 -1.36412725 -2.19818801 -1.88644556 -1.5484598   1.37859089
  2.76949406  3.30152861  0.64235589  5.38882483  0.53461276  6.05075642
  5.05837464 -0.22741176  5.44418995 -0.31915973  2.06976058 -1.09690709
  3.50723352 -1.42417244  3.74399682 -0.7376395   4.29077333 -0.91915634
 -1.29504179  2.41377469 -1.82107581  1.66149524  3.9194715  -0.94847333
  1.94211163 -0.66347775 -3.54527072  1.87144039 -1.37829511  1.2970349
  3.43180639 -1.51679494  2.56661072 -0.98889289 -1.41869694  4.40306523
  4.23808976  6.17171906  4.1490885  -2.78675004  1.759037   -1.41106917
 -0.54688482  7.84604761  5.98091445  6.95963586  3.9143897  -2.17888103
  2.30249943 -2.37673294  3.42927718  2.43069267  2.22296753 -3.01990217
 -2.89718526 -2.84470762  1.518487   -2.83854182 27.24018257]
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2091.891840875336
gradient value of function right now is: [-1.57752109e+00  1.09963075e-01  2.41198560e+00  3.83454723e-01
  1.57752109e+00 -1.09963075e-01 -2.41198560e+00 -3.83454723e-01
  2.14846581e+00  1.06278932e-01  3.00206680e+00  1.17477064e-01
  8.68919057e-02  1.57496734e-01  9.41755277e-02  1.78126615e-01
  3.48909863e+00  4.47051530e+00  3.57812499e+00  4.68264165e+00
  6.27912618e-01  8.69347553e-01  6.58276505e-01  9.33177151e-01
 -2.44961668e-01 -6.52941211e-01 -1.18542103e-01 -4.78220195e-01
 -4.27114126e-01  2.25323070e-01 -2.77748625e-01  1.64491315e-01
 -1.05201378e-01 -1.03065631e+00 -1.92628160e-02 -7.59981453e-01
 -5.17857731e-01  2.99338522e-01 -3.38703306e-01  2.17386299e-01
  1.03763991e+00 -7.06613766e-02 -1.10575438e-01 -9.31125168e-02
  3.71095135e-01  4.51246047e-01  2.52800701e+00  6.03089880e-01
  8.23115411e-01 -6.08042579e-03  1.20869970e-01 -6.58494439e-03
  2.19155757e-01  2.70771368e-01  1.33249891e+00  3.50603666e-01
 -7.01454337e-01 -2.73221501e-01  7.36072314e-01  4.30123179e-03
 -1.19106676e+00  2.66002837e+00  7.39957965e-01 -4.05313441e-02
 -8.78765617e+00]
supnorm grad right now is: 8.787656165673587
Weights right now are: 
[ 0.81427314 -1.5164815  -2.03120801 -1.70212291 -1.60449238  1.53094514
  2.60251406  3.11720596  0.76417417  6.73428632  0.68474655  7.44288875
  5.80437589  0.06903379  6.12246948 -0.11702594  2.12093587 -0.97148452
  3.59466213 -1.28951876  4.1685174  -0.22318341  4.71118226 -0.42991279
 -0.59956374  2.13991421 -1.03801878  1.5356056   3.99345932 -0.33715909
  2.31459823 -0.257554   -3.56442766  1.6624951  -1.16838964  1.2389376
  3.45998921 -0.98236533  2.92746086 -0.63603152 -1.25423055  4.1997136
  4.62508246  5.98414546  4.66677895 -3.09705429  2.57489683 -1.45013567
 -0.56889978  8.13286473  6.9571364   7.34791528  4.52298817 -2.5164744
  3.1565575  -2.43823596  3.64304005  2.39319408  3.51233458 -3.3928482
 -4.2147099  -2.25309241  2.65931958 -3.1181327  26.93715259]
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2096.208500020476
gradient value of function right now is: [-0.78169505 -0.02631802 -1.40100395 -0.13209779  0.78169505  0.02631802
  1.40100395  0.13209779  1.06089882  0.02517735  1.53539541  0.02599809
 -0.04384064 -0.05493445 -0.04794343 -0.05860228 -2.42080823 -2.32634072
 -2.67127892 -2.43962737 -0.28080813 -0.31319392 -0.3072589  -0.33374722
  0.01973828  0.22316636 -0.03865764  0.13773538 -0.13523965 -0.10182781
 -0.0950796  -0.06179939  0.14248915  0.35624293  0.0216209   0.21932143
 -0.16208756 -0.13259242 -0.11096563 -0.08067217  0.77254618 -0.01487586
  0.80535048 -0.02044214 -0.15450613 -0.15586618 -1.17957119 -0.19570801
  0.32036761 -0.00995014  0.17365536 -0.01582719 -0.07937344 -0.08892989
 -0.58509085 -0.10928547  0.82148794 -0.70304903 -0.40029166 -0.27699368
 -1.26038597  2.29541997 -0.35988776 -0.28656696  6.60588994]
supnorm grad right now is: 6.60588993797263
Weights right now are: 
[ 9.84670405e-01 -2.08396562e+00 -2.30208264e+00 -1.95800545e+00
 -1.77488964e+00  2.09842925e+00  2.87338869e+00  3.37308850e+00
  7.72628177e-01  7.65833566e+00  6.90047391e-01  8.44105495e+00
  6.07241947e+00 -2.16371876e-02  6.43619216e+00 -3.38454118e-01
  1.87462545e+00 -1.25813338e+00  3.37106579e+00 -1.58660076e+00
  4.19617259e+00 -2.01870635e-01  4.77039057e+00 -4.43622705e-01
 -2.66600814e-01  2.70211660e+00 -1.19648718e+00  2.05480126e+00
  4.50912341e+00 -9.70998891e-02  3.89666548e+00 -4.87174010e-02
 -3.59016591e+00  2.20538497e+00 -8.19347214e-01  1.74865590e+00
  3.89583308e+00 -9.37584039e-01  4.46559970e+00 -6.09550870e-01
 -1.15348573e+00  4.18002204e+00  4.82996337e+00  6.04546965e+00
  5.63231294e+00 -3.72160878e+00  2.32841936e+00 -1.88438611e+00
 -1.47263205e+00  1.04153155e+01  7.52304805e+00  9.86530448e+00
  5.62622743e+00 -3.09335162e+00  3.00743212e+00 -2.82021898e+00
  3.77521925e+00  2.95337308e+00  3.67007772e+00 -3.72717081e+00
 -4.41840359e+00 -2.32824556e+00  2.94867833e+00 -3.00783478e+00
  2.72880290e+01]
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -2091.2922874311307
gradient value of function right now is: [ 1.93527022e+00 -6.24974022e-02 -3.09548152e+00 -1.90620053e-01
 -1.93527022e+00  6.24974022e-02  3.09548152e+00  1.90620053e-01
 -1.31029797e+00  1.61022504e-03 -4.51129891e+00  7.90752737e-05
 -1.39315389e-01 -1.86636793e-01 -1.48497092e-01 -2.20585555e-01
 -4.77093138e+00 -5.12165673e+00 -4.94447948e+00 -5.53187599e+00
 -4.13080794e-01 -4.99902536e-01 -4.11471686e-01 -5.62654276e-01
  2.78895120e-01  5.26330129e-01  9.69209300e-02  3.01859754e-01
 -6.99642510e-02 -2.37768570e-01  1.52082458e-02 -1.34187956e-01
  3.59325420e-01  8.43025166e-01  4.85872889e-02  4.81758866e-01
 -9.08247546e-02 -3.36005878e-01  2.04318787e-02 -1.90845172e-01
  7.72240665e-01  6.25086189e-02  1.36516400e+00  9.51364538e-02
 -3.97210899e-01 -4.33918966e-01 -2.81477121e+00 -5.58133221e-01
 -1.32046712e-01 -4.70644912e-03  4.60681696e-02 -6.35808238e-03
 -2.21677216e-01 -2.49128585e-01 -1.42237245e+00 -3.14084930e-01
  1.46042192e+00 -7.64446402e-01 -1.23220621e+00 -4.98860541e-01
 -5.15137710e-01  7.26710915e-01 -1.26648347e+00 -2.73910486e-01
  1.92219016e+01]
supnorm grad right now is: 19.221901606685268
Weights right now are: 
[ 1.36817888 -3.39025194 -2.19799873 -2.15111413 -2.15839811  3.40471558
  2.76930478  3.56619718  0.36550905  8.25255451  0.60842449  9.07533236
  6.65121404  0.26419684  6.94885461 -0.85368078  1.94534159 -1.30896303
  3.52181572 -1.65425317  4.50389751  0.22688286  5.08486381 -0.20941582
  0.84416352  2.90030164  0.17926897  2.35479633  4.94360891  0.64206692
  4.62561383  0.5834     -3.94946552  2.43216041 -0.66783122  2.11464109
  4.27331076 -0.62892893  5.14949065 -0.51485278 -1.23612955  6.02595414
  4.29484496  7.50189208  5.80710653 -3.92396746  2.68829515 -2.19088919
 -1.42525911 13.04881049  7.77577187 11.93120812  5.8301498  -3.25848702
  3.46626718 -3.06095878  3.59187628  3.15453203  3.90231668 -2.84518418
 -3.99725809 -2.86863828  3.15161582 -2.46334766 27.86061485]
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2092.4405235437275
gradient value of function right now is: [-2.17929991e+00  8.66379770e-03  1.72686330e+00  3.66371052e-02
  2.17929991e+00 -8.66379770e-03 -1.72686330e+00 -3.66371052e-02
  5.21266187e-01 -2.43208415e-02  3.81493249e+00 -3.27207394e-02
  1.17500614e-02  1.72892002e-02  5.27213003e-03  2.96927783e-02
  3.09277455e+00  3.09186746e+00  2.89777672e+00  3.35474655e+00
  1.27333345e-01  1.55874065e-01 -3.56602593e-03  1.79690415e-01
 -1.08298747e-01 -2.25108555e-01  1.02518101e-01 -1.06465299e-01
  2.04447179e-01  1.30940469e-01  1.56130494e-02  6.01395756e-02
 -2.92596452e-01 -3.94722686e-01 -1.28541160e-02 -1.86562199e-01
  2.89416757e-01  1.76456545e-01  2.48822406e-02  8.47862091e-02
 -1.34018542e+00 -1.33128302e-01 -1.60554209e+00 -1.72439714e-01
  1.21549266e-01  1.25242462e-01  1.25217307e+00  1.67576192e-01
 -2.67703283e-01 -1.14951681e-02 -1.07306841e-01 -1.48226623e-02
  5.40450078e-02  5.69195578e-02  5.16534626e-01  7.50416149e-02
 -9.08564491e-01  7.21429375e-01  5.73216329e-01 -1.27718021e-01
  1.09837633e+00 -1.52115977e+00  6.81836997e-01 -3.20857110e-01
 -6.54753492e+00]
supnorm grad right now is: 6.547534923834789
Weights right now are: 
[ 0.71164579 -3.40753191 -2.18155442 -2.11138009 -1.50186502  3.42199554
  2.75286047  3.52646314  0.49815275  9.52928106  1.37828412 10.45564826
  7.56068282  1.37536867  7.82915692 -0.18571874  1.97038371 -1.38058878
  3.65156223 -1.70357297  4.72461736  0.64347628  5.11858822  0.18308615
  0.78103038  2.81685197  1.3033531   2.27022955  4.7939547   0.99240854
  4.90430524  0.93522146 -5.80276621  2.3819768  -1.87127886  2.07741588
  4.03802782 -0.36323973  5.45751352 -0.36319105 -1.98030697  5.44604125
  3.84024752  6.88574724  5.61436927 -3.89826801  2.9963654  -2.0464399
 -1.54536512 14.02667336  8.34614049 12.56964748  5.84634888 -3.10875547
  3.88562626 -2.81898462  3.95941284  3.90967841  4.74846703 -2.60394338
 -3.8099952  -3.33795445  4.06420032 -2.42785734 27.35495025]
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2095.383124564855
gradient value of function right now is: [-2.35030284e-01  6.45045733e-03  6.64151008e-02  8.37620298e-03
  2.35030284e-01 -6.45045733e-03 -6.64151008e-02 -8.37620298e-03
 -2.17710743e-01 -4.42913992e-02  4.64833258e-01 -6.27947562e-02
  4.60963250e-03  1.07295118e-02  3.95789934e-03  2.54114859e-02
 -2.42743987e-03 -1.43618264e-01  1.64259348e-01 -7.65143273e-02
  1.12651276e-02  1.48469055e-02 -3.56774830e-03  2.82230763e-02
 -7.86123733e-02 -5.07467030e-02  2.21292130e-02 -2.52985092e-02
  2.44073193e-01  2.65071008e-02  7.46334698e-02  1.11093419e-02
 -4.89786649e-02 -8.41344541e-02 -9.63272223e-03 -4.11088539e-02
  3.79408355e-01  5.33416310e-02  1.17225104e-01  2.68457745e-02
 -1.28776252e+00 -5.77663304e-02 -1.99164325e-01 -7.02825492e-02
 -5.97925111e-02  6.73852849e-02  2.72366745e-01  1.20058203e-01
 -8.29351671e-01 -3.19608597e-02 -2.34008006e-01 -3.88040512e-02
 -2.77722606e-02  3.81205783e-02  1.39562856e-01  6.39772692e-02
 -3.10144613e-01  7.13369265e-01  4.10180211e-01 -1.89444644e-01
  1.45580460e+00 -2.88515899e+00  4.07494774e-01 -4.84809579e-01
 -5.32751441e+00]
supnorm grad right now is: 5.3275144061950614
Weights right now are: 
[ 1.1482659  -4.29975616 -2.32943218 -1.93761763 -1.93848514  4.3142198
  2.90073822  3.35270068  0.07792737 10.26252311  1.26834298 11.24285927
  8.27495106  2.10833448  8.4670184  -0.43290137  1.59794301 -1.71176418
  3.47524484 -2.02513268  5.05246292  1.09597909  5.5830307   0.52964649
  1.25093885  2.87246053  1.66149456  2.34443701  4.74243768  1.22332183
  6.03277871  1.23575038 -5.92439546  2.4570482  -1.8860923   2.1884924
  3.8821903  -0.26211995  6.54890252 -0.36703482 -1.76027551  5.41238676
  4.14202429  7.11352923  4.59218496 -4.09762145  3.35014154 -2.06178645
 -1.88940492 15.64428991  9.12359916 13.74630165  5.02975428 -3.24979904
  4.31632453 -2.75458258  4.572274    3.56365737  5.05203147 -2.02625724
 -4.45137566 -3.2346922   4.01281885 -2.06080242 27.1032229 ]
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2088.140963800651
gradient value of function right now is: [-9.02232344e-01 -1.29183754e-03 -3.84591318e+00 -1.82832744e-02
  9.02232344e-01  1.29183754e-03  3.84591318e+00  1.82832744e-02
  1.03516006e-01 -8.37753546e-03  2.56426184e+00 -1.37787552e-02
 -4.56813783e-03 -5.72672193e-03 -6.89356752e-03 -7.32035844e-03
 -5.27038167e+00 -5.10339265e+00 -7.03415102e+00 -5.47668381e+00
 -2.41311415e-02 -2.39985930e-02 -5.31503368e-02 -2.75800863e-02
  2.02007664e-01  1.37408832e-01  6.27985126e-02  5.64874840e-02
 -1.81639132e-01 -1.98911374e-01 -1.85370861e-04 -8.08193385e-02
  3.94235558e-01  3.48615938e-01  6.67076379e-03  1.42054876e-01
 -1.83765308e-01 -2.36615354e-01  5.45106626e-03 -9.63648376e-02
  1.60640400e+00  2.48593996e-01  2.55684919e+00  3.29546268e-01
 -1.47356378e-01 -1.27910743e-01 -9.21499691e-01 -2.10733224e-01
 -1.76447581e-01  2.41248490e-02 -1.06191511e-01  2.13476089e-02
 -5.63654698e-02 -5.27058702e-02 -3.21704671e-01 -8.38667744e-02
  7.70921650e-01 -3.98025782e-01 -5.39994416e-01  7.65569563e-01
  8.65256715e-02 -4.34849696e-01 -9.90299145e-01  9.89499938e-01
  1.94287395e+01]
supnorm grad right now is: 19.42873953721175
Weights right now are: 
[ 1.38300234 -5.4773781  -2.41274943 -1.58935885 -2.17322158  5.49184174
  2.98405548  3.0044419  -0.132668   11.08818234  1.46122306 12.07713809
  9.45555344  2.89624256  9.69131814 -1.06747258  1.31866067 -2.00401151
  3.45090025 -2.30350634  5.41402375  1.60518197  6.40614284  0.87688505
  2.12887568  3.05940012  2.43333005  2.53305542  4.78556734  1.47116594
  6.68983504  1.76939314 -6.4125368   2.66812373 -1.98861167  2.39582337
  3.81657271 -0.24521836  7.20830463 -0.37005817 -1.54840654  6.84929759
  3.45304715  8.62137864  5.68938255 -3.92841172  3.3503514  -1.85931009
 -2.19999    15.47857257 10.11998372 13.48297346  6.10323482 -3.15026426
  4.40831056 -2.54341639  3.41392615  4.56053621  5.03832631 -1.96524859
 -4.1203161  -3.26324816  3.65620621 -2.08657306 27.81055026]
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2091.6756497482916
gradient value of function right now is: [-2.42226998e-01  4.36875381e-04  8.88497087e-01  1.37925811e-02
  2.42226998e-01 -4.36875381e-04 -8.88497087e-01 -1.37925811e-02
  8.27888478e-02 -1.69543519e-04  7.72070233e-01  1.67658431e-03
  3.65710791e-02  3.49242664e-03  5.62916923e-02 -1.06099958e-02
  1.65900468e+00  1.53428383e+00  2.46411495e+00  1.64744485e+00
  4.56475110e-02  3.45320677e-02  6.55582583e-02  3.31790887e-02
 -2.08737217e-01  1.58972371e-02  1.12713741e-02  9.64566043e-03
  9.56554536e-02  9.86898841e-03 -2.41958243e-03  3.99200139e-03
 -3.66093073e-01  1.65849426e-02 -5.90034942e-03  1.13981417e-02
  1.37132046e-01 -7.21916485e-03 -7.05328622e-03 -4.93612612e-03
 -1.82408383e+00 -1.10454905e-01 -1.87912397e+00 -1.55853991e-01
  1.61689656e-01  1.38029357e-02 -1.45751556e-01 -1.22394880e-03
 -2.02305329e-02 -1.69271062e-02  2.95267499e-02 -1.71420631e-02
  6.14657550e-02  4.79309291e-03 -1.09594094e-01 -4.24116565e-03
 -4.02299973e-01  6.27475737e-01  1.82552325e-01 -6.31381749e-01
  9.42771038e-02  7.27877488e-02  3.49859768e-01 -8.77472227e-01
 -3.41525028e+00]
supnorm grad right now is: 3.4152502750681943
Weights right now are: 
[ 1.54329550e+00 -6.86459707e+00 -2.08117070e+00 -2.36798607e+00
 -2.33351473e+00  6.87906071e+00  2.65247675e+00  3.78306911e+00
  1.32459506e-02  1.14881908e+01  1.51374741e+00  1.25770685e+01
  7.16116284e+00  7.14670020e-01  7.57398950e+00 -2.89107571e+00
  2.14709356e+00 -1.30047074e+00  4.15872837e+00 -1.79124013e+00
  4.78786267e+00  4.26997185e-01  6.68587713e+00 -4.83903593e-01
  2.91242049e+00  4.73640385e+00  1.79864241e+00  4.27818572e+00
  4.71229415e+00  2.83006838e-01  7.25929526e+00  4.31293366e-01
 -6.58338934e+00  4.22251854e+00 -2.06217521e+00  4.04951559e+00
  3.55296478e+00 -1.69860318e+00  7.80876911e+00 -1.96053289e+00
 -1.33885612e+00  6.68815810e+00  3.03766666e+00  8.47139926e+00
  6.73633756e+00 -4.65504265e+00  1.26882751e+00 -2.93666011e+00
 -2.18307603e+00  1.61138102e+01  1.10947595e+01  1.39237015e+01
  7.16160471e+00 -3.88261455e+00  2.09227321e+00 -3.65855999e+00
  3.67483036e+00  5.09759543e+00  3.95468045e+00 -2.65619600e+00
 -5.52973417e+00 -2.47070162e+00  2.45026576e+00 -2.81881864e+00
  2.68819711e+01]
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2090.4223068530873
gradient value of function right now is: [-0.82259131 -0.01174784 -0.03985187 -0.01131629  0.82259131  0.01174784
  0.03985187  0.01131629  0.17771873  0.0027817   2.00222788  0.00329372
 -0.02558149 -0.05306076 -0.05147739 -0.07101715  0.2933786   0.23627272
 -0.02904429  0.23859825 -0.0073188  -0.01376954 -0.03823404 -0.0189061
  0.05565094  0.0506782   0.13533336  0.02275444  0.03095642 -0.0077909
 -0.01982475 -0.00353932 -0.13438589  0.08141027 -0.01487466  0.03643868
  0.04758463 -0.03528716 -0.0272428  -0.01586765 -0.74935377 -0.01423941
 -0.46986763 -0.02424485 -0.10041348 -0.0396711  -0.45759746 -0.05978901
  0.08574785  0.01732235 -0.04238268  0.00889744 -0.05019796 -0.01862679
 -0.21155905 -0.02797379  0.40301893 -0.12679789  0.01141599  0.29649901
  0.84193527 -1.26995676  0.05433829  0.01747242 -0.066498  ]
supnorm grad right now is: 2.0022278821514052
Weights right now are: 
[ 9.82185115e-01 -6.49122592e+00 -2.21157046e+00 -2.23591749e+00
 -1.77240435e+00  6.50568956e+00  2.78287651e+00  3.65100053e+00
 -6.21111750e-01  1.23031215e+01  2.27731508e+00  1.32702107e+01
  7.59295763e+00  1.24554747e+00  7.79421781e+00 -2.34993348e+00
  1.96554218e+00 -1.42158077e+00  3.83066611e+00 -1.92106163e+00
  5.18898010e+00  8.94647179e-01  6.82375993e+00 -1.74712723e-02
  3.22926574e+00  4.98434970e+00  1.41116948e+00  4.39447066e+00
  4.69296980e+00  4.55266561e-01  7.83772525e+00  6.87271033e-01
 -6.18246486e+00  4.40526436e+00 -1.37707627e+00  4.11174085e+00
  3.58600415e+00 -1.54276661e+00  8.45235532e+00 -1.69270177e+00
 -9.48648147e-01  8.03063976e+00  3.54566318e+00  9.39101001e+00
  7.14695229e+00 -4.00633449e+00  5.36146378e-01 -2.49960240e+00
 -1.93930654e+00  1.86140810e+01  1.10269290e+01  1.58121444e+01
  7.78178964e+00 -3.25732203e+00  1.50311646e+00 -3.21783326e+00
  5.04751389e+00  4.27151712e+00  3.92756347e+00 -1.49512320e+00
 -4.90383582e+00 -3.12495717e+00  2.24879317e+00 -2.08379001e+00
  2.65909460e+01]
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2093.7069745064914
gradient value of function right now is: [-9.22033137e-01 -4.73672849e-03 -2.57142314e+00 -1.53415496e-02
  9.22033137e-01  4.73672849e-03  2.57142314e+00  1.53415496e-02
  1.62059064e-01  5.99600442e-03  2.95350846e+00  1.05502369e-02
 -2.30956396e-02 -5.20615868e-02 -2.89656493e-02 -3.91239675e-02
 -1.45234169e+00 -2.07338683e+00 -2.19194926e+00 -2.45325833e+00
 -7.73134614e-03 -1.42588314e-02 -1.38538722e-02 -1.43080731e-02
  2.27751107e-01  3.08428963e-01  1.01366421e-01  8.78128205e-02
 -8.79401520e-02 -3.07292356e-01 -1.34778838e-02 -9.40853052e-02
  7.27523765e-02  7.27803757e-01 -1.46819333e-02  2.03131266e-01
 -1.41217437e-01 -4.20899848e-01 -2.60614447e-02 -1.14048949e-01
  6.29843761e-02 -2.39942588e-02  8.84032852e-01 -1.70526038e-02
 -2.23662097e-01 -1.10530780e-01 -3.13853242e+00 -2.16657101e-01
  1.30832115e-01 -3.01789324e-03  4.79305625e-02 -2.75236019e-03
 -5.33997636e-02 -3.74274926e-02 -8.00910854e-01 -7.34446677e-02
  1.26050594e+00 -1.24494404e+00 -2.96058573e-01 -2.27283676e-01
 -4.52963278e-01  9.96639291e-01 -3.61263560e-01 -2.06089973e-01
  6.77624154e+00]
supnorm grad right now is: 6.776241539751774
Weights right now are: 
[ 1.41369516 -4.75902692 -1.80897215 -0.41004357 -2.2039144   4.77349056
  2.3802782   1.82512662 -1.39197408 12.44214282  2.14597297 13.30605257
  9.08429131  3.34086975  9.30595137 -0.51669338  1.61139297 -1.76785122
  4.10005659 -2.20045518  5.96485007  2.45292421  7.79859631  1.54949981
  3.55478092  3.92970467  1.10688149  3.15925601  5.31749927  0.27519962
  8.37204616  1.83044144 -6.21773647  3.8494089  -0.84321302  3.33923878
  4.21640492 -0.77051756  8.86940134 -0.9454173  -1.7610066   7.37105012
  4.14824007  8.96028296  6.88527985 -4.24293914  1.34489073 -1.70177805
 -1.60312433 17.96133119 11.97384596 15.55553546  7.67023725 -3.50405469
  2.85321242 -2.31935506  6.24330391  3.56623436  4.77144237 -2.37630296
 -5.72155182 -2.77235866  3.45378461 -2.43037887 27.06588629]
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -2090.6928146018868
gradient value of function right now is: [ 1.13254945e+00 -2.53163304e-03 -3.14307854e+00 -3.25315607e-03
 -1.13254945e+00  2.53163304e-03  3.14307854e+00  3.25315607e-03
 -1.98611564e-01 -2.87041049e-02 -4.74751476e+00 -4.64000876e-02
 -8.02606132e-03 -3.09522813e-02 -6.20343080e-03 -2.58069302e-02
 -2.19070242e+00 -2.59631245e+00 -2.04262151e+00 -2.89297861e+00
 -2.23135963e-03 -5.81551040e-03  8.43452092e-04 -6.09275062e-03
 -2.43966433e-01  1.79648189e-01 -3.02599326e-01  2.44334738e-02
  5.31486253e-02 -3.10153060e-01  1.68713905e-02 -4.76516948e-02
  2.39300672e-01  5.65827079e-01  1.29401146e-02  7.65968738e-02
  1.53233352e-01 -4.17723443e-01  2.91219465e-02 -5.51986238e-02
  4.76476873e-02  4.41470578e-02  1.57965528e+00  7.81004773e-02
 -3.81215827e-01 -1.24266940e-01 -2.31703107e+00 -2.24391046e-01
 -4.55823641e-01 -2.32011212e-02 -9.30579154e-02 -2.57971357e-02
 -3.19578810e-02 -1.45845709e-02 -2.45549396e-01 -3.09113323e-02
  1.34498612e+00 -1.48594699e+00 -3.67128219e-01 -3.98995444e-01
  5.59499040e-02 -1.16129866e+00 -6.41485442e-01 -2.30629637e-01
  9.20030577e+00]
supnorm grad right now is: 9.200305765767778
Weights right now are: 
[ 2.0877573  -5.47970081 -1.93902039 -0.5717804  -2.87797654  5.49416445
  2.51032643  1.98686345 -2.31585915 12.52195256  1.63771941 13.27387839
 10.51178117  4.60423784 10.62695282 -0.34039649  1.08444249 -2.18989103
  3.88818692 -2.55821688  6.7088504   3.57182489  8.41329346  2.19648351
  2.61588051  3.94478952  1.20583766  2.8645215   5.9362389   0.30157945
  8.82668052  2.65886395 -6.30630444  4.11653002 -0.27628162  3.37475827
  4.87944601 -0.68508658  9.46737803 -0.98648328 -1.70027931  8.10816406
  3.83323131  9.64348141  6.09750067 -4.91100169  1.5386396  -2.86191247
 -1.18296717 19.24404461 12.10995776 16.85845998  7.42280195 -3.29142961
  3.6101896  -2.12655244  6.11890625  3.95956321  4.14674939 -2.12028343
 -5.77925137 -2.92318875  2.85007361 -2.21538408 26.99993468]
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2098.747051528991
gradient value of function right now is: [ 2.74544793e-01  6.35196284e-02  1.68377566e+00  1.46282518e-02
 -2.74544793e-01 -6.35196284e-02 -1.68377566e+00 -1.46282518e-02
 -2.06133712e-01 -6.74305624e-02 -1.24748822e+00 -1.00515610e-01
  1.55733491e-02  1.19062378e-01  7.97141411e-03  3.83700633e-01
  8.15744772e-01  8.28387547e-01  1.10028715e+00  9.56747854e-01
  9.43818673e-04  5.39115619e-03  1.51680796e-03  1.51738793e-02
 -5.03277416e-02 -1.76645422e-01  3.91381932e-02 -4.85191134e-02
  3.44249496e-01 -3.09270086e-01  1.94830809e-02 -1.41087034e-01
 -3.51393701e-02 -1.61543714e-01  1.69851676e-04 -3.30519583e-02
  5.37047127e-01  1.61123138e-01  3.18070333e-02  3.91308426e-02
 -2.97109941e+00 -7.02371612e-02 -1.08435314e+00 -1.64550363e-01
  7.96315092e-02  1.39156331e-01  5.28472156e-01  2.19416754e-01
 -1.11362647e+00 -3.13694113e-02 -1.68243286e-01 -6.91904539e-02
  1.17479182e-02  2.22177312e-01  4.48123967e-01  2.78466649e-01
 -3.67372165e-01  5.49395051e-01  6.63844544e-01 -8.74832366e-01
  2.04400931e+00 -5.40047748e+00  1.07375556e+00 -3.06613296e+00
 -1.05927590e+01]
supnorm grad right now is: 10.592759022425136
Weights right now are: 
[ 1.91103433 -5.70576534 -1.23169804 -0.08788023 -2.70125356  5.72022897
  1.80300409  1.50296328 -4.06349984 12.05318548  2.20697274 12.79772288
 12.20700831  6.09659363 12.07445547 -0.158055    1.46163454 -1.91847545
  4.16020231 -2.32123817  7.60652021  4.96567891  8.32036266  2.9402318
  1.46640986  3.44428347  2.14507365  2.58618599  6.72798459  0.08579163
 10.80546842  3.27131894 -5.86600512  4.1940328   0.13803396  3.59240256
  5.63167755 -0.40828877 11.55266887 -1.14864159 -1.42244762  8.12032404
  3.97331382  9.98350295  7.92392607 -3.93302542  1.4487611  -1.84516274
 -1.01885966 19.85803838 12.5581884  18.06140125  8.41183763 -3.51501398
  3.90139206 -1.82424393  5.85424153  4.53554358  4.28614036 -1.82537472
 -5.50081731 -2.8933316   2.53964624 -1.5517209  26.85971021]
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2096.979996161344
gradient value of function right now is: [-9.03081809e-01  1.15301962e-02  7.32789690e+00 -8.35668878e-01
  9.03081809e-01 -1.15301962e-02 -7.32789690e+00  8.35668878e-01
  4.93284957e-01 -8.07315960e-02  3.06923217e+00 -1.21778110e-01
  2.04325676e-02  4.48529280e-02  1.65341813e-02  8.83705017e-02
  4.89477122e+00  5.46002234e+00  5.04032880e+00  6.67110997e+00
 -1.89976408e+00  1.95440480e-01 -8.28632867e+00  2.55700001e-01
  1.08181571e+01 -1.09680874e+00  3.39540284e+00 -2.16335444e-01
  3.12793075e-01  5.50076611e-01  1.21087946e-05  9.78066677e-02
 -3.64561944e-01 -1.98219302e+00 -3.23029852e-02 -3.80617397e-01
  5.44803854e-01  9.38601148e-01 -4.19047153e-03  1.82350074e-01
 -2.71892695e+00 -2.83477402e-01 -4.20421706e+00 -4.15373765e-01
  3.97377093e-01  7.53835546e-01  9.15329465e+00  1.13564926e+00
 -1.38829524e+01 -2.88108338e-01 -1.69995526e+00 -4.07707871e-01
  6.80853976e-02  1.90736857e-01  1.81110815e+00  2.76334302e-01
 -1.56896738e+00  1.56605754e+00  3.88509843e+00 -1.06781043e+01
  2.98439095e+00 -3.90598361e+01  4.49182025e+00 -1.42618830e+01
 -1.98661608e+01]
supnorm grad right now is: 39.05983611308861
Weights right now are: 
[ 1.53680339e+00 -6.94631635e+00 -1.10211364e+00 -5.03100570e+00
 -2.32702263e+00  6.96077999e+00  1.67341968e+00  6.44608874e+00
 -6.06137487e+00  1.05333992e+01  3.12526432e+00  1.16213075e+01
  1.27425888e+01  6.12883654e+00  1.29487898e+01 -9.37607074e-01
  2.19797216e+00 -1.49665241e+00  4.63031114e+00 -1.91746952e+00
  7.03608010e+00  5.96485511e+00  4.32608790e-02  3.49412235e+00
  2.47853089e-02  3.50673395e+00  5.23715146e+00  3.01503593e+00
  7.73414900e+00  7.07270437e-01  1.34523488e+01  4.46158911e+00
 -5.89344339e+00  3.96521751e+00 -4.93448239e-01  3.71612064e+00
  6.34336183e+00 -2.75656776e-01  1.45360257e+01 -1.67989344e+00
 -1.70018270e+00  7.86672848e+00  2.91251553e+00  9.21727871e+00
  6.60848247e+00 -4.72661538e+00  2.09993797e+00 -2.63176568e+00
 -1.70522132e+00  2.24663824e+01  1.64383383e+01  2.05461240e+01
  7.90821989e+00 -4.77547356e+00  3.94553059e+00 -2.74677590e+00
  6.85155883e+00  4.15348608e+00  3.53627658e+00 -2.26477434e+00
 -6.24232654e+00 -1.75420031e+00  2.77462982e+00 -2.07191078e+00
  2.72607435e+01]
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2116.0037888819725
gradient value of function right now is: [ 2.56148438e+00 -3.72907279e-02 -3.67286348e+00  4.53497435e-01
 -2.56148438e+00  3.72907279e-02  3.67286348e+00 -4.53497435e-01
 -1.72591793e+00  8.56544114e-02 -5.06063246e+00  1.10561267e-01
 -2.80638777e-02 -1.43029055e-01 -1.40146260e-02 -2.78995925e-01
 -1.29860354e+00 -1.75177665e+00 -1.18066220e+00 -2.07206056e+00
  1.21370860e+00 -4.81126574e-02  5.03572602e+00 -7.08914890e-02
 -1.17811102e+01  6.00563510e-01 -3.89716339e+00  9.68373357e-02
 -1.89609597e-01  1.66209414e-01  1.80290536e-03  7.14370634e-02
  2.42467719e-01  7.36594607e-01  5.35272874e-02  9.94790657e-02
 -2.30569094e-01 -4.97892468e-01  5.36043062e-03 -7.12830274e-02
 -2.30687751e-01 -4.86702304e-02  2.02345141e+00 -1.36033364e-02
 -6.95987733e-02 -2.23105162e-01 -3.52940044e+00 -4.68272408e-01
  1.54246858e+01  1.85257238e-01  1.44124317e+00  2.54392288e-01
 -2.03306592e-02 -1.85149790e-01 -9.95639328e-01 -3.09732182e-01
  1.76429700e+00 -3.66924298e+00 -2.25694252e+00  9.26399524e+00
 -9.64846422e+00  5.49727917e+01 -2.80659341e+00  1.24459770e+01
  4.30462711e+00]
supnorm grad right now is: 54.97279165042564
Weights right now are: 
[ 1.33411145 -6.91319984 -0.87224607 -5.61685242 -2.12433069  6.92766348
  1.44355211  7.03193547 -5.99257011 10.42469356  2.84781768 11.58873543
 13.80160996  7.03883593 14.02184538 -0.7621057   2.17336557 -1.54591378
  4.63479049 -1.98738297  9.55908706  6.41013313  0.08252012  4.05987045
 -0.7694556   3.53333172  5.69514379  2.94381057  7.80165792  0.2272906
 15.04319277  4.3811831  -5.61431058  4.50556091  1.12063829  4.35346653
  6.28288234 -0.03640201 16.40516715 -1.67139384 -1.85506848  7.64457017
  4.08077314  8.8752446   7.54976503 -4.79889083  1.59387971 -2.75972358
 -1.3010867  25.46057503 17.1679753  23.45351994  9.61941032 -4.58411206
  3.93427298 -2.49883309  7.82347768  3.21163778  2.61681056 -1.79803969
 -6.01871285 -1.90285728  1.53236539 -1.74839325 27.01456689]
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2100.583666643767
gradient value of function right now is: [-5.86026792e+00  7.37365986e-03  5.56957241e+00 -2.08524519e-01
  5.86026792e+00 -7.37365986e-03 -5.56957241e+00  2.08524519e-01
  2.32561288e+00  4.56851820e-02  4.50519508e+00  1.01420142e-01
  1.64812180e-02  4.49861215e-02  9.38614234e-03  4.81017236e-02
  2.12230084e+00  3.15287131e+00  1.78243894e+00  3.37887539e+00
 -9.75432517e-01  5.67767263e-02 -2.80555985e+00  5.90563528e-02
  8.83570344e+00 -9.93880339e-01  1.48339467e+00 -1.59258607e-01
 -1.47711054e-01  3.41556121e-01 -9.34092788e-04  5.60766992e-02
 -2.63564877e-01 -1.37171405e+00 -1.01210989e-02 -2.08789562e-01
 -4.32961398e-01  6.22526105e-01 -4.33080434e-03  9.77189852e-02
  2.77237677e+00  2.07313501e-02  6.49100377e-01  1.88318608e-02
  4.15543516e-01  8.03964530e-01  6.44416490e+00  1.30706799e+00
 -7.23546366e+00 -1.89979232e-01 -6.27630745e-01 -2.29298003e-01
  6.68447594e-02  1.62447169e-01  1.19573324e+00  2.65521014e-01
 -1.47242628e+00  7.38818692e-01  2.76441377e+00 -7.31863695e+00
 -5.10738397e-01 -1.10517204e+01  2.79869783e+00 -7.83588508e+00
 -8.11336270e+00]
supnorm grad right now is: 11.051720374242223
Weights right now are: 
[ 0.24242873 -7.18471243 -0.79550565 -5.81072065 -1.03264797  7.19917607
  1.36681169  7.2258037  -5.41649221  9.41315004  3.22222155 10.90485278
 14.80030337  7.87839589 15.37488652 -0.47339719  2.71967489 -1.26403508
  5.36351269 -1.58704241 10.27616377  6.76531541  0.12473238  4.33781337
 -0.59198642  3.58801263  6.12918068  3.34246111  8.19474839  0.29144857
 16.69702191  4.79535857 -6.05952694  4.68115198  1.81370584  4.71724103
  6.27849243  0.64742459 18.34720805 -0.70554407 -2.07307891  7.27088918
  3.59044792  8.28926881  8.94537161 -4.52138383  1.62669026 -2.60895198
 -1.44895722 26.26150972 17.63027156 24.25363874 10.82387176 -5.04279312
  3.9243963  -2.95637438  6.46977129  4.28791158  2.44000569 -2.23397205
 -6.46704136 -1.8301153   1.53877476 -2.15708373 27.69426701]
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2119.2783081069765
gradient value of function right now is: [-7.52219975e-01 -8.81950217e-03 -2.00344751e+00  2.78593877e-02
  7.52219975e-01  8.81950217e-03  2.00344751e+00 -2.78593877e-02
  1.65415934e-01 -6.58505587e-02  6.00714833e-01 -1.35084239e-01
 -2.66376308e-03 -3.41197788e-02 -3.77750177e-04 -2.51640895e-02
 -5.89385477e-01 -9.36089887e-01 -4.58473077e-01 -7.98110801e-01
 -3.70469281e-02 -1.96227829e-02  2.09972352e-01 -1.35525068e-02
  1.68324550e+00  1.77377283e-01  3.51237570e-01  1.73346852e-02
  2.03611658e-01 -1.24781236e-02 -4.72271863e-06  4.35965385e-02
  1.11720113e-01  2.91811178e-01 -9.86358761e-03  1.36281849e-02
  5.08305261e-01 -2.10525090e-01 -1.32501404e-03 -8.31553766e-03
 -1.83683103e+00 -1.75847603e-01 -4.45540756e-01 -1.84964463e-01
 -4.51584049e-01 -1.95798626e-01 -9.43048363e-01 -2.23920950e-01
 -1.92771644e+00 -7.29589617e-03 -3.73251856e-01 -2.42254507e-02
 -4.59422615e-02 -1.01947997e-01 -1.98455507e-01 -1.06479770e-01
  1.83265126e-01  6.92105390e-01  5.53325643e-01 -1.58893962e-01
  4.13658705e+00 -1.52907284e+01  8.35762425e-01 -1.41799153e+00
 -1.95376792e+00]
supnorm grad right now is: 15.290728428430878
Weights right now are: 
[ 0.93656768 -6.60420086 -1.08694609 -5.91190854 -1.72678691  6.6186645
  1.65825214  7.32699159 -5.68863717  9.36853759  2.92631448 10.98334206
 16.24340112  9.03355234 17.02785852  0.36867369  1.68286612 -2.14394741
  4.50004405 -2.24475169 11.30861905  7.99280258  0.24778016  5.54322177
 -1.08330585  3.529126    6.28883326  3.35380189  8.231052   -0.24097588
 18.82591672  4.90068781 -6.13803255  5.60279765  2.92035592  5.35945312
  6.17736163  1.21867187 20.87345317  0.75469092 -2.15524619  6.38446138
  4.5438186   7.37009823  6.30761268 -6.21562712  1.18769465 -3.71138029
 -1.32575864 28.34789634 17.21687498 26.23014596 10.85427948 -5.50519111
  4.08475893 -3.38793617  7.13133243  3.32099062  1.96181721 -1.69046902
 -5.6485924  -2.60855074  1.42586168 -1.70255413 27.46471234]
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2115.9510837277503
gradient value of function right now is: [ 1.68594722e-01 -1.87382569e-02  3.80055207e-01  2.13026744e-01
 -1.68594722e-01  1.87382569e-02 -3.80055207e-01 -2.13026744e-01
 -5.88188389e-01 -3.93189169e-02 -2.12688464e+00 -9.62558114e-02
 -1.45300686e-02 -4.44627724e-02 -6.25144743e-03 -3.36908064e-02
  4.26161101e-01  3.24209110e-01  5.29125928e-01  3.34938076e-01
  4.85588759e-01 -4.97528264e-02  2.80834450e+00 -3.67778456e-02
 -6.18207512e+00  2.02412195e-01 -2.63654772e+00  7.06058448e-02
  1.45830396e-01  2.80135714e-01 -2.46263440e-04  8.38262150e-02
  9.05697110e-02  2.11875821e-02  1.20926500e-02  1.80250475e-02
  3.53826424e-01  6.14573361e-02 -1.98307660e-03  1.34067575e-02
 -3.10769920e+00 -2.62271846e-01 -1.18234611e+00 -2.78838018e-01
  3.42876326e-02 -1.19267085e-01 -5.32965576e-01 -1.42592730e-01
  1.05548042e+01  1.62874473e-01  4.62294160e-01  1.74663774e-01
 -8.33107478e-02 -1.74241246e-01 -7.36983544e-01 -2.04059196e-01
  4.35325137e-01  1.61849720e-01 -1.53681311e+00  9.00275997e+00
 -1.87307189e+00  1.50689364e+01 -1.23346998e+00  8.53460551e+00
  1.99347747e+00]
supnorm grad right now is: 15.068936406928168
Weights right now are: 
[ 0.62807484 -7.2958193  -0.76811732 -6.39850016 -1.41829408  7.31028294
  1.33942336  7.81358321 -5.37738661  8.82904909  3.04831218 10.67031685
 15.74516591  8.4037149  17.26972666  0.08138276  1.63775451 -2.01191872
  4.44185934 -2.1596598  12.37379227  7.38434552  0.25314574  5.29772065
 -1.33648886  3.70723961  6.45757872  4.75877582  8.6437015   0.90855116
 20.10677327  5.90370477 -6.48682219  5.14752429  3.20619113  5.58651357
  6.19888229  2.76176077 22.5735092   2.07699396 -2.46449844  7.15747677
  3.74370093  7.9503249   6.99893693 -5.91454748  1.38496293 -3.4959137
 -1.10707897 29.3796208  17.90786179 27.23806184 12.46926521 -6.04285822
  2.77092139 -4.10695136  5.9246251   4.3423747   0.91800676 -1.77755813
 -6.0196495  -2.17830217  0.58505898 -1.77817738 27.33340821]
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2092.2351720711285
gradient value of function right now is: [ 9.47594771e-01 -3.75115462e-03 -1.06980683e-01 -2.65971451e-01
 -9.47594771e-01  3.75115462e-03  1.06980683e-01  2.65971451e-01
 -1.20219473e+00 -1.06651605e-01 -7.87037408e-01 -2.66424963e-01
 -3.32403308e-03 -1.02587415e-02 -1.60457244e-03 -7.44863986e-03
  1.93048045e-01 -1.01828868e-02  2.62284472e-01  4.38892873e-02
 -1.08734172e+00 -1.19295959e-02 -3.91208683e+00 -1.35625559e-03
  7.38137450e+00  4.80029742e-02  2.57828703e+00  9.97420626e-03
  3.56614943e-01  4.95114029e-02  2.46752608e-03  1.13334582e-02
  5.68104688e-02  3.16315672e-02 -2.15183021e-02  2.40706853e-03
  1.07898126e+00  1.45561248e-02  9.45663909e-03  1.67135022e-03
 -2.90902190e+00 -3.89759126e-01 -1.14248286e+00 -4.18664362e-01
 -1.68014512e-01 -9.22838210e-02 -1.05816565e-01 -9.44899315e-02
 -1.52885239e+01 -7.32883456e-01 -4.04494568e-01 -7.31312352e-01
 -4.53836496e-02 -3.56752942e-02 -8.16345352e-02 -3.76830615e-02
 -1.13846570e+00  3.07439686e+00  5.13638998e+00 -3.63560576e+01
  4.56550226e+00 -1.68361800e+01  5.21150361e+00 -3.46131359e+01
 -7.77267386e+00]
supnorm grad right now is: 36.35605760859498
Weights right now are: 
[ 1.13691639 -7.82093984 -0.97987417 -7.84020177 -1.92713563  7.83540348
  1.55118021  9.25528482 -5.75042963  9.402602    2.76073149 11.2478908
 15.4202907   8.10728811 17.24394295 -0.19721694  1.33005033 -2.24788691
  4.07992746 -2.38598611 11.76455345  7.10527922 -0.96536397  5.01879942
 -0.95563749  4.24422235  7.55854128  5.66861671  8.37710615  1.39128917
 21.40681611  6.71658458 -6.69386286  5.78882285  3.08886932  6.2940041
  5.68307979  2.98479448 23.97798373  2.73368854 -2.04331671  7.09156724
  4.85299436  7.84158379  6.88113663 -6.25849317  0.58177748 -3.92895893
 -1.85871878 30.33395121 17.35750312 28.16796623 12.23910557 -6.79190265
  1.85957174 -4.92080592  6.66985176  3.69112139  0.18869451 -1.84103464
 -5.17208733 -3.06106723 -0.08569799 -1.87944624 27.62727192]
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2110.471218884131
gradient value of function right now is: [ 1.43732496e+00 -2.87845494e-03  1.38981984e+00 -1.26217295e-01
 -1.43732496e+00  2.87845494e-03 -1.38981984e+00  1.26217295e-01
 -1.47108969e+00 -1.24117926e-01 -1.22120088e+00 -3.23310084e-01
 -4.28333111e-05 -1.41499695e-03  5.75568440e-04 -9.23416229e-04
  6.36346217e-01  5.33678181e-01  6.41841593e-01  5.24734755e-01
 -3.27798061e-01  1.10948702e-02 -1.70438701e+00  1.00156100e-02
  2.98788102e+00 -9.06687209e-02  1.73705531e+00 -2.03414932e-02
  2.93683698e-01  1.14852710e-01  8.48803734e-04  3.63720720e-02
  6.54602806e-02 -1.20157101e-01 -8.93074655e-03 -2.76090399e-02
  1.18907851e+00  1.15349840e-01  5.71794746e-03  3.10480474e-02
 -3.79589599e+00 -5.16169547e-01 -1.35514087e+00 -5.61479426e-01
  1.12215677e-01  3.30133997e-02  2.00699235e-01  4.12411581e-02
 -8.70835167e+00 -2.71446645e-01 -2.55607666e-01 -2.65754918e-01
 -1.62972758e-02 -3.75106299e-02 -3.86149331e-04 -3.82675121e-02
 -1.74816692e+00  4.17620140e+00  3.51096540e+00 -1.86576792e+01
  4.45864885e+00 -1.52863858e+01  3.68500461e+00 -1.81197239e+01
 -1.55839342e+01]
supnorm grad right now is: 18.65767922062745
Weights right now are: 
[ 1.12960237e+00 -7.34878217e+00 -6.27526578e-01 -7.11434382e+00
 -1.91982161e+00  7.36324581e+00  1.19883262e+00  8.52942687e+00
 -5.62878709e+00  8.50628152e+00  2.82642345e+00  1.09440504e+01
  1.60807864e+01  8.78393201e+00  1.79829414e+01  6.23729496e-01
  1.53910401e+00 -2.05771032e+00  4.34923657e+00 -2.21598514e+00
  1.28749900e+01  7.96507641e+00 -2.12705283e-01  6.11192114e+00
 -1.46019001e+00  3.49885157e+00  7.34510051e+00  5.68236958e+00
  8.54775236e+00  1.39623681e+00  2.12786950e+01  6.78589571e+00
 -7.11006672e+00  5.32678545e+00  3.25172614e+00  6.52279377e+00
  5.19638717e+00  3.86401601e+00  2.46092281e+01  3.24804763e+00
 -2.17774688e+00  6.67904740e+00  5.02487518e+00  7.29093632e+00
  8.26211736e+00 -5.40910212e+00  4.96726060e-01 -3.23099825e+00
 -1.45050260e+00  3.14375208e+01  1.78506298e+01  2.90840052e+01
  1.30715989e+01 -6.67801593e+00  1.27633129e+00 -5.02227112e+00
  7.07008399e+00  3.50181473e+00  1.90347663e-02 -1.82109662e+00
 -5.31682854e+00 -2.84908537e+00 -5.77328495e-01 -1.93013577e+00
  2.71951687e+01]
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2117.7109544041273
gradient value of function right now is: [-1.95841489e+00 -4.53720611e-04  8.93674783e-01 -1.97036957e-02
  1.95841489e+00  4.53720611e-04 -8.93674783e-01  1.97036957e-02
  1.53485649e+00 -1.75016757e-02  3.45597500e+00 -9.35393678e-02
  7.69555904e-04  1.16570188e-03  2.93117056e-04  5.37609329e-04
  4.52917126e-01  4.10452931e-01  4.33906283e-01  4.37046200e-01
 -1.56862037e-01  3.41342280e-03 -3.87531143e-01  2.31531868e-03
  5.00685661e+00 -2.84550821e-02  1.41176559e+00 -8.39390727e-03
  6.88354597e-02  5.07693456e-02 -7.95754881e-05  1.83445363e-02
 -4.00592779e-02 -3.91551402e-02 -4.34148434e-03 -8.70446054e-03
  4.73395063e-01  4.81197163e-02 -3.96955837e-03  1.57922705e-02
 -2.52875271e-01 -1.21538668e-01 -4.91748243e-01 -1.49510432e-01
  4.18357928e-02  2.81893508e-02  1.01366332e-01  4.03808450e-02
 -7.78145340e+00 -1.72523107e-01 -3.55069030e-01 -2.26473357e-01
  2.68983563e-03 -2.86689134e-03 -1.04487874e-02 -5.29254891e-03
 -2.11348132e-01  3.66483992e-01  9.86857256e-01 -9.85381803e+00
  2.45389124e+00 -1.40457634e+01  1.36115769e+00 -1.22291948e+01
 -1.26942724e+01]
supnorm grad right now is: 14.045763373387475
Weights right now are: 
[ 0.96310605 -5.96118637 -0.92367045 -6.36847866 -1.75332528  5.97565001
  1.4949765   7.78356171 -5.0925802   8.73138124  3.29580743 11.78794465
 17.16303039  9.93813332 19.08961416  2.0861652   1.2576066  -2.90318411
  4.45597318 -2.82625683 13.69259504  8.62135943  0.21209324  6.99948136
 -1.63593665  2.96334033  7.31448273  5.0758515   8.74099723  0.44636397
 22.60267353  5.68152466 -8.77675589  5.69418082  3.83819927  6.4933737
  3.96374817  3.10647458 27.08639483  1.77985377 -2.11973797  6.23836439
  5.33834643  6.60181472  9.06852381 -4.34131974  0.96517224 -2.36402775
 -1.19480746 32.09506673 18.71144289 29.93405179 14.60963842 -5.45512964
  2.06445109 -3.98360582  6.05760385  4.35934315  0.14846056 -2.10390306
 -5.68711815 -2.38240527 -0.85251292 -2.04185238 26.81188386]
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2121.6996427504027
gradient value of function right now is: [-2.81150823e+00  5.42790667e-03  2.58526021e+00 -5.91391283e-02
  2.81150823e+00 -5.42790667e-03 -2.58526021e+00  5.91391283e-02
  2.48016601e+00  4.85325970e-03  4.43452098e+00  1.03937006e-01
  1.18117129e-03  1.07211589e-02  3.25051630e-05  4.83950761e-03
  2.52413671e+00  2.69359519e+00  2.40828564e+00  2.53983986e+00
 -2.32387827e-01  1.84755416e-02 -9.47280877e-01  8.01839862e-03
  5.84893519e+00 -1.57954531e-01  1.38741353e+00 -3.61126143e-02
 -2.09824449e-02  6.95295552e-02 -3.44657872e-04 -2.92004946e-02
 -6.92459374e-02 -1.96167175e-01 -1.99959459e-03 -1.51029359e-02
 -5.75921992e-01  1.11386628e-01 -1.33873502e-02  6.90202396e-03
  2.60088636e+00 -9.24166592e-04  1.39565014e-02 -7.61943648e-03
  2.96667080e-01  2.80869005e-01  1.01688576e+00  4.33887326e-01
 -7.85265228e+00 -2.04925821e-01 -3.16398593e-01 -2.41761230e-01
  1.58210686e-02  1.01076865e-01  2.42066953e-01  1.49164307e-01
 -1.12859100e+00  6.64545132e-01  1.25899062e+00 -1.00108975e+01
 -2.62913619e-02 -7.68534524e+00  1.20176644e+00 -1.08850998e+01
 -1.12185740e+01]
supnorm grad right now is: 11.21857395039733
Weights right now are: 
[ 9.16924350e-01 -5.59009518e+00 -1.30064937e+00 -7.31819545e+00
 -1.70714359e+00  5.60455882e+00  1.87195542e+00  8.73327850e+00
 -5.12853390e+00  9.38622286e+00  3.10450797e+00  1.22112969e+01
  1.84107656e+01  1.14554148e+01  1.94488773e+01  3.02677376e+00
  2.14126754e+00 -2.36818399e+00  5.56894658e+00 -2.11036023e+00
  1.38490357e+01  9.46676098e+00 -5.36707047e-01  7.64058341e+00
 -1.66067153e+00  2.39415846e+00  7.89625945e+00  4.64454878e+00
  8.78341124e+00 -1.00317039e+00  2.31183648e+01  4.70217360e+00
 -9.59575112e+00  5.95839368e+00  3.95363009e+00  8.23594111e+00
  3.51161417e+00  2.20889914e+00  2.82044103e+01  1.14730255e+00
 -2.08623635e+00  8.26727069e+00  4.61482831e+00  7.88689288e+00
  9.53087142e+00 -4.10158490e+00  1.87056392e+00 -1.78807669e+00
 -1.37598786e+00  3.26470873e+01  1.94872803e+01  3.05268113e+01
  1.54837076e+01 -4.18426120e+00  3.79598917e+00 -2.27939620e+00
  4.64342599e+00  5.22881815e+00  1.26311040e+00 -2.12006634e+00
 -5.75038783e+00 -2.25252839e+00 -1.53864353e-02 -2.09616870e+00
  2.74997594e+01]
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2117.211906426232
gradient value of function right now is: [ 9.78739290e-01  3.13387875e-02  1.36314480e-01 -5.44707226e-02
 -9.78739290e-01 -3.13387875e-02 -1.36314480e-01  5.44707226e-02
 -1.59418639e+00 -6.85852336e-02 -1.55155370e+00 -3.88247030e-01
  2.43782334e-03  6.29038274e-02  2.79451802e-07  1.84684899e-02
 -2.30300945e-01 -1.09346484e-01 -2.53342411e-02 -1.95986244e-01
 -1.99447805e-01  1.26321812e-01 -1.24996295e+00  3.53010141e-02
  1.74439378e+00 -8.09818242e-02  1.30395981e+00 -6.34020495e-02
  9.62513377e-02 -8.58882027e-01  2.86838145e-04 -4.04973175e-01
  3.01431100e-02  1.04572816e-01 -4.88135509e-04  2.28950969e-04
  2.02508031e+00 -1.31968523e-01  1.46486955e-02 -5.29367153e-02
 -3.00872304e+00 -2.21213847e-01 -9.62276971e-01 -2.35183538e-01
 -3.80151760e-01 -1.14214606e-01 -4.09947127e-01 -1.33905944e-01
 -7.06113577e+00 -1.26401353e-01 -4.44268342e-01 -1.39101426e-01
  1.99414531e-02  5.96261653e-01  1.01587923e+00  7.60375743e-01
 -7.96899870e-01  2.53648428e+00  2.30461839e+00 -7.91018499e+00
  5.27121350e+00 -2.07838051e+01  2.01122835e+00 -8.72932347e+00
 -1.00355719e+01]
supnorm grad right now is: 20.78380507064344
Weights right now are: 
[  1.42446947  -5.23805498  -1.02136357  -6.94239815  -2.2146887
   5.25251862   1.59266962   8.3574812   -5.57919331   9.1799858
   3.01578278  12.10234015  18.51448486  12.33216603  18.98918364
   3.81321038   1.80078187  -2.55000188   5.46653006  -2.42881724
  13.87022107  10.16085677  -0.11056697   8.30922674  -1.74855501
   2.39888974   8.08609118   4.85492467   9.63581716  -1.20347518
  23.8530706    4.87132901 -10.13424486   8.57953168   3.94186013
   9.78632808   3.39735276   1.9886677   28.9587965    1.31536297
  -2.45602074   7.96975313   4.50694587   7.05411965   6.05945589
  -5.75047718  -0.55978404  -3.27297443  -1.45598009  33.74782917
  19.1678113   31.46542358  15.12905902  -4.62660271   4.07163262
  -2.47149459   6.73627321   3.20069748   1.62878323  -1.8876865
  -5.51042497  -2.63284485   0.63495953  -2.01893392  27.43752261]
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2120.8155479002785
gradient value of function right now is: [-2.28052524e+00 -8.80471346e-03 -1.63147084e+00  1.05841010e-01
  2.28052524e+00  8.80471346e-03  1.63147084e+00 -1.05841010e-01
  3.18968839e+00  1.63954848e-02  3.02631300e+00  3.72070399e-01
 -1.17167528e-03 -1.27769149e-02 -1.32216136e-06 -1.08939776e-03
 -4.45665545e-01 -6.89532768e-01 -8.70231770e-02 -2.53151470e-01
  2.24527008e-01 -1.69376098e-02  1.62509731e+00 -1.72635804e-03
 -1.75141747e+00  2.35954394e-01 -1.85829999e+00  2.71173294e-02
 -4.28296449e-02  4.12422563e-02 -1.24628585e-04  1.32026010e-01
 -9.60627408e-03  1.62253028e-01  2.17756964e-04  2.01901354e-03
 -2.57860551e+00 -1.71601484e-01 -3.61402845e-02  3.97468807e-03
  3.52899667e+00  2.03745114e-01  1.08479515e+00  3.04566178e-01
 -1.15297311e-01 -6.91945294e-02 -6.38673895e-01 -1.34550669e-01
  1.00742021e+01  1.72355413e-01  3.24991800e-01  2.34292623e-01
  1.33388877e-03 -2.25134578e-01 -5.26278491e-01 -3.33859819e-01
  6.74584740e-01 -8.15530911e-01 -2.16457849e+00  1.29355850e+01
 -2.67627468e+00  1.48366123e+01 -2.54376511e+00  1.68052083e+01
  6.68924219e+00]
supnorm grad right now is: 16.805208334630418
Weights right now are: 
[  1.07461599  -5.94312109  -0.86764537  -7.35263386  -1.86483523
   5.95758473   1.43895142   8.76771691  -5.23911972  10.51754367
   3.74688834  12.39185184  18.53726994  12.21843699  19.01847976
   3.70951292   1.78589226  -2.0534618    4.9383787   -2.31670752
  15.21795522   9.80664938   0.26892956   8.19561259  -1.9929797
   1.96702004   7.97140338   5.45408721  10.7395355   -0.63643593
  24.01558567   5.47936881 -11.27915304   7.18158262   3.96582535
   9.79428617   3.32021758   3.78251847  30.55583265   1.69691859
  -2.40711548   9.13141135   3.75087605   7.94877427   7.57800238
  -4.81791756   0.48371952  -2.50415456  -1.17900255  34.36856711
  19.72411894  32.19272371  15.62321542  -5.13608791   4.34679482
  -2.70537214   5.4934128    4.27026459   2.06014079  -1.8747921
  -5.67843483  -2.48013476   0.83077775  -1.83190395  27.70473812]
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2112.823035998074
gradient value of function right now is: [-3.31818770e-01 -2.48849828e-03 -1.08142660e+00 -9.60672531e-02
  3.31818770e-01  2.48849828e-03  1.08142660e+00  9.60672531e-02
  1.30663659e-01  3.75941417e-03  8.49362690e-01 -6.12681436e-02
 -1.02984303e-03 -8.88110380e-03 -3.53333236e-05 -1.61154178e-03
 -7.56742636e-01 -8.45715744e-01 -7.35639767e-01 -7.33013869e-01
 -3.00391520e-01 -2.57052415e-02 -1.48840092e+00 -4.69772372e-03
  3.52417435e+00  8.60521670e-02  1.51678361e+00  8.48893207e-03
 -3.60719328e-03  2.05296756e-02  5.80474324e-04  1.63361791e-02
  4.55257192e-03  5.70000916e-02 -2.77783757e-03  5.45705028e-04
  5.08117157e-01 -4.53807133e-02  3.04192958e-02  8.88160882e-04
  1.38526299e+00  2.21914082e-01 -3.38096195e-01  1.78704171e-01
 -1.86486145e-01 -1.01418296e-01 -1.86850461e-01 -1.27603836e-01
 -9.95817404e+00 -2.62894965e-01 -3.37551537e-01 -3.68422048e-01
 -2.33878051e-02 -4.96890826e-02 -1.12769002e-01 -6.82172514e-02
  1.03579651e-01  3.52173960e-02  2.87333582e+00 -1.40671312e+01
  4.38840931e+00 -1.35215108e+01  4.56571477e+00 -1.98067784e+01
 -3.09423772e+00]
supnorm grad right now is: 19.806778392017605
Weights right now are: 
[  1.5454951   -6.53987105  -1.47455522  -8.54523698  -2.33571434
   6.55433468   2.04586126   9.96032003  -5.77357707  11.98050721
   3.20982322  13.23078326  17.26356634  11.42656236  18.87338082
   3.6927976    1.46209607  -2.43243003   4.41708714  -2.613354
  14.35958828   8.80072065  -0.53953181   7.66465524  -2.02677034
   3.24550565   8.56629943   6.6122601   10.18987016   0.03895604
  25.96452396   6.03280976 -10.14097555   7.27062431   5.11518107
  11.26383359   2.48553978   3.51618769  33.49704904   1.33416266
  -1.73322834   9.1851307    5.70316147   8.34860714   7.93597982
  -4.65917468   0.39186948  -2.60073565  -1.64882393  35.18087797
  19.11800123  32.71374236  16.20967672  -5.67528759   3.34349231
  -3.50612114   5.22000321   4.42537672   0.88192553  -1.8437867
  -5.3192185   -3.07806363  -0.59063736  -1.94046652  27.43525585]
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -2115.64373868047
gradient value of function right now is: [-1.54176146e+00  4.84481242e-03  6.76997308e-01 -1.96802503e-01
  1.54176146e+00 -4.84481242e-03 -6.76997308e-01  1.96802503e-01
  1.73835713e+00 -6.18288395e-03  4.28768803e+00 -3.28781576e-02
  5.33806147e-04  8.62553125e-03  2.11000776e-06  1.37976337e-03
  4.57569603e-01  5.41501167e-01  4.20637828e-01  4.95660556e-01
 -3.87521653e-01  4.34106689e-02 -2.93172127e+00  5.35516325e-03
  8.97753028e+00 -4.46469070e-02  3.53048945e+00 -1.57906811e-02
  1.33273624e-02 -7.90972320e-02  3.94081400e-05 -2.83867136e-02
 -3.19152692e-02  1.38055311e-02 -1.50711120e-03 -1.03194027e-05
  3.12723417e-01 -3.04862095e-02  1.48517585e-02 -6.14284635e-03
  2.42964925e+00  6.69398203e-02 -3.06493737e-01  5.90309873e-02
 -3.00347575e-02 -4.96156137e-02  3.38377900e-02 -3.88416855e-02
 -1.94519527e+01 -4.16597332e-01 -7.03338165e-01 -5.18896264e-01
 -4.97299319e-03  4.53673187e-02  1.58311318e-01  1.09550568e-01
 -2.58080738e-01  3.58143189e-01  2.79939242e+00 -2.20888359e+01
  5.01971522e+00 -2.27702676e+01  3.71426642e+00 -2.62078764e+01
 -4.73115848e+00]
supnorm grad right now is: 26.207876415409853
Weights right now are: 
[  1.40329926  -4.78300607  -1.29410223  -7.16521845  -2.19351849
   4.79746971   1.86540827   8.5803015   -5.54081581  11.71643291
   3.7425209   12.88242174  18.20375766  12.49644459  19.68501203
   5.3095788    1.59503113  -2.18587013   4.5691005   -2.49774049
  15.36478434   9.149772     0.49845345   8.83827303  -2.13911858
   2.50385835   8.44883525   6.15900987  11.75497552  -0.65783524
  26.31394599   4.96027532 -10.67086951   7.49565558   5.06613523
  11.11107711   2.37483332   3.48527812  34.32217925  -0.11370877
  -2.15183047   6.82583733   6.31345047   6.35796614   7.9092235
  -4.39373249   0.42281597  -2.440009    -1.56500879  35.67941515
  18.94262669  33.09964296  17.63161214  -4.79648085   4.36707482
  -2.56598356   4.59056308   4.55372092   1.47730872  -2.14078452
  -5.88235032  -2.95259059  -0.28611151  -2.22193138  27.8858922 ]
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -2122.176578472506
gradient value of function right now is: [-1.98556691e-02  1.48201401e-02  4.86485512e+00 -2.99757708e-03
  1.98556691e-02 -1.48201401e-02 -4.86485512e+00  2.99757708e-03
 -2.91484781e-01 -1.91737467e-02  5.25134511e-01 -2.40666680e-01
  5.28588175e-04  3.64338258e-02  5.24778993e-06  1.30511411e-03
  2.55915816e+00  3.48159705e+00  2.44014644e+00  2.36599798e+00
 -1.18782744e-01  2.34602378e-01 -7.16647244e-01  7.11166883e-03
  3.07740888e+00 -2.88043540e-01  1.32477240e+00 -2.72156573e-02
  4.41494185e-02 -5.07234826e-01  9.09473249e-06 -3.82223524e-01
 -7.18230764e-02 -1.82955661e-01 -1.53341051e-03 -6.66524432e-04
  1.52444755e+00  8.72125631e-02  1.04239592e-02 -1.42426588e-02
 -2.04161203e+00 -2.11398748e-01 -1.15991557e+00 -3.73311072e-01
  4.33802044e-01  1.64948002e-01  1.01168633e+00  4.23593237e-01
 -8.05189668e+00 -1.66326441e-01 -2.81345873e-01 -2.33414861e-01
  8.15587952e-03  6.50073352e-01  1.01778333e+00  8.95270547e-01
 -1.20918612e+00  8.97204650e-01  1.98382327e+00 -9.90585547e+00
  1.54137088e+00 -1.16693518e+01  2.20184216e+00 -1.42716482e+01
 -1.91754271e+01]
supnorm grad right now is: 19.175427097849806
Weights right now are: 
[ 1.24931700e+00 -5.06075838e+00 -1.11768809e+00 -7.99332953e+00
 -2.03953624e+00  5.07522201e+00  1.68899414e+00  9.40841258e+00
 -5.85600298e+00  1.22298421e+01  3.42829187e+00  1.19008582e+01
  1.83095947e+01  1.26370763e+01  1.97848728e+01  5.02355767e+00
  2.05137801e+00 -1.94412088e+00  4.73302866e+00 -1.97700570e+00
  1.49426922e+01  8.76853377e+00 -8.22284516e-03  8.38080433e+00
 -2.27907010e+00  3.03534510e+00  8.61739353e+00  6.54704202e+00
  1.19311272e+01 -1.06419010e+00  2.66513318e+01  4.41618908e+00
 -9.79435923e+00  6.84981301e+00  6.51962478e+00  1.26718869e+01
  2.41409652e+00  4.64803886e+00  3.36777655e+01  9.97924678e-02
 -2.71417363e+00  7.87027322e+00  5.68141900e+00  6.60762507e+00
  8.07172767e+00 -4.69838119e+00  7.61266464e-01 -2.41775147e+00
 -1.43636950e+00  3.61209179e+01  1.97131768e+01  3.38448087e+01
  1.70659404e+01 -4.66937130e+00  5.00932010e+00 -1.96282543e+00
  4.12454291e+00  5.27332071e+00  2.25004859e+00 -2.09499199e+00
 -6.26786535e+00 -2.50157193e+00 -2.65024789e-01 -2.09431396e+00
  2.72793650e+01]
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2125.7144361617716
gradient value of function right now is: [-2.86395115e-02  3.94329353e-03  3.15730460e+00 -1.78323107e-02
  2.86395115e-02 -3.94329353e-03 -3.15730460e+00  1.78323107e-02
 -9.37654398e-02 -1.31852695e-02  3.03607140e-01 -1.00570355e-01
  2.35588974e-03  1.79936109e-02  5.67749526e-05  5.95683238e-04
  1.90952105e+00  2.45896529e+00  1.58106496e+00  1.65041704e+00
 -6.26760571e-02  1.21793156e-01 -5.68149771e-01  4.23295646e-03
  1.84299025e+00 -4.60322115e-01  7.65545916e-01 -4.94643557e-02
  1.15046021e-03 -1.30957128e-01  6.66417794e-05 -5.82423797e-02
 -1.32090658e-02 -2.36377157e-01 -4.31390082e-03 -2.39234391e-03
  6.91484221e-01  1.08517378e-01  9.86956819e-03 -8.82721347e-04
 -3.54648910e-01 -3.47910910e-02 -2.01948736e-01 -4.62351999e-02
  4.15750698e-01  2.51123106e-01  1.14926175e+00  5.51938771e-01
 -5.01321752e+00 -1.22003874e-01 -2.09278062e-01 -1.52323614e-01
  1.59952534e-02  9.75402146e-02  6.10523195e-01  3.81326078e-01
 -1.31870569e+00  8.21170623e-01  1.71232158e+00 -7.48217605e+00
  1.60370899e+00 -8.45989198e+00  1.96332550e+00 -8.95671634e+00
 -1.06116466e+01]
supnorm grad right now is: 10.611646632278388
Weights right now are: 
[ 1.37794723e+00 -5.95517027e+00 -9.99038611e-01 -8.66522433e+00
 -2.16816646e+00  5.96963391e+00  1.57034466e+00  1.00803074e+01
 -6.07302995e+00  1.33025656e+01  3.59288726e+00  1.12596928e+01
  1.83514108e+01  1.21448879e+01  2.06469350e+01  4.81755584e+00
  2.03072552e+00 -1.54324909e+00  4.49301481e+00 -1.91597283e+00
  1.53238670e+01  8.59197729e+00 -3.38797568e-02  8.28227036e+00
 -2.22297518e+00  2.60217681e+00  9.02050899e+00  7.23841827e+00
  1.09391935e+01 -2.88345999e-01  2.67619842e+01  5.39401789e+00
 -7.99994774e+00  6.60295085e+00  6.52925433e+00  1.33531901e+01
  2.80976870e+00  5.72024199e+00  3.41368370e+01  7.39470674e-01
 -2.50024086e+00  1.12306699e+01  5.88259452e+00  9.08125586e+00
  8.15907137e+00 -4.20274002e+00  8.08138763e-01 -2.10719619e+00
 -1.62212114e+00  3.66683932e+01  1.98332020e+01  3.42813366e+01
  1.81021360e+01 -5.61175988e+00  4.18317733e+00 -2.91751224e+00
  4.23490672e+00  4.61190364e+00  1.58001908e+00 -1.98170876e+00
 -6.10334041e+00 -2.69696872e+00 -6.29349396e-01 -2.09627454e+00
  2.76043836e+01]
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2103.5569774676073
gradient value of function right now is: [-1.20901238e+00  5.82764027e-03  3.39401906e+00 -1.65764686e-01
  1.20901238e+00 -5.82764027e-03 -3.39401906e+00  1.65764686e-01
  1.19301787e+00 -1.26248494e-02  2.29732551e+00  9.89796177e-02
  2.81771416e-03  2.13884941e-02  1.51509254e-05  5.67438397e-04
  1.68543920e+00  2.39748043e+00  1.13949309e+00  1.33240169e+00
 -3.49789737e-01  1.25347909e-01 -2.96341165e+00  3.51654377e-03
  6.65075351e+00 -7.39886877e-01  2.55526395e+00 -2.47385612e-02
  1.05718090e-02 -1.48680810e-01 -6.53189343e-06 -5.19836165e-02
 -5.78212502e-02 -2.50986399e-01 -1.65930787e-03 -9.27503299e-05
 -6.15375566e-01  1.29361935e-01 -7.17208614e-03 -1.33483149e-03
  1.56868274e+00 -2.43940887e-02 -1.97296546e-01 -4.77066119e-02
  9.74477302e-01  2.43519117e-01  1.51665202e+00  4.17850192e-01
 -1.39323936e+01 -2.15030481e-01 -7.22200200e-01 -2.26793972e-01
  3.74552820e-02  1.17456244e-01  4.05893505e-01  2.13207896e-01
 -1.86619515e+00  1.87993425e+00  1.70905935e+00 -1.37897681e+01
  1.47341058e+00 -2.21221014e+01  1.81408850e+00 -1.37674237e+01
 -1.74467962e+01]
supnorm grad right now is: 22.122101387938653
Weights right now are: 
[ 0.84490625 -5.91908912 -1.0054453  -7.78402644 -1.63512549  5.93355276
  1.57675135  9.19910949 -5.71715098 13.53884328  4.12132465 11.82459449
 18.61733755 12.27146147 21.2644384   5.05878627  2.17479934 -1.22241278
  5.01712142 -1.62378647 15.77432247  8.71436837  0.87274087  8.62189747
 -2.14911628  2.55201068  9.09397739  7.42061895 12.15679134  0.09142141
 28.01321611  5.77256169 -9.29865078  8.30079085  5.98762682 13.91005509
  1.93977632  5.0053233  34.09333436  0.84683356 -2.69580745 11.14426941
  5.21067635  8.74462131  6.66542852 -6.39191142 -0.26749571 -3.58426238
 -1.66315393 37.17797868 20.02172651 34.67796771 18.91612391 -5.89321846
  3.8847952  -3.2935134   4.61152711  4.40272543  1.15820539 -2.3375436
 -6.93780951 -2.12833323 -0.45220224 -2.40427129 26.77973688]
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2112.2332535340156
gradient value of function right now is: [-4.41392290e+00  2.56745405e-03  5.35166928e+00 -1.50957237e-03
  4.41392290e+00 -2.56745405e-03 -5.35166928e+00  1.50957237e-03
  2.89316507e+00 -2.01645602e-02  4.12295275e+00  4.28750006e-02
  1.70313300e-03  1.09674511e-02  5.61780678e-06  8.33856329e-05
  1.80497948e+00  3.86509914e+00  6.44575684e-01  7.41975432e-01
 -5.20790905e-02  1.13800017e-01 -3.33681660e-01  9.84978964e-04
  4.96161251e+00 -1.82920399e+00  1.14532859e+00 -9.01600545e-02
  8.12373867e-03  3.82514634e-01 -1.02339939e-06 -2.85825566e-02
 -6.63266662e-02 -3.59471877e-01 -1.23956739e-02 -8.88721003e-04
 -4.74774307e-01  8.43087619e-02 -9.59266434e-03  3.93407404e-05
  6.08804797e-01 -4.48160968e-02 -9.62637115e-02 -5.88415058e-02
  9.11468900e-01  4.43227240e-01  2.40124300e+00  7.31627585e-01
 -7.03434232e+00 -1.20559989e-01 -3.20334282e-01 -1.59355741e-01
  1.75968395e-02  1.64767166e-01  7.16206149e-01  3.42922443e-01
 -2.38978884e+00  1.79834730e+00  2.09579635e+00 -7.78687111e+00
  1.19546897e+00 -1.01101772e+01  2.05816753e+00 -9.42809243e+00
 -1.66398791e+01]
supnorm grad right now is: 16.639879082243148
Weights right now are: 
[ 0.45707469 -5.06668438 -0.97069895 -8.08657416 -1.24729393  5.08114802
  1.542005    9.50165721 -5.67757323 13.34722735  4.25736634 10.84443673
 20.08222429 13.30721339 21.4962628   5.85803427  2.7072249  -0.84459448
  5.59861577 -0.87119433 16.92820128  9.5072187   0.51499946  9.44410336
 -2.48344966  1.92128078  9.0949871   7.11303932 13.33561384 -0.44615943
 28.28936953  5.81135137 -8.11622884  7.6450643   8.74420749 14.41587119
  2.60279852  6.12703202 35.52237471  1.01330199 -3.55140724 10.21151713
  4.80653883  7.79213103  7.60930522 -5.14730756 -0.17844894 -2.61340642
 -1.38863189 38.60656277 19.98322584 35.88892121 20.0660507  -6.1403304
  4.5436997  -3.06149404  4.3945072   4.22675728  1.82294114 -2.30233149
 -6.67902568 -2.58047892  0.43747305 -2.24408735 27.45248203]
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2115.405052751185
gradient value of function right now is: [-2.23114156e-01  4.14295584e-03  1.41514366e+00 -9.47516014e-02
  2.23114156e-01 -4.14295584e-03 -1.41514366e+00  9.47516014e-02
 -2.35631655e-01 -7.53278736e-03  5.51297529e-01 -2.22778847e-01
  7.10613755e-05  6.04020985e-03 -2.27984707e-05  1.93534227e-05
  1.66001303e+00  2.03967145e+00  1.44948773e+00  1.46355718e+00
 -1.89777775e-01  4.79422301e-02 -1.07152681e+00  1.26948871e-04
  4.06786754e+00 -1.30462382e-01  1.87021937e+00 -8.48904153e-03
  2.20506452e-02 -3.16119987e-02  1.28573828e-05 -8.80788181e-02
 -2.98045915e-01 -1.82618384e-01 -9.08460069e-02 -6.94753749e-05
  1.27473529e+00  3.44996420e-02  2.42434347e-02 -3.87092742e-04
 -6.56880131e-01 -7.28996349e-03 -8.37076578e-01 -6.40541141e-02
  5.46758233e-01  7.82980265e-02  1.10805134e+00  2.13749874e-01
 -1.12230892e+01 -1.65843152e-01 -5.10095515e-01 -3.31209769e-01
  2.02684122e-03  1.60108471e-01  2.48309015e-01  2.02715645e-01
 -1.92447359e+00  2.01352301e+00  2.66024430e+00 -1.01600763e+01
  5.89924669e+00 -1.94341136e+01  4.94726780e+00 -2.01657943e+01
 -1.34650276e+01]
supnorm grad right now is: 20.165794277791818
Weights right now are: 
[ 1.14652925 -3.86157459 -1.91423707 -7.90668461 -1.93674849  3.87603823
  2.48554312  9.32176766 -6.01967405 13.02945099  3.97358371 11.17652464
 20.86791014 14.29769711 23.30431521  6.24490716  2.26949552 -1.56604925
  5.02131621 -0.95717085 16.95797536 10.03140236  0.34854767  9.78309375
 -2.47781923  2.93809988  9.47304915  6.65471951 14.10167651 -1.21712888
 29.17955054  5.07724296 -6.43957367  7.3549137  10.84313785 16.26990587
  2.13946791  6.94817439 39.44068983  0.63814063 -2.58814596 13.0901195
  5.84471032 10.01855159  8.33214555 -5.3050956  -0.31497988 -2.85556229
 -1.6824008  39.10392303 19.54202759 36.51066309 19.83450652 -5.70161403
  5.41734349 -2.3914793   4.43407916  4.30643664  2.40066343 -1.99987444
 -5.89313371 -3.17584705  0.7082419  -1.92675467 27.65784912]
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2103.604515575698
gradient value of function right now is: [ 2.81261373e+00  5.32759016e-03  7.55762884e+00  5.94983140e-02
 -2.81261373e+00 -5.32759016e-03 -7.55762884e+00 -5.94983140e-02
 -2.19368596e+00 -2.61405558e-01 -2.52493486e+00 -4.99951084e-01
  4.07814976e-03  1.08107104e-02  3.10360155e-04  6.20835517e-05
  4.23039884e+00  5.47212366e+00  2.33683450e+00  2.11573328e+00
  1.07546929e-01  9.56456720e-02  3.60810136e-01  6.25474512e-04
 -2.00326833e+00 -2.85913820e+00 -5.69408849e-01 -2.38962482e-01
  3.54555014e-02  1.73017831e+00  6.88340260e-07  8.67261424e-02
  1.42221146e-01 -5.15854181e-01  2.79608160e-02 -5.15151656e-03
  2.22641810e+00  1.78035334e-01  3.40353179e-03  2.41618171e-03
 -3.87765287e+00 -1.97183631e-01 -1.47987208e+00 -3.41507156e-01
  6.56751307e-01  6.37040546e-01  2.79019068e+00  1.18543977e+00
  1.97944828e+00 -6.86667484e-03  4.55347668e-02 -3.20647741e-03
  3.46097288e-02  2.63118689e-01  8.30027260e-01  4.89440185e-01
 -2.57541059e+00  1.39063699e+00  2.30219610e+00 -2.29744803e+00
  1.28464901e+00 -3.06162135e+00  1.87218562e+00 -2.29003510e+00
 -2.67676726e+01]
supnorm grad right now is: 26.767672641627566
Weights right now are: 
[ 0.91081159 -4.41573924 -0.99291684 -7.80610619 -1.70103083  4.43020288
  1.56422288  9.22118924 -6.36456761 12.46645636  3.57631198 10.40159004
 21.72720894 14.1909208  18.76274174  6.66170626  2.26614917 -0.92403052
  4.48977823 -1.3788254  17.74540938 10.0930828   0.85843102 10.56693515
 -2.92453926  1.48616801  9.34728858  6.08853447 14.15001485  0.11530793
 29.60563162  6.04503004 -6.56283788  6.91811021 10.76510489 15.57056152
  2.55400472  7.6614038  40.26716961  0.79121451 -3.39904867 13.02747364
  5.62474546  9.20914737  9.16267775 -4.03521702  0.33875503 -1.67023444
 -1.24994571 39.86143871 20.96823903 37.20819456 20.13755713 -6.42148079
  5.01680941 -3.11529096  4.21501409  4.59773046  1.69220295 -2.3087754
 -6.22895797 -2.51165343  0.09139522 -2.11926133 27.10293604]
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2120.200567686292
gradient value of function right now is: [ 4.24027404e-01  6.42019884e-03  5.22664271e+00 -7.77912916e-02
 -4.24027404e-01 -6.42019884e-03 -5.22664271e+00  7.77912916e-02
 -8.50073580e-01 -3.15194789e-02  5.19476426e-02 -4.04880400e-01
  8.53003463e-04  1.02458266e-02 -1.69710678e-04  3.04695504e-05
  2.06138515e+00  4.67724027e+00  8.28567949e-01  8.43438700e-01
 -1.82084555e-01  1.16256349e-01 -1.10504746e+00  2.96445997e-04
  4.37835440e+00 -1.67172621e+00  2.14543956e+00 -1.01396046e-01
  1.79476150e-02  4.18636866e-01  1.05738723e-05 -1.34313702e-01
 -3.58905899e-01 -3.31331041e-01 -1.38305168e-01 -8.77679866e-04
  2.08978860e+00  6.49332655e-02  2.58455965e-02 -5.06331652e-04
 -7.76742059e-01 -5.10234775e-02 -5.96976724e-01 -8.71137681e-02
  6.13061885e-01  2.83829133e-01  2.01867575e+00  4.85112506e-01
 -1.27545222e+01 -1.97890440e-01 -5.25862422e-01 -3.07164387e-01
  1.37977360e-02  3.99891583e-01  9.81419476e-01  5.97930362e-01
 -2.80913087e+00  3.96088432e+00  3.57599202e+00 -1.28706618e+01
  5.19098784e+00 -2.05022014e+01  3.98797522e+00 -1.90056887e+01
 -1.97696083e+01]
supnorm grad right now is: 20.502201432945533
Weights right now are: 
[ 1.11906398 -3.56561467 -1.27992251 -8.4663399  -1.90928322  3.58007831
  1.85122855  9.88142295 -6.24062704 13.6455447   3.59101708 10.88330955
 22.30570787 15.04061493 15.42991067  7.86593931  2.36872658 -0.91223264
  4.85040961 -0.90364795 17.5127543  10.48887097  0.31783026 11.5521118
 -2.69812493  1.9824133   9.9385109   6.31742322 13.84311462 -0.67224458
 29.72636706  5.53304115 -6.61578902  7.51421052 11.23705459 17.13589302
  1.55318828  7.62483838 41.23713152 -0.56251583 -2.94189103 14.21106712
  5.75523324 10.25729916  8.73318449 -4.83460803 -0.34359654 -2.27829165
 -1.60970387 40.73445995 20.99489577 37.80193938 20.08758417 -6.64578885
  5.42714446 -3.02079745  5.12900228  3.23193593  1.77116822 -2.29727936
 -5.60457425 -2.95138905  0.56351396 -2.1758669  27.79751332]
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2121.0654806804578
gradient value of function right now is: [ 6.12585004e-01  1.01824278e-02  6.33632732e+00 -6.21322373e-02
 -6.12585004e-01 -1.01824278e-02 -6.33632732e+00  6.21322373e-02
 -8.28773682e-01 -9.20636096e-02  3.16611984e-01 -4.57767542e-01
  2.89523677e-03  1.68780483e-02  1.52744539e-04  3.91809696e-05
  1.75687350e+00  4.09079923e+00  1.29805729e-01  2.65743910e-01
 -1.15045946e-01  1.52068851e-01 -1.18923812e+00  3.29001007e-04
  4.74694540e+00 -2.11123864e+00  2.21417908e+00 -1.73684650e-01
  2.59455811e-02  4.96781085e-01  6.06614066e-06 -1.28445292e-01
 -1.56797206e-02 -1.02713439e-01  1.42459454e-02 -7.02016066e-04
  1.99999588e+00  9.19749450e-02  1.26686050e-02  2.72312126e-04
 -1.17837038e+00 -8.22567969e-02 -7.76287001e-01 -1.19206330e-01
  2.11409522e-02  9.19352696e-02  7.17222468e-01  1.67567012e-01
 -1.36081067e+01 -1.87555089e-01 -5.66588094e-01 -2.64893096e-01
  3.61412525e-02  4.83206497e-01  1.42657715e+00  7.48643019e-01
 -1.51776891e+00  3.61587736e+00  3.44746128e+00 -1.28639061e+01
  5.11450023e+00 -2.48804929e+01  3.28902697e+00 -1.71852807e+01
 -1.87407507e+01]
supnorm grad right now is: 24.88049285830251
Weights right now are: 
[ 1.09069239 -3.95930103 -1.10022989 -8.06189905 -1.88091162  3.97376467
  1.67153594  9.47698209 -6.44194284 13.72047032  3.82705231  9.64440572
 22.53696698 15.12081861 16.18172749  7.83845863  1.72566191 -0.7554465
  3.32724115 -2.2546055  18.47975873 10.66973334  0.87813856 11.69472653
 -2.74390721  1.71979328 10.04563635  6.56965269 14.54235749 -0.22468634
 30.1049823   5.88913479 -7.08290303  7.79604117 10.75855093 17.33600597
  1.95622463  7.91971184 41.38052199 -0.19718349 -3.38431516 15.86091065
  5.58533002 10.95286732  7.93691663 -5.42700743 -0.36365234 -2.4537249
 -1.49892129 41.40060341 21.57110481 38.36089185 18.85746331 -7.4091033
  5.19876671 -3.48845103  5.81472988  2.74040017  2.06740566 -2.28876503
 -5.88462573 -2.7115471   0.91755803 -2.19621626 27.56944926]
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2111.8874505701074
gradient value of function right now is: [ 1.11153566e+00  2.47552439e-03  2.84373939e+00 -1.87770950e-01
 -1.11153566e+00 -2.47552439e-03 -2.84373939e+00  1.87770950e-01
 -9.35807124e-01 -2.41225289e-02  2.08435439e-01 -4.11443460e-01
  6.44516730e-04  5.23038454e-03  7.99987210e-05  4.60380770e-06
  2.30830803e+00  3.15790802e+00  1.41989092e+00  1.39074622e+00
 -3.73590202e-01  5.77134034e-02 -2.94980254e+00  6.23252345e-05
  7.11947978e+00 -9.03428593e-01  3.35647919e+00 -3.90243071e-02
  3.47870992e-02  3.75025113e-01  1.04142513e-06 -2.91642769e-02
 -2.79856025e-02 -2.90650184e-01  1.49887679e-02 -5.95098259e-04
  1.62781175e+00  9.23702703e-02  8.50601014e-03  7.51147252e-05
 -1.02965427e+00 -8.79144059e-02 -1.33121960e+00 -1.29149055e-01
  5.10594833e-01  1.30802806e-01  1.62174488e+00  2.38074191e-01
 -2.16286563e+01 -2.58014630e-01 -1.11626954e+00 -3.40301500e-01
  1.28841028e-02  1.04973220e-01  3.74148833e-01  1.68801757e-01
 -2.12510719e+00  2.80564494e+00  2.39840039e+00 -1.80041242e+01
  5.69354063e+00 -4.23851097e+01  2.68881182e+00 -2.19016706e+01
 -1.84155975e+01]
supnorm grad right now is: 42.38510970293339
Weights right now are: 
[ 0.81278056 -4.32198285 -1.68092271 -8.3902158  -1.60299979  4.33644648
  2.25222875  9.80529885 -6.58400248 14.04371451  3.64735061  9.60336439
 22.80550895 15.04533628 13.36523351  8.07162195  2.36183296 -1.13552127
  4.22784304 -1.53577414 17.84273483 10.3484463   0.59266212 11.87506998
 -2.72941998  2.18952725 10.51209428  7.14811797 16.36452168 -0.16241271
 30.42220018  6.03787122 -7.56787462  7.49107815 10.53233353 19.21263909
  1.94713327  8.95172041 43.11072963 -0.7576063  -3.22737033 17.53107672
  5.30372739 11.85265785  7.69884991 -6.3523535  -0.08767192 -3.3225937
 -1.70884292 41.58667764 22.10371266 38.6964217  16.78144379 -7.99606119
  5.14163429 -3.72217458  4.94840241  3.74164575  2.24785233 -2.52507551
 -6.34579859 -2.41517212  1.0544822  -2.43786299 27.33538078]
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2124.33228216519
gradient value of function right now is: [-2.48488715e+00  2.51797786e-03  1.01686974e+00 -3.26966170e-02
  2.48488715e+00 -2.51797786e-03 -1.01686974e+00  3.26966170e-02
  1.10420862e+00 -6.59950014e-03  2.17564184e+00 -2.00950872e-01
  4.85237555e-05  9.08351519e-03 -2.69193324e-03  4.83480965e-06
  1.13096590e+00  1.15349905e+00  9.45043443e-01  9.08314031e-01
 -6.89090076e-02  6.46262181e-02 -5.53748947e-01  3.69647747e-05
  4.57170423e+00 -1.13254081e-01  1.44026690e+00 -1.51082200e-02
  1.48911313e-02 -4.52908770e-01  6.05976856e-08 -1.24720634e-01
 -7.93453188e-02 -1.33935847e-01  1.17811144e-02 -9.87642864e-06
  8.34542460e-01  4.38443021e-02  1.75574750e-03 -8.28611174e-05
 -3.63426769e-01 -3.73338034e-02 -7.68669978e-01 -6.48134580e-02
  4.54242175e-01  5.98644298e-02  7.17265443e-01  1.20816732e-01
 -1.03683293e+01 -1.97530288e-01 -4.19864892e-01 -2.11215716e-01
  8.41965794e-03  1.35187342e-01  6.52565691e-01  2.98922448e-01
 -1.36009631e+00  1.18959543e+00  2.78320557e+00 -1.39486188e+01
  3.38253789e+00 -1.80477389e+01  2.74635730e+00 -1.41370115e+01
 -9.78259623e+00]
supnorm grad right now is: 18.047738869369237
Weights right now are: 
[ 0.695424   -4.75238675 -1.43280496 -8.44132504 -1.48564323  4.76685039
  2.00411101  9.85640809 -6.32706299 15.37508492  3.93967508  9.82827554
 22.29309027 15.49017559  7.30324656  7.92487287  2.31894035 -0.96726308
  4.5568873  -1.45418548 18.15410014 11.27084184  1.01569606 11.58480367
 -2.87844325  2.54202624 10.55660977  7.97210188 17.55965503 -0.74873161
 30.47119037  6.03672304 -7.43652166  7.9796744  12.05265183 19.59022253
  1.79443124  8.9613307  43.67247378 -0.50476417 -3.37773547 17.84245765
  5.20487838 11.82185151  7.13659948 -7.22990181 -0.70924854 -4.12735352
 -1.59996433 42.88753945 22.43564794 39.79761885 18.09306484 -7.99452629
  4.40698056 -4.2601419   3.93271768  4.6548275   1.2415242  -2.25219856
 -5.99730052 -2.62868315  0.12297487 -2.31335099 27.61461095]
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2100.0509239504477
gradient value of function right now is: [-5.70309298e+00  9.48176817e-04 -3.73660797e+00  9.33220397e-04
  5.70309298e+00 -9.48176817e-04  3.73660797e+00 -9.33220397e-04
  5.30431761e+00  3.23191056e-03  5.85201635e+00  9.08409558e-01
 -2.31628953e-04  1.15225404e-03 -3.00953554e-03  1.96823671e-06
 -2.63736893e+00 -4.16915509e+00 -1.93230103e+00 -1.51733085e+00
  1.80780402e-02  9.93225026e-04  3.78479494e-02  1.08363372e-06
  2.62626206e+00  5.49744907e-01 -1.36049187e-01  1.48014903e-03
 -5.12856848e-02 -7.66941849e-01 -1.51961624e-06 -5.82810249e-02
  8.31043243e-02  4.49400187e-01  3.40905769e-02  1.62166675e-05
 -5.17408010e+00 -1.93541247e-01 -9.69361973e-02 -6.86181482e-05
  4.53101077e+00  3.31611922e-01  1.06616514e+00  4.60023983e-01
 -1.81394678e+00 -3.27594458e-01 -2.04694693e+00 -5.16819379e-01
  4.55643011e+00  2.36592848e-01  1.13680290e-02  2.45025354e-01
  1.37595888e-03  6.91193757e-02  1.00628843e-01  8.25125371e-02
  3.45620968e+00 -7.36135167e+00 -2.26140485e+00  2.24530716e+01
 -7.75200606e-01  3.61830852e+00 -2.18648931e+00  2.06260624e+01
  3.44844397e+01]
supnorm grad right now is: 34.48443973475953
Weights right now are: 
[ 0.71574843 -5.37803858 -2.23861897 -8.72136797 -1.50596766  5.39250222
  2.80992501 10.13645102 -6.09953288 15.01965101  4.18885219 10.21983618
 22.32332816 16.33666068  4.96079264  7.33211776  2.19386916 -1.90415934
  4.30111529 -1.67328949 18.31546405 12.60357429  0.86704233 11.30132638
 -2.84799231  3.16151322 10.89108276  7.76580321 17.85665992 -2.15717732
 30.60614192  5.24556618 -7.04044317  8.57868531 12.70435519 21.08582522
  1.30357136  8.70670499 43.30912336  0.06156921 -3.26541507 16.57593444
  6.56692245 10.6791344   7.09031623 -6.64014315 -1.65888902 -4.04676091
 -1.66034397 43.913104   22.45648307 40.7833856  19.05065809 -6.26722261
  6.23032551 -2.40733299  5.07115441  2.89359381  2.37497959 -1.91040183
 -6.04413834 -2.91863274  0.59037507 -1.9608369  27.78785059]
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2107.7871076734514
gradient value of function right now is: [ 2.08685914e-01  3.94887732e-03  5.48783461e+00 -1.04602561e-01
 -2.08685914e-01 -3.94887732e-03 -5.48783461e+00  1.04602561e-01
 -5.49210928e-01 -7.54437656e-03  9.47466955e-02 -2.99879745e-01
 -1.53951941e-03  2.06243835e-02 -3.46195747e-02  7.35362454e-06
  2.17142872e+00  4.75500150e+00  1.08533584e+00  1.17589077e+00
 -1.55503224e-01  8.38767989e-02 -1.73998604e+00  2.80417410e-05
  4.25724020e+00 -1.00596609e+00  1.87997379e+00 -4.68382218e-02
  1.68610631e-02  3.02052344e-01  3.08692348e-07 -2.18125480e-01
  3.23433672e-01 -1.89289010e-01  2.00323916e-01 -9.91475854e-05
  1.48047493e+00  1.09658247e-01  6.12994036e-03 -1.89133856e-05
 -1.30530793e+00 -9.55998846e-02 -7.33396441e-01 -1.39922807e-01
  3.06773727e-01  1.07440241e-01  8.94320007e-01  2.06616027e-01
 -1.35604617e+01 -1.92282931e-01 -3.94229880e-01 -2.65429352e-01
  2.98894212e-02  5.43423021e-01  1.05574126e+00  7.52077707e-01
 -1.69230718e+00  2.03080498e+00  3.52238179e+00 -1.48196922e+01
  4.95079864e+00 -1.99117448e+01  3.60544662e+00 -1.94904724e+01
 -2.14076779e+01]
supnorm grad right now is: 21.407677894827614
Weights right now are: 
[ 0.50815483 -6.03486319 -1.35833908 -8.48062257 -1.29837406  6.04932683
  1.92964513  9.89570562 -6.24153417 15.57711153  4.2979512   9.34171425
 22.97760509 15.81029772  5.52055319  7.0010513   2.05212046 -1.10537973
  3.64035952 -2.41077181 19.12633846 12.23262659  1.37502419 10.97908473
 -2.86687978  2.1502838  10.9912442   7.90922856 16.92382598 -0.96027941
 30.63012553  6.04969854 -7.98480469  8.01142756 11.78755349 21.42064972
  2.18192686  9.23635584 42.53963016  0.52693909 -3.73252444 15.78521126
  7.42129173  9.98338352  7.94172758 -6.1235799  -0.51148646 -3.26775063
 -1.54501757 44.55407478 22.82917627 41.28233076 20.64904695 -6.87799176
  5.760683   -3.12778603  4.10456876  3.26994266  1.70820261 -2.20074476
 -6.19269116 -3.04123053  0.3963425  -2.16597053 26.99062693]
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2122.1236878656237
gradient value of function right now is: [ 1.67127444e+00  4.55205941e-03  1.25138988e+00  2.22533381e-02
 -1.67127444e+00 -4.55205941e-03 -1.25138988e+00 -2.22533381e-02
 -2.31989523e+00 -8.79976381e-03 -2.59712063e+00 -5.63250661e-01
  1.10243823e-03  9.64714385e-03  6.54652267e-03  4.06384198e-06
  1.49641085e+00  1.63610850e+00  1.42299650e+00  1.25880462e+00
  3.05548030e-02  4.19495609e-02  1.82909008e-01  1.61359531e-05
 -1.21194242e+00 -6.22369260e-02 -2.19244094e-01 -8.10668161e-03
  1.50987458e-02 -2.45989229e-01  1.40719332e-08 -1.49212940e-01
  2.22868208e-02 -1.36959254e-01 -4.54364473e-04 -5.93489543e-06
  2.69474178e+00  5.91479475e-02  7.03857201e-03 -4.22179624e-05
 -2.82050296e+00 -1.66236983e-01 -1.06372094e+00 -2.04209760e-01
  3.66005548e-01  2.51722606e-02  7.19436998e-01  8.56098521e-02
  6.12820861e-01 -6.09597021e-03 -3.49614728e-02 -1.37707778e-02
  8.04363726e-03  3.31043318e-01  4.59500197e-01  4.05619775e-01
 -1.43512144e+00  1.70416487e+00  1.14021547e+00 -1.64519927e+00
  1.58543618e+00 -5.47719243e+00  9.11640908e-01 -2.08712969e+00
 -1.26976235e+01]
supnorm grad right now is: 12.6976235128107
Weights right now are: 
[ 1.16405701 -5.90837267 -1.77775184 -8.58014838 -1.95427625  5.92283631
  2.34905789  9.99523143 -6.38156954 14.25406796  4.34212775  9.37879453
 23.55617263 16.38272609  4.67318609  6.59525665  2.78444208 -1.21595304
  4.37841008 -1.74361335 20.13988395 12.36851785  1.50816789 10.39510949
 -3.21772294  2.34195894 10.71136763  9.18994589 19.72318453 -1.53477762
 30.63728271  5.64396407 -7.6917423   8.39777799 12.84636748 23.01132851
  1.99810117  8.7108124  43.43101044  1.0968885  -3.89729054 15.68349341
  6.80014017  9.20905273  7.53258734 -6.67281287 -0.06897894 -3.34936223
 -1.38677231 44.65389504 23.42475317 41.51144114 21.99236226 -6.21359863
  6.43312302 -2.52964359  3.15087109  3.29933961  2.42584871 -2.09994698
 -6.45931775 -2.73307512  0.65951448 -2.29254739 27.42613485]
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2125.564512530031
gradient value of function right now is: [ 2.60463345e-01 -4.21870806e-04 -4.09307742e+00  2.44173195e-02
 -2.60463345e-01  4.21870806e-04  4.09307742e+00 -2.44173195e-02
  4.39404169e-01  1.09283330e-02  1.60352343e-01  4.31257991e-01
  9.27299285e-04 -4.98173391e-03  1.47061085e-02 -1.40021978e-06
 -3.07604936e+00 -5.34193345e+00 -1.66369030e+00 -1.48351230e+00
  4.17589762e-02 -1.74316434e-02  4.33906040e-01 -7.01066709e-06
 -1.49090776e+00  1.63898062e+00 -7.16091382e-01  9.47431548e-03
 -2.23725590e-02 -6.13561475e-01 -1.31485696e-06  6.39218696e-02
 -5.52400862e-02  3.17891822e-01 -4.11491884e-02  8.33983291e-05
 -1.37706086e+00 -1.48642047e-01  4.26476211e-03 -1.54452824e-05
  1.69626434e+00  1.16638256e-01  9.48350581e-01  1.48514908e-01
 -6.84249375e-01 -3.57971269e-01 -2.23563364e+00 -5.25472694e-01
  4.94687812e+00  7.12555043e-02  2.35400533e-01  7.49387894e-02
 -2.23250149e-03 -1.56593366e-01 -3.23801332e-01 -2.16410421e-01
  3.17947508e+00 -5.08881096e+00 -2.51502733e+00  8.51864478e+00
 -3.87944851e+00  1.40621716e+01 -1.95563692e+00  7.98192994e+00
  1.64423817e+01]
supnorm grad right now is: 16.44238171301644
Weights right now are: 
[ 1.29497731 -6.22527446 -1.71057917 -8.63876158 -2.08519654  6.2397381
  2.28188522 10.05384463 -6.5712771  15.42487719  4.45871485  9.89593067
 23.82279424 16.08698506  4.98521043  6.26169909  2.77069219 -0.9630312
  3.83869307 -2.02197471 19.911865   12.02426272  1.59207526  9.85252592
 -3.05117579  2.12461799 11.26199687 10.7762224  18.91721265 -1.00579924
 30.64480755  6.05569986 -8.59922417  8.40022694 12.24576841 23.53427188
  1.72766707  9.23023203 44.2425819   1.44938609 -3.41480101 17.87296665
  6.83532816 11.04902436  7.91229143 -6.64827688  0.10686363 -3.02335533
 -1.65706565 45.16213242 23.36093252 42.01131284 23.40405708 -6.4558445
  6.06866936 -2.95649705  3.58038277  2.01533952  1.48572015 -2.12576542
 -6.55553506 -2.80075497  0.50604362 -2.19094032 27.85705124]
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2118.1148561783534
gradient value of function right now is: [-3.65640934e+00 -7.63512203e-04  5.39923904e-01 -5.75732714e-03
  3.65640934e+00  7.63512203e-04 -5.39923904e-01  5.75732714e-03
  2.20609673e+00 -4.16298670e-04  2.82453474e+00  2.56998358e-01
 -6.42891922e-04 -3.11295316e-04 -5.74024214e-03 -9.28453733e-08
  1.72784907e+00  1.49225557e+00  1.63320492e+00  1.58217592e+00
 -8.81860155e-03 -1.41407549e-03 -6.79706347e-02 -1.24765578e-06
  2.63567218e+00  1.94233653e-02  5.29683440e-01  7.71141400e-04
  5.90383435e-03 -5.52803310e-02 -1.66268144e-10  3.59748300e-03
 -1.09974649e-01 -1.32185763e-01 -1.01741067e-02  4.41098093e-05
 -1.32866254e+00  4.77566933e-02 -4.14805476e-03 -1.71527684e-06
  8.04141285e-01 -3.13965890e-02  1.93846751e-01 -3.87922065e-02
  3.94577736e-01  1.01319033e-01  5.98962589e-01  1.38839758e-01
 -4.21710718e+00 -1.10870530e-01 -4.44525167e-02 -1.28580428e-01
  1.86824876e-04 -7.76346375e-03 -2.45637890e-02 -1.52384328e-02
 -9.75152280e-01  1.04559967e+00  5.14704883e-01 -8.44154457e+00
 -2.41286082e+00  3.57588246e+00  5.01070575e-01 -8.82312139e+00
 -6.61991323e+00]
supnorm grad right now is: 8.823121393203834
Weights right now are: 
[ 0.42361512 -6.55945526 -2.30023172 -9.52996168 -1.21383436  6.5739189
  2.87153777 10.94504472 -6.41671152 15.60508123  4.3966008   9.21381512
 22.85342681 16.35245473  3.53937651  6.40809925  3.09167165 -1.18945912
  4.36990252 -1.4979929  19.33579686 12.15921064  0.68049793 10.06670938
 -3.1952492   3.12564256 11.64900862 11.70363838 20.15149109 -0.66284147
 30.6957487   6.09375564 -7.50808526  7.92499992 13.51124772 27.34419579
  1.65537434 10.3458369  42.22099421 -0.2050165  -4.07300199 16.87653875
  6.17735321 10.00475063  8.96219404 -6.33477973  0.51444091 -2.75773641
 -1.74633328 45.80511472 24.28423702 42.73761703 21.82961754 -6.9650755
  5.96856204 -3.1378981   3.4659408   3.38551336  2.22539085 -2.34193677
 -7.16977691 -2.32639381  0.55196258 -2.3176125  27.37601439]
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2110.5552994625123
gradient value of function right now is: [ 6.25254583e+00  1.19343297e-03 -3.30882731e+00  3.75726096e-02
 -6.25254583e+00 -1.19343297e-03  3.30882731e+00 -3.75726096e-02
 -5.53525276e+00  7.33609540e-03 -7.37299107e+00 -5.87905107e-01
  3.08708335e-03 -7.39617785e-03  3.50523903e-02 -4.93116608e-06
 -2.53558585e+00 -4.14935462e+00 -1.65222573e+00 -1.77269041e+00
  7.74079178e-02 -4.19219035e-02  6.82251712e-01 -3.48697512e-05
 -8.15754589e+00  7.50788879e-01 -2.23764258e+00  7.56928081e-03
 -1.42270912e-02 -6.57800558e-01  3.40293893e-09  3.58868246e-02
  7.55323417e-02  3.11839139e-01 -2.99484985e-02  1.44018712e-04
  2.90074119e+00 -1.57193174e-01  6.06377700e-03 -3.88621624e-05
 -2.51286156e+00 -1.20544397e-01 -6.67939473e-02 -1.18873295e-01
 -6.21188587e-01 -2.69375391e-01 -1.99931466e+00 -5.06457574e-01
  1.63966038e+01  2.25057189e-01  5.58401518e-01  2.85114857e-01
 -2.25207353e-03 -9.01849998e-02 -2.45531177e-01 -1.61035965e-01
  2.45083071e+00 -2.33634140e+00 -3.31403452e+00  1.93690850e+01
 -4.10385391e+00  2.43751627e+01 -3.87040267e+00  2.42982148e+01
  6.97008210e+00]
supnorm grad right now is: 24.375162743021136
Weights right now are: 
[ 1.3185162  -6.11149494 -2.14992541 -8.92180757 -2.10873544  6.12595858
  2.72123145 10.33689062 -6.77811117 16.37562372  4.22557737  9.30297834
 23.45638996 16.77586243  4.0428662   6.62671508  2.59839031 -1.47665816
  3.86296019 -2.33750282 19.9058578  12.65761995  1.23337898 10.61035786
 -3.50696408  3.30606928 11.49977784 11.46227529 20.434234   -0.10524791
 30.69737867  6.18874359 -8.60804786  8.57479173 12.97741397 28.75277924
  1.86931581  9.63368779 43.7483222  -2.55215619 -4.27107213 16.86190072
  6.19998911  9.81294648  8.93609086 -6.04593163  0.15487824 -2.71926975
 -1.53513562 47.16123063 24.02411443 43.92263725 21.77743815 -7.08918599
  5.90165738 -3.21081799  4.09345961  2.71331844  1.69349707 -1.89078156
 -6.76313719 -2.67666845  0.27011257 -1.94296052 26.99242429]
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2120.1300991576827
gradient value of function right now is: [-3.45081679e+00  5.74749271e-03  1.72634402e+00 -1.92580850e-02
  3.45081679e+00 -5.74749271e-03 -1.72634402e+00  1.92580850e-02
  3.75431447e+00 -8.53900383e-03  4.89175084e+00  1.89886163e-01
 -1.67153818e-03  1.53930041e-02 -2.73041171e-02  9.84778382e-06
  2.22833882e-01  1.32962268e+00  1.13525059e-01  2.48936491e-01
 -6.40761180e-02  1.37935678e-01 -7.12237457e-01  5.49904270e-05
  5.61877322e+00 -2.30803124e-01  1.25031103e+00 -1.94440852e-02
  3.42521284e-03 -8.16004431e-01 -2.21425461e-09 -2.35553799e-01
  6.65968283e-02 -1.57695234e-02  6.15986900e-02 -1.03973959e-05
 -1.16583622e+00  7.58781007e-03 -1.44376303e-02 -1.54439519e-04
  1.23225658e+00  4.66236736e-02 -4.57616226e-02  4.80236615e-02
  7.44429458e-03 -3.96604805e-02 -4.63149045e-02 -5.45347076e-02
 -9.93920445e+00 -1.87168038e-01 -4.35045560e-01 -2.14563513e-01
  1.52956946e-02  7.41068525e-01  1.02292910e+00  9.26457548e-01
 -4.62522404e-01  1.07972757e+00  2.16626915e+00 -1.15248929e+01
  3.13875154e+00 -1.79732939e+01  1.93664536e+00 -1.45601262e+01
 -6.50929218e+00]
supnorm grad right now is: 17.97329393532219
Weights right now are: 
[ 0.80225036 -4.02221451 -1.81310725 -8.32968516 -1.5924696   4.03667815
  2.38441329  9.74476821 -6.1059114  17.31786624  4.97877757  9.35453109
 24.36343853 18.5051012   4.00920716  7.37353621  2.87361929 -0.78539511
  4.14364813 -1.8970421  20.00040719 13.1684127   1.21465274 12.03376848
 -3.0174137   3.07563312 12.03547824 10.94670492 21.06189814  0.0998239
 30.69641851  4.95521271 -8.50485187  9.07201233 13.63574824 29.25748978
  1.62730317  9.84348713 43.00462463 -2.77960549 -4.01231333 18.00786041
  5.72627182 10.70625691  8.81728554 -6.85907977 -0.33152446 -3.71852354
 -1.95808733 47.47563498 24.07830369 44.23290098 21.21549037 -6.48119122
  7.32624623 -1.92547665  4.55882649  2.56203574  2.89194641 -1.9908284
 -6.89826862 -2.84041318  0.69003989 -2.16766576 27.64673993]
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2126.4440008400043
gradient value of function right now is: [ 4.70870761e-01  1.13075347e-03  7.57957214e-01  1.22957801e-02
 -4.70870761e-01 -1.13075347e-03 -7.57957214e-01 -1.22957801e-02
 -1.14538592e+00 -6.73066421e-03 -1.42736898e+00 -2.90053090e-01
  5.59844035e-04  4.62870815e-03 -2.49195719e-03  6.44484552e-07
  1.67422465e-01  4.31043254e-01  2.18363644e-01  1.72674933e-01
  1.95261724e-02  7.36488091e-02  2.59720423e-02  5.05325544e-06
 -1.06478298e+00 -2.45384428e-01 -2.07225065e-01 -1.38917773e-02
  2.10400604e-03 -5.08668781e-01  2.06269310e-09 -1.74880049e-02
  6.16652374e-02 -1.49159867e-02  1.95937296e-02 -6.00867016e-06
  1.35990085e+00  9.35937615e-03  4.16378730e-04 -2.49986991e-06
 -1.16298724e+00 -8.13416670e-02 -3.45724195e-01 -1.05025826e-01
  1.87171920e-02 -5.22068797e-03 -1.48532120e-01 -2.52224350e-02
  1.53691141e+00  3.50405605e-02  2.46166270e-02  3.45900645e-02
  1.50707254e-02  1.05597369e-01  2.38282197e-01  1.61560562e-01
 -3.09057333e-01  8.60713790e-01  3.13273120e-01  1.80944020e+00
  2.47089799e-01 -5.99568775e-01  1.65868236e-01  1.92091233e+00
 -6.00347851e+00]
supnorm grad right now is: 6.003478508029683
Weights right now are: 
[ 0.95885321 -3.86046491 -1.77830696 -8.52836671 -1.74907244  3.87492854
  2.34961301  9.94344976 -6.5502073  17.76466948  4.37405265  8.66652179
 25.49741052 18.63114994  3.92280421  7.42760752  3.27564395 -0.44479797
  4.5141769  -1.59250848 20.22468048 12.86750296  1.01533393 12.27878156
 -3.47508332  2.74762849 12.00925487 11.48376659 21.17931277  1.06401194
 30.70201036  6.33714975 -8.10915439  9.08828331 13.89226417 29.21512004
  2.00298496 10.37647261 42.54991682 -1.49016839 -4.46236202 19.57120392
  5.16387118 11.32543404  9.5273533  -5.40821859 -0.38549786 -2.59348171
 -1.80425874 48.24675855 24.51867364 45.06451801 21.20482027 -7.94774827
  6.36077633 -3.26486529  4.98141467  2.34598076  1.36918509 -2.20765015
 -6.52680776 -2.92422271  0.12664728 -2.08595381 27.74342553]
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2125.2484079329033
gradient value of function right now is: [ 4.70421200e-01 -1.85906389e-03 -8.02764583e-02 -4.02112531e-03
 -4.70421200e-01  1.85906389e-03  8.02764583e-02  4.02112531e-03
 -1.40173139e+00  1.79997675e-03 -1.89198929e+00 -3.16387600e-01
 -1.97552991e-04 -1.30736773e-03 -2.28326759e-03 -5.35061066e-07
  2.08278469e-01  1.29325440e-02  3.18623844e-01  2.55443127e-01
  8.15848639e-03 -3.32983990e-03  5.11084072e-03 -8.16875359e-06
 -1.77324802e+00  1.77316197e-01 -3.79965044e-01  1.56060886e-03
  1.90412000e-03  1.77581413e-02  9.65731656e-10  1.83036019e-02
  1.18345827e-01 -3.29979828e-02  3.39005923e-02  1.74718750e-06
  1.36593403e+00  1.67761643e-02 -3.15483297e-03  3.67560853e-06
 -1.43315020e+00 -8.81063661e-02 -5.14217364e-01 -1.20929961e-01
  5.95899529e-02 -1.17806115e-02 -7.60185252e-02 -3.35977815e-02
  3.08652300e+00  7.29854299e-02  4.30012092e-02  9.00616635e-02
  8.75824644e-04 -4.44701301e-02 -1.04153413e-01 -7.22171751e-02
 -5.09531693e-01  1.38456077e+00 -2.87565395e-01  4.38552527e+00
  7.49085678e-01 -7.84403096e-01 -2.34091672e-01  5.65347944e+00
 -3.26989429e+00]
supnorm grad right now is: 5.653479438683652
Weights right now are: 
[ 0.80162958 -3.72019412 -2.09034489 -8.66831756 -1.59184881  3.73465776
  2.66165094 10.0834006  -6.23472618 16.72181256  4.57013789  8.77727013
 26.27375282 18.71586624  4.02386212  7.73795221  3.57342108 -0.69589639
  4.19964504 -2.17099325 20.44374173 12.620827    0.81464748 13.54137502
 -3.51882348  2.45212898 12.07573683 11.91413377 23.55501037  1.40145757
 30.70331473  6.87964192 -7.79791176  8.40960267 14.83624547 29.31478647
  1.92203801 11.22297506 41.70224206 -1.88639943 -4.28459236 19.26100562
  5.58334655 10.7802322   9.39752011 -6.36114714  0.98716892 -2.6647819
 -1.7398535  48.8516264  25.06838061 45.74305897 18.78368805 -8.87184183
  5.96564198 -3.89414803  3.47405467  3.49141879  1.56100739 -2.53367282
 -6.62590036 -2.8226725   0.30054108 -2.18452217 28.07719904]
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2125.7770826559704
gradient value of function right now is: [-6.51307050e-01 -3.42163135e-03 -3.40567122e-01 -6.23431777e-03
  6.51307050e-01  3.42163135e-03  3.40567122e-01  6.23431777e-03
 -4.79360245e-01  7.60640411e-03 -7.97678248e-01 -2.17287800e-01
 -4.00498398e-04 -3.20153534e-03 -1.88461603e-03 -1.33552545e-06
  2.39144057e-01 -9.45445712e-02  4.09137440e-01  3.41075236e-01
  1.17809438e-02 -2.42880838e-02  6.05173882e-02 -1.88709972e-05
 -1.12795741e+00  4.09593540e-01 -3.32651082e-01  7.27343305e-03
  1.97079832e-03  8.11730923e-02  3.92878177e-10  2.59468371e-02
  7.69323528e-02 -3.40368905e-02  2.73543091e-02  1.24479397e-05
  9.56772532e-01  1.70239721e-02 -3.53536522e-03  5.07415761e-06
 -1.01227094e+00 -6.78198524e-02 -3.76960442e-01 -9.23902327e-02
  6.76065408e-02 -2.79637219e-02 -1.15734888e-01 -5.82182658e-02
  2.53052185e+00  4.68678627e-02  4.28884946e-02  6.23480891e-02
 -1.12947358e-02 -8.43590199e-02 -2.10267764e-01 -1.31549469e-01
 -2.88863838e-01  1.03171026e+00 -3.73024052e-01  2.84555862e+00
  4.20746256e-01 -1.25201554e-01 -2.97372675e-01  4.16154548e+00
 -1.87086615e+00]
supnorm grad right now is: 4.161545479584936
Weights right now are: 
[ 1.12479243 -4.18226196 -2.63348204 -9.27234375 -1.91501166  4.1967256
  3.20478808 10.6874268  -6.42509662 17.24293478  4.33266997  9.39906186
 26.32918875 18.95268994  3.02676905  8.11218599  3.19203232 -1.49338313
  4.47112444 -1.89248195 20.04814551 12.79830047  0.22419964 14.08108386
 -3.55359763  2.9943106  12.53021643 12.47964957 25.27378948  1.13592067
 30.70201412  7.2389729  -7.99121105 10.14034314 15.48503498 31.26866957
  1.5789165   9.76090277 41.93851634 -3.40702329 -4.33377843 18.81701434
  4.98939039  9.8272897   8.661333   -6.77378853 -0.66124998 -3.76605959
 -1.95629395 49.77618594 25.37405484 46.3749759  19.01743053 -9.20683363
  5.43724983 -4.43132964  4.89696167  2.63621562  0.73905642 -2.35214723
 -6.79569989 -2.82733031 -0.79809297 -2.20281925 27.43570703]
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2126.453899680587
gradient value of function right now is: [-9.89874951e-01 -1.04616467e-03  3.43075511e-02 -2.45082898e-03
  9.89874951e-01  1.04616467e-03 -3.43075511e-02  2.45082898e-03
 -1.99234815e-01  1.05341728e-03 -2.66605109e-01 -2.46182983e-01
 -1.26636225e-04 -3.79647348e-05 -2.55596903e-03 -2.22911917e-07
  4.04832835e-01  2.20964187e-01  4.34378744e-01  3.85269178e-01
  4.95453508e-03  5.60059152e-03 -1.50879606e-02 -5.31716897e-06
  5.19126132e-04  1.32074637e-01  1.09131566e-03 -1.94058664e-03
  3.02929848e-03 -1.07340060e-01  6.01556336e-10  5.29979462e-03
  3.87174424e-02 -6.29909852e-02  1.50230956e-02 -8.59523996e-07
  1.10840709e+00  2.81048062e-02 -2.04818433e-03  3.98075851e-07
 -9.80263898e-01 -6.60208543e-02 -4.16958549e-01 -9.32188090e-02
  1.36423804e-01  4.36273768e-03  1.70515111e-01  1.22814439e-02
 -1.46765265e-01  8.82893836e-04 -4.05491032e-02 -5.95275276e-03
 -3.97179585e-03 -1.39014704e-02  1.20864938e-03 -7.85554843e-03
 -7.51149114e-01  1.65339966e+00  4.03242733e-01 -9.36810732e-01
  9.58647361e-01 -3.58408421e+00  5.59644835e-01 -1.21646943e+00
 -4.41001682e+00]
supnorm grad right now is: 4.41001682047771
Weights right now are: 
[ 0.78354516 -3.61893928 -1.64356465 -9.12585302 -1.5737644   3.63340292
  2.2148707  10.54093606 -6.29160105 17.27473457  4.2743461   9.45142126
 26.48123022 19.81093855  3.08327182  8.45746425  3.69732016 -0.23593897
  4.32486278 -1.89586991 19.80577511 13.24263     0.28041327 15.30097198
 -3.54588152  2.06004117 12.7405977  12.72255685 24.97792596  0.98820446
 30.70675457  6.63268086 -8.25595881 10.69154015 15.10027776 31.50794564
  1.74187937  9.74315935 41.83857219 -2.70514934 -3.61158604 20.27599104
  5.9207584  11.10878328  9.1043442  -5.31376727 -0.56342772 -2.67000327
 -1.92108798 50.7607103  25.3150786  47.21856192 21.0750623  -8.92807582
  5.41294403 -4.60800922  5.0058073   2.28046353  0.76114561 -2.16532741
 -6.68516021 -3.10567597 -0.77370133 -2.14505941 27.29303696]
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2126.5947575061414
gradient value of function right now is: [-1.02865856e+00 -6.50768819e-04  1.49581375e-01  2.13818485e-04
  1.02865856e+00  6.50768819e-04 -1.49581375e-01 -2.13818485e-04
 -8.78824617e-02 -1.37768391e-03 -1.33035424e-01 -2.17053002e-01
 -3.62930649e-05  6.68231527e-04 -2.82790660e-03  1.35216149e-07
  3.81622714e-01  2.64743595e-01  3.80876628e-01  3.41511110e-01
  7.48708750e-03  1.53515013e-02 -5.73029446e-03  5.38972650e-07
  7.16108377e-02  4.34588310e-02  1.80299329e-03 -5.82934663e-03
  2.57856070e-03 -1.50546272e-01  6.42083440e-10 -4.00922665e-04
  3.80864683e-02 -6.02855325e-02  1.63946731e-02 -3.40494201e-06
  9.81851653e-01  2.58836928e-02 -1.42236742e-03 -3.39002397e-06
 -8.34027123e-01 -5.93247233e-02 -3.28372652e-01 -8.12989670e-02
  1.47283434e-01  1.75587098e-02  1.92138935e-01  2.76069905e-02
 -2.20302044e-01 -2.70903408e-03 -3.85280193e-02 -1.02512877e-02
  3.35882597e-04  1.00514680e-02  7.48736223e-02  3.47637253e-02
 -7.02784284e-01  1.49177282e+00  4.64967107e-01 -1.07343771e+00
  7.81243949e-01 -3.19373275e+00  5.69917622e-01 -1.38549094e+00
 -5.15406556e+00]
supnorm grad right now is: 5.154065559830249
Weights right now are: 
[ 8.10943022e-01 -2.85708244e+00 -1.63689547e+00 -7.79288654e+00
 -1.60116226e+00  2.87154608e+00  2.20820151e+00  9.20796959e+00
 -6.16675921e+00  1.77318736e+01  4.26958630e+00  9.10985122e+00
  2.75523784e+01  2.10975363e+01  3.46179787e+00  8.87152630e+00
  3.37655939e+00 -3.51140181e-01  4.01106877e+00 -2.07054606e+00
  2.08939977e+01  1.42987474e+01  1.35203614e+00  1.60772545e+01
 -3.82627661e+00  1.98731018e+00  1.24027226e+01  1.19771047e+01
  2.55892978e+01  2.18673464e-01  3.07054132e+01  6.28918705e+00
 -8.54631563e+00  1.03030903e+01  1.49251256e+01  3.21955510e+01
  1.91568178e+00  1.03637812e+01  4.35948414e+01 -2.61279112e+00
 -3.51894851e+00  2.12966644e+01  5.92896871e+00  1.12733642e+01
  8.61758010e+00 -7.08030147e+00 -6.57620607e-01 -3.34986329e+00
 -1.56427965e+00  5.12254640e+01  2.59358803e+01  4.76463495e+01
  1.99684057e+01 -9.61039677e+00  6.28207819e+00 -4.43876587e+00
  4.36474596e+00  2.87265794e+00  1.72990621e+00 -2.49030247e+00
 -7.40075129e+00 -2.54930317e+00  8.55259723e-03 -2.36345785e+00
  2.75597143e+01]
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1457.158634988792
W_T_median: 1233.679988250743
W_T_pctile_5: 763.8134471368486
W_T_CVAR_5_pct: 669.6476267283676
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.0
F value: -2126.5947575061414
-----------------------------------------------
