Starting at: 
2022-06-20 18:03:38
tracing parameter entered from terminal:  0.6


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[ 0.10347998  0.18844875 -0.3666709   0.62803316 -0.89369922 -0.17398511
  0.93797695  0.78704989 -0.60791207 -0.16293226 -0.31685198  0.28094308
  0.0404241   0.17453202  0.0940472   0.01169373  0.2300954  -0.23784803
  0.78511084 -0.41859022  0.4809118  -0.01155852  0.07219357 -0.14482284
  0.4701344  -0.18827011 -0.8138637  -0.24629474  0.28361272  0.33354483
 -0.63777411 -0.25343004 -0.81551088 -0.26234589  0.20198453 -0.15135741
  0.25264285 -0.29817275  0.41496663 -0.58895503 -0.60305385 -0.63454123
  0.3979274   0.74701442  0.57452389 -0.67377327  0.6493153   0.07340044
 -0.29694484  0.52758424 -0.14347696  0.04319718 -0.28527617 -0.63077443
  0.13133703 -0.58713125  0.12759166  0.87507529 -0.19770888 -0.66759109
  0.25529887 -0.48501395  0.58877641 -0.72315372] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1260.6521530687958
W_T_median: 1222.3920506735662
W_T_pctile_5: 834.1581876304141
W_T_CVAR_5_pct: 746.6575474940535
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1573.662906507003
gradient value of function right now is: [ 10.91076469   5.34485014   2.14274901   0.94041004 -10.91076469
  -5.34485014  -2.14274901  -0.94041004  -5.02856962  -2.31925529
  -4.99030228  -2.44665259  -3.01601461  -0.9415593   -2.99500234
  -1.01472628   0.83714743   0.45607904   0.83106699   0.47736678
  -0.26796834  -0.08555955  -0.26614129  -0.09200563  -0.2580142
  -0.21210722  -0.28880525  -0.11272273   0.37371434   0.3072764
   0.41888315   0.15855299  -0.25918093  -0.21300165  -0.28995649
  -0.11295647   0.52699464   0.43240459   0.58878526   0.2176322
  -1.43645488  -0.27491079  -0.29670444  -0.29274691  -0.88569816
  -0.17194336  -0.17995266  -0.17854412  -1.38546571  -0.27865453
  -0.29121879  -0.28902402  -0.2923882   -0.12770676  -0.11993158
  -0.12165414  -0.25087543   0.31553649   0.44261225  -0.97838049
   0.46599853  -1.21564114   0.55651837  -1.35577887 -19.90799547]
supnorm grad right now is: 19.907995466303444
Weights right now are: 
[ 0.71047008  0.60653203 -0.09793966  0.90880836 -1.50068932 -0.59206839
  0.6692457   0.50627468 -1.12962063  1.1699459  -0.95057444  1.73290098
 -0.04695233  1.78865175 -0.11272907  1.82869285  1.31849715 -0.22250545
  1.94740708 -0.51169158  1.54531809  1.91488007  1.09730457  1.91509196
 -0.92953317 -1.06115029 -2.05711527 -0.38711925  2.1964551   1.93889044
  1.21325908  1.60692815 -2.10291828 -1.01705456 -0.93081916 -0.23942123
  1.98285935  0.94405406  2.00604196  0.2194244  -1.12019566  3.37658422
  4.32809002  5.24796573 -0.35744449  2.90698939  4.06014732  3.9653566
 -0.95259213  4.04557561  3.20896563  3.9373998   2.39849194  1.04966158
  1.94994223  0.92418878  0.67844153  2.78263477  1.52288816 -2.66958821
  0.837952   -2.80736967  0.94906307 -2.78993357 30.63032713]
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1575.5474304661632
gradient value of function right now is: [ 1.22228045e+01  3.19968683e+00  7.23429156e-01  3.42072276e-01
 -1.22228045e+01 -3.19968683e+00 -7.23429156e-01 -3.42072276e-01
 -7.17260348e+00 -1.58433687e+00 -6.99555635e+00 -2.04333090e+00
 -2.19979580e+00 -2.90317801e-01 -2.15099351e+00 -4.06831592e-01
  3.54063798e-01  1.40141081e-01  3.46375681e-01  1.63329478e-01
 -8.47765993e-02 -1.45709307e-02 -8.28027382e-02 -1.94971044e-02
 -2.37394751e-01 -2.40275957e-01 -2.88376085e-01 -1.87408977e-01
  4.81011555e-01  4.83131946e-01  5.85642514e-01  3.59645347e-01
 -2.27604839e-01 -2.30340589e-01 -2.76021822e-01 -1.79993300e-01
  7.40320493e-01  7.50120731e-01  8.97515900e-01  5.81204753e-01
 -1.41921698e+00 -3.53857239e-01 -5.13247847e-01 -5.42204023e-01
 -8.22874393e-01 -2.26878141e-01 -3.33283668e-01 -3.55477923e-01
 -1.30435793e+00 -3.57388308e-01 -5.22223452e-01 -5.55848132e-01
 -3.96071409e-01 -3.32788185e-01 -4.73292470e-01 -5.21047984e-01
 -2.19218007e-01  5.89206252e-01  1.51275648e+00 -1.03389379e+00
  2.17732379e+00 -1.40006952e+00  2.51912621e+00 -1.65088699e+00
 -2.41998167e+01]
supnorm grad right now is: 24.19981667808162
Weights right now are: 
[ 0.8570715   0.5237267  -0.10194282  0.86686635 -1.64729073 -0.50926307
  0.67324887  0.5482167  -1.06559886  2.56223243 -0.90172064  2.83194099
  0.57369239  2.71944347  0.4801847   2.78247642  2.0770286  -0.06273487
  2.68499713 -0.20857656  2.29823253  2.63925871  1.8222527   2.6681303
 -1.37128804 -1.16419879 -2.3339482  -1.32881581  2.9997263   2.42247948
  1.85663195  3.52629577 -2.41940148 -1.03920926 -1.1186936  -1.14493088
  2.59476379  1.12639219  2.4104545   1.46077587 -2.07105277  3.93381288
  4.80527937  5.82435189 -0.92923687  3.29631933  4.07060838  4.03464369
 -1.51110732  4.47311784  3.25836521  4.04646314  4.99322482  2.35589036
  1.21961813  0.17243292  3.16688218  3.46452985  2.76737104 -2.7006742
  1.81723752 -2.50808535  1.55192453 -2.65721803 30.65761769]
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1581.1736536919936
gradient value of function right now is: [ 7.41706571e+00  6.87576486e-01  2.78641009e-01  7.32460591e-02
 -7.41706571e+00 -6.87576486e-01 -2.78641009e-01 -7.32460591e-02
 -4.69752649e+00 -1.19772167e+00 -4.45875790e+00 -1.47510904e+00
 -4.83896090e-01 -5.96565638e-02 -4.61569103e-01 -8.58715540e-02
  7.90031725e-02  4.79772374e-02  7.65820777e-02  5.03943679e-02
 -2.33993538e-02 -4.61486829e-03 -2.22233737e-02 -6.01466339e-03
 -1.50784819e-01 -1.75137564e-01 -2.24422319e-01 -8.72500255e-02
  2.46591317e-01  2.89870146e-01  3.80177532e-01  1.07839929e-01
 -1.51182908e-01 -1.73586913e-01 -2.21898885e-01 -8.84629130e-02
  3.68514138e-01  4.38155735e-01  5.61743310e-01  2.26554837e-01
 -7.83520148e-01 -1.66671056e-01 -2.97761086e-01 -4.00508906e-01
 -3.95946314e-01 -9.22931520e-02 -1.66491029e-01 -2.26528746e-01
 -7.55571262e-01 -1.75962795e-01 -3.15254230e-01 -4.27128729e-01
 -2.27997934e-01 -3.74674679e-02 -3.00318693e-02 -6.97253938e-03
 -5.71689283e-02  5.36469947e-01  3.27808517e-01 -1.03206208e+00
  9.29787623e-01 -1.52987738e+00  1.67675851e+00 -2.03823401e+00
 -1.30730118e+01]
supnorm grad right now is: 13.073011832430195
Weights right now are: 
[ 1.00359629  0.47861894  0.04226711  0.92169437 -1.79381553 -0.4641553
  0.52903894  0.49338868 -1.11903195  2.95001205 -0.96295539  2.94007705
  1.26193397  3.2658913   1.14266871  3.42052715  2.68074758  0.13318427
  3.25713375  0.13449828  2.97501737  3.16087154  2.4696049   3.25360412
 -1.60841975 -0.82583344 -2.1685397  -1.23441228  3.28294459  2.46753691
  2.02498672  4.21733003 -2.56376729 -0.5795377  -0.84106933 -0.93698918
  2.87945347  0.91829419  2.38321899  1.79701119 -2.64847011  4.44785224
  5.55599712  6.79705412 -1.23265738  3.48177138  4.41599821  4.48735094
 -1.93949041  4.58152662  3.49773497  4.366597    6.0095696   4.29604318
  1.60144213  0.05426227  4.71894454  2.59477551  2.66037942 -3.11188608
  1.39534336 -2.53850448  0.46506583 -2.48347737 30.59897963]
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1584.0383863161676
gradient value of function right now is: [ 2.85870577e+00  1.67091138e-01  1.69979170e-01  2.10272277e-02
 -2.85870577e+00 -1.67091138e-01 -1.69979170e-01 -2.10272277e-02
 -2.60638421e+00 -4.71488289e-01 -2.43217264e+00 -1.03593905e+00
 -1.00950773e-01 -1.65167191e-02 -9.41174959e-02 -3.75539326e-02
  8.66171539e-02  5.00187928e-02  8.45932055e-02  6.29473282e-02
 -4.74236300e-03 -9.35494211e-04 -4.42345887e-03 -1.95404463e-03
 -1.90624821e-02 -5.50843230e-02 -6.32764747e-02 -2.69687886e-01
  3.18699092e-02  7.39137766e-02  8.33272813e-02  4.36503777e-01
 -1.65714612e-02 -5.14686632e-02 -5.88328047e-02 -2.51511128e-01
  6.72244592e-02  1.81880517e-01  2.13901725e-01  8.33189871e-01
  4.70382160e-03 -1.27456089e-02 -6.08579640e-02 -1.28380315e-01
  1.03709374e-02  7.83058265e-04 -4.07378786e-02 -1.01279337e-01
  2.74000120e-02  6.02318895e-03 -7.98762628e-02 -2.06649480e-01
 -1.52478785e-01 -2.82130087e-01 -6.30279492e-01 -1.08202494e+00
  4.42645108e-01 -8.01807077e-02  7.90337926e-01  1.01835355e-01
  1.00398536e+00 -1.66993225e-01  1.09359502e+00 -4.04618932e-01
 -4.70349770e+00]
supnorm grad right now is: 4.703497696723035
Weights right now are: 
[ 0.94491217  0.43560262 -0.20791549  0.86627755 -1.7351314  -0.42113898
  0.77922154  0.5488055  -0.94623304  3.33560115 -0.78825101  3.22348281
  1.65694707  3.60855667  1.52762538  3.87800952  3.04698784 -0.61389891
  3.55186336 -0.41224596  3.44998987  3.57634503  2.92813344  3.73276498
 -1.90710069 -0.79300723 -2.1703754  -1.23300724  3.25638427  2.55865769
  2.16702426  4.5508867  -2.92985488 -0.58537304 -0.88322144 -0.9269319
  2.97503662  0.78206558  2.25452649  1.79750395 -2.3746563   5.07472971
  6.10197192  7.28832708 -1.12439629  3.57237142  4.50530509  4.58698102
 -1.85347943  4.64072639  3.50493358  4.32867734  5.21619513  4.07276879
  1.07429543 -0.61465829  4.19567679  1.84114612  3.50050491 -2.50453452
  1.76401356 -2.15714599  0.44719368 -2.40435794 30.67185429]
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1580.0666596484102
gradient value of function right now is: [ 5.62219538e+00  1.84624717e-01  3.16857529e-01  2.21135228e-02
 -5.62219538e+00 -1.84624717e-01 -3.16857529e-01 -2.21135228e-02
 -5.55168159e+00 -1.00208789e+00 -4.97499155e+00 -2.14052437e+00
 -9.16073058e-02 -1.45818361e-02 -8.09795196e-02 -3.56365995e-02
  3.71357885e-01  1.84351631e-01  3.51296523e-01  2.32086217e-01
 -6.94364525e-03 -1.09685153e-03 -6.23293082e-03 -2.50989680e-03
 -1.04966513e-02 -1.29936164e-01 -2.25550336e-01 -5.50158386e-01
  3.56693166e-02  2.07598014e-01  3.71219351e-01  6.97134887e-01
 -4.15566394e-03 -1.23935499e-01 -2.17176763e-01 -5.42119126e-01
  3.94765797e-02  3.88885443e-01  6.75429421e-01  1.53796658e+00
 -3.84239526e-02 -5.13493665e-02 -9.14091891e-02 -1.75501395e-01
 -1.87193823e-01 -9.54144673e-02 -1.80269659e-01 -3.51349846e-01
 -5.01972007e-01 -2.60094691e-01 -4.93589772e-01 -9.74105703e-01
 -5.55210718e-01 -5.79545781e-01 -1.06142700e+00 -2.21567824e+00
  5.67468987e-01 -1.69581490e-01  1.60818907e+00 -4.52695244e-01
  1.43183683e+00 -6.09677450e-01  1.39291167e+00 -8.77587506e-01
 -2.17301657e+01]
supnorm grad right now is: 21.73016567312256
Weights right now are: 
[ 0.91523828  0.38376982 -0.73291598  0.93771049 -1.70545751 -0.36930618
  1.30422202  0.47737256 -0.93119096  3.54291846 -0.77742981  3.17812942
  2.1425268   3.90006175  2.00252469  4.15221323  3.32199414 -1.26845384
  3.72730558 -0.67956445  3.94501517  4.0347785   3.40208341  4.22673879
 -2.26286266 -0.89479642 -2.47158545 -1.40519909  3.32923596  2.93396654
  2.6912001   5.19824204 -3.35951223 -0.67020193 -1.16332057 -1.0046365
  3.29397429  0.88088806  2.43155199  2.23780385 -2.16719841  5.88008451
  6.81760485  8.16667059 -1.01475151  3.01799481  4.12331185  4.28005753
 -2.03069163  3.50334017  2.60500239  3.56469918  4.43620812  4.4959186
  1.13860877 -0.92390259  4.69220738  0.94227947  3.59450739 -2.92932817
  2.21975155 -2.27391213  0.27291604 -2.27277568 30.51574594]
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1580.163750439369
gradient value of function right now is: [ 9.39253493e+00  1.00723788e-01  3.59470523e-01  8.15225764e-03
 -9.39253493e+00 -1.00723788e-01 -3.59470523e-01 -8.15225764e-03
 -7.33302754e+00 -1.08853292e+00 -6.77383781e+00 -2.14980315e+00
 -3.60456415e-02 -4.14436618e-03 -3.31730586e-02 -9.54221160e-03
  4.06694503e-01  2.20175023e-01  3.86821293e-01  2.84351360e-01
 -9.35834844e-04 -1.47685223e-04 -8.51893252e-04 -3.34978485e-04
 -1.15794993e-01 -1.79414969e-01 -3.13455735e-01 -5.21088791e-01
  1.62180025e-01  2.35460010e-01  4.42135327e-01  6.11211645e-01
 -1.27766305e-01 -1.93804726e-01 -3.37343472e-01 -5.28722747e-01
  2.91988726e-01  4.59563609e-01  8.22871953e-01  1.29978318e+00
 -9.90490323e-01 -2.06334907e-01 -3.10073636e-01 -4.93322733e-01
 -3.77891281e-01 -8.73411723e-02 -1.44152052e-01 -2.65436235e-01
 -8.54819280e-01 -2.01656892e-01 -3.45284653e-01 -6.64468492e-01
 -4.72549188e-01 -4.00241230e-01 -7.57460264e-01 -1.70575352e+00
  7.20987343e-02  7.91507136e-01  1.70706529e+00 -9.59767312e-01
  1.94041871e+00 -1.55287920e+00  2.77053503e+00 -2.55080517e+00
 -2.47426084e+01]
supnorm grad right now is: 24.74260844245867
Weights right now are: 
[ 1.00754157e+00  2.45612288e-01 -7.52670384e-01  7.90598710e-01
 -1.79776080e+00 -2.31148650e-01  1.32397643e+00  6.24484338e-01
 -8.94199039e-01  3.40530612e+00 -8.08714752e-01  3.36999072e+00
  2.82325283e+00  4.21715862e+00  2.64621966e+00  4.84595522e+00
  3.58582837e+00 -1.44491222e+00  3.94752909e+00 -6.95247465e-01
  4.89937790e+00  4.28175217e+00  4.29474838e+00  4.94260306e+00
 -3.54617486e+00 -7.35487930e-01 -2.07541402e+00 -4.53755567e-01
  4.18332718e+00  2.87769706e+00  2.49726815e+00  5.11946219e+00
 -4.69401730e+00 -5.80210337e-01 -7.94835712e-01  1.48840075e-02
  4.71168664e+00  9.97783187e-01  2.27242880e+00  1.82058664e+00
 -2.91194091e+00  6.95275789e+00  7.51600993e+00  8.67833751e+00
 -8.74848932e-01  3.75333052e+00  5.04141370e+00  5.37632922e+00
 -1.91738892e+00  3.74380659e+00  3.21694897e+00  4.46302699e+00
  4.85879780e+00  4.79391672e+00  1.35132433e+00 -8.65758324e-01
  3.88554942e+00  2.14505918e+00  3.60872015e+00 -2.34994053e+00
  2.22949196e+00 -2.34550740e+00  1.01381232e-01 -3.03591158e+00
  3.04783213e+01]
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -1576.9601307121063
gradient value of function right now is: [-1.28601769e+01 -7.18841125e-02 -5.21309918e-01 -6.25788027e-03
  1.28601769e+01  7.18841125e-02  5.21309918e-01  6.25788027e-03
  1.03266826e+01  2.03390946e+00  9.79382069e+00  3.08237279e+00
  4.83110838e-02  8.03582810e-03  4.57399829e-02  1.36559491e-02
 -8.84590950e-01 -3.56355286e-01 -8.16791720e-01 -5.09974108e-01
  3.29888648e-03  7.89303752e-04  3.06050437e-03  1.34020499e-03
  6.93266747e-02  1.01044995e-01  3.44397497e-01  5.08202822e-01
 -2.05730738e-01 -2.66705008e-01 -8.87032332e-01 -9.57828504e-01
  6.60597129e-02  9.80533578e-02  3.38151154e-01  4.92027795e-01
 -2.35516302e-01 -3.27021858e-01 -1.02864581e+00 -1.43827816e+00
  1.19354623e+00  2.40605636e-01  3.07943787e-01  3.71210316e-01
  4.70253124e-01  1.32144845e-01  1.77074637e-01  2.75809554e-01
  1.67525632e+00  5.81713607e-01  7.60063103e-01  1.16770930e+00
  9.64789455e-01  8.82478617e-01  1.36020201e+00  3.16566834e+00
 -7.48198303e-01 -7.94794874e-01 -3.56748480e+00  1.12458426e+00
 -2.76015435e+00  1.67438152e+00 -1.89850665e+00  2.26333961e+00
  3.20746265e+01]
supnorm grad right now is: 32.07462652435657
Weights right now are: 
[ 0.77941026  0.45971566 -1.18343491  1.09863916 -1.56962949 -0.44525202
  1.75474095  0.31644389 -0.65340332  3.80053533 -0.55050541  3.57597872
  3.12930009  4.67230563  2.95174696  5.23791989  3.99689092 -2.49912203
  4.1649936  -1.10024431  5.10721217  4.79724232  4.51338235  5.37555199
 -4.42345344 -0.78311575 -2.22436655 -0.93105192  4.48483063  2.7434923
  2.31953836  5.23173697 -5.71115093 -0.67544536 -0.9300177  -0.47691523
  5.55698966  0.99497452  2.03427223  2.23974528 -3.06961411  8.74294629
  8.70160658  9.24520696 -0.35317436  4.34366217  5.58301986  5.64295645
 -1.4787493   3.44595124  3.10453238  4.20459152  4.25536701  5.47697903
  1.8965252  -0.76734103  3.21319437  2.16882429  3.15157753 -2.43713725
  2.2720201  -2.271481    0.32481945 -2.99720971 30.67678874]
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1579.0282305573985
gradient value of function right now is: [-2.06871140e+01 -3.75908087e-02  1.37110070e-01 -2.32416057e-03
  2.06871140e+01  3.75908087e-02 -1.37110070e-01  2.32416057e-03
  1.34176577e+01  2.46305380e-01  1.23803608e+01  1.34620532e+00
  2.27575416e-02  7.74504212e-04  2.05245828e-02  3.25669720e-03
  1.48574582e-01  1.99943827e-01  1.57885309e-01  1.88530373e-01
  1.40067676e-03  5.49548586e-05  1.20979565e-03  2.81567802e-04
  5.23653931e-02  6.55124686e-02  2.66700101e-01  2.56121502e-01
 -5.78507192e-02 -8.56020774e-02 -4.45775953e-01 -3.72651352e-01
  8.10015005e-02  9.26117171e-02  3.60067540e-01  3.00115129e-01
 -2.29196773e-01 -3.04800095e-01 -1.30772510e+00 -1.16665459e+00
  7.30724619e-01  1.13636758e-01  1.48786764e-01  2.59274472e-01
  1.28556520e-01  3.05302919e-02  4.40477003e-02  1.04544780e-01
  6.32255613e-01  2.07656671e-01  3.14158203e-01  8.06925260e-01
  4.42516068e-01  2.41028062e-01  4.40382454e-01  1.50952161e+00
  2.15677105e-02 -5.99737134e-01 -1.50411104e+00  6.27425478e-01
 -1.47379158e+00  7.79807168e-01 -1.90960490e+00  1.27280712e+00
  2.04114738e+01]
supnorm grad right now is: 20.687114035280473
Weights right now are: 
[ 0.71171306  0.37671245 -1.01009858  1.09693629 -1.5019323  -0.36224881
  1.58140463  0.31814675 -0.57727055  3.29192098 -0.54687964  3.39471373
  3.7450805   4.54152375  3.51799198  5.47892739  4.84472476 -2.53139619
  4.84567661 -0.83891666  5.74823621  4.60343034  5.12231891  5.48992382
 -4.73229068 -0.3041159  -2.16893491 -1.22504736  4.7894257   2.83081984
  3.38404969  5.3392896  -6.41772355 -0.16947533 -0.38736936 -0.69764737
  6.1755602   0.66015068  1.55407358  2.5094191  -3.44789013  9.49829089
  9.40581483 10.0173277  -0.2583274   3.91582182  5.47368191  5.85535181
 -2.48142783  1.42748793  1.50534968  3.23208666  4.4378303   5.59030427
  2.05368195 -0.9624499   3.15149672  2.3468466   3.33894591 -2.18086187
  2.45990932 -2.26565937  0.1808617  -3.27185697 30.64648041]
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1585.928552353986
gradient value of function right now is: [-2.14202340e+00 -3.06949033e-03  2.30196871e-01 -2.36276195e-04
  2.14202340e+00  3.06949033e-03 -2.30196871e-01  2.36276195e-04
  1.25128082e+00 -2.33923327e-01  1.09008854e+00 -9.59059580e-02
  1.30812366e-03 -3.22527057e-05  9.66607793e-04  2.39476836e-04
  4.04724663e-01  3.88506335e-01  3.98859337e-01  4.01646728e-01
  1.33946137e-04 -7.84876093e-06  9.18037484e-05  2.39233877e-05
  7.58694983e-04  1.09342535e-02  3.94031013e-03  1.01079045e-01
  2.57436616e-03 -6.29999313e-03  5.15136474e-02 -4.01271749e-02
 -2.35639547e-03  1.29313213e-02 -3.44989775e-02  1.59986415e-01
  2.24628381e-02 -3.44685230e-02  1.01014731e-01 -4.65430951e-01
 -2.56917947e-01 -6.11501870e-02 -5.91204521e-02 -1.63957090e-02
 -8.01915076e-03 -1.40420189e-03  3.22666105e-04  1.43613264e-02
 -1.50791200e-01 -1.37859507e-01 -1.31062262e-01 -2.25970863e-02
  5.63895967e-02 -3.89205119e-02 -2.27416220e-02  1.94070797e-01
 -2.59186324e-01  2.89417413e-01 -1.09778750e-02 -2.46422865e-01
 -7.65641570e-02 -2.78420759e-01 -2.91815942e-01 -2.83700126e-01
  4.96668112e+00]
supnorm grad right now is: 4.966681123375873
Weights right now are: 
[ 9.27444787e-01  2.89920250e-01 -1.59692308e+00  1.08458661e+00
 -1.71766402e+00 -2.75456612e-01  2.16822912e+00  3.30496441e-01
 -5.88104128e-01  3.34533430e+00 -7.10684584e-01  3.62051665e+00
  4.42958838e+00  4.79357961e+00  4.10898411e+00  6.08933703e+00
  4.96719807e+00 -3.63611923e+00  4.65203938e+00 -1.35650238e+00
  6.55304352e+00  4.90863458e+00  5.87010450e+00  6.00624556e+00
 -5.23360295e+00  9.91912073e-03 -2.05364397e+00 -1.03840786e+00
  5.18089869e+00  2.80457330e+00  4.06740781e+00  5.56718971e+00
 -7.04707882e+00  3.23731984e-01  3.84570274e-01 -2.63710367e-01
  6.77814956e+00  5.42453155e-01  9.67704733e-01  2.46447314e+00
 -3.64008213e+00  1.05641802e+01  1.04838544e+01  1.10301204e+01
  3.73336881e-01  4.61201333e+00  6.18636750e+00  6.61454438e+00
 -2.61427517e+00  1.08015475e+00  1.17107392e+00  3.01798511e+00
  4.87753416e+00  5.54174723e+00  1.97885335e+00 -1.06090210e+00
  2.88632452e+00  2.19844857e+00  3.37741529e+00 -2.16055098e+00
  2.53742762e+00 -2.35184623e+00  2.41754188e-01 -3.42769440e+00
  3.07180144e+01]
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1586.0243811337969
gradient value of function right now is: [ 2.26551593e+00  3.19005453e-03  1.39499577e-01  3.45532681e-04
 -2.26551593e+00 -3.19005453e-03 -1.39499577e-01 -3.45532681e-04
 -2.80324818e+00 -8.80999124e-02 -1.56494562e+00 -7.30996675e-01
 -3.09103110e-03 -9.40298883e-05 -1.87391332e-03 -7.43663247e-04
  2.53928288e-01  2.59203759e-01  2.45872228e-01  2.48732143e-01
 -4.52006572e-04 -1.48000356e-05 -2.74608924e-04 -1.15608876e-04
 -1.39471848e-02 -2.04669166e-02 -1.50248687e-01 -4.02413157e-02
  1.30452227e-02  1.73957775e-02  1.73218257e-01  2.85610485e-02
 -3.81739925e-02 -4.62573437e-02 -3.46810651e-01 -9.93543870e-02
  1.08152552e-01  1.19805905e-01  1.05338141e+00  3.33647920e-01
 -4.64776036e-01 -1.00393099e-01 -1.20823779e-01 -1.71304095e-01
 -3.19745061e-02 -9.45804486e-03 -1.25496586e-02 -2.44622376e-02
 -3.17872629e-01 -1.04348955e-01 -1.14291898e-01 -1.63420987e-01
 -1.51249169e-01  4.41266465e-02  4.84890076e-02  1.04855631e-02
 -2.02803469e-02  3.48675116e-01  2.01592668e-01 -1.00008579e+00
  4.10698012e-01 -8.72883884e-01  8.79003619e-01 -9.24085357e-01
 -4.30118748e+00]
supnorm grad right now is: 4.301187480931639
Weights right now are: 
[ 1.01272780e+00  6.11914993e-01 -1.76300064e+00  1.53224812e+00
 -1.80294704e+00 -5.97451355e-01  2.33430668e+00 -1.17165068e-01
 -5.92521148e-01  3.93804306e+00 -7.11975564e-01  3.69375460e+00
  4.70468163e+00  5.15301536e+00  4.40317375e+00  6.34922990e+00
  5.22515390e+00 -4.21770670e+00  4.57500704e+00 -1.44577419e+00
  6.55461668e+00  5.33558558e+00  6.00728563e+00  6.02014045e+00
 -5.07238793e+00 -5.50225565e-03 -2.27482073e+00 -1.17966671e+00
  5.44664041e+00  3.25139189e+00  4.73313107e+00  5.74301006e+00
 -7.23750683e+00  6.72801169e-01  8.32038010e-01 -2.36976787e-01
  7.16048999e+00  9.06304210e-01  1.07512587e+00  2.75223463e+00
 -3.63607656e+00  1.10150017e+01  1.10896678e+01  1.16428259e+01
  1.06073930e+00  5.17265806e+00  6.71016641e+00  6.82116884e+00
 -2.61581499e+00  1.22489580e+00  1.25159351e+00  2.99205922e+00
  5.20714658e+00  5.99148747e+00  2.27623535e+00 -9.23320955e-01
  3.54169973e+00  1.76651269e+00  3.15280424e+00 -2.71110445e+00
  2.48701465e+00 -2.68365749e+00  6.21563102e-01 -3.23807064e+00
  3.06452015e+01]
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1584.5273614830858
gradient value of function right now is: [ 1.00793727e+00 -2.04679445e-04 -8.59427870e-02 -4.39998820e-05
 -1.00793727e+00  2.04679445e-04  8.59427870e-02  4.39998820e-05
  9.79142588e-01  1.30305208e-01 -4.69858254e-01  1.08400593e+00
  4.92400934e-06  7.61284383e-07 -9.24999044e-08  5.94561325e-06
 -2.85216998e-01 -4.00483038e-02 -1.60176413e-01 -1.65503598e-01
  1.73907476e-06  1.42211815e-07  6.58903303e-07  1.04908688e-06
 -1.09517243e-02 -1.86850378e-02  1.68294870e-01  4.76930784e-02
 -2.97478299e-03  1.50804446e-03 -2.04422319e-01 -6.50016420e-02
 -7.20566779e-03 -1.07349635e-01  5.76497334e-01 -8.51364221e-02
 -7.20715615e-02  9.42319229e-02 -2.13317420e+00  3.06286741e-02
  1.31210027e+00  2.22989597e-01  2.19098705e-01  1.28634529e-02
  2.18764249e-02  5.43395495e-03  5.23041560e-03  1.90868236e-03
  3.47024862e-01  2.45404580e-01  2.80305593e-01  4.22563167e-01
  4.03489245e-02  1.12023908e-01  1.37531501e-01  3.05736357e-01
 -2.83829389e-01 -6.15206108e-01 -1.83073385e-01  1.53215950e+00
  1.47683069e-01  1.68475677e+00  9.41160286e-01  6.63676344e-01
  1.80210598e+01]
supnorm grad right now is: 18.02105982396704
Weights right now are: 
[ 1.09471568e+00  3.59635506e-02 -2.12396028e+00  7.42945485e-01
 -1.88493492e+00 -2.14999126e-02  2.69526632e+00  6.72137563e-01
 -4.17032107e-01  4.29939689e+00 -8.78940155e-01  4.00981533e+00
  6.22143765e+00  5.39206584e+00  5.62820722e+00  7.44449936e+00
  5.05760267e+00 -4.77964137e+00  4.23498316e+00 -1.71345934e+00
  8.34997022e+00  5.59734264e+00  7.61475265e+00  7.29392112e+00
 -5.62442385e+00  5.67016755e-01 -2.59779232e+00  2.02249410e-01
  5.68275742e+00  3.37651698e+00  5.55171841e+00  6.16424750e+00
 -7.98306862e+00  9.18883817e-01  1.22047343e+00  1.19740490e+00
  7.63946216e+00  1.26286626e+00  7.83298257e-01  2.07040854e+00
 -3.24687955e+00  1.21036184e+01  1.19126172e+01  1.17535464e+01
  2.08331301e+00  5.01701966e+00  6.51278767e+00  6.57056728e+00
 -3.12578596e+00  1.50048987e+00  1.25189573e+00  2.51166947e+00
  4.56836876e+00  6.03097267e+00  2.41177858e+00 -6.65279412e-01
  3.28892508e+00  2.20112843e+00  3.84905305e+00 -2.18598753e+00
  3.27115318e+00 -2.13892804e+00  1.65835749e+00 -3.21556520e+00
  3.08027764e+01]
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1586.4808767951783
gradient value of function right now is: [-4.95563869e-01  1.15266947e-03 -1.61564532e-02  1.96999134e-04
  4.95563869e-01 -1.15266947e-03  1.61564532e-02 -1.96999134e-04
 -2.97892343e-01  4.37757251e-03  5.76468500e-01 -2.05812842e-01
 -1.56241506e-03 -3.25482664e-05 -7.54317378e-04 -3.13769527e-04
 -8.36898266e-02 -2.76142350e-02 -4.65040580e-02 -7.95354746e-02
 -4.04748740e-04 -9.18992848e-06 -1.98550489e-04 -8.58317362e-05
 -4.61920337e-03 -1.20641997e-02  3.18362848e-02 -1.32856276e-01
  1.54237205e-03  6.63512546e-03 -1.28228602e-01  1.41094435e-01
 -1.24148758e-02 -5.19298132e-02 -1.16474041e-02 -3.09733363e-01
  3.35978899e-02  9.14196473e-02 -1.89815082e-01  8.36903237e-01
  1.96906180e-01  4.77958872e-02  2.97331085e-02 -9.82502515e-02
  1.36914690e-03 -2.25983636e-04 -9.07941267e-04 -6.32401030e-03
  4.62619364e-01  2.86220961e-01  2.78900357e-01  1.11452187e-01
 -1.14457344e-01 -1.26172134e-01 -2.22776535e-01 -9.43380874e-01
  1.88084730e-01 -1.72921035e-02  8.20338797e-01  6.26551780e-01
  7.25363438e-01  4.87323514e-01  9.32882986e-01 -1.26354597e-01
 -1.49989616e+00]
supnorm grad right now is: 1.4998961630757544
Weights right now are: 
[ 0.97165274  0.87903524 -2.19308782  2.04414532 -1.76187197 -0.8645716
  2.76439386 -0.62906227 -0.37228084  4.85508293 -0.78066545  4.18391452
  6.04055038  5.78239057  5.85699883  7.71306342  5.32142505 -5.09825141
  4.23982244 -1.7219118   7.59956658  5.89907947  7.56588913  7.22422395
 -4.28722324  1.08433127 -3.02708396 -1.11475091  6.25822521  3.41163859
  5.51138686  6.6531082  -7.66797507  2.01476625  1.42283988  0.62428638
  7.58542037  1.1135618   1.05354687  2.91374076 -3.85071267 11.67529605
 11.65411608 12.22195316  2.4490221   5.2564438   6.94086151  7.72922531
 -2.55576173  1.72670806  1.41908994  2.35665586  6.10304051  6.45679347
  2.72505949 -0.99012182  3.6005017   2.61148891  4.20658352 -2.04590548
  3.5002642  -2.21604334  1.00510157 -2.86175199 30.55603951]
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1584.0167563324712
gradient value of function right now is: [ 7.46630681e+00  2.49735084e-03  1.90609900e-01  5.95203595e-04
 -7.46630681e+00 -2.49735084e-03 -1.90609900e-01 -5.95203595e-04
 -9.15948510e+00 -2.34675396e-01 -3.69831711e+00 -1.73711457e+00
 -5.46035873e-03 -8.82056919e-05 -1.85673805e-03 -9.45344645e-04
  5.16329105e-01  2.86094814e-01  3.65162193e-01  3.53901385e-01
 -1.96410199e-03 -3.62283136e-05 -6.52902641e-04 -3.66381144e-04
 -2.11585741e-02 -2.52852987e-02 -3.06926500e-01 -1.35994995e-01
  1.33309665e-02  1.68973580e-02  4.13667447e-01  1.41151706e-01
 -1.61066131e-01 -1.07903629e-01 -1.04218209e+00 -3.43900482e-01
  2.08673680e-01  2.00165633e-01  2.68891836e+00  9.73356501e-01
 -9.32626665e-01 -1.93792823e-01 -2.08646380e-01 -3.73634505e-01
 -5.72503865e-03 -6.72682626e-03 -9.26877229e-03 -2.40660182e-02
 -6.61523051e-01 -5.44615775e-01 -6.30369918e-01 -1.09820074e+00
 -2.08302975e-01 -1.81059182e-01 -2.80773883e-01 -8.88677282e-01
 -2.50819125e-01  9.70028598e-01  1.31002020e+00 -1.00057146e+00
  1.24127451e+00 -1.03400398e+00  2.02808418e+00 -1.76233738e+00
 -1.79022561e+01]
supnorm grad right now is: 17.902256135758186
Weights right now are: 
[ 1.09410041  1.27101894 -2.18752806  2.62844734 -1.88431964 -1.2565553
  2.7588341  -1.2133643  -0.47433866  5.12919822 -0.90013796  4.519443
  6.05197838  6.58242478  6.46184939  7.98813091  5.78687789 -5.37811893
  4.34977377 -1.59025741  7.32232928  6.35306265  7.99100173  7.34483952
 -3.89715094  1.07259957 -3.37559809 -1.35603688  6.73074181  3.49004667
  5.95311416  6.38748659 -7.29457078  2.61288009  1.9862211   0.9663452
  7.86571216  1.53308789  1.38780553  2.8332049  -4.27037585 11.02967581
 11.23092212 12.40420496  1.92186259  4.783551    6.63895207  7.90323798
 -2.75513451  1.39143651  0.98677719  2.02297976  7.16151896  6.44995328
  2.77308338 -0.62920466  4.2590482   2.13871218  4.07742976 -2.27103864
  3.27371691 -2.58246815  0.93979761 -3.01080462 30.56757746]
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -1585.5923478677005
gradient value of function right now is: [ 4.46262615e+00 -2.74564923e-04  1.97953064e-01 -1.29951045e-04
 -4.46262615e+00  2.74564923e-04 -1.97953064e-01  1.29951045e-04
 -3.86260272e+00 -1.83552275e-01 -2.67024089e+00 -7.03734064e-01
  4.44929601e-04 -5.54097586e-06  2.60336018e-05  4.46620753e-05
  4.32286671e-01  3.55658522e-01  3.88433335e-01  3.91740377e-01
  3.77753832e-04 -4.63919502e-06  2.96961592e-05  3.78254400e-05
 -1.24670123e-02  3.29073208e-03 -1.12601157e-01  1.20607709e-02
  5.42871652e-03  4.64912363e-03  1.92779763e-01  5.15461916e-02
 -1.08064048e-01 -1.08357815e-02 -5.27526845e-01  1.26743082e-02
  9.74540883e-02 -8.95140690e-03  9.96070372e-01 -6.43927054e-02
 -7.28192247e-01 -1.45657073e-01 -1.42451823e-01 -1.37733106e-01
  1.31324298e-02 -7.67352102e-04 -1.46914497e-03  1.51235903e-03
 -3.60514122e-01 -3.39504356e-01 -3.99892721e-01 -5.07305902e-01
 -6.18339043e-02 -7.88044747e-02 -1.12509529e-01 -1.59652873e-01
 -3.07642859e-01  8.67933276e-01  5.34451818e-01 -8.64844864e-01
  4.31684766e-01 -9.20008370e-01  2.18329719e-01 -1.13043898e+00
 -4.77345613e+00]
supnorm grad right now is: 4.773456129592608
Weights right now are: 
[ 1.16743871  1.00451485 -1.90987172  2.47958849 -1.95765794 -0.99005121
  2.48117776 -1.06450544 -0.39131083  4.87936482 -1.19409721  4.58197067
  7.33456844  7.40807622  8.50871732  8.70216926  6.2675679  -5.11266872
  4.72116055 -1.22832962  8.2245272   6.88953532  9.86131426  7.90079444
 -2.8546452   1.92802571 -2.92079867 -1.38413116  6.41393428  4.06957361
  6.36693977  6.33627221 -8.23283642  3.50022194  2.30205276  1.84160325
  7.27625623  1.65689112  1.65890589  2.1417938  -4.48783901 11.2489552
 11.73488032 12.93382359  2.77397266  3.58722382  5.38888437  7.39341325
 -2.65816905  1.75893164  1.1950459   2.14608671  6.93336267  5.7562594
  2.36533042 -0.28238258  4.88854762  2.32783279  4.23369685 -1.95743059
  3.0527711  -2.39033978  1.06116889 -2.92264737 30.60116623]
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1584.7109528601645
gradient value of function right now is: [ 5.02228177e+00 -3.18170587e-04  1.28575929e-01 -1.82142871e-04
 -5.02228177e+00  3.18170587e-04 -1.28575929e-01  1.82142871e-04
 -5.00365007e+00 -2.04802917e-01 -2.59928656e+00 -9.79582935e-01
  4.58418029e-04 -7.15813246e-06  1.53256070e-05  1.21558370e-05
  2.73713062e-01  2.02538918e-01  2.29825786e-01  2.31972162e-01
  4.93358513e-04 -7.67861291e-06  2.36925234e-05  1.37819338e-05
 -1.09165355e-02  5.56560774e-03 -1.65689929e-01  2.07054925e-02
  3.26633925e-03  9.02156542e-03  2.81681051e-01  3.64724065e-02
 -8.38760576e-02 -2.49549043e-02 -6.76366671e-01  3.76164141e-03
  6.46286047e-02  5.18973062e-03  1.66902676e+00 -3.69549973e-02
 -5.76233170e-01 -1.17003790e-01 -1.14215455e-01 -1.10711302e-01
 -4.19374740e-03 -9.56230569e-03 -1.24097023e-02 -1.33919744e-02
 -7.82537978e-01 -5.55811373e-01 -6.45722462e-01 -7.80504504e-01
 -6.20891162e-02 -6.57768598e-02 -8.69775423e-02 -9.93798818e-02
 -5.15239800e-01  8.00632477e-01  6.02434744e-01 -7.03238062e-01
  4.83796247e-01 -7.67655177e-01  4.32269910e-01 -9.73280406e-01
 -5.62443730e+00]
supnorm grad right now is: 5.624437296379119
Weights right now are: 
[ 1.10351062e+00  9.83510903e-01 -1.73274264e+00  2.51943286e+00
 -1.89372986e+00 -9.69047265e-01  2.30404869e+00 -1.10434981e+00
 -3.68892966e-01  5.35329155e+00 -1.17125817e+00  4.63582625e+00
  7.82797457e+00  7.79894070e+00  9.29076642e+00  8.57860809e+00
  6.66664940e+00 -5.03318953e+00  4.92348534e+00 -1.00220715e+00
  8.54205412e+00  7.23721840e+00  1.05840330e+01  7.55666348e+00
 -2.81675041e+00  2.44727676e+00 -2.76041370e+00 -1.27134196e+00
  6.60352768e+00  4.56301402e+00  6.78939753e+00  6.08517332e+00
 -9.36479040e+00  3.12533501e+00  2.51868277e+00  2.13575999e+00
  6.94889252e+00  1.98464022e+00  2.11757918e+00  2.17859503e+00
 -4.35639776e+00  1.17131877e+01  1.23460121e+01  1.34850879e+01
  2.83136929e+00  2.82347271e+00  4.62422938e+00  6.46417420e+00
 -2.92677829e+00  1.75752794e+00  1.12197382e+00  2.13193518e+00
  7.10240455e+00  5.77808584e+00  2.39726246e+00  7.37778105e-03
  4.40056223e+00  2.86110182e+00  4.14978951e+00 -1.61521800e+00
  2.93315934e+00 -2.25246163e+00  1.28536875e+00 -2.90763972e+00
  3.06804816e+01]
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1585.7114867368907
gradient value of function right now is: [ 6.97493069e+00  9.25916399e-04 -3.35490076e-01  5.49661855e-04
 -6.97493069e+00 -9.25916399e-04  3.35490076e-01 -5.49661855e-04
 -7.75746235e+00 -1.59130865e-02 -2.47053254e+00 -1.10784664e+00
 -2.46664927e-03 -1.38217748e-05 -5.45504569e-04 -3.31268143e-04
 -8.13497110e-01 -7.62382389e-01 -8.29863454e-01 -8.47254573e-01
 -2.31399675e-03 -1.41521798e-05 -5.05805622e-04 -3.27434467e-04
 -2.38674154e-02 -5.05889286e-02 -1.12400823e-01 -1.06578532e-01
  5.88569728e-03  1.58860315e-02  3.94920747e-02  4.41861091e-02
 -1.50499586e-01 -1.81096333e-01 -8.21786547e-01 -3.95404662e-01
  1.79508085e-01  3.50088554e-01  2.05673675e+00  1.10896570e+00
 -6.72539689e-01 -1.55710762e-01 -2.12997468e-01 -2.91707064e-01
 -3.60370085e-03 -1.10955297e-02 -2.05756323e-02 -3.52317116e-02
 -2.06083803e-01  2.72936566e-01  2.77007673e-01  2.21790846e-01
 -5.30450534e-02  1.75942724e-02 -2.86517603e-02 -1.38559199e-01
 -2.87774114e-01  8.54647246e-01  6.67566069e-01 -1.47543845e+00
  1.27545493e+00 -1.42639604e+00  2.11589745e+00 -1.65849127e+00
 -1.05502633e+01]
supnorm grad right now is: 10.550263262665087
Weights right now are: 
[ 1.0154344   1.57809287 -2.65690399  3.1904245  -1.80565364 -1.56362923
  3.22821003 -1.77534145 -0.38274926  5.67355227 -1.19357302  5.19878735
  7.45545208  8.18454201  9.43550818  8.68716918  6.20203983 -6.27725757
  4.02907845 -1.85147731  7.98712114  7.49529057 10.54467867  7.50669598
 -2.93226681  2.3820313  -3.24749794 -1.84705488  6.20088025  3.43171761
  7.0093286   6.69412627 -9.72474117  2.85954025  2.57981488  1.63875413
  7.23159117  2.03314331  1.93160421  2.04994755 -4.79681884 11.3410135
 12.41772192 13.61233573  2.47715924  4.086851    6.15108335  7.64890322
 -2.99016134  2.14704064  1.44474653  2.2262519   7.71245279  5.7358506
  2.26160684 -0.07983859  5.91649172  2.64000507  3.95064568 -2.37461408
  2.81169462 -2.52630651  1.76392757 -2.79630511 30.53602634]
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1581.9262025336636
gradient value of function right now is: [-9.64361925e+00 -2.25902423e-03  1.81417188e-01 -1.61380411e-03
  9.64361925e+00  2.25902423e-03 -1.81417188e-01  1.61380411e-03
  1.36860929e+01  1.10610668e-02  1.85480819e+00  1.78744087e+00
  3.78540080e-03  1.17259387e-05  3.94079289e-04  4.66554600e-04
  3.27685891e-01  4.50894011e-01  4.55724456e-01  4.51841128e-01
  5.02724684e-03  1.69788433e-05  5.07878311e-04  6.50166797e-04
  1.29141289e-02  2.83434335e-02  1.07217863e-01  3.39840070e-02
 -8.39390647e-03 -1.99197025e-02 -1.66357644e-01 -6.71951910e-03
  5.91084681e-01  2.85421159e-01  2.09256824e+00  2.30863861e-01
 -4.28399939e-01 -5.71840426e-01 -5.24110985e+00 -8.12748535e-01
  4.10801812e+00  7.50938837e-01  6.53812370e-01  6.12633674e-01
  3.44608999e-02  4.30595272e-02  5.87773557e-02  9.83008671e-02
  4.85174276e-01  1.13036759e-01  1.20819348e-01  1.83262423e-01
  1.05318366e-01  1.73126123e-03  1.64976951e-02  1.08136933e-01
  9.89873258e-01 -2.87396894e+00 -1.62104321e+00  6.51444242e+00
 -1.91319810e+00  5.79343714e+00 -2.77107460e+00  5.35867799e+00
  1.53811674e+01]
supnorm grad right now is: 15.381167383448917
Weights right now are: 
[ 0.96770164  1.0515528  -2.03410215  2.62179346 -1.75792087 -1.03708916
  2.6054082  -1.20671041 -0.07940432  5.932062   -1.49665747  5.51768164
  8.40207363  8.38844599 10.30325035  9.02635911  7.00866433 -5.73699754
  4.68637338 -1.17417305  8.8591868   7.70055943 11.34335949  7.76562517
 -2.68465157  3.56162783 -3.14071832 -1.55816144  6.7990597   3.17499142
  7.26021592  6.85717348 -9.76503865  3.43583681  3.71056725  2.2460136
  7.63987829  2.42402877  1.67124525  2.35050542 -4.12150795 12.35710457
 13.21982175 14.34922617  1.67077851  3.53094102  5.3827      6.68859517
 -2.98052558  2.10251846  1.29273833  1.93894989  7.74019449  5.56594577
  1.97987131 -0.52191602  5.11239943  2.78298727  4.17779802 -1.66147683
  3.1368367  -2.14398658  1.73685425 -2.75185085 30.43483315]
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1582.8941576988414
gradient value of function right now is: [ 5.95529542e+00  6.19331974e-04  2.01313215e-01  4.80222698e-04
 -5.95529542e+00 -6.19331974e-04 -2.01313215e-01 -4.80222698e-04
 -6.88340214e+00 -5.46791215e-02 -1.13250953e+00 -7.41922835e-01
 -8.93785429e-05 -2.93535224e-07 -1.54972306e-05 -7.75948570e-06
  4.68361911e-01  3.55813707e-01  3.80037308e-01  3.74264589e-01
 -6.02346297e-04 -2.21219441e-06 -1.02975658e-04 -5.57889789e-05
 -2.50973197e-02 -7.70825897e-02 -1.64820059e-01 -1.17259439e-01
  3.68299594e-03  2.57908512e-02  8.22239039e-02  7.01803713e-02
 -2.18288074e-01 -4.03616553e-01 -8.47162597e-01 -4.71852399e-01
  1.20388862e-01  4.90800763e-01  1.32935387e+00  8.59031657e-01
 -6.56251443e-01 -1.39043289e-01 -1.76981961e-01 -2.50589939e-01
 -2.34207399e-02 -3.94720112e-02 -6.02219466e-02 -9.55666368e-02
 -2.45311215e-02 -9.80538737e-02 -1.48006195e-01 -2.32384994e-01
 -7.69495099e-02 -1.40310058e-01 -2.22296363e-01 -3.70034655e-01
 -2.35073869e-01  6.07104148e-01  1.10019039e+00 -7.07457498e-01
  1.41660028e+00 -9.00252243e-01  2.09272071e+00 -1.17700133e+00
 -2.39851386e+01]
supnorm grad right now is: 23.985138588065997
Weights right now are: 
[  0.95088883   0.09250266  -1.99193554   1.51780315  -1.74110806
  -0.07803902   2.56324159  -0.1027201   -0.14711153   6.44517819
  -1.33876504   5.49730753   9.93934561   8.35750285  10.94677417
   9.95632508   7.24621532  -5.79604042   4.72403638  -1.09343587
  10.26843985   7.53959602  11.82774753   8.38821404  -2.98886498
   3.79208502  -3.00096876  -1.87656914   7.24983384   4.03692819
   7.48731104   7.02973954 -10.44066448   2.59929893   3.76108734
   1.45220946   7.98586758   2.95192271   2.03792719   2.55773544
  -4.12744848  12.40196564  13.45538118  14.52855057   0.36452314
   2.57681155   4.59187253   6.29283254  -2.86317112   2.84480949
   1.84938595   2.29743233   7.34521563   5.35294797   2.04685538
  -0.34545602   5.57642693   2.53486771   4.23809939  -2.38060047
   3.27150497  -2.65241628   2.19702519  -2.96941419  30.32715399]
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1582.934671863856
gradient value of function right now is: [ 7.06692061e+00  5.25033537e-04  2.29117575e-01  8.03816678e-04
 -7.06692061e+00 -5.25033537e-04 -2.29117575e-01 -8.03816678e-04
 -6.94559611e+00 -4.93342024e-02 -1.82625624e+00 -8.02833573e-01
 -8.05063611e-04 -1.51166384e-06 -1.10076886e-04 -6.80677764e-05
  5.80829822e-01  4.41646145e-01  4.57085338e-01  4.58492545e-01
 -2.10394289e-03 -4.90741726e-06 -2.81350383e-04 -1.95096364e-04
 -2.81150177e-02 -5.98474945e-02 -1.78859583e-01 -7.45592158e-02
  1.38915421e-03  1.04171803e-02  9.71738575e-02  2.30831187e-02
 -2.60440526e-01 -2.91643388e-01 -9.02851502e-01 -2.72412899e-01
  9.28983327e-02  3.24750974e-01  1.66532135e+00  6.03992561e-01
 -8.61635638e-01 -1.42211473e-01 -1.80084257e-01 -2.25943794e-01
  5.89646341e-02 -1.62127075e-02 -2.56280694e-02 -3.23670575e-02
 -2.25658077e-01 -2.93350011e-01 -3.35702643e-01 -3.83852512e-01
 -5.17043894e-02 -6.51976157e-02 -9.83237250e-02 -1.39686379e-01
 -5.11692536e-01  8.68334469e-01  7.31147798e-01 -9.79548502e-01
  1.08326919e+00 -1.07802098e+00  1.46181340e+00 -1.30055718e+00
 -2.30293274e+01]
supnorm grad right now is: 23.029327390587113
Weights right now are: 
[  0.93825545   1.01235019  -2.36739491   2.42668743  -1.72847469
  -0.99788655   2.93870095  -1.01160439  -0.10638295   6.24499188
  -1.523442     5.54729239  10.33835535   8.46184406  11.85068042
  10.33195425   7.15608978  -6.42392589   4.26792583  -1.48183812
   9.94310685   7.59442381  12.03755251   8.14731613  -1.5738729
   4.64719459  -2.94481313  -1.86438824   6.73374109   3.69231838
   8.42225362   7.14721822 -10.80751458   2.89009106   4.00088117
   1.96692997   8.31199042   2.55400294   2.28108924   2.33307852
  -4.54227599  12.58983034  13.77430738  14.84996051   0.44999882
   3.11532461   5.21852505   6.82529876  -3.39000286   2.34772243
   1.30973335   1.82168443   7.555814     4.98353394   2.02763487
  -0.11959349   5.74598448   3.044237     3.96461415  -2.99364508
   2.84823189  -3.25306924   2.17125216  -3.28051816  30.3401325 ]
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1585.5166873914857
gradient value of function right now is: [ 1.91873714e+00 -1.38644475e-06  1.00051565e-01 -5.12621734e-05
 -1.91873714e+00  1.38644475e-06 -1.00051565e-01  5.12621734e-05
  4.00589907e-01  6.78423415e-02 -9.40433646e-01  6.55954941e-01
  2.24732897e-05  1.20650747e-06 -2.47036207e-05  3.27120475e-05
  1.83822056e-01  2.67223087e-01  2.44498695e-01  2.28397271e-01
  2.03263225e-04  4.04688648e-06 -2.46220796e-05  1.02072101e-04
  1.38456643e-02  1.27188265e-02  5.40960263e-02  2.24699092e-02
 -2.68674607e-04 -9.08568654e-03 -1.13964260e-01 -4.59768272e-02
 -2.06951671e-01 -2.17189269e-01 -1.99471813e-01 -1.21526388e-01
  7.23750058e-03 -1.40643880e-01 -1.13677820e+00 -3.26305556e-01
 -3.13414883e-01 -4.24439652e-02 -5.37601180e-02 -6.22545616e-02
  1.24009227e-01  5.13195728e-02  6.51769181e-02  7.61935956e-02
  3.85932992e-01  2.77654372e-01  3.61315834e-01  4.22867473e-01
  3.91932910e-02  1.09367721e-01  1.66057566e-01  2.11250199e-01
 -1.25568041e-01  2.06996279e-01 -4.12975086e-01 -4.94048799e-01
 -1.52498460e-01 -5.20333219e-01 -3.22943269e-02 -5.22534089e-01
  8.75864441e+00]
supnorm grad right now is: 8.758644406832262
Weights right now are: 
[  1.01438477   1.49628461  -1.98952348   2.84180568  -1.80460401
  -1.48182097   2.56082952  -1.42672263   0.06809676   6.66591547
  -1.80345884   6.00014957  10.54892949   8.54909079  11.86334668
  10.46097226   7.65386741  -6.00186724   4.72149594  -1.03256247
  10.08901822   7.85219252  12.10068699   8.26080721  -1.29449077
   4.21378443  -2.80124254  -1.52292678   6.20074252   3.47461209
   8.77987924   7.11365432 -11.45000161   2.30608816   4.06995237
   1.58491046   8.36352754   2.51515935   2.01147379   1.95797953
  -4.28007765  13.25046872  14.22699075  15.08940825   0.12314467
   3.43829669   5.50346449   7.19811464  -3.03726986   2.71076908
   1.51528979   1.99574786   7.52664541   5.49721529   2.40853048
   0.28770886   5.93205998   2.61212655   3.87283537  -2.82088345
   3.16353919  -3.00176039   2.72278997  -3.14701874  30.62295187]
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1585.2874613043912
gradient value of function right now is: [-5.78643478e+00 -2.26262827e-03  1.16158940e-01 -3.74505070e-03
  5.78643478e+00  2.26262827e-03 -1.16158940e-01  3.74505070e-03
  5.15968943e+00  4.33185796e-02  1.46252690e+00  6.88744017e-01
  6.94777093e-03  1.38502218e-05  1.12368593e-03  5.93740475e-04
  2.02219102e-01  3.48211794e-01  3.21345709e-01  3.16999740e-01
  1.51425955e-02  4.01105793e-05  2.31032343e-03  1.51342021e-03
  1.34434280e-02  3.11734493e-02  9.35822434e-02  2.63526234e-02
 -1.84012520e-03 -1.16520065e-02 -1.08755938e-01 -1.22974346e-02
  2.87769713e-01  2.94889971e-01  7.86980283e-01  1.84072880e-01
 -1.01550552e-01 -2.99356779e-01 -1.73590780e+00 -1.58585710e-01
  1.18859406e+00  1.76289802e-01  2.08818274e-01  2.28850788e-01
  6.56595478e-02  3.82143595e-02  4.39514142e-02  4.66339415e-02
  4.75928512e-01  2.50150664e-01  2.94907889e-01  3.20531540e-01
  3.64635667e-02  1.75781023e-02  3.70975587e-02  5.25809803e-02
  5.71523738e-01 -1.06235184e+00 -6.91147110e-01  1.52300945e+00
 -9.06022463e-01  1.77465147e+00 -1.14487100e+00  2.01884113e+00
  1.17871114e+01]
supnorm grad right now is: 11.787111437224073
Weights right now are: 
[  0.88315219   2.46119933  -1.94564105   3.89962281  -1.67337143
  -2.44673569   2.51694709  -2.48453976   0.07554939   6.71932398
  -1.58552086   6.020678     9.84526812   9.02414276  12.50640258
   9.95184377   7.85509509  -6.17609561   4.61535852  -1.05536308
   9.23499387   8.71380359  12.55797599   7.69713743  -0.88287799
   4.57757107  -2.24884583  -1.56780952   5.18639381   2.99007303
   8.91231145   8.16143791 -11.45646966   2.91426946   4.62652811
   2.27742672   8.80767433   2.56453983   2.15701752   2.3152741
  -4.65349597  13.70046447  14.8989923   15.84013869   0.08738314
   3.32544474   5.23054379   6.89558814  -2.67052603   3.26029867
   1.64678126   1.89334567   8.77857829   5.23186519   1.88392384
  -0.35787013   6.24575753   3.22264253   4.2953834   -2.36807582
   3.25575918  -2.45617356   2.65614726  -2.56463825  30.5573877 ]
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1581.3473562308104
gradient value of function right now is: [ 1.84326137e+00  2.36113086e-03  2.97793915e-01  3.98445254e-03
 -1.84326137e+00 -2.36113086e-03 -2.97793915e-01 -3.98445254e-03
 -4.28838584e+00 -5.59295405e-02  7.14385429e-01 -7.65114723e-01
 -1.28165435e-02 -8.54291570e-06 -1.14292381e-03 -9.88756422e-04
  8.30500152e-01  5.29806030e-01  6.17569780e-01  6.44361807e-01
 -2.59149417e-02 -2.42427993e-05 -2.24153855e-03 -2.22922904e-03
 -1.40938269e-02  8.64316303e-03 -6.37263576e-02 -8.72911701e-03
  1.33713943e-04  2.02595886e-03  1.11445014e-01  3.60666532e-02
 -2.11308422e-01 -2.54261136e-01 -6.64062358e-01 -2.20955042e-01
  4.21701426e-02  2.60287753e-01  1.61895246e+00  6.14518842e-01
 -5.54575355e-01 -7.46045665e-02 -1.16182105e-01 -1.36759071e-01
  3.16169028e-02 -3.03498278e-02 -5.19578443e-02 -6.73399560e-02
 -2.54878813e-01 -7.88831502e-01 -9.89233405e-01 -1.10752282e+00
 -2.34349987e-02 -1.97555895e-01 -2.98146065e-01 -3.61911930e-01
 -6.03215202e-01  6.19183904e-01  9.98657862e-01  2.49192348e-01
  1.09657421e+00 -3.92163274e-01  1.27208924e+00 -6.21125105e-01
 -2.58222522e+01]
supnorm grad right now is: 25.82225219393192
Weights right now are: 
[  0.75996914   3.5557365   -2.59804863   4.93196524  -1.55018838
  -3.54127286   3.16935467  -3.5168822    0.19404233   6.25563822
  -1.40959615   6.19721509   8.78848279   9.48031107  11.6282414
   9.92719848   7.56011778  -7.25818186   3.83013588  -1.72147436
   8.28445268   9.4500413   11.73475942   7.71510659  -1.37234184
   4.54673272  -3.04685381  -1.9344738    4.82323417   3.43939048
  10.60582882   8.97075136 -12.20738074   2.74407607   4.64504204
   2.36283175   9.41758895   2.63870208   2.59845821   1.87963487
  -5.05906633  13.94399784  15.11346713  16.02191443  -0.36578108
   3.00315159   5.06731927   6.83305847  -3.82834957   2.85552178
   0.96634429   1.11372165   8.7023844    5.28910863   1.77690129
  -0.46546849   5.48898318   3.54597685   4.93074306  -2.28461577
   3.5898844   -2.48376975   3.00645356  -2.72357643  30.25300985]
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1586.105122837431
gradient value of function right now is: [ 4.15447989e+00  3.03436739e-02 -1.09452715e-01  3.41199056e-02
 -4.15447989e+00 -3.03436739e-02  1.09452715e-01 -3.41199056e-02
 -3.63234557e+00 -3.06688316e-04 -6.56486032e-01 -3.53425763e-01
 -1.93067561e-01 -4.81950575e-05 -1.12218009e-02 -1.03131722e-02
 -2.19606795e-01 -3.15136306e-01 -3.21599435e-01 -3.48808236e-01
 -2.32471970e-01 -6.50897153e-05 -1.44326418e-02 -1.31679208e-02
  2.65337768e-02  1.56237511e-01  2.67309191e-01  2.25219754e-01
  4.17143975e-04  2.45480756e-03 -3.02383168e-02  4.61596778e-03
  8.40457304e-02  8.63396870e-02  6.52893284e-02  5.18736971e-02
  8.56529446e-02  4.13846852e-01  1.01535950e+00  7.52837576e-01
 -1.22396672e-01 -3.41666130e-02 -5.89271541e-02 -7.02164676e-02
 -2.52274904e-02 -5.01404895e-02 -1.14943542e-01 -1.51797583e-01
  1.14622291e-02  1.99886395e-01  1.67620501e-01  1.41502690e-01
 -3.55301491e-02 -1.98638979e-02 -9.61743066e-02 -1.42549136e-01
  9.42701463e-02  1.27690296e-01  5.17343009e-01 -3.70800542e-01
  9.28768666e-01 -2.42774867e-01  1.13468817e+00 -2.85883530e-01
  1.58920707e+00]
supnorm grad right now is: 4.154479891655908
Weights right now are: 
[  1.05062002   5.09092736  -2.56762962   6.14820079  -1.84083925
  -5.07646372   3.13893566  -4.73311774  -0.13163484   8.080624
  -1.52915996   7.03294446   7.38009074  10.09386402   8.77963908
  10.96647377   7.72937425  -7.48700657   3.58471727  -1.83179958
   7.27689403  10.54018032   9.20873428   8.69085173   0.43393599
   4.93624723  -3.03726478  -1.52801842   4.61413395   3.30210803
  10.54648579   8.96625325 -11.73981307   2.97578253   5.18753664
   2.64075869   9.49640887   2.84974447   2.35191383   2.34753873
  -5.28126812  13.76564059  15.1990132   16.22656242  -0.87560714
   4.12988429   5.23088266   6.63305668  -3.3478175    3.32129814
   1.24841442   1.34493753   9.62989358   5.7349405    1.97548308
  -0.32206024   6.31633064   3.26462069   4.90236613  -2.16299464
   3.36932901  -2.45608392   2.82793608  -2.73090421  30.73461205]
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1584.355243420926
gradient value of function right now is: [ 5.71656985e+00  4.05929653e-03  2.00101687e-01  4.34599415e-03
 -5.71656985e+00 -4.05929653e-03 -2.00101687e-01 -4.34599415e-03
 -6.76414384e+00 -2.75633895e-02 -8.67327817e-01 -7.86854223e-01
 -2.78203517e-02 -5.61329591e-06 -3.66366317e-03 -1.30429480e-03
  6.04824130e-01  3.34376313e-01  4.19066513e-01  4.40512492e-01
 -3.18452642e-02 -1.00610257e-05 -3.68440544e-03 -1.72672047e-03
 -3.94377697e-02 -6.30547328e-02 -2.19394618e-01 -5.32874076e-02
  1.72771027e-04  1.54000115e-03  1.11127430e-01  1.37072386e-02
 -1.66294185e-01 -2.74099400e-01 -5.94928964e-01 -2.11009704e-01
  7.97833224e-02  4.37080441e-01  2.33984279e+00  6.12463056e-01
 -3.31291904e-01 -5.87268133e-02 -1.13770337e-01 -1.35781478e-01
 -1.26075879e-01 -6.70960175e-02 -9.44431316e-02 -1.06774008e-01
 -4.35660342e-01 -9.48483050e-01 -1.25622806e+00 -1.35273674e+00
 -2.78269235e-02 -8.88926575e-02 -1.75676963e-01 -2.09781929e-01
 -6.11882373e-01  6.45592243e-01  1.05446379e+00  1.34511238e-01
  1.40889956e+00 -5.25272485e-01  1.67731617e+00 -7.20331636e-01
 -2.34169481e+01]
supnorm grad right now is: 23.416948138059908
Weights right now are: 
[  0.92787596   4.39474365  -2.70990388   5.34712694  -1.7180952
  -4.38028001   3.28120992  -3.93204389  -0.1251412    8.89384663
  -1.59775308   7.36632468   8.33148569  11.40232903   7.29304705
  13.09237864   7.80309165  -7.68470295   3.5169997   -1.86192585
   8.28311751  11.87046091   8.00898553  10.56925283   0.52384931
   4.62718684  -3.89403528  -2.25109123   4.18822203   3.46105693
  11.64112367   9.2675832  -12.27944914   2.39384975   5.01658756
   2.31280496   9.32786721   2.95524388   2.3344652    1.78551203
  -4.72566696  14.3475418   15.5668875   16.56159911  -1.55748457
   4.41657161   5.6880588    7.15941708  -3.51516114   2.71588818
   0.72279633   0.83865832  10.13111633   5.56743844   2.25593106
   0.0567505    5.4436895    3.03898586   4.62356636  -1.90498576
   3.02048898  -2.55267278   2.56797738  -2.79392568  30.40467164]
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1587.1404943615955
gradient value of function right now is: [ 1.75203206e+00  1.52539968e-03 -1.16269452e-02  9.84623337e-04
 -1.75203206e+00 -1.52539968e-03  1.16269452e-02 -9.84623337e-04
  1.17228925e+00 -1.23463576e-02 -1.12490977e+00  4.11071340e-01
 -7.34832659e-03 -3.47658249e-07 -7.86373525e-03  6.68944223e-05
 -2.70359928e-02 -8.94969924e-02  3.87694210e-02 -7.19362852e-02
 -5.00199811e-03 -7.82250277e-07 -4.89182903e-03  1.91025911e-04
 -1.61861684e-01 -1.34949738e-01 -1.77420629e-01 -3.44713886e-02
  1.81405206e-05 -3.42377068e-04  1.79272154e-02  6.03419638e-03
 -2.00649293e-01 -2.76733136e-01 -3.29839008e-01 -2.28243529e-01
  1.48486802e-02 -7.84338632e-02 -1.96999483e+00  1.85944617e-03
  1.09841698e-01  3.84337137e-02 -2.07320871e-02 -6.33988670e-02
  3.78242083e-01  6.24786315e-02  8.36037315e-02  9.27373912e-02
  4.73455014e-01  1.10375749e-01  1.36413549e-01  1.47154265e-01
  3.29071255e-02 -7.41686038e-03 -6.82024704e-03 -4.53883935e-03
 -6.43768939e-01  2.26568503e-01  2.81238100e-01  7.36648858e-01
  9.05859344e-01  3.89836032e-01  1.36931719e+00  1.87913231e-01
 -1.94027154e+00]
supnorm grad right now is: 1.9699948324449525
Weights right now are: 
[  0.91964075   4.52175374  -3.07321058   5.34139116  -1.70985998
  -4.5072901    3.64451663  -3.92630811  -0.13992329   9.2477106
  -1.56200947   7.55519986   8.07833954  11.64442324   6.39219857
  15.11646803   7.86571805  -8.17458517   3.12256341  -2.11601757
   8.20881618  11.89468116   7.00607113  12.60313592   1.67581394
   5.02614785  -4.30295058  -2.32113218   4.53496384   4.08863329
  12.29854393   9.97979159 -13.26348332   1.55835305   4.34513677
   2.03107194   9.53406132   2.75503629   1.92248569   1.80964747
  -5.39246879  14.19472111  15.50708492  16.46881423  -1.33876279
   5.94967149   7.15539785   8.55813015  -2.96113305   2.73109826
   0.8202497    0.87727779  10.50884424   5.13858214   2.00306995
  -0.23118344   4.88205381   3.17374192   4.18215506  -2.10927001
   2.99095981  -2.19512255   2.49033512  -2.31948435  30.49977017]
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1583.6994090100375
gradient value of function right now is: [ 4.25517127e+00  2.40588782e-03  1.21275278e-01  2.33312462e-03
 -4.25517127e+00 -2.40588782e-03 -1.21275278e-01 -2.33312462e-03
 -5.14660338e+00 -3.99412488e-03 -4.04135624e-01 -3.74534556e-01
 -1.42510459e-02 -1.09879937e-06 -3.46910604e-03 -6.21183110e-04
  3.01466822e-01  2.37943597e-01  3.10045031e-01  2.81268740e-01
 -1.47295451e-02 -1.34355457e-06 -3.36909225e-03 -6.93682645e-04
  2.26268881e-01  2.49101601e-02 -4.60441063e-02 -8.87275876e-02
  2.64129377e-04  8.02383515e-04  3.54274779e-02 -6.02451428e-04
 -1.76289997e-01 -2.12262200e-01 -6.22579243e-01 -1.44448770e-01
  1.03037961e-01  2.49497376e-01  1.55764765e+00  2.71964463e-01
 -8.18676110e-01 -1.84001715e-01 -2.07523504e-01 -2.40617800e-01
 -3.75379025e-01 -5.75683649e-02 -6.12136801e-02 -6.91805516e-02
 -2.04128265e-01 -5.50869753e-01 -5.77680224e-01 -5.90101128e-01
 -1.57680057e-02 -1.91526411e-02 -2.21108988e-02 -2.66873369e-02
 -8.95177665e-01  1.11377730e+00  1.01172677e+00 -1.10313925e+00
  1.34754431e+00 -1.33108667e+00  1.73179948e+00 -1.58301542e+00
 -1.43941175e+01]
supnorm grad right now is: 14.39411750678452
Weights right now are: 
[  0.96092299   4.14602021  -2.56198498   5.05455674  -1.75114223
  -4.13155658   3.13329102  -3.63947369  -0.48003356  11.76056466
  -1.23407566   8.10359958   8.23860818  11.79549137   8.11869083
  14.88894101   9.09112607  -6.87008444   2.75208596  -0.86840232
   8.32894133  12.1889883    8.40157561  12.3408811    2.16642987
   5.97901722  -4.18673455  -1.86251876   4.9805784    3.88367149
  12.54817246   9.43525447 -13.83938102   1.42839369   4.46876039
   2.72201644   9.90606482   3.70500736   2.35762841   2.23640972
  -6.31779232  13.17475614  14.90173813  16.03463863  -1.45942084
   6.4365794    7.15831439   8.38583566  -3.1248856    2.54344815
   0.75088609   0.8168238   11.59972422   5.62981189   2.68280978
   0.39578132   4.99124908   3.29541341   3.70933397  -2.38010264
   2.97550264  -2.75025619   2.6295512   -2.71338054  30.65832592]
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1596.8706483078631
gradient value of function right now is: [-5.83360645e-01  5.54461743e-04  1.03859147e+00  5.42708854e-04
  5.83360645e-01 -5.54461743e-04 -1.03859147e+00 -5.42708854e-04
  4.17374520e+00  1.36104804e-02 -4.44080923e-01  5.73414583e-01
 -1.13625636e-03  1.03735096e-06 -1.08161188e-03 -1.09245652e-04
 -5.36499973e-01 -8.83231240e-01  7.37157708e+00 -1.03382484e+00
 -1.44714036e-03  1.72198133e-06 -7.43474386e-04 -9.82046074e-05
 -4.96892741e+00 -3.14062871e+00 -4.72362497e+00  2.18873860e-01
 -2.81007363e-04 -1.04797133e-03 -1.39000450e-01 -1.62603443e-02
  1.86106324e-01  1.96161964e-01  7.41864602e-01  9.08261718e-02
 -6.57995862e-02 -9.98458291e-02 -1.87802872e+00  1.49913994e-01
  1.47028828e+00  1.62734645e-01  2.22870895e-01  2.90300845e-01
  6.58949986e+00  3.36754920e-01  3.77608539e-01  4.74542011e-01
 -6.43603401e-01  1.10444910e+00  1.46589916e+00  1.57408696e+00
  3.13714200e-02  7.74937913e-02  1.01155766e-01  9.15941124e-02
  2.05783245e+00 -6.09137911e+00 -1.67375876e+00  3.42637018e+00
 -1.37079456e+00  5.93277500e+00 -1.59621920e+00  8.76383467e+00
  2.07279951e+01]
supnorm grad right now is: 20.72799508494381
Weights right now are: 
[  1.10328521   3.87883968  -4.0770004    4.78252688  -1.89350445
  -3.86437604   4.64830645  -3.36744383  -0.41212355  14.41147341
  -1.63227435   8.20025138   8.64541003  11.78048947   8.80108432
  15.86733277   9.42951223  -6.68826677   0.2900457   -0.65303141
   8.77721848  12.15405014   9.01862296  13.24329556   2.3110812
   6.95191259  -4.14538485  -0.64812939   6.90129804   5.73760703
  12.63287083  10.12856809 -14.0585686    1.60869933   4.52986261
   3.91241131  10.44563614   3.92882453   2.60300778   2.15638687
  -5.92864239  13.2918571   14.69950383  15.79905919  -2.07792839
   7.61950935   8.97931938  10.19237936  -3.81679372   3.35942589
   1.3226376    1.22949056   9.79216158   5.98539749   2.86295987
   0.5170725    6.22957796   1.85643722   4.04238095  -2.30120184
   2.44387234  -2.39613069   1.68473261  -2.26418687  30.71738048]
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -1595.8350477645893
gradient value of function right now is: [ 2.61794333e+00  5.34132444e-04 -8.96619950e-01  5.36433402e-04
 -2.61794333e+00 -5.34132444e-04  8.96619950e-01 -5.36433402e-04
 -8.67977218e+00 -3.58646759e-02  4.13762535e-01 -1.65695971e+00
 -1.78148432e-03 -2.02921692e-07 -1.77854622e-04 -1.07314759e-04
 -7.42784778e-01 -1.93832172e-01 -6.19021713e+00 -1.27757882e-01
 -1.95962952e-03 -3.57198062e-07 -2.10978902e-04 -1.34499562e-04
  4.15486272e+00  2.93347028e+00  3.99772178e+00  3.98380631e-01
  1.06006065e-04  3.84877256e-04  1.34351830e-01  3.70065878e-02
 -5.05515687e-02 -6.10037505e-02 -6.76315578e-01 -2.43371903e-01
  7.02520918e-02  1.66113510e-01  4.43170296e+00  1.91700543e+00
 -1.04599059e+00 -1.02120497e-01 -1.68768813e-01 -2.59355176e-01
 -3.53920440e+00 -1.66029596e-01 -2.63607484e-01 -3.83908915e-01
  3.81802763e-01 -5.15065320e-01 -1.72522200e+00 -2.52971922e+00
  3.55005596e-03 -8.37744725e-02 -3.86666565e-01 -6.37640554e-01
 -2.20602958e+00  5.50154714e+00  2.09882984e+00 -2.10860723e+00
  3.69131663e+00 -3.67117416e+00  5.19447973e+00 -5.95764487e+00
 -1.74049474e+01]
supnorm grad right now is: 17.404947402656568
Weights right now are: 
[  1.05281277   2.34460167  -4.7672522    3.24696186  -1.84303201
  -2.33013803   5.33855825  -1.83187881  -0.652859    14.98873607
  -1.70823538   8.17426306  10.07422419  11.81656467  10.25573948
  17.13624854   9.5146952   -6.76510995  -0.26006771  -0.64199424
  10.21254656  12.20675839  10.5196568   14.46066571   2.28108665
   7.10593941  -4.20427099  -0.66057478   8.28177353   6.01874976
  13.26288863  10.05423331 -14.90457158   0.96281182   3.82104101
   4.85511085  11.72171736   4.41074197   2.72806356   1.70490676
  -5.52659281  13.28333451  14.23115404  15.38677758  -1.95989172
   8.69875019  10.23917294  11.35403741  -4.03816529   3.4496883
   1.07798842   0.95882799  10.66625851   5.92764925   3.06611839
   0.92691137   6.22344289   1.98675143   4.63446695  -1.80449558
   2.11552335  -2.38200685   1.13619797  -2.43835568  30.58638377]
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -1589.0922959904233
gradient value of function right now is: [-6.29493946e+00 -4.87922039e-04  1.08114045e+00 -4.95489971e-04
  6.29493946e+00  4.87922039e-04 -1.08114045e+00  4.95489971e-04
  1.62721204e+01  2.20798817e-02 -4.39419673e-01  2.03082477e+00
  1.92710714e-03  1.53411766e-07 -2.56817254e-05  1.14573820e-04
  1.70780726e+00  6.45275825e-01  7.38891046e+00  6.61999731e-01
  2.09398800e-03  2.28563889e-07  2.42495269e-05  1.38102205e-04
 -6.19697932e+00 -4.14859317e+00 -5.88185982e+00 -2.22585582e-01
 -5.34077390e-04 -1.00449237e-03 -7.17851305e-02 -2.11852689e-02
  1.20750718e-01  1.56862831e-01  1.35741770e+00  5.30015832e-01
 -1.64541548e-01 -2.91168773e-01 -5.41132260e+00 -3.24040240e+00
  1.97991814e+00  2.00701937e-01  3.98266865e-01  7.06331196e-01
  6.98595019e+00  4.18496065e-01  5.38634396e-01  8.58437990e-01
 -2.39477048e+00  4.86277855e-02  9.82692160e-01  2.09024967e+00
 -4.70748545e-02  4.15135294e-02  4.47700543e-01  9.88177471e-01
  2.87792829e+00 -1.02480448e+01 -1.78706491e+00  5.64051626e+00
 -4.86462151e+00  9.81921901e+00 -8.08665502e+00  1.73370544e+01
  2.62709746e+01]
supnorm grad right now is: 26.270974627590924
Weights right now are: 
[ 1.02141257e+00  2.19109767e+00 -4.15650541e+00  3.08085696e+00
 -1.81163180e+00 -2.17663403e+00  4.72781145e+00 -1.66577391e+00
 -5.44938290e-01  1.63544430e+01 -2.05028651e+00  7.71687848e+00
  1.02340968e+01  1.18147259e+01  1.02754774e+01  1.74604616e+01
  1.01772127e+01 -6.03882008e+00  3.03192443e-01 -1.57444037e-02
  1.03864091e+01  1.22023301e+01  1.05412658e+01  1.47507393e+01
  2.08280498e+00  6.78762582e+00 -4.32753182e+00 -1.54990060e+00
  9.82151662e+00  7.46647963e+00  1.32667607e+01  1.11420168e+01
 -1.51689446e+01  8.63039006e-01  3.79701335e+00  5.18455672e+00
  1.22871862e+01  4.80623719e+00  2.96405128e+00  2.02643179e+00
 -5.35211288e+00  1.28233647e+01  1.38208045e+01  1.52258349e+01
 -2.19319945e+00  8.16798625e+00  1.06913489e+01  1.19983374e+01
 -2.59791758e+00  4.34590034e+00  1.17967281e+00  9.27784914e-01
  1.05610557e+01  5.65686417e+00  2.50245396e+00  4.15308103e-01
  6.95940207e+00  1.50320738e+00  5.20968244e+00 -1.98749527e+00
  2.04852499e+00 -2.35173586e+00  6.96271797e-01 -2.24729365e+00
  3.06506762e+01]
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1595.9538153241424
gradient value of function right now is: [ 1.75876808e+00  4.46409113e-04  2.70583280e-01  4.14216221e-04
 -1.75876808e+00 -4.46409113e-04 -2.70583280e-01 -4.14216221e-04
 -5.69543731e+00 -3.49994562e-02 -9.32636473e-02 -1.05104737e+00
 -1.92971000e-03 -1.74856394e-07 -3.47837217e-04 -7.66765480e-05
  8.74367651e-01  9.52108117e-01  2.83621166e-01  1.12402090e+00
 -1.89900003e-03 -3.16239991e-07 -3.39372179e-04 -8.66104843e-05
  1.65710338e+00  1.18345830e+00  1.61958699e+00  3.69765015e-01
  1.24762308e-04  1.86124908e-04  2.12927808e-01  1.16856396e-02
 -2.89716208e-02 -2.57732812e-02 -6.33210911e-01 -1.19218070e-01
  6.31909220e-02  8.23470661e-02  2.59733335e+00  6.90758573e-01
 -9.04540598e-01 -1.38570101e-01 -1.86593352e-01 -2.74639361e-01
 -1.51455114e+00 -1.50369454e-01 -1.85475972e-01 -2.52400326e-01
  1.09703124e-01 -1.41344679e+00 -2.66878405e+00 -3.28810948e+00
  3.72643445e-03 -1.87879955e-02 -9.84026108e-02 -1.73887461e-01
 -1.10901737e+00  3.15771440e+00  1.56346498e+00 -1.15231350e+00
  2.01135474e+00 -3.10527877e+00  3.19656903e+00 -4.66259623e+00
 -2.40083198e+01]
supnorm grad right now is: 24.008319810451052
Weights right now are: 
[  1.01319531   3.22144066  -4.09308472   4.07209142  -1.80341454
  -3.20697702   4.66439076  -2.65700837  -0.4661888   16.67600144
  -2.02180516   8.12262717  10.02300666  11.81245207   8.77586519
  18.20346834   9.7912942   -6.85941651   0.26845615  -0.56198896
  10.21658273  12.19749103   8.96655849  15.44633452   2.29771152
   7.16328003  -4.13340263  -0.92859294  12.19582483   9.47137285
  14.06583869  10.83434226 -15.00470735   0.98996461   3.87738639
   5.7127497   14.39725996   6.59742652   2.83431087   1.58029669
  -4.85601347  12.96575661  12.99379593  14.34534018  -2.15487294
   8.99372339  11.39479678  12.49898599  -2.85836552   3.47178543
   0.93601427   0.93434461  12.00220551   6.58501729   3.78851079
   1.99322939   6.52729929   1.40579653   5.06316092  -1.90364358
   2.05169177  -2.56879437   0.83775292  -2.65928566  30.37180665]
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.1281212137815
gradient value of function right now is: [ 1.20414435e+00  4.60991451e-04  1.13498297e+00  3.91621783e-04
 -1.20414435e+00 -4.60991451e-04 -1.13498297e+00 -3.91621783e-04
  1.57488120e+00 -5.07906545e-03 -4.30900354e-01  5.97851175e-01
 -8.97988400e-04  2.05784982e-08 -2.01991737e-03 -5.40637955e-06
  1.21186151e+00  8.43300596e-01  5.67633662e+00  9.91214343e-01
 -8.10403554e-04  2.10600041e-08 -1.78505861e-03  1.27117898e-06
 -9.94895089e-01 -9.29750212e-01 -9.56263557e-01 -3.99053567e-01
 -8.18433423e-05 -1.30253146e-04  7.96009858e-02 -3.19358989e-03
 -9.47053540e-02 -9.57340482e-02 -3.43113687e-02 -1.06884897e-01
  1.37166637e-02  1.34666405e-02 -1.84789204e+00 -3.54232527e-01
 -1.71789475e-01 -3.20137697e-02 -5.10657421e-02 -9.32879863e-02
  4.92933770e-01  9.15977002e-03 -9.55124665e-03  1.92860286e-03
  2.18892193e-01 -7.34925383e-01 -1.04921654e+00 -8.08580153e-01
 -1.99785918e-02  6.95259906e-03  9.01014328e-02  2.08638419e-01
  2.82264339e-01 -1.06815895e+00  4.32137409e-01  1.42325909e+00
 -1.15140248e-01 -3.60289560e-01  1.62575515e-01 -6.97210698e-01
 -4.64883277e+00]
supnorm grad right now is: 5.676336619321322
Weights right now are: 
[  1.09631044   3.26053325  -3.91732937   4.11867938  -1.88652968
  -3.24606961   4.48863542  -2.70359633  -0.10321828  18.01804644
  -2.03762689   8.6975534   10.4713473   11.81532501   8.80216408
  19.02206912   9.85219636  -7.13159172   0.36131167  -0.63360855
  10.64352769  12.20327245   8.97218897  16.15710361   2.38518973
   7.23633481  -4.0335955   -1.56997951  12.53269211   9.87124534
  14.32114073  11.34308033 -15.67680988   0.40380902   4.19935746
   5.10577326  14.0934299    6.39276529   2.66259046   1.99100399
  -4.67590293  12.54603029  13.11810328  14.58492502  -2.33523394
   9.08011553  11.82434404  12.85931345  -2.57028805   3.5745025
   0.94690229   0.73493519  12.88819805   6.9835503    4.07182388
   2.07710422   6.78463021   1.19066775   5.54703331  -1.80344624
   2.15864788  -2.620732     0.88714081  -2.75186192  30.51931596]
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1596.471494085
gradient value of function right now is: [-3.08363215e+00  1.84022768e-04 -1.66151320e+00  1.79918563e-04
  3.08363215e+00 -1.84022768e-04  1.66151320e+00 -1.79918563e-04
 -4.59232609e+00 -2.13824707e-02  1.60036014e+00 -8.43467915e-01
 -1.03530067e-03 -8.71065573e-08  3.22692850e-04 -2.97953437e-05
 -2.20946014e+00 -1.02116670e+00 -1.04741596e+01 -1.08556752e+00
 -1.04109348e-03 -1.54760419e-07  2.75290767e-04 -3.65586053e-05
  5.55745711e+00  4.29906602e+00  6.47375601e+00  4.34518470e-01
  1.09606341e-04  1.86621807e-04  1.56360438e-02  2.24930300e-02
 -1.22615660e-02 -4.72750854e-02 -1.99098166e-01 -2.81581526e-01
  3.71044499e-02  5.53680242e-02  1.82861277e+00  1.07354605e+00
 -1.55540260e+00 -9.17290102e-02 -1.30487277e-01 -2.85024336e-01
 -6.39820307e+00 -5.26146819e-01 -4.36302587e-01 -5.68297518e-01
  2.90115962e+00  1.09499749e+00  5.81847967e-01 -4.61648519e-01
  5.51629768e-02 -2.64748041e-02 -1.86229452e-01 -4.88024529e-01
 -2.61985314e+00  9.71286759e+00  1.48969021e+00 -6.68079512e+00
  3.47642284e+00 -6.65980523e+00  5.84084329e+00 -9.91593988e+00
 -4.63755007e+00]
supnorm grad right now is: 10.474159571551569
Weights right now are: 
[  1.01941802   2.85182124  -4.53433697   3.72147983  -1.80963725
  -2.8373576    5.10564302  -2.30639678  -0.30030902  17.76568294
  -2.03409057   8.2737795   11.03591972  11.81443226   9.45722988
  19.27065455   9.70351903  -7.28524114  -0.19801406  -0.8448524
  11.19600971  12.20166273   9.60307719  16.31634681   2.45929542
   7.38056264  -3.93710491  -1.73189797  14.57998765  11.92762961
  14.08762305  12.00311994 -15.33307317   0.69518255   4.42542278
   5.68943313  14.96054684   7.2734961    3.2262337    2.15602474
  -4.19839893  12.98547424  12.98585343  14.59449524  -2.29838057
   9.57770527  12.30429291  13.18241214  -2.76001752   3.64860504
   1.56970855   1.16696467  14.4024668    8.08662461   4.47321392
   2.23158297   6.22043613   1.34828068   4.9309537   -1.9722418
   2.25896281  -2.7253773    0.64784031  -2.86358712  30.62694875]
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1593.135860851565
gradient value of function right now is: [ 3.41357816e+00  2.22174420e-04  3.82254388e-01  1.98705734e-04
 -3.41357816e+00 -2.22174420e-04 -3.82254388e-01 -1.98705734e-04
 -5.52373881e+00 -3.76962036e-02 -1.17446227e+00 -9.17269053e-01
 -7.29854568e-04 -8.70867613e-08 -5.53630922e-04 -1.70064672e-05
  5.87239547e-01  5.69065438e-01  1.15513880e+00  7.00116732e-01
 -6.86895153e-04 -1.62529364e-07 -5.13651459e-04 -1.94951425e-05
  5.33654122e-01  6.46823219e-01  6.85783453e-01  5.13121762e-01
  4.10233382e-05  4.71960191e-05  2.12868843e-01  4.41715436e-03
 -1.54329058e-01 -1.41841136e-01 -1.19498434e+00 -1.75711826e-01
  3.20957739e-02  3.30017707e-02  2.13811644e+00  1.02044694e-01
 -4.44534985e-01 -9.94175525e-02 -1.60432283e-01 -2.72028610e-01
  6.98486490e-01  6.36576292e-02 -4.86378051e-02 -1.05241268e-01
 -5.39574415e-01 -1.33960661e+00 -2.80127541e+00 -3.60292431e+00
  5.01277505e-02  3.31293168e-03  5.77445654e-03  3.88372275e-02
 -1.40893706e+00  1.20488559e+00  1.36369968e+00  1.74479911e+00
  1.51344984e+00 -1.22960436e+00  2.48694950e+00 -3.42435965e+00
 -2.24153104e+01]
supnorm grad right now is: 22.415310434541613
Weights right now are: 
[  1.0834508    3.17710094  -3.98121098   4.01697925  -1.87367004
  -3.1626373    4.55251703  -2.6018962    0.09202834  17.46340978
  -2.63165723   8.04764327  10.85366548  11.81092297   9.25712929
  20.59069512   9.91989276  -7.10502944   0.2627285   -0.58620583
  11.05814998  12.19418446   9.37666475  17.4391647    2.37627031
   7.39043483  -3.91951311  -1.40146766  17.16588267  14.48318476
  15.18905833  11.99812881 -15.91565682   0.16578536   4.18456512
   5.906444    14.50919914   6.71855144   3.60846743   1.47189133
  -3.86546885  12.74453407  12.91139119  14.84281678  -1.87438497
   9.85577105  12.68558593  13.45642061  -3.10677071   3.82622966
   1.00945834   0.48934526  15.53212909   9.03607905   4.53386159
   2.07566076   6.13661709   1.14301287   5.96705551  -1.67684132
   2.6069172   -2.74108284   0.66704173  -3.1322796   30.40114972]
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1595.8437656203548
gradient value of function right now is: [ 3.19525056e+00 -5.73855223e-06 -3.36785452e-01 -3.64648051e-06
 -3.19525056e+00  5.73855223e-06  3.36785452e-01  3.64648051e-06
 -8.13668166e+00 -3.71272696e-02 -1.11294986e+00 -1.20811884e+00
 -1.23931357e-04 -4.29414177e-08  1.83292556e-04 -5.84352494e-06
  4.83022943e-01  7.11468639e-01 -3.12548175e+00  8.27171802e-01
 -1.24633965e-04 -7.49423680e-08  1.74030298e-04 -7.18013876e-06
  2.85137420e+00  1.99997039e+00  3.19473948e+00 -7.07650458e-02
  1.40924290e-04  1.34402516e-04  2.80878127e-01  2.83113730e-03
 -1.72274661e-01 -1.48335849e-01 -1.38802009e+00 -1.78482700e-01
  4.56267823e-02  4.20440316e-02  3.41536190e+00  2.15883941e-01
 -1.79066926e+00 -2.33515893e-01 -2.57932833e-01 -3.69728194e-01
 -4.18510874e+00 -3.74227383e-01 -2.91801546e-01 -2.67331102e-01
  8.20916604e-01 -1.42455259e+00 -3.24221613e+00 -4.88693195e+00
  7.58307128e-03  3.93625279e-04 -1.39922071e-03  3.70185363e-03
 -1.57640197e+00  5.96709221e+00  2.16115900e+00 -3.81065607e+00
  2.00905975e+00 -5.51814863e+00  2.46638230e+00 -6.69092158e+00
 -2.50503528e+01]
supnorm grad right now is: 25.05035281155724
Weights right now are: 
[ 1.21288211e+00  2.30547982e+00 -4.34450409e+00  3.14416615e+00
 -2.00310135e+00 -2.29101618e+00  4.91581014e+00 -1.72908310e+00
 -1.70451418e-02  2.07659142e+01 -2.25445237e+00  8.63959091e+00
  1.18958991e+01  1.18117007e+01  9.34015285e+00  2.09966405e+01
  1.03433835e+01 -7.09920494e+00 -3.41362764e-02 -3.35203878e-01
  1.21028319e+01  1.21963751e+01  9.42479154e+00  1.78172044e+01
  2.42076396e+00  7.34196829e+00 -3.94798724e+00 -1.81656198e+00
  1.87877687e+01  1.60827606e+01  1.44584951e+01  1.18660269e+01
 -1.60315496e+01  7.22936207e-02  4.09513914e+00  5.65867196e+00
  1.53029325e+01  7.24200097e+00  3.76985661e+00  1.49715240e+00
 -4.03813500e+00  1.20299634e+01  1.22576065e+01  1.45331873e+01
 -2.30862374e+00  9.60174498e+00  1.30171006e+01  1.38750365e+01
 -2.90467031e+00  4.19823840e+00  9.55671681e-01  1.66080885e-01
  1.63868190e+01  1.07587392e+01  6.08254627e+00  3.67292542e+00
  6.66515506e+00  1.22249012e+00  5.60538466e+00 -1.98628481e+00
  2.41783354e+00 -2.72154969e+00  3.40271645e-01 -3.13292699e+00
  3.04740954e+01]
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1592.715033588402
gradient value of function right now is: [-5.23507022e+00 -2.75658124e-06 -2.56948204e+00 -5.79003804e-07
  5.23507022e+00  2.75658124e-06  2.56948204e+00  5.79003804e-07
 -6.91466198e+00 -2.20488273e-02  3.16327037e+00 -8.59565201e-01
 -3.84450127e-04 -3.40932962e-08  6.31381475e-04 -6.49572584e-06
 -7.02163210e-01  8.99077871e-01 -1.68634267e+01  9.73844518e-01
 -3.84933128e-04 -5.61660409e-08  6.19420431e-04 -7.84792453e-06
  1.01637965e+01  6.88074696e+00  1.14429052e+01  6.70695171e-01
  4.03770897e-04  3.52476870e-04  1.80627064e-01  1.04203835e-02
 -6.88255642e-02 -5.52956423e-02 -6.64520888e-01 -1.53502103e-01
  5.49512542e-02  4.87903911e-02  2.65712302e+00  5.64020368e-01
 -3.69293278e+00 -3.44132621e-01 -3.54588598e-01 -5.14709139e-01
 -1.20042411e+01 -9.20376809e-01 -8.03044793e-01 -8.42277812e-01
  3.49185823e+00 -3.79092990e-01 -1.18715062e+00 -2.79608120e+00
  7.37173876e-02 -9.28726640e-03 -5.00033016e-02 -2.15123887e-01
 -4.33848207e+00  1.41664135e+01  3.46478262e+00 -1.08217843e+01
  4.57820034e+00 -1.34363165e+01  7.12561138e+00 -1.63163967e+01
 -1.94085386e+01]
supnorm grad right now is: 19.408538607167255
Weights right now are: 
[ 9.71808477e-01  1.80881432e+00 -4.17994024e+00  2.66271044e+00
 -1.76202771e+00 -1.79435068e+00  4.75124628e+00 -1.24762740e+00
 -1.55006156e-01  2.19626125e+01 -1.80386394e+00  9.04551370e+00
  1.25781481e+01  1.18125546e+01  9.77870420e+00  2.08760732e+01
  1.02768616e+01 -7.06535564e+00 -3.51074513e-03 -2.63630165e-01
  1.27561518e+01  1.21980039e+01  9.86561532e+00  1.76692898e+01
  2.55427237e+00  7.63191607e+00 -3.71964848e+00 -1.80121306e+00
  1.97260670e+01  1.70980445e+01  1.36871166e+01  1.15061441e+01
 -1.55473447e+01  1.06699523e+00  4.61086301e+00  7.08272216e+00
  1.64218199e+01  8.27907659e+00  3.79211911e+00  2.21002973e+00
 -4.10503785e+00  1.14038489e+01  1.19575357e+01  1.48546561e+01
 -1.99630161e+00  1.04033749e+01  1.36703318e+01  1.41813541e+01
 -3.11439577e+00  4.33355685e+00  1.43932512e+00  4.93864778e-01
  1.83454795e+01  1.33513060e+01  6.58415623e+00  3.11116176e+00
  6.46608010e+00  1.58122487e+00  4.55200054e+00 -2.17112744e+00
  2.65681829e+00 -2.69715829e+00  5.74845223e-01 -3.18173617e+00
  3.06646606e+01]
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.240748425078
gradient value of function right now is: [-4.65088029e-01  4.91166728e-05  2.20597157e-01  4.57568057e-05
  4.65088029e-01 -4.91166728e-05 -2.20597157e-01 -4.57568057e-05
 -2.27118058e+00 -5.12622887e-03  1.45922829e-01 -1.93723792e-01
 -6.31712078e-05 -1.13366766e-09 -8.88535890e-06 -2.52847074e-07
  1.43079132e+00  1.70664705e+00 -4.42908738e-01  1.79053711e+00
 -6.62817795e-05 -2.08838326e-09 -9.34517984e-06 -3.09756411e-07
  2.89877936e+00  1.85647518e+00  3.40595445e+00  1.47875800e-01
  3.41057531e-05  2.81230845e-05  8.06687724e-02 -5.26585837e-06
 -6.22254978e-02 -3.89680598e-02 -3.34276223e-01 -1.88629579e-02
  1.17603590e-02  9.81150389e-03  6.85604889e-01  4.92965489e-02
 -1.49899041e+00 -1.25150221e-01 -1.25130375e-01 -1.42531619e-01
 -4.48049817e+00 -2.76199213e-01 -2.51977329e-01 -2.29230194e-01
  4.76961657e-01 -9.36344688e-01 -1.05467765e+00 -1.19607209e+00
  8.41282743e-04 -1.84182416e-03 -3.46813305e-03 -7.47247601e-03
 -7.73749462e-01  4.68415095e+00  7.11820695e-01 -3.97350686e+00
  6.22641603e-01 -4.92012075e+00  7.53254949e-01 -5.18241291e+00
 -1.38607975e+01]
supnorm grad right now is: 13.860797456647527
Weights right now are: 
[ 1.12323896e+00  1.33753648e+00 -4.29809920e+00  2.20266753e+00
 -1.91345820e+00 -1.32307284e+00  4.86940525e+00 -7.87584482e-01
  2.30564758e-01  2.05610886e+01 -2.59326964e+00  8.70192207e+00
  1.42554938e+01  1.18120205e+01  1.02196229e+01  2.08572971e+01
  1.06326954e+01 -6.76042440e+00 -4.29538073e-02 -8.38529949e-03
  1.44090759e+01  1.21966235e+01  1.02718631e+01  1.76202284e+01
  2.43654745e+00  7.49483255e+00 -3.79623730e+00 -2.14471865e+00
  1.98431764e+01  1.72566535e+01  1.42480326e+01  1.13024911e+01
 -1.53987954e+01  1.34056506e+00  4.97484702e+00  8.45689953e+00
  1.64182500e+01  8.35366669e+00  3.98477246e+00  2.09231244e+00
 -3.83826692e+00  1.17770702e+01  1.23945885e+01  1.53956069e+01
 -2.02880543e+00  1.05782633e+01  1.40665675e+01  1.46184875e+01
 -3.75578019e+00  3.77295022e+00  1.42423209e+00  6.75253870e-01
  1.93313745e+01  1.46262142e+01  7.10765373e+00  3.16837930e+00
  6.79947564e+00  1.29750028e+00  3.51259816e+00 -2.57930649e+00
  2.11383626e+00 -2.78598112e+00  3.81658869e-01 -2.99408512e+00
  3.03728330e+01]
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1579.7152089236138
gradient value of function right now is: [ 1.17195266e+01  4.26519758e-05 -3.80585040e-01  4.08547772e-05
 -1.17195266e+01 -4.26519758e-05  3.80585040e-01 -4.08547772e-05
 -1.72877601e+01 -3.30707052e-02 -2.29275524e+00 -1.36260570e+00
 -3.16666740e-05 -1.09973618e-09 -6.39206426e-06 -2.20861825e-07
 -3.71692739e-01 -2.46674160e-01 -2.49045087e+00 -2.22426058e-01
 -3.75953097e-05 -2.05826171e-09 -6.82353294e-06 -3.03254484e-07
  1.25851873e+00  1.04738958e+00  1.18527656e+00  1.28591976e-01
  2.06981395e-03  1.02938649e-03  2.30454055e-01  1.82048193e-02
 -4.53263572e-01 -3.10064262e-01 -2.47106384e+00 -5.37953319e-01
  1.69562361e-01  9.81169061e-02  4.36112545e+00  8.68290528e-01
 -1.30735035e+00 -4.92246823e-01 -5.88173201e-01 -9.65071789e-01
 -6.71062053e-01 -8.00866621e-02 -9.59731042e-02 -1.57454354e-01
  7.23311696e-02 -4.53370048e-01 -1.11215129e+00 -2.36144583e+00
  5.84690482e-02  2.92006333e-03 -4.26537912e-02 -1.63128354e-01
 -2.04389980e+00  4.18432619e+00  3.18317311e+00 -2.94361394e+00
  4.43415517e+00 -3.32961122e+00  8.48214170e+00 -5.52355721e+00
 -4.26497864e+01]
supnorm grad right now is: 42.649786419662675
Weights right now are: 
[ 1.35724909e+00  6.00985170e-01 -4.65457491e+00  1.43955896e+00
 -2.14746833e+00 -5.86521532e-01  5.22588096e+00 -2.44759162e-02
 -8.05187812e-02  2.32430957e+01 -2.84355610e+00  9.45122175e+00
  1.56054116e+01  1.18119700e+01  1.18331364e+01  2.08552967e+01
  1.02398376e+01 -7.59537093e+00 -3.04495342e-01 -6.41442893e-01
  1.57403356e+01  1.21965520e+01  1.16458678e+01  1.76172179e+01
  2.35887068e+00  7.45508643e+00 -3.90131046e+00 -2.24441596e+00
  2.18798160e+01  1.91507073e+01  1.38939283e+01  1.24019412e+01
 -1.56816171e+01  1.39050218e+00  4.56206332e+00  8.91157240e+00
  1.82752287e+01  1.00481929e+01  3.80062134e+00  3.16185955e+00
 -4.01518529e+00  1.07253631e+01  1.11925969e+01  1.41860091e+01
 -1.98425107e+00  1.12685476e+01  1.47153395e+01  1.48273974e+01
 -3.07605732e+00  3.98839300e+00  1.53568003e+00  7.56668089e-01
  2.07191932e+01  1.56221902e+01  6.73477005e+00  2.33636552e+00
  7.04369977e+00  1.16665940e+00  4.42692487e+00 -1.88012364e+00
  2.94162540e+00 -2.61043985e+00  1.40247986e+00 -3.09429865e+00
  3.03520701e+01]
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1578.476110235999
gradient value of function right now is: [-1.20981468e+01  2.07245903e-06  1.14143103e+00  1.01455360e-05
  1.20981468e+01 -2.07245903e-06 -1.14143103e+00 -1.01455360e-05
  2.48958204e+01  7.04255762e-02  2.77623147e+00  2.34071896e+00
  1.65835127e-04  5.60269659e-08 -2.08330589e-04  6.24894754e-06
 -1.54117670e+00 -3.06514112e+00  1.13309052e+01 -3.54973463e+00
  2.15778717e-04  1.19644663e-07 -3.04241339e-04  1.01153675e-05
 -1.11279491e+01 -8.46597617e+00 -1.26633539e+01 -1.59535295e+00
 -2.41313695e-03 -1.19176913e-03 -7.76472318e-01 -2.20853495e-02
  6.81177224e-01  3.30067506e-01  4.48110480e+00  3.86279067e-01
 -2.02499631e-01 -1.07060651e-01 -7.24573711e+00 -8.42003518e-01
  6.46610295e+00  1.12034892e+00  1.25933508e+00  1.66942728e+00
  1.04472217e+01  8.28525147e-01  7.69117375e-01  9.14732362e-01
 -3.34877904e+00  3.74144438e+00  6.89278472e+00  9.69805346e+00
 -1.99519861e-01 -1.00880051e-02  4.72536620e-02  1.83168831e-01
  6.87953697e+00 -2.11263954e+01 -8.21214005e+00  1.27110633e+01
 -9.72908359e+00  2.06200659e+01 -1.40019460e+01  2.94531250e+01
  8.62456224e+01]
supnorm grad right now is: 86.2456223698891
Weights right now are: 
[  0.772302     1.73196766  -4.53797191   2.64782576  -1.56252124
  -1.71750402   5.10927796  -1.23274271   0.11030204  22.83413894
  -2.48270693   9.294402    13.28490525  11.8121523   10.33713062
  20.85116103  10.08357782  -7.80750638  -0.22622572  -0.86471318
  13.24085354  12.19684324  10.08591476  17.60962103   2.2263072
   7.22179668  -3.94784524  -2.75859825  21.70090777  18.5472756
  14.34556243  11.28442318 -16.19301434   0.78856156   4.5482926
   8.27719633  17.30654966   9.17836861   4.03687232   3.09291675
  -3.72147327  11.16531027  11.79698331  14.67415434  -2.16156675
  11.14331353  15.03505388  15.46064627  -2.73657653   4.59972625
   1.59402262   0.69109943  21.31413832  17.10674357   7.59361722
   2.71952019   7.24865784   1.29912506   4.48214533  -2.08758868
   2.36037733  -2.61074507   0.81859767  -2.85638384  30.87062232]
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.8278866020337
gradient value of function right now is: [ 2.05415871e+00 -2.70152910e-04  1.72411828e+00 -3.17205450e-04
 -2.05415871e+00  2.70152910e-04 -1.72411828e+00  3.17205450e-04
  7.05437163e+00  3.13313259e-02  2.57190096e-02  8.80953742e-01
  1.88117384e-04  4.28307876e-09  3.36477391e-04  3.73228411e-07
  2.08007400e+00  9.78562066e-01  1.00053143e+01  1.02517984e+00
  2.35909460e-04  8.95612610e-09  4.24957507e-04  6.06660367e-07
 -5.58035478e+00 -3.98295959e+00 -7.16997357e+00  1.44432307e-01
 -7.59748888e-04 -3.22003030e-04 -1.89809622e-01 -1.20124556e-02
  2.02153305e-01  1.71725744e-01  1.11016523e+00  3.14506150e-01
 -4.61675660e-02 -2.31181511e-02 -2.65035405e+00 -3.62118557e-01
  1.89813521e+00  2.04102665e-01  3.19857312e-01  3.83795504e-01
  6.72620948e+00  5.08943445e-01  4.98198183e-01  4.18106073e-01
 -2.11882866e+00 -4.83502328e-01  6.09357562e-01  1.60592266e+00
 -5.75011131e-02 -8.36401012e-03  2.69843475e-03  3.69491924e-02
  2.43195519e+00 -9.36068976e+00 -2.16865915e+00  7.56335387e+00
 -4.18325962e+00  1.06158095e+01 -5.09154686e+00  1.02649980e+01
  1.21710239e+01]
supnorm grad right now is: 12.17102394031641
Weights right now are: 
[  1.20354479   1.57596688  -4.18310375   2.40291246  -1.99376402
  -1.56150325   4.7544098   -0.98782941   0.33698153  24.95691616
  -3.09355232   9.6798768   15.50595985  11.81230046  11.54470898
  20.8740594   10.72985791  -7.14575451  -0.2474146   -0.11758691
  15.43756166  12.19730008  11.1824604   17.63232022   2.27560104
   7.40094662  -3.8588137   -1.72392919  23.79266632  20.04880769
  14.10659842  11.70025528 -15.66515364   1.68568894   4.69434607
   9.50976342  17.18010358   8.5631036    4.19343864   2.84876319
  -3.63503176  10.50267472  11.41348657  14.69212813  -2.19683017
  11.26659394  15.61572636  15.75565729  -3.47805514   3.6115548
   1.08211528   0.72668961  22.30311403  17.05922582   7.85747436
   3.16480209   7.35658713   1.24510687   4.41148177  -2.07503201
   1.97244917  -2.54721448   0.93774169  -2.95340317  30.46734593]
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1577.9291488978288
gradient value of function right now is: [ 1.23005226e+01  1.06547131e-05  3.83865660e-01  1.38461915e-05
 -1.23005226e+01 -1.06547131e-05 -3.83865660e-01 -1.38461915e-05
 -1.19406739e+01 -1.83111509e-02 -2.24220088e+00 -8.12270533e-01
 -1.67405996e-05 -2.22978248e-09 -1.65591792e-05 -3.17063067e-07
  6.61354031e-01  2.72331114e-01  2.15712705e+00  2.93462068e-01
 -2.23194275e-05 -4.21473862e-09 -2.50068407e-05 -4.71232293e-07
 -1.75369892e+00 -1.33733000e+00 -1.96073630e+00 -2.16777235e-01
  1.08118960e-03  3.08446355e-04  1.54231511e-01  4.15105909e-03
 -3.68943899e-01 -1.96797080e-01 -2.25669080e+00 -2.95508218e-01
  9.43248245e-02  3.38349817e-02  2.81011515e+00  2.58873419e-01
 -5.19175453e-01 -3.01034779e-01 -4.55018187e-01 -6.05281913e-01
  1.34914885e+00  5.96237913e-02  5.65038038e-02  3.56863385e-02
 -8.48221397e-01 -9.68590089e-01 -1.21113991e+00 -1.49334102e+00
  1.67286888e-02  2.49936222e-02  5.14804564e-02  7.87811459e-02
 -7.44322509e-01 -1.38076043e-01  1.00627040e+00 -5.11536508e-01
  1.70649429e+00 -6.28372296e-01  3.60678277e+00 -2.11036754e+00
 -3.10232417e+01]
supnorm grad right now is: 31.023241699759925
Weights right now are: 
[  1.20633265   1.60963223  -3.64003284   2.44368787  -1.99655189
  -1.59516859   4.21133888  -1.02860482   0.0844747   24.02771276
  -3.2503911    9.39577811  15.48032078  11.81227642  11.33050653
  20.87249805  10.39823758  -7.63512192   0.2651009   -0.58091075
  15.40527451  12.1972053   10.94190636  17.62721677   1.85982617
   6.90340618  -4.09375511  -2.27053933  24.21653178  20.55775053
  14.6732048   12.29145694 -15.90763182   1.69265502   4.59426121
   9.40712011  17.1802068    8.25498869   4.47622042   3.40576305
  -3.90456467   9.44306324  10.58582292  14.06545616  -1.93219052
  11.57873759  15.98778161  16.27200539  -4.04954174   3.70886239
   1.14799481   0.58832677  23.78542977  18.05678065   7.90950669
   2.81432741   7.50555023   0.96054699   3.92926823  -2.44697963
   2.40397975  -2.66739115   1.31101554  -3.02371288  30.22538761]
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1595.9435874126232
gradient value of function right now is: [-1.44777286e+00  5.40523715e-06 -1.26458914e+00  4.71757900e-06
  1.44777286e+00 -5.40523715e-06  1.26458914e+00 -4.71757900e-06
 -2.36385913e+00 -6.62318682e-03  4.36351243e-02 -1.63777374e-01
 -2.23053649e-05 -3.36306247e-09  1.00363821e-05 -3.57797790e-07
 -2.27973423e+00 -1.53173310e+00 -6.32365998e+00 -1.72687889e+00
 -2.77980478e-05 -6.87380335e-09  1.99100639e-05 -5.22395501e-07
  2.16231073e+00  1.89805282e+00  2.58063697e+00  9.55686009e-02
 -2.96049815e-05  4.46913784e-05 -1.36167957e-01  7.68439286e-03
 -1.87544895e-01 -1.81401800e-01 -2.15226231e-01 -3.29995360e-01
  1.23147587e-02  9.37604274e-03  3.63821547e-01  2.54901902e-01
  1.68297555e-01  1.04447136e-01 -6.58953956e-03 -1.56876580e-01
 -1.09120669e+00 -3.17368575e-02 -6.15230079e-02 -7.72988667e-02
  1.29969557e+00  1.89939455e+00  2.23868821e+00  1.96135816e+00
  5.33906119e-02  6.38526429e-03  2.45470250e-03 -3.37079494e-03
 -1.90264329e+00  4.78717279e+00 -1.94946540e-02 -1.75415200e+00
  1.61435048e+00 -1.26863353e+00  3.16106904e+00 -2.17091350e+00
  1.07262594e+01]
supnorm grad right now is: 10.726259399816087
Weights right now are: 
[  0.92730891   1.80484466  -4.31611052   2.64602392  -1.71752815
  -1.79038103   4.88741656  -1.23094087   0.52669881  26.23582763
  -3.41213232   9.42843985  14.97807728  11.81219585  11.01777603
  20.88382359   9.91268416  -8.10925249  -0.39475803  -0.99569653
  14.90090511  12.19714046  10.61056542  17.6346113    2.26722343
   7.34051037  -3.68755179  -3.0755537   25.01334424  20.43942968
  13.97117518  14.19778586 -16.60880653   1.01940025   4.62411337
   9.08010215  16.00776067   6.62332925   4.85181653   3.76197339
  -3.53932582  10.19520197  10.9122081   14.22459529  -2.35597021
  11.72220148  16.51960245  17.02365756  -2.83302715   4.52937143
   1.4746709    0.66552332  25.84359065  19.25450959   7.9226125
   2.25089338   7.09031542   1.59216155   4.52901935  -1.90390653
   2.62926084  -2.66039226   1.25077329  -3.06399255  30.72319887]
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1590.6706651043971
gradient value of function right now is: [ 4.53604269e+00  3.94120771e-05  2.15531520e+00  5.49715431e-05
 -4.53604269e+00 -3.94120771e-05 -2.15531520e+00 -5.49715431e-05
  1.08823282e+01  6.23623430e-02  2.63870645e-03  1.25907778e+00
  4.60225619e-06  2.00326508e-08 -1.53625337e-04  9.48467596e-07
 -9.64410576e-01 -2.26434148e+00  1.46823064e+01 -2.58761447e+00
  4.78214372e-06  4.29943050e-08 -2.27502125e-04  1.57219231e-06
 -9.88349813e+00 -7.40151602e+00 -1.09278482e+01 -1.19144433e+00
 -2.91388485e-03 -6.62349181e-04 -6.81056988e-01 -1.34779332e-02
  1.86193251e-01  3.38267340e-02  1.87281606e+00  1.46047289e-01
 -1.14862260e-01 -3.45297690e-02 -3.81902370e+00 -2.93799502e-01
  3.29763547e+00  6.42478784e-01  6.13358540e-01  6.78621892e-01
  8.75787237e+00  8.71348245e-01  5.61739683e-01  4.67125841e-01
 -2.41703043e+00  2.94643631e+00  5.27541791e+00  6.84685852e+00
 -1.04157970e-01 -5.42471122e-03  3.76071644e-02  9.86400754e-02
  4.91216081e+00 -1.59389844e+01 -6.96614593e+00  1.03708173e+01
 -6.50569378e+00  1.32315049e+01 -6.95850766e+00  1.39929241e+01
  5.44072473e+01]
supnorm grad right now is: 54.407247328942844
Weights right now are: 
[  0.98415072   1.76978529  -3.8254633    2.597227    -1.77436996
  -1.75532166   4.39676934  -1.18214396   0.22972237  26.13579872
  -2.84864188   9.85550119  14.99027105  11.81221258  11.29267961
  20.88371204  10.18660532  -7.83720882   0.04677145  -0.70746383
  14.91860897  12.19704488  10.96687264  17.63406783   2.24476917
   7.21778354  -3.66344388  -2.78308153  24.66860443  18.9685569
  14.07252196  14.55959914 -16.77979248   1.21802248   5.05558307
   8.80831427  14.21916348   4.85314791   4.57696563   4.26745698
  -3.76270184   9.85967833  11.14076361  14.46110886  -2.3638557
  11.58308934  16.70765666  17.45241088  -2.96056148   4.32669329
   1.45763146   0.64806525  26.3049655   20.26277085   8.32391882
   2.38025112   7.45773766   1.25857569   3.91333267  -2.03565276
   2.32802158  -2.7560577    1.32459486  -3.15929479  30.79910541]
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1586.8618839191158
gradient value of function right now is: [-3.38674094e+00 -5.10996709e-08 -2.86989615e+00 -2.01168444e-06
  3.38674094e+00  5.10996709e-08  2.86989615e+00  2.01168444e-06
 -5.44752918e+00 -1.66309121e-02 -4.65416076e-01 -3.98529167e-01
 -2.66275593e-05 -5.12188356e-09  3.57869746e-05 -5.96668840e-07
 -2.22895009e+00 -5.20429624e-01 -1.70893870e+01 -4.95562041e-01
 -3.20955638e-05 -1.07751409e-08  5.07113384e-05 -8.58209375e-07
  1.03437282e+01  6.47917956e+00  1.13104565e+01  1.00339989e+00
  2.68188521e-04  8.28658860e-05  1.05451671e-01  5.33693565e-03
 -4.35723566e-01 -2.84656869e-01 -1.25837833e+00 -4.82455208e-01
  4.77382267e-02  2.03364809e-02  1.18450760e+00  3.15254652e-01
 -3.18447771e+00 -3.99299122e-01 -4.57439775e-01 -6.08035796e-01
 -1.03867105e+01 -9.37455632e-01 -7.49326290e-01 -6.26268480e-01
  4.22347824e+00  7.02769162e-01  2.26987700e-02 -8.12978883e-01
  1.03029645e-01  2.54545920e-02  3.70578032e-02  4.66261544e-02
 -5.20839401e+00  1.61613639e+01  3.70709474e+00 -1.23188461e+01
  5.42124221e+00 -1.62748180e+01  7.61464114e+00 -1.73556884e+01
 -1.39238369e+01]
supnorm grad right now is: 17.35568840617219
Weights right now are: 
[  0.96381741   1.67777544  -4.49516326   2.48375504  -1.75403665
  -1.6633118    5.06646931  -1.06867199   0.87554667  26.34227362
  -3.43562734   9.75555607  15.16400347  11.81226334  11.83187733
  20.89958253  10.33156716  -7.73355013  -0.46289819  -0.56846994
  15.10844957  12.197138    11.5813872   17.65095178   2.37296722
   7.57055053  -3.5178962   -2.4608605   22.82524956  17.35075661
  14.4467801   15.52076594 -17.47441088   0.85503819   4.73617337
   8.8630114   12.91780667   3.69774501   4.61574088   3.92244029
  -4.05828853   9.62454843  11.27285347  14.80940444  -2.27721773
  12.19355059  17.62597925  18.44605921  -2.66631816   4.39640446
   1.30883029   0.34456697  27.25088871  20.61783424   7.94555485
   1.93016446   7.33155132   1.55351932   3.95364249  -2.12938589
   2.45259987  -2.63809715   1.18294135  -3.09818911  30.6236759 ]
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1594.3534916725218
gradient value of function right now is: [ 6.90459540e+00  1.23663470e-05  7.71663325e-01  1.53388701e-05
 -6.90459540e+00 -1.23663470e-05 -7.71663325e-01 -1.53388701e-05
  1.44832321e+00  6.99164292e-03 -1.05884184e+00  4.88211091e-02
  2.57875739e-06  1.17336836e-09 -5.84810630e-05  1.97958233e-07
 -2.31841745e-01 -1.43873008e+00  6.86045816e+00 -1.62784802e+00
  2.76926322e-06  3.88803450e-09 -7.62045314e-05  2.71347366e-07
 -6.82867088e+00 -4.90220879e+00 -7.82697949e+00 -1.05345477e+00
  4.60111889e-05 -2.43933509e-06 -1.86778414e-01 -1.07353422e-03
 -2.44737513e-02 -4.75182893e-02  5.57529893e-02  1.07321101e-01
 -9.51939185e-03 -5.11348770e-03 -9.99702221e-02 -7.72125066e-02
  1.39089222e+00  1.46074705e-01  1.61259507e-01  2.31202450e-01
  5.58405273e+00  5.95757751e-01  4.67567993e-01  4.18152392e-01
 -2.15013366e+00  1.49023569e+00  2.28310176e+00  2.84910557e+00
 -9.59665656e-02 -3.97487504e-02 -6.44466925e-02 -1.07548169e-01
  2.88314307e+00 -1.03949501e+01 -2.55740036e+00  4.85326317e+00
 -2.79985338e+00  9.22901480e+00 -3.84026604e+00  1.05861988e+01
  2.39473866e+01]
supnorm grad right now is: 23.9473866404663
Weights right now are: 
[  1.06728524   2.04624472  -4.40504975   2.86606822  -1.85750448
  -2.03178108   4.9763558   -1.45098517   0.05085854  26.98095651
  -3.07333201   9.53345387  14.12861042  11.81228642  11.35243086
  20.89371821  10.29544496  -7.92643049  -0.27188736  -0.71541914
  14.00170703  12.19719922  11.14889263  17.64168178   2.16287486
   7.20398007  -3.59071228  -3.80340615  24.4701905   18.77963785
  14.51362485  15.538346   -16.48980159   1.95684269   4.42405405
   8.92241425  14.58407775   4.42568289   5.44463768   3.50224443
  -3.70310794   9.50044019  10.90761003  14.40603491  -2.47935483
  12.09507878  17.77866462  18.84740321  -2.8378669    4.23628932
   1.2901641    0.28011472  26.87625343  22.07334245   9.31375216
   3.202466     8.11246158   1.07893348   3.70220147  -2.24581407
   2.34585877  -2.74187273   1.1742243   -3.1078686   30.75254736]
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1589.148639985143
gradient value of function right now is: [ 2.03643294e+00  1.08258015e-02  6.17074442e-01  1.12012150e-02
 -2.03643294e+00 -1.08258015e-02 -6.17074442e-01 -1.12012150e-02
 -1.87928260e+00 -1.22221490e-02 -7.26271985e-01 -4.03547704e-01
 -8.46376636e-03 -1.45943942e-08 -7.31473802e-03 -9.38331571e-07
  9.37219979e-01  3.22163308e-01  2.67332362e+00  3.96708346e-01
 -8.94877775e-03 -2.93348198e-08 -7.96599303e-03 -1.51515795e-06
 -2.00211539e+00 -1.45313684e+00 -2.45855538e+00 -9.49692276e-02
  4.06219582e-04  7.66186434e-05  1.47240119e-01  5.70865901e-04
 -1.05866331e-02 -2.84790743e-02 -1.44528089e-01  8.82067022e-02
  5.10859758e-02  1.16495871e-02  1.41811704e+00  6.63835262e-02
  3.18019186e-01  6.77765315e-02  1.31217619e-02 -2.50890561e-02
  1.46505916e+00  2.61495665e-01  1.14238086e-01  6.12750086e-02
 -1.16689826e+00 -1.41288731e+00 -1.94546965e+00 -2.35684540e+00
 -3.51236426e-02 -2.50079605e-02 -2.90288118e-02 -3.13442911e-02
  5.84965038e-01 -3.57178049e+00  5.32688618e-01  4.07008542e+00
  2.06705580e-01  3.06282779e+00  3.16966037e-01  2.23006766e+00
 -1.08247258e+01]
supnorm grad right now is: 10.824725769165388
Weights right now are: 
[  1.34420277   3.08915793  -4.17957468   3.89083408  -2.13442201
  -3.07469429   4.75088072  -2.47575103   0.03401447  27.48647094
  -2.63314848  10.32110384  14.94675698  11.81137986  10.73770391
  20.90544684  10.47738394  -7.72442389  -0.09482912  -0.4001023
  14.83223207  12.19479369  10.56235725  17.62815801   2.30202471
   7.43404074  -3.34184387  -3.6824016   25.80027063  19.70703171
  14.91120712  15.07907035 -13.70481621   5.47296397   6.18519558
  10.54441494  14.93097265   4.93274624   4.62089839   3.42814479
  -3.43898644   9.4176545   10.74606732  14.18966389  -2.22949839
  12.14967194  17.98799656  19.13807706  -2.43970066   3.91008545
   0.78641329  -0.04632987  26.35453364  23.43609036  10.52917263
   3.99857667   8.77193173   0.27606591   4.4228645   -1.87642007
   2.43146509  -2.74081753   1.23520024  -3.24279623  30.52250881]
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.052802069882
gradient value of function right now is: [ 2.82316410e+00  8.76911165e-03  1.26253325e+00  9.18004590e-03
 -2.82316410e+00 -8.76911165e-03 -1.26253325e+00 -9.18004590e-03
  1.26690350e+00  6.48721581e-03 -1.07728567e+00  1.14938136e-02
  1.47607944e-03  3.42693083e-10 -7.71459105e-03 -1.08012272e-07
  1.17055178e+00  2.95842911e-01  6.32660348e+00  3.03453463e-01
  1.55387215e-03  1.31052133e-09 -8.61514468e-03 -1.14915526e-07
 -3.94947430e+00 -2.56457817e+00 -4.61502004e+00 -1.80136042e-01
  2.03613238e-04  1.52299895e-05 -2.27928125e-02 -1.65643013e-04
 -1.55990135e-01 -1.20354258e-01 -1.23885908e-01  7.64419793e-02
 -4.82498244e-04 -6.44993266e-03  6.00383110e-02 -1.54054614e-02
  7.46323429e-01  1.02576566e-01  8.52231886e-02  1.15011152e-01
  3.37900565e+00  5.17885922e-01  3.02426268e-01  2.61350359e-01
 -1.36317184e+00 -2.75189321e-01 -6.02371512e-02  7.29326334e-02
 -4.24871980e-02 -2.16025771e-02 -2.98805831e-02 -4.49355045e-02
  1.30934785e+00 -7.01558114e+00 -9.01107411e-01  6.49207991e+00
 -1.14088182e+00  6.81500277e+00 -1.36658132e+00  7.45585549e+00
  5.47913045e+00]
supnorm grad right now is: 7.455855485815359
Weights right now are: 
[ 1.30601714e+00  1.23104294e+00 -4.71125179e+00  2.03871084e+00
 -2.09623638e+00 -1.21657931e+00  5.28255784e+00 -6.23627795e-01
 -2.59242911e-01  2.72682090e+01 -2.65574718e+00  1.01216395e+01
  1.65800442e+01  1.18113389e+01  1.26535717e+01  2.09408754e+01
  1.03303486e+01 -7.87888433e+00 -2.94160724e-01 -4.80485032e-01
  1.64093937e+01  1.21947665e+01  1.24764890e+01  1.76530700e+01
  2.41565660e+00  7.69371059e+00 -3.18561979e+00 -3.08470005e+00
  2.63097361e+01  2.06483791e+01  1.51546768e+01  1.62913068e+01
 -1.34986240e+01  6.25078128e+00  5.57664511e+00  9.93869119e+00
  1.53148680e+01  5.37696523e+00  4.93310874e+00  2.84134311e+00
 -3.33735639e+00  8.39537099e+00  9.89535186e+00  1.38020552e+01
 -2.18108269e+00  1.21739926e+01  1.86047617e+01  2.02391232e+01
 -1.69258043e+00  4.25436997e+00  8.22022139e-01 -1.91502482e-02
  2.71374845e+01  2.50655137e+01  1.14428143e+01  4.61332028e+00
  8.89246882e+00  5.13325725e-01  4.62767886e+00 -1.90768665e+00
  1.93120232e+00 -2.88034779e+00  8.08584208e-02 -3.18715659e+00
  3.05090073e+01]
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1600.47012844845
gradient value of function right now is: [ 2.15695245e+00 -2.17453416e-03  8.72431466e-01 -2.12222440e-03
 -2.15695245e+00  2.17453416e-03 -8.72431466e-01  2.12222440e-03
  5.33653243e-01  9.87367743e-03 -6.93167558e-01  1.23766690e-01
  6.92506030e-03  1.08538329e-09 -6.76878871e-03  5.82914357e-09
  4.62991004e-01 -1.28500063e-01  4.44616165e+00 -1.72883062e-01
  7.56756096e-03  2.64692040e-09 -7.52087857e-03  2.54156520e-08
 -3.23109241e+00 -1.98783364e+00 -3.81001570e+00  2.24649352e-02
 -4.33587947e-05  7.40752690e-06 -1.04583654e-01 -3.02933524e-06
 -2.81621992e-02 -2.21722414e-02  4.37322742e-02  5.68323992e-02
  1.36170002e-02 -9.31050054e-04 -2.14329071e-01  2.25295950e-02
  8.16096150e-01  9.46030625e-02  6.86207728e-02  7.28924701e-02
  3.26626758e+00  4.38334120e-01  2.47856529e-01  2.06670146e-01
 -1.14262900e+00  3.92766482e-01  9.01867081e-01  1.18576218e+00
 -3.91301167e-02 -1.33105202e-02 -2.00951686e-02 -3.22508144e-02
  1.22881720e+00 -5.99079844e+00 -1.17862614e+00  5.28482677e+00
 -9.82932387e-01  5.75886196e+00 -8.34803153e-01  6.00048023e+00
  2.01654027e+00]
supnorm grad right now is: 6.000480227084907
Weights right now are: 
[  1.02858878   2.02817631  -4.93729914   2.83174486  -1.81880801
  -2.01371267   5.50860518  -1.41666181   0.09167782  26.54784399
  -2.36145528  10.49305847  16.3501207   11.81135283  13.11044653
  21.03203054  10.05297839  -7.87311228  -0.58077182  -0.63135617
  16.15880798  12.19472966  12.92754489  17.75481193   2.39641582
   7.70734058  -2.96382178  -3.30257932  26.69096618  20.92061611
  15.31107202  15.36295827 -12.79938097   7.51506188   6.05974524
  10.23590863  14.43823713   4.94383047   4.15087215   1.77371637
  -2.81533609   8.4203688    9.95149114  14.02194586  -2.10778768
  12.16054367  18.93249104  20.61234034  -2.35750302   4.2798188
   1.44544052   0.61350901  28.7667839   27.14002522  14.15386785
   7.47670159   8.05185089   0.90943494   3.99959517  -2.28967203
   1.4077191   -2.97335681  -0.44048457  -3.24381452  30.51617481]
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1601.0945323516405
gradient value of function right now is: [ 1.47028941e+00  1.05023195e-02  8.77210781e-01  1.06732536e-02
 -1.47028941e+00 -1.05023195e-02 -8.77210781e-01 -1.06732536e-02
  8.97252852e-01  9.69746830e-03 -4.68134614e-01  1.83909757e-01
  5.72904207e-03  1.14105121e-09 -8.23537793e-03  9.99953521e-09
  5.97424966e-01  9.33938806e-02  3.92287458e+00  7.14044027e-02
  6.27851248e-03  2.69046736e-09 -9.04315906e-03  4.68348465e-08
 -2.72187410e+00 -1.71508782e+00 -3.28538010e+00  8.65710260e-02
 -8.17844115e-05  3.96288489e-06 -9.05857360e-02 -1.79739505e-04
  4.64753230e-03  3.92935928e-03  1.08776970e-01  7.92190239e-02
  1.24241870e-02 -7.02416234e-04 -4.26805159e-01  8.08884931e-03
  6.44338663e-01  6.55411738e-02  5.57738525e-02  7.03572199e-02
  2.93081418e+00  3.67221341e-01  2.07117058e-01  1.67893610e-01
 -1.01404107e+00  2.10929798e-01  7.44380622e-01  1.17455477e+00
 -3.57937822e-02 -1.18239263e-02 -1.72039607e-02 -2.58277609e-02
  1.08510112e+00 -5.31978900e+00 -1.03688810e+00  4.34841029e+00
 -9.11875586e-01  4.82158558e+00 -7.49897317e-01  5.01793768e+00
  7.52686068e-01]
supnorm grad right now is: 5.319789004521819
Weights right now are: 
[  1.38850197   2.08247842  -5.06738132   2.87382695  -2.17872121
  -2.06801478   5.63868737  -1.45874391  -0.04655089  27.30252028
  -3.16224051  10.14878273  16.97287245  11.81134299  13.90773301
  21.04473069  10.823639    -7.11803306  -0.47828879   0.20359037
  16.77448735  12.19473436  13.71568923  17.75391848   2.36405349
   7.63231207  -2.98547296  -3.41887781  27.15354526  21.67726246
  15.90424025  16.21981334 -13.39653727   7.53868123   4.99155893
  11.15977286  14.96950677   5.90207448   4.67315239   1.73168891
  -2.66812171   8.29960179   8.9513462   12.87013383  -2.03377152
  12.21202716  19.49050836  21.49725054  -2.18324806   3.80331974
   1.11776359   0.03806622  28.9370799   29.25198106  15.2508404
   7.69651003   8.61876016   0.29092885   3.89946546  -2.092912
   1.71700686  -2.93648379  -0.21767318  -3.25938845  30.6307597 ]
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1601.1699984826432
gradient value of function right now is: [ 9.96655134e-01  2.56172461e-02  8.38976349e-01  2.60048668e-02
 -9.96655134e-01 -2.56172461e-02 -8.38976349e-01 -2.60048668e-02
  9.24191572e-01  6.63291606e-03 -3.18854602e-01  1.40026243e-01
  8.72506901e-04  9.20503467e-10 -8.88704732e-03 -4.17012557e-08
  7.44206402e-01  2.78693294e-01  3.57883812e+00  2.79780257e-01
  1.07585474e-03  2.11117946e-09 -9.62460980e-03 -3.47278254e-09
 -2.32911288e+00 -1.43785443e+00 -2.85794368e+00  8.08330453e-02
 -7.77152256e-05  1.90180171e-06 -5.09743945e-02 -1.42599275e-04
  9.02840092e-02  6.47947534e-02  2.08891850e-01  9.68335582e-02
  8.18881334e-03 -1.44182180e-03 -3.40033461e-01  1.41843055e-04
  6.76332715e-01  7.93390066e-02  6.31108538e-02  8.80849543e-02
  2.67830832e+00  3.32989406e-01  1.71644617e-01  1.27637574e-01
 -9.78409199e-01 -2.50880764e-02  3.13625021e-01  6.30793889e-01
 -3.25474055e-02 -1.21270092e-02 -1.64150012e-02 -2.67313066e-02
  9.24818781e-01 -4.72522752e+00 -7.73989588e-01  4.21768372e+00
 -6.74411899e-01  4.13850131e+00 -5.91851295e-01  4.21208101e+00
  1.02100023e+00]
supnorm grad right now is: 4.7252275221689155
Weights right now are: 
[  1.60665991   3.14657516  -4.61878632   3.93669058  -2.39687915
  -3.13211152   5.19009236  -2.52160753  -0.047669    26.9033431
  -3.00275355  10.20134251  16.13000399  11.81125976  14.41643648
  21.21338991  10.91567299  -7.3422383   -0.37982862   0.04160351
  15.92693025  12.19448653  14.23693208  17.93418972   2.46023258
   7.74642096  -2.71830721  -3.78354958  26.23055442  20.51798384
  16.43840034  16.42307331 -12.88374875   8.21754634   5.61441841
  12.36018351  14.1841575    5.86177223   4.67893467   2.40395653
  -2.42471068   8.00764859   9.24211513  13.62948791  -1.8356633
  12.34574926  19.73085024  21.52328113  -2.56471397   3.93730462
   1.22708769  -0.50100575  30.15046319  30.78402409  15.74050314
   7.5284155    8.16416705   0.55724256   3.17235205  -2.33179152
   2.16908258  -3.06343523  -0.15629102  -3.49363023  30.63161363]
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1601.1004641663862
gradient value of function right now is: [ 1.58504604e+00  3.69603463e-02  8.62749636e-01  3.76491681e-02
 -1.58504604e+00 -3.69603463e-02 -8.62749636e-01 -3.76491681e-02
  5.72557056e-01  4.27258153e-03 -4.65429193e-01  1.13365266e-01
 -5.58030135e-03  6.20109295e-10 -9.53043361e-03 -3.16627998e-07
  7.80945405e-01  2.22938061e-01  3.38953904e+00  2.18419373e-01
 -5.86768097e-03  1.38429564e-09 -1.02994145e-02 -3.11368216e-07
 -2.53867494e+00 -1.62873915e+00 -3.17251451e+00 -1.36049015e-02
 -8.08734450e-05  1.34364133e-06 -3.80918454e-02 -9.11659307e-05
  1.57143998e-02  1.69230090e-02  8.34827894e-02  8.12842119e-02
  9.88518252e-03 -6.73756801e-04 -2.79770445e-01  1.08338935e-03
  6.30093022e-01  6.76236602e-02  5.25990289e-02  7.72280844e-02
  2.89550852e+00  3.55469716e-01  1.95108293e-01  1.63207086e-01
 -9.89640279e-01  7.66577379e-03  2.73351624e-01  4.91771321e-01
 -3.20957936e-02 -1.08344545e-02 -1.40948201e-02 -2.39457260e-02
  9.81629399e-01 -4.85261232e+00 -8.26155942e-01  4.39582504e+00
 -7.67217327e-01  4.57774108e+00 -8.25842229e-01  4.92428325e+00
  1.47805337e-01]
supnorm grad right now is: 4.924283252757392
Weights right now are: 
[  1.37520505   2.24240212  -4.85608131   3.03601953  -2.16542428
  -2.22793848   5.42738736  -1.62093648   0.09971222  25.22075224
  -3.02835007   9.92922687  16.99748263  11.81124797  15.0177304
  21.27471575  10.35140641  -7.9036361   -0.67704369  -0.5562468
  16.78784626  12.19430104  14.81091978  18.00131553   2.21800318
   7.44320004  -2.76606415  -3.88257863  27.18564423  20.49006894
  17.55241916  16.77440126 -12.85297387   8.13764206   5.81537026
  11.02097286  14.32495731   7.01424854   4.31064442   2.83148179
  -2.09055248   8.55749147   9.55828526  13.42915069  -2.15045562
  12.45290991  20.13717805  22.18670704  -1.72771288   4.56092425
   1.56122358   0.10719484  30.811469    31.92515174  17.09306637
   8.78343709   7.90122614   1.04214105   3.28771984  -2.46143719
   1.76418307  -2.98906717  -0.07214144  -3.21341788  30.67982131]
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1175.6498851869019
W_T_median: 1075.6381107123923
W_T_pctile_5: 931.095317705531
W_T_CVAR_5_pct: 895.7105951445934
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.6
F value: -1601.1004641663862
-----------------------------------------------
