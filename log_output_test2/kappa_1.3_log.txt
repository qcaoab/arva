Starting at: 
2022-06-20 18:03:38
tracing parameter entered from terminal:  1.3


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[ 0.10347998  0.18844875 -0.3666709   0.62803316 -0.89369922 -0.17398511
  0.93797695  0.78704989 -0.60791207 -0.16293226 -0.31685198  0.28094308
  0.0404241   0.17453202  0.0940472   0.01169373  0.2300954  -0.23784803
  0.78511084 -0.41859022  0.4809118  -0.01155852  0.07219357 -0.14482284
  0.4701344  -0.18827011 -0.8138637  -0.24629474  0.28361272  0.33354483
 -0.63777411 -0.25343004 -0.81551088 -0.26234589  0.20198453 -0.15135741
  0.25264285 -0.29817275  0.41496663 -0.58895503 -0.60305385 -0.63454123
  0.3979274   0.74701442  0.57452389 -0.67377327  0.6493153   0.07340044
 -0.29694484  0.52758424 -0.14347696  0.04319718 -0.28527617 -0.63077443
  0.13133703 -0.58713125  0.12759166  0.87507529 -0.19770888 -0.66759109
  0.25529887 -0.48501395  0.58877641 -0.72315372] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1260.6521530687958
W_T_median: 1222.3920506735662
W_T_pctile_5: 834.1581876304141
W_T_CVAR_5_pct: 746.6575474940535
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2532.9480118816286
gradient value of function right now is: [-1.5393308  -0.30532516 -0.82518956 -0.31036577  1.5393308   0.30532516
  0.82518956  0.31036577  0.08889706  0.02506393  0.85069339  0.04286007
 -0.06824414 -0.05580068 -0.61119225 -0.06974391 -0.24041918 -0.13457379
 -2.23202481 -0.18311648 -0.105777   -0.09624953 -0.94018295 -0.11803019
  0.10872675  0.01491186  0.0072383   0.01890046 -0.31966996 -0.09340027
 -0.04277875 -0.11460466  0.98238639  0.18567017  0.08772939  0.23116235
 -0.42226602 -0.0928183  -0.04324271 -0.11491742  0.96398775  0.13579911
  0.14035804  0.14876067 -0.50306833 -0.07693461 -0.07872496 -0.08508107
 -0.1419821  -0.02077885 -0.02129073 -0.02302823 -0.54416908 -0.0796835
 -0.081994   -0.087646    0.45156614 -1.38240125 -0.34712925  1.04449623
 -0.2630519   0.83202204 -0.45292378  1.31734563  4.18916301]
supnorm grad right now is: 4.189163005011728
Weights right now are: 
[-3.28318295e-02 -9.54238766e-01 -1.29818500e+00 -8.02156001e-01
 -7.57387407e-01  9.68702404e-01  1.86949104e+00  2.21723905e+00
  5.46432849e-01  8.09370750e-01  1.60870396e+00  1.38246349e+00
  1.03343978e+00 -1.77569874e+00  3.63802422e+00 -1.59177942e+00
  2.52364405e-02 -1.71272001e+00  2.67026414e+00 -1.63280526e+00
  1.14944948e+00 -2.27276307e+00  3.68475730e+00 -1.78765805e+00
  2.29113878e+00  1.33962575e+00  6.89634702e-01  1.24704589e+00
  4.57904338e+00 -2.86800870e+00 -1.31113049e+00 -2.50930506e+00
 -2.98138921e+00  1.98504933e+00  1.48437839e+00  1.88994688e+00
  3.84095617e+00 -2.49677291e+00 -3.04934930e-01 -2.31830927e+00
 -2.86243477e+00  3.11068093e+00  3.77853883e+00  4.72498835e+00
  3.49195413e+00 -4.36653554e+00 -2.39834768e+00 -3.79121389e+00
  3.74632696e+00 -1.13460159e+00 -1.26608100e+00 -2.05158479e+00
  3.17165092e+00 -4.49686401e+00 -1.77247217e+00 -4.69701905e+00
  4.14473979e+00  2.41847140e+00 -1.18282151e+00 -2.37324298e+00
 -4.34593198e-01 -2.09882957e+00 -2.07852658e+00 -2.56794201e+00
  2.59660163e+01]
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2533.9302782580216
gradient value of function right now is: [ 7.69574795e-01  1.37894830e-01  3.11049064e-01  1.45848038e-01
 -7.69574795e-01 -1.37894830e-01 -3.11049064e-01 -1.45848038e-01
 -1.37583121e-01 -1.03855596e-01 -7.94702722e-01 -1.18099953e-01
  2.65179276e-02  3.82794145e-03  1.60716985e-01  9.09445931e-03
  9.93695220e-02  6.24280153e-02  5.75256035e-01  7.42832744e-02
  4.38153047e-02  1.57552382e-03  2.64741786e-01  9.82268133e-03
 -4.48142775e-02 -6.63207753e-03 -4.75971660e-03 -7.88408145e-03
  2.15857280e-01  5.32583339e-02  2.82757318e-02  6.33153866e-02
 -3.19431684e-01 -5.66919166e-02 -3.75587063e-02 -6.86165484e-02
  2.47721823e-01  6.55647250e-02  3.29373964e-02  7.77219887e-02
 -6.80025791e-01 -5.81207271e-02 -4.44438480e-02 -1.04620114e-01
  2.41718773e-01  1.49979807e-02  1.09163480e-02  3.11414489e-02
  3.82103392e-02  9.82717001e-04  3.69321241e-04  3.97668935e-03
  2.56894006e-01  1.79118635e-02  1.32607929e-02  3.53020567e-02
 -1.03499604e+00  2.07131091e+00  1.86605100e-01 -5.02136056e-01
  9.16120973e-02 -2.98551707e-01  5.24586359e-01 -1.16554042e+00
 -4.64065266e-01]
supnorm grad right now is: 2.071310907141412
Weights right now are: 
[ 0.32749696 -1.1997275  -1.0803566  -0.9763859  -1.11771619  1.21419113
  1.65166265  2.39146895  0.90178681  1.58778566  1.56197248  2.08384369
  1.72068149 -1.5360652   5.12613781 -1.24906192  0.64364379 -1.50594163
  3.93689521 -1.30646885  1.90954802 -2.00798761  4.99554347 -1.41044618
  1.44861948  1.6411163   0.74879986  1.46382644  5.36022905 -2.87827837
 -1.03687856 -2.52233182 -4.08287464  1.96543318  1.19338274  1.85910718
  4.79971477 -2.51039308 -0.07134808 -2.31041687 -3.07170628  4.25162032
  4.86228131  5.75093927  3.9130584  -5.24462238 -3.24818103 -4.52779411
  4.53147545 -1.35796458 -1.48085183 -2.18189784  3.68452114 -5.35561741
 -2.57335385 -5.44155095  4.42903676  2.47608677 -1.03691441 -2.89270267
 -0.13841541 -2.83318314 -2.15207161 -2.84867584 26.26081234]
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2530.96421989963
gradient value of function right now is: [ 8.05581692e-01  8.17557661e-02  1.89743289e-01  7.54362586e-02
 -8.05581692e-01 -8.17557661e-02 -1.89743289e-01 -7.54362586e-02
 -2.19687487e-01 -8.45438767e-02 -1.42953777e+00 -1.21285981e-01
  4.68765982e-02  4.72808008e-02  3.33954443e-01  6.15126877e-02
  8.52206564e-02  7.79623141e-02  5.94803346e-01  1.01689254e-01
  4.68260057e-02  4.55066065e-02  3.32451188e-01  5.94259844e-02
 -1.34404568e-02 -1.67611986e-02 -4.63454966e-03 -1.76030118e-02
  3.34258625e-01  1.12137077e-01  3.16310683e-02  1.19216275e-01
 -3.34398777e-01 -1.47080894e-01 -4.46219126e-02 -1.55427925e-01
  4.66815135e-01  1.42772643e-01  3.90638052e-02  1.52155867e-01
 -1.27246395e+00 -1.39452890e-01 -1.80550494e-01 -1.30892253e-01
  4.58909512e-01  5.13798466e-02  6.64745163e-02  4.89694347e-02
  2.36718184e-02  2.78422452e-03  3.60585505e-03  2.82519698e-03
  4.46258663e-01  4.99765293e-02  6.46477270e-02  4.75565154e-02
 -1.80803604e+00  3.54593215e+00  6.17948722e-01 -1.38698382e+00
  7.37434767e-01 -1.65644770e+00  6.23297805e-01 -1.36159162e+00
 -1.04430472e+01]
supnorm grad right now is: 10.443047168437788
Weights right now are: 
[ 0.64451434 -2.34714737 -1.53715224 -1.8294124  -1.43473357  2.36161101
  2.10845828  3.24449545  1.00153023  3.24139507  1.92985554  3.84263393
  1.69753261 -2.25273081  5.69689019 -2.10938891  1.0817589  -1.93631853
  4.72492148 -1.86037449  2.01674676 -2.17762822  5.66472192 -1.71045359
  1.56353571  2.47432995  1.37625845  2.27157878  5.53015711 -3.04804105
 -0.58057766 -2.71829751 -4.77704487  2.02396251  0.87952789  1.92829389
  4.83654074 -2.90748778  0.12675302 -2.72249186 -2.84588405  5.53331691
  6.50863633  6.30916383  4.12125505 -6.09421582 -4.33824105 -4.79810187
  5.60416361 -0.8223617  -1.25986433 -1.17987458  3.96560463 -6.14008256
 -3.57292478 -5.67665648  4.85157962  2.61727466 -1.39304782 -3.06644496
 -1.04155256 -2.64190619 -2.06620979 -3.43174445 25.73727854]
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2530.619163592669
gradient value of function right now is: [ 1.17689835e-01  7.84374584e-02  2.57403898e-01  7.68590315e-02
 -1.17689835e-01 -7.84374584e-02 -2.57403898e-01 -7.68590315e-02
 -1.92317481e-02 -1.27287424e-02 -1.37444412e-01 -2.29361385e-02
  3.18135987e-02  5.04074722e-02  2.42102353e-01  7.73688275e-02
  8.78019947e-02  1.37793426e-01  6.56207088e-01  2.08675512e-01
  3.46089273e-02  5.38757746e-02  2.63328967e-01  8.28542013e-02
 -7.05857427e-02 -2.67484734e-02 -6.79780206e-03 -2.86069515e-02
  1.98152344e-01  9.34070841e-02  3.03348154e-02  9.89998318e-02
 -4.70798339e-01 -2.34394056e-01 -7.83695928e-02 -2.48135764e-01
  2.78732815e-01  1.19448088e-01  3.70462997e-02  1.26876910e-01
 -1.06871034e+00 -1.35756020e-01 -1.64632371e-01 -1.52274696e-01
  3.83723032e-01  4.89783622e-02  5.93717713e-02  5.57487231e-02
  1.87642235e-02  2.24399268e-03  2.72980723e-03  2.93591058e-03
  3.75554150e-01  4.80242621e-02  5.82060249e-02  5.44793849e-02
 -1.63496011e+00  3.05670899e+00  5.10549298e-01 -1.14096795e+00
  5.70588943e-01 -1.27235360e+00  6.66595254e-01 -1.39424069e+00
 -1.13263488e+01]
supnorm grad right now is: 11.326348773832766
Weights right now are: 
[ 0.25635558 -1.98832556 -1.37621041 -1.50407578 -1.04657482  2.0027892
  1.94751646  2.91915883  2.04947069  4.13993208  3.07838605  5.0291289
  1.59380618 -1.64400763  5.84416822 -1.50575963  0.80999186 -1.92722396
  4.66210952 -2.01618669  1.88883837 -1.70641221  5.75986908 -1.23794903
  1.64406839  2.71083396  1.49617407  2.51617793  5.46482414 -2.7234165
 -0.26587462 -2.40489729 -4.76946923  1.83115439  0.66069845  1.74678948
  4.46100476 -2.85653138  0.17461252 -2.68247001 -2.71869222  5.67213573
  6.59317174  6.51247131  4.37627484 -5.87425943 -4.0605163  -4.68708915
  6.06195658 -0.41676787 -0.70001852 -0.93202501  4.22279443 -5.91895948
 -3.29380574 -5.56622556  5.06389566  2.63608127 -1.38843181 -3.3423975
 -1.01730972 -2.94940981 -2.14165885 -3.55417922 25.60793217]
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2531.474368700781
gradient value of function right now is: [-0.01042649  0.03716246  0.19902022  0.0398499   0.01042649 -0.03716246
 -0.19902022 -0.0398499   0.00541426 -0.00297172  0.02008337 -0.00903016
  0.01671466  0.02857792  0.16536108  0.07711504  0.06122779  0.11529364
  0.56847566  0.27700671  0.01984849  0.03424861  0.19698415  0.09204212
 -0.08973888 -0.03220433 -0.01850772 -0.03402481  0.12376811  0.06411964
  0.04428956  0.0667646  -0.44639774 -0.24206698 -0.17047727 -0.25163428
  0.23686037  0.11047175  0.07319624  0.11539717 -0.5481568  -0.08579681
 -0.10313703 -0.12371665  0.18360669  0.02632933  0.03202111  0.03996823
  0.07468079  0.00961025  0.01193     0.01653411  0.17507613  0.02531805
  0.03074556  0.03811149 -1.65641291  2.58639939  0.27192803 -0.47607309
  0.31185818 -0.54189736  0.50455843 -0.82326716 -1.23585611]
supnorm grad right now is: 2.586399388479226
Weights right now are: 
[ 0.46876241 -2.60617265 -1.5087426  -2.19807751 -1.25898165  2.62063629
  2.08004864  3.61316056  2.06902443  6.68733831  3.45996892  8.68755087
  2.50206115 -1.27716272  6.45346631 -1.14304488  1.34617411 -1.49625768
  4.91470539 -1.82043998  2.77400433 -1.49322947  6.32513231 -1.02189959
  1.59669385  2.53268105  2.5677255   2.31714383  5.58146896 -2.19963331
 -0.67459934 -1.86032945 -5.10156795  1.5039989   1.70463584  1.38045121
  4.03156859 -2.96907614 -0.78434643 -2.77198226 -3.39502459  4.88389546
  5.81396035  5.9205083   5.48799338 -4.58170034 -2.7869941  -3.53898475
  6.6458871  -1.71351291 -1.81338212 -1.92819204  5.34122667 -4.62798271
 -2.02175415 -4.41197996  5.6205035   2.72395254 -1.2307016  -4.2330759
 -0.90067056 -3.77892774 -2.18121986 -4.27247427 26.42213054]
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2533.939490920138
gradient value of function right now is: [-1.10106164e-01 -4.23332013e-02 -1.10257509e+00 -4.75063471e-02
  1.10106164e-01  4.23332013e-02  1.10257509e+00  4.75063471e-02
  8.83947621e-03  1.55358189e-03  3.12686903e-01  4.58048019e-02
 -4.46604687e-03 -1.49508127e-02 -2.06906103e-01 -8.96674609e-02
 -8.98441471e-02 -1.16441285e-01 -4.14748623e+00 -1.26808854e+00
 -5.65511865e-03 -1.75403042e-02 -2.58604533e-01 -1.07408449e-01
  1.04549043e-02  1.30900111e-03  1.01228549e-03  1.34064629e-03
 -8.02629284e-02 -4.25975252e-02 -3.40787208e-02 -4.35254808e-02
  3.58382729e-01  2.13985996e-01  1.71557050e-01  2.18607533e-01
 -1.52367298e+00 -1.05134039e-01 -8.10496132e-02 -1.08611780e-01
  2.31720630e-01  2.76847044e-03  4.61877361e-03  1.68636348e-02
 -9.47584774e-02 -3.60288148e-03 -4.98287926e-03 -8.97414576e-03
 -4.46732284e-02 -4.69819780e-03 -6.02427958e-03 -8.29098079e-03
 -9.18289212e-02 -2.65209076e-03 -3.79290931e-03 -7.49321125e-03
  9.46475177e-01 -1.64178547e+00 -9.59260716e-02  9.20532690e-02
 -1.12476726e-01  1.10178130e-01 -1.79672008e-01  2.01772473e-01
  7.73520505e+00]
supnorm grad right now is: 7.735205052259647
Weights right now are: 
[ 1.03543658e+00 -2.74567119e+00 -2.20820375e+00 -2.34247815e+00
 -1.82565582e+00  2.76013483e+00  2.77950979e+00  3.75756120e+00
  1.87687896e+00  7.86798784e+00  3.05712095e+00  1.05787614e+01
  2.31370357e+00 -7.42553055e-01  6.03305118e+00 -6.82828188e-01
  1.53391747e-02 -1.05532571e+00  2.94061008e+00 -2.43079955e+00
  2.55066840e+00 -9.59132164e-01  5.86727727e+00 -5.76238563e-01
  3.71502560e+00  2.92177689e+00  3.18138791e+00  2.70996545e+00
  5.66536630e+00 -1.47097127e+00  4.63637969e-04 -1.13043885e+00
 -4.99191795e+00  1.12654565e+00  1.36798597e+00  9.97175479e-01
  1.94089704e+00 -3.75683325e+00 -1.69532343e+00 -3.56104344e+00
 -3.18741561e+00  4.64148150e+00  5.55363921e+00  5.64227783e+00
  5.68393759e+00 -3.94291135e+00 -2.13123522e+00 -2.89466895e+00
  7.02359615e+00 -1.21732910e+00 -1.23359789e+00 -1.30535456e+00
  5.52608446e+00 -3.99000461e+00 -1.36883899e+00 -3.76794541e+00
  6.13191723e+00  2.36229160e+00 -9.93155181e-01 -4.66276241e+00
 -6.77655870e-01 -4.15673747e+00 -1.90020342e+00 -4.71032573e+00
  2.64352296e+01]
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -2538.1015714618397
gradient value of function right now is: [-1.46711725e-01 -1.37039232e-02 -2.00171751e-01 -1.44534724e-02
  1.46711725e-01  1.37039232e-02  2.00171751e-01  1.44534724e-02
  1.33816322e-02  5.72908013e-03  6.09224199e-01  9.03406943e-02
 -5.60984409e-04 -2.20863812e-02 -6.28738762e-02 -5.78237946e-02
  3.03036924e-03 -2.23528902e-02 -4.12325555e-01  1.18839598e-01
 -6.80249044e-04 -2.39133591e-02 -7.29194318e-02 -6.28430959e-02
 -1.83059782e-02  1.36760116e-03  3.88162647e-04  1.48813729e-03
 -4.62476964e-02 -3.90737133e-02 -1.96636033e-02 -4.10157151e-02
  4.27074293e-03  1.71500578e-01  8.95610102e-02  1.78802167e-01
 -6.57947262e-01  1.74246459e-02  1.03169012e-02  1.76234272e-02
  1.72749752e-01  2.20475269e-03 -2.47952639e-03  1.01171072e-02
 -2.04818338e-02  5.35117553e-03  7.47862411e-03  3.48368833e-03
 -5.01372857e-03 -4.86732045e-03 -5.03777528e-03 -5.77586982e-03
 -2.52390608e-02  8.11084313e-03  1.05920477e-02  6.27863213e-03
  7.04197615e-02 -3.30377637e-01 -7.43929540e-02 -2.82668970e-02
 -8.43950157e-02 -2.47906535e-02 -1.02098006e-01  1.53405032e-02
  1.13391114e+00]
supnorm grad right now is: 1.1339111370136048
Weights right now are: 
[ 1.75389692 -3.15572801 -1.26041541 -2.7102337  -2.54411616  3.17019165
  1.83172145  4.12531675  1.63872736  8.40442087  2.34174503  9.33333458
  2.29993894 -1.5739201   6.95501963 -0.56606942 -0.6455783  -0.68118006
  3.47590299 -2.44312917  2.55557125 -1.72926937  6.81335971 -0.43326667
  4.46844505  3.09855275  3.25729421  2.89872025  5.8279922  -0.78715888
  0.44680286 -0.45107547 -5.26523026  0.43339474  0.96015979  0.30396902
  2.63756497 -4.79072764 -1.98884821 -4.66069538 -1.91889293  5.35455181
  6.35264748  6.09286334  4.50660497 -4.96305626 -3.21801881 -3.71659769
  7.24850757 -1.52008466 -1.32041825 -0.98620118  4.27924594 -5.194728
 -2.6467634  -4.78962506  6.31643062  2.26986998 -0.70530137 -4.00965896
 -0.27939842 -3.57571242 -1.40918832 -4.37116969 26.16378804]
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2531.8070509806266
gradient value of function right now is: [-1.97044018e-01  1.42765422e-01  4.24014246e+00  1.45446584e-01
  1.97044018e-01 -1.42765422e-01 -4.24014246e+00 -1.45446584e-01
  4.40731799e-03  9.62246325e-04  6.95898062e-01  2.52321680e-02
  1.83429561e-03  3.73010337e-01  1.98851817e-01  6.64831518e-01
  5.03101766e-02  6.65697807e-01  3.83198465e+00  4.48631461e+00
  2.03711764e-03  4.05054038e-01  2.18370625e-01  7.25122475e-01
  2.11870480e-03  2.42388266e-03 -1.94284350e-03  5.64197656e-03
 -9.97397783e-03  3.54840545e-01  2.89518799e-01  3.55913353e-01
 -4.75340403e-01 -3.20833626e+00 -1.64611351e+00 -3.45223729e+00
  1.47475447e-01  1.45903076e-01  2.50052080e-02  2.10897801e-01
 -6.50474162e-01 -2.21374297e-01 -1.96007161e-01 -2.38159803e-01
  2.52778681e-01  1.62768115e-02  1.66775828e-02  1.27069751e-02
  2.17976342e-01  3.67583162e-01  3.39862926e-01  3.98658652e-01
  3.44675454e-01  2.44145121e-02  2.58754170e-02  1.83214657e-02
 -1.78108978e+00  2.48380591e+00  5.82850230e-01 -8.00128461e-01
  5.50319664e-01 -7.50669777e-01  7.00498847e-01 -8.72369710e-01
 -4.86112077e+00]
supnorm grad right now is: 4.8611207705818975
Weights right now are: 
[ 1.46613379 -3.20563641 -0.73645625 -2.74487962 -2.25635303  3.22010005
  1.3077623   4.15996267  1.61267359  8.39114017  2.73461207  8.92896834
  3.63592205 -1.2432998   8.27043067  0.11624145 -0.60524581  0.12036171
  3.55861185 -2.59143267  3.82342303 -1.41296677  8.10541987  0.23366979
  5.33144948  2.26923221  3.26678577  1.97245652  6.78428902  0.06343988
 -1.4096647   0.63641587 -5.81812966 -0.2092267   2.45710173 -0.51403621
  3.19672245 -5.60770608 -2.37303036 -5.66021987 -2.45463388  4.65104414
  5.78545747  5.48689823  4.33729416 -5.74461748 -4.15808819 -4.28653363
  9.23115084 -1.33123817 -1.0695373  -1.09170159  3.68741172 -7.45582576
 -4.92275127 -6.58986426  5.88466527  3.16673892 -0.42626454 -3.89573056
  0.1404188  -3.67970045 -1.19264925 -4.40581793 26.52235997]
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2536.2380376543992
gradient value of function right now is: [-1.20642196e-01 -2.88916358e-03 -6.25443679e-01 -3.11066493e-03
  1.20642196e-01  2.88916358e-03  6.25443679e-01  3.11066493e-03
  2.48777933e-03  6.72587427e-04  4.30038106e-01  3.76063096e-02
  2.32810270e-04 -1.68606074e-03 -1.34255599e-02 -1.35379581e-02
 -7.96838755e-03 -1.60130716e-02 -8.38499671e-01 -3.02376561e-01
  2.42045531e-04 -1.83493426e-03 -1.59327939e-02 -1.48259294e-02
 -4.95007761e-03 -4.01524027e-03 -2.65480005e-05 -4.76107475e-03
 -1.22312769e-02 -8.48001667e-03 -6.76258975e-03 -1.13658969e-02
  7.27120587e-02  9.02483155e-02  5.56363766e-02  1.18472236e-01
 -2.10997414e-01  2.00226495e-02 -3.90452852e-04  5.20599111e-02
  3.30712059e-02  5.96115204e-03  2.77646191e-03  7.36278454e-03
  7.26069844e-02  6.09943439e-03  7.16383158e-03  3.74123744e-03
 -1.20188913e-02 -5.81960436e-03 -4.64480676e-03 -4.93593165e-03
  1.60026029e-01  1.95329838e-02  2.14680667e-02  1.29364396e-02
 -7.04617792e-02  4.01756857e-01 -4.80503299e-02 -1.02120450e-01
 -4.83116761e-02 -8.23602239e-02 -5.06746494e-02 -3.71179203e-02
 -6.06964083e+00]
supnorm grad right now is: 6.0696408251370935
Weights right now are: 
[ 1.43781635e+00 -3.46761386e+00 -1.31243917e+00 -3.01046541e+00
 -2.22803559e+00  3.48207750e+00  1.88374522e+00  4.42554846e+00
  1.80720250e+00  8.75810148e+00  2.98301092e+00  9.11090621e+00
  4.85307773e+00 -1.68027625e+00  8.42244158e+00  1.48518335e-02
 -4.84838448e-01 -7.20159221e-01  3.03339000e+00 -3.50492180e+00
  5.02292445e+00 -1.85433347e+00  8.24515090e+00  1.10611919e-01
  5.78090230e+00  1.06236011e+00  3.53023841e+00  6.54969261e-01
  7.28502560e+00 -1.61644498e-01 -2.26049130e+00  6.58822660e-01
 -5.69981015e+00  5.34093892e-01  3.27898694e+00  7.01414323e-02
  3.18407734e+00 -6.14989565e+00 -2.56600487e+00 -6.33281417e+00
 -2.20868116e+00  4.64614315e+00  5.80314336e+00  5.45733407e+00
  4.08590181e+00 -5.97707148e+00 -4.45122028e+00 -4.49097975e+00
  8.21839127e+00 -3.03037619e+00 -2.87954537e+00 -2.69927244e+00
  3.17835023e+00 -8.79013771e+00 -6.34461747e+00 -7.85937175e+00
  6.94340579e+00  2.65942248e+00 -8.41476293e-01 -3.44676693e+00
 -3.48733774e-01 -3.26861227e+00 -1.46419829e+00 -4.05221554e+00
  2.55620060e+01]
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2534.9867658322783
gradient value of function right now is: [-2.10129347e-01 -5.37142605e-03 -2.00409002e+00 -5.52747813e-03
  2.10129347e-01  5.37142605e-03  2.00409002e+00  5.52747813e-03
  1.94120948e-03  3.25393052e-04  8.87435297e-01  3.09607721e-02
 -2.89988263e-04 -9.15069981e-03 -1.64203962e-02 -3.52384774e-02
 -1.17682657e-02 -2.53589305e-02 -2.41157001e+00 -1.74567443e+00
 -3.15006124e-04 -9.83270430e-03 -1.84421231e-02 -3.80445918e-02
 -3.77608875e-03  1.84534153e-03  7.90735544e-04  1.51433586e-03
 -1.46280574e-02 -3.95825577e-02 -2.14249820e-02 -4.53383448e-02
  1.81823754e-01  3.05142032e-01  1.56477509e-01  3.72989507e-01
 -6.08006811e-01 -1.40178254e-01 -3.53859638e-02 -2.03177908e-01
  3.48238711e-01  5.18286008e-02  4.31291934e-02  5.51233022e-02
 -2.31134441e-01 -1.46360439e-02 -1.25927790e-02 -1.34923860e-02
 -5.94086785e-02 -2.92282088e-02 -2.43553239e-02 -3.30719821e-02
 -2.82380775e-01 -1.30945524e-02 -1.08170440e-02 -1.22677649e-02
  1.15664870e+00 -2.15949005e+00 -2.69274172e-01  4.08202646e-01
 -2.23822622e-01  3.29633022e-01 -2.73633635e-01  3.93822446e-01
  1.22198183e+01]
supnorm grad right now is: 12.2198182761946
Weights right now are: 
[ 1.78642012e+00 -3.79290393e+00 -1.41949249e+00 -3.33546982e+00
 -2.57663936e+00  3.80736757e+00  1.99079854e+00  4.75055286e+00
  1.52108542e+00  8.55814679e+00  3.02293578e+00  7.95612236e+00
  5.23519038e+00 -2.20943526e+00  9.43352131e+00  4.73288769e-01
 -2.25652905e-01 -9.11495923e-01  3.33298945e+00 -4.02739355e+00
  5.40528306e+00 -2.37391164e+00  9.25981168e+00  5.63333374e-01
  6.62022534e+00  1.51616012e+00  4.00721076e+00  1.08317097e+00
  8.63547151e+00  1.57916637e-01 -2.77157602e+00  1.21533982e+00
 -6.26183448e+00  2.38187741e-01  3.19773622e+00 -3.17774274e-01
  4.06564610e+00 -6.23911322e+00 -2.62726448e+00 -6.66118832e+00
 -2.74738405e+00  4.52471705e+00  5.76019558e+00  5.26463601e+00
  4.27971126e+00 -6.53812851e+00 -5.04858124e+00 -5.03971587e+00
  9.17198697e+00 -2.20462208e+00 -2.11072255e+00 -1.86645966e+00
  3.38635215e+00 -1.06646194e+01 -8.15450608e+00 -9.87709135e+00
  7.00804727e+00  2.96406030e+00 -8.16686392e-03 -3.60479991e+00
  4.52400785e-01 -3.53800747e+00 -7.50891590e-01 -4.09196709e+00
  2.66280252e+01]
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2532.8863975018908
gradient value of function right now is: [-4.05079176e-02  9.21009105e-03  2.47817007e+00  9.27699463e-03
  4.05079176e-02 -9.21009105e-03 -2.47817007e+00 -9.27699463e-03
  1.91260299e-04  3.50569188e-05  1.74176904e-01  1.08897793e-03
  2.07169992e-04  7.34331878e-03  6.29576642e-02  9.03957542e-02
  2.72934695e-03  7.03439645e-02  1.49698554e+00  1.67692791e+00
  2.18282560e-04  7.74968665e-03  6.64853572e-02  9.54833374e-02
 -2.41084065e-05 -6.92203058e-04  9.09101049e-06 -7.60942837e-04
  6.21605212e-02  7.74876627e-02  3.80525890e-02  9.90364256e-02
 -4.99025106e-01 -5.88049650e-01 -2.97167668e-01 -7.59474761e-01
  1.10721574e-01  3.42854385e-02  4.41716675e-03  8.65846668e-02
 -4.95676012e-01 -1.14958981e-01 -9.51080556e-02 -1.25776051e-01
  1.61529274e-01  2.69236784e-02  2.25820660e-02  2.82718853e-02
  6.66924008e-02  1.42940295e-02  9.19960897e-03  1.94352646e-02
  2.31536551e-01  2.42260075e-02  2.05663529e-02  2.38884883e-02
 -6.88025020e-01  1.85208452e+00  2.43127512e-01 -8.08571432e-01
  1.76121254e-01 -6.33224198e-01  3.24590976e-01 -9.53201867e-01
 -1.32399688e+01]
supnorm grad right now is: 13.239968813186206
Weights right now are: 
[  1.83965828  -4.69022762  -0.42676355  -4.2203941   -2.62987752
   4.70469126   0.9980696    5.63547714   1.33451121   8.90036727
   3.12275334   7.0157797    4.53872486  -3.24624257   9.16996704
  -0.28999241  -0.54509633  -1.47906585   4.12806408  -3.34248603
   4.72064263  -3.39171926   9.01753041  -0.18106869   7.46504665
   2.34407986   4.63059899   1.87208846   8.68055689  -0.66105503
  -3.94692095   0.48118454  -6.69943192   0.91306894   4.1243626
   0.23837886   4.2295736   -7.17055106  -4.90020035  -7.32227132
  -3.0539919    4.8741058    6.09839692   5.68205078   4.52354961
  -7.03673869  -5.48166683  -5.7744702    9.50396269  -2.39185087
  -2.27839937  -2.09711754   3.53837628 -11.37572145  -8.77238588
 -10.9564511    8.4127883    2.3404303   -0.93712677  -3.30756131
  -0.25426892  -3.36220969  -1.80046353  -3.5137333   25.29610291]
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2537.9284111153534
gradient value of function right now is: [-1.05395905e-01 -9.07777881e-03 -5.04715504e-02 -9.09492636e-03
  1.05395905e-01  9.07777881e-03  5.04715504e-02  9.09492636e-03
  2.39214873e-04  1.05666052e-04  4.57612795e-01  5.06817459e-02
 -6.02317917e-05 -1.38712775e-02 -2.30556441e-02 -6.53308873e-02
  2.59979964e-04 -1.40143899e-02  4.53883432e-01  5.44404348e-01
 -6.39825072e-05 -1.46297879e-02 -2.47976422e-02 -6.89700968e-02
 -1.52077435e-04  4.09687116e-04  5.32809095e-05  4.80818127e-04
 -1.59268812e-02 -6.94568945e-02 -1.93448846e-02 -8.68980321e-02
  3.37120790e-02  2.82337314e-01  7.28835037e-02  3.47533527e-01
 -1.83093784e-01  2.34284839e-02  3.38126602e-03  3.83914988e-02
  1.05188357e-01  5.62103620e-02  4.68747782e-02  5.93559276e-02
  1.72764157e-02 -7.28455554e-03 -6.06744915e-03 -8.05348186e-03
 -3.37963695e-02 -2.43599917e-02 -1.99353365e-02 -2.59195953e-02
 -6.85593349e-02  8.47129248e-03  8.41690365e-03  6.58368449e-03
 -6.43663715e-02  2.90689222e-01 -1.89629082e-01  2.02863272e-01
 -1.85148250e-01  2.11580180e-01 -2.16838674e-01  2.45326861e-01
  5.19576194e+00]
supnorm grad right now is: 5.195761935818678
Weights right now are: 
[  1.8179085   -4.00245055  -1.04048095  -3.53929018  -2.60812774
   4.01691419   1.611787     4.95437323   1.1935592    8.90416637
   3.30248981   7.17104055   4.17717006  -2.42342532   9.7950986
   0.48348156  -0.12907448  -2.87214569   4.2701696   -3.33077033
   4.36155075  -2.58424879   9.6284799    0.57466922   7.97453367
   3.07202116   4.68266871   2.61530779   9.40833954  -0.3988345
  -3.60784843   0.7509458   -7.33948768   1.13951834   4.01399293
   0.4417223    3.72328933  -7.01722856  -4.21358513  -7.91216382
  -2.59076583   5.70039411   7.01145296   6.3295663    4.26148878
  -7.62252745  -6.23568384  -6.135745    10.42572134  -2.5164196
  -2.42642969  -2.16934429   2.41835514 -12.87027203 -10.45201146
 -12.26920102   7.3599093    3.17874895  -0.4798608   -3.19449336
   0.09511915  -3.0623186   -1.32663444  -3.74378094  26.41404591]
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2537.5785826662973
gradient value of function right now is: [-1.63270451e-01 -2.65312915e-03 -6.49156200e-01 -2.87769447e-03
  1.63270451e-01  2.65312915e-03  6.49156200e-01  2.87769447e-03
  2.37539080e-04  2.22180860e-05  7.41137814e-01  1.86332328e-02
 -6.74276282e-07 -9.46096841e-03 -6.18400722e-03 -2.05103911e-02
 -9.12202075e-05 -1.11129333e-04 -7.15436290e-01 -4.97443821e-01
 -5.64197331e-07 -1.08082473e-02 -7.10975307e-03 -2.34233246e-02
 -2.69644174e-04 -4.15517045e-07  4.89896040e-05 -1.63422989e-05
 -7.56522391e-03 -3.43277247e-02 -2.38219945e-02 -3.97497116e-02
  2.94188101e-02  8.56532717e-02  6.59517182e-02  1.01111751e-01
 -2.85808577e-03  5.56582397e-03 -8.98723740e-04  4.27046728e-02
 -3.81367575e-02  1.18160165e-02  5.75325425e-03  2.47639593e-02
  3.20650182e-02 -1.10326656e-03 -6.69851578e-04 -1.70458477e-03
 -9.76904612e-03 -2.58506041e-02 -1.92706051e-02 -3.86610260e-02
  1.77534074e-01  9.14231771e-03  8.76543646e-03  6.64853457e-03
 -1.81470578e-01  5.34643420e-01 -6.55884998e-02 -5.70932096e-02
 -5.08795930e-02 -4.98227947e-02 -1.20242752e-01  3.65716698e-03
  6.34517744e+00]
supnorm grad right now is: 6.345177440155258
Weights right now are: 
[  1.94983746  -4.32246963  -0.99980277  -3.90068837  -2.7400567
   4.33693327   1.57110882   5.31577142   1.16550393   8.38572326
   3.28638351   7.62191701   5.05248567  -3.73575674  11.48759854
   0.91098055  -0.05866782  -2.11727582   3.63985403  -4.13774686
   5.24292868  -3.93333108  11.31534982   0.96196679   8.06879952
   2.54695964   4.98861814   2.00875448  10.56655584  -0.03581668
  -5.16875093   1.38333843  -7.37412074   0.19567295   4.44692838
  -0.50860723   4.2318483   -6.91944667  -4.7041633   -8.22554016
  -3.66021377   3.96771704   5.1767619    4.70576734   5.00410261
  -5.94458447  -4.54301235  -4.52088678  11.78286541  -1.65868555
  -1.71259786  -1.36397864   2.39043291 -14.39760562 -12.07112563
 -14.09275658   7.32062415   3.43652687   0.17870709  -3.90851998
   0.79211846  -3.91101711  -0.93000146  -4.36980776  26.61507165]
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -2537.817071136319
gradient value of function right now is: [-5.00142696e-02 -1.43882817e-03 -2.89676459e+00 -1.50491400e-03
  5.00142696e-02  1.43882817e-03  2.89676459e+00  1.50491400e-03
  3.19792906e-04  4.03135472e-05  3.16391949e-01  9.35173118e-02
  7.41563895e-04 -3.75031705e-03 -2.88758299e-03 -1.08109253e-02
 -1.08095906e-02 -7.70662722e-03 -2.36465218e+00 -1.92512755e+00
  7.96654476e-04 -4.14289177e-03 -3.22344518e-03 -1.19576611e-02
 -1.77384487e-02 -1.97247340e-02 -3.18210242e-03 -3.41670013e-02
 -1.35135569e-02 -2.68663206e-02 -2.13863622e-02 -3.68891203e-02
  1.11559734e-01  1.51166413e-01  9.13614864e-02  2.21703776e-01
 -1.16694443e+00 -1.21720987e-01 -7.43152196e-03 -4.22362094e-01
  6.52412890e-01  5.21203901e-02  4.73644300e-02  5.11586958e-02
 -3.75701554e-01 -8.21954827e-03 -8.08967737e-03 -5.85898741e-03
 -1.05587168e-02  4.69554538e-03  7.97300413e-03  1.76845100e-03
 -1.48469567e+00 -2.89361511e-02 -2.97442479e-02 -1.88856768e-02
  1.41333498e+00 -4.30608667e+00 -3.01526417e-01  9.36389751e-01
 -2.88302432e-01  8.89345008e-01 -2.53117002e-01  6.74769470e-01
  2.39792672e+00]
supnorm grad right now is: 4.306086674498799
Weights right now are: 
[  2.67529985  -4.17535421  -0.92013492  -3.73576214  -3.46551909
   4.18981784   1.49144097   5.15084519   0.11131028   8.1228539
   2.7543049    6.9848857    4.21485562  -3.52957111  11.97462749
   1.15715705  -3.3980296   -3.08933681   3.68398023  -4.55562595
   4.43236999  -3.70785669  11.82358677   1.22406449   8.62036177
   0.91179644   6.42132213  -0.35925997  10.96847637   0.19296617
  -4.94724043   1.61148384  -7.24364898   0.21078484   4.21374002
  -0.42631586   4.29007323  -7.13863087  -4.10272873  -8.69358633
  -2.62578619   4.69701046   6.04272691   5.23793776   4.54743434
  -6.55496075  -5.28235372  -5.11660887  11.89480296  -1.73084815
  -1.9322375   -1.316776     2.21366673 -15.77944189 -13.60312512
 -15.58037289   8.3286818    2.73782251  -0.03762341  -2.97232484
   0.47863105  -2.82423384  -1.04677644  -3.55632905  25.86201578]
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2537.269732265825
gradient value of function right now is: [-5.60332109e-02 -8.35786649e-04  1.16028410e-01 -8.94268670e-04
  5.60332109e-02  8.35786649e-04 -1.16028410e-01  8.94268670e-04
  2.86983565e-05  1.75186813e-05  2.92389855e-01 -5.37755974e-03
  1.89683169e-03 -1.06613779e-03 -1.89935029e-03 -6.77982313e-03
 -1.02545141e-02 -2.27606317e-03  6.09251793e-01  4.30191350e-01
  1.95677149e-03 -1.24697458e-03 -2.14580912e-03 -7.69587414e-03
 -6.33996858e-03 -2.16386814e-02 -5.87722174e-04 -4.19660617e-02
 -3.39117185e-03 -9.57737829e-03 -5.06418170e-03 -1.88078249e-02
 -1.00284321e-02  3.71157524e-02  8.41958278e-03  7.76803865e-02
  3.42670108e-01  4.12176598e-02  2.17989722e-03  2.11836613e-01
 -1.92545766e-01  1.79881568e-02  1.67227731e-02  2.03031973e-02
  1.08308202e-01  1.77339969e-03  1.63396190e-03  2.13593329e-03
  2.37420260e-03  8.24810881e-04  1.97584783e-03 -1.53562053e-03
  6.21354077e-01  2.68831280e-02  2.62318086e-02  2.88278608e-02
 -7.95860880e-01  1.81729453e+00  1.94285478e-01 -5.93833172e-01
  1.46617045e-01 -4.80817243e-01  2.29625682e-01 -6.68706118e-01
 -7.11614988e+00]
supnorm grad right now is: 7.116149880471689
Weights right now are: 
[ 2.27699312e+00 -4.38824154e+00 -1.16801762e+00 -3.96820673e+00
 -3.06721235e+00  4.40270518e+00  1.73932366e+00  5.38328977e+00
 -1.51336804e-02  8.05757535e+00  3.38796444e+00  6.42442399e+00
  3.19107445e+00 -3.85640697e+00  1.22397107e+01  1.19799751e+00
 -4.10865939e+00 -4.58991125e+00  4.49046029e+00 -4.10750714e+00
  3.33872367e+00 -4.04572375e+00  1.20671071e+01  1.24298170e+00
  1.04008327e+01  2.06758894e-01  8.19721400e+00 -6.01940568e-01
  1.08432825e+01 -4.70349790e-02 -5.46404353e+00  1.36032340e+00
 -7.14310685e+00  8.02324578e-01  4.90988940e+00  1.32342331e-01
  4.90411482e+00 -6.17754307e+00 -3.04011759e+00 -8.68490075e+00
 -2.58543483e+00  6.07184743e+00  7.62797776e+00  5.99169770e+00
  5.14862119e+00 -6.90529135e+00 -5.78638326e+00 -5.14748593e+00
  1.20446097e+01 -2.36188039e+00 -2.54175907e+00 -1.86365909e+00
  2.62377550e+00 -1.72969254e+01 -1.50550746e+01 -1.75856664e+01
  7.56016411e+00  3.51238284e+00 -2.17782786e-01 -2.61256058e+00
  2.50081855e-01 -2.46488264e+00 -9.79510865e-01 -2.84118136e+00
  2.56680968e+01]
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2538.194927891968
gradient value of function right now is: [-9.91021325e-02  2.91055505e-02 -5.38084755e-01  3.03162844e-02
  9.91021325e-02 -2.91055505e-02  5.38084755e-01 -3.03162844e-02
 -1.26089278e-03 -9.78301246e-05  4.23447762e-01  1.08468228e-02
  6.46075961e-02  1.10675494e-01 -2.81932939e-03  1.59111506e-01
 -3.33487082e-02 -7.82702111e-04 -2.69898703e-01 -3.16464095e-01
  7.07963231e-02  1.23434466e-01 -3.12118885e-03  1.77129509e-01
 -3.34245127e-02 -4.30693499e-01 -3.12146372e-01 -4.65666779e-01
 -3.53886692e-03  3.27986093e-01  2.56691959e-01  3.27909540e-01
  1.30610712e-01  1.37209634e-01  4.82487339e-02  2.27901557e-01
  1.92477338e-02  6.80183801e-03  3.60381927e-04  3.72797627e-02
  1.16278848e-01  1.49959514e-02  1.32076573e-02  2.96235904e-02
  1.48114557e-03 -2.79846939e-03 -1.95773607e-03 -7.21134483e-03
  3.34081427e-02  2.70477046e-01  2.38446135e-01  3.64609815e-01
  1.43667294e-01  6.44414425e-03  7.51487208e-03  5.89131907e-03
  1.23431491e-01 -4.28945253e-01  4.30443961e-02  1.04078207e-03
  4.23709749e-02  4.88760227e-03 -6.65388526e-02  1.41314213e-01
 -1.71664081e+00]
supnorm grad right now is: 1.7166408078502837
Weights right now are: 
[  1.76926974  -3.62227516  -0.75178502  -3.30117367  -2.55948898
   3.6367388    1.32309107   4.71625672  -0.15306546   7.54081252
   3.79903482   6.28590259   5.17580294  -3.62110611  12.87411303
   2.54458686  -4.01861438  -5.63663448   4.51671254  -4.26044742
   5.35442965  -3.83263562  12.68204619   2.56571544   9.87744168
  -1.7070391    6.47152465  -2.79315105   9.84332269   1.31034339
  -5.38573719   2.70048718  -5.90993566   1.28381504   6.20894008
   1.13289804   5.206017    -7.20093473  -3.56578621  -8.73338283
  -1.922458     7.28981014   8.89279835   7.1762027    4.33868972
  -7.42454974  -6.28225183  -5.6746447   13.37588219  -1.89461353
  -2.1430986   -1.0355224    3.49688336 -16.84195133 -14.57925488
 -17.04402614   8.22138484   2.74021432   0.29479708  -3.16424836
   0.92699461  -2.99585235  -1.08627002  -3.11564129  25.97361382]
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2535.1373764054147
gradient value of function right now is: [-2.95987133e-02  5.53218871e-03  2.49772717e+00  5.77944922e-03
  2.95987133e-02 -5.53218871e-03 -2.49772717e+00 -5.77944922e-03
 -4.29324993e-04 -1.24957104e-04  1.56228510e-01 -4.23840538e-02
  6.52364725e-03  8.90059118e-03  4.46611056e-03  4.05025164e-02
  3.74393367e-02  6.06903228e-03  2.26504693e+00  2.17509868e+00
  7.43568582e-03  1.02587153e-02  5.13408274e-03  4.65932634e-02
  2.76103027e-02 -9.31096797e-03 -8.62677823e-03  3.69236721e-02
  2.03201394e-02  7.01345516e-02  3.48321206e-02  8.58006411e-02
 -4.04176286e-01 -3.43213727e-01 -1.69444030e-01 -6.11638898e-01
  6.49220614e-01  1.09099432e-01  1.79143060e-02  3.76333404e-01
 -8.90002428e-01 -7.94437314e-02 -7.96445777e-02 -8.23089045e-02
  2.21505439e-01  9.87899474e-03  9.93075035e-03  1.00896813e-02
  9.89079299e-02  6.05760832e-02  5.61594225e-02  7.03962204e-02
  9.40251291e-01  3.76578338e-02  4.09746363e-02  3.31068414e-02
 -2.08918632e+00  4.16388893e+00  4.16267939e-01 -1.09520098e+00
  4.26548318e-01 -1.15379612e+00  4.10577598e-01 -9.87329148e-01
 -1.19135315e+01]
supnorm grad right now is: 11.913531512850795
Weights right now are: 
[  2.36416872  -3.87369709  -0.87547297  -3.58238655  -3.15438796
   3.88816073   1.44677901   4.99746959   0.30188469   7.80422122
   3.5084345    6.27799017   3.96407301  -4.71942002  14.01751512
   2.44658068  -2.56587435  -5.49802851   4.75951574  -3.98213628
   4.08619223  -4.95316206  13.87013069   2.44783891  10.92668393
  -0.59045751   7.46091185  -1.51912045  10.96864574   0.50342484
  -6.2178346    2.07171177  -6.31881333   0.65784016   5.94948898
   0.17466092   5.55260098  -6.3454808   -3.74532035  -8.71542967
  -2.58815809   6.48206209   8.20118275   6.12050617   5.4299457
  -6.74542373  -5.79563072  -4.74911132  12.9692359   -2.74882463
  -2.99452245  -1.8211413    2.94464898 -18.74506603 -16.70986856
 -18.2742943    7.99488645   3.37084567   1.14428823  -3.38409111
   1.68875552  -3.14291633   0.17217495  -3.79333978  25.75370114]
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2534.4598691952515
gradient value of function right now is: [ 2.15479645e-03  1.30522522e-03  4.89955281e+00  1.50353667e-03
 -2.15479645e-03 -1.30522522e-03 -4.89955281e+00 -1.50353667e-03
 -7.54979291e-04 -2.87298208e-04 -6.55623835e-03  5.85606908e-02
  5.94540209e-03  4.86968185e-03  4.86129004e-03  1.24462862e-02
  1.51005747e-01  3.44864863e-02  1.78769635e+00  2.05774832e+00
  7.57527207e-03  6.26944859e-03  6.22771405e-03  1.59969468e-02
  1.21577999e-01  8.33200889e-02  7.91109958e-03  3.56166272e-01
  5.15308817e-02  1.12542663e-01  4.04527230e-02  1.93000055e-01
 -2.28101214e-01 -3.27248822e-01 -1.14230913e-01 -6.68350806e-01
 -2.98133078e-01  4.43053504e-03  3.90370902e-04 -1.04756973e-01
 -5.49091632e-01 -1.27933048e-01 -1.16628352e-01 -1.27657347e-01
 -3.09614175e-03  3.00783603e-03  2.38172647e-03  3.55499321e-03
  9.67807548e-02  5.05704744e-02  4.53154278e-02  5.51408593e-02
 -9.26203326e-01 -1.51069666e-02 -1.87421512e-02 -7.57386727e-03
 -1.06326393e+00  1.71835586e+00  4.81031372e-01 -4.12627346e-01
  4.78137563e-01 -4.02794277e-01  5.05939797e-01 -6.48557121e-01
 -7.90296615e+00]
supnorm grad right now is: 7.902966146401713
Weights right now are: 
[ 2.65607339e+00 -4.37965818e+00 -3.14412057e-01 -4.10360627e+00
 -3.44629263e+00  4.39412182e+00  8.85718102e-01  5.51868932e+00
  1.97920587e-01  7.50494758e+00  3.36947263e+00  5.70328971e+00
  3.28647773e+00 -5.88272312e+00  1.41547216e+01  2.09306946e+00
 -3.50643592e+00 -5.51695700e+00  4.76682601e+00 -3.69939331e+00
  3.40473000e+00 -6.14292411e+00  1.39810566e+01  2.07842803e+00
  9.88096089e+00  1.01536913e-02  8.20961147e+00 -1.50600560e+00
  1.15773863e+01 -4.20908331e-01 -7.00505573e+00  1.40914044e+00
 -7.41361465e+00  1.99005097e-01  5.63747264e+00 -3.58026137e-01
  4.81407248e+00 -7.09404751e+00 -3.88261442e+00 -1.03529962e+01
 -1.78306350e+00  7.50968614e+00  9.23639538e+00  7.12152410e+00
  4.40841541e+00 -6.16106764e+00 -5.50561975e+00 -3.74500042e+00
  1.26652301e+01 -4.50481513e+00 -4.77661056e+00 -3.43994566e+00
  1.74804085e+00 -2.10970402e+01 -1.89224769e+01 -2.07343697e+01
  7.51403062e+00  3.72176130e+00  3.61568394e-01 -2.73308627e+00
  9.20097549e-01 -2.55183573e+00 -5.48035528e-01 -3.22642736e+00
  2.58734311e+01]
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2536.868600231809
gradient value of function right now is: [-5.94081610e-02 -3.52246033e-03 -1.33659632e+00 -4.28577748e-03
  5.94081610e-02  3.52246033e-03  1.33659632e+00  4.28577747e-03
  4.44286899e-04  7.84498569e-05  3.09380921e-01 -6.47487219e-03
 -2.08919795e-02 -1.40570546e-02 -6.84917272e-03 -2.89154685e-02
 -3.53612527e-02 -4.14266197e-03 -2.65124462e-01 -3.50266035e-01
 -2.76219844e-02 -1.85743116e-02 -9.06252773e-03 -3.82363556e-02
 -4.79943817e-02 -7.34864904e-03 -4.29484775e-04 -7.20348914e-02
 -1.50002402e-02 -7.86919375e-02 -5.18694274e-03 -1.30585938e-01
  5.38735402e-02  1.27200052e-01  9.17750311e-03  2.52630552e-01
  1.62906795e-01  2.75883014e-02  1.37500465e-03  5.32040755e-02
  1.78218783e-01  3.83461607e-02  3.81971955e-02  3.76380466e-02
  3.10701747e-02 -1.09187430e-02 -1.09226436e-02 -1.07573901e-02
 -2.61639728e-02 -8.60436105e-03 -8.05161962e-03 -9.17053588e-03
  2.10005556e-01 -6.54644824e-04 -6.25252970e-04 -7.30176923e-04
 -3.37276591e-01  7.96738737e-01 -1.05671912e-01  2.64664194e-01
 -1.23215946e-01  3.17137624e-01 -9.48107222e-02  2.33869592e-01
  2.00805436e+00]
supnorm grad right now is: 2.0080543562402893
Weights right now are: 
[ 2.29379342e+00 -4.41644719e+00 -9.70048504e-01 -4.16976374e+00
 -3.08401265e+00  4.43091083e+00  1.54135455e+00  5.58484679e+00
  2.44677851e-01  7.84291923e+00  3.83389368e+00  5.66072237e+00
  1.63839584e+00 -6.63543766e+00  1.35745646e+01  1.99746829e+00
 -4.23951680e+00 -7.06754129e+00  4.12071079e+00 -4.58226656e+00
  1.68464609e+00 -6.95060445e+00  1.33770768e+01  1.95149073e+00
  8.45951806e+00  1.85225874e-01  8.26972039e+00 -2.00082975e+00
  1.15451481e+01 -1.24370605e+00 -7.26554343e+00  4.92717075e-01
 -7.10941003e+00  1.11192095e+00  5.91604580e+00  6.76068865e-01
  5.82895809e+00 -6.87383288e+00 -3.71212697e+00 -9.45464505e+00
 -1.56634806e+00  8.44129197e+00  1.01475080e+01  8.07185813e+00
  4.68619663e+00 -7.85223205e+00 -7.30080188e+00 -5.21755160e+00
  1.20034236e+01 -5.26298387e+00 -5.57453047e+00 -3.97627909e+00
  3.23972974e+00 -2.00179679e+01 -1.79786744e+01 -2.00996050e+01
  8.05208840e+00  3.57210492e+00 -4.90734993e-01 -3.00159838e+00
  3.66562628e-03 -2.81698895e+00 -1.16702915e+00 -3.29520249e+00
  2.60605785e+01]
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2538.2910955969214
gradient value of function right now is: [-5.13483664e-02 -3.82433062e-03  9.61781807e-01 -4.87755544e-03
  5.13483664e-02  3.82433062e-03 -9.61781807e-01  4.87755543e-03
  5.11577203e-05  7.83557922e-06  3.64515582e-01  8.80894162e-03
 -3.70694127e-03 -1.25991305e-02 -6.15910224e-03 -2.98144023e-02
  5.45831755e-03  2.70043822e-03  1.31891436e+00  1.26927506e+00
 -5.20293113e-03 -1.74033122e-02 -8.55637376e-03 -4.12544100e-02
  1.03759417e-02  8.44734116e-03  1.15086963e-03  2.63952125e-02
 -9.45616255e-03 -6.11165043e-02 -2.23964717e-02 -1.00362585e-01
 -1.01207024e-01  3.51867832e-02  1.24072265e-02 -1.09004603e-02
  1.29775282e-01  2.70867760e-02  2.95526789e-03  1.39850391e-01
 -3.08606630e-01 -5.14077183e-04 -2.52352972e-03  2.60493033e-03
  5.69261436e-02 -7.83872398e-03 -7.69090062e-03 -8.10183283e-03
 -2.67911064e-02 -1.59720660e-02 -1.52638738e-02 -1.72091694e-02
  3.40864528e-01  1.47061420e-02  1.55995502e-02  1.33748336e-02
 -6.51013227e-01  1.51164815e+00  5.01392528e-02 -2.99777123e-01
  4.75515563e-02 -3.01867654e-01  4.58758375e-02 -2.78564909e-01
 -3.18499005e+00]
supnorm grad right now is: 3.1849900508613462
Weights right now are: 
[ 3.25971887e+00 -4.24451359e+00 -6.31605853e-01 -4.01599656e+00
 -4.04993810e+00  4.25897723e+00  1.20291190e+00  5.43107961e+00
  4.76020536e-01  8.11584353e+00  3.11783398e+00  7.01012579e+00
  1.95646855e+00 -6.64643506e+00  1.40935413e+01  2.33659221e+00
 -3.10368292e+00 -6.99445760e+00  4.79287121e+00 -3.91992519e+00
  1.98605367e+00 -7.00287008e+00  1.38763084e+01  2.26039583e+00
  1.02385487e+01  9.87743872e-01  8.44570047e+00 -7.14666767e-01
  1.21557958e+01 -1.56717707e+00 -7.28527486e+00  6.54410954e-01
 -7.64865194e+00  1.60943072e+00  6.03526050e+00  4.81988264e-01
  5.24486475e+00 -6.85726413e+00 -3.95359444e+00 -1.00589941e+01
 -2.23041999e+00  8.23727501e+00  9.87176700e+00  7.99095977e+00
  5.39704673e+00 -7.79780467e+00 -7.15803118e+00 -5.28524912e+00
  1.13146929e+01 -6.25272710e+00 -6.69585972e+00 -4.83050554e+00
  2.30157474e+00 -2.10338105e+01 -1.91509672e+01 -2.09116687e+01
  8.13601507e+00  3.74731697e+00 -4.37333348e-01 -3.22473459e+00
 -8.55237554e-03 -3.01645439e+00 -1.10248258e+00 -3.54969257e+00
  2.59886856e+01]
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2537.5653214271365
gradient value of function right now is: [-1.94434720e-02  1.40253720e-03  2.88722604e+00  1.92412745e-03
  1.94434720e-02 -1.40253720e-03 -2.88722604e+00 -1.92412745e-03
  2.76787739e-06 -2.40694665e-05  1.37843091e-01  5.94363421e-02
  1.37282487e-03  5.37280457e-03  4.75722866e-03  1.25528255e-02
  8.37965298e-03  1.73575288e-02  5.05569820e-01  7.47572344e-01
  2.04298499e-03  8.61848798e-03  7.19544273e-03  1.95145260e-02
  5.17731904e-03  1.14214449e-03 -1.41136929e-04  1.31570726e-02
  4.81783729e-02  8.28836371e-02  4.32576068e-02  1.27200668e-01
 -1.17818200e-01 -1.75517815e-01 -9.16866591e-02 -2.84543683e-01
 -5.22147113e-01 -1.58869346e-02 -6.67418711e-04 -1.43265071e-01
 -7.75470545e-04 -4.06907519e-02 -3.65558190e-02 -4.64417387e-02
 -5.24006727e-02  8.63934053e-03  8.07773230e-03  9.37911789e-03
  7.51488762e-02  2.69316100e-02  2.44632231e-02  3.05618284e-02
 -9.26664847e-01 -4.60404903e-03 -4.03697035e-03 -4.90867112e-03
 -7.70534044e-03 -4.83207837e-01  9.29340934e-02 -1.16189930e-01
  8.96732204e-02 -1.41785600e-01  1.16883964e-01 -1.44570938e-01
 -2.68093587e+00]
supnorm grad right now is: 2.887226041098003
Weights right now are: 
[  3.07503258  -4.00984889  -0.22272659  -3.76724695  -3.86525181
   4.02431253   0.79403264   5.18233      0.65039949   8.30146844
   3.3901726    7.64551748   2.28633962  -6.42569347  14.78009659
   2.70536342  -2.53950603  -6.53642123   4.19289366  -4.18825163
   2.34073864  -6.77235964  14.58166252   2.64315022  11.07471107
   0.97023312   8.62786764  -0.38036497  12.46958387  -1.28021944
  -7.85101755   1.17177988  -8.35921286   1.07794022   6.19335889
  -0.46163782   4.47172769  -8.87404473  -5.24960636 -11.52381677
  -3.06754558   7.21920542   8.7785673    7.10356364   5.37805411
  -6.94723679  -6.29787923  -4.45744185  11.66803074  -6.53013552
  -6.95307136  -5.17314993   1.82720601 -22.36040257 -20.28142916
 -22.55311168   9.10535116   2.89067813  -0.67237058  -3.58995834
  -0.16494388  -3.55250685  -1.42527199  -3.73845447  25.93526891]
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2537.1197338246
gradient value of function right now is: [-5.33930429e-02 -2.58351395e-03 -4.63920742e-01 -3.64438783e-03
  5.33930429e-02  2.58351395e-03  4.63920742e-01  3.64438783e-03
  1.70296471e-04  5.01751154e-05  3.46987856e-01  1.99595770e-02
 -1.79775205e-03 -9.18373058e-03 -6.39225342e-03 -2.22004920e-02
  5.71187701e-05 -1.07593903e-02 -1.77485011e-01 -1.75017896e-01
 -2.85962510e-03 -1.40262610e-02 -9.81175279e-03 -3.39810917e-02
  7.81423275e-04 -1.88845662e-03 -5.12573901e-04  2.28690176e-03
 -7.69703725e-02 -8.50384427e-02 -4.53104846e-02 -1.28972815e-01
  1.23167123e-01  1.37548944e-01  7.17621944e-02  2.03428413e-01
 -7.27324209e-02 -1.08745312e-02 -1.37024018e-03  1.23962678e-02
  1.17147430e-01  1.53164903e-02  1.30037914e-02  1.99765761e-02
 -7.30485273e-02 -6.52978399e-03 -5.95810985e-03 -7.75917007e-03
 -6.75591503e-02 -8.46278458e-03 -7.49166790e-03 -1.06796987e-02
  1.08887595e-01  8.63286773e-03  9.54883454e-03  7.55509761e-03
  7.52731624e-01 -1.65197782e+00 -1.18982313e-01  7.60057455e-02
 -1.15190403e-01  6.19099736e-02 -1.38188761e-01  1.32154140e-01
 -1.09808475e+00]
supnorm grad right now is: 1.6519778195033812
Weights right now are: 
[  2.91043085  -4.52024038  -1.11758257  -4.30097057  -3.70065008
   4.53470402   1.68888862   5.71605362   0.39613454   9.3503297
   3.64444199   6.54229495   0.66811285  -6.99346168  14.25091856
   2.25810516  -4.3507466   -9.30527088   4.72185819  -3.88201045
   0.56151876  -7.40233285  13.99584169   2.14408066   9.54083821
   1.34240034  10.09813621  -1.55857591  11.40876275  -2.57513248
  -8.76492432  -0.08532142  -7.84744015   2.29385582   7.13876253
   0.87838909   5.21125221  -9.61561322  -6.13441426 -11.08506317
  -2.05586689   9.1062505   10.88541226   8.67174451   4.52377436
  -8.68117088  -8.12483377  -6.02667063  11.3216068   -7.21976289
  -7.75399806  -5.70961955   2.72156273 -21.95110677 -19.94753324
 -21.96493284   9.20977765   2.92130495  -0.42900156  -3.64242091
   0.12323176  -3.48778184  -1.27515343  -3.84324729  25.73146566]
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2538.380784542011
gradient value of function right now is: [-5.74019857e-02 -1.85759932e-03 -2.36346879e-01 -2.75125392e-03
  5.74019857e-02  1.85759932e-03  2.36346879e-01  2.75125392e-03
  1.76838360e-04  2.59386161e-05  3.34124227e-01 -3.75246380e-04
 -1.22004651e-03 -5.78266052e-03 -2.37771312e-03 -1.29990517e-02
 -1.17016692e-02 -3.83335536e-03  3.20687718e-01  1.99621478e-01
 -2.34698588e-03 -9.19547946e-03 -3.86001121e-03 -2.07817317e-02
 -1.24478150e-02 -9.83832230e-03 -7.50392853e-04 -4.50985258e-02
 -2.92066684e-02 -4.40222126e-02 -2.57481122e-02 -6.93892480e-02
  5.01694149e-02  7.55038931e-02  4.08350080e-02  1.29562844e-01
  2.75851660e-01  3.59625705e-02  1.64858384e-03  1.33688982e-01
 -1.84866848e-01  1.27964691e-02  1.10050358e-02  1.73930093e-02
  1.43471289e-01 -7.70593479e-04 -3.92538435e-04 -1.51684168e-03
 -2.05335935e-02 -6.17461102e-03 -5.13639629e-03 -9.04832769e-03
  6.39228027e-01  1.17837840e-02  1.28520621e-02  1.13706451e-02
 -4.57405188e-01  1.41552397e+00 -2.94546101e-02 -1.54947936e-01
 -2.69466856e-02 -1.61062811e-01 -5.23308952e-02 -1.11925814e-01
 -3.02385025e+00]
supnorm grad right now is: 3.0238502500217463
Weights right now are: 
[  2.5485954   -3.76000946  -1.02399253  -3.49463991  -3.33881464
   3.7744731    1.59529857   4.90972296   0.75254016   9.57633383
   4.09563442   5.90633095   0.18474388  -6.12222198  14.90822019
   3.04059849  -5.197044    -9.60576587   4.51643282  -4.03106236
  -0.15702743  -6.56165833  14.6048562    2.89566533   9.1237628
   2.05802639  10.31932317  -2.39650297  12.07531234  -1.62910873
  -8.34081213   0.75586332  -8.1586141    1.69844675   6.98146314
   0.47828315   5.28731262  -9.71110429  -6.28273411 -11.23758998
  -1.74357448   9.41170143  11.33273776   8.78376454   4.88651457
  -8.39743243  -7.95552258  -5.57335446  12.66779134  -6.3459437
  -6.79179281  -4.96622526   2.74274441 -22.73874207 -20.78818289
 -22.71808537   8.72904188   3.48760175   0.34886087  -3.98816842
   0.97102983  -3.77525003  -0.63049032  -4.23062643  25.90270228]
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2536.418160578005
gradient value of function right now is: [-2.78007403e-02 -6.23762031e-03 -2.24542414e+00 -8.58529767e-03
  2.78007403e-02  6.23762031e-03  2.24542414e+00  8.58529767e-03
  1.07548379e-03  5.10433603e-04  2.06363202e-01  3.08105258e-02
 -4.29643512e-03 -1.80034605e-02 -5.76476701e-03 -4.01087770e-02
 -2.28350372e-02 -1.04714608e-02 -1.48135563e+00 -1.47309525e+00
 -7.48367567e-03 -2.68045425e-02 -8.62950358e-03 -5.96496211e-02
 -5.88543823e-02 -2.31576290e-02 -3.18014859e-03 -7.03756899e-02
 -1.04315996e-01 -1.18311987e-01 -7.72946022e-02 -1.66153584e-01
  2.52935410e-01  2.16014618e-01  1.21025369e-01  3.12910269e-01
 -2.40440824e-01 -5.84928936e-02 -5.91648742e-03 -8.01415207e-02
  4.27834124e-01  2.01140167e-02  1.64958897e-02  3.18051964e-02
 -1.98388167e-01 -4.61122270e-03 -3.84901319e-03 -6.97545065e-03
 -8.74245006e-02 -1.16112137e-02 -9.20354917e-03 -1.94949447e-02
 -1.81164503e-01  3.09508956e-03  3.58160112e-03  2.50781119e-03
  1.70313703e+00 -4.45252369e+00 -1.43422225e-01  2.04156667e-01
 -1.22430026e-01  1.67819606e-01 -2.26156469e-01  3.56171532e-01
  3.29838660e+00]
supnorm grad right now is: 4.452523694090722
Weights right now are: 
[  3.40340754  -3.43945576  -1.04996683  -3.12061536  -4.19362678
   3.4539194    1.62127287   4.5356984   -0.77334912   9.33841065
   3.50128274   4.82381154   0.63245297  -5.85761413  15.51057058
   3.54394225  -5.89341068 -10.58809032   4.36362459  -4.38592625
   0.35905444  -6.2619962   15.26714438   3.4454249    8.89896972
   2.32455281  12.15162857  -3.40685619  11.65486148  -1.70632294
  -9.11540496   0.86796627  -7.78194922   1.84994349   7.9267901
   0.59419328   5.57158485 -10.7061152   -7.25680012 -11.65326307
  -1.75036569   9.91601783  11.77024087   9.35283941   4.97999496
  -7.77951484  -7.35618312  -4.88260423  12.93369853  -6.92644984
  -7.34863778  -5.55277526   3.03510846 -23.0104797  -21.10098169
 -22.91988928   9.59175537   2.86682161   0.19873871  -4.04382881
   0.96620609  -3.88723514  -1.02740158  -4.16463977  25.91310364]
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2533.257690392717
gradient value of function right now is: [-2.84910371e-02  4.02166692e-03  4.70935695e+00  3.38251640e-03
  2.84910371e-02 -4.02166692e-03 -4.70935695e+00 -3.38251640e-03
 -4.16169563e-03 -1.12166533e-03  1.94678003e-01 -4.91333267e-02
  1.61195983e-02  1.14065497e-02  5.28851622e-03  3.90483047e-02
  6.99422279e-02  8.40547602e-03  1.14400954e+00  1.22238257e+00
  1.42998361e-02  9.69469591e-03  4.23837909e-03  3.18768106e-02
  1.36177617e-01  2.37399262e-02  3.97033400e-03  1.81702711e-01
  5.10648260e-02  9.47579867e-02  4.61964794e-02  1.37555545e-01
 -2.58323973e-01 -2.48875656e-01 -1.39134201e-01 -4.11555234e-01
  1.58145397e-01  1.60231270e-02  1.21352829e-03  8.26098176e-02
 -7.69878349e-01 -4.56269362e-02 -4.39573162e-02 -5.81366210e-02
  6.94632130e-02  5.57049302e-03  5.14616722e-03  7.01731753e-03
  1.11111149e-01  5.06133688e-02  4.74814794e-02  5.97992400e-02
  4.98439995e-01  1.68006381e-02  1.78316103e-02  1.81407947e-02
 -1.39439275e+00  2.85265043e+00  3.88017219e-01 -1.01377617e+00
  3.79201685e-01 -1.04035259e+00  4.81299975e-01 -1.16426203e+00
 -1.29395717e+01]
supnorm grad right now is: 12.939571669537628
Weights right now are: 
[  2.95455511  -4.61173341  -0.28858688  -3.85055353  -3.74477435
   4.62619705   0.85989293   5.26563658   0.65507224  11.69944545
   4.03005748   4.38825675   3.36657598  -6.04942107  16.2468692
   3.44593894  -6.00705758 -10.72929138   5.17379874  -3.70053697
   3.07379506  -5.98948976  16.09490339   3.74375206   9.26154571
   0.98148299  10.41938941  -3.57573804  12.1486343   -0.3186869
  -8.83710611   1.85327306  -7.85624788   1.18182162   8.09173042
   0.11347784   6.23301756 -10.37024616  -7.05058787 -11.6983694
  -1.70740646  11.48146485  13.39021444  10.54773628   5.89284262
  -5.61536339  -5.27435787  -2.53944377  14.85429547  -5.00425794
  -5.29280816  -3.83216356   3.24377769 -24.10484373 -22.21266623
 -24.12851941   9.22890264   3.61008161  -0.35556484  -3.73237523
   0.32848402  -3.48843648  -1.295114    -3.9186137   25.62375409]
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2534.705276987973
gradient value of function right now is: [-3.68544544e-02 -7.77172520e-04 -2.75590422e+00 -6.06542901e-04
  3.68544544e-02  7.77172520e-04  2.75590422e+00  6.06542900e-04
  3.88403853e-03  3.48510206e-04  2.61469543e-01  1.14968838e-01
  1.36240831e-03  1.75629237e-03 -6.68861006e-04 -6.84961082e-03
 -3.95038775e-02 -3.66697125e-04 -1.33417693e+00 -1.06792426e+00
  1.87049748e-03  2.13236532e-03 -6.30118301e-04 -5.55417431e-03
 -1.17920673e-01 -3.74652041e-02 -7.10185802e-03 -9.87383987e-02
 -4.19164896e-03  7.13301062e-03  3.14007480e-03  4.96321275e-03
  1.45923353e-01  5.94438942e-02  1.88612828e-02  1.16119362e-01
 -6.44415794e-01 -4.91660525e-02 -7.02541169e-04 -2.36776820e-01
  1.13466578e+00  9.90862600e-03  1.45416368e-02  8.44392860e-03
 -2.89018500e-01 -1.46549789e-03 -2.12065077e-03 -1.37277595e-03
  2.84187834e-03  1.61748012e-02  1.57331597e-02  1.69825943e-02
 -1.53558698e+00 -9.42283729e-03 -1.43157894e-02 -7.96204770e-03
  1.27479264e+00 -4.31370440e+00 -1.04661186e-01  4.51781223e-01
 -1.60620654e-01  6.93730082e-01 -8.59151026e-02  3.67508634e-01
 -1.80278886e+00]
supnorm grad right now is: 4.313704399877589
Weights right now are: 
[  3.61528515  -4.31194944  -1.03669942  -3.68730779  -4.40550439
   4.32641308   1.60800547   5.10239084   1.66644805  12.56966916
   3.4916689    4.3733466    4.38958587  -5.63622453  16.9646661
   4.40046782  -5.90531654 -11.43875755   4.13987479  -5.07277881
   3.86704864  -5.68666507  16.74996835   4.51200763   9.08042055
  -0.08974321   9.31275653  -4.77893988  12.68256518   0.8663267
  -7.83265929   3.28619942  -6.35665735   1.8408041    8.48528743
   0.88714114   5.75009941 -11.58395322  -8.3495671  -13.218259
  -1.21715899  11.41006288  13.53502943  10.18544351   5.11980133
  -5.18140581  -4.73350129  -2.43536256  15.50495702  -4.2400032
  -4.6811679   -2.63564855   2.23419038 -26.33070637 -24.44174037
 -26.4802652    9.84457194   2.94681249   0.81001405  -3.72757047
   1.3526505   -3.27653148  -0.17650904  -4.08895108  25.49041075]
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2537.5103404464985
gradient value of function right now is: [ 5.24930222e-02 -3.37700046e-03 -1.64786636e+00 -3.21689292e-03
 -5.24930222e-02  3.37700046e-03  1.64786636e+00  3.21689292e-03
  6.61400666e-04  9.54701573e-04 -4.58461014e-01 -2.14996309e-02
 -2.68335263e-03 -9.74925184e-03 -9.23529022e-04 -2.82390382e-02
 -1.76259082e-02 -5.84553466e-04 -5.28429449e-01 -7.83135693e-01
 -2.72704606e-03 -9.61774973e-03 -8.78275662e-04 -2.73859057e-02
 -1.50594834e-02  6.86463693e-03  6.14120880e-03 -1.61842297e-02
 -1.33606221e-02 -4.84835213e-02 -3.68804167e-02 -7.78934476e-02
  9.28691948e-02  5.78646630e-02  2.84152244e-02  1.21789414e-01
  2.45163785e-01  1.25291317e-03 -1.29788925e-03  4.63028233e-02
 -1.00666640e-01  1.00307016e-02  8.51254785e-03  1.70259688e-02
  4.07219851e-02 -6.77138831e-04 -5.32554802e-04 -1.22825018e-03
 -4.09334593e-02 -2.83178843e-02 -2.44834420e-02 -4.02903976e-02
  4.68123593e-01  4.46927555e-03  5.35695763e-03  4.65187789e-03
 -7.57047781e-02  6.28632919e-01 -5.64544743e-02 -2.52845502e-02
 -4.42274421e-02 -4.75733020e-02 -9.81904655e-02  1.75964111e-02
  1.82560968e+00]
supnorm grad right now is: 1.8256096832252386
Weights right now are: 
[  3.87217949  -4.46129236  -1.0440644   -3.82858058  -4.66239872
   4.475756     1.61537044   5.24366363   3.06286277  13.87128942
   3.32424838   3.35991676   4.44271701  -5.79350095  17.39878025
   4.25097714  -2.83096313 -11.44601575   4.26767101  -5.08628315
   3.95833334  -5.83370909  17.1642216    4.37131294  11.11457365
   0.63881756   9.53156251  -2.99335021  12.42073067   0.47740639
  -8.42861791   2.92801741  -6.63648823   1.31059339   8.35106908
  -0.13752143   6.9976608  -11.3184781   -9.27045938 -13.01638753
  -2.60625696  10.72504455  12.56358189  10.0851492    5.87675993
  -4.22448342  -3.87336505  -1.35309472  15.52330351  -4.42886066
  -4.84482933  -2.91702772   3.07033001 -27.5093471  -25.50944234
 -27.44188446   9.23990604   3.83132882   0.93009829  -4.1751727
   1.85822863  -3.8197956   -0.53400478  -4.40866332  26.21946647]
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -2536.327230618092
gradient value of function right now is: [-2.29780756e-02 -8.24859690e-03 -1.95600234e+00 -6.91466820e-03
  2.29780756e-02  8.24859690e-03  1.95600234e+00  6.91466820e-03
  5.42188452e-04  6.80003985e-04  1.55473185e-01  4.25097667e-02
 -3.34927265e-03 -8.76837938e-03 -2.47378550e-03 -8.26800059e-02
 -3.89685511e-02 -1.23379612e-03 -9.50934466e-01 -1.19512282e+00
 -3.05329657e-03 -7.56882347e-03 -2.06162690e-03 -6.93266854e-02
 -5.01392937e-02 -7.71561916e-03  5.45880400e-03 -6.67424104e-02
 -2.70937335e-02 -6.08655294e-02 -4.96776302e-02 -9.03709473e-02
  4.18389349e-01  2.78056892e-01  1.25530248e-01  4.54615600e-01
 -7.14484485e-03 -1.66938045e-02 -1.10212261e-03  5.85349412e-03
  2.64614030e-01  1.90504242e-02  1.83617003e-02  2.75390857e-02
 -9.01933023e-02 -1.59810473e-03 -1.50480596e-03 -2.45720095e-03
 -8.25394207e-02 -1.63617030e-02 -1.42407531e-02 -2.54868158e-02
  1.51533609e-01  5.49045068e-03  7.43354983e-03  4.78627428e-03
  1.40657151e+00 -2.89398408e+00 -1.20122737e-01  7.04889936e-02
 -1.22227461e-01  5.59786259e-02 -1.60676959e-01  1.34143458e-01
  9.45853127e+00]
supnorm grad right now is: 9.45853127051415
Weights right now are: 
[  3.91358372  -5.16559658  -1.301151    -4.44039887  -4.70380295
   5.18006022   1.87245705   5.85548192   5.22454138  14.28365949
   3.39892626   4.56320733   4.98741614  -6.47486841  18.13504447
   3.86159895  -4.01957238 -12.46594651   5.09094263  -4.16163157
   4.55662624  -6.44205311  17.90184075   4.0657385   10.75403494
   0.23122326   9.24634196  -3.94080265  12.91582898   0.46365528
  -8.43958987   3.20822604  -6.35259286   2.13872625   8.80228149
   0.69019149   6.46004033 -12.03044295 -10.40604147 -13.50674166
  -2.13768857  11.71618475  13.84181912  10.34104741   5.42401203
  -5.87663066  -5.82511872  -2.46369597  15.81036657  -3.92436837
  -4.32060763  -2.32909111   2.85077126 -27.67335741 -25.59294498
 -27.81128744   9.97289604   3.3936991    1.05932334  -4.22565831
   1.85075534  -3.80084995  -0.1780434   -4.51817579  26.43679921]
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -2536.125614517288
gradient value of function right now is: [ 2.05638282e-01 -1.54992631e-02 -1.50869811e+00 -1.42190705e-02
 -2.05638282e-01  1.54992631e-02  1.50869811e+00  1.42190705e-02
  2.85990694e-04  8.80101175e-04 -1.95327314e+00 -2.53348689e-03
 -2.84027378e-03 -1.49619798e-02 -1.73795712e-03 -1.51606830e-01
 -4.97312636e-03 -7.15372990e-04 -7.38877380e-02 -3.28583916e-01
 -2.97293387e-03 -1.41358685e-02 -1.65108329e-03 -1.42058419e-01
 -8.69798357e-04  4.66050856e-03  2.76376107e-03  2.56854611e-03
 -5.66811553e-02 -9.95276633e-02 -8.39476978e-02 -1.48464146e-01
  2.98816393e-01  1.33612550e-01  4.70701435e-02  1.97833207e-01
  2.15017046e-01 -1.67196196e-03 -1.78670596e-03  7.50345517e-02
 -1.91376745e-01  3.19307371e-03 -6.68904065e-04  1.07462207e-02
 -2.53702796e-02 -9.01881986e-04 -4.64015553e-04 -1.71140136e-03
 -7.94042107e-02 -1.24557381e-02 -9.30170053e-03 -1.92533955e-02
  5.53137533e-01  1.44611182e-02  1.54118423e-02  1.45075810e-02
  8.59167856e-01 -1.82260389e+00 -3.53691878e-02 -3.05500902e-01
 -1.05821418e-02 -3.64489538e-01 -7.51366913e-02 -2.23354147e-01
 -2.80757145e+00]
supnorm grad right now is: 2.8075714536117986
Weights right now are: 
[  4.56294239  -5.030616    -0.95606609  -4.42099975  -5.35316162
   5.04507964   1.52737214   5.8360828    6.23154128  14.97778847
   2.94268101   4.56321595   3.82365459  -6.83058739  16.92010984
   4.08674528  -2.89853729 -13.27261126   5.46584928  -3.96304175
   3.43665581  -6.8193104   16.66279239   4.18887762  10.91150577
   1.11859253   9.70669063  -3.09624562  13.2091943   -0.2462316
  -8.87585739   2.66507047  -5.2378857    3.47866423  10.13693512
   2.02954527   7.10811722 -11.26709557  -9.86833879 -13.10329033
  -2.18043388  12.1762762   14.14067361  10.94789605   5.74446898
  -7.29887059  -7.42782435  -3.48181476  13.6158127   -5.53486673
  -5.9988448   -3.69760428   3.12670652 -28.28551556 -26.08303104
 -28.45805595  10.62410582   3.21086083   0.16836413  -3.75987916
   1.13631909  -3.52722294  -1.00966805  -3.97908973  25.67827795]
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2537.124248920056
gradient value of function right now is: [ 1.91144060e-01  1.97117207e-02  7.35276440e-02  1.96881437e-02
 -1.91144060e-01 -1.97117207e-02 -7.35276440e-02 -1.96881437e-02
 -1.21439658e-04 -1.29353666e-06 -1.89831265e+00 -1.06360959e-01
  3.93650654e-04  8.58786310e-02 -1.84702403e-04  9.05955949e-02
 -7.68467934e-03  2.37024252e-05  1.14547061e+00  1.08357162e+00
  4.59099047e-04  8.88995809e-02 -1.94644259e-04  9.41012507e-02
  1.86436111e-03 -2.06647598e-03 -2.03491596e-04 -1.51104726e-02
 -1.32567176e-04  8.42881182e-02  8.37379238e-02  8.28197516e-02
 -3.16701813e-01 -6.41600830e-02 -8.24490086e-03 -2.86245542e-01
  5.06270917e-01  1.62626205e-02  6.95100018e-04  1.68194322e-01
 -8.07542746e-01 -9.64665684e-03 -1.26693105e-02 -6.81561314e-03
  1.49044540e-01  1.35158890e-03  1.64846692e-03  1.09840190e-03
  3.37025033e-02  1.31401248e-03  1.63995731e-03  7.31935820e-04
  1.34231831e+00  1.39428052e-02  1.82512566e-02  9.94995773e-03
 -1.19263772e+00  2.91688063e+00  1.72164833e-01 -6.41703129e-01
  2.18442226e-01 -8.10886670e-01  1.22415105e-01 -4.52003070e-01
 -7.88538455e+00]
supnorm grad right now is: 7.885384554607299
Weights right now are: 
[  4.83591518  -3.81575837  -1.14821779  -3.25451184  -5.62613442
   3.83022201   1.71952383   4.66959488   7.16216899  15.83153886
   2.75636121   5.7958751    1.43959741  -5.32921866  17.45477137
   5.30127538  -2.79013136 -13.85232075   5.91974107  -3.39307932
   1.00153517  -5.38035158  17.2617907    5.35254124  11.00387096
   1.87609101   9.90145511  -2.45353842  14.84439943   0.9378093
  -6.91301711   3.69596125  -6.33053213   2.91232625   9.53862567
   1.9426353    6.42967356 -11.68425067 -10.09136501 -14.35607396
  -2.08222598  11.94574557  14.07537952  10.57476697   5.72488658
  -9.04539941  -9.22131225  -5.13972406  12.93351804  -6.05793273
  -6.75721588  -3.88429252   2.06720867 -30.06843068 -27.86712805
 -30.10017606   9.82010874   4.05738037   0.64210999  -3.51573204
   1.28786665  -3.10016042  -0.26209198  -4.05512651  25.79466697]
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2536.4106280999213
gradient value of function right now is: [ 2.93060205e-01 -3.27263889e-02 -3.28018674e+00 -4.06988178e-02
 -2.93060205e-01  3.27263889e-02  3.28018674e+00  4.06988178e-02
  5.34038619e-04  1.70351097e-04 -2.97070721e+00  1.44946357e-02
 -1.79252319e-01 -1.89891586e-02 -1.23162744e-02 -3.34463409e-01
 -1.41613481e-02 -1.75179431e-04 -3.91103707e-01 -5.75899487e-01
 -2.40063617e-01 -2.34492319e-02 -1.66984061e-02 -4.31213585e-01
 -4.43583652e-02 -7.45597232e-02 -1.19498716e-02 -2.08007112e-01
 -4.62626898e-02 -1.59704818e-01 -7.87972126e-02 -2.75629295e-01
  2.81641779e-01  1.34378952e-01  1.52993135e-02  6.14301401e-01
 -7.84461427e-02  1.03251374e-02  2.14997853e-04 -9.75092458e-02
  1.38233224e+00  8.20715295e-02  9.18430509e-02  7.19271042e-02
 -8.10475826e-02 -1.35774563e-02 -1.50050957e-02 -1.19026249e-02
 -2.41068231e-02 -1.01553012e-02 -9.69260302e-03 -1.13265535e-02
 -1.37509550e+00 -3.44342594e-02 -4.41728128e-02 -2.37688071e-02
 -3.00721994e-01  8.26049607e-01 -5.49107168e-01  2.47527281e+00
 -6.41403699e-01  3.05050626e+00 -4.38469270e-01  1.75526195e+00
  8.05414790e+00]
supnorm grad right now is: 8.054147904473279
Weights right now are: 
[  5.07865691  -5.47008434  -0.503688    -5.06697126  -5.86887614
   5.48454798   1.07499405   6.48205431   6.78448373  15.43793491
   2.6810243    5.76424521  -2.29481164  -7.67578568  17.73107401
   4.12378044  -3.12206535 -13.31213692   4.13424978  -4.70425596
  -2.47821413  -7.83621465  17.37919897   4.00552686  10.70461319
   1.04615363   9.98230429  -3.49406453  14.95268432  -0.41795743
  -8.02834135   2.43753227  -5.9754904    2.68654572   8.1210207
   2.91010259   6.61500244 -12.55007776 -11.14158762 -14.456576
  -1.28285227  13.50564515  15.57704729  11.83601445   4.97428369
 -10.53035222 -10.73479507  -6.47138069  13.14138977  -7.2119692
  -8.18669932  -4.67410355   2.38437495 -30.73510363 -28.25987058
 -31.04419394   9.78300133   4.13969984   0.47401125  -3.08966366
   0.87980135  -2.84146937  -0.19548661  -3.47680586  26.2293584 ]
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2534.0707723888004
gradient value of function right now is: [-2.70677300e-02  7.52951729e-02  8.02096431e+00  7.98883035e-02
  2.70677300e-02 -7.52951729e-02 -8.02096431e+00 -7.98883035e-02
 -3.89706063e-04 -5.84645553e-04  2.90558938e-01 -9.70064576e-02
  2.09955095e-02  2.93730927e-02  9.28699265e-03  8.23305027e-01
  6.26363095e-03  4.92867406e-04  9.19808613e-01  9.83626731e-01
  2.46768187e-02  3.25820735e-02  1.05747317e-02  9.06874658e-01
  1.66729196e-02  4.85047980e-02  1.15121514e-02  8.87410391e-02
  9.01965033e-02  2.80331704e-01  2.13471409e-01  3.69162359e-01
 -3.37930497e-01 -2.11815833e-01 -8.65201734e-02 -4.54486790e-01
  3.63192008e-01  2.62687156e-02  4.68500561e-04  1.35074647e-01
 -6.77175035e-01 -6.34828065e-02 -5.75931488e-02 -8.26401327e-02
  2.84433214e-01  1.07566133e-02  1.08320715e-02  1.11862234e-02
  5.22887882e-02  2.49658431e-02  2.03581116e-02  3.82601517e-02
  1.00099234e+00  1.27615831e-02  1.38813742e-02  1.15039054e-02
 -1.39734812e+00  2.92008516e+00  4.96831617e-01 -8.86578983e-01
  4.87972161e-01 -9.11584240e-01  5.52957254e-01 -8.73722640e-01
 -1.30634671e+01]
supnorm grad right now is: 13.063467101864426
Weights right now are: 
[  4.02662304  -5.61677863  -0.18303062  -5.13945654  -4.81684228
   5.63124227   0.75433666   6.55453959   6.58163965  16.79887388
   3.82269073   6.08554679  -2.42432538  -6.9699738   17.68429823
   3.99036931  -1.04414368 -13.99882314   4.22535695  -4.268243
  -2.5479963   -7.17446718  17.33899202   3.94426223  12.50265678
   0.60261213  10.99360104  -2.87124229  14.94501337   0.13985387
  -7.71165819   3.20444512  -6.42761517   3.62446935   9.81238178
   2.26067672   6.30354162 -13.08424818 -12.07738914 -14.91841645
  -2.51969563  11.55771355  13.67471334   9.96633446   4.98627188
 -10.58622104 -10.90055185  -6.16797747  14.54020159  -6.11372212
  -7.208729    -3.41733425   2.44088459 -30.95815508 -28.27549011
 -31.78090298   9.7369577    4.07543582   1.33981281  -4.55165658
   1.82720639  -4.36888098   0.45605004  -4.8086038   25.79284364]
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2536.3043523141114
gradient value of function right now is: [-6.84569862e-03  4.52448271e-02  6.61168840e+00  4.77540972e-02
  6.84569862e-03 -4.52448271e-02 -6.61168840e+00 -4.77540972e-02
 -9.81502258e-05 -2.89641394e-04  9.26764990e-02  5.15708689e-02
  2.92161508e-02  2.47574121e-02  1.02882799e-02  4.87530696e-01
  9.49015772e-03  6.90999628e-04  1.88545052e-01  5.70921437e-01
  3.43146791e-02  2.71950627e-02  1.14963624e-02  5.32615699e-01
  2.19698861e-03  3.02713720e-02  2.57384953e-03  4.80940905e-02
  9.80631160e-02  2.34536285e-01  1.72011911e-01  3.49926928e-01
 -2.63937736e-01 -2.74294937e-01 -1.44304471e-01 -5.60310083e-01
 -6.88195796e-01 -6.85722258e-03 -6.04583549e-06 -2.31584179e-01
  1.10505855e-01 -5.38443747e-02 -4.83649325e-02 -6.23527589e-02
 -2.56893848e-03  1.41045017e-02  1.37247020e-02  1.41978795e-02
  9.14315603e-02  3.18874443e-02  2.77772604e-02  3.86265268e-02
 -2.38882868e+00 -6.39975398e-03 -7.50229365e-03 -4.55694490e-03
 -4.73886128e-01  4.91509562e-01  3.43081447e-01 -2.46217148e-01
  3.33165986e-01 -2.23412256e-01  3.49847777e-01 -3.11395299e-01
 -5.00020667e+00]
supnorm grad right now is: 6.6116883998242235
Weights right now are: 
[  4.96611878  -5.51469412  -0.16315637  -5.011032    -5.75633802
   5.52915776   0.73446242   6.42611505   7.1532064   17.16625348
   3.04406276   7.15087958  -1.274311    -7.38450412  18.8336989
   4.17077303  -0.49635069 -14.50182394   4.46727635  -4.4746967
  -1.41850331  -7.58883963  18.49943972   4.14257722  13.54718066
   1.3941876   11.07594826  -1.71325688  15.39534883  -0.44135708
  -8.11391927   2.83695333  -7.12166176   2.42321347   9.61910034
   1.18993389   5.53886555 -13.34036243 -11.36862532 -16.2433565
  -2.29876585  10.70773962  12.78902257   9.38148565   5.41575841
  -8.91044301  -9.31498346  -4.28131595  12.47238684  -8.25187226
  -9.64128978  -5.15686716   1.19720959 -33.6578432  -30.97623859
 -34.2653994    9.96193906   3.81954072   1.18457224  -4.06404758
   1.7372059   -3.85878402   0.25543798  -4.52983594  26.04535568]
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2538.7368149167055
gradient value of function right now is: [-2.60008225e-02  2.31028642e-03  2.21465362e-01  2.42102528e-03
  2.60008225e-02 -2.31028642e-03 -2.21465362e-01 -2.42102528e-03
 -2.34186051e-05 -2.32377913e-05  2.46780618e-01 -4.32789453e-02
  9.96573831e-04  1.10686034e-03  1.91656674e-04  2.19333700e-02
  8.40230203e-04  5.96904520e-05  2.41497007e-01 -2.09682269e-02
  1.15133927e-03  1.20285198e-03  2.15230768e-04  2.39352091e-02
  2.12874828e-04  1.40734443e-03 -3.48694504e-06  2.51636034e-03
  5.00998889e-03  9.87675189e-03  1.27780188e-02  1.70124628e-02
  2.22360969e-02  1.17316773e-02  5.66432588e-03  6.95093695e-03
  6.08314912e-01  1.89034025e-02  1.61645007e-06  1.88977687e-01
 -3.56171225e-01 -5.59491804e-03 -4.69323492e-03 -8.89101117e-03
  1.75200259e-01  1.03219841e-03  1.02127757e-03  1.03655182e-03
 -9.17216865e-03 -6.07325891e-04 -8.78077833e-04  9.53903876e-04
  1.67569515e+00  9.68871774e-03  9.45052633e-03  1.08663548e-02
 -6.69250716e-01  1.73563250e+00  8.46279105e-02 -3.45040646e-01
  7.16359719e-02 -3.12928417e-01  1.15944303e-01 -4.00175636e-01
 -5.26632386e+00]
supnorm grad right now is: 5.266323860014511
Weights right now are: 
[ 4.51288287e+00 -4.75384888e+00 -9.05016061e-01 -4.24474299e+00
 -5.30310211e+00  4.76831252e+00  1.47632211e+00  5.65982604e+00
  7.58889082e+00  1.78694435e+01  3.51670536e+00  6.74293703e+00
 -1.14014370e+00 -6.72371140e+00  1.85243008e+01  5.01027181e+00
 -1.14649760e+00 -1.44989548e+01  4.37552870e+00 -4.59817212e+00
 -1.30199251e+00 -6.91926823e+00  1.81738138e+01  4.98369665e+00
  1.34927880e+01  1.97260130e+00  1.24110430e+01 -1.27676846e+00
  1.52513515e+01  5.12438246e-01 -8.33498815e+00  3.83252082e+00
 -6.93485458e+00  2.57316919e+00  9.25587097e+00  1.65524404e+00
  5.92685070e+00 -1.38431011e+01 -1.34535955e+01 -1.59081755e+01
 -2.74178523e+00  1.03399885e+01  1.23247778e+01  9.27617372e+00
  5.17298019e+00 -8.97581079e+00 -9.50946030e+00 -4.06142450e+00
  1.50481994e+01 -6.71838292e+00 -8.08586054e+00 -3.82862479e+00
  1.96209994e+00 -3.40371351e+01 -3.13925941e+01 -3.44825056e+01
  9.20305629e+00  4.37863167e+00  1.42046007e+00 -5.00264459e+00
  2.22050298e+00 -4.87175220e+00 -1.23296887e-02 -5.17504584e+00
  2.60073272e+01]
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2536.1971133612624
gradient value of function right now is: [-3.87665079e-02 -1.24448016e-03 -4.61791735e+00 -1.39486345e-03
  3.87665079e-02  1.24448015e-03  4.61791735e+00  1.39486345e-03
 -2.75313039e-06 -5.28775330e-06  3.48758930e-01  4.91956308e-02
  4.90118866e-04 -4.68611251e-03 -3.68444762e-04 -1.01758065e-02
 -2.22301737e-04 -1.43721687e-05 -1.51308188e+00 -1.11561506e+00
  5.49295028e-04 -5.39618859e-03 -4.09016963e-04 -1.16987499e-02
 -1.84936958e-04  7.17150856e-04  4.51321343e-05  5.68086323e-04
 -4.68267505e-03 -2.43156698e-02 -2.58966766e-02 -3.33527251e-02
  1.11089137e-01  5.08220386e-02  1.84154709e-02  9.29424536e-02
 -8.22995995e-01 -5.77377951e-02 -2.33279584e-04 -2.15910461e-01
  6.85472875e-01  5.36425942e-03  3.76909889e-03  1.08459622e-02
 -4.99395238e-01 -8.03187675e-04 -6.81916736e-04 -9.82743698e-04
 -1.04456620e-02 -1.94501942e-03 -6.73360431e-04 -6.86060753e-03
 -1.78062691e+00 -2.98733927e-03 -2.46827234e-03 -4.11089382e-03
  1.44566768e+00 -4.62386770e+00 -9.03757558e-02  1.93791176e-01
 -6.84953174e-02  1.52360972e-01 -1.43562196e-01  2.74303477e-01
  5.31942204e+00]
supnorm grad right now is: 5.319422041689314
Weights right now are: 
[  4.22774321  -4.59992186  -0.74358222  -4.0878195   -5.01796244
   4.6143855    1.31488826   5.50290255   6.46905655  19.08338384
   3.90238962   6.93235484  -0.78620882  -6.70053262  20.03046003
   5.25917907  -1.25602189 -15.21192609   3.69410058  -5.35819094
  -0.95364067  -6.90022195  19.63945435   5.22811166  13.4965865
   2.38556907  12.81158882  -0.83245074  15.12065077   0.50929911
  -8.57237632   3.86458055  -6.82346981   1.77373362   8.14573204
   1.85086694   5.80600092 -15.0973873  -15.11472899 -16.24854913
  -2.16979943  10.86808739  12.93958439   9.72896917   4.48534077
  -8.69930347  -9.19737034  -3.73521523  15.25980659  -7.06568906
  -8.4339785   -4.12969734   2.16394499 -34.85278817 -31.92622274
 -35.81007367  10.30843724   3.44954025   0.65525166  -4.5402392
   1.38725968  -4.48284128  -0.70581481  -4.68068137  26.06560911]
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2536.303169269211
gradient value of function right now is: [-3.52690398e-02 -5.16414854e-03 -2.85287434e+00 -6.02625686e-03
  3.52690398e-02  5.16414854e-03  2.85287434e+00  6.02625686e-03
  1.56487768e-05  1.90739751e-05  3.53963602e-01  2.30879972e-02
 -7.23163843e-03 -3.74889929e-03 -1.92627764e-03 -5.35611875e-02
 -4.65409419e-03 -1.85034768e-04 -1.61835300e+00 -1.46357581e+00
 -9.72468588e-03 -4.49279780e-03 -2.48675189e-03 -6.50876711e-02
 -7.98788622e-03 -7.15438624e-03 -1.18264474e-03 -2.12004246e-02
 -1.49440457e-02 -3.18948926e-02 -2.83431492e-02 -5.02322479e-02
  1.31233815e-01  8.80117520e-02  3.44474701e-02  1.76792801e-01
 -5.87594031e-01 -4.11118426e-02 -4.89966941e-04 -1.86996989e-01
  4.12072032e-01  1.46460538e-02  1.24929679e-02  2.21726078e-02
 -3.06577900e-01 -3.77871037e-03 -3.38919844e-03 -4.99656167e-03
 -2.56951299e-02 -4.36999623e-03 -3.17293170e-03 -8.86960921e-03
 -1.22277994e+00 -5.23570591e-03 -4.65843630e-03 -6.88883878e-03
  1.46176495e+00 -3.87979917e+00 -1.49933527e-01  3.57485705e-01
 -1.30119028e-01  3.13939980e-01 -2.10230849e-01  4.73756816e-01
  6.66775938e+00]
supnorm grad right now is: 6.6677593848168275
Weights right now are: 
[  4.71094432  -5.31902901  -1.15149919  -4.87522433  -5.50116355
   5.33349265   1.72280524   6.29030738   7.91225675  19.44146409
   3.5939702    7.87490075  -3.57713139  -7.41563266  17.62289847
   4.62643196  -3.19872516 -16.28113838   4.06945037  -5.06472171
  -3.72433004  -7.65075365  17.14409591   4.52264245  12.47844859
  -0.3435414   10.25671212  -3.19730874  14.88404679  -0.26565119
  -9.23145726   3.28356101  -7.84846884   2.147608     9.02115207
   1.78890892   5.87927007 -14.81379653 -17.55541189 -16.30403008
  -3.07466477  11.06652274  13.19410406   9.92618235   5.15504484
  -8.45714178  -9.11744668  -3.14487031  15.2638713   -7.79910083
  -9.19140972  -4.79833262   2.09823539 -35.94182238 -33.13089341
 -36.62721839  10.25253611   3.7241959    0.65652937  -4.43884917
   1.38874429  -4.31247152  -0.84558938  -4.67364783  26.08788354]
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2535.2237977976124
gradient value of function right now is: [-4.20440991e-02 -1.03298973e-02 -2.24827368e+00 -1.35645423e-02
  4.20440991e-02  1.03298973e-02  2.24827368e+00  1.35645423e-02
  1.30957549e-04  1.79389636e-05  3.90451263e-01  3.19981180e-03
 -2.26160191e-02 -9.28690533e-03 -7.35467019e-03 -1.13943437e-01
 -1.51032408e-02 -2.00652114e-04 -7.04631829e-01 -6.58890521e-01
 -3.61070441e-02 -1.19317248e-02 -1.17997823e-02 -1.56098004e-01
 -9.95330255e-02 -5.66309015e-02 -2.48891949e-02 -1.36888512e-01
 -7.39544380e-02 -8.36125692e-02 -7.21341534e-02 -1.10734375e-01
  2.21006495e-01  1.08207824e-01  3.80352884e-02  2.81348563e-01
 -1.60425355e-01 -2.33326377e-02 -7.14984174e-04 -5.86405598e-02
  4.93812839e-01  2.27608631e-02  2.31991944e-02  3.34567656e-02
 -1.91169133e-01 -4.67677935e-03 -4.71123970e-03 -7.06635355e-03
 -2.49043696e-02 -1.97590379e-03 -1.68197323e-03 -4.92321323e-03
 -3.43076193e-01 -5.20094891e-03 -5.16096403e-03 -7.82784891e-03
  1.25669017e+00 -3.11215563e+00 -2.28775267e-01  5.36198757e-01
 -2.39134287e-01  5.69830201e-01 -3.40652894e-01  7.58697518e-01
  9.04009261e+00]
supnorm grad right now is: 9.040092606116758
Weights right now are: 
[  4.35858551  -5.73764553  -0.7299055   -5.3742935   -5.14880475
   5.75210917   1.30121154   6.78937655   6.97666041  19.40259625
   4.02653895   7.86565838  -5.92592477  -8.75595082  16.24442052
   4.42163237  -5.53267807 -16.01751674   4.43253235  -5.01499241
  -6.15776197  -9.0862598   15.46648222   4.26220027   9.86120333
  -1.45889689   9.05736406  -5.84583683  13.82164536  -1.54148824
 -10.57784583   2.00403652  -7.09571421   3.06194859   8.69939067
   3.51943354   6.62672955 -14.71255252 -18.56757793 -15.68110191
  -2.60269971  13.54584451  15.82075295  12.10927959   5.38586754
 -10.66526245 -11.32870594  -5.22577711  14.82866909  -8.49923434
  -9.80922637  -5.7887674    3.0024943  -35.9930837  -33.49190507
 -36.16576642  10.59755359   3.71474562   0.3092552   -4.07333203
   1.0509421   -3.75287532  -1.48029463  -4.44293503  26.19712541]
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2536.869961842329
gradient value of function right now is: [-3.30054920e-02 -2.46191504e-03 -1.59887283e+00 -3.81462364e-03
  3.30054920e-02  2.46191504e-03  1.59887283e+00  3.81462364e-03
  5.21564379e-05  9.02151202e-06  3.16619631e-01  2.61972935e-02
 -9.84852905e-03 -7.17514176e-03 -6.69255187e-03 -2.82613451e-02
 -2.50447113e-02 -1.54052181e-03 -9.06138413e-01 -7.92153017e-01
 -1.68154710e-02 -1.06750090e-02 -1.06655918e-02 -4.41464103e-02
 -7.79436556e-02 -2.06875694e-02 -4.76494449e-03 -1.10262027e-01
 -7.57978386e-02 -5.94114955e-02 -3.44463785e-02 -1.02865117e-01
  1.56738623e-01  9.18098447e-02  4.12435563e-02  2.30435774e-01
 -3.21805280e-01 -3.94467530e-03 -7.14019449e-05 -8.00264899e-02
  5.43519076e-01  2.30962914e-02  2.47407978e-02  2.93162349e-02
 -7.61470798e-02 -3.16849060e-03 -3.16608697e-03 -4.83002342e-03
 -5.00283076e-02 -2.76332980e-03 -2.55760018e-03 -5.32645446e-03
 -8.96411716e-01 -8.56652350e-03 -1.06594926e-02 -8.50933045e-03
  9.14156536e-01 -1.90283470e+00 -2.04596690e-01  6.80564706e-01
 -2.26450509e-01  8.11210445e-01 -2.65384086e-01  7.28376298e-01
  4.63142957e+00]
supnorm grad right now is: 4.631429567726108
Weights right now are: 
[  4.42848219  -5.96941625  -0.89093423  -5.44426675  -5.21870143
   5.98387989   1.46224027   6.8593498    8.36613087  19.96642847
   4.10921682   9.57747379  -5.03477007 -10.82496812  16.4264222
   4.23024497  -5.16187458 -16.37215851   4.37386238  -4.85173471
  -5.36219998 -11.24246117  15.6086047    4.18831941  10.51722934
  -1.1253236    8.27527087  -5.36796504  11.5148305   -3.53036015
 -12.60742223   0.16397321  -8.07931281   2.06998957   9.66394903
   2.69845205   5.57378832 -14.91568308 -18.67537412 -16.67194362
  -2.69043183  13.76871369  16.09020565  12.20144823   5.96824547
 -10.17372066 -10.81825414  -4.74515208  14.8208601   -9.22039414
 -10.44800559  -6.96540784   2.12627154 -36.73057866 -34.36328083
 -36.40967995  10.55459467   4.05021476   0.52318846  -3.94805058
   1.30806607  -3.59209485  -1.48822747  -4.45556431  26.01393079]
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2531.053320005327
gradient value of function right now is: [ 4.52513770e-03 -3.90705918e-03  1.08893590e+00 -6.17873219e-03
 -4.52513770e-03  3.90705918e-03 -1.08893590e+00  6.17873219e-03
  1.66744527e-05  2.80982629e-07 -3.98666135e-02  5.38044275e-02
 -2.54219305e-02 -5.73259809e-03 -1.01521078e-02 -4.67614485e-02
  3.75079161e-03  3.36600556e-04 -3.74767569e-02  7.91476229e-03
 -4.09621635e-02 -8.34836607e-03 -1.59531252e-02 -7.23946613e-02
 -4.84765523e-02 -4.66166140e-02 -9.26626824e-03 -1.20869904e-01
 -5.11088047e-02 -4.90277756e-02 -1.55732395e-02 -1.11974714e-01
  9.31592607e-02  8.63044487e-02  1.44290579e-02  2.64808724e-01
 -3.98274890e-01 -5.89028464e-03  5.96187351e-06 -8.93726211e-02
  6.03961727e-01  4.23242419e-02  3.79900884e-02  6.60182050e-02
 -1.64990986e-01 -8.77836739e-03 -7.58875361e-03 -1.49806812e-02
 -3.22747560e-02 -3.01273482e-03 -2.13412566e-03 -7.61080491e-03
 -1.07926857e+00 -1.01364319e-02 -9.70065205e-03 -1.43109004e-02
  7.76423318e-01 -1.99425087e+00 -3.38348944e-01  1.22327396e+00
 -2.90732867e-01  1.13958279e+00 -5.85638630e-01  1.77816776e+00
  1.52879979e+01]
supnorm grad right now is: 15.287997939279833
Weights right now are: 
[  4.73925462  -6.5639175    0.19523107  -6.11339941  -5.52947386
   6.57838114   0.37607497   7.52848246   7.72140704  19.47949078
   3.88021314   7.37979449  -6.22033375 -11.42454493  15.58886406
   3.63910687  -3.51858926 -15.44753116   4.41732487  -4.81257871
  -6.54424466 -11.96917009  14.81227608   3.53799949  11.44134774
  -1.91799106   7.62628062  -4.83622597  11.9386071   -3.43510888
 -12.29262188  -0.27688771  -8.39679935   2.48425313   9.4100865
   3.18873226   5.981614   -15.30582921 -19.17654139 -16.95695318
  -3.16940911  14.38364855  16.55959993  13.08855093   5.21175603
 -12.35585623 -12.89076653  -6.96499069  15.1772549  -10.36637879
 -11.61363625  -7.88598452   2.45396256 -36.88430531 -34.35232128
 -36.91501576  10.79735317   3.88826318  -0.61997049  -3.59455113
   0.24574931  -3.45205296  -2.57657849  -3.79664736  26.48143963]
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2533.864428381118
gradient value of function right now is: [ 2.69394150e-02 -3.58309520e-04 -6.78131977e-01 -1.82168107e-03
 -2.69394150e-02  3.58309519e-04  6.78131977e-01  1.82168107e-03
 -1.61301398e-05 -3.78122026e-06 -2.93393284e-01 -1.36997006e-02
 -2.25448945e-03 -9.88709075e-05 -1.50672720e-03 -4.70223795e-03
 -1.05447295e-02 -1.78606508e-04 -2.09259050e-01 -2.89448397e-01
 -1.27236434e-02 -3.49318006e-04 -8.82659175e-03 -2.49346851e-02
 -4.60150061e-02 -2.18749072e-02 -1.97689973e-03 -6.09692461e-02
 -3.86968413e-03 -2.35006947e-03 -5.30085723e-04 -4.43303280e-03
  9.18207513e-02  3.57926581e-02  2.13538306e-03  1.05162721e-01
  7.12835231e-02  1.44613671e-03 -5.23897114e-06  6.51438835e-03
  2.57824491e-01  1.74911142e-02  1.55792710e-02  9.54395763e-03
 -3.84407420e-02 -4.21310516e-03 -3.45767539e-03 -2.16454056e-03
 -1.84884569e-03 -1.59551457e-04 -1.16481745e-04 -7.13889962e-05
  6.51873404e-03 -5.90145073e-03 -4.28557555e-03 -3.08714762e-03
  2.67448481e-01 -7.33857587e-01 -2.81966317e-01  7.49072285e-01
 -2.39962469e-01  6.42690820e-01 -1.27379076e-01  3.44768846e-01
 -1.50580686e+00]
supnorm grad right now is: 1.5058068590352633
Weights right now are: 
[  5.16853135  -6.70544967  -0.83437852  -6.77462713  -5.95875059
   6.71991331   1.40568456   8.18971018   6.35729189  18.83839622
   3.51008367   6.62199206  -8.09546709 -10.81560423  15.12284551
   3.58841856  -3.13670919 -15.76090424   4.2994106   -5.17277943
  -9.3995707  -11.48898001  13.72537959   3.01961941  10.98188589
  -3.60132437   7.36401973  -6.06198864  12.57421716  -2.92603349
 -11.71735646   0.16348868  -7.99238801   3.3050732    9.00174752
   4.39537206   6.37250955 -16.21098649 -20.01604284 -16.92192491
  -2.39864652  16.33964118  19.23566945  14.01976728   4.30869417
 -14.74601849 -15.8883177   -7.70928597  15.80530221 -10.16790171
 -11.80695858  -7.13282144   3.64519139 -36.04541074 -32.95896741
 -36.37229354  11.02777388   3.79119663  -2.49113525  -3.39518893
  -1.81271964  -3.29588477  -2.81810579  -4.00738445  25.5244878 ]
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2531.1171456696998
gradient value of function right now is: [-1.14187737e-02  8.44437243e-05  3.57474075e-01  4.44755481e-04
  1.14187737e-02 -8.44437246e-05 -3.57474075e-01 -4.44755481e-04
 -5.96393968e-05 -6.08200059e-07  1.16877036e-01 -6.19173248e-03
 -3.41988898e-04  2.65717527e-05  7.43781871e-04  1.30667187e-03
 -2.65720748e-02 -2.93561355e-04 -9.71179397e-02 -1.17972494e-01
 -3.11494957e-03  1.72709420e-04  1.07274009e-02  1.42243146e-02
  1.00371811e-02 -2.66347767e-05  4.29458498e-03  3.53631490e-03
 -1.00296448e-03 -5.98059108e-05  3.06051536e-04 -1.16122691e-03
  3.87657387e-02  1.55583408e-02 -4.09631494e-03  4.29244590e-02
  2.24710060e-02  1.37657794e-03 -2.55970446e-06  5.16130483e-03
  1.83524947e-02  1.98268186e-03  2.29126946e-03  1.90278956e-03
 -4.27273603e-03 -9.18042664e-04 -9.33190493e-04 -1.03127309e-03
 -1.13319260e-05 -8.08461000e-05 -8.60367760e-05 -7.89570594e-05
  4.19251374e-02 -2.42667485e-04 -2.11328128e-04 -3.70873046e-04
  8.75314794e-02 -1.60831389e-01 -4.26665709e-02  1.11384625e-01
 -4.17273591e-02  1.21215378e-01 -4.65779054e-02  1.09942240e-01
 -8.60922520e+00]
supnorm grad right now is: 8.609225204307329
Weights right now are: 
[ 4.83920883e+00 -7.57118152e+00  5.09384338e-01 -8.10224212e+00
 -5.62942806e+00  7.58564516e+00  6.19217081e-02  9.51732517e+00
  6.43899521e+00  1.92937533e+01  3.95445783e+00  8.49757951e+00
 -9.28324368e+00 -1.09150296e+01  1.36965079e+01  2.63631382e+00
 -1.03996581e+00 -1.46498901e+01  6.16990610e+00 -3.12003362e+00
 -1.07861762e+01 -1.17965860e+01  1.24254309e+01  1.59009506e+00
  1.01081216e+01 -5.26521945e+00  4.87977656e+00 -7.27542879e+00
  1.24473409e+01 -3.11084285e+00 -1.18531503e+01  7.32811347e-03
 -8.14113606e+00  3.87171265e+00  9.92265768e+00  4.92633340e+00
  6.34000618e+00 -1.59340550e+01 -2.06855834e+01 -1.69044788e+01
 -2.18510390e+00  1.70949563e+01  1.99964230e+01  1.48683036e+01
  4.83697974e+00 -1.50209347e+01 -1.63710731e+01 -8.23532879e+00
  1.54576964e+01 -1.06087645e+01 -1.23940294e+01 -7.29656004e+00
  4.01338430e+00 -3.63092859e+01 -3.32546474e+01 -3.71164536e+01
  1.12588945e+01  3.89524423e+00 -2.40380993e+00 -3.46202144e+00
 -1.90138008e+00 -3.23686181e+00 -3.10889158e+00 -3.70471583e+00
  2.52379744e+01]
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2535.7788376108674
gradient value of function right now is: [-1.92153478e-02 -2.21225230e-04  1.66051508e+00 -5.23103674e-03
  1.92153478e-02  2.21225233e-04 -1.66051508e+00  5.23103675e-03
 -3.32426238e-06 -3.02255724e-08  1.91201779e-01 -8.45848358e-03
 -2.61826605e-03  4.37927028e-06 -1.48260617e-03 -2.73643186e-03
  6.89749741e-03  5.75558345e-05  4.23365776e-01  2.53506280e-01
 -5.70429816e-02 -1.16081965e-04 -3.38399864e-02 -6.46011048e-02
 -2.42756742e-02 -8.83426825e-03  2.03020004e-03 -7.10423027e-02
  1.24291585e-04  4.50105574e-04  4.33107465e-04 -1.11977347e-03
  7.76447419e-02  3.10808862e-02 -1.86346068e-03  2.05354008e-01
  3.83081075e-01  1.37065264e-02  2.05818040e-05  6.85251326e-02
  2.69452739e-01  3.29454642e-02  3.45998228e-02  3.14535817e-02
  8.80514847e-02 -2.76605837e-03 -2.78232323e-03 -2.77268450e-03
 -3.90401125e-04 -7.23896863e-05 -7.34626367e-05 -7.08415886e-05
  8.35931948e-01  1.03979563e-02  1.21657213e-02  8.66522145e-03
 -4.90285574e-01  1.08059058e+00 -5.04033152e-02 -3.69322201e-02
 -7.94387038e-02  3.24512219e-02 -3.15575347e-02 -6.02711722e-02
 -5.54814203e+00]
supnorm grad right now is: 5.5481420273555315
Weights right now are: 
[  4.66071339  -6.25639244  -0.23780278  -6.52199998  -5.45093263
   6.27085608   0.80910883   7.93708302   6.03554667  19.13125848
   4.19813077   9.96843686  -7.80472824 -10.60621279  15.1320443
   4.01813416  -2.06077375 -14.28361157   3.5503497   -5.46368243
  -9.5066554  -10.58935419  13.49941832   3.04884576  11.44891085
  -3.66764038   6.29545033  -5.92191551  13.58234837  -2.11018512
 -10.99047493   0.96310544  -9.64652851   2.25304402   8.44191304
   3.48206684   4.38087305 -16.66615472 -20.92984349 -19.23330359
  -2.84919221  16.4361907   19.36967771  14.14505764   5.45773956
 -14.35279858 -15.77527665  -7.44591051  16.91738813  -9.39674868
 -11.1080545   -6.43524458   4.03602856 -36.18738994 -33.14022013
 -36.94981382  10.14627029   5.04942519  -1.48708756  -4.11953107
  -1.01595996  -3.87979658  -2.1242834   -4.418408    25.74246714]
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2537.5207300108427
gradient value of function right now is: [-3.84951035e-02 -3.16134034e-04 -8.30968131e-01 -3.66673643e-03
  3.84951035e-02  3.16134032e-04  8.30968131e-01  3.66673643e-03
  4.28298518e-06  2.13741889e-06  3.86276329e-01  1.60709892e-02
 -1.52168829e-03 -9.78941632e-04 -1.46266041e-03 -3.80169357e-03
 -4.03943280e-03 -5.10138551e-04 -1.85674965e-01 -1.29893343e-01
 -2.82946620e-02 -6.01740746e-03 -2.02731471e-02 -4.47433986e-02
 -2.71820047e-02 -2.65933575e-02 -5.52181653e-03 -5.56686592e-02
 -2.80219235e-02 -2.80850120e-02 -1.20082253e-02 -4.53378025e-02
  7.01886738e-02  6.88627692e-02  1.65727456e-02  1.45433073e-01
 -2.88669721e-02  2.83674317e-03 -2.89249636e-06  1.85927144e-02
  1.70948735e-01  1.90034989e-02  1.85211648e-02  2.04708602e-02
 -7.59515610e-03 -3.76998071e-03 -3.59324862e-03 -4.17174552e-03
 -1.85071904e-02 -2.03876711e-03 -1.88151452e-03 -2.39661797e-03
  2.43594132e-01  3.01486263e-03  3.78589713e-03  2.17276241e-03
  2.84652938e-01 -3.62553902e-01 -1.64471238e-01  2.08160027e-01
 -1.78622707e-01  2.32649955e-01 -1.52155149e-01  1.95341291e-01
  2.54537193e+00]
supnorm grad right now is: 2.5453719292362633
Weights right now are: 
[  4.65724092  -6.14497738  -0.5368626   -6.1392362   -5.44746016
   6.15944102   1.10816864   7.55431925   6.10370138  19.53452819
   4.23379791  10.57112904  -7.17185731 -11.35875497  16.05103477
   4.21067438  -2.19053623 -15.6171106    3.86454679  -5.40985889
  -8.9682956  -11.67192346  14.13626732   3.44945295  11.97704802
  -3.37638741   5.82246938  -5.25608935  12.58771455  -3.39378238
 -12.98533579   0.05242024 -10.21858089   2.02756171   9.06312094
   2.95970804   3.67164268 -18.25075628 -21.07924385 -20.0075
  -3.37720538  15.87640434  18.81288742  13.59049609   5.25595326
 -13.84568056 -15.25104291  -6.96883964  17.00707429  -9.69434137
 -11.4429213   -6.56943047   3.86955881 -35.74887595 -32.71820756
 -36.51189766  10.89956277   4.42374844  -1.07591739  -4.65738772
  -0.55631948  -4.42987538  -1.78459884  -4.92199438  26.09198515]
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2502.2383606429416
gradient value of function right now is: [ 1.46717211e-09 -1.50660959e-08 -6.90081290e-04 -3.40093444e-04
 -1.46717211e-09  1.50633556e-08  6.90081288e-04  3.40093441e-04
 -2.12332757e-09 -3.81169568e-10 -1.14123195e-08 -1.11711020e-08
 -5.65710837e-08 -9.56135857e-09 -1.37783429e-07 -1.79967760e-07
 -3.68360525e-05 -7.49562344e-06 -4.48068843e-04 -3.70382999e-04
 -1.92852337e-03 -3.26383065e-04 -4.84283903e-03 -6.23317131e-03
 -5.15411629e-03 -8.45826710e-04 -2.34626729e-09 -2.42771356e-03
 -1.14581391e-03 -1.82446472e-04 -5.03083316e-10 -5.16567540e-04
  3.82495490e-03  6.22023563e-04  1.72243040e-09  1.77815455e-03
 -2.13098278e-04 -2.76841173e-05 -7.28726595e-11 -7.02208621e-05
  6.02588221e-02  1.80314257e-04  2.09397461e-04  1.68891580e-04
 -8.96595055e-03 -2.58452775e-05 -3.00325891e-05 -2.41951618e-05
 -1.55585323e-08 -4.08383444e-11 -4.75323981e-11 -3.81778943e-11
 -2.97883713e-02 -8.66053621e-05 -1.00622159e-04 -8.10859092e-05
  3.66055231e-04 -4.18980817e-03 -6.96602571e-03  7.97145657e-02
 -8.40103299e-03  9.61242331e-02 -6.06044553e-03  6.93562912e-02
 -2.86848116e+00]
supnorm grad right now is: 2.8684811634872696
Weights right now are: 
[ 4.29281205e+00 -6.34236706e+00  5.91418546e-01 -9.87484793e+00
 -5.08303128e+00  6.35683069e+00 -2.01125007e-02  1.12899310e+01
  8.13490663e+00  2.01598577e+01  4.60299267e+00  1.14256874e+01
 -7.86508259e+00 -1.09854926e+01  1.57615307e+01  4.01986882e+00
 -1.10423475e+00 -1.66137354e+01  4.75189699e+00 -4.47236453e+00
 -1.30696142e+01 -1.23864041e+01  9.80533004e+00 -4.97643279e-01
  8.45111459e+00 -6.45027352e+00  3.95575130e+00 -8.84678923e+00
  1.16607593e+01 -4.08375093e+00 -1.30687224e+01 -1.13048744e+00
 -7.14139033e+00  4.46146230e+00  9.79085827e+00  6.24239548e+00
  3.56022656e+00 -1.79698519e+01 -2.07207126e+01 -2.01745363e+01
  7.52578050e-01  1.97375042e+01  2.26951223e+01  1.73466488e+01
  3.18326624e+00 -1.73697199e+01 -1.86919709e+01 -1.04545066e+01
  1.60895037e+01 -1.06039490e+01 -1.24397334e+01 -7.33571446e+00
  2.23437396e+00 -3.88016124e+01 -3.55490689e+01 -3.97861793e+01
  1.31572106e+01  1.60397728e+00 -4.13111115e+00 -8.98331500e-01
 -3.53870844e+00 -8.36458319e-01 -4.84662082e+00 -9.67474643e-01
  2.47770601e+01]
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2501.2091455115356
gradient value of function right now is: [ 1.90428146e-09  1.70222447e-09  6.20959466e-03 -2.17480846e-06
 -1.90428146e-09 -1.70391617e-09 -6.20959466e-03  2.17480677e-06
 -3.07158770e-09 -4.85523818e-10 -1.45742724e-08 -1.51486755e-08
 -1.13102922e-09 -9.52132054e-11  2.13457469e-08  1.48934443e-08
 -2.60481179e-04 -4.11723517e-05 -1.22507555e-03 -1.27925441e-03
 -1.60495824e-04 -2.25690428e-05  1.38923718e-04 -1.01741525e-04
 -3.09450110e-04 -7.87968709e-05 -2.20511963e-10 -2.85220438e-04
 -2.80064753e-04 -4.22699323e-05 -1.14629536e-10 -1.26831198e-04
  4.63568827e-04  8.69467886e-05  2.39547857e-10  2.86793748e-04
 -2.66231501e-04 -3.32177650e-05 -8.88195835e-11 -8.92214259e-05
  7.39707037e-03  3.29787399e-05  5.91360514e-05  4.11996191e-05
 -1.57889460e-03 -5.20897031e-06 -9.49628399e-06 -6.46872759e-06
 -4.79698534e-09 -1.01311535e-11 -1.90932714e-11 -1.24277333e-11
 -5.28447909e-03 -1.84537981e-05 -3.35542458e-05 -2.29373631e-05
  6.19291525e-05 -7.69465972e-04 -1.38442861e-03  1.69248663e-02
 -2.56979535e-03  3.13286646e-02 -1.60927053e-03  1.96935101e-02
  6.34800812e+00]
supnorm grad right now is: 6.348008120809196
Weights right now are: 
[  4.29077001  -6.34270289   0.62688603  -9.78703515  -5.08098924
   6.35716652  -0.05557998  11.2021182    8.17938572  20.17161141
   4.60477267  11.43280905  -7.86552679 -10.98550072  15.76105068
   4.01952292  -1.17332091 -16.85715727   4.73893184  -4.49503705
 -13.0368617  -12.24531793   9.95295564  -0.41322619   8.47486022
  -6.46624957   3.95216064  -8.88162285  11.73092743  -4.07243626
 -13.06900292  -1.11527331  -7.14063689   4.47607396   9.79277754
   6.27179302   3.55901272 -17.97305278 -20.72172577 -20.17836842
   0.63883565  19.81161459  22.77793711  17.42047491   3.22421077
 -17.43280141 -18.76074881 -10.51703506  16.08570749 -10.6051582
 -12.44116907  -7.33668574   2.24852053 -38.89718279 -35.64778132
 -39.88719818  13.20780039   1.51083037  -4.18866311  -0.83141339
  -3.61302719  -0.73303228  -4.91733379  -0.87201663  25.42050312]
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2502.4085807432684
gradient value of function right now is: [ 3.45158855e-30  6.54299625e-13  6.54299861e-13  6.54299862e-13
 -9.87902323e-30 -1.87219029e-12 -1.87219097e-12 -1.87219097e-12
 -6.50046990e-29 -6.50020110e-29 -1.11551038e-35 -6.50051752e-29
  5.80709053e-18  5.80686469e-18  9.39585653e-25  5.80713314e-18
 -9.71264195e-23 -9.71236661e-23 -9.54568344e-30 -9.71271520e-23
  7.34029910e-23  7.34000873e-23  1.21063987e-29  7.34035290e-23
 -5.66870892e-33  3.35129883e-22  3.35341094e-22  3.35129883e-22
 -2.19531601e-28  2.93493041e-21 -2.37668866e-23  2.93494264e-21
  1.17394162e-30 -1.48074108e-23  1.30746454e-25 -1.48074684e-23
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  2.55488768e-27  1.88030844e-28  2.79977166e-28  1.52126864e-28
  5.18327509e-26  4.96465194e-26  5.03787408e-26  4.66503126e-26
 -2.11510205e-22 -1.08605058e-22 -1.12063040e-22 -1.03946462e-22
 -1.17601870e-29 -1.36950430e-30 -1.78791789e-30 -1.18383459e-30
 -6.80794878e-23 -1.55318386e-22  9.69791839e-23 -3.70775684e-22
  1.16936788e-22 -4.74535816e-22  6.57346886e-23 -2.43816763e-22
 -2.07281064e+00]
supnorm grad right now is: 2.0728106396575945
Weights right now are: 
[ 4.29076916e+00 -6.34412189e+00  5.06885738e-01 -1.04891251e+01
 -5.08098840e+00  6.35858551e+00  6.44203077e-02  1.19042081e+01
  8.17995250e+00  2.01717008e+01  4.60477327e+00  1.14328199e+01
 -7.86676036e+00 -1.09856363e+01  1.57585783e+01  4.01813612e+00
 -8.93963320e-01 -1.63210997e+01  4.77967551e+00 -4.43086277e+00
 -1.37138131e+01 -1.27957648e+01  9.20694873e+00 -1.14123210e+00
  7.77948658e+00 -6.78436769e+00  3.95215091e+00 -9.39995282e+00
  1.12850750e+01 -4.18726095e+00 -1.30690045e+01 -1.39228684e+00
 -6.57805152e+00  4.65968994e+00  9.79278175e+00  6.60840306e+00
  3.56662125e+00 -1.79538739e+01 -2.07217187e+01 -2.01637425e+01
  1.36063019e+00  2.01850377e+01  2.31226578e+01  1.77999021e+01
  2.55013647e+00 -1.77207869e+01 -1.90295683e+01 -1.08007885e+01
  1.60856752e+01 -1.06051619e+01 -1.24411732e+01 -7.33668872e+00
  1.55826642e+00 -3.92736021e+01 -3.59814726e+01 -4.02930332e+01
  1.33589292e+01  1.05302406e+00 -4.89268805e+00 -6.66276921e-03
 -4.27201279e+00  3.28500602e-02 -5.62438455e+00 -6.39481335e-02
  2.50513173e+01]
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2502.4801567222485
gradient value of function right now is: [ 2.28588968e-30  4.33586762e-13  4.33586918e-13  4.33586918e-13
 -3.44004528e-30 -6.52537321e-13 -6.52537557e-13 -6.52537557e-13
 -2.72868923e-29 -2.72867978e-29 -1.26251189e-36 -2.72870558e-29
  2.49309756e-18  2.49308903e-18  1.14989251e-25  2.49311251e-18
 -6.94228095e-23 -6.94224495e-23 -3.76924253e-30 -6.94232275e-23
  1.93671426e-23  1.93670772e-23  8.89076236e-31  1.93672587e-23
 -1.27712127e-37  1.17555301e-22  1.17714435e-22  1.17555301e-22
  1.90318850e-33  2.57529948e-22  2.42514290e-23  2.57529962e-22
 -1.15113339e-35 -1.81211550e-24 -2.14143045e-25 -1.81211558e-24
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -2.06140667e-32 -8.59688953e-33 -9.23245191e-33 -7.88344434e-33
  5.61329028e-29  2.36154533e-29  2.53216669e-29  2.16981894e-29
  2.54539391e-22  1.14832626e-22  1.21739521e-22  1.07017328e-22
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -1.67949573e-23  8.62316082e-22  3.73765506e-23 -1.94863127e-21
  4.44938798e-23 -2.32089228e-21  2.52640815e-23 -1.31620401e-21
 -1.54348461e+00]
supnorm grad right now is: 1.5434846115036367
Weights right now are: 
[ 4.29076916e+00 -6.34412193e+00  5.06884763e-01 -1.04891343e+01
 -5.08098840e+00  6.35858554e+00  6.44212831e-02  1.19042174e+01
  8.17995250e+00  2.01717008e+01  4.60477327e+00  1.14328199e+01
 -7.86676037e+00 -1.09856363e+01  1.57585783e+01  4.01813610e+00
 -8.93961728e-01 -1.63210976e+01  4.77967558e+00 -4.43086258e+00
 -1.37138219e+01 -1.27957721e+01  9.20693860e+00 -1.14124181e+00
  7.77947741e+00 -6.78437171e+00  3.95215091e+00 -9.39995941e+00
  1.12850687e+01 -4.18726248e+00 -1.30690045e+01 -1.39229053e+00
 -6.57804405e+00  4.65969229e+00  9.79278175e+00  6.60840737e+00
  3.56662121e+00 -1.79538740e+01 -2.07217187e+01 -2.01637426e+01
  1.36064064e+00  2.01850424e+01  2.31226622e+01  1.77999068e+01
  2.55012715e+00 -1.77207905e+01 -1.90295717e+01 -1.08007920e+01
  1.60856752e+01 -1.06051619e+01 -1.24411732e+01 -7.33668872e+00
  1.55825697e+00 -3.92736068e+01 -3.59814768e+01 -4.02930383e+01
  1.33589310e+01  1.05301854e+00 -4.89269699e+00 -6.65166348e-03
 -4.27202141e+00  3.28609124e-02 -5.62439364e+00 -6.39368281e-02
  2.50827396e+01]
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2502.560959978528
gradient value of function right now is: [ 1.91431363e-30  3.63190739e-13  3.63190870e-13  3.63190870e-13
  1.20063976e-29  2.27793506e-12  2.27793588e-12  2.27793588e-12
  5.27901985e-29  5.27904855e-29  7.98148556e-38  5.27904900e-29
 -4.39963954e-18 -4.39966355e-18 -5.83480040e-27 -4.39966382e-18
 -1.07415127e-22 -1.07415650e-22 -6.29722209e-31 -1.07415725e-22
 -3.13388321e-23 -3.13390026e-23 -4.60463228e-32 -3.13390051e-23
 -1.21878431e-37 -1.91052676e-22 -1.90654125e-22 -1.91052676e-22
 -3.38928846e-37 -2.94257874e-24 -1.16554009e-24 -2.94257875e-24
  6.56377568e-39  9.19539018e-26  6.87967447e-26  9.19539020e-26
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  4.14802684e-36  2.42261795e-36  2.48040123e-36  2.34559579e-36
 -3.85247996e-32 -2.15459915e-32 -2.22828240e-32 -2.06011628e-32
 -4.86061131e-24 -2.28291233e-24 -2.42263923e-24 -2.10879053e-24
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
  1.78889879e-25 -1.38183176e-23 -6.48010265e-25  4.08707674e-23
 -7.66463181e-25  4.83014933e-23 -4.39911141e-25  2.77916056e-23
  3.90391019e-03]
supnorm grad right now is: 0.0039039101915238988
Weights right now are: 
[ 4.29076916e+00 -6.34412197e+00  5.06884763e-01 -1.04891343e+01
 -5.08098840e+00  6.35858555e+00  6.44212831e-02  1.19042174e+01
  8.17995250e+00  2.01717008e+01  4.60477327e+00  1.14328199e+01
 -7.86676037e+00 -1.09856363e+01  1.57585783e+01  4.01813610e+00
 -8.93961728e-01 -1.63210976e+01  4.77967558e+00 -4.43086258e+00
 -1.37138219e+01 -1.27957721e+01  9.20693860e+00 -1.14124181e+00
  7.77947741e+00 -6.78437171e+00  3.95215091e+00 -9.39995941e+00
  1.12850687e+01 -4.18726248e+00 -1.30690045e+01 -1.39229053e+00
 -6.57804405e+00  4.65969229e+00  9.79278175e+00  6.60840737e+00
  3.56662121e+00 -1.79538740e+01 -2.07217187e+01 -2.01637426e+01
  1.36064064e+00  2.01850424e+01  2.31226622e+01  1.77999068e+01
  2.55012715e+00 -1.77207905e+01 -1.90295717e+01 -1.08007920e+01
  1.60856752e+01 -1.06051619e+01 -1.24411732e+01 -7.33668872e+00
  1.55825697e+00 -3.92736068e+01 -3.59814768e+01 -4.02930383e+01
  1.33589310e+01  1.05301854e+00 -4.89269699e+00 -6.65166348e-03
 -4.27202141e+00  3.28609124e-02 -5.62439364e+00 -6.39368281e-02
  2.49557452e+01]
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2502.560812386088
gradient value of function right now is: [ 1.79593648e-30  3.40743426e-13  3.40743549e-13  3.40743549e-13
 -7.57459032e-30 -1.43713080e-12 -1.43713132e-12 -1.43713132e-12
 -4.61921069e-29 -4.61923514e-29 -7.16592154e-38 -4.61923550e-29
  4.08117744e-18  4.08119904e-18  6.39902183e-27  4.08119936e-18
 -3.73961021e-23 -3.73962973e-23 -9.90210669e-32 -3.73963040e-23
  2.56923542e-23  2.56924902e-23  3.99521677e-32  2.56924922e-23
 -3.65713246e-39  1.72457921e-22  1.72383023e-22  1.72457921e-22
  3.15502608e-37  3.53149002e-24  1.46094963e-24  3.53149003e-24
 -4.35491700e-39 -1.00841278e-25 -6.93193325e-26 -1.00841278e-25
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -3.40155457e-36 -1.67891355e-36 -1.78145806e-36 -1.54488840e-36
  2.54274151e-32  1.24593632e-32  1.32302251e-32  1.14517461e-32
  8.17664608e-24  4.13670119e-24  4.36792009e-24  3.83363148e-24
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -3.94927778e-25  2.42108233e-23  1.13254196e-24 -7.10368699e-23
  1.33272059e-24 -8.35928942e-23  7.73432230e-25 -4.85060848e-23
 -7.80650582e-02]
supnorm grad right now is: 0.07806505820362186
Weights right now are: 
[ 4.29076916e+00 -6.34412202e+00  5.06884763e-01 -1.04891343e+01
 -5.08098840e+00  6.35858557e+00  6.44212832e-02  1.19042174e+01
  8.17995250e+00  2.01717008e+01  4.60477327e+00  1.14328199e+01
 -7.86676037e+00 -1.09856363e+01  1.57585783e+01  4.01813610e+00
 -8.93961728e-01 -1.63210976e+01  4.77967558e+00 -4.43086258e+00
 -1.37138219e+01 -1.27957721e+01  9.20693860e+00 -1.14124181e+00
  7.77947741e+00 -6.78437171e+00  3.95215091e+00 -9.39995941e+00
  1.12850687e+01 -4.18726248e+00 -1.30690045e+01 -1.39229053e+00
 -6.57804405e+00  4.65969229e+00  9.79278175e+00  6.60840737e+00
  3.56662121e+00 -1.79538740e+01 -2.07217187e+01 -2.01637426e+01
  1.36064064e+00  2.01850424e+01  2.31226622e+01  1.77999068e+01
  2.55012715e+00 -1.77207905e+01 -1.90295717e+01 -1.08007920e+01
  1.60856752e+01 -1.06051619e+01 -1.24411732e+01 -7.33668872e+00
  1.55825697e+00 -3.92736068e+01 -3.59814768e+01 -4.02930383e+01
  1.33589310e+01  1.05301854e+00 -4.89269699e+00 -6.65166348e-03
 -4.27202141e+00  3.28609124e-02 -5.62439364e+00 -6.39368281e-02
  2.53430781e+01]
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2502.5560363330515
gradient value of function right now is: [ 1.74141067e-30  3.30402252e-13  3.30402371e-13  3.30402371e-13
 -1.87044209e-29 -3.54883864e-12 -3.54883992e-12 -3.54883992e-12
 -1.02508398e-28 -1.02508936e-28 -9.66259875e-38 -1.02508938e-28
  8.90653804e-18  8.90658474e-18  8.42184669e-27  8.90658491e-18
  8.75926259e-24  8.75930878e-24 -7.63666818e-33  8.75930789e-24
  5.41718406e-23  5.41721247e-23  5.10993806e-32  5.41721257e-23
  1.73048043e-38  3.68749066e-22  3.68474709e-22  3.68749066e-22
  3.75724063e-38  1.90473718e-24  1.32461096e-24  1.90473718e-24
 -8.03645073e-40 -1.32718787e-25 -1.19674852e-25 -1.32718787e-25
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -5.04116401e-37 -2.81512105e-37 -2.94746119e-37 -2.63504190e-37
  6.01636040e-33  3.32216178e-33  3.47701722e-33  3.11099744e-33
  2.46468469e-24  1.24466346e-24  1.31784737e-24  1.14606478e-24
  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00
 -6.90018963e-26  6.10116440e-24  3.13715426e-25 -2.23734450e-23
  3.68440002e-25 -2.62558103e-23  2.14342240e-25 -1.53143926e-23
 -3.90003354e-01]
supnorm grad right now is: 0.3900033544924061
Weights right now are: 
[ 4.29076916e+00 -6.34412208e+00  5.06884762e-01 -1.04891344e+01
 -5.08098840e+00  6.35858560e+00  6.44212833e-02  1.19042174e+01
  8.17995250e+00  2.01717008e+01  4.60477327e+00  1.14328199e+01
 -7.86676037e+00 -1.09856363e+01  1.57585783e+01  4.01813610e+00
 -8.93961728e-01 -1.63210976e+01  4.77967558e+00 -4.43086258e+00
 -1.37138219e+01 -1.27957721e+01  9.20693860e+00 -1.14124181e+00
  7.77947741e+00 -6.78437171e+00  3.95215091e+00 -9.39995941e+00
  1.12850687e+01 -4.18726248e+00 -1.30690045e+01 -1.39229053e+00
 -6.57804405e+00  4.65969229e+00  9.79278175e+00  6.60840737e+00
  3.56662121e+00 -1.79538740e+01 -2.07217187e+01 -2.01637426e+01
  1.36064064e+00  2.01850424e+01  2.31226622e+01  1.77999068e+01
  2.55012715e+00 -1.77207905e+01 -1.90295717e+01 -1.08007920e+01
  1.60856752e+01 -1.06051619e+01 -1.24411732e+01 -7.33668872e+00
  1.55825697e+00 -3.92736068e+01 -3.59814768e+01 -4.02930383e+01
  1.33589310e+01  1.05301854e+00 -4.89269699e+00 -6.65166348e-03
 -4.27202141e+00  3.28609124e-02 -5.62439364e+00 -6.39368281e-02
  2.45092935e+01]
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1550.7177017476208
W_T_median: 1404.9332849243788
W_T_pctile_5: 624.2405424982234
W_T_CVAR_5_pct: 486.6279485535706
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.3
F value: -2502.5560363330515
-----------------------------------------------
