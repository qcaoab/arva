Starting at: 
2022-06-20 18:03:38
tracing parameter entered from terminal:  0.25


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[ 0.10347998  0.18844875 -0.3666709   0.62803316 -0.89369922 -0.17398511
  0.93797695  0.78704989 -0.60791207 -0.16293226 -0.31685198  0.28094308
  0.0404241   0.17453202  0.0940472   0.01169373  0.2300954  -0.23784803
  0.78511084 -0.41859022  0.4809118  -0.01155852  0.07219357 -0.14482284
  0.4701344  -0.18827011 -0.8138637  -0.24629474  0.28361272  0.33354483
 -0.63777411 -0.25343004 -0.81551088 -0.26234589  0.20198453 -0.15135741
  0.25264285 -0.29817275  0.41496663 -0.58895503 -0.60305385 -0.63454123
  0.3979274   0.74701442  0.57452389 -0.67377327  0.6493153   0.07340044
 -0.29694484  0.52758424 -0.14347696  0.04319718 -0.28527617 -0.63077443
  0.13133703 -0.58713125  0.12759166  0.87507529 -0.19770888 -0.66759109
  0.25529887 -0.48501395  0.58877641 -0.72315372] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1260.6521530687958
W_T_median: 1222.3920506735662
W_T_pctile_5: 834.1581876304141
W_T_CVAR_5_pct: 746.6575474940535
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1194.4492779142663
gradient value of function right now is: [ 8.57787260e+00  1.90783386e+00  3.71797468e-01  2.98501117e-01
 -8.57787260e+00 -1.90783386e+00 -3.71797468e-01 -2.98501117e-01
 -8.14896779e-01 -2.68454173e-01 -8.08781165e-01 -5.47081656e-02
 -1.09028475e+00 -3.51824769e-01 -1.08248853e+00 -6.60547090e-02
 -8.53483709e-02 -2.82187259e-02 -8.47025859e-02 -5.82257473e-03
 -1.32484830e-01 -4.31445253e-02 -1.31516508e-01 -8.41890215e-03
 -1.52182626e-02 -1.24065726e-02 -1.38346654e-02 -1.12794994e-02
  5.66925443e-02  4.92293977e-02  5.02388434e-02  4.45580390e-02
 -1.08940446e-02 -8.86618628e-03 -9.92054150e-03 -8.06454868e-03
  1.18519577e-02  9.94119059e-03  1.06069900e-02  9.00872015e-03
 -1.02296255e-02 -8.31797149e-03 -3.93119958e-03 -3.48521496e-03
 -1.36321443e-02 -1.09642103e-02 -3.65239193e-03 -3.18207676e-03
 -7.02380817e-03 -5.82975204e-03 -3.71899948e-03 -3.35192468e-03
 -7.98184513e-03 -6.46905389e-03 -2.45997417e-03 -2.16490941e-03
 -9.99209989e-03  1.87945621e-03 -6.01130993e-03  2.68064070e-03
  1.11003352e-02 -1.95679502e-03  1.23586966e-02 -1.76040641e-03
  6.23396727e+00]
supnorm grad right now is: 8.577872603176667
Weights right now are: 
[ 0.91773846  0.38777817  0.41083191  0.94895734 -1.7079577  -0.37331453
  0.16047413  0.46612571 -1.70290904 -0.76408247 -1.45224926 -0.08919877
  0.59049193  0.6836099   0.55759838  0.23589266  1.33301014  0.35008542
  1.87713319  0.11215444  1.79564585  1.25852774  1.30989026  0.83718327
 -0.56956668 -1.05010051 -1.72864754 -1.04378846  0.54129319  0.67293001
 -0.28321984  0.17785217 -1.69529967 -0.96105483 -0.55516456 -0.78887996
  1.40177373  0.79153962  1.51242222  0.28834368 -1.75245686 -0.91275496
  1.48283672  2.20597103 -0.7719625  -1.09854549  2.07669661  2.04948487
 -1.60421515  0.04330491  1.04425545  1.74202232 -0.81285318 -0.47536795
  2.03243983  1.8185911   0.37140908  3.97482441  0.60460519  1.76510988
  0.5690735  -3.98955202  0.75200979 -4.37832675 30.99713508]
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1195.5720633293108
gradient value of function right now is: [ 3.44892254e+00  1.01130533e-01  1.70913400e-02  1.80571725e-02
 -3.44892254e+00 -1.01130533e-01 -1.70913400e-02 -1.80571725e-02
 -4.63491275e-02 -4.43309964e-02 -4.61232062e-02 -1.11002794e-02
 -2.98603751e-02 -2.86163633e-02 -2.97499845e-02 -3.36456450e-03
 -4.62570592e-03 -4.42472805e-03 -4.60356453e-03 -1.05820805e-03
 -4.61404164e-03 -4.41352286e-03 -4.59358428e-03 -8.27743883e-04
 -1.00960419e-03 -7.31664411e-04 -1.13526560e-03 -7.69395165e-04
  5.20385332e-05  9.93934688e-05  3.80588072e-06  8.83750124e-05
 -8.65987960e-04 -6.28351506e-04 -9.73173392e-04 -6.60603584e-04
  4.12801297e-04  3.14391713e-04  4.46748629e-04  3.26539141e-04
 -1.05479811e-03 -5.42262391e-04 -1.04704769e-03 -1.02264705e-03
 -7.95098523e-04 -4.02419646e-04 -7.34962175e-04 -7.16929309e-04
 -1.25638356e-03 -6.56393442e-04 -1.38011535e-03 -1.34998602e-03
 -7.15891334e-04 -3.64632473e-04 -7.22360366e-04 -7.05317868e-04
 -2.65207469e-03  9.44639765e-05 -4.33781698e-04  3.15967466e-05
  4.66511143e-03 -6.78431703e-05  5.50344374e-03 -6.87991769e-05
  1.26923877e+01]
supnorm grad right now is: 12.692387699846085
Weights right now are: 
[ 0.83996732  0.17810348  0.45537555  0.86084166 -1.63018656 -0.16363984
  0.1159305   0.55424139 -2.26114291 -1.40994791 -2.01277215 -0.09355023
  1.08076232  1.68798836  1.03916075  0.92309376  2.12935762  1.22661573
  2.61072176  0.62751616  2.15489042  1.96871566  1.6548201   1.36968237
 -0.98847863 -1.57198293 -2.14571479 -1.55105149 -0.69270285 -0.75565298
 -1.55974132 -1.20705367 -2.16161009 -1.52916162 -1.03047089 -1.31437627
  2.03559438  1.45855508  2.22240188  0.88448904 -1.94007715 -0.5680725
  2.82657971  3.71235678 -1.24957578 -1.07466774  3.51837364  3.7022733
 -2.10332703  0.0472503   2.5453005   3.42720951 -1.44416084 -0.64801394
  3.50547477  3.51007973  0.8189792   5.62127692  2.11356283  1.10219723
  0.46827741 -5.92400069  0.52344834 -6.11490281 31.04963887]
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1196.327871130069
gradient value of function right now is: [-1.36283298e+00 -4.74627953e-03  1.61029564e-03  3.27796857e-04
  1.36283298e+00  4.74627953e-03 -1.61029564e-03 -3.27796857e-04
  4.83594632e-03  5.28898550e-03  4.92101195e-03 -1.15638980e-02
  8.46650285e-04  8.65372438e-04  8.50026488e-04 -3.63143912e-04
  1.76832181e-05  2.08646981e-05  1.82841825e-05 -8.51105140e-05
  6.17896219e-05  6.51649190e-05  6.24117139e-05 -7.85229774e-05
 -7.42938097e-04 -5.20669262e-04 -7.99696868e-04 -5.54641931e-04
 -3.73612271e-04 -2.35790884e-04 -4.04412066e-04 -2.55365498e-04
 -6.56113740e-04 -4.56721052e-04 -7.06270065e-04 -4.86981041e-04
  1.15956311e-04  8.07531820e-05  1.24706214e-04  8.60814469e-05
 -1.18379454e-03 -7.93383222e-04 -1.14594491e-03 -1.13700966e-03
 -9.16786439e-04 -6.17527754e-04 -8.53602508e-04 -8.45810647e-04
 -1.49308542e-03 -1.00589644e-03 -1.49457069e-03 -1.48358229e-03
 -9.63426836e-04 -6.48014467e-04 -9.03963993e-04 -8.95807731e-04
 -1.99439109e-03 -1.41542008e-04 -2.74674254e-04 -2.46420095e-05
  3.10727332e-03  2.58024299e-04  3.69999611e-03  3.17069858e-04
  1.80004958e+00]
supnorm grad right now is: 1.8000495837057786
Weights right now are: 
[ 0.78534312  0.05826476  0.31074525  0.7399781  -1.57556235 -0.04380112
  0.26056079  0.67510495 -2.11946728 -1.20773214 -1.86983737  0.25633829
  1.25802389  2.21328197  1.21525644  1.11786271  2.22203962  1.34990395
  2.69728433  0.71724166  2.26648669  2.27496177  1.76352407  1.57099414
 -1.10263921 -1.68242678 -2.2882844  -1.67110706 -0.94301053 -1.00238737
 -1.85419304 -1.47334013 -2.27753619 -1.64080902 -1.17528369 -1.42973204
  2.04051475  1.45646103  2.23637698  0.88676357 -2.1582146  -0.41450737
  2.83711208  3.75213186 -1.44923588 -0.94250157  3.4504791   3.66021787
 -2.32659321  0.19651003  2.6218578   3.5357866  -1.68343222 -0.52793375
  3.43738624  3.46929893 -0.25322697  5.8462522   1.74559559  1.16696115
  1.15459176 -6.16694325  1.2093013  -6.39405937 30.93469179]
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1195.8952428771026
gradient value of function right now is: [ 4.54557158e+00  1.63744806e-02  3.21827258e-03  2.78738126e-03
 -4.54557158e+00 -1.63744806e-02 -3.21827258e-03 -2.78738126e-03
 -2.15857031e-02 -2.15353019e-02 -2.15209126e-02 -7.51375261e-03
 -3.01026423e-03 -3.00460627e-03 -3.00357937e-03 -4.62762038e-04
 -7.76203637e-04 -7.74397873e-04 -7.73897510e-04 -2.54538915e-04
 -6.19930292e-04 -6.18578593e-04 -6.18254448e-04 -1.53118392e-04
 -4.91156848e-04 -3.66456249e-04 -5.80242438e-04 -3.99349990e-04
 -2.71398566e-04 -2.01991925e-04 -3.21347487e-04 -2.20198112e-04
 -4.53984982e-04 -3.39474616e-04 -5.35477038e-04 -3.69773301e-04
  1.26365866e-04  9.44379062e-05  1.48948062e-04  1.02927603e-04
 -9.13887342e-04 -2.48466248e-04 -7.46137069e-04 -7.41355466e-04
 -7.42605081e-04 -2.01533444e-04 -5.76774682e-04 -5.72671783e-04
 -1.14855103e-03 -3.14081118e-04 -9.76916627e-04 -9.71320899e-04
 -7.72447242e-04 -2.07878325e-04 -6.09094451e-04 -6.04870238e-04
 -2.59453000e-03 -5.42654588e-06 -1.91607366e-06  3.12257801e-06
  5.45030725e-03  7.95886775e-05  6.29649382e-03  9.70032261e-05
  3.67516254e+00]
supnorm grad right now is: 4.545571578295094
Weights right now are: 
[ 0.8467386   0.11373567  0.44807745  0.8475753  -1.63695783 -0.09927203
  0.12322859  0.56750775 -2.69488402 -1.75084648 -2.44763699  0.38269578
  1.52864419  2.97242584  1.48314523  1.66782756  2.81142677  2.04931988
  3.25710999  1.18830235  2.67898713  3.17886728  2.16456102  2.17573262
 -1.44367654 -2.11623853 -2.56368525 -2.0844977  -1.56360497 -1.76462791
 -2.39900668 -2.2061176  -2.63256587 -2.08942576 -1.46810956 -1.85936515
  2.56070269  2.04717127  2.72103368  1.45966342 -1.83937983  0.04156585
  3.74162277  4.70722417 -1.31559508 -0.70549125  4.40682558  4.67165649
 -2.0666752   0.56993797  3.49808673  4.46073902 -1.53839654 -0.29067294
  4.41449765  4.50060837  0.38903195  6.6305965   2.9665124  -0.11614227
  0.90283548 -7.01732766  0.92027192 -7.26559218 31.03738813]
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1196.3071893350811
gradient value of function right now is: [-1.79481634e+00  2.00836548e-03  1.55498582e-03  8.12121467e-04
  1.79481634e+00 -2.00836548e-03 -1.55498582e-03 -8.12121467e-04
 -1.52736889e-02 -1.52821373e-02 -1.52775855e-02 -2.05324254e-02
  1.24744263e-05  1.34695388e-05  1.29018641e-05  1.09396797e-04
  6.41006479e-06  6.40036591e-06  6.40600654e-06  7.34624464e-06
  8.22757582e-06  8.25256564e-06  8.23942219e-06  1.31681148e-05
  5.77232635e-05  1.84507686e-05  5.61220457e-05  7.72417216e-05
  1.34015084e-04  1.03687908e-04  1.35891516e-04  1.44522244e-04
  1.01718374e-04  6.26724663e-05  1.02369166e-04  1.17814762e-04
  2.33039014e-05  2.42242231e-05  2.44345465e-05  2.12472479e-05
 -1.05977146e-03 -1.23452458e-03 -5.79095220e-04 -5.63862464e-04
 -1.12894355e-03 -1.33378207e-03 -6.34439927e-04 -6.16691622e-04
 -1.28305879e-03 -1.43348033e-03 -6.68518313e-04 -6.51522598e-04
 -1.04828084e-03 -1.31090550e-03 -6.21907428e-04 -6.05095420e-04
  3.93556332e-04 -6.41767892e-05 -4.80313610e-06 -4.91459055e-04
 -2.55395259e-03 -2.47450121e-03 -2.56825905e-03 -2.73193836e-03
 -3.28567479e+00]
supnorm grad right now is: 3.2856747887072126
Weights right now are: 
[ 7.60342903e-01 -1.87127184e-02  2.88313936e-01  6.99246390e-01
 -1.55056214e+00  3.31763564e-02  2.82992110e-01  7.15836658e-01
 -2.72015032e+00 -1.75904347e+00 -2.47803674e+00  1.85843971e-01
  1.92979046e+00  3.77477299e+00  1.88139871e+00  2.55918517e+00
  3.34903109e+00  2.67530258e+00  3.76977349e+00  1.76243281e+00
  3.10252841e+00  3.97881348e+00  2.57676314e+00  3.01347478e+00
 -7.82713703e-01 -1.55565201e+00 -1.75914753e+00 -1.50578701e+00
 -8.75504476e-01 -1.19855520e+00 -1.57751547e+00 -1.61332195e+00
 -1.98115277e+00 -1.54158899e+00 -6.70575813e-01 -1.30544809e+00
  1.96008935e+00  1.56817909e+00  2.01594406e+00  9.91478082e-01
 -3.35272452e-01  1.43427871e+00  6.00728421e+00  7.00966884e+00
 -2.00544442e-02  5.33790180e-01  6.90102924e+00  7.21501892e+00
 -5.20936839e-01  1.97867804e+00  5.59595615e+00  6.59161602e+00
 -1.86610777e-01  9.80875555e-01  6.84582663e+00  6.97821669e+00
  2.46239177e+00  4.15102393e+00  2.73668628e+00 -8.84261720e-02
 -4.49511028e-01 -5.54075977e+00 -4.50142864e-01 -5.71042489e+00
  3.09470913e+01]
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1195.0750171294178
gradient value of function right now is: [ 5.08432485e+00  7.51082770e-03  3.43366874e-03  2.03361141e-03
 -5.08432485e+00 -7.51082770e-03 -3.43366874e-03 -2.03361141e-03
 -2.21330982e-01 -2.20221675e-01 -2.20532884e-01 -1.21885049e-01
  3.05948318e-03  3.04324912e-03  3.04823860e-03  1.56509086e-03
  1.95337963e-03  1.94492494e-03  1.94671048e-03  1.25537317e-03
  8.69765715e-04  8.65569700e-04  8.66654835e-04  5.06913057e-04
 -1.02795213e-02 -9.11680358e-03 -1.13220751e-02 -9.39127046e-03
 -6.21405071e-03 -5.52131274e-03 -6.83450810e-03 -5.68623761e-03
 -9.29354845e-03 -8.24646069e-03 -1.02316423e-02 -8.49455396e-03
  4.24471184e-03  3.73591453e-03  4.70311641e-03  3.85210184e-03
 -1.60191730e-02 -7.58294271e-03 -5.87790988e-03 -5.70837206e-03
 -1.61504912e-02 -7.62040957e-03 -5.32579981e-03 -5.16433897e-03
 -1.78681745e-02 -8.49300620e-03 -7.06159894e-03 -6.86541373e-03
 -1.58097028e-02 -7.44205849e-03 -5.32782629e-03 -5.16783544e-03
 -3.74511836e-03  3.40597757e-03  1.47271263e-02 -1.73179184e-02
  6.76787015e-02 -4.02458977e-02  7.25400733e-02 -4.27209062e-02
 -1.45791419e+01]
supnorm grad right now is: 14.579141910909433
Weights right now are: 
[ 0.86456847 -0.31186299 -0.19471739  0.35908392 -1.65478771  0.32632663
  0.76602343  1.05599912 -2.20577229 -1.2363819  -1.95953477  1.13816181
  2.08224949  4.0524982   2.03161298  2.53866736  3.3887555   2.72094694
  3.8057491   1.66877991  3.19381222  4.13971704  2.66460252  2.94775097
 -1.20607423 -1.98283188 -2.18611348 -1.95027839 -1.31784825 -1.65033765
 -2.01821948 -2.08114979 -2.40848942 -1.97469969 -1.10005266 -1.7551392
  2.44977832  2.03667947  2.5460974   1.47908258 -0.30739381  2.07102995
  6.52874004  7.54348111 -0.03256283  1.0985493   7.70523372  8.04512505
 -0.47122207  2.65928939  5.94318294  6.94482365 -0.20927172  1.55703765
  7.59340648  7.74818799  2.99632204  1.90508429  3.57537736 -0.47948459
  0.37148243 -5.37944325  0.37327005 -5.49656297 30.81551525]
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -1193.7535897190296
gradient value of function right now is: [-1.65684090e+01 -4.10715843e-03 -9.80969112e-04 -6.93214863e-04
  1.65684090e+01  4.10715843e-03  9.80969112e-04  6.93214863e-04
  4.81721111e-01  4.77976847e-01  4.80183272e-01  2.46886861e-01
 -9.79192057e-04 -9.71967743e-04 -9.76073549e-04 -5.33478041e-04
 -2.64421543e-05 -2.63271278e-05 -2.63677590e-05 -2.02867268e-05
 -5.09952915e-05 -5.07084288e-05 -5.08406237e-05 -3.45319844e-05
  1.84576804e-02  1.71821133e-02  1.98696439e-02  1.71718027e-02
  1.10597890e-02  1.03820650e-02  1.18399493e-02  1.03562384e-02
  1.66622195e-02  1.55263115e-02  1.79223128e-02  1.55136222e-02
 -7.77838546e-03 -7.20546008e-03 -8.40362875e-03 -7.20890436e-03
  7.56364575e-03  5.59337252e-03  6.54891887e-03  6.53150781e-03
  9.26357562e-03  6.53591618e-03  5.64815839e-03  5.62177409e-03
  7.17882666e-03  5.48746256e-03  7.92740960e-03  7.91739694e-03
  8.94244008e-03  6.39468093e-03  5.67373555e-03  5.64766947e-03
 -2.16971107e-03  3.43402742e-03 -2.86632323e-02  3.66091990e-02
 -1.73135455e-01  6.55489148e-02 -1.87013265e-01  6.99110666e-02
  1.10741461e+01]
supnorm grad right now is: 16.56840899428334
Weights right now are: 
[ 0.63156874 -0.18116768  0.25910698  0.64325042 -1.42178798  0.19563132
  0.31219906  0.77183263 -2.19083911 -1.21582579 -1.94497115  1.00593799
  2.65591998  4.80361253  2.6028348   3.53412636  4.38301662  3.72623691
  4.79660798  2.86267244  4.03262656  5.07022108  3.49715776  4.11734512
 -1.33413002 -2.31081409 -2.16970715 -2.24758448 -1.3854188  -1.97989112
 -1.89833314 -2.3718979  -2.52729687 -2.30313811 -1.06787363 -2.05151685
  2.43878986  2.01708729  2.5594168   1.44671688  0.18245796  2.58851537
  7.97506769  9.03083515  0.2847926   1.42201038  9.42499374  9.81873697
  0.0810054   3.27597237  7.25104439  8.28719146  0.15526092  1.92992463
  9.34231296  9.54806576  4.05297601  0.21479252  3.41745074 -0.74259058
  0.36025333 -5.13000907  0.33951604 -5.19639002 30.96454682]
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1196.1660635891412
gradient value of function right now is: [-1.19059885e+00  4.31093092e-04  1.91486099e-04  1.13149293e-04
  1.19059885e+00 -4.31093092e-04 -1.91486099e-04 -1.13149293e-04
 -4.00200428e-02 -4.00298936e-02 -4.00414353e-02 -4.86887580e-02
  7.35933065e-05  7.36026119e-05  7.36313253e-05  8.73236853e-05
  2.27420617e-05  2.27073229e-05  2.27376641e-05  2.11096385e-05
  1.46060428e-05  1.45891275e-05  1.46059310e-05  1.45133242e-05
  8.91591233e-05  3.00294397e-05  1.30432576e-04  8.70441052e-05
  9.90700951e-05  6.50145568e-05  1.23935747e-04  9.86318964e-05
  9.99467630e-05  4.48812268e-05  1.38639910e-04  9.64178391e-05
 -5.97834135e-05 -4.47011914e-05 -7.13077232e-05 -6.17161724e-05
 -1.90691122e-03 -1.94605758e-03 -7.40556655e-04 -7.24522722e-04
 -2.20703785e-03 -2.24217707e-03 -1.02152386e-03 -1.00538120e-03
 -2.00975801e-03 -2.05472678e-03 -6.28397422e-04 -6.09369699e-04
 -2.03173219e-03 -2.06694244e-03 -9.12511845e-04 -8.97138574e-04
  4.15354335e-04 -7.12756596e-04  1.84284201e-03 -4.45412950e-03
 -1.09546464e-02 -1.15390072e-02 -1.20268261e-02 -1.22100927e-02
  9.83660554e+00]
supnorm grad right now is: 9.836605535940896
Weights right now are: 
[ 0.83181015 -0.17461794  0.17496821  0.5826543  -1.62202938  0.18908158
  0.39633784  0.83242875 -2.50558299 -1.52595455 -2.2592347   0.80740445
  2.8703065   5.09298096  2.81629747  3.81045584  4.49609496  3.84210249
  4.90898273  2.98305329  4.16961799  5.23113708  3.63298985  4.28587082
 -1.69417626 -2.77342929 -2.48762881 -2.70353006 -1.78811816 -2.50147677
 -2.25018011 -2.88508741 -2.89580559 -2.77609191 -1.39314975 -2.51773783
  2.6526746   2.27611689  2.75720068  1.70175916  0.5797894   3.46926596
  8.96661201 10.02042865  0.46439806  2.06075295 10.87962288 11.28323056
  0.60365544  4.29040819  7.92546348  8.95318943  0.35631498  2.61026668
 10.69226319 10.90445488  4.49319137 -0.93599674  3.52311892 -1.32627723
  0.79423409 -4.51657715  0.77644626 -4.55499334 31.02687782]
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1195.6045018757136
gradient value of function right now is: [-1.18096353e+00  1.93234439e-04  2.61853306e-04  7.20910393e-05
  1.18096353e+00 -1.93234439e-04 -2.61853306e-04 -7.20910393e-05
 -2.57639840e-02 -2.55441580e-02 -2.56957549e-02 -2.11664518e-02
  8.41749291e-05  8.34358308e-05  8.39473682e-05  6.76905699e-05
  2.16338651e-04  2.14812425e-04  2.15849537e-04  1.73519378e-04
  3.82045033e-05  3.79146867e-05  3.81130691e-05  3.03899138e-05
 -6.77716295e-04 -5.99810597e-04 -7.75255186e-04 -5.94005180e-04
 -4.54020168e-04 -4.00554798e-04 -5.20259439e-04 -3.96839137e-04
 -6.22708780e-04 -5.50878125e-04 -7.12453844e-04 -5.45604766e-04
  2.31717586e-04  2.05708847e-04  2.64702938e-04  2.03605023e-04
 -1.16722501e-03 -1.21854894e-03 -8.45084902e-04 -8.42498102e-04
 -1.20413265e-03 -1.25225963e-03 -7.90545204e-04 -7.86776278e-04
 -1.28547698e-03 -1.34555040e-03 -9.99990882e-04 -9.98159170e-04
 -1.16474072e-03 -1.21236446e-03 -7.80093431e-04 -7.76643409e-04
  6.90937444e-04 -1.11010421e-03  3.33131250e-03 -5.20269226e-03
  7.27370872e-03 -7.46370172e-03  7.83950042e-03 -7.90945697e-03
  1.47945224e+01]
supnorm grad right now is: 14.79452238229756
Weights right now are: 
[ 0.79908207 -0.3851885  -0.45468593  0.23302012 -1.58930131  0.39965214
  1.02599197  1.18206293 -2.89268258 -1.90333842 -2.64007158  1.05951327
  3.3005149   5.60335083  3.24252209  3.7582682   4.30683583  3.64342155
  4.71896527  2.45376238  4.39279372  5.46230841  3.85259382  4.05015847
 -3.11004763 -4.11584701 -3.9828174  -4.08111537 -3.01248109 -3.7297082
 -3.5003801  -4.13421804 -4.28832681 -4.10585059 -2.85655801 -3.88088137
  4.5309734   3.83756496  4.88912397  3.33551081  1.05990018  4.54908954
  8.79478432  9.83669525  0.6300091   2.75119185 11.32938161 11.72468377
  1.283956    5.60458839  7.35599434  8.37142993  0.58096467  3.36386318
 11.02260286 11.22571408  4.56212813 -1.88812256  4.32385247 -1.87081242
  3.12482585 -4.35940594  3.10598441 -4.39365751 31.04226461]
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1196.6439898253982
gradient value of function right now is: [-5.71397604e-01  1.86801458e-04  2.51657037e-02  2.27929118e-04
  5.71397604e-01 -1.86801458e-04 -2.51657037e-02 -2.27929118e-04
 -1.52909188e-01 -1.50910446e-01 -1.52838956e-01 -1.30135522e-01
  3.84469099e-05  3.80564538e-05  3.84310349e-05  3.15647223e-05
  6.32800183e-02  6.25854781e-02  6.32532838e-02  5.34589284e-02
  1.54356026e-04  1.52745952e-04  1.54291822e-04  1.26638183e-04
 -3.73303798e-03 -3.17447432e-03 -4.38308614e-03 -3.14789551e-03
 -2.36020772e-03 -2.00447428e-03 -2.77373446e-03 -1.98737906e-03
 -3.60736360e-03 -3.06665786e-03 -4.23655780e-03 -3.04111541e-03
  2.68327963e-03  2.27821141e-03  3.15559235e-03  2.25937963e-03
 -4.08350608e-03 -4.95967413e-03 -5.09373491e-03 -5.10795444e-03
 -4.12654423e-03 -4.99709880e-03 -5.02917610e-03 -5.04336590e-03
 -4.59289889e-03 -5.58244169e-03 -5.76932625e-03 -5.78514539e-03
 -3.89395213e-03 -4.72133907e-03 -4.77365272e-03 -4.78714758e-03
  4.27515471e-03 -5.94031423e-03  1.84278171e-02 -2.50112641e-02
  4.87471874e-02 -6.15718941e-02  5.19001829e-02 -6.55433459e-02
  5.88500884e+00]
supnorm grad right now is: 5.885008840989938
Weights right now are: 
[ 0.7790577  -0.18114229 -2.1160468   0.08540833 -1.56927694  0.19560593
  2.68735285  1.32967472 -2.26717015 -1.27416076 -2.01298415  2.25796068
  3.68917292  5.89367404  3.62605918  3.63298541  2.63452676  1.95902268
  3.05031233 -0.69219184  4.13909622  5.14157251  3.5979282   3.58165222
 -3.02275243 -4.46095353 -3.71157143 -4.33844631 -2.72369696 -3.91949519
 -3.00621069 -4.22966248 -4.26262872 -4.52420212 -2.64900247 -4.21127922
  4.93510856  4.62768832  5.10612967  4.04458825  1.52657278  4.98010148
 10.21110555 11.24604649  0.56444415  2.65246667 12.8020586  13.20483135
  2.13729501  6.41068513  8.56337621  9.56595581  0.63321788  3.3837571
 12.5489443  12.75623353  4.41309482 -3.79802216  3.84831766 -3.51981898
  2.35893297 -4.58437797  2.35258372 -4.57927399 31.01239062]
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1198.5648178685065
gradient value of function right now is: [ 1.36019727e+00 -8.62429130e-05 -1.80517398e-02 -1.28328077e-04
 -1.36019727e+00  8.62429130e-05  1.80517398e-02  1.28328077e-04
  7.09249968e-02  6.70541017e-02  7.13695490e-02  1.74917730e-01
 -5.65713233e-05 -5.55603610e-05 -5.64539683e-05 -3.90479189e-05
 -5.38412374e-02 -5.27589503e-02 -5.37563394e-02 -4.21583028e-02
 -1.51772703e-04 -1.49049353e-04 -1.51481370e-04 -1.07335308e-04
  6.53935002e-03  5.76318229e-03  8.67132083e-03  5.57298723e-03
  2.90826527e-03  2.48565236e-03  3.96274799e-03  2.40912725e-03
  6.01295402e-03  5.20958320e-03  8.09950231e-03  5.04782002e-03
 -9.83694229e-03 -8.77567636e-03 -1.29205980e-02 -8.48131049e-03
  9.87920680e-03  1.21104019e-02  9.29336678e-03  9.46191952e-03
  8.79034482e-03  1.08331738e-02  7.52643648e-03  7.70649824e-03
  1.41057316e-02  1.73193983e-02  1.52988817e-02  1.54806203e-02
  8.02842667e-03  9.88360983e-03  6.86239882e-03  7.02548534e-03
  6.75930269e-03  7.26611428e-02  2.80722203e-02  2.02696057e-01
  1.29442682e-01  3.40399656e-01  1.35928340e-01  3.67545466e-01
 -2.09488439e+00]
supnorm grad right now is: 2.09488438534963
Weights right now are: 
[ 0.92799705 -0.55023327 -2.48988182 -0.31308464 -1.71821629  0.56469691
  3.06118787  1.72816769 -1.51444242 -0.51656413 -1.26135117  3.09883205
  3.62293428  5.82681558  3.55948378  3.55886044  2.35320395  1.67526446
  2.76792981 -1.01547172  3.98556601  4.98710096  3.44376477  3.41549233
 -2.39253864 -3.8564517  -3.29722664 -3.72356711 -2.22962242 -3.46090391
 -2.69632279 -3.76640544 -3.71406776 -3.96620168 -2.32840722 -3.64908302
  4.07298576  3.71965458  4.5451023   3.12270794  2.74738702  6.0773927
 10.835553   11.87907891  1.65944869  3.70946565 14.00605324 14.41323275
  3.41062069  7.41489357  8.56133746  9.57640167  1.75422937  4.45951124
 13.6947716  13.90677271  4.05654322 -3.32960174  3.55251914 -2.97651681
  2.55971646 -3.09640998  2.56872255 -3.07636481 30.87325238]
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1196.216877522428
gradient value of function right now is: [ 3.45347625e+00  1.32606424e-04  2.15240463e-02  1.51495095e-04
 -3.45347625e+00 -1.32606424e-04 -2.15240463e-02 -1.51495095e-04
 -1.12574061e+00 -1.06995024e+00 -1.12311675e+00 -4.04977031e-01
  8.17148424e-05  7.91120062e-05  8.15925940e-05  5.30028182e-05
  6.08953094e-02  5.90983377e-02  6.08157739e-02  4.04662643e-02
  1.44689529e-04  1.40071133e-04  1.44473023e-04  9.36193416e-05
 -2.39210065e-02 -1.75854816e-02 -3.19204327e-02 -1.77567966e-02
 -8.32231724e-03 -6.13196894e-03 -1.10626479e-02 -6.19402547e-03
 -2.02176202e-02 -1.48660063e-02 -2.69696222e-02 -1.50093102e-02
  4.38428279e-02  3.20537262e-02  5.89235753e-02  3.23358181e-02
 -1.28535890e-02 -1.93126082e-02 -2.77020260e-02 -2.77907612e-02
 -1.05033587e-02 -1.59268086e-02 -2.33853492e-02 -2.34382132e-02
 -1.79958000e-02 -2.67173619e-02 -3.70797385e-02 -3.72517511e-02
 -9.65380712e-03 -1.46503480e-02 -2.15351636e-02 -2.15836690e-02
  2.71477791e-02 -5.47831124e-02  1.00306681e-01 -1.85206195e-01
  3.33930011e-01 -5.02952791e-01  3.54127646e-01 -5.38275546e-01
 -2.10314430e+01]
supnorm grad right now is: 21.031443044284995
Weights right now are: 
[ 0.91593937 -0.50472668 -2.1511051  -0.0909438  -1.7061586   0.51919032
  2.72241115  1.50602685 -1.39267028 -0.381138   -1.14239427  3.56271514
  3.97948934  6.18315615  3.91557516  3.90152832  2.84693504  2.16652412
  3.26077738 -0.6229392   4.46634168  5.4671451   3.9237989   3.85986227
 -2.50022127 -4.08584144 -3.34479632 -3.9475496  -1.82467474 -3.23833475
 -2.18744228 -3.53509547 -3.76524931 -4.12029131 -2.34178232 -3.79853216
  4.72994686  4.41390198  5.2111125   3.81734213  2.56386543  5.90523165
 10.71803288 11.75674629  1.51784224  3.5745252  14.04710061 14.44423223
  3.13216397  7.14661353  8.23838156  9.25329274  1.66422464  4.37844963
 13.78070321 13.98309577  4.21467845 -4.45568859  3.51008311 -3.90123519
  2.53844219 -3.62866901  2.55323911 -3.61136495 30.71580345]
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1196.8085158596696
gradient value of function right now is: [ 2.04488123e+00  1.06290693e-04  1.35841791e-02  1.28791989e-04
 -2.04488123e+00 -1.06290693e-04 -1.35841791e-02 -1.28791989e-04
 -9.09383275e-01 -8.76260373e-01 -9.03684724e-01 -6.74071894e-01
 -3.03558152e-06 -2.95482388e-06 -3.02145758e-06 -2.42668577e-06
  2.63535013e-02  2.57315598e-02  2.62408982e-02  2.17243576e-02
  3.57815100e-05  3.48299118e-05  3.56149986e-05  2.86151085e-05
 -1.38270765e-02 -8.38368205e-03 -2.36350474e-02 -8.45761366e-03
 -5.54782451e-03 -3.20591060e-03 -9.78237637e-03 -3.23965364e-03
 -1.20883592e-02 -7.32429875e-03 -2.06671170e-02 -7.38941648e-03
  2.29446644e-02  1.40968072e-02  3.90328745e-02  1.42066041e-02
 -9.51532484e-03 -1.40670041e-02 -2.04699821e-02 -2.04664365e-02
 -6.65805740e-03 -9.92560609e-03 -1.46276203e-02 -1.46199257e-02
 -1.76288177e-02 -2.57087413e-02 -3.67782830e-02 -3.67834197e-02
 -6.17497045e-03 -9.21094528e-03 -1.35950536e-02 -1.35870323e-02
  2.95840226e-02 -4.27108626e-02  9.41883675e-02 -1.28798873e-01
  2.60153458e-01 -3.08982563e-01  2.77542040e-01 -3.31783686e-01
 -1.68192082e+01]
supnorm grad right now is: 16.819208150201852
Weights right now are: 
[ 7.97728470e-01  2.87246850e-02 -1.52292818e+00  4.48603605e-01
 -1.58794771e+00 -1.42610470e-02  2.09423423e+00  9.66479443e-01
 -1.71856782e+00 -6.71063629e-01 -1.46826767e+00  3.24544973e+00
  4.44608387e+00  6.64788343e+00  4.38156469e+00  4.37012011e+00
  3.43278953e+00  2.74747279e+00  3.84501233e+00 -4.78716236e-02
  4.90255868e+00  5.90094712e+00  4.35898414e+00  4.29362490e+00
 -2.54869725e+00 -4.26695736e+00 -3.37900356e+00 -4.13042128e+00
 -1.65905964e+00 -3.26038031e+00 -1.93305807e+00 -3.55847153e+00
 -3.75670320e+00 -4.23938901e+00 -2.32528899e+00 -3.91994749e+00
  4.59952769e+00  4.27230876e+00  5.21424666e+00  3.68187120e+00
  3.06579454e+00  6.35291346e+00  1.10036761e+01  1.20480234e+01
  2.24314208e+00  4.22864659e+00  1.46016414e+01  1.49997150e+01
  3.25116050e+00  7.22491241e+00  8.11409457e+00  9.13805890e+00
  2.41227614e+00  5.05050516e+00  1.43418937e+01  1.45455453e+01
  4.32086978e+00 -4.20806386e+00  3.63325392e+00 -3.62834337e+00
  2.68552728e+00 -3.28706940e+00  2.70425200e+00 -3.27201655e+00
  3.07794021e+01]
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -1195.7086264275679
gradient value of function right now is: [ 8.31372350e+00  2.65384052e-05  3.56920754e-03  3.32319645e-05
 -8.31372350e+00 -2.65384052e-05 -3.56920754e-03 -3.32319645e-05
 -8.79747535e-01 -8.46232728e-01 -8.73094090e-01 -4.25578751e-01
 -3.89279647e-06 -3.76902596e-06 -3.86267493e-06 -2.83300018e-06
  6.08994158e-03  5.91173560e-03  6.04621812e-03  4.48245775e-03
  2.73988772e-06  2.65277562e-06  2.71874350e-06  1.98742596e-06
 -1.28487750e-02 -7.62894795e-03 -2.42707721e-02 -7.68307788e-03
 -7.01367184e-03 -4.39007120e-03 -1.25459051e-02 -4.42348530e-03
 -1.14901596e-02 -6.84639031e-03 -2.16090443e-02 -6.89557463e-03
  1.86887724e-02  1.07684656e-02  3.65339661e-02  1.08378903e-02
 -7.36069600e-03 -1.10692580e-02 -1.69880923e-02 -1.69221179e-02
 -4.76589744e-03 -7.28628160e-03 -1.14260989e-02 -1.13769348e-02
 -1.66202719e-02 -2.44516586e-02 -3.65603316e-02 -3.64333497e-02
 -4.45193839e-03 -6.81431535e-03 -1.07094520e-02 -1.06625301e-02
  2.54209054e-02 -3.73532736e-02  8.14133088e-02 -1.12423356e-01
  2.29737504e-01 -2.67402022e-01  2.44922043e-01 -2.87661030e-01
 -1.97723204e+00]
supnorm grad right now is: 8.313723500035064
Weights right now are: 
[ 0.9716207   0.13824479 -1.22093095  0.63681073 -1.76183994 -0.12378115
  1.792237    0.77827232 -1.89835656 -0.8132178  -1.64522212  3.33938422
  4.87591976  7.07481892  4.80962944  4.78444136  3.86388137  3.16667288
  4.27185715  0.28718932  5.32549638  6.31821523  4.77922528  4.67624821
 -2.78102806 -4.63925037 -3.63922061 -4.50215389 -1.94503201 -3.83184682
 -2.05349483 -4.12203837 -3.97529791 -4.60955144 -2.56114273 -4.2891166
  4.61226143  4.22689725  5.46220751  3.64294296  3.2857786   6.52121983
 11.07165576 12.11952852  2.79850732  4.6978525  14.99080734 15.38831143
  2.958835    6.88796706  7.6611664   8.69075999  2.98727805  5.53525816
 14.74164205 14.94481831  4.47269254 -4.28447672  3.7506983  -3.69810581
  2.75651387 -3.26332697  2.78061197 -3.25443596 30.89367405]
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1197.5975872833906
gradient value of function right now is: [ 5.01424606e+00  1.44537216e-05  2.75152503e-03  2.01125438e-05
 -5.01424606e+00 -1.44537216e-05 -2.75152503e-03 -2.01125438e-05
 -1.13349750e+00 -1.09392060e+00 -1.12087021e+00 -5.39260389e-01
  8.69994977e-07  8.48875565e-07  8.62018593e-07  6.73296408e-07
  4.52989400e-03  4.42767600e-03  4.49123292e-03  3.54669593e-03
  4.13230387e-06  4.03139272e-06  4.09431087e-06  3.18555631e-06
 -1.44939942e-02 -7.70873797e-03 -3.34389260e-02 -7.75463632e-03
 -5.12919109e-03 -2.78053384e-03 -1.15478477e-02 -2.79868059e-03
 -1.26263503e-02 -6.73611538e-03 -2.89873491e-02 -6.77694412e-03
  2.99116278e-02  1.56172366e-02  7.08943262e-02  1.57006592e-02
 -9.83792486e-03 -1.46389226e-02 -2.30925699e-02 -2.29062636e-02
 -5.72741284e-03 -8.62610581e-03 -1.39120034e-02 -1.37852029e-02
 -2.81484144e-02 -4.09704501e-02 -6.25814255e-02 -6.21500044e-02
 -5.29161127e-03 -7.97366207e-03 -1.28753385e-02 -1.27570980e-02
  3.69804222e-02 -5.69420709e-02  1.12529789e-01 -1.71032232e-01
  2.90514335e-01 -3.87049372e-01  3.11056909e-01 -4.19250220e-01
 -8.05994304e+00]
supnorm grad right now is: 8.059943040676263
Weights right now are: 
[ 0.8887997  -0.04700421 -1.20594138  0.52257138 -1.67901894  0.06146785
  1.77724743  0.89251166 -1.62489683 -0.48934574 -1.36274023  3.9939665
  5.20185105  7.3991955   5.13462485  5.10670572  4.04078478  3.33342238
  4.44429014  0.40120522  5.60358173  6.59259909  5.05535292  4.93696675
 -2.90966588 -5.00087932 -3.8083876  -4.86069282 -2.4095819  -4.70272116
 -2.21871386 -4.98922384 -4.11810733 -5.01647597 -2.7052338  -4.69241548
  4.5690311   4.16888562  5.77421158  3.58458568  3.60940183  6.78039578
 11.15064995 12.20925202  3.42752452  5.21815432 15.42843186 15.82431319
  2.68236151  6.55128899  7.01410716  8.06651304  3.63897333  6.07232458
 15.18354158 15.38570301  4.46539101 -4.4434863   3.88404231 -3.79100723
  2.93119885 -3.22410994  2.96780496 -3.21952841 30.88959574]
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1197.0213685278545
gradient value of function right now is: [ 2.19786347e+00  1.05127099e-05  1.43207695e-03  1.30482885e-05
 -2.19786347e+00 -1.05127099e-05 -1.43207695e-03 -1.30482885e-05
 -9.32218095e-01 -8.93130486e-01 -9.18295320e-01 -5.33174581e-01
 -4.22945707e-07 -4.14639010e-07 -4.19693000e-07 -3.43234138e-07
  1.81001219e-03  1.77883520e-03  1.79780539e-03  1.51112583e-03
  5.56916942e-07  5.45972123e-07  5.52635977e-07  4.51747120e-07
 -1.44175288e-02 -7.83538598e-03 -3.48788833e-02 -7.86880831e-03
 -4.58192103e-03 -2.47902495e-03 -1.10262046e-02 -2.49191450e-03
 -1.25753608e-02 -6.84825671e-03 -3.02946436e-02 -6.87883520e-03
  3.08523497e-02  1.66925960e-02  7.57580967e-02  1.67471464e-02
 -8.70923638e-03 -1.29552100e-02 -2.08207276e-02 -2.05939106e-02
 -5.83525446e-03 -8.76211974e-03 -1.46139842e-02 -1.44103367e-02
 -2.52339256e-02 -3.65958769e-02 -5.32144071e-02 -5.30912143e-02
 -5.36296400e-03 -8.05987540e-03 -1.34807651e-02 -1.32904306e-02
  3.57363572e-02 -6.96227406e-02  9.88519874e-02 -1.89790108e-01
  2.77805856e-01 -4.31393053e-01  2.91690462e-01 -4.63932732e-01
 -1.82556443e+01]
supnorm grad right now is: 18.25564431575358
Weights right now are: 
[ 0.82879248  0.04812092 -0.88449797  0.67244764 -1.61901172 -0.03365728
  1.45580402  0.7426354  -1.58956504 -0.45200528 -1.32936676  3.98155805
  5.37876677  7.57434143  5.3104165   5.27591548  4.392687    3.68150396
  4.79311503  0.73832143  5.83676402  6.8233229   5.28676335  5.16106888
 -2.84685583 -5.38441807 -3.54668382 -5.22986901 -2.57167272 -5.44191166
 -1.84115888 -5.71128588 -4.07938952 -5.44994698 -2.42338726 -5.110717
  4.33483208  4.16959277  5.64970788  3.57616898  4.32279485  7.36676056
 11.77879318 12.82226999  4.13013545  5.72619097 16.13523644 16.49581813
  2.97664763  6.77538432  7.02289704  8.08815511  4.35500854  6.59257313
 15.90211442 16.06909482  4.40283975 -4.4206164   3.81395401 -3.82342516
  2.48887075 -3.51842328  2.56058397 -3.49537737 30.78584215]
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1195.8784773054765
gradient value of function right now is: [ 1.09401520e+00 -1.06696410e-05 -8.70788987e-04 -1.11970977e-05
 -1.09401520e+00  1.06696410e-05  8.70788987e-04  1.11970977e-05
  8.38675739e-01  7.93111814e-01  8.17882403e-01  9.90793696e-01
  4.42154831e-06  4.14779068e-06  4.33775064e-06  3.53875774e-06
 -4.50905823e-04 -4.25356297e-04 -4.43005077e-04 -3.68953747e-04
  4.72937457e-06  4.43888028e-06  4.64042606e-06  3.79204855e-06
 -3.86577056e-05 -3.17853599e-03  2.58168986e-02 -2.97770088e-03
 -9.47295321e-04 -1.39617660e-03  4.80996608e-03 -1.34823392e-03
 -5.62245077e-04 -3.00216908e-03  2.06063633e-02 -2.83410142e-03
 -6.67563831e-03  4.34928542e-03 -8.37392456e-02  3.79875049e-03
 -1.14333273e-04  3.84177375e-04  1.67950768e-02  1.46418354e-02
 -2.20987811e-03 -3.08579636e-03  2.69867313e-03  1.72837205e-03
  1.56994851e-02  2.54622250e-02  1.11265622e-01  1.01470172e-01
 -1.92077093e-03 -2.66673883e-03  2.90864021e-03  1.99182371e-03
 -1.20273918e-01 -7.28695446e-02 -3.53018713e-01 -1.81301362e-01
 -1.38324538e+00 -4.48116633e-01 -1.42359595e+00 -4.73866237e-01
 -1.24758354e+01]
supnorm grad right now is: 12.475835395953274
Weights right now are: 
[ 0.96580425  0.38117617 -0.21289463  1.08908456 -1.75602349 -0.36671253
  0.78420068  0.32599849 -1.49662488 -0.37362813 -1.24156269  4.30644876
  5.84501912  8.0236043   5.77070619  5.65985715  5.00440104  4.28871718
  5.40150106  1.32677989  6.37589758  7.34596994  5.81973984  5.62012517
 -2.60248766 -5.55690374 -2.8802321  -5.39143195 -1.80736139 -5.46053593
  0.17716898 -5.7119091  -3.80765362 -5.62810264 -1.66424989 -5.27671443
  4.23803246  4.25381259  5.53359781  3.65614132  5.09824544  8.02933167
 12.4910428  13.52107765  4.93295454  6.33347798 16.93850349 17.26107252
  3.54975359  7.28239076  7.38291594  8.45859583  5.1917289   7.22868846
 16.73473882 16.86341473  3.85075155 -4.55017536  3.32258659 -3.97456186
  2.00151704 -3.72375421  2.08882125 -3.69436714 30.74065673]
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1197.4780538245018
gradient value of function right now is: [ 4.73530376e+00  8.37795563e-06  3.54743508e-04  8.75174813e-06
 -4.73530376e+00 -8.37795563e-06 -3.54743508e-04 -8.75174813e-06
 -8.80985774e-01 -8.20379489e-01 -8.62171147e-01 -5.65324596e-01
 -6.49688397e-06 -6.05498818e-06 -6.35706801e-06 -4.72980550e-06
 -3.68934266e-05 -3.48649007e-05 -3.62367863e-05 -2.90352759e-05
 -6.80780314e-06 -6.35261938e-06 -6.66351107e-06 -4.99209655e-06
 -8.56797302e-03 -3.81749297e-03 -3.64885070e-02 -3.81929553e-03
 -3.78460111e-03 -1.64050606e-03 -1.61044736e-02 -1.64584647e-03
 -7.69482938e-03 -3.41949306e-03 -3.25721176e-02 -3.42305784e-03
  1.32845534e-02  5.94584014e-03  5.83346118e-02  5.93476106e-03
 -4.59047939e-03 -6.40865540e-03 -1.12495004e-02 -1.08420597e-02
 -3.03148718e-03 -4.24294491e-03 -7.85046683e-03 -7.51598595e-03
 -2.47235668e-02 -3.35244709e-02 -5.32698346e-02 -5.18821855e-02
 -2.80471015e-03 -3.92624241e-03 -7.30886190e-03 -6.99240680e-03
  3.65926114e-02 -5.18175227e-02  8.81202509e-02 -1.25876661e-01
  2.29805132e-01 -2.42303575e-01  2.38159929e-01 -2.61574351e-01
  5.70799667e-01]
supnorm grad right now is: 4.735303761578978
Weights right now are: 
[ 8.87155956e-01  6.97892422e-01  3.75402973e-01  1.40200593e+00
 -1.67737519e+00 -6.83428784e-01  1.95903072e-01  1.30771201e-02
 -1.90864935e+00 -7.71200642e-01 -1.64888042e+00  3.52399943e+00
  5.76736028e+00  7.95817538e+00  5.69700667e+00  5.60637358e+00
  5.26506015e+00  4.54166623e+00  5.65967655e+00  1.57715248e+00
  6.29861368e+00  7.28158120e+00  5.74661059e+00  5.56923288e+00
 -2.35450713e+00 -5.53602455e+00 -2.93805782e+00 -5.36386463e+00
 -2.06471471e+00 -6.39554383e+00  2.69045738e-01 -6.62727854e+00
 -3.56934960e+00 -5.67358365e+00 -1.66472903e+00 -5.31314858e+00
  4.01601118e+00  3.97800042e+00  5.90306482e+00  3.38166996e+00
  5.62865788e+00  8.46553356e+00  1.26945638e+01  1.37452706e+01
  5.58746470e+00  6.82723143e+00  1.75574688e+01  1.78551306e+01
  3.27456070e+00  6.98429223e+00  6.39908829e+00  7.55079308e+00
  5.85038641e+00  7.72226966e+00  1.73530152e+01  1.74567129e+01
  4.30394458e+00 -4.19830077e+00  3.89538068e+00 -3.62314031e+00
  2.45957989e+00 -3.26109927e+00  2.58993327e+00 -3.24678742e+00
  3.09179401e+01]
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1194.5386436662366
gradient value of function right now is: [ 8.79452159e+00  1.41496586e-06  7.07522520e-05  1.44637641e-06
 -8.79452159e+00 -1.41496586e-06 -7.07522520e-05 -1.44637641e-06
 -9.61894779e-01 -9.22795831e-01 -9.53689498e-01 -2.22453185e-01
 -6.32293287e-07 -5.91911755e-07 -6.22191454e-07 -4.51565372e-07
  2.80170634e-05  2.65240907e-05  2.76362267e-05  2.12579245e-05
 -6.31602536e-07 -5.91945428e-07 -6.21661767e-07 -4.53915221e-07
 -4.92565099e-03 -2.91877994e-03 -1.58506117e-02 -2.87925484e-03
 -2.05440470e-03 -1.28942232e-03 -5.87912356e-03 -1.27543445e-03
 -4.38935260e-03 -2.61701338e-03 -1.39149190e-02 -2.58237949e-03
  9.39309938e-03  5.38387401e-03  3.25068162e-02  5.30192445e-03
 -5.00923839e-03 -6.54860968e-03 -8.74677033e-03 -8.63605683e-03
 -3.86560739e-03 -5.10585648e-03 -6.89090517e-03 -6.80100638e-03
 -1.80286039e-02 -2.30114877e-02 -2.98909105e-02 -2.95569920e-02
 -3.59054415e-03 -4.74559851e-03 -6.41358775e-03 -6.32909835e-03
  2.20163351e-02 -4.56913604e-02  4.64790074e-02 -9.73567926e-02
  9.04605871e-02 -1.70657841e-01  9.66174167e-02 -1.85252841e-01
 -5.94414756e+00]
supnorm grad right now is: 8.794521586553083
Weights right now are: 
[ 1.03788434  0.40263821 -0.06569324  1.094852   -1.82810358 -0.38817457
  0.63699929  0.32023105 -1.72194948 -0.49913844 -1.44498004  4.24999105
  6.00165822  8.18134801  5.92749981  5.80665829  5.42864628  4.70042305
  5.82187803  1.7247005   6.54477672  7.51620055  5.98883367  5.77981925
 -3.88549978 -7.51444686 -3.62887041 -7.3465605  -3.24754165 -8.07829958
  0.20841199 -8.31637382 -5.11264104 -7.66697282 -2.3510293  -7.31004778
  5.51939878  5.8337818   6.8044745   5.24405019  5.43183515  8.07693021
 11.91132507 13.00302773  4.94759585  5.9295904  16.39530562 16.712074
  3.56476995  7.19481692  6.14745871  7.36092897  5.20116276  6.81300159
 16.17574979 16.29859437  5.4097688  -4.56695908  4.94379904 -4.05263522
  3.93939308 -3.73830724  4.02796255 -3.72831103 30.91410409]
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1197.064748908992
gradient value of function right now is: [ 6.79515577e+00  5.68541199e-06  8.75235551e-05  5.62786322e-06
 -6.79515577e+00 -5.68541199e-06 -8.75235551e-05 -5.62786322e-06
 -1.07164547e+00 -9.57222417e-01 -1.04195942e+00 -4.40526848e-01
 -3.81249664e-06 -3.30849110e-06 -3.67112665e-06 -2.29877740e-06
 -1.52021053e-05 -1.36788533e-05 -1.47655015e-05 -1.08136088e-05
 -3.69155599e-06 -3.21415356e-06 -3.55741510e-06 -2.26156172e-06
 -1.13046731e-02 -6.30327982e-03 -4.73748542e-02 -6.26412808e-03
 -5.31807939e-03 -3.05588844e-03 -2.00931791e-02 -3.04374677e-03
 -1.05396124e-02 -5.91938102e-03 -4.29972556e-02 -5.88571180e-03
  1.66958158e-02  8.94296831e-03  8.02001206e-02  8.86169898e-03
 -5.05674231e-03 -6.67213595e-03 -1.16826445e-02 -1.11891676e-02
 -4.43400724e-03 -5.90306935e-03 -1.08304140e-02 -1.03162003e-02
 -2.92025602e-02 -3.72508139e-02 -5.65436307e-02 -5.50546603e-02
 -4.12817580e-03 -5.49887478e-03 -1.01434122e-02 -9.65556247e-03
  4.49361592e-02 -7.33586470e-02  9.29807139e-02 -1.57543352e-01
  2.49824402e-01 -3.06027681e-01  2.53727817e-01 -3.27975436e-01
  1.00147811e+00]
supnorm grad right now is: 6.795155770481229
Weights right now are: 
[ 0.96741361  0.58254227  0.44565764  1.2728921  -1.75763285 -0.56807864
  0.1256484   0.14219095 -1.76154511 -0.6035165  -1.49271993  4.09201119
  5.95396274  8.14512286  5.88416264  5.76965135  5.85972112  5.11654869
  6.24819634  2.14222534  6.49942229  7.48271973  5.9478799   5.74712889
 -2.47453084 -6.4886219  -2.48812611 -6.32736901 -2.58922023 -8.16309656
  1.80622952 -8.41437715 -3.73342899 -6.732491   -1.08325076 -6.38281586
  4.13147225  4.43562992  6.45007479  3.84254667  6.79714194  9.4346552
 13.51386726 14.58686693  6.74834397  7.62894924 18.42582702 18.70534092
  3.28496028  6.94711329  5.70155758  6.9456952   7.05553284  8.56043057
 18.23995139 18.32764082  4.3417946  -4.62737001  4.04604976 -4.1257742
  2.68008208 -3.69216287  2.8161932  -3.69414718 30.96973899]
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1197.637192503613
gradient value of function right now is: [ 1.03425585e+00  1.25419671e-05  9.27784957e-05  1.22939561e-05
 -1.03425585e+00 -1.25419671e-05 -9.27784957e-05 -1.22939561e-05
 -8.88398699e-01 -7.63244681e-01 -8.50939723e-01 -6.78869005e-01
 -9.56163600e-06 -7.92562639e-06 -9.08058721e-06 -5.73000092e-06
 -4.35939999e-05 -3.81407610e-05 -4.19665077e-05 -3.13234150e-05
 -9.26622237e-06 -7.72084572e-06 -8.81123692e-06 -5.66037679e-06
 -4.10236773e-03 -1.13624743e-03 -4.76555630e-02 -1.13412456e-03
 -8.70562790e-04  1.35673727e-04 -1.67837894e-02  1.33351596e-04
 -3.38845488e-03 -7.89588819e-04 -4.15752145e-02 -7.89549225e-04
  8.59020938e-03  3.28867856e-03  8.94594386e-02  3.27153374e-03
 -2.83013738e-03 -3.48766295e-03 -6.76870763e-03 -6.32474576e-03
 -2.11754134e-03 -2.50425276e-03 -5.22937706e-03 -4.81370740e-03
 -3.35772493e-02 -4.14667407e-02 -6.75014159e-02 -6.47284529e-02
 -1.96258752e-03 -2.31449384e-03 -4.86635156e-03 -4.47417316e-03
  4.75276560e-02 -5.00810799e-02  9.95134158e-02 -1.15136814e-01
  2.18726786e-01 -1.68232902e-01  2.27708733e-01 -1.89853972e-01
 -1.47387486e+01]
supnorm grad right now is: 14.73874864267059
Weights right now are: 
[ 0.82036237  0.68324162  0.72422325  1.37851051 -1.61058161 -0.66877799
 -0.15291721  0.03657254 -1.72484125 -0.61294687 -1.46510765  3.90620264
  5.97558536  8.16024891  5.90388757  5.76467369  6.21287313  5.4512026
  6.59576094  2.46699938  6.51886246  7.4963019   5.96562819  5.74196587
 -2.08565552 -6.4200238  -2.00016611 -6.26523301 -2.63650983 -8.71286881
  2.54008319 -8.96625658 -3.38263644 -6.73068102 -0.54698593 -6.38600801
  3.52427511  3.90637814  6.34470951  3.32405064  7.98895155 10.54719707
 14.39021034 15.49626292  7.9794023   8.68049805 19.39846594 19.67816
  3.12039945  6.85684834  5.32734865  6.6259073   8.28614587  9.60926611
 19.20147246 19.29023443  4.19814512 -4.28527276  4.00291967 -3.81415377
  2.64030757 -3.27738229  2.80304989 -3.29589982 30.79821373]
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1196.9963989648193
gradient value of function right now is: [ 6.96391072e+00  8.59243697e-06  1.55242115e-05  8.12625516e-06
 -6.96391072e+00 -8.59243697e-06 -1.55242115e-05 -8.12625516e-06
 -1.48519447e+00 -1.21480102e+00 -1.42642592e+00 -2.33652236e-01
 -7.18804719e-06 -4.54305440e-06 -6.54375751e-06 -2.34358563e-06
 -6.99121215e-06 -4.70650986e-06 -6.42350968e-06 -2.88356522e-06
 -6.84493852e-06 -4.35060238e-06 -6.23629149e-06 -2.28156446e-06
 -8.85482843e-03 -5.22524477e-03 -6.31681353e-02 -5.19786152e-03
 -2.84925852e-03 -1.77525967e-03 -1.61170250e-02 -1.77115867e-03
 -8.31297783e-03 -4.94414898e-03 -5.67092540e-02 -4.92012149e-03
  1.31947782e-02  7.49010010e-03  1.16351938e-01  7.43641776e-03
 -4.17413775e-03 -5.00508468e-03 -9.04863896e-03 -8.45973087e-03
 -4.23841343e-03 -5.09656887e-03 -9.49145733e-03 -8.82956888e-03
 -3.99510874e-02 -4.71364379e-02 -7.63242708e-02 -7.25650724e-02
 -3.98944682e-03 -4.79674977e-03 -8.95983006e-03 -8.33035910e-03
  4.90551655e-02 -7.76784149e-02  9.67879606e-02 -1.66049014e-01
  2.09481378e-01 -2.76979853e-01  2.17295687e-01 -3.05511587e-01
  3.72290359e+00]
supnorm grad right now is: 6.963910724518228
Weights right now are: 
[  0.97321691   0.674471     0.66218022   1.38136181  -1.76343615
  -0.66000737  -0.09087417   0.03372123  -1.46613596  -0.27166156
  -1.18220711   4.83900719   6.31609445   8.40905293   6.22382754
   5.82119245   6.90131721   6.12416663   7.28563217   3.03286367
   6.82094877   7.72288938   6.25133129   5.80259422  -2.8827666
  -7.86060516  -2.10252422  -7.71134067  -2.96514059  -9.76223264
   3.57312914 -10.01217477  -4.26359368  -8.29038026  -0.5490094
  -7.9498667    4.0520281    4.80316661   7.23367737   4.22921209
   8.68203362  11.12515759  14.68148273  15.84779645   8.56421595
   8.99511899  19.57315828  19.87240795   2.423423     6.23512589
   3.97323916   5.41115665   8.87705543   9.92482186  19.37347616
  19.48199352   4.91317493  -4.56797815   4.7806965   -4.18873122
   3.40092041  -3.59259899   3.6117024   -3.61777258  30.9798381 ]
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1196.6644556339652
gradient value of function right now is: [ 8.20265203e+00  2.32779227e-05  3.60996110e-05  2.42840309e-05
 -8.20265203e+00 -2.32779227e-05 -3.60996110e-05 -2.42840309e-05
 -1.55906617e+00 -1.14239444e+00 -1.43479490e+00 -3.35991283e-01
 -1.75677132e-06 -8.10893049e-07 -1.45824409e-06 -4.64075623e-07
 -1.13593208e-05 -5.49618923e-06 -9.50743292e-06 -3.43927748e-06
 -2.65469524e-06 -1.23303364e-06 -2.20607513e-06 -7.13433864e-07
 -1.22564556e-02 -7.84544591e-03 -1.16658924e-01 -7.88659715e-03
 -6.88777279e-03 -4.50515821e-03 -5.13469232e-02 -4.54473741e-03
 -1.23218813e-02 -7.93114718e-03 -1.08863283e-01 -7.97918319e-03
  1.06112900e-02  6.49985623e-03  1.67515384e-01  6.50944454e-03
 -3.42301491e-03 -3.39077223e-03 -9.60033758e-03 -8.10653327e-03
 -4.73994135e-03 -4.57875710e-03 -1.41416416e-02 -1.17137804e-02
 -4.52727069e-02 -4.72390878e-02 -8.39780952e-02 -7.79405515e-02
 -4.56925070e-03 -4.39859679e-03 -1.37196662e-02 -1.13408970e-02
  6.45913014e-02 -7.05563215e-02  9.44192210e-02 -1.37292118e-01
  3.78543270e-01 -2.93114413e-01  3.32018842e-01 -3.02426866e-01
  6.98949696e+00]
supnorm grad right now is: 8.202652033021344
Weights right now are: 
[ 1.04063524e+00  7.74744587e-02  5.77141147e-01  8.08943867e-01
 -1.83085448e+00 -6.30108207e-02 -5.83510074e-03  6.06139180e-01
 -1.45525569e+00 -6.77425255e-01 -1.27627371e+00  4.78594882e+00
  7.84296071e+00  9.35865018e+00  7.64334591e+00  6.34024766e+00
  8.28868755e+00  6.87499021e+00  8.51925379e+00  3.48402759e+00
  8.27665859e+00  8.49892013e+00  7.55296924e+00  6.19879550e+00
 -2.37854658e+00 -8.05983625e+00 -3.06409358e-01 -7.90469444e+00
 -4.08720344e+00 -1.18084207e+01  5.40498039e+00 -1.20390703e+01
 -3.87249538e+00 -8.63828646e+00  1.38948531e+00 -8.28974632e+00
  3.49848438e+00  4.65744527e+00  7.10165300e+00  4.08325248e+00
  1.05315924e+01  1.25694818e+01  1.63786753e+01  1.75098960e+01
  1.01730302e+01  1.00587241e+01  2.09717925e+01  2.11939979e+01
  1.64417902e+00  5.74472519e+00  2.96437194e+00  4.52663906e+00
  1.05124064e+01  1.10072289e+01  2.07790116e+01  2.08116962e+01
  4.70646052e+00 -4.54157710e+00  5.19026326e+00 -4.12843225e+00
  2.88489891e+00 -3.57713807e+00  3.30497432e+00 -3.57606205e+00
  3.09894488e+01]
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1197.8722231306713
gradient value of function right now is: [ 4.11393161e-01  1.77681949e-05  2.10250691e-05  1.70449599e-05
 -4.11393161e-01 -1.77681949e-05 -2.10250691e-05 -1.70449599e-05
 -6.06870988e-01 -2.11763097e-01 -4.97631804e-01 -2.13295790e-01
 -1.35171427e-05 -5.07498621e-06 -1.09158722e-05 -3.35719515e-06
 -1.60681708e-05 -6.21318410e-06 -1.30272312e-05 -4.33475053e-06
 -1.29534301e-05 -4.88636531e-06 -1.04675025e-05 -3.25956822e-06
 -1.03786551e-02 -7.17513226e-03 -1.02258316e-01 -7.15291482e-03
 -5.24638308e-03 -3.79418093e-03 -3.60043751e-02 -3.79211715e-03
 -1.06133478e-02 -7.41929016e-03 -9.51847385e-02 -7.40080837e-03
  8.83277975e-03  5.82927944e-03  1.40621160e-01  5.79401907e-03
 -3.88034610e-03 -4.22467693e-03 -8.79706041e-03 -7.92773592e-03
 -5.64971423e-03 -6.16336846e-03 -1.31196881e-02 -1.17708907e-02
 -2.78144533e-02 -3.20325582e-02 -4.53351010e-02 -4.46179161e-02
 -5.43096608e-03 -5.91923705e-03 -1.26542672e-02 -1.13428112e-02
  4.90984609e-02 -7.90331295e-02  6.84690776e-02 -1.38774139e-01
  2.20758037e-01 -2.90604308e-01  2.02617026e-01 -3.04750691e-01
 -1.23916722e+01]
supnorm grad right now is: 12.391672221581656
Weights right now are: 
[ 8.11146921e-01  7.28311125e-01  1.01754792e+00  1.42895332e+00
 -1.60136616e+00 -7.13847487e-01 -4.46241873e-01 -1.38702690e-02
 -1.42508227e+00 -5.61176245e-01 -1.24538805e+00  5.39787876e+00
  8.89533784e+00  9.92812714e+00  8.56675031e+00  6.74308367e+00
  9.32995815e+00  7.69519304e+00  9.53820656e+00  4.08091665e+00
  9.37343801e+00  9.08095691e+00  8.51058660e+00  6.60263483e+00
 -3.11701552e+00 -9.01336202e+00  2.16063363e-01 -8.86114747e+00
 -4.27346927e+00 -1.22056304e+01  6.31684402e+00 -1.24266458e+01
 -4.55983296e+00 -9.52830766e+00  1.90060353e+00 -9.17999495e+00
  4.04155098e+00  5.46172523e+00  6.91409862e+00  4.89602052e+00
  1.12658860e+01  1.32512205e+01  1.65751471e+01  1.78477547e+01
  1.06129803e+01  1.03318991e+01  2.10370016e+01  2.12926189e+01
  1.37517583e+00  5.57773112e+00  2.53907923e+00  4.22432138e+00
  1.09504533e+01  1.12809995e+01  2.08396144e+01  2.09057793e+01
  4.83719880e+00 -5.07490884e+00  5.15397105e+00 -4.63986125e+00
  3.16641642e+00 -4.16341540e+00  3.54265376e+00 -4.14355369e+00
  3.08632189e+01]
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1198.1906552801627
gradient value of function right now is: [-2.33364104e+00 -2.10062003e-05 -3.33397211e-05 -2.16803467e-05
  2.33364104e+00  2.10062003e-05  3.33397211e-05  2.16803467e-05
  1.38139742e+00  9.72948660e-01  1.25603324e+00  7.39804879e-01
  1.57686481e-05  7.04998021e-06  1.29317736e-05  6.29961179e-06
  2.83494955e-05  1.33839639e-05  2.35161865e-05  1.22180095e-05
  1.67632861e-05  7.56907171e-06  1.37761643e-05  6.78743100e-06
  4.94019474e-03  4.78604409e-03  9.09367569e-02  4.62349831e-03
  2.85488859e-03  2.73407096e-03  2.49823950e-02  2.66935415e-03
  4.91460469e-03  4.82118769e-03  7.67160098e-02  4.66326442e-03
 -7.17265647e-03 -5.87895660e-03 -3.28859027e-01 -5.67796899e-03
  2.27084875e-03  4.24237628e-03  2.16730972e-03  3.56028110e-03
  3.63374777e-03  7.02549170e-03  3.50384221e-03  5.95686287e-03
  1.51779658e-01  1.60222920e-01  2.44895448e-01  2.25497304e-01
  3.35701795e-03  6.59069563e-03  3.09224746e-03  5.47640951e-03
 -1.06634458e-02  1.75397807e-01 -1.19597613e-01  4.46954314e-01
  1.22716650e-01  4.76624989e-01  1.72819089e-03  6.05736814e-01
  9.34184971e+00]
supnorm grad right now is: 9.341849705638882
Weights right now are: 
[  0.88302708   0.81895924   1.20272955   1.54303829  -1.67324632
  -0.80449561  -0.6314235   -0.12795525  -1.13321782  -0.34987005
  -0.97039812   6.0011608    9.36140366  10.15189629   8.99000613
   6.74949345   9.71475922   7.9570801    9.9129917    4.11170839
   9.80830596   9.29085288   8.90565533   6.60409395  -2.83782906
  -8.86623713   0.88604933  -8.71791639  -4.43119458 -12.52420482
   6.87627035 -12.73874311  -4.36601725  -9.47751705   2.59399116
  -9.13144997   3.95512317   5.40656928   6.8338692    4.84325492
  12.04020618  13.99871859  17.13588124  18.44164046  11.31731437
  10.90996524  21.57120806  21.82231449   1.78912984   6.23235381
   2.53503425   4.38197398  11.65491044  11.85902019  21.37063217
  21.43302011   4.83851598  -4.58533949   5.27211092  -4.03517986
   3.1880037   -3.77169642   3.67166217  -3.71252855  30.94463093]
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1196.9631148225028
gradient value of function right now is: [ 6.66275911e+00  1.23963173e-04  1.16163153e-04  1.13730259e-04
 -6.66275911e+00 -1.23963173e-04 -1.16163153e-04 -1.13730259e-04
 -1.47884968e+00 -7.26256594e-01 -1.22819341e+00 -1.77600444e-01
 -1.15168116e-04 -1.81940094e-05 -7.65247792e-05 -1.60803010e-05
 -1.01451576e-04 -1.66328077e-05 -6.77686305e-05 -1.51606651e-05
 -1.04896213e-04 -1.67045926e-05 -6.97806523e-05 -1.48633685e-05
 -1.87193628e-02 -1.26438354e-02 -1.83444312e-01 -1.26396444e-02
 -7.43307238e-03 -5.46709129e-03 -3.55346644e-02 -5.49377301e-03
 -1.92454120e-02 -1.33420001e-02 -1.51522266e-01 -1.33561807e-02
  5.70507484e-03  3.52289606e-03  1.58907294e-01  3.50336688e-03
 -3.48540978e-03 -3.16927314e-03 -1.04756376e-02 -7.26852883e-03
 -5.54230397e-03 -4.94512265e-03 -1.77192834e-02 -1.19482563e-02
 -4.71108449e-02 -4.49030822e-02 -7.74124750e-02 -6.69137943e-02
 -5.36284972e-03 -4.76516385e-03 -1.72370708e-02 -1.15885774e-02
  6.17409396e-02 -7.81329983e-02  7.59380978e-02 -1.23562702e-01
  3.79397101e-01 -3.46427540e-01  2.56420588e-01 -2.93560982e-01
 -9.00862808e+00]
supnorm grad right now is: 9.008628082888688
Weights right now are: 
[  0.98552246   0.96656317   1.19735438   1.66240475  -1.7757417
  -0.95209953  -0.62604833  -0.2473217   -1.48036157  -0.48745055
  -1.19704414   5.81077091  10.36392393  10.97689781   9.99861085
   7.63205974  10.68291136   8.68491867  10.86211044   4.8770382
  10.79126929  10.06683184   9.88692769   7.42441825  -2.69835702
  -8.61065336   0.77822847  -8.46173726  -3.17846011 -11.45147854
   8.25796033 -11.65049974  -3.71914768  -8.8065752    2.85588808
  -8.45430386   5.37091121   6.69591039   7.7789841    6.13170066
  12.2396937   13.89516152  17.12237054  18.56051799  11.86695452
  10.90253027  22.06069743  22.30096215   0.71855183   5.67257515
   1.16670823   3.17459465  12.2469169   11.88766548  21.89141263
  21.94813194   4.90301435  -5.08045246   6.04439837  -4.56730747
   2.90648687  -3.92945595   3.79568295  -4.10272671  30.91462753]
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1197.9775297314934
gradient value of function right now is: [-6.29456499e+00 -8.23102571e-06 -9.96304261e-06 -7.73864876e-06
  6.29456499e+00  8.23102571e-06  9.96304261e-06  7.73864876e-06
  7.82553479e-01  8.60573274e-01  8.11556744e-01  2.91128016e-01
  1.27632353e-05  1.45304640e-06  7.15526068e-06  5.29479498e-06
  1.65844261e-05  3.16478239e-06  1.02106729e-05  6.92207191e-06
  1.19716348e-05  1.49250713e-06  6.78668748e-06  5.12154829e-06
 -6.97809430e-03 -4.79506633e-03 -2.42007412e-02 -4.75571230e-03
 -2.20361568e-03 -1.48671772e-03 -6.45714765e-03 -1.48035863e-03
 -5.96120989e-03 -4.04820148e-03 -2.23403663e-02 -4.01862832e-03
  3.64465724e-03  2.56527191e-03 -5.90708432e-02  2.53854863e-03
 -1.91391172e-03 -2.35440682e-03 -5.17544337e-03 -3.64006524e-03
 -3.16569514e-03 -3.80544397e-03 -8.80542836e-03 -6.05413401e-03
  6.67386010e-02  5.93124421e-02  1.22642025e-01  9.07537412e-02
 -3.05007562e-03 -3.66335938e-03 -8.49431830e-03 -5.83571761e-03
 -6.86759588e-03 -4.23808846e-02 -9.38801940e-02 -3.57852166e-02
  9.34431003e-02 -1.68608871e-01 -1.58304299e-02 -1.33324884e-01
  9.05688374e+00]
supnorm grad right now is: 9.056883735598209
Weights right now are: 
[  0.80375789   2.5560092    2.80936358   3.24843414  -1.59397712
  -2.54154556  -2.23805754  -1.83335109  -1.47008152  -0.57855263
  -1.16968138   6.52905896  10.17408768  11.62551191  10.05530124
   8.08058121  10.53930813   9.36433943  10.95754036   5.2928336
  10.62318438  10.72537807   9.96382776   7.87197359  -3.02066047
  -9.18082998   1.32472608  -9.02651305  -4.62039999 -13.24701031
   7.91592071 -13.4140618   -4.31230941  -9.71338903   3.40671072
  -9.34576054   5.47899235   6.82640142   7.58069846   6.27407703
  12.87051532  14.17091545  17.21573426  18.94679857  12.13769324
  10.32613241  22.21433742  22.33209065   1.66884528   7.41896007
   1.54156145   3.91415399  12.49810026  11.2818245   22.03001038
  21.96227563   4.9165675   -5.40262759   5.19360296  -4.55234561
   3.06662297  -4.28701905   3.92698968  -4.50577585  30.97426957]
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -1198.206877100943
gradient value of function right now is: [ 2.89591244e+00  7.84175610e-04  6.85134133e-04  7.01026064e-04
 -2.89591244e+00 -7.84175610e-04 -6.85134133e-04 -7.01026064e-04
 -7.05635049e-01 -2.43324795e-01 -5.11909379e-01 -1.63531168e-01
 -1.85519043e-03 -2.70752911e-04 -1.10527065e-03 -2.96877717e-04
 -1.54547042e-03 -2.28743356e-04 -9.22547041e-04 -2.56810883e-04
 -1.63734286e-03 -2.39582123e-04 -9.75774912e-04 -2.64095474e-04
 -1.35535222e-02 -9.83343828e-03 -1.52063879e-01 -9.81354044e-03
 -6.40845613e-03 -4.89804526e-03 -3.67682214e-02 -4.90827655e-03
 -1.28552443e-02 -9.47888717e-03 -1.13319782e-01 -9.47398506e-03
  3.34890828e-03  2.27372871e-03  1.37412959e-01  2.25576820e-03
 -2.72354255e-03 -2.65576209e-03 -7.70469707e-03 -5.15158269e-03
 -4.77664412e-03 -4.64029783e-03 -1.41882137e-02 -9.23384680e-03
 -3.64004830e-02 -3.29961665e-02 -5.45169631e-02 -4.60089705e-02
 -4.63608921e-03 -4.49492415e-03 -1.38288895e-02 -8.97771797e-03
  4.32319666e-02 -7.02006196e-02  6.25844758e-02 -8.45616089e-02
  2.31297150e-01 -3.00388438e-01  1.54835628e-01 -2.23432546e-01
 -5.22238137e-01]
supnorm grad right now is: 2.895912440191758
Weights right now are: 
[  0.82543891   3.07460321   3.2273414    3.73979898  -1.61565814
  -3.06013957  -2.65603536  -2.32471593  -1.68761966  -0.90373184
  -1.40239408   6.21876074   9.82766497  12.19051955   9.90082574
   9.24212793  10.33037016  10.04726831  10.93963297   6.43063257
  10.31210491  11.32144574   9.84459129   9.02515043  -2.99886027
  -9.10231371   1.74520158  -8.95500768  -3.93782503 -12.74058162
   8.81594599 -12.89088922  -4.07819367  -9.50781768   3.97484362
  -9.1392172    5.59666476   6.90763129   7.67853552   6.36062559
  13.66519129  14.71749377  17.57594752  19.54876263  12.8255438
  10.55330265  22.66899585  22.85941542   0.41811477   6.41164652
   0.36548782   2.70339757  13.19669299  11.51733255  22.48150243
  22.49631402   5.26822419  -5.38035711   6.24778082  -4.91458533
   2.95298874  -4.31082159   4.1771651   -4.50788337  30.94447515]
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -1198.2468655478237
gradient value of function right now is: [-3.03075917e+00 -2.59779556e-02 -2.04961160e-02 -2.26513204e-02
  3.03075917e+00  2.59779556e-02  2.04961160e-02  2.26513204e-02
  4.03484614e-01  6.12030719e-02  2.08190127e-01  1.57316254e-02
  5.85066013e-02  4.43644243e-03  2.46992323e-02  8.22604865e-03
  4.13252958e-02  3.06617240e-03  1.73174240e-02  6.14196544e-03
  4.94556513e-02  3.72995100e-03  2.08395815e-02  7.06176475e-03
  3.02992586e-03  2.74189123e-03 -2.34128895e-01  2.83927954e-03
 -3.38499673e-04  1.67434032e-04 -3.81789064e-02  1.73256519e-04
  1.28345432e-03  1.62466877e-03 -1.34149301e-01  1.67143736e-03
 -4.80323964e-03 -2.12807699e-03 -2.14012271e-01 -2.24097493e-03
 -2.42954251e-04 -1.03430991e-03  2.83656844e-03 -3.17667269e-04
 -6.20953304e-04 -2.48884952e-03  1.42836053e-03 -1.17021757e-03
  5.84721707e-02  2.31260889e-02  8.01818792e-01  1.13621270e-01
 -5.81239126e-04 -2.30487940e-03  1.32794609e-03 -1.07722446e-03
 -4.59174565e-02 -2.58430697e-02 -9.30193746e-02 -3.21670465e-02
 -2.20583975e-01  6.79394918e-02 -3.30490274e-01 -9.72280023e-02
 -1.05841739e+01]
supnorm grad right now is: 10.584173881147485
Weights right now are: 
[  0.82811262   4.36240754   4.2490953    4.94162008  -1.61833186
  -4.3479439   -3.67778926  -3.52653704  -1.93739431  -0.97763739
  -1.51785858   6.89263965   8.59877168  12.54380711   8.97522829
  10.3501012    9.41564014  10.83307864  10.35763283   7.86098067
   9.18096347  11.78533913   9.0194344   10.21790876  -1.71621915
  -8.50575424   2.7598006   -8.32302549  -3.63199012 -12.96856127
   9.43489286 -13.0827912   -3.1450532   -9.30314444   5.20062185
  -8.89459594   7.03241416   7.72465738   6.80751418   7.25864075
  14.65703066  15.5434948   19.68844983  20.532759    13.15411205
  10.56351138  24.69217799  23.1776904    0.96501726   8.08657055
   0.12199851   3.31607295  13.51046225  11.46109111  24.54136025
  22.81660363   4.41656945  -5.70373054   5.13043888  -3.22577045
   0.42952193  -4.94370782   3.26351524  -4.43047646  30.7638976 ]
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1197.0682844060493
gradient value of function right now is: [ 4.20562631e+00  6.76533508e-02  5.11958564e-02  5.79778869e-02
 -4.20562631e+00 -6.76533508e-02 -5.11958564e-02 -5.79778869e-02
 -9.76052382e-01 -2.76521349e-01 -5.72998130e-01 -3.13679079e-01
 -1.48181207e-01 -9.97338858e-03 -5.63763751e-02 -2.26214563e-02
 -9.92634104e-02 -6.61235896e-03 -3.76420213e-02 -1.51006136e-02
 -1.22457892e-01 -8.18044664e-03 -4.64820848e-02 -1.86197988e-02
  2.43162645e-03 -1.78747026e-03  5.74571421e-01 -1.61276405e-03
  6.14583983e-04  2.84334773e-04  9.26974401e-02  2.74881129e-04
  7.02395497e-04 -1.01724785e-03  3.03566894e-01 -9.61349408e-04
  7.13640929e-03  4.79144547e-03  6.32417553e-01  4.69409062e-03
 -1.38312748e-03 -2.40250526e-03 -2.41101364e-03 -2.69875705e-03
 -1.67052723e-03 -3.34047828e-03  7.86372034e-04 -3.25632344e-03
 -1.57348835e-01 -1.64537644e-01 -1.20375958e+00 -2.90224213e-01
 -1.51530525e-03 -3.05839730e-03  1.11722231e-03 -2.95179590e-03
  9.04224681e-02 -6.95631980e-02  6.09912271e-01 -3.52318854e-01
 -2.58216797e-01 -9.17521395e-02  5.19790568e-01 -2.76543075e-01
 -1.90254630e+01]
supnorm grad right now is: 19.025462968415724
Weights right now are: 
[  0.94689211   4.50585369   4.24333012   5.03041574  -1.73711135
  -4.49139005  -3.67202407  -3.61533269  -2.37096587  -0.44677792
  -1.51033894   7.38280839   8.17006199  12.03533579   8.46382346
  10.53228473   9.17679974  10.50862058  10.03598858   8.14753522
   8.82008905  11.33744963   8.57400101  10.44075357  -1.64295481
  -8.53302906   2.60872879  -8.36412383  -3.43119084 -13.22518446
   9.82567855 -13.32151355  -3.06656225  -9.47196146   5.35487393
  -9.0655852    7.78138482   7.80860944   7.32955456   7.39765082
  16.2956014   16.86520519  19.74339551  21.8932656   14.53159178
  11.48778894  25.23570418  24.29181053   1.08898531   8.17973683
  -0.1881868    3.20471565  14.91164944  12.40607332  25.07845741
  23.940254     4.13135466  -4.67726012   4.56462642  -3.34914027
   0.7313157   -4.75664787   3.32205896  -3.6900226   30.79957637]
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1197.8351813260188
gradient value of function right now is: [-7.56257335e+00 -4.79703698e-02 -2.97600099e-02 -3.77568154e-02
  7.56257335e+00  4.79703698e-02  2.97600099e-02  3.77568154e-02
  1.80386350e+00  4.14345685e-01  1.00493346e+00  3.90908302e-01
  1.31807314e-01  7.61291070e-03  4.88866530e-02  1.50558400e-02
  6.83290905e-02  3.88039267e-03  2.51506350e-02  8.10424015e-03
  9.80964586e-02  5.63291255e-03  3.62884660e-02  1.13432083e-02
  4.71422326e-02  4.09596245e-02  1.11250055e-01  4.05994831e-02
 -2.00813449e-03 -1.14695994e-03 -7.92640322e-02 -1.15232159e-03
  2.59368395e-02  2.43330326e-02 -4.88696350e-02  2.40881522e-02
 -1.24411858e-02 -8.80849065e-03 -5.38941878e-01 -8.76051914e-03
  4.75728075e-03  5.32244500e-03  1.28330022e-02  8.52463527e-03
  1.05143112e-02  1.34384584e-02  2.38073819e-02  1.96182858e-02
  2.98383111e-01  1.32660086e-01  9.32828430e-01  3.33189498e-01
  1.00647444e-02  1.28491640e-02  2.28370235e-02  1.87875422e-02
 -2.20729097e-01  2.34462717e-01 -7.29809448e-01  1.18752933e-01
 -6.08413078e-01  8.19539549e-01 -9.26782910e-01  6.20227593e-01
  1.03945940e+01]
supnorm grad right now is: 10.394594007665965
Weights right now are: 
[  0.8004401    4.15899548   3.7892926    4.64212471  -1.59065933
  -4.14453185  -3.21798655  -3.22704167  -2.55241983  -0.03331507
  -1.42579944   7.66004442   8.33688414  12.26288064   8.5901657
  11.24473579   9.50297159  10.86136868  10.3120267    8.8827744
   9.04709857  11.6046267    8.75469986  11.15793361  -1.88107702
  -8.72574594   1.97725766  -8.56057637  -2.63666929 -12.49079428
   9.8870022  -12.58702929  -3.0124041   -9.63779695   5.07279401
  -9.22295111   8.0193909    7.92382953   7.35879538   7.52840341
  17.50820901  17.49405255  19.86094265  22.81215477  15.41921288
  11.75142092  25.65732787  24.94377576   0.58144453   7.57727861
   0.16182575   2.75728119  15.82373988  12.68748204  25.47838319
  24.60960279   3.05811641  -4.61875067   4.12555908  -3.8954054
   1.15372935  -4.27924558   2.73719077  -3.79435718  30.9283614 ]
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1197.4159662791817
gradient value of function right now is: [-7.03076657e+00  1.55687018e-02  1.09936641e-02  1.29564718e-02
  7.03076657e+00 -1.55687018e-02 -1.09936641e-02 -1.29564718e-02
  4.90457025e-02  2.25908262e-01  1.47955737e-01 -4.46882540e-02
 -3.77525744e-02 -3.08051605e-03 -1.55472716e-02 -7.06943190e-03
 -2.32259521e-02 -1.82421500e-03 -9.47736437e-03 -4.24616778e-03
 -3.01035951e-02 -2.41117220e-03 -1.23387101e-02 -5.56248784e-03
  4.76141267e-03  3.99706850e-04  9.35429169e-02  6.94455368e-04
  2.62080936e-04  4.53286210e-04  3.21468913e-02  4.17354139e-04
  2.38319193e-03  2.16925081e-04  6.77358385e-02  3.54618357e-04
  2.55524915e-03  2.82126251e-03  1.82675575e-01  2.67006368e-03
 -9.45420672e-04 -2.58478459e-03  2.89514881e-03 -1.67187020e-03
 -2.04291138e-03 -5.77322162e-03  4.98499581e-03 -3.74468853e-03
 -5.08525467e-02 -7.53705201e-02 -2.01003181e-01 -8.21515673e-02
 -1.82179497e-03 -5.27158408e-03  5.13441705e-03 -3.35985140e-03
 -1.72610016e-02 -4.86740004e-02  2.46192487e-01 -1.78691289e-01
 -5.05394079e-01 -1.02113470e-01  4.83968294e-02 -1.60249052e-01
  9.55925423e+00]
supnorm grad right now is: 9.559254225387043
Weights right now are: 
[  0.71183252   4.69317689   4.32780545   5.17615154  -1.50205176
  -4.67871325  -3.7564994   -3.7610685   -2.85743179   0.24547809
  -1.62851818   7.77938942   7.91697901  12.21943413   8.24452424
  10.90679604   9.09548224  10.83744184   9.98094495   8.53595345
   8.63117242  11.55573695   8.41038858  10.80763583  -3.85667987
 -11.02801521   2.72172638 -10.8510259   -3.49681481 -13.55680457
  10.39975947 -13.6504517   -5.23782249 -12.23233566   5.60557989
 -11.79766171   8.74547378   8.89324321   7.46123129   8.47796631
  16.63181188  16.24909317  18.46593593  21.76986415  13.99374241
   9.77757737  24.17709168  23.30056807   0.05852631   7.70679194
  -0.62098028   2.35084834  14.40255873  10.72258514  24.00991209
  22.97659277   4.71418096  -6.07346923   4.63183972  -4.26179667
   2.39459791  -6.24487677   4.17719665  -4.96482571  31.0506873 ]
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1197.740719881778
gradient value of function right now is: [ 1.64451981e+00  3.95872185e-03  2.36773151e-03  3.08046303e-03
 -1.64451981e+00 -3.95872185e-03 -2.36773151e-03 -3.08046303e-03
 -6.27653298e-01 -2.03453684e-01 -3.97297289e-01 -2.54330315e-01
 -9.49911567e-03 -1.13299632e-03 -4.43782792e-03 -2.03062227e-03
 -4.59206230e-03 -5.17579511e-04 -2.10145990e-03 -9.19125429e-04
 -6.92555156e-03 -8.08193598e-04 -3.21002328e-03 -1.44323568e-03
 -1.43799772e-03 -3.79722385e-03 -2.32144211e-01 -3.55024983e-03
 -1.09712374e-04  2.23283102e-05  7.27014237e-03  1.31241762e-05
 -1.67533245e-03 -2.28909376e-03 -9.54693725e-02 -2.19716071e-03
  1.00946539e-03  1.59410655e-03  2.57262681e-01  1.50291593e-03
 -1.18798729e-03 -1.73078127e-03  3.72133364e-04 -1.95832428e-03
 -3.37627190e-03 -4.48931647e-03 -8.48614874e-04 -5.54160447e-03
 -1.25290471e-01 -1.11278569e-01 -1.59784571e-01 -1.47108868e-01
 -3.12977376e-03 -4.18788595e-03 -6.49756267e-04 -5.14620768e-03
  6.15500321e-04 -7.98705848e-02  1.82689292e-01 -1.59356684e-01
 -1.59848995e-01 -1.09565604e-01  7.79354527e-02 -2.12031116e-01
 -1.17405627e+01]
supnorm grad right now is: 11.74056274845915
Weights right now are: 
[  0.84173806   3.74491632   3.25047228   4.18402658  -1.6319573
  -3.73045268  -2.67916624  -2.76894353  -3.08506927  -0.13138922
  -1.9184071    7.07573969   8.83101222  14.15309378   9.4234575
  12.87807338  10.15827604  12.91113718  11.30881818  10.61276662
   9.59617162  13.53345041   9.63900094  12.81507641  -3.13363103
  -9.80695639   1.90093186  -9.67273165  -2.99489618 -13.82613881
   9.47757654 -13.85032377  -4.15891047 -10.93769433   4.91863091
 -10.522013     7.95949314   7.45623474   7.57143309   7.05674327
  19.53504393  18.51080989  19.14796914  24.27985731  16.49005146
  11.64270905  25.17618437  25.45692382  -0.1122905    7.19809591
  -0.72750115   1.9278905   16.92562775  12.62951986  24.97605206
  25.15029703   3.77366939  -4.5134281    4.65679102  -3.71682421
   2.40490788  -5.28328435   3.35800321  -3.6979349   30.80584224]
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1197.7800169425043
gradient value of function right now is: [ 6.11263338e+00  2.45722851e-03  1.43112874e-03  1.89606147e-03
 -6.11263338e+00 -2.45722851e-03 -1.43112874e-03 -1.89606147e-03
 -6.58760354e-01 -2.45595665e-01 -4.29551406e-01 -1.24219684e-01
 -5.71505765e-03 -7.35961253e-04 -2.66661538e-03 -1.08983188e-03
 -2.52502030e-03 -3.27687127e-04 -1.17853284e-03 -5.03879361e-04
 -4.05567542e-03 -5.22841017e-04 -1.89179271e-03 -7.82521773e-04
 -1.17534044e-02 -1.17091493e-02 -2.28688136e-01 -1.14813652e-02
 -3.92852994e-05 -3.03219428e-05  5.24376377e-03 -3.28829586e-05
 -7.09304140e-03 -7.01383253e-03 -9.92734197e-02 -6.89665178e-03
  3.49004419e-03  3.53195688e-03  2.16434804e-01  3.43674900e-03
 -3.09564350e-03 -3.95455196e-03 -4.71150185e-03 -4.98289226e-03
 -6.09130159e-03 -7.81107233e-03 -9.36628622e-03 -9.89062231e-03
 -4.64476517e-02 -5.36085753e-02 -5.71684746e-02 -6.03670152e-02
 -5.81494255e-03 -7.45857186e-03 -8.95136221e-03 -9.44916228e-03
  7.69813949e-02 -1.08572850e-01  1.21553898e-01 -2.11440610e-01
  1.62866209e-01 -2.04083202e-01  1.95618845e-01 -2.78617192e-01
  4.55599347e+00]
supnorm grad right now is: 6.11263337949136
Weights right now are: 
[  0.93884784   3.38355625   2.87343718   3.82150679  -1.72906708
  -3.36909261  -2.30213113  -2.40642375  -2.63476157  -0.07878177
  -1.6622171    7.83689535   9.24153446  14.79722254   9.86841217
  13.50270743  10.57299089  13.49356822  11.74573776  11.15205226
  10.00252337  14.14725378  10.07349879  13.40674777  -3.98921241
 -10.39936617   2.37769249 -10.29166405  -3.39110685 -14.35777959
   9.28046232 -14.37639148  -5.05124768 -11.80539695   5.26409205
 -11.40216922   8.3233226    7.52948959   6.96425408   7.15967721
  19.28052243  18.82435689  18.15513062  23.95838804  16.37351643
  11.86514878  24.56882568  25.27339079   0.11232629   7.11253897
  -0.58797393   2.04590542  16.77414842  12.8383415   24.33014547
  24.93634505   4.63436541  -4.76846386   4.3513363   -4.34294727
   3.73632937  -4.39921315   3.93612874  -4.09596723  30.9427624 ]
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1197.6849490588675
gradient value of function right now is: [ 4.28188428e+00  1.87758551e-03  1.14616411e-03  1.50785509e-03
 -4.28188428e+00 -1.87758551e-03 -1.14616411e-03 -1.50785509e-03
 -4.76099236e-01 -1.47175076e-01 -3.45510423e-01 -1.19875256e-01
 -3.57469974e-03 -4.36225527e-04 -2.02869688e-03 -7.17742240e-04
 -1.65977576e-03 -2.04773718e-04 -9.39450673e-04 -3.45761775e-04
 -2.65011153e-03 -3.24069754e-04 -1.50256612e-03 -5.37036060e-04
 -8.28588893e-03 -8.78484820e-03 -1.89803931e-01 -8.57492795e-03
 -1.64077538e-04 -1.58406785e-04  2.53243088e-03 -1.58330115e-04
 -5.46112009e-03 -5.74876350e-03 -1.00148234e-01 -5.62175416e-03
  2.35836906e-03  2.57815139e-03  1.77806838e-01  2.49654190e-03
 -2.69379342e-03 -3.85099409e-03 -3.98704120e-03 -3.95351339e-03
 -5.31212836e-03 -7.68363987e-03 -7.88192561e-03 -7.83477087e-03
 -4.47740621e-02 -4.96875142e-02 -5.37020828e-02 -5.22358505e-02
 -5.06896089e-03 -7.32382565e-03 -7.52871240e-03 -7.47798540e-03
  5.51863526e-02 -9.07498796e-02  1.00397426e-01 -1.59997837e-01
  1.05917563e-01 -1.70066534e-01  1.27727522e-01 -2.06111717e-01
 -1.95809757e+00]
supnorm grad right now is: 4.281884275397563
Weights right now are: 
[ 8.58227972e-01  3.12147870e+00  2.67655888e+00  3.58959862e+00
 -1.64844721e+00 -3.10701507e+00 -2.10525284e+00 -2.17451557e+00
 -2.68039791e+00 -1.03053846e-01 -1.87918628e+00  7.78695053e+00
  9.80606121e+00  1.60179547e+01  1.07726634e+01  1.44358061e+01
  1.10654260e+01  1.46660983e+01  1.25584617e+01  1.20939047e+01
  1.05350969e+01  1.53416648e+01  1.09387436e+01  1.43318512e+01
 -4.85350216e+00 -1.11356478e+01  2.74632152e+00 -1.10541617e+01
 -1.72420217e+00 -1.27642221e+01  9.38566410e+00 -1.27613990e+01
 -6.62041020e+00 -1.32477463e+01  4.88374239e+00 -1.28699856e+01
  7.94270120e+00  7.05159367e+00  7.16148938e+00  6.69567256e+00
  1.94476930e+01  1.96138426e+01  1.80439375e+01  2.40556274e+01
  1.64188761e+01  1.24782633e+01  2.43672320e+01  2.52596117e+01
 -3.37516382e-03  6.67714807e+00 -7.95411169e-01  1.79988977e+00
  1.68029250e+01  1.34502292e+01  2.41046618e+01  2.49065048e+01
  4.54441445e+00 -5.47471064e+00  4.91299216e+00 -4.39988221e+00
  3.77992360e+00 -4.96676467e+00  4.15416937e+00 -4.75263577e+00
  3.09447104e+01]
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1197.651595297523
gradient value of function right now is: [ 9.20556118e-01  4.84915170e-03  2.88050735e-03  3.71649160e-03
 -9.20556118e-01 -4.84915170e-03 -2.88050735e-03 -3.71649160e-03
 -4.01072332e-01 -1.06910144e-01 -1.94680922e-01 -1.50408654e-01
 -6.37621138e-03 -9.21237366e-04 -2.67768805e-03 -2.54955193e-03
 -2.40328257e-03 -2.91641236e-04 -9.36264017e-04 -7.67046384e-04
 -4.31208326e-03 -5.81440623e-04 -1.75617473e-03 -1.58041551e-03
 -1.40912778e-03 -2.48070754e-03 -1.56510318e-01 -2.37763160e-03
 -9.76017450e-04 -8.22479691e-04  9.69421216e-03 -8.26369897e-04
 -2.22441443e-03 -1.77236503e-03 -4.44865714e-02 -1.76259589e-03
  2.25056763e-05  4.26593471e-04  2.68435540e-01  3.74427161e-04
 -5.72267989e-04 -1.21507971e-03  1.21501543e-04 -9.10060673e-04
 -1.33654034e-03 -1.99754470e-03 -1.15851426e-03 -2.15889421e-03
 -8.12913305e-02 -9.38028241e-02 -1.03386724e-01 -1.10196057e-01
 -1.25694129e-03 -1.91116598e-03 -1.04327530e-03 -2.03866563e-03
 -3.79020341e-02 -7.34884895e-02  4.16220144e-02 -2.93226048e-01
 -1.37617206e-01 -1.11322011e-01 -5.89770359e-02 -2.27314513e-01
 -1.71895324e+01]
supnorm grad right now is: 17.189532356830043
Weights right now are: 
[  0.8290812    2.75844968   1.87553519   3.04662173  -1.61930043
  -2.74398604  -1.30422915  -1.63153868  -2.60164615   0.12616329
  -1.37325807   7.84533597   9.56833071  15.84561772  10.49659796
  15.27637912  11.5194757   14.99408227  12.89556512  13.18415679
  10.55887275  15.3631715   10.8973122   15.28344794  -3.39453677
  -9.54278479   2.53346609  -9.46542598   0.4985804  -11.01683826
  10.02802178 -10.98391864  -3.86428795 -10.61443535   6.10404225
 -10.2283938    9.60871216   8.24308121   7.28862502   7.91567799
  20.18322017  21.03264733  18.50790956  24.73603983  18.15587532
  14.15479922  26.07483136  26.72975407   0.10813352   6.58700231
  -0.66575331   1.82183615  18.55025391  15.15228463  25.81903961
  26.38865784   3.55712438  -4.83231194   4.2524619   -4.44887912
   2.66831081  -4.37063215   3.16076544  -4.19185313  30.82386356]
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1197.7007449343662
gradient value of function right now is: [ 6.73966782e+00  2.38990987e-03  9.33873473e-04  1.55045799e-03
 -6.73966782e+00 -2.38990987e-03 -9.33873473e-04 -1.55045799e-03
 -1.09684124e+00 -5.30837394e-01 -8.85650604e-01  1.07573304e-01
 -4.21184136e-03 -2.75493034e-04 -1.60139363e-03 -8.47856118e-04
 -8.12312715e-04 -5.61983900e-05 -3.09023822e-04 -1.85114600e-04
 -2.22732845e-03 -1.48546983e-04 -8.46439081e-04 -4.67945658e-04
 -2.44678583e-02 -2.30261730e-02 -1.62302642e-01 -2.24074502e-02
  5.13031780e-02  5.04206883e-02  6.54845814e-02  5.02885992e-02
 -1.45206248e-02 -1.35590953e-02 -6.13366246e-02 -1.32812175e-02
  7.01475041e-03  6.57808263e-03  1.72251067e-02  6.33875547e-03
 -5.43938251e-03 -1.07630717e-02 -9.21273609e-03 -9.09244064e-03
 -7.69529904e-03 -1.56907230e-02 -1.23424476e-02 -1.27139257e-02
  8.79708814e-02  9.64000036e-02  1.03997181e-01  9.74536077e-02
 -7.30063388e-03 -1.48255070e-02 -1.17125651e-02 -1.20463978e-02
  1.26569496e-01 -1.43986587e-01  1.04934522e-01 -1.91765230e-01
  2.89901269e-01 -2.71166296e-01  2.53088838e-01 -3.23270611e-01
 -4.12491284e+00]
supnorm grad right now is: 6.739667820026738
Weights right now are: 
[  1.01911024   2.60376021   1.60433927   2.84428122  -1.80932948
  -2.58929657  -1.03303323  -1.42919817  -2.53305296   1.31350284
  -1.30885126   7.96860068   9.59666369  16.40671767  10.6758968
  16.68854856  11.94488597  15.5327054   13.32855183  14.38260278
  10.73681198  15.90682286  11.1733984   16.59546743  -4.59258068
 -10.67250122   2.97047407 -10.5937654    2.25333839  -9.3757235
  10.99085353  -9.35749978  -4.53154854 -11.72626756   6.44430706
 -11.31106333  10.9675141    9.17629249   6.04996019   8.89340487
  19.17456442  20.22526207  17.11280781  23.6853964   17.76656882
  13.43556163  25.5562015   26.23352931   0.14088812   6.94700537
  -0.60763372   1.98759011  18.15193235  14.43976409  25.28627201
  25.89086038   4.48870617  -5.37102657   4.54073334  -3.59895842
   3.45320462  -5.04520363   3.97363659  -4.51704912  30.893549  ]
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1196.21362600501
gradient value of function right now is: [-1.41199883e+01 -2.96989162e-02 -1.81128118e-02 -2.30068550e-02
  1.41199883e+01  2.96989162e-02  1.81128118e-02  2.30068550e-02
  9.00616210e-01  3.77510144e-02  4.69246639e-01  7.74000414e-02
  2.00276641e-02  6.40586965e-04  6.41495326e-03  5.21794888e-03
  2.78732974e-03  8.53026391e-05  8.65467293e-04  7.57805136e-04
  1.11121867e-02  3.46337004e-04  3.50652244e-03  2.93368003e-03
  2.50259451e-02  2.90727576e-02  4.07872539e-01  2.76133712e-02
 -1.11787564e-02 -1.12713626e-02 -3.09071608e-02 -1.11584396e-02
  1.43047124e-02  1.68067518e-02  1.40382949e-01  1.60749974e-02
 -1.41910665e-02 -1.51134534e-02 -4.41389053e-01 -1.42974327e-02
  7.49119336e-03  2.16998566e-02  1.13692482e-02  1.40629500e-02
  1.15266944e-02  3.94379580e-02  1.69759931e-02  2.32095169e-02
 -1.25412347e-01 -6.55287707e-02 -1.16858055e-01 -1.01611182e-01
  1.06891506e-02  3.65505141e-02  1.57604888e-02  2.15081281e-02
 -9.73127828e-02  2.92632455e-01 -8.13165362e-02  1.09508530e+00
 -1.67544885e-01  5.41512434e-01 -1.81410451e-01  9.25589881e-01
 -6.26532080e-02]
supnorm grad right now is: 14.119988321744893
Weights right now are: 
[ 6.07236180e-01  1.51501311e+00  5.91716966e-01  1.78890587e+00
 -1.39745542e+00 -1.50054947e+00 -2.04109200e-02 -3.73822827e-01
 -2.80414610e+00  7.76914257e-01 -1.89239125e+00  6.76876891e+00
  1.06231517e+01  1.71576077e+01  1.17151847e+01  1.80492479e+01
  1.28278093e+01  1.61148355e+01  1.42002656e+01  1.56455423e+01
  1.17253722e+01  1.66019505e+01  1.21723222e+01  1.79200459e+01
 -4.86614943e+00 -1.08525056e+01  3.50363303e+00 -1.07883711e+01
  2.33821871e+00 -9.34953412e+00  1.17976755e+01 -9.33319522e+00
 -4.53147162e+00 -1.16219039e+01  6.52712373e+00 -1.12170478e+01
  1.02372942e+01  8.56543394e+00  5.52669213e+00  8.28358180e+00
  1.98648038e+01  2.09835552e+01  1.75858780e+01  2.42339739e+01
  1.83060064e+01  1.40841069e+01  2.59274673e+01  2.66672904e+01
 -9.88802823e-01  5.82735718e+00 -1.50124740e+00  9.82267856e-01
  1.86827324e+01  1.50894545e+01  2.56435937e+01  2.63164918e+01
  4.36540974e+00 -5.18361349e+00  5.12027116e+00 -3.03999823e+00
  3.55978338e+00 -4.71577453e+00  4.07816206e+00 -4.05820145e+00
  3.08652218e+01]
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1198.443112272565
gradient value of function right now is: [ 2.77134619e+00 -9.89098243e-02 -4.94313777e-02 -7.39538075e-02
 -2.77134619e+00  9.89098243e-02  4.94313777e-02  7.39538075e-02
 -2.94794093e-01 -4.18508048e-01 -6.37395692e-01  3.78908781e-02
  8.34840675e-02  9.88490342e-04  1.63265117e-02  1.75505713e-02
  1.59671856e-02  1.92883912e-04  3.10505300e-03  3.54592669e-03
  4.80607645e-02  5.73912348e-04  9.37860815e-03  1.03126341e-02
 -5.06459561e-05  1.55290355e-03 -1.91649672e-01  1.47586566e-03
  1.46538457e-01  1.41798514e-01  1.54934841e-01  1.41759577e-01
 -2.65973771e-03 -6.57348805e-04 -9.90375551e-02 -6.95253006e-04
 -2.01341058e-02 -9.03261723e-03 -4.22081815e-01 -8.97796012e-03
  6.87028889e-03  4.15130620e-03  1.34482390e-02  1.04936673e-02
  4.04345189e-03  4.06943484e-03  8.97121236e-03  7.86173577e-03
  1.23302146e-01  3.16150706e-02  2.18490814e-01  1.56325903e-01
  3.93449607e-03  3.97319522e-03  8.76373418e-03  7.68255739e-03
 -1.15057515e-01  1.37415137e-01 -5.76498806e-01 -1.71273187e-01
 -1.10044086e-01  4.28953242e-01 -5.61244163e-01  2.59511927e-01
  9.33277680e+00]
supnorm grad right now is: 9.33277679676405
Weights right now are: 
[  1.01084575   2.05362428   1.05470139   2.27559489  -1.80106499
  -2.03916064  -0.48339534  -0.86051184  -2.60254633   2.30578666
  -1.52311295   6.43992763  10.37834085  16.81519306  11.23186472
  17.53525977  13.4350443   16.48741309  14.60546274  16.18033698
  11.67622272  16.41241703  11.88068692  17.59848107  -4.15811667
 -10.1897644    3.36216864 -10.10306589   2.36399267  -9.36481722
  12.84632045  -9.36627578  -3.8411787  -11.26064718   7.21886355
 -10.83163459  11.3083355    9.99194103   5.68514581   9.67932804
  19.7889248   20.14883658  17.46778939  23.84582485  19.62314926
  14.53818753  27.19690503  27.92999519  -0.34398267   5.83176136
  -1.00655714   1.22316681  20.06738482  15.65054299  26.96541071
  27.65963189   3.28089398  -4.93681183   3.97866914  -4.63401483
   2.51619962  -4.16376409   2.81990474  -4.20504461  30.95534417]
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1199.2011000124571
gradient value of function right now is: [-4.88043509e+00  3.78629024e-01  2.46446911e-01  3.17506098e-01
  4.88043509e+00 -3.78629024e-01 -2.46446911e-01 -3.17506098e-01
  2.72490093e+00  3.39637999e-01  2.03759032e+00 -1.03917208e-01
 -2.65105488e-01 -3.67201557e-03 -3.30084441e-02 -9.68603142e-02
 -1.12572404e-01 -1.46290435e-03 -1.51857221e-02 -3.59975154e-02
 -1.99788547e-01 -2.67958494e-03 -2.60958267e-02 -6.76179962e-02
  1.94382940e-01  7.56374883e-02  2.96021212e+00  7.50688597e-02
 -4.62289210e-01 -3.81624949e-01 -5.78017862e-01 -3.82139122e-01
  3.32059216e-02  1.78268893e-02  5.00759591e-01  1.76510635e-02
  3.94591474e-02  4.13537826e-03  1.96199924e+00  4.16989267e-03
  1.69196566e-03  5.39121640e-03  6.55675350e-03  5.41438788e-03
  2.45906694e-03  8.28786080e-03 -1.51851853e-02  5.38547754e-04
 -4.41212405e-01 -3.34280149e-01 -2.34374364e+00 -8.89051717e-01
  2.30893228e-03  7.98906216e-03 -1.55549909e-02  2.30009159e-04
  5.31455736e-02  1.10008604e-01  1.32168252e+00 -1.73302212e-01
 -1.17918100e+00 -5.86123994e-01  1.04394184e+00 -3.80770636e-02
  1.37690687e+01]
supnorm grad right now is: 13.769068738827105
Weights right now are: 
[ 1.05652467e+00  3.35804302e+00  2.20005148e+00  3.50856347e+00
 -1.84674390e+00 -3.34357938e+00 -1.62874544e+00 -2.09348042e+00
 -1.88031351e+00  4.25757542e+00 -4.31663946e-01  6.01209093e+00
  9.17367622e+00  1.72030758e+01  1.01617277e+01  1.69438025e+01
  1.28625345e+01  1.71960193e+01  1.41641663e+01  1.57196962e+01
  1.06758169e+01  1.68801414e+01  1.10076855e+01  1.70061283e+01
 -4.50283955e+00 -1.03713378e+01  3.89857291e+00 -1.02675371e+01
  1.68969124e+00 -1.01818329e+01  1.27429098e+01 -1.01866611e+01
 -3.84086378e+00 -1.19509796e+01  8.07849912e+00 -1.14867737e+01
  1.38680247e+01  1.17654333e+01  5.77404781e+00  1.14917109e+01
  1.77458849e+01  1.88966938e+01  1.48114193e+01  2.15341872e+01
  2.00545173e+01  1.46352579e+01  2.80256330e+01  2.85765707e+01
 -1.35455899e-02  6.24685886e+00 -1.42440731e+00  1.17863917e+00
  2.05207834e+01  1.57664189e+01  2.78094494e+01  2.83259815e+01
  3.27319543e+00 -5.48635115e+00  3.96720744e+00 -4.46927400e+00
  1.02124341e+00 -4.57960897e+00  2.43212000e+00 -4.67329929e+00
  3.11984546e+01]
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1199.7604727675955
gradient value of function right now is: [ 5.80537132e+00  1.29874317e-01  4.40935807e-02  8.31531989e-02
 -5.80537132e+00 -1.29874317e-01 -4.40935807e-02 -8.31531989e-02
 -4.13427241e+00 -1.01771570e+00 -2.86163118e+00 -2.92066723e-01
 -1.60644896e-01 -8.38847213e-04 -1.17133465e-02 -2.79798927e-02
 -1.76401086e-02 -6.74349189e-05 -1.09509812e-03 -2.93316454e-03
 -7.43668048e-02 -3.39334668e-04 -5.03966417e-03 -1.27052776e-02
 -3.05691485e-02 -1.16470141e-02  3.42417045e-01 -1.14945006e-02
  8.71548167e-01  7.44801324e-01  1.13790061e+00  7.42249778e-01
 -6.61793878e-03 -3.96003359e-03  6.43233611e-02 -3.97113757e-03
  1.02597449e-02  1.56977751e-03  9.71564340e-01  1.50639727e-03
 -6.47201055e-03 -1.95345187e-02 -4.04084584e-02 -1.46834868e-02
  5.57823913e-03  3.42283329e-02  5.89995994e-02  1.78884241e-02
 -1.84283221e-01 -2.76352485e-01 -1.39264041e+00 -4.05579512e-01
  5.62234231e-03  3.42942183e-02  5.91883237e-02  1.79662997e-02
 -5.80219779e-03  1.83704064e-01  4.39051754e-01  1.17091857e-02
 -1.55778130e+00  3.68800085e+00  8.30445166e-02  8.21366100e-01
 -7.05274160e+00]
supnorm grad right now is: 7.052741596809906
Weights right now are: 
[  1.35822113   2.81395494   1.17557394   2.73050851  -2.14844037
  -2.7994913   -0.60426789  -1.31542546  -1.9187898    4.57949291
  -0.29198643   5.36655612   9.37832497  17.87860869  10.25498315
  17.3245555   14.11649471  18.39638661  15.24171043  16.82169513
  11.29272934  17.76246255  11.49047347  17.65780536  -5.24357514
 -10.46505635   2.17471021 -10.34768203   1.92580847 -10.04661248
  13.11294508 -10.0495429   -3.51111839 -11.98323289   7.65808038
 -11.48072309  14.48846375  11.8068629    5.66513041  11.57761615
  16.64194281  18.57526541  12.62283024  19.75143818  20.65569889
  14.51547651  29.18631391  29.13675111   0.24667419   6.95949977
  -1.34371812   1.36154496  21.11452065  15.64124461  28.96446156
  28.88109959   3.51372946  -5.36375996   4.07423009  -3.65843211
  -0.34028325  -4.11044325   2.21914116  -4.58014554  30.89971877]
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1204.1942701471519
gradient value of function right now is: [ 2.72146473e+00  6.96345348e-03 -6.24394940e-04  1.33781804e-03
 -2.72146473e+00 -6.96345348e-03  6.24394940e-04 -1.33781804e-03
 -2.01389229e+00 -5.04311664e-01 -9.89773552e-01 -1.59172635e-01
 -2.26531996e-02 -4.86331950e-04 -2.85878441e-03 -4.59169766e-03
 -5.94650159e-05 -9.84292215e-06 -4.55180618e-05 -4.52089076e-05
 -4.52172501e-03 -1.36990393e-04 -7.43718569e-04 -1.13514621e-03
 -4.18824490e-02 -1.12991345e-02 -3.42445997e-01 -1.12499380e-02
  2.72557722e-01  2.30285844e-01  3.83517439e-01  2.28481658e-01
 -3.44293484e-03 -2.63167127e-03  3.06362050e-03 -2.66531840e-03
  8.00479059e-03  1.40137041e-03  3.50020656e-01  1.35635326e-03
 -6.82161913e-03 -1.40573421e-02 -2.61082588e-02 -1.40060775e-02
  4.50079232e-03  1.77601322e-02  7.15078816e-03  1.01439534e-02
 -3.50417324e-02 -9.66277911e-02 -1.58039960e-01 -9.55031791e-02
  4.54882525e-03  1.78387707e-02  7.34481673e-03  1.02377057e-02
  1.46292796e-02  1.71774275e-01  1.41366735e-01 -3.81226970e-02
  5.00690351e-01  5.08563031e-01  1.20432325e-01  4.55383956e-01
  5.26046098e+00]
supnorm grad right now is: 5.260460981388329
Weights right now are: 
[  1.29352652   2.95359579   0.81669447   2.65983294  -2.08374576
  -2.93913215  -0.24538843  -1.2447499   -1.92637759   4.47683114
  -0.13917621   5.20642634   8.88910831  17.96797366   9.75438937
  17.3277149   14.6522417   18.53305432  15.35728421  17.52603737
  11.08860852  17.74483811  11.13982534  17.85202589  -5.55733063
 -11.87978227   2.36767545 -11.71419923   1.59229621 -10.42633752
  12.96379078 -10.4295002   -1.20346538  -9.96699879   8.49401613
  -9.40516385  16.09850594  12.8272784    5.00562741  12.62479835
  16.17361695  18.45380037  11.19224352  18.77900949  21.08081211
  14.01683831  29.20865856  29.39237273  -0.21638322   6.65555622
  -0.93759206   1.37489714  21.5469392   15.14790829  28.98187245
  29.13839584   3.73608966  -5.47060529   3.74164433  -4.27911781
   0.18058764  -4.49215612   2.14512189  -4.75480136  31.09828578]
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1200.2641838952231
gradient value of function right now is: [-9.59061933e-02  1.02049987e-01  3.35357371e-02  6.74899826e-02
  9.59061933e-02 -1.02049987e-01 -3.35357371e-02 -6.74899826e-02
  2.83319335e+00  1.90433164e+00  3.28220917e+00 -2.47802844e-01
 -1.02988680e-01 -6.70316891e-04 -8.04792993e-03 -3.52767588e-02
 -5.88267790e-03 -3.20248480e-05 -4.22583525e-04 -2.31201193e-03
 -4.44886331e-02 -2.71067913e-04 -3.36392654e-03 -1.61392075e-02
 -1.05847364e-02 -4.87095718e-03  2.82130492e-01 -5.00829475e-03
 -1.35079717e+00 -1.13447486e+00 -1.70012069e+00 -1.13058897e+00
  1.16544208e-02  7.84703341e-03  7.70567461e-02  7.73062023e-03
  1.51400012e-02  1.37555051e-03  9.09400936e-01  1.34529450e-03
 -6.03457370e-04  2.37033946e-03 -1.85445502e-02 -1.45993888e-03
 -2.01999756e-02 -6.24602543e-02 -1.18860333e-01 -4.70669305e-02
 -1.62600214e-01 -1.31861414e-01 -7.81558496e-01 -2.54917654e-01
 -2.01174329e-02 -6.22395804e-02 -1.18513085e-01 -4.69046872e-02
  1.73086208e-01 -7.28884107e-01  7.95486990e-01 -1.09091437e+00
  2.26924034e+00 -5.89331037e+00  9.31683342e-01 -2.24458245e+00
  1.12340554e+01]
supnorm grad right now is: 11.234055367450908
Weights right now are: 
[  1.31767398   2.96313113   0.83278344   2.69299822  -2.10789322
  -2.9486675   -0.2614774   -1.27791518  -1.75524881   4.66621447
  -0.11480875   4.65917207   9.1269438   20.24530637  10.56266612
  17.69248158  15.2375978   20.04997999  16.26054481  18.40926804
  11.30121373  19.84168682  11.87194629  18.24156775  -5.01518345
 -11.6047259    3.06193574 -11.4130533    1.22051253 -10.80314633
  12.80212395 -10.80877325  -1.19593866 -10.4879979    8.02851239
  -9.85981074  16.12085976  12.56930829   4.40134649  12.35054079
  17.70617303  19.29190852  10.89503541  19.4133041   21.27134721
  14.03050162  29.10642816  29.39876793  -1.11567612   5.4932557
  -1.3730911    0.6368745   21.73491158  15.16100385  28.87009316
  29.13962944   3.90407806  -5.55817715   3.6521133   -4.28054903
   0.36696391  -4.76747999   2.62408912  -4.97010299  31.27268367]
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1199.8774632789552
gradient value of function right now is: [ 6.22331357e+00  3.19403076e-01  7.77038714e-02  2.03196544e-01
 -6.22331357e+00 -3.19403076e-01 -7.77038714e-02 -2.03196544e-01
 -4.30383505e+00 -1.43231406e+00 -2.63345142e+00 -4.45344566e-01
 -2.97342996e-01 -1.77983411e-03 -1.93461659e-02 -9.15970720e-02
  2.04037266e-03  9.07695517e-06  1.14508401e-04  7.83196161e-04
 -1.06119915e-01 -5.74607595e-04 -6.55930561e-03 -3.53690752e-02
  4.26384598e-02 -1.35280513e-02  7.75817428e-01 -1.33158426e-02
  8.96611982e-01  7.44703743e-01  1.17439030e+00  7.40339684e-01
 -4.40633757e-02 -4.17002515e-02  4.08906145e-02 -4.14415619e-02
  6.62495210e-02  3.99424496e-03  2.04881020e+00  3.88543920e-03
 -1.22525921e-02 -4.14677426e-02 -1.58743213e-01 -3.32702213e-02
  4.75412572e-03  5.11782359e-02  6.12603275e-02  1.66265807e-02
 -2.63521961e-01 -4.19776481e-01 -2.10398635e+00 -5.38765730e-01
  4.81073340e-03  5.14074477e-02  6.17385837e-02  1.67636167e-02
 -6.32832529e-02  1.54118588e-01  7.51650452e-01  2.72491571e-01
 -1.51749006e+00  3.66670883e+00  1.97065207e-01  7.04985599e-01
 -4.67562505e+00]
supnorm grad right now is: 6.223313566634265
Weights right now are: 
[  1.4328606    2.98992361   0.20694468   2.44381455  -2.22307983
  -2.97545997   0.36436137  -1.0287315   -2.02709734   4.22373928
  -0.42279308   5.17588125   8.67486351  20.87071504  10.17226335
  17.47285201  16.78807511  20.61003937  17.26194868  20.2135138
  11.23248673  20.35512926  11.64560389  18.33866887  -3.54744546
 -10.67816561   3.30982607 -10.45202675   1.50483939 -10.58076455
  13.1507318  -10.58517491  -0.15804914  -9.83563035   8.5425138
  -9.16159427  17.32483006  11.70698457   4.21651257  11.52899498
  17.51395069  19.47576515   9.18180142  18.52224364  21.92506851
  14.2445416   30.12884282  30.03368526  -0.998689     5.83088659
  -1.31393459   0.68687632  22.3781651   15.37039761  29.8807925
  29.76614048   3.8417852   -5.58360241   3.88784089  -3.3960122
  -0.44601147  -4.24115719   2.42431209  -4.7275236   30.89332532]
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1200.0065552449266
gradient value of function right now is: [ 4.69504191e+00  6.79550779e-02  3.24082806e-03  2.57832971e-02
 -4.69504191e+00 -6.79550779e-02 -3.24082806e-03 -2.57832971e-02
 -4.01992495e+00 -8.43817041e-01 -2.47431936e-01 -1.76493936e-01
 -1.02283632e-01 -1.01298886e-03 -4.00390991e-03 -9.84741739e-03
  2.75949702e-03  2.67225519e-05  1.06956815e-04 -2.27856706e-04
 -1.60280529e-02 -1.54427779e-04 -6.29522623e-04 -9.66238395e-04
 -2.87213185e-02 -1.92967636e-02 -1.87101854e-01 -1.93269395e-02
  8.72697346e-01  6.60594117e-01  1.09528968e+00  6.59425045e-01
 -9.19257293e-04 -2.90947317e-03  1.39815381e-02 -2.90683121e-03
  3.11263448e-02  2.15115576e-03  5.24652491e-01  2.11176151e-03
 -8.86686189e-03 -2.32743423e-02 -7.35298150e-02 -1.91613156e-02
  6.89718036e-03  3.07966137e-02  7.77806226e-02  1.81652860e-02
  2.59139649e-02 -8.03991805e-02 -2.02497572e-01 -7.95609493e-03
  6.92059909e-03  3.08504697e-02  7.80855752e-02  1.82188202e-02
 -1.85723504e-02  2.47727781e-01 -3.29633776e-03 -1.02462813e-01
 -1.15665164e+00  5.00234149e+00 -1.31970069e-01  8.40627718e-01
 -6.75693545e-01]
supnorm grad right now is: 5.002341493334415
Weights right now are: 
[  1.56161174   2.65726563  -0.80019924   1.77973384  -2.35183098
  -2.642802     1.37150528  -0.3646508   -1.87546559   4.58489412
  -0.04089694   5.51558666   8.67575388  20.98473771  10.1042082
  17.07369918  17.87822245  21.68650667  18.60843555  21.52205658
  11.78955678  20.70233079  11.94606397  18.50012909  -2.62897576
 -11.29461127   3.06792793 -10.93760489   1.50721748 -10.60694513
  13.29526834 -10.61270887   2.6805433   -6.23503567   9.72536778
  -5.57420007  17.1491635   11.37083564   4.34781978  11.23217018
  18.4320514   20.12190011   8.7513005   18.6097211   22.68139808
  14.35276651  30.75074965  30.59035414  -0.04904851   6.46298991
  -1.01483587   1.3620818   23.13052582  15.47599832  30.48798612
  30.31702032   3.98464179  -5.13061362   3.44581539  -3.86700455
  -0.98386988  -3.89344869   2.27126083  -4.53920822  30.86711184]
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1205.0930747404532
gradient value of function right now is: [ 1.08442792e+00  1.68415492e-02  2.68552183e-04  4.57698467e-03
 -1.08442792e+00 -1.68415492e-02 -2.68552183e-04 -4.57698467e-03
 -8.28899378e-01 -2.55113373e-01 -3.35508225e-02 -1.40876317e-01
 -2.87351719e-02 -3.98342756e-04 -1.30872871e-03 -7.28129615e-03
  3.03281016e-04  6.08058265e-06  1.95284038e-05  9.05065004e-05
 -2.96643916e-03 -4.46501500e-05 -1.48347935e-04 -8.19197848e-04
 -1.89565895e-02 -4.72976591e-03 -1.88287290e-01 -4.72502977e-03
  6.52957655e-02  6.28780085e-02  9.08993798e-02  6.20184539e-02
 -3.66742306e-04 -7.09127643e-04  4.84988134e-03 -7.07812747e-04
  6.62581653e-03  1.18749052e-03  3.82025533e-01  1.14522695e-03
 -3.37976370e-03 -8.26916297e-03 -8.42501051e-03 -5.70309255e-03
  8.78047829e-04  6.64591121e-03 -4.48567314e-03  1.45872905e-03
 -1.36453364e-02 -5.87764414e-02 -2.86969387e-01 -6.83125470e-02
  9.30855748e-04  6.77568857e-03 -4.23486466e-03  1.55322721e-03
  2.20233935e-02  3.87044249e-02  2.47415407e-01 -2.63852330e-02
  2.12740262e-01 -1.87447350e-01  1.09360427e-01  8.11619794e-02
 -5.06128319e+00]
supnorm grad right now is: 5.061283194715144
Weights right now are: 
[  1.30623856   2.67535576  -0.85905364   1.70991599  -2.0964578
  -2.66089212   1.43035968  -0.29483295  -1.48168809   4.32212256
   0.31305549   5.81984899   8.84451736  21.75534371  10.31615564
  16.51725173  18.32110674  21.43860149  18.86131306  22.5963397
  12.31552637  21.63715097  12.27789972  18.40011568  -3.55136096
 -12.46522066   2.6158893  -12.03230352   1.13059991 -10.82942311
  13.03938218 -10.84206025   4.06173577  -4.48731772  10.60793965
  -3.82814739  16.43725864  11.90973324   4.64644866  11.78682281
  18.34038478  20.04245192   9.81795161  18.5804592   23.11170967
  14.5821267   30.15165777  30.75541439   0.5512305    6.73955103
  -1.41097933   1.50467707  23.57488451  15.71194492  29.88267856
  30.48827174   4.18856435  -5.21326022   3.68401738  -3.88982844
  -0.42176064  -4.58721363   2.94299542  -4.63140785  31.06829308]
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1204.9529942343788
gradient value of function right now is: [ 1.19062326e+00  2.71291924e-02  1.23821651e-03  8.23017995e-03
 -1.19062326e+00 -2.71291924e-02 -1.23821651e-03 -8.23017995e-03
 -1.13131996e+00 -4.14500219e-01  1.18338894e-03 -1.27866032e-01
 -4.00600800e-02 -4.66894238e-04 -1.41892870e-03 -1.18285073e-02
  8.87350647e-04  8.65587707e-06  2.81983776e-05  3.06763907e-04
 -3.70363373e-03 -4.14345564e-05 -1.29198745e-04 -1.18127970e-03
 -1.34187069e-02 -2.97237934e-03 -1.54830014e-01 -2.96181075e-03
  2.18909770e-01  1.87800564e-01  2.71846890e-01  1.86664293e-01
  1.96594035e-05 -2.27970924e-04  6.08908917e-03 -2.28776565e-04
  7.95477020e-03  1.09077734e-03  4.53313660e-01  1.04928631e-03
 -4.48867652e-03 -1.07893949e-02 -1.42374906e-02 -7.86246936e-03
  2.32152888e-03  1.27158270e-02  9.63732052e-03  5.31914994e-03
  4.45080345e-04 -5.21275536e-02 -3.42202878e-01 -5.50497662e-02
  2.36798931e-03  1.28221986e-02  9.85052501e-03  5.39974449e-03
  1.35416531e-02  8.83037513e-02  2.21597356e-01  4.07816740e-02
 -1.24849964e-01  6.26198590e-01  6.36782882e-02  2.73755586e-01
 -4.87587448e+00]
supnorm grad right now is: 4.8758744778706316
Weights right now are: 
[  1.07191109   2.06417356  -2.09161918   0.81987037  -1.86213033
  -2.04970992   2.66292523   0.59521268  -1.29701842   4.24886114
  -0.36311867   5.07687589   9.03717761  22.11191256  10.67831661
  16.72544219  17.50331562  21.28651173  18.68577943  21.98513035
  12.96232631  21.99447619  12.52659977  18.89798418  -3.56874166
 -11.974527     1.8230854  -11.51428948   1.43207028 -10.50660848
  13.38101151 -10.51658291   4.27380004  -4.24097174  10.75350172
  -3.58192307  16.6717286   12.24035889   4.57500705  12.09693752
  17.96506124  19.88385994   8.82596154  18.26039425  22.9962921
  14.38089719  30.66040744  30.63790415   0.40652626   6.42320229
  -1.37274703   1.32690649  23.46261962  15.51173041  30.38513922
  30.37194263   4.35278258  -5.64422446   3.98768217  -4.08181053
  -0.93857577  -4.18258272   3.03426013  -4.95302058  31.11009143]
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1204.8299886918405
gradient value of function right now is: [ 1.48957289e+00  1.92656378e-02  7.08629293e-04  4.75715910e-03
 -1.48957289e+00 -1.92656378e-02 -7.08629293e-04 -4.75715910e-03
 -1.65906953e+00 -5.55206485e-01 -3.61895246e-02 -2.41075777e-01
 -2.76055047e-02 -3.80782760e-04 -1.17795358e-03 -1.17443282e-02
  5.29026955e-04  7.53059927e-06  2.47950015e-05  3.32544766e-04
 -1.69214192e-03 -2.37011101e-05 -7.54975839e-05 -8.37919612e-04
 -1.52568145e-02 -2.77126771e-03 -1.92787724e-01 -2.77749518e-03
  3.84086708e-01  3.12623054e-01  4.91827963e-01  3.11291165e-01
 -3.94044767e-03 -3.50929295e-03 -5.04173260e-03 -3.50246864e-03
  6.42905037e-03  1.06587213e-03  5.40071715e-01  1.02078680e-03
 -4.61043507e-03 -1.23956581e-02 -1.05549006e-02 -7.99925687e-03
  3.13439550e-03  1.95119731e-02  2.88231896e-02  7.61604091e-03
 -9.07958090e-02 -1.65102997e-01 -5.51931788e-01 -1.75392237e-01
  3.17409468e-03  1.96068039e-02  2.90619004e-02  7.68470309e-03
  1.92508147e-03  1.19588856e-01  2.93001232e-01  1.22988465e-01
 -6.55210891e-01  1.78715033e+00  2.54595220e-02  3.94186866e-01
 -4.81757409e+00]
supnorm grad right now is: 4.8175740923047465
Weights right now are: 
[  1.75456481   2.64300795  -1.69711436   1.20723564  -2.54478405
  -2.62854431   2.26842041   0.20784741  -1.61047509   4.49631464
  -2.37965806   4.69190048   8.62609247  23.98827153  12.49537087
  16.70135439  18.82073343  21.22540178  18.90139468  23.3757657
  14.03595708  22.8652337   13.40040179  19.87347007  -4.15573137
 -13.48222536   2.39218837 -12.94214994   1.47154569 -10.53564607
  13.66497939 -10.54179533   4.55429205  -3.6359156    9.60766427
  -2.95991888  16.70605723  12.06400379   3.9073559   11.91927845
  20.02061667  21.50574579   7.76873862  20.07741192  23.43529322
  13.67037072  30.99086584  30.96210572  -0.54738667   5.82408904
  -1.66839958   0.55974376  23.94315675  14.8338534   30.717512
  30.73030663   4.49878117  -5.00607084   4.20975422  -3.83720306
  -0.93301925  -4.14179537   2.98253464  -4.55913994  30.80605214]
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1204.9917356867675
gradient value of function right now is: [ 1.08577383e+00  1.51337243e-03 -1.44333506e-03 -2.54915891e-03
 -1.08577383e+00 -1.51337243e-03  1.44333506e-03  2.54915891e-03
 -1.32530524e+00 -4.73991137e-01 -3.18570877e-02 -2.28226893e-01
 -9.96480338e-03 -2.96962265e-04 -9.17727888e-04 -7.03535107e-03
 -8.21370695e-04  4.92621789e-06  1.25154376e-05 -6.46856808e-05
  1.96773068e-04 -1.41828212e-05 -4.24314740e-05 -2.29725721e-04
 -1.12073327e-02 -1.74877727e-03 -1.95761139e-01 -1.75622372e-03
  3.28810936e-01  2.68752627e-01  4.23397447e-01  2.67456321e-01
 -4.69311742e-03 -4.15986798e-03 -1.16945917e-02 -4.15288994e-03
  5.22254813e-03  9.61492282e-04  4.36526852e-01  9.20918962e-04
 -4.33894491e-03 -1.08548679e-02 -3.70181775e-03 -7.11190950e-03
  3.43102628e-03  1.76167968e-02  2.35308197e-02  7.43622673e-03
 -8.53106244e-02 -1.51521333e-01 -4.22048491e-01 -1.57207736e-01
  3.46781319e-03  1.76991514e-02  2.37404376e-02  7.49731002e-03
 -1.57165114e-03  1.39385687e-01  2.54224215e-01  1.37004913e-01
 -4.57811316e-01  1.45802120e+00  1.49725462e-02  3.98611457e-01
 -4.64864006e+00]
supnorm grad right now is: 4.6486400606155245
Weights right now are: 
[  1.54577533   2.39985126  -1.8988378    0.97076288  -2.33599457
  -2.38538762   2.47014385   0.44432017  -1.38543713   4.80188986
  -2.03022269   5.19367485   9.34281325  25.093744    13.25557782
  16.05203466  18.92216753  21.10461925  19.46850512  24.42701852
  15.24652646  23.75119336  14.12582195  20.15509469  -3.84503689
 -13.57521985   2.4683566  -12.96195375   1.05969489 -10.92719796
  13.45119128 -10.93950892   5.11124928  -2.83708547  10.60776827
  -2.12905931  16.82557728  12.66795925   4.14022731  12.52845351
  19.58786381  21.14335162   6.9523618   19.61986195  23.60401376
  13.91505027  30.98836772  31.01563004   0.19030469   6.39000307
  -1.47513991   1.60871173  24.12330321  15.08423751  30.70475377
  30.78839688   4.92449418  -5.44829341   3.28720348  -4.62176767
  -0.83708643  -4.49132097   3.12865037  -5.09694318  31.04311227]
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1204.8107782105012
gradient value of function right now is: [ 1.46078368e+00  4.84943500e-03 -1.20779495e-03 -1.65515708e-03
 -1.46078368e+00 -4.84943500e-03  1.20779495e-03  1.65515708e-03
 -1.82246466e+00 -5.97744223e-01 -3.22115040e-02 -2.30689984e-01
 -1.35977334e-02 -2.88151433e-04 -8.97375574e-04 -8.28485308e-03
 -6.75297839e-04  5.11763087e-06  1.41216977e-05 -7.67387263e-06
  2.68280517e-05 -1.02559344e-05 -3.14851183e-05 -2.25687174e-04
 -1.34014518e-02 -2.44447917e-03 -1.87179754e-01 -2.44354644e-03
  4.66502117e-01  3.75252074e-01  5.97594812e-01  3.73516491e-01
 -5.93193779e-03 -5.00513425e-03 -1.56365207e-02 -4.99378459e-03
  5.97461789e-03  9.82445638e-04  4.55989470e-01  9.41881336e-04
 -4.77048080e-03 -1.23959852e-02 -8.14651363e-03 -8.02884907e-03
  5.12390101e-03  2.44990047e-02  3.60329540e-02  1.08552273e-02
 -8.85309127e-02 -1.65118111e-01 -4.51943582e-01 -1.60585960e-01
  5.15756423e-03  2.45688562e-02  3.62445663e-02  1.09107219e-02
 -1.11672031e-02  2.09748096e-01  2.40844091e-01  2.35744523e-01
 -6.91463474e-01  2.22999848e+00 -1.62070804e-02  5.81594067e-01
 -4.15826740e+00]
supnorm grad right now is: 4.158267400686239
Weights right now are: 
[  1.52184155   3.02327842  -1.66258533   1.27084484  -2.31206078
  -3.00881478   2.23389138   0.14423821  -1.01687301   4.89277403
  -1.82755737   5.80097212   9.02652737  26.61096394  13.98645667
  14.97884002  19.82885332  21.29195431  20.23992062  26.21819144
  17.26882348  24.34785834  15.16531496  21.69269544  -5.06280084
 -14.82248654   2.54846018 -14.19400984   1.23960091 -10.66360106
  13.64941556 -10.67676604   5.49309885  -2.22501405  11.52597004
  -1.50496453  16.73937842  12.8979322    4.46805478  12.74063186
  20.53994985  21.50254565   6.1106984   19.75855097  23.69592243
  14.02802501  30.99705475  31.19270004   1.09939863   7.09495595
  -1.83396577   2.23347029  24.22370246  15.20556915  30.71327089
  30.97277629   4.36660156  -5.57886156   3.27600653  -4.37492823
  -0.51718722  -4.5874199    3.17178399  -5.10055133  30.96033876]
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1076.8437748233544
W_T_median: 1053.0900195608708
W_T_pctile_5: 961.4047233688926
W_T_CVAR_5_pct: 935.6556108139042
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.25
F value: -1204.8107782105012
-----------------------------------------------
