Starting at: 
2022-06-20 18:03:38
tracing parameter entered from terminal:  10.0


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[ 0.10347998  0.18844875 -0.3666709   0.62803316 -0.89369922 -0.17398511
  0.93797695  0.78704989 -0.60791207 -0.16293226 -0.31685198  0.28094308
  0.0404241   0.17453202  0.0940472   0.01169373  0.2300954  -0.23784803
  0.78511084 -0.41859022  0.4809118  -0.01155852  0.07219357 -0.14482284
  0.4701344  -0.18827011 -0.8138637  -0.24629474  0.28361272  0.33354483
 -0.63777411 -0.25343004 -0.81551088 -0.26234589  0.20198453 -0.15135741
  0.25264285 -0.29817275  0.41496663 -0.58895503 -0.60305385 -0.63454123
  0.3979274   0.74701442  0.57452389 -0.67377327  0.6493153   0.07340044
 -0.29694484  0.52758424 -0.14347696  0.04319718 -0.28527617 -0.63077443
  0.13133703 -0.58713125  0.12759166  0.87507529 -0.19770888 -0.66759109
  0.25529887 -0.48501395  0.58877641 -0.72315372] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1260.6521530687958
W_T_median: 1222.3920506735662
W_T_pctile_5: 834.1581876304141
W_T_CVAR_5_pct: 746.6575474940535
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.30695825839
gradient value of function right now is: [ 1.92505661e-02  1.68922492e-01  2.21804290e-01  2.21570788e-01
 -1.92505661e-02 -1.68922492e-01 -2.21804290e-01 -2.21570788e-01
  4.70851442e-03  2.81451102e-02  1.73246546e-03  2.81319243e-02
  1.73847901e-02  1.03895441e-01  6.39783102e-03  1.03846058e-01
  3.11656061e-03  1.86304939e-02  1.14668398e-03  1.86218038e-02
  2.48217395e-03  1.48405533e-02  9.13120684e-04  1.48337084e-02
 -1.09883778e-04 -8.41113661e-04 -6.21530966e-04 -1.01331059e-03
  1.20564947e-04  9.15539313e-04  6.77809637e-04  1.10486291e-03
 -2.55572132e-04 -1.94637485e-03 -1.43965855e-03 -2.34712280e-03
  1.43827430e-04  1.05470852e-03  7.92560714e-04  1.28662444e-03
  1.76490542e-04  3.15505760e-04  2.14228753e-04  3.11673637e-04
  4.03498280e-04  5.93002788e-04  4.64536645e-04  5.83967437e-04
  5.04172809e-04  1.26867815e-03  7.10007304e-04  1.25784852e-03
  8.30290366e-05  1.01057055e-04  8.88956508e-05  9.92941294e-05
  2.92048940e-05 -5.33727292e-06  1.06879512e-04 -6.14717694e-05
  5.68702917e-05  6.62255470e-05  7.45560978e-05 -1.94283436e-05
 -2.69612074e+00]
supnorm grad right now is: 2.6961207435629415
Weights right now are: 
[-1.20468604e+00 -1.22837585e+00 -2.09030480e+00 -1.08349973e+00
  4.14466802e-01  1.24283948e+00  2.66161085e+00  2.49858278e+00
  4.71007850e-01  9.15092259e-01  7.66998350e-01  1.36450454e+00
  3.19835144e-01 -5.02417414e-01  5.13992946e-01 -6.79132599e-01
 -1.18119677e+00 -1.81944600e+00 -5.96423040e-01 -2.00415600e+00
 -1.14636789e+00 -1.79432987e+00 -1.50618240e+00 -1.92081581e+00
  1.46316534e+00  7.77303768e-01  1.69127291e-01  7.46545411e-01
 -1.20261159e+00 -1.31022444e+00 -2.21897827e+00 -1.85013687e+00
  3.37365614e-01  9.47433293e-01  1.38709685e+00  1.12312499e+00
 -1.13267349e+00 -1.81251622e+00 -1.04305708e+00 -2.13025340e+00
  3.90623981e-01  3.51767336e-01  1.40070104e+00  1.73768715e+00
  1.31237689e-01 -1.43943783e+00 -1.13115226e-01 -7.65035493e-01
 -2.48679824e-01  1.96673703e-01 -4.71662209e-01 -4.01497490e-01
 -1.70922356e+00 -2.05862754e+00 -1.28644434e+00 -2.01509718e+00
  7.95492019e-01  1.44980004e+00 -8.29582654e-01 -1.41458929e+00
  1.39881888e-02  4.30512417e-01 -7.36290084e-01 -1.46992678e+00
  2.47969357e+01]
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.713366700133
gradient value of function right now is: [ 8.30521231e-03  7.63823553e-02  8.52876029e-02  8.52862957e-02
 -8.30521231e-03 -7.63823553e-02 -8.52876029e-02 -8.52862957e-02
  2.01728254e-03  1.21465929e-02  7.04752123e-04  1.21363828e-02
  4.04142056e-03  2.43274965e-02  1.41237232e-03  2.43068324e-02
  1.19322949e-03  7.18513228e-03  4.16853012e-04  7.17910320e-03
  9.13174583e-04  5.49956881e-03  3.18955040e-04  5.49497955e-03
  4.98433224e-05  3.94048075e-04  2.94848667e-04  4.66349843e-04
  4.62878205e-05  3.52160023e-04  2.67064624e-04  4.21158117e-04
 -5.00341249e-05 -3.81509984e-04 -2.89156636e-04 -4.56024512e-04
  5.14522487e-05  3.79301472e-04  2.91242890e-04  4.57897091e-04
  2.15609498e-05  2.97834336e-05  2.39692595e-05  2.92058426e-05
  9.03171256e-05  1.23141675e-04  1.01627092e-04  1.20644017e-04
  1.37878553e-04  3.40179514e-04  1.94956527e-04  3.36805322e-04
  2.01791713e-05  2.34157985e-05  2.13133077e-05  2.28751137e-05
  1.10658113e-05 -1.84830260e-06  2.56076285e-05 -1.63187222e-05
  2.88540299e-05  3.14429376e-05  2.76876695e-05 -6.16247414e-06
 -3.90007626e-01]
supnorm grad right now is: 0.39000762573144393
Weights right now are: 
[-1.21340121e+00 -1.33717302e+00 -2.19266774e+00 -1.18760428e+00
  4.23181978e-01  1.35163666e+00  2.76397379e+00  2.60268733e+00
  4.60738642e-01  8.51791583e-01  7.63513157e-01  1.30204302e+00
  2.40979211e-01 -9.57233693e-01  4.86960873e-01 -1.12610291e+00
 -1.18504043e+00 -1.84000476e+00 -5.97742588e-01 -2.02416500e+00
 -1.15801847e+00 -1.84498293e+00 -1.51028962e+00 -1.96946549e+00
  1.46298986e+00  7.75519765e-01  1.67911545e-01  7.45240868e-01
 -1.20487885e+00 -1.32756344e+00 -2.23205487e+00 -1.86035176e+00
  3.38756435e-01  9.59870050e-01  1.39571258e+00  1.13220214e+00
 -1.13387453e+00 -1.82227341e+00 -1.05015003e+00 -2.13664141e+00
  3.84757331e-01  3.43402782e-01  1.39408817e+00  1.72779220e+00
  1.02231862e-01 -1.46496135e+00 -1.35331068e-01 -7.91892192e-01
 -2.71869049e-01  1.53663721e-01 -4.98286680e-01 -4.49265103e-01
 -1.71307352e+00 -2.06182472e+00 -1.28946471e+00 -2.01847929e+00
  7.85294363e-01  1.45638370e+00 -8.55199386e-01 -1.37393483e+00
 -8.87778057e-03  4.02277227e-01 -7.48121319e-01 -1.46187438e+00
  2.49435824e+01]
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.262058339122
gradient value of function right now is: [ 3.93771776e-03  3.32344222e-02  3.50424715e-02  3.50755705e-02
 -3.93771776e-03 -3.32344222e-02 -3.50424715e-02 -3.50755705e-02
  9.80399590e-04  5.74726413e-03  3.19721222e-04  5.74057883e-03
  1.11489197e-03  6.53375062e-03  3.63750185e-04  6.52608908e-03
  5.00833468e-04  2.93606994e-03  1.63326570e-04  2.93265733e-03
  3.66856637e-04  2.15093377e-03  1.19608303e-04  2.14844296e-03
  3.29462552e-05  2.62991955e-04  2.01342607e-04  3.09966728e-04
  1.58389764e-05  1.21700323e-04  9.43026485e-05  1.44857415e-04
 -1.35366887e-05 -1.04317961e-04 -8.07738475e-05 -1.24084428e-04
  1.68801066e-05  1.25917618e-04  9.86156853e-05  1.51139873e-04
 -5.38240353e-08 -4.80456784e-06 -1.44751356e-06 -4.81603915e-06
  2.31335579e-05  2.90619526e-05  2.53987724e-05  2.83421817e-05
  4.25956414e-05  1.02657980e-04  6.06880700e-05  1.01551998e-04
  5.54580459e-06  6.05577652e-06  5.75646085e-06  5.88736567e-06
  4.04765220e-06 -6.78299061e-07  6.98364714e-06 -4.87912427e-06
  1.21844983e-05  1.36445793e-05  1.02762943e-05 -2.18814980e-06
 -3.62261841e+00]
supnorm grad right now is: 3.6226184097918908
Weights right now are: 
[-1.22461107 -1.47375524 -2.30859866 -1.30562618  0.43439184  1.48821888
  2.87990471  2.72070923  0.44740768  0.77042096  0.75926151  1.22177737
  0.18497039 -1.27753478  0.4689012  -1.44077688 -1.18942993 -1.86326257
 -0.59915928 -2.04679346 -1.17077959 -1.89994828 -1.51451925 -2.02223956
  1.46097862  0.7563614   0.15458155  0.73090335 -1.20715148 -1.34523197
 -2.24564    -1.870663    0.33961822  0.96769252  1.40124661  1.13785797
 -1.13501537 -1.83173411 -1.05714314 -2.14276664  0.38328978  0.34241676
  1.39276572  1.72665329  0.08351819 -1.48075195 -0.14955414 -0.80843775
 -0.29035662  0.11934831 -0.51992961 -0.48734312 -1.7157325  -2.06401154
 -1.29155487 -2.02078249  0.77470328  1.46138834 -0.87338444 -1.345248
 -0.03797475  0.36442723 -0.76043157 -1.45568796 24.71817917]
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15991.156463728348
gradient value of function right now is: [ 1.86619224e-03  1.34770565e-02  1.38590610e-02  1.38834489e-02
 -1.86619224e-03 -1.34770565e-02 -1.38590610e-02 -1.38834489e-02
  4.81252310e-04  2.70476310e-03  1.45124251e-04  2.70087024e-03
  3.30824199e-04  1.85881160e-03  9.98206871e-05  1.85611877e-03
  2.04411292e-04  1.14886352e-03  6.16422697e-05  1.14721039e-03
  1.43072946e-04  8.04213108e-04  4.31335725e-05  8.03059175e-04
  1.35327714e-05  1.10176610e-04  8.59949084e-05  1.29391732e-04
  5.17980319e-06  4.04003115e-05  3.19249995e-05  4.79463016e-05
 -5.21523656e-06 -4.09404004e-05 -3.22955555e-05 -4.85130782e-05
  5.22531183e-06  3.96171648e-05  3.15970065e-05  4.73745502e-05
 -1.23732586e-06 -3.98028025e-06 -2.11508569e-06 -3.95023590e-06
  7.02192953e-06  8.39871052e-06  7.60644151e-06  8.16131044e-06
  1.45337847e-05  3.44200559e-05  2.09992805e-05  3.40323712e-05
  1.73148104e-06  1.81119189e-06  1.77515076e-06  1.75376626e-06
  1.49612294e-06 -2.54969203e-07  2.24909433e-06 -1.62906394e-06
  4.79733000e-06  5.69552124e-06  3.82675137e-06 -8.28437827e-07
 -7.82202724e+00]
supnorm grad right now is: 7.822027243479116
Weights right now are: 
[-1.23913913 -1.63075237 -2.43666736 -1.43612147  0.44891989  1.64521601
  3.00797341  2.85120452  0.4295731   0.66539563  0.75397881  1.11821082
  0.14123954 -1.51889652  0.45580144 -1.67782363 -1.1944141  -1.88874899
 -0.60065394 -2.07158237 -1.18463568 -1.95754811 -1.51878649 -2.07752559
  1.45821343  0.72967559  0.13560263  0.71098356 -1.20923143 -1.36155295
 -2.25848042 -1.88016673  0.34036368  0.97454657  1.40620759  1.14279817
 -1.13601516 -1.84010552 -1.06346625 -2.14817106  0.38398063  0.34507833
  1.39414509  1.72983302  0.06924806 -1.49167608 -0.16010075 -0.8198297
 -0.30684378  0.08987108 -0.53940269 -0.52002705 -1.71788892 -2.06563539
 -1.29321025 -2.02248387  0.76411225  1.46689627 -0.88781201 -1.31968256
 -0.07037076  0.32065257 -0.77290246 -1.4490591  24.32026752]
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.707268929711
gradient value of function right now is: [ 8.60088697e-04  5.01258338e-03  5.08978342e-03  5.10199138e-03
 -8.60088697e-04 -5.01258338e-03 -5.08978342e-03 -5.10199138e-03
  2.27957367e-04  1.22543229e-03  6.32009907e-05  1.22337803e-03
  9.82174718e-05  5.27865804e-04  2.72499631e-05  5.26976107e-04
  7.74351768e-05  4.16269411e-04  2.14700372e-05  4.15571494e-04
  5.18338838e-05  2.78670873e-04  1.43672842e-05  2.78204721e-04
  4.26978988e-06  3.58096984e-05  2.84304700e-05  4.18578491e-05
  1.61097300e-06  1.28664432e-05  1.03453138e-05  1.52090126e-05
 -2.39749021e-06 -1.93557680e-05 -1.55202848e-05 -2.28234627e-05
  1.48650987e-06  1.15547355e-05  9.36444803e-06  1.37512653e-05
 -3.71456546e-07 -1.22575081e-06 -6.69642627e-07 -1.21725151e-06
  2.51705413e-06  3.11078138e-06  2.77810025e-06  3.02111842e-06
  5.19451619e-06  1.23887411e-05  7.74594671e-06  1.22498330e-05
  6.02450542e-07  6.36069200e-07  6.21501042e-07  6.14857314e-07
  5.47331369e-07 -8.28077411e-08  8.47720219e-07 -5.69240852e-07
  1.75344301e-06  2.32458296e-06  1.38161503e-06 -2.82402506e-07
 -1.63242088e+00]
supnorm grad right now is: 1.6324208800355133
Weights right now are: 
[-1.2580465  -1.80093385 -2.57294376 -1.57508159  0.46782727  1.81539748
  3.1442498   2.99016463  0.40559555  0.5302315   0.74742994  0.98495663
  0.10508632 -1.70989636  0.44581612 -1.86536338 -1.19988745 -1.91554584
 -0.60216794 -2.09763947 -1.19918015 -2.01543592 -1.52291808 -2.13307441
  1.45541716  0.70202554  0.11561363  0.69044128 -1.21107507 -1.37632787
 -2.27029957 -1.88873187  0.34124311  0.98284572  1.41230998  1.14874653
 -1.13684188 -1.84718612 -1.06889663 -2.15271807  0.38527868  0.34862091
  1.39628231  1.73405141  0.05650207 -1.50145637 -0.16956119 -0.83000506
 -0.32264437  0.06134082 -0.5585176  -0.55165197 -1.71981523 -2.06708539
 -1.29468904 -2.0239987   0.7532877   1.47225977 -0.90174271 -1.29592346
 -0.10463358  0.26959895 -0.78566012 -1.44236936 24.87816249]
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.072357333855
gradient value of function right now is: [ 4.09266614e-04  1.84075159e-03  1.85642466e-03  1.86171749e-03
 -4.09266614e-04 -1.84075159e-03 -1.85642466e-03 -1.86171749e-03
  1.08516641e-04  5.62874517e-04  2.77402483e-05  5.61810244e-04
  3.05132408e-05  1.58241894e-04  7.80650777e-06  1.57941327e-04
  2.88833888e-05  1.49816447e-04  7.38427797e-06  1.49533066e-04
  1.85757397e-05  9.63587635e-05  4.74738098e-06  9.61768465e-05
  1.13634576e-06  9.80342674e-06  7.91578503e-06  1.14044401e-05
  5.34715956e-07  4.36384322e-06  3.56932859e-06  5.13734276e-06
 -1.17310137e-06 -9.71021205e-06 -7.91623589e-06 -1.13964841e-05
  4.36296488e-07  3.46909072e-06  2.85662586e-06  4.10869464e-06
  2.55544100e-08 -1.26344438e-07 -3.13910991e-08 -1.28438222e-07
  1.09645449e-06  1.43282945e-06  1.24930788e-06  1.39194260e-06
  2.06363062e-06  4.93961548e-06  3.17891331e-06  4.88372489e-06
  2.49095546e-07  2.69479734e-07  2.60422586e-07  2.60200711e-07
  2.14932781e-07 -2.96728633e-08  3.79367743e-07 -2.30892604e-07
  6.50481500e-07  9.67300661e-07  5.23173533e-07 -1.04402233e-07
  4.74341328e+00]
supnorm grad right now is: 4.7434132812001755
Weights right now are: 
[-1.28175274 -1.96963846 -2.70674351 -1.71159103  0.49153351  1.9841021
  3.27804956  3.12667408  0.37502245  0.36489807  0.7397398   0.82199846
  0.07563704 -1.8591086   0.43832985 -2.01183818 -1.20541344 -1.94150053
 -0.60357562 -2.12287162 -1.21325298 -2.06916654 -1.52659911 -2.18462175
  1.4532105   0.67961384  0.09911432  0.67385094 -1.21265695 -1.38925377
 -2.28083926 -1.89620517  0.34237656  0.99377253  1.42049788  1.15655488
 -1.13748086 -1.85277484 -1.07325877 -2.15629402  0.38583376  0.35074924
  1.39748337  1.7365968   0.04276757 -1.5123454  -0.17998074 -0.84132708
 -0.33883212  0.03258222 -0.57860939 -0.58351892 -1.72180579 -2.06858097
 -1.29622322 -2.02555769  0.74226737  1.47677741 -0.91718409 -1.27259612
 -0.13819199  0.21663239 -0.79846193 -1.43599184 25.29298511]
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.8042130452
gradient value of function right now is: [ 1.98168101e-04  6.58306896e-04  6.61198028e-04  6.63296087e-04
 -1.98168101e-04 -6.58306893e-04 -6.61198026e-04 -6.63296085e-04
  5.01216359e-05  2.53989946e-04  1.18452287e-05  2.53455411e-04
  9.49661302e-06  4.81168650e-05  2.24637913e-06  4.80152180e-05
  1.04054631e-05  5.27286730e-05  2.45950092e-06  5.26176454e-05
  6.45550378e-06  3.27146201e-05  1.52526205e-06  3.26458457e-05
  2.49634970e-07  2.19742176e-06  1.80781781e-06  2.54455496e-06
  1.95599274e-07  1.61734726e-06  1.34788885e-06  1.89646993e-06
 -5.51913906e-07 -4.63898643e-06 -3.85299226e-06 -5.42158383e-06
  1.43285512e-07  1.15640113e-06  9.69026666e-07  1.36302278e-06
  9.48435148e-08  1.09376699e-07  1.02122979e-07  1.05513629e-07
  5.15107277e-07  6.88261889e-07  5.98567165e-07  6.67747235e-07
  8.72967015e-07  2.04853039e-06  1.37204985e-06  2.02340935e-06
  1.12830451e-07  1.22211240e-07  1.18515472e-07  1.17682274e-07
  9.01169083e-08 -1.38269110e-08  1.81352989e-07 -1.06955418e-07
  2.49732596e-07  4.07898491e-07  2.08867692e-07 -4.62074258e-08
 -6.24543316e-02]
supnorm grad right now is: 0.06245433159969254
Weights right now are: 
[-1.31282008e+00 -2.13670833e+00 -2.83852946e+00 -1.84609814e+00
  5.22600848e-01  2.15117197e+00  3.40983551e+00  3.26118119e+00
  3.35735483e-01  1.58804317e-01  7.30610079e-01  6.18910213e-01
  5.06127693e-02 -1.98204185e+00  4.32452263e-01 -2.13248918e+00
 -1.21095434e+00 -1.96674056e+00 -6.04879885e-01 -2.14740350e+00
 -1.22683471e+00 -2.11945519e+00 -1.52988161e+00 -2.23285620e+00
  1.45173069e+00  6.64280170e-01  8.76128915e-02  6.62538857e-01
 -1.21415440e+00 -1.40164285e+00 -2.29114079e+00 -1.90335056e+00
  3.43876427e-01  1.00847578e+00  1.43172266e+00  1.16702590e+00
 -1.13801562e+00 -1.85751164e+00 -1.07702551e+00 -2.15931544e+00
  3.84810244e-01  3.50330557e-01  1.39668596e+00  1.73614210e+00
  2.55469438e-02 -1.52639932e+00 -1.93359747e-01 -8.55932126e-01
 -3.57083466e-01  7.30643182e-04 -6.01790436e-01 -6.18796171e-01
 -1.72421119e+00 -2.07037612e+00 -1.29808267e+00 -2.02742484e+00
  7.31316165e-01  1.48005517e+00 -9.35246575e-01 -1.25082944e+00
 -1.69947041e-01  1.63107552e-01 -8.11399562e-01 -1.42975156e+00
  2.49749361e+01]
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.50547154881
gradient value of function right now is: [ 9.23216221e-05  2.23173448e-04  2.23576724e-04  2.24335684e-04
 -9.23216241e-05 -2.23173453e-04 -2.23576729e-04 -2.24335689e-04
  2.07765347e-05  1.03986511e-04  4.54163407e-06  1.03747123e-04
  2.85906413e-06  1.43081166e-05  6.25572898e-07  1.42750770e-05
  3.52587175e-06  1.76467855e-05  7.70866776e-07  1.76061416e-05
  2.11962869e-06  1.06091080e-05  4.63218247e-07  1.05847065e-05
  6.49627156e-08  5.81988903e-07  4.87524185e-07  6.69829338e-07
  7.69632615e-08  6.43549764e-07  5.45971460e-07  7.50345900e-07
 -2.23880818e-07 -1.90489552e-06 -1.61085075e-06 -2.21366023e-06
  5.73946777e-08  4.69966325e-07  4.00376451e-07  5.50250970e-07
  5.50838966e-08  7.28830216e-08  6.38623290e-08  7.06301580e-08
  2.19645185e-07  2.92478233e-07  2.57017543e-07  2.83344600e-07
  3.50677738e-07  8.08584857e-07  5.59817503e-07  7.98001405e-07
  4.79234408e-08  5.10822693e-08  5.02024177e-08  4.90766417e-08
  3.75013509e-08 -6.09120545e-09  7.96144449e-08 -4.62919647e-08
  9.86250922e-08  1.73229034e-07  8.39001257e-08 -1.95735975e-08
  2.98291785e+00]
supnorm grad right now is: 2.982917845405135
Weights right now are: 
[-1.35356774e+00 -2.29694045e+00 -2.96450146e+00 -1.97470629e+00
  5.63348506e-01  2.31140409e+00  3.53580751e+00  3.38978934e+00
  2.88089843e-01 -8.68483051e-02  7.20361435e-01  3.76886670e-01
  2.95489880e-02 -2.08371130e+00  4.27875112e-01 -2.23225207e+00
 -1.21628534e+00 -1.99060370e+00 -6.06041048e-01 -2.17059255e+00
 -1.23946471e+00 -2.16540961e+00 -1.53270600e+00 -2.27692496e+00
  1.45083453e+00  6.54817547e-01  8.03882998e-02  6.55595525e-01
 -1.21571100e+00 -1.41469145e+00 -2.30217792e+00 -1.91084524e+00
  3.45698124e-01  1.02658680e+00  1.44578527e+00  1.17985479e+00
 -1.13853955e+00 -1.86222867e+00 -1.08083707e+00 -2.16230517e+00
  3.82159492e-01  3.47455518e-01  1.39382747e+00  1.73282489e+00
  5.16337869e-03 -1.54381508e+00 -2.09791556e-01 -8.73943500e-01
 -3.77493422e-01 -3.47939832e-02 -6.28292116e-01 -6.57985624e-01
 -1.72705442e+00 -2.07254149e+00 -1.30030629e+00 -2.02966676e+00
  7.22258077e-01  1.48231238e+00 -9.52749873e-01 -1.23622448e+00
 -1.94214955e-01  1.19624776e-01 -8.24251931e-01 -1.42407883e+00
  2.51715443e+01]
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.76847782414
gradient value of function right now is: [ 4.13458518e-05  7.57128310e-05  7.57251158e-05  7.59929782e-05
 -4.13458436e-05 -7.57128160e-05 -7.57251007e-05 -7.59929632e-05
  7.72987286e-06  3.81732094e-05  1.56226635e-06  3.80787038e-05
  8.84145933e-07  4.36595439e-06  1.78858430e-07  4.35511934e-06
  1.19698924e-06  5.91118706e-06  2.41951924e-07  5.89654853e-06
  7.00221068e-07  3.45807665e-06  1.41473888e-07  3.44952316e-06
  3.81707585e-08  3.44323277e-07  2.93273660e-07  3.94331332e-07
  3.14471821e-08  2.63231098e-07  2.27039445e-07  3.05549270e-07
 -7.82945421e-08 -6.67011635e-07 -5.73567863e-07 -7.71742099e-07
  2.66652607e-08  2.19357490e-07  1.89801191e-07  2.55470347e-07
  1.72369683e-08  1.91347241e-08  1.84126726e-08  1.83825650e-08
  8.30023275e-08  1.06199881e-07  9.55594102e-08  1.02643802e-07
  1.32217739e-07  2.95395667e-07  2.09818133e-07  2.91254904e-07
  1.84495940e-08  1.89253104e-08  1.90251613e-08  1.81325832e-08
  1.51110087e-08 -2.85905085e-09  3.12303673e-08 -1.89760616e-08
  4.03830868e-08  7.10109458e-08  3.38610434e-08 -8.80781229e-09
 -1.06284048e+00]
supnorm grad right now is: 1.0628404827231852
Weights right now are: 
[-1.40499811e+00 -2.44626801e+00 -3.08165412e+00 -2.09433246e+00
  6.14778873e-01  2.46073165e+00  3.65296016e+00  3.50941551e+00
  2.36289288e-01 -3.50890965e-01  7.10030626e-01  1.16791719e-01
  1.19535491e-02 -2.16768726e+00  4.24332390e-01 -2.31464078e+00
 -1.22124839e+00 -2.01256893e+00 -6.07042629e-01 -2.19193324e+00
 -1.25086990e+00 -2.20645673e+00 -1.53506902e+00 -2.31628173e+00
  1.44989625e+00  6.44855980e-01  7.26293403e-02  6.48296725e-01
 -1.21743112e+00 -1.42909654e+00 -2.31457846e+00 -1.91917160e+00
  3.47612508e-01  1.04560995e+00  1.46082410e+00  1.19329571e+00
 -1.13917237e+00 -1.86793570e+00 -1.08552909e+00 -2.16591301e+00
  3.79216608e-01  3.44270048e-01  1.39066056e+00  1.72923882e+00
 -1.33034770e-02 -1.56083390e+00 -2.25966501e-01 -8.91297040e-01
 -3.97529034e-01 -7.00456011e-02 -6.54978154e-01 -6.96343230e-01
 -1.72998621e+00 -2.07477662e+00 -1.30265145e+00 -2.03195645e+00
  7.17431028e-01  1.48330142e+00 -9.62851573e-01 -1.22941903e+00
 -2.07047408e-01  9.63731063e-02 -8.33375132e-01 -1.42114839e+00
  2.49486379e+01]
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15992.583939558594
gradient value of function right now is: [ 1.72678475e-05  2.58227138e-05  2.57996791e-05  2.58929657e-05
 -1.72678506e-05 -2.58227184e-05 -2.57996837e-05 -2.58929704e-05
  2.59011040e-06  1.24361331e-05  4.82536288e-07  1.24039436e-05
  2.84082402e-07  1.36392827e-06  5.29695728e-08  1.36039096e-06
  4.13164893e-07  1.98377023e-06  7.69767802e-08  1.97863502e-06
  2.35879652e-07  1.13258086e-06  4.39260389e-08  1.12965221e-06
  2.44197565e-08  2.22268025e-07  1.91381883e-07  2.53636351e-07
  1.19831362e-08  1.00780193e-07  8.78767123e-08  1.16614301e-07
 -2.34818026e-08 -2.01016199e-07 -1.74770881e-07 -2.31857358e-07
  1.15728672e-08  9.58740602e-08  8.38192490e-08  1.11250942e-07
  1.82978960e-09 -1.44531303e-09  3.33869273e-10 -1.55671873e-09
  2.68919851e-08  3.29189571e-08  3.03310312e-08  3.17601476e-08
  4.49724287e-08  9.91673056e-08  7.12147772e-08  9.77584776e-08
  6.16621988e-09  6.06621186e-09  6.24727153e-09  5.80198914e-09
  5.52142510e-09 -1.04724767e-09  1.05900600e-08 -6.53499992e-09
  1.59665089e-08  2.79409758e-08  1.28564401e-08 -3.30967269e-09
  6.00625474e+00]
supnorm grad right now is: 6.006254736147957
Weights right now are: 
[-1.46708380e+00 -2.58735758e+00 -3.19219908e+00 -2.20722359e+00
  6.76864567e-01  2.60182123e+00  3.76350514e+00  3.62230665e+00
  1.85357716e-01 -6.05582970e-01  7.00696583e-01 -1.34072920e-01
 -3.25062433e-03 -2.23894610e+00  4.21519860e-01 -2.38456548e+00
 -1.22595935e+00 -2.03302657e+00 -6.07915361e-01 -2.21180723e+00
 -1.26134730e+00 -2.24358325e+00 -1.53706248e+00 -2.35188551e+00
  1.44828758e+00  6.27487184e-01  5.88535225e-02  6.35307477e-01
 -1.21911507e+00 -1.44361593e+00 -2.32718888e+00 -1.92807395e+00
  3.49272474e-01  1.06250477e+00  1.47436115e+00  1.20529905e+00
 -1.13993036e+00 -1.87498415e+00 -1.09138712e+00 -2.17041120e+00
  3.77999591e-01  3.43289170e-01  1.38951596e+00  1.72821578e+00
 -2.24594374e-02 -1.57142391e+00 -2.35629651e-01 -9.01804504e-01
 -4.10411502e-01 -9.60912399e-02 -6.74188583e-01 -7.23543830e-01
 -1.73176987e+00 -2.07639869e+00 -1.30429263e+00 -2.03357610e+00
  7.15414045e-01  1.48358350e+00 -9.66842732e-01 -1.22721764e+00
 -2.12570313e-01  8.62392379e-02 -8.37797888e-01 -1.42020756e+00
  2.53745855e+01]
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15992.842948654215
gradient value of function right now is: [ 7.18343696e-06  9.42837909e-06  9.41390920e-06  9.44817008e-06
 -7.18343675e-06 -9.42837881e-06 -9.41390892e-06 -9.44816980e-06
  8.67530204e-07  4.00026506e-06  1.50266492e-07  3.98974301e-06
  1.00715876e-07  4.64399028e-07  1.74585893e-08  4.63175496e-07
  1.54074728e-07  7.10456858e-07  2.66874352e-08  7.08588214e-07
  8.61092013e-08  3.97065809e-07  1.49078430e-08  3.96022519e-07
  1.34304501e-08  1.21994260e-07  1.05690380e-07  1.39195604e-07
  4.57950092e-09  3.83212916e-08  3.36284764e-08  4.43574235e-08
 -6.93267703e-09 -5.90381201e-08 -5.16624689e-08 -6.81226983e-08
  4.83949346e-09  3.99350749e-08  3.51288239e-08  4.63460377e-08
 -1.29551478e-09 -4.12935042e-09 -2.65491571e-09 -4.09822915e-09
  8.69790377e-09  9.88145108e-09  9.44654811e-09  9.49540380e-09
  1.58019641e-08  3.37725667e-08  2.45813771e-08  3.32613238e-08
  2.05770727e-09  1.90371406e-09  2.02651533e-09  1.81324357e-09
  2.04557022e-09 -4.48716002e-10  3.55756951e-09 -2.39036406e-09
  6.42240447e-09  1.08367492e-08  5.00243241e-09 -1.42046854e-09
 -4.89132815e+00]
supnorm grad right now is: 4.891328150480665
Weights right now are: 
[-1.53882927e+00 -2.72506573e+00 -3.30003803e+00 -2.31735508e+00
  7.48610046e-01  2.73952940e+00  3.87134410e+00  3.73243816e+00
  1.38584217e-01 -8.31461943e-01  6.92757815e-01 -3.56597795e-01
 -1.65094361e-02 -2.29929170e+00  4.19237636e-01 -2.44388507e+00
 -1.23062239e+00 -2.05260198e+00 -6.08714234e-01 -2.23082544e+00
 -1.27101658e+00 -2.27745393e+00 -1.53876739e+00 -2.38442909e+00
  1.44608333e+00  6.04868803e-01  4.03078676e-02  6.16332129e-01
 -1.22035222e+00 -1.45418553e+00 -2.33642848e+00 -1.93619713e+00
  3.50513725e-01  1.07470902e+00  1.48437768e+00  1.21463791e+00
 -1.14071876e+00 -1.88212952e+00 -1.09743716e+00 -2.17544706e+00
  3.78017707e-01  3.43953130e-01  1.38983618e+00  1.72889515e+00
 -2.58361154e-02 -1.57546664e+00 -2.39361825e-01 -9.05724933e-01
 -4.16066192e-01 -1.08407936e-01 -6.83044681e-01 -7.35877262e-01
 -1.73252748e+00 -2.07712467e+00 -1.30503781e+00 -2.03427814e+00
  7.14660719e-01  1.48371961e+00 -9.68240080e-01 -1.22635942e+00
 -2.14839130e-01  8.18698663e-02 -8.39575850e-01 -1.41976418e+00
  2.46020560e+01]
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.798906342872
gradient value of function right now is: [ 2.98026877e-06  3.62688974e-06  3.62037319e-06  3.63338856e-06
 -2.98026923e-06 -3.62689031e-06 -3.62037376e-06 -3.63338913e-06
  2.99330751e-07  1.33823351e-06  4.94309803e-08  1.33473541e-06
  3.85577010e-08  1.72379518e-07  6.37171175e-09  1.71928281e-07
  6.01457103e-08  2.68898160e-07  9.93175232e-09  2.68195389e-07
  3.32315050e-08  1.48572114e-07  5.48479375e-09  1.48184208e-07
  6.43963052e-09  5.87894404e-08  5.10048028e-08  6.70223278e-08
  1.76186680e-09  1.48006575e-08  1.30074443e-08  1.71197185e-08
 -2.11675421e-09 -1.80882623e-08 -1.58534825e-08 -2.08586577e-08
  1.96272146e-09  1.62636290e-08  1.43265772e-08  1.88598337e-08
 -1.11402513e-09 -2.70605059e-09 -1.88669498e-09 -2.67137004e-09
  2.83646452e-09  3.04065064e-09  2.99560098e-09  2.91381248e-09
  5.66913625e-09  1.21234604e-08  8.83063978e-09  1.19412844e-08
  6.96432509e-10  6.15858027e-10  6.72829253e-10  5.85287792e-10
  7.71543501e-10 -1.61604978e-10  1.21289858e-09 -8.29200183e-10
  2.60074181e-09  4.39469029e-09  1.96087764e-09 -5.31737615e-10
 -4.09457291e-01]
supnorm grad right now is: 0.4094572913050658
Weights right now are: 
[-1.61538346 -2.85708479 -3.40362328 -2.42312764  0.82516424  2.87154847
  3.97492935  3.83821072  0.10043715 -1.00827115  0.68660518 -0.53104613
 -0.02571544 -2.3402744   0.41771218 -2.48440975 -1.23509022 -2.07075047
 -0.60943821 -2.24847513 -1.27826826 -2.30429944 -1.5399838  -2.41046475
  1.44438295  0.58898319  0.0267312   0.6001981  -1.22093447 -1.45900139
 -2.340671   -1.94109721  0.35116997  1.08056513  1.48938784  1.22011288
 -1.1412591  -1.88667772 -1.10139931 -2.1795585   0.37827519  0.34463531
  1.3903005   1.72957181 -0.02695965 -1.57666759 -0.24054597 -0.90687658
 -0.41815019 -0.11267255 -0.6862047  -0.74008375 -1.73279672 -2.07735891
 -1.30529563 -2.03450095  0.71438991  1.48378685 -0.96869922 -1.22602996
 -0.21571042  0.08051887 -0.84024919 -1.41955276 24.96136854]
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15991.713244455814
gradient value of function right now is: [ 1.18099335e-06  1.37884924e-06  1.37640931e-06  1.38116603e-06
 -1.18099331e-06 -1.37884920e-06 -1.37640926e-06 -1.38116599e-06
  1.04924304e-07  4.61229145e-07  1.69102882e-08  4.60032008e-07
  1.49501468e-08  6.57176649e-08  2.41096103e-09  6.55468726e-08
  2.30330494e-08  1.01249955e-07  3.71176021e-09  1.00987227e-07
  1.27986528e-08  5.62614081e-08  2.06148896e-09  5.61155650e-08
  2.74707165e-09  2.52145322e-08  2.18782189e-08  2.87216404e-08
  6.69237384e-10  5.64883986e-09  4.96516643e-09  6.52880079e-09
 -6.77885495e-10 -5.81813873e-09 -5.10045088e-09 -6.70452335e-09
  7.68050040e-10  6.39484138e-09  5.63394286e-09  7.40973255e-09
 -5.64710944e-10 -1.29655839e-09 -9.21342222e-10 -1.27839851e-09
  9.55880213e-10  9.78033600e-10  9.87958822e-10  9.35310867e-10
  2.05454143e-09  4.42788812e-09  3.21824473e-09  4.36289874e-09
  2.42276164e-10  2.07002692e-10  2.30848840e-10  1.96471554e-10
  2.89257179e-10 -5.57319709e-11  4.23077264e-10 -2.88640778e-10
  1.02087317e-09  1.74468647e-09  7.52807751e-10 -1.90114494e-10
  8.05667443e+00]
supnorm grad right now is: 8.056674432767219
Weights right now are: 
[-1.70214289e+00 -2.99533850e+00 -3.51383949e+00 -2.53555632e+00
  9.11923679e-01  3.00980218e+00  4.08514557e+00  3.95063940e+00
  7.28573142e-02 -1.13203255e+00  6.82242433e-01 -6.53735214e-01
 -3.06675292e-02 -2.36212976e+00  4.16910102e-01 -2.50615620e+00
 -1.23931877e+00 -2.08796605e+00 -6.10103658e-01 -2.26530792e+00
 -1.28242384e+00 -2.32146587e+00 -1.54065835e+00 -2.42739563e+00
  1.44348017e+00  5.80602663e-01  1.94947714e-02  5.90880864e-01
 -1.22117121e+00 -1.46101956e+00 -2.34244001e+00 -1.94337197e+00
  3.51425389e-01  1.08280697e+00  1.49133712e+00  1.22255962e+00
 -1.14151871e+00 -1.88887553e+00 -1.10332503e+00 -2.18194749e+00
  3.78447769e-01  3.45050620e-01  1.39058931e+00  1.72998170e+00
 -2.73139559e-02 -1.57705806e+00 -2.40924272e-01 -9.07250852e-01
 -4.18891910e-01 -1.14315945e-01 -6.87381522e-01 -7.41703507e-01
 -1.73288363e+00 -2.07743925e+00 -1.30538094e+00 -2.03457739e+00
  7.14283548e-01  1.48380707e+00 -9.68860861e-01 -1.22592579e+00
 -2.16071297e-01  7.98649362e-02 -8.40522213e-01 -1.41948475e+00
  2.55387124e+01]
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.65225370934
gradient value of function right now is: [ 5.26080535e-07  6.03637081e-07  6.02627813e-07  6.04628438e-07
 -5.26081041e-07 -6.03637661e-07 -6.02628393e-07 -6.04629020e-07
  4.51144414e-08  1.96841746e-07  7.20453986e-09  1.96331579e-07
  6.72847447e-09  2.93572391e-08  1.07513727e-09  2.92810593e-08
  1.01697582e-08  4.43726065e-08  1.62385103e-09  4.42576381e-08
  5.72202517e-09  2.49664274e-08  9.13213120e-10  2.49018049e-08
  1.27495936e-09  1.16729059e-08  1.01354929e-08  1.33025393e-08
  2.99270167e-10  2.51885680e-09  2.21566985e-09  2.91278699e-09
 -2.82179544e-10 -2.41443169e-09 -2.11827503e-09 -2.78384830e-09
  3.47372417e-10  2.88423987e-09  2.54293390e-09  3.34372357e-09
 -2.76785996e-10 -6.18683314e-10 -4.43695218e-10 -6.09587358e-10
  4.11454482e-10  4.09393765e-10  4.19548398e-10  3.90777398e-10
  9.08367817e-10  1.93900654e-09  1.41410710e-09  1.90989943e-09
  1.05331758e-10  8.84130134e-11  9.95572829e-11  8.37809325e-11
  1.28960660e-10 -2.63568747e-11  1.84131688e-10 -1.29370560e-10
  4.60440923e-10  7.77182196e-10  3.38595905e-10 -8.93628652e-11
  2.10056328e+00]
supnorm grad right now is: 2.1005632788028126
Weights right now are: 
[-1.78638148e+00 -3.11521249e+00 -3.61610167e+00 -2.63940811e+00
  9.96162264e-01  3.12967617e+00  4.18740774e+00  4.05449120e+00
  5.90554310e-02 -1.19266790e+00  6.80045518e-01 -7.14117884e-01
 -3.27995461e-02 -2.37146110e+00  4.16568149e-01 -2.51545979e+00
 -1.24209118e+00 -2.09968569e+00 -6.10542147e-01 -2.27689574e+00
 -1.28423662e+00 -2.32930792e+00 -1.54094889e+00 -2.43520069e+00
  1.44308037e+00  5.76929880e-01  1.63069854e-02  5.86709424e-01
 -1.22126712e+00 -1.46182874e+00 -2.34315176e+00 -1.94430461e+00
  3.51518960e-01  1.08361085e+00  1.49204183e+00  1.22347923e+00
 -1.14162896e+00 -1.88979401e+00 -1.10413443e+00 -2.18300222e+00
  3.78532601e-01  3.45242102e-01  1.39072684e+00  1.73017055e+00
 -2.74487846e-02 -1.57719435e+00 -2.41062973e-01 -9.07381153e-01
 -4.19185964e-01 -1.14944109e-01 -6.87841474e-01 -7.42322659e-01
 -1.73291797e+00 -2.07746832e+00 -1.30541356e+00 -2.03460498e+00
  7.14242163e-01  1.48381456e+00 -9.68920437e-01 -1.22588515e+00
 -2.16217067e-01  7.96353805e-02 -8.40630258e-01 -1.41945887e+00
  2.51303322e+01]
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15991.654239149755
gradient value of function right now is: [ 2.93570673e-07  3.34225436e-07  3.33687683e-07  3.34768717e-07
 -2.93570502e-07 -3.34225242e-07 -3.33687489e-07 -3.34768522e-07
  2.51298333e-08  1.09248028e-07  3.99929199e-09  1.08964596e-07
  3.80238150e-09  1.65301652e-08  6.05481075e-10  1.64872286e-08
  5.68286758e-09  2.47055273e-08  9.04278603e-10  2.46414519e-08
  3.22537495e-09  1.40219606e-08  5.12979197e-10  1.39856304e-08
  7.31311754e-10  6.65986142e-09  5.78808763e-09  7.59653558e-09
  1.69955006e-10  1.42221543e-09  1.25231312e-09  1.64634813e-09
 -1.56203913e-10 -1.32875273e-09 -1.16696963e-09 -1.53364936e-09
  1.98099587e-10  1.63543896e-09  1.44338345e-09  1.89794604e-09
 -1.62553591e-10 -3.55703371e-10 -2.56965582e-10 -3.50249739e-10
  2.32743549e-10  2.27419295e-10  2.35159443e-10  2.16735347e-10
  5.16944648e-10  1.08624717e-09  7.96534000e-10  1.06932919e-09
  5.96583592e-11  4.94898216e-11  5.60540744e-11  4.68208148e-11
  7.32135375e-11 -1.65080971e-11  1.04102046e-10 -7.60515570e-11
  2.61424001e-10  4.31872877e-10  1.92832306e-10 -5.50350571e-11
 -7.12565385e+00]
supnorm grad right now is: 7.12565385345238
Weights right now are: 
[-1.85279426e+00 -3.19711374e+00 -3.69342109e+00 -2.71734402e+00
  1.06257506e+00  3.21157744e+00  4.26472718e+00  4.13242711e+00
  5.22755879e-02 -1.22221042e+00  6.78966574e-01 -7.43576607e-01
 -3.38265146e-02 -2.37593344e+00  4.16404439e-01 -2.51992029e+00
 -1.24359532e+00 -2.10619076e+00 -6.10781132e-01 -2.28337226e+00
 -1.28510843e+00 -2.33309842e+00 -1.54108770e+00 -2.43898023e+00
  1.44288484e+00  5.75138342e-01  1.47507045e-02  5.84668281e-01
 -1.22131281e+00 -1.46221318e+00 -2.34349015e+00 -1.94474914e+00
  3.51561503e-01  1.08397494e+00  1.49236143e+00  1.22389871e+00
 -1.14168209e+00 -1.89023499e+00 -1.10452347e+00 -2.18351300e+00
  3.78575455e-01  3.45337274e-01  1.39079551e+00  1.73026429e+00
 -2.75115387e-02 -1.57725617e+00 -2.41126777e-01 -9.07440148e-01
 -4.19324944e-01 -1.15238907e-01 -6.88057662e-01 -7.42612957e-01
 -1.73293414e+00 -2.07748168e+00 -1.30542877e+00 -2.03461763e+00
  7.14222214e-01  1.48381856e+00 -9.68948671e-01 -1.22586544e+00
 -2.16288343e-01  7.95201726e-02 -8.40682660e-01 -1.41944527e+00
  2.44387874e+01]
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.793569519477
gradient value of function right now is: [ 1.91155931e-07  2.16617275e-07  2.16277353e-07  2.16966938e-07
 -1.91157409e-07 -2.16618950e-07 -2.16279025e-07 -2.16968615e-07
  1.63958940e-08  7.11151161e-08  2.59873829e-09  7.09311378e-08
  2.49804806e-09  1.08349081e-08  3.96163474e-10  1.08068450e-08
  3.70873632e-09  1.60862718e-08  5.87748636e-10  1.60446698e-08
  2.11708118e-09  9.18266683e-09  3.35342657e-10  9.15894270e-09
  4.81659110e-10  4.40813182e-09  3.82878486e-09  5.02402461e-09
  1.11076739e-10  9.34310814e-10  8.22140780e-10  1.08058012e-09
 -1.00714691e-10 -8.61107747e-10 -7.55765816e-10 -9.93019296e-10
  1.29733826e-10  1.07654507e-09  9.49480581e-10  1.24821376e-09
 -1.06967486e-10 -2.36781369e-10 -1.70397466e-10 -2.33240266e-10
  1.49994092e-10  1.47373930e-10  1.52037884e-10  1.40559078e-10
  3.35188482e-10  7.13435131e-10  5.20886210e-10  7.02656041e-10
  3.85996866e-11  3.21396002e-11  3.63554069e-11  3.04363232e-11
  4.78341931e-11 -9.92656210e-12  6.75331456e-11 -4.79009526e-11
  1.71808401e-10  2.88894097e-10  1.26121205e-10 -3.36551991e-11
  5.98267953e-01]
supnorm grad right now is: 0.5982679528420374
Weights right now are: 
[-1.90054024e+00 -3.25209121e+00 -3.74778001e+00 -2.77192432e+00
  1.11032105e+00  3.26655492e+00  4.31908612e+00  4.18700743e+00
  4.80681540e-02 -1.24048390e+00  6.78298762e-01 -7.61802214e-01
 -3.44658186e-02 -2.37870981e+00  4.16302895e-01 -2.52268945e+00
 -1.24454464e+00 -2.11030957e+00 -6.10931757e-01 -2.28747937e+00
 -1.28565048e+00 -2.33545198e+00 -1.54117370e+00 -2.44132761e+00
  1.44276205e+00  5.74013978e-01  1.37742596e-02  5.83387038e-01
 -1.22134124e+00 -1.46245228e+00 -2.34370054e+00 -1.94502565e+00
  3.51587471e-01  1.08419699e+00  1.49255630e+00  1.22415474e+00
 -1.14171525e+00 -1.89051013e+00 -1.10476614e+00 -2.18383198e+00
  3.78602550e-01  3.45397508e-01  1.39083877e+00  1.73032362e+00
 -2.75501594e-02 -1.57729403e+00 -2.41165876e-01 -9.07476243e-01
 -4.19410687e-01 -1.15421886e-01 -6.88191069e-01 -7.42793163e-01
 -1.73294408e+00 -2.07748992e+00 -1.30543812e+00 -2.03462543e+00
  7.14210084e-01  1.48382119e+00 -9.68965975e-01 -1.22585297e+00
 -2.16332242e-01  7.94444058e-02 -8.40714665e-01 -1.41943640e+00
  2.50490742e+01]
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.607734174984
gradient value of function right now is: [ 1.44505484e-07  1.63257373e-07  1.63005546e-07  1.63519762e-07
 -1.44505113e-07 -1.63256955e-07 -1.63005128e-07 -1.63519342e-07
  1.24099401e-08  5.37432933e-08  1.96376377e-09  5.36042444e-08
  1.89987269e-09  8.22767099e-09  3.00806900e-10  8.20635920e-09
  2.80829473e-09  1.21618559e-08  4.44323268e-10  1.21304005e-08
  1.60919825e-09  6.96896741e-09  2.54478438e-10  6.95096105e-09
  3.68382556e-10  3.36631819e-09  2.92472634e-09  3.83765066e-09
  8.46290064e-11  7.10694677e-10  6.25563050e-10  8.22197027e-10
 -7.60032962e-11 -6.48750773e-10 -5.69564269e-10 -7.48353321e-10
  9.89926714e-11  8.20142980e-10  7.23560559e-10  9.51201094e-10
 -8.24559140e-11 -1.81328044e-10 -1.30786765e-10 -1.78580308e-10
  1.14038945e-10  1.11427756e-10  1.15267375e-10  1.06220879e-10
  2.55478727e-10  5.41299120e-10  3.95834621e-10  5.33028282e-10
  2.93594409e-11  2.43670627e-11  2.76056930e-11  2.30640034e-11
  3.64498994e-11 -7.79908100e-12  5.13750863e-11 -3.68763342e-11
  1.30951105e-10  2.18844804e-10  9.62143749e-11 -2.63062785e-11
 -2.27664453e+00]
supnorm grad right now is: 2.276644528246631
Weights right now are: 
[-1.93334119e+00 -3.28927961e+00 -3.78486105e+00 -2.80912743e+00
  1.14312200e+00  3.30374332e+00  4.35616715e+00  4.22421054e+00
  4.52421999e-02 -1.25273240e+00  6.77850868e-01 -7.74018930e-01
 -3.48973618e-02 -2.38058021e+00  4.16234459e-01 -2.52455500e+00
 -1.24518376e+00 -2.11307933e+00 -6.11033036e-01 -2.29024187e+00
 -1.28601609e+00 -2.33703659e+00 -1.54123161e+00 -2.44290812e+00
  1.44267841e+00  5.73251687e-01  1.31116423e-02  5.82517534e-01
 -1.22136050e+00 -1.46261373e+00 -2.34384270e+00 -1.94521251e+00
  3.51604860e-01  1.08434514e+00  1.49268641e+00  1.22432571e+00
 -1.14173776e+00 -1.89069633e+00 -1.10493045e+00 -2.18404799e+00
  3.78621381e-01  3.45438468e-01  1.39086848e+00  1.73036396e+00
 -2.75761588e-02 -1.57731958e+00 -2.41192235e-01 -9.07500602e-01
 -4.19469207e-01 -1.15544685e-01 -6.88281311e-01 -7.42914061e-01
 -1.73295074e+00 -2.07749550e+00 -1.30544441e+00 -2.03463071e+00
  7.14201690e-01  1.48382294e+00 -9.68977803e-01 -1.22584459e+00
 -2.16362086e-01  7.93966737e-02 -8.40736806e-01 -1.41943045e+00
  2.48161017e+01]
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15992.357454622977
gradient value of function right now is: [ 1.16611124e-07  1.31440575e-07  1.31240530e-07  1.31651137e-07
 -1.16611659e-07 -1.31441178e-07 -1.31241132e-07 -1.31651741e-07
  1.00212625e-08  4.33463179e-08  1.58424148e-09  4.32340967e-08
  1.54029327e-09  6.66240729e-09  2.43637864e-10  6.64513899e-09
  2.26913281e-09  9.81504344e-09  3.58669499e-10  9.78964162e-09
  1.30404820e-09  5.64062911e-09  2.06021350e-10  5.62604562e-09
  3.00267412e-10  2.73718648e-09  2.37908760e-09  3.12172279e-09
  6.87981892e-11  5.76206864e-10  5.07418050e-10  6.66930101e-10
 -6.13065649e-11 -5.21900896e-10 -4.58406852e-10 -6.02315241e-10
  8.05757611e-11  6.65780645e-10  5.87647105e-10  7.72546111e-10
 -6.77568873e-11 -1.47733026e-10 -1.06870061e-10 -1.45456986e-10
  9.27467014e-11  8.99459845e-11  9.33966705e-11  8.56889249e-11
  2.08042426e-10  4.37697481e-10  3.20859609e-10  4.30904824e-10
  2.38861352e-11  1.97187794e-11  2.24011493e-11  1.86518627e-11
  2.96223623e-11 -6.60520869e-12  4.17221539e-11 -3.04425739e-11
  1.06389264e-10  1.76076846e-10  7.82695796e-11 -2.21210634e-11
 -6.00374586e+00]
supnorm grad right now is: 6.003745857641124
Weights right now are: 
[-1.95881660e+00 -3.31803867e+00 -3.81357083e+00 -2.83792792e+00
  1.16859742e+00  3.33250240e+00  4.38487695e+00  4.25301105e+00
  4.30522283e-02 -1.26221033e+00  6.77504047e-01 -7.83472245e-01
 -3.52332419e-02 -2.38203385e+00  4.16181236e-01 -2.52600486e+00
 -1.24567942e+00 -2.11522447e+00 -6.11111521e-01 -2.29238143e+00
 -1.28630049e+00 -2.33826744e+00 -1.54127662e+00 -2.44413578e+00
  1.44261288e+00  5.72656522e-01  1.25939209e-02  5.81838238e-01
 -1.22137557e+00 -1.46273938e+00 -2.34395346e+00 -1.94535810e+00
  3.51618347e-01  1.08445941e+00  1.49278689e+00  1.22445772e+00
 -1.14175541e+00 -1.89084147e+00 -1.10505869e+00 -2.18421659e+00
  3.78636228e-01  3.45470453e-01  1.39089176e+00  1.73039544e+00
 -2.75967778e-02 -1.57733926e+00 -2.41212864e-01 -9.07519341e-01
 -4.19515084e-01 -1.15639961e-01 -6.88351602e-01 -7.43007824e-01
 -1.73295606e+00 -2.07749981e+00 -1.30544936e+00 -2.03463478e+00
  7.14195267e-01  1.48382452e+00 -9.68986909e-01 -1.22583774e+00
 -2.16385370e-01  7.93581210e-02 -8.40753789e-01 -1.41942527e+00
  2.44931922e+01]
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.72965086332
gradient value of function right now is: [ 9.57613693e-08  1.07733536e-07  1.07571380e-07  1.07905562e-07
 -9.57628762e-08 -1.07735231e-07 -1.07573072e-07 -1.07907259e-07
  8.23221022e-09  3.55709904e-08  1.29832996e-09  3.54791085e-08
  1.26970417e-09  5.48630601e-09  2.00359917e-10  5.47211851e-09
  1.86537994e-09  8.06026616e-09  2.94150805e-10  8.03945340e-09
  1.07467248e-09  4.64365359e-09  1.69380670e-10  4.63167511e-09
  2.47307592e-10  2.26488266e-09  1.96735845e-09  2.58108853e-09
  5.64102578e-11  4.74749724e-10  4.17787314e-10  5.49030442e-10
 -4.99468802e-11 -4.27249284e-10 -3.75018252e-10 -4.92667193e-10
  6.61228144e-11  5.48999120e-10  4.84239378e-10  6.36492695e-10
 -5.55679749e-11 -1.22638138e-10 -8.83530584e-11 -1.20796491e-10
  7.52560899e-11  7.34798827e-11  7.60672475e-11  7.00602332e-11
  1.69479631e-10  3.60994566e-10  2.63521271e-10  3.55552945e-10
  1.94394223e-11  1.61190235e-11  1.82792546e-11  1.52620949e-11
  2.42838909e-11 -4.99831119e-12  3.40332215e-11 -2.41316067e-11
  8.76088708e-11  1.47493036e-10  6.41874147e-11 -1.70076413e-11
  1.54045274e+00]
supnorm grad right now is: 1.5404527377844304
Weights right now are: 
[-1.98022481e+00 -3.34214924e+00 -3.83764428e+00 -2.86207649e+00
  1.19000563e+00  3.35661297e+00  4.40895041e+00  4.27715962e+00
  4.12122561e-02 -1.27016557e+00  6.77214275e-01 -7.91407031e-01
 -3.55164601e-02 -2.38325836e+00  4.16136608e-01 -2.52722621e+00
 -1.24609619e+00 -2.11702640e+00 -6.11177147e-01 -2.29417872e+00
 -1.28654028e+00 -2.33930423e+00 -1.54131436e+00 -2.44516991e+00
  1.44255819e+00  5.72151168e-01  1.21555782e-02  5.81263225e-01
 -1.22138802e+00 -1.46284525e+00 -2.34404646e+00 -1.94548029e+00
  3.51629417e-01  1.08455509e+00  1.49287072e+00  1.22456783e+00
 -1.14176999e+00 -1.89096378e+00 -1.10516637e+00 -2.18435810e+00
  3.78648321e-01  3.45497852e-01  1.39091132e+00  1.73042245e+00
 -2.76130816e-02 -1.57735564e+00 -2.41229561e-01 -9.07534991e-01
 -4.19552079e-01 -1.15720886e-01 -6.88410114e-01 -7.43087608e-01
 -1.73296027e+00 -2.07750339e+00 -1.30545336e+00 -2.03463818e+00
  7.14189904e-01  1.48382542e+00 -9.68994336e-01 -1.22583278e+00
 -2.16404844e-01  7.93243169e-02 -8.40767924e-01 -1.41942206e+00
  2.51170972e+01]
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.699923157554
gradient value of function right now is: [ 8.25257734e-08  9.26985243e-08  9.25603105e-08  9.28462018e-08
 -8.25260930e-08 -9.26988833e-08 -9.25606690e-08 -9.28465614e-08
  7.09542569e-09  3.06328401e-08  1.11826183e-09  3.05536824e-08
  1.09769949e-09  4.73904008e-09  1.73095980e-10  4.72678025e-09
  1.60896057e-09  6.94635136e-09  2.53538531e-10  6.92840782e-09
  9.28807916e-10  4.00994808e-09  1.46288101e-10  3.99960019e-09
  2.14606074e-10  1.96207113e-09  1.70480187e-09  2.23664134e-09
  4.88485495e-11  4.10378551e-10  3.61248222e-10  4.74738443e-10
 -4.30044732e-11 -3.67200669e-10 -3.22408109e-10 -4.23559166e-10
  5.73090759e-11  4.74986876e-10  4.19082013e-10  5.50858947e-10
 -4.85146634e-11 -1.06401338e-10 -7.68209571e-11 -1.04782796e-10
  6.51537777e-11  6.33142663e-11  6.56932437e-11  6.03386753e-11
  1.46933770e-10  3.11454178e-10  2.27738367e-10  3.06702448e-10
  1.68272170e-11  1.39155559e-11  1.57993024e-11  1.31691977e-11
  2.10331844e-11 -4.47593208e-12  2.94589621e-11 -2.11505544e-11
  7.58447946e-11  1.26842589e-10  5.56361006e-11 -1.51379034e-11
 -1.72130000e+00]
supnorm grad right now is: 1.7212999996058065
Weights right now are: 
[-1.99802971e+00 -3.36216639e+00 -3.85763137e+00 -2.88212552e+00
  1.20781052e+00  3.37663010e+00  4.42893748e+00  4.29720863e+00
  3.96816742e-02 -1.27677761e+00  6.76972530e-01 -7.98001952e-01
 -3.57528603e-02 -2.38427959e+00  4.16099250e-01 -2.52824480e+00
 -1.24644313e+00 -2.11852517e+00 -6.11231935e-01 -2.29567361e+00
 -1.28674033e+00 -2.34016844e+00 -1.54134593e+00 -2.44603187e+00
  1.44251177e+00  5.71729589e-01  1.17891053e-02  5.80782227e-01
 -1.22139861e+00 -1.46293371e+00 -2.34412437e+00 -1.94558272e+00
  3.51638771e-01  1.08463447e+00  1.49294045e+00  1.22465947e+00
 -1.14178241e+00 -1.89106612e+00 -1.10525671e+00 -2.18447689e+00
  3.78658881e-01  3.45520727e-01  1.39092786e+00  1.73044496e+00
 -2.76272959e-02 -1.57736939e+00 -2.41243844e-01 -9.07548085e-01
 -4.19584137e-01 -1.15787931e-01 -6.88459231e-01 -7.43153592e-01
 -1.73296393e+00 -2.07750641e+00 -1.30545679e+00 -2.03464104e+00
  7.14185304e-01  1.48382646e+00 -9.69000802e-01 -1.22582808e+00
 -2.16421180e-01  7.92960389e-02 -8.40780092e-01 -1.41941860e+00
  2.48381983e+01]
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15991.619536504697
gradient value of function right now is: [ 7.09637820e-08  7.96021069e-08  7.94843846e-08  7.97286027e-08
 -7.09637386e-08 -7.96020583e-08 -7.94843361e-08 -7.97285540e-08
  6.10132827e-09  2.63205181e-08  9.59540498e-10  2.62526592e-08
  9.46488994e-10  4.08304001e-09  1.48933148e-10  4.07250140e-09
  1.38458175e-09  5.97298260e-09  2.17715553e-10  5.95758882e-09
  8.00728022e-10  3.45429364e-09  1.25846430e-10  3.44540012e-09
  1.84666847e-10  1.69705488e-09  1.47351466e-09  1.93289675e-09
  4.18759769e-11  3.53630169e-10  3.11067651e-10  4.08719503e-10
 -3.66857557e-11 -3.14881739e-10 -2.76271073e-10 -3.62883481e-10
  4.91602458e-11  4.09531912e-10  3.61072247e-10  4.74521608e-10
 -4.14705529e-11 -9.22831094e-11 -6.63025458e-11 -9.09234007e-11
  5.53114801e-11  5.41015905e-11  5.59835553e-11  5.16091336e-11
  1.25079727e-10  2.68799780e-10  1.95638661e-10  2.64839213e-10
  1.43423229e-11  1.18929141e-11  1.34958774e-11  1.12676541e-11
  1.80046245e-11 -3.47097951e-12  2.51028802e-11 -1.74478299e-11
  6.53039389e-11  1.11281445e-10  4.76339983e-11 -1.19863654e-11
  8.25572083e+00]
supnorm grad right now is: 8.255720826758013
Weights right now are: 
[-2.01379077e+00 -3.37985956e+00 -3.87529825e+00 -2.89984685e+00
  1.22357157e+00  3.39432326e+00  4.44660434e+00  4.31492995e+00
  3.83266227e-02 -1.28262626e+00  6.76758823e-01 -8.03835468e-01
 -3.59627581e-02 -2.38518555e+00  4.16066129e-01 -2.52914840e+00
 -1.24675050e+00 -2.11985187e+00 -6.11280404e-01 -2.29699688e+00
 -1.28691791e+00 -2.34093489e+00 -1.54137392e+00 -2.44679635e+00
  1.44247054e+00  5.71354309e-01  1.14629180e-02  5.80354185e-01
 -1.22140800e+00 -1.46301222e+00 -2.34419351e+00 -1.94567360e+00
  3.51647016e-01  1.08470453e+00  1.49300199e+00  1.22474035e+00
 -1.14179343e+00 -1.89115701e+00 -1.10533695e+00 -2.18458238e+00
  3.78668243e-01  3.45541103e-01  1.39094257e+00  1.73046503e+00
 -2.76398809e-02 -1.57738150e+00 -2.41256463e-01 -9.07559616e-01
 -4.19612436e-01 -1.15847410e-01 -6.88502769e-01 -7.43212157e-01
 -1.73296718e+00 -2.07750908e+00 -1.30545984e+00 -2.03464357e+00
  7.14181296e-01  1.48382734e+00 -9.69006455e-01 -1.22582393e+00
 -2.16435600e-01  7.92713888e-02 -8.40790712e-01 -1.41941562e+00
  2.55420504e+01]
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.741964053514
gradient value of function right now is: [ 6.39699622e-08  7.16731226e-08  7.15679113e-08  7.17868446e-08
 -6.39703606e-08 -7.16735689e-08 -7.15683569e-08 -7.17872916e-08
  5.49978153e-09  2.37100654e-08  8.65161905e-10  2.36488334e-08
  8.55306886e-10  3.68729191e-09  1.34620126e-10  3.67775876e-09
  1.24897032e-09  5.38445740e-09  1.96442801e-10  5.37055691e-09
  7.23388963e-10  3.11862463e-09  1.13720872e-10  3.11058173e-09
  1.67834708e-10  1.53490492e-09  1.33367475e-09  1.74962666e-09
  3.80302810e-11  3.19573414e-10  2.81321017e-10  3.69678736e-10
 -3.31602511e-11 -2.83206654e-10 -2.48667325e-10 -3.26663519e-10
  4.46788373e-11  3.70398530e-10  3.26811023e-10  4.29547998e-10
 -3.81191413e-11 -8.35079852e-11 -6.03176723e-11 -8.22359526e-11
  5.04623682e-11  4.89098027e-11  5.08209539e-11  4.66052186e-11
  1.14186359e-10  2.42130499e-10  1.77031496e-10  2.38440906e-10
  1.30536220e-11  1.07767049e-11  1.22481393e-11  1.01980043e-11
  1.63725689e-11 -3.47007240e-12  2.28587905e-11 -1.64070331e-11
  5.91478013e-11  9.89746831e-11  4.33519251e-11 -1.17549980e-11
 -1.38475832e+00]
supnorm grad right now is: 1.3847583209483556
Weights right now are: 
[-2.02747391e+00 -3.39520030e+00 -3.89061638e+00 -2.91521196e+00
  1.23725470e+00  3.40966399e+00  4.46192247e+00  4.33029505e+00
  3.71501439e-02 -1.28769983e+00  6.76573759e-01 -8.08895937e-01
 -3.61454678e-02 -2.38597348e+00  4.16037372e-01 -2.52993430e+00
 -1.24701756e+00 -2.12100358e+00 -6.11322407e-01 -2.29814562e+00
 -1.28707246e+00 -2.34160140e+00 -1.54139822e+00 -2.44746114e+00
  1.44243480e+00  5.71026608e-01  1.11782717e-02  5.79980796e-01
 -1.22141611e+00 -1.46308047e+00 -2.34425359e+00 -1.94575254e+00
  3.51654104e-01  1.08476518e+00  1.49305524e+00  1.22481028e+00
 -1.14180296e+00 -1.89123609e+00 -1.10540672e+00 -2.18467407e+00
  3.78676292e-01  3.45558919e-01  1.39095540e+00  1.73048258e+00
 -2.76506731e-02 -1.57739191e+00 -2.41267323e-01 -9.07569543e-01
 -4.19636713e-01 -1.15899224e-01 -6.88540571e-01 -7.43263192e-01
 -1.73296999e+00 -2.07751137e+00 -1.30546246e+00 -2.03464574e+00
  7.14177830e-01  1.48382806e+00 -9.69011298e-01 -1.22582046e+00
 -2.16448227e-01  7.92498153e-02 -8.40799883e-01 -1.41941317e+00
  2.49109923e+01]
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15992.325910137286
gradient value of function right now is: [ 5.80723453e-08  6.49987842e-08  6.49039928e-08  6.51017693e-08
 -5.80708883e-08 -6.49971537e-08 -6.49023646e-08 -6.51001362e-08
  4.99218430e-09  2.15091851e-08  7.85282559e-10  2.14535763e-08
  7.78109731e-10  3.35252904e-09  1.22465055e-10  3.34385196e-09
  1.13447523e-09  4.88799597e-09  1.78427602e-10  4.87536338e-09
  6.57947223e-10  2.83483760e-09  1.03428784e-10  2.82751863e-09
  1.53302053e-10  1.39776587e-09  1.21507414e-09  1.59411175e-09
  3.47072156e-11  2.90700868e-10  2.56037164e-10  3.36474739e-10
 -3.01359907e-11 -2.56542537e-10 -2.25370698e-10 -2.96077550e-10
  4.08027269e-11  3.37167993e-10  2.97645664e-10  3.91239438e-10
 -3.50687251e-11 -7.60973155e-11 -5.51444851e-11 -7.49159413e-11
  4.61876841e-11  4.44346390e-11  4.63403760e-11  4.23112482e-11
  1.04515078e-10  2.19759734e-10  1.61143781e-10  2.16346243e-10
  1.19421479e-11  9.80809686e-12  1.11757564e-11  9.27428440e-12
  1.49386727e-11 -3.33365233e-12  2.08732910e-11 -1.52798928e-11
  5.38967154e-11  8.91424162e-11  3.95820598e-11 -1.11881837e-11
 -6.06758517e+00]
supnorm grad right now is: 6.067585170641836
Weights right now are: 
[-2.03956072e+00 -3.40873631e+00 -3.90413257e+00 -2.92876942e+00
  1.24934149e+00  3.42319997e+00  4.47543863e+00  4.34385248e+00
  3.61110605e-02 -1.29217818e+00  6.76410528e-01 -8.13362745e-01
 -3.63072173e-02 -2.38667060e+00  4.16011949e-01 -2.53062962e+00
 -1.24725361e+00 -2.12202091e+00 -6.11359482e-01 -2.29916033e+00
 -1.28720926e+00 -2.34219100e+00 -1.54141969e+00 -2.44804922e+00
  1.44240315e+00  5.70735878e-01  1.09258028e-02  5.79649634e-01
 -1.22142327e+00 -1.46314088e+00 -2.34430673e+00 -1.94582236e+00
  3.51660334e-01  1.08481863e+00  1.49310214e+00  1.22487188e+00
 -1.14181137e+00 -1.89130611e+00 -1.10546846e+00 -2.18475521e+00
  3.78683441e-01  3.45574757e-01  1.39096680e+00  1.73049818e+00
 -2.76601027e-02 -1.57740112e+00 -2.41276851e-01 -9.07578316e-01
 -4.19658093e-01 -1.15945080e-01 -6.88573964e-01 -7.43308356e-01
 -1.73297243e+00 -2.07751340e+00 -1.30546476e+00 -2.03464765e+00
  7.14174727e-01  1.48382869e+00 -9.69015603e-01 -1.22581743e+00
 -2.16459437e-01  7.92308493e-02 -8.40808096e-01 -1.41941102e+00
  2.45110689e+01]
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.529318505827
gradient value of function right now is: [ 5.19705295e-08  5.81138043e-08  5.80295440e-08  5.82057044e-08
 -5.19690568e-08 -5.81121577e-08 -5.80278997e-08 -5.82040552e-08
  4.46683375e-09  1.92347952e-08  7.01305894e-10  1.91851833e-08
  6.97671218e-10  3.00425546e-09  1.09595485e-10  2.99649808e-09
  1.01579929e-09  4.37419579e-09  1.59457973e-10  4.36291770e-09
  5.89877876e-10  2.54011745e-09  9.25517902e-11  2.53357482e-09
  1.37079753e-10  1.25643372e-09  1.09142284e-09  1.43167904e-09
  3.09303128e-11  2.60486736e-10  2.29243800e-10  3.01212739e-10
 -2.67612220e-11 -2.29059898e-10 -2.01069549e-10 -2.64108573e-10
  3.63765544e-11  3.02227711e-10  2.66590074e-10  3.50357875e-10
 -3.11386247e-11 -6.85663166e-11 -4.94403121e-11 -6.75340531e-11
  4.07540115e-11  3.95359106e-11  4.10756760e-11  3.76847405e-11
  9.25086260e-11  1.97286466e-10  1.43967463e-10  1.94323559e-10
  1.05697219e-11  8.72537529e-12  9.92189684e-12  8.26022258e-12
  1.33064414e-11 -2.70801728e-12  1.85096189e-11 -1.31118051e-11
  4.82378244e-11  8.13660359e-11  3.52583468e-11 -9.25498738e-12
  2.88361580e+00]
supnorm grad right now is: 2.8836157991483296
Weights right now are: 
[-2.05080288e+00 -3.42131382e+00 -3.91669178e+00 -2.94136682e+00
  1.26058366e+00  3.43577749e+00  4.48799785e+00  4.35644989e+00
  3.51449091e-02 -1.29634042e+00  6.76259073e-01 -8.17514301e-01
 -3.64579338e-02 -2.38731989e+00  4.15988310e-01 -2.53127725e+00
 -1.24747325e+00 -2.12296714e+00 -6.11393908e-01 -2.30010413e+00
 -1.28733672e+00 -2.34274013e+00 -1.54143966e+00 -2.44859694e+00
  1.44237374e+00  5.70464151e-01  1.06901304e-02  5.79340483e-01
 -1.22142989e+00 -1.46319716e+00 -2.34435616e+00 -1.94588731e+00
  3.51666076e-01  1.08486824e+00  1.49314560e+00  1.22492898e+00
 -1.14181914e+00 -1.89137135e+00 -1.10552589e+00 -2.18483069e+00
  3.78690035e-01  3.45589628e-01  1.39097740e+00  1.73051283e+00
 -2.76686602e-02 -1.57740965e+00 -2.41285571e-01 -9.07586463e-01
 -4.19677643e-01 -1.15987970e-01 -6.88604858e-01 -7.43350615e-01
 -1.73297464e+00 -2.07751529e+00 -1.30546685e+00 -2.03464944e+00
  7.14171885e-01  1.48382928e+00 -9.69019530e-01 -1.22581467e+00
 -2.16469831e-01  7.92114212e-02 -8.40815614e-01 -1.41940904e+00
  2.51981310e+01]
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15992.362423273147
gradient value of function right now is: [ 4.83060322e-08  5.39708509e-08  5.38930336e-08  5.40561134e-08
 -4.83046068e-08 -5.39692586e-08 -5.38914436e-08 -5.40545186e-08
  4.15122280e-09  1.78670880e-08  6.52124421e-10  1.78209130e-08
  6.49649337e-10  2.79611598e-09  1.02109870e-10  2.78888185e-09
  9.44642235e-10  4.06581441e-09  1.48372167e-10  4.05531075e-09
  5.49152342e-10  2.36360151e-09  8.62106787e-11  2.35750155e-09
  1.28345465e-10  1.17031672e-09  1.01738792e-09  1.33470164e-09
  2.89591533e-11  2.42566787e-10  2.13650847e-10  2.80760778e-10
 -2.49630987e-11 -2.12511502e-10 -1.86697591e-10 -2.45261390e-10
  3.40799876e-11  2.81628522e-10  2.48625760e-10  3.26792135e-10
 -2.94695597e-11 -6.38686114e-11 -4.63036586e-11 -6.28751849e-11
  3.83937630e-11  3.68527170e-11  3.84808798e-11  3.50871390e-11
  8.71010569e-11  1.83129191e-10  1.34290395e-10  1.80284669e-10
  9.93853358e-12  8.15055881e-12  9.29512684e-12  7.70631606e-12
  1.24632412e-11 -2.78022235e-12  1.73732008e-11 -1.27259562e-11
  4.50240828e-11  7.44662859e-11  3.30487759e-11 -9.33705393e-12
 -5.99245419e+00]
supnorm grad right now is: 5.992454186354057
Weights right now are: 
[-2.06090318e+00 -3.43260382e+00 -3.92796544e+00 -2.95267466e+00
  1.27068397e+00  3.44706751e+00  4.49927153e+00  4.36775775e+00
  3.42769277e-02 -1.30007764e+00  6.76122730e-01 -8.21241870e-01
 -3.65936232e-02 -2.38790412e+00  4.15966984e-01 -2.53185997e+00
 -1.24767070e+00 -2.12381729e+00 -6.11424918e-01 -2.30095209e+00
 -1.28745144e+00 -2.34323406e+00 -1.54145767e+00 -2.44908960e+00
  1.44234701e+00  5.70219671e-01  1.04777711e-02  5.79061884e-01
 -1.22143593e+00 -1.46324782e+00 -2.34440077e+00 -1.94594593e+00
  3.51671295e-01  1.08491272e+00  1.49318466e+00  1.22498029e+00
 -1.14182625e+00 -1.89143014e+00 -1.10557778e+00 -2.18489889e+00
  3.78696078e-01  3.45602976e-01  1.39098698e+00  1.73052597e+00
 -2.76767202e-02 -1.57741729e+00 -2.41293589e-01 -9.07593733e-01
 -4.19695654e-01 -1.16026387e-01 -6.88632784e-01 -7.43388445e-01
 -1.73297674e+00 -2.07751698e+00 -1.30546880e+00 -2.03465104e+00
  7.14169367e-01  1.48382988e+00 -9.69023071e-01 -1.22581196e+00
 -2.16479180e-01  7.91940296e-02 -8.40822297e-01 -1.41940702e+00
  2.44977467e+01]
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.63922234746
gradient value of function right now is: [ 4.41357082e-08  4.92744647e-08  4.92037467e-08  4.93521846e-08
 -4.41344467e-08 -4.92730564e-08 -4.92023405e-08 -4.93507741e-08
  3.79203037e-09  1.63136685e-08  5.94697290e-10  1.62715993e-08
  5.94451072e-10  2.55737438e-09  9.32766559e-11  2.55077225e-09
  8.63443471e-10  3.71463588e-09  1.35390387e-10  3.70506027e-09
  5.02463601e-10  2.16166428e-09  7.87485663e-11  2.15609756e-09
  1.17120673e-10  1.07317836e-09  9.32311515e-10  1.22292892e-09
  2.63491425e-11  2.21828694e-10  1.95240025e-10  2.56527287e-10
 -2.26480239e-11 -1.93782724e-10 -1.70118979e-10 -2.23448722e-10
  3.10174633e-11  2.57615364e-10  2.27258483e-10  2.98660053e-10
 -2.67113523e-11 -5.86884929e-11 -4.23504245e-11 -5.78016230e-11
  3.46183696e-11  3.34920508e-11  3.48459379e-11  3.19179191e-11
  7.87553297e-11  1.67776673e-10  1.22479828e-10  1.65251453e-10
  8.98631247e-12  7.40556306e-12  8.42890816e-12  7.00967401e-12
  1.13335227e-11 -2.32085461e-12  1.57344516e-11 -1.11799029e-11
  4.11229792e-11  6.92759954e-11  3.00524431e-11 -7.92614920e-12
  2.17961902e+00]
supnorm grad right now is: 2.1796190199730443
Weights right now are: 
[-2.06989048e+00 -3.44264179e+00 -3.93798898e+00 -2.96272849e+00
  1.27967125e+00  3.45710545e+00  4.50929504e+00  4.37781156e+00
  3.35043807e-02 -1.30340109e+00  6.76001234e-01 -8.24556690e-01
 -3.67146246e-02 -2.38842466e+00  4.15947944e-01 -2.53237915e+00
 -1.24784653e+00 -2.12457372e+00 -6.11452566e-01 -2.30170655e+00
 -1.28755369e+00 -2.34367397e+00 -1.54147374e+00 -2.44952837e+00
  1.44232300e+00  5.70001987e-01  1.02882027e-02  5.78813261e-01
 -1.22144137e+00 -1.46329298e+00 -2.34444063e+00 -1.94599829e+00
  3.51675968e-01  1.08495221e+00  1.49321943e+00  1.22502595e+00
 -1.14183265e+00 -1.89148262e+00 -1.10562421e+00 -2.18495990e+00
  3.78701667e-01  3.45614792e-01  1.39099568e+00  1.73053760e+00
 -2.76840509e-02 -1.57742416e+00 -2.41300879e-01 -9.07600266e-01
 -4.19712202e-01 -1.16060246e-01 -6.88658019e-01 -7.43421773e-01
 -1.73297865e+00 -2.07751849e+00 -1.30547057e+00 -2.03465247e+00
  7.14167028e-01  1.48383039e+00 -9.69026345e-01 -1.22580956e+00
 -2.16487616e-01  7.91821122e-02 -8.40828507e-01 -1.41940529e+00
  2.51673307e+01]
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.799431827925
gradient value of function right now is: [ 4.10228200e-08  4.57654012e-08  4.57000370e-08  4.58375042e-08
 -4.10241330e-08 -4.57668658e-08 -4.57014996e-08 -4.58389712e-08
  3.52390988e-09  1.51535300e-08  5.52501305e-10  1.51144385e-08
  5.53398969e-10  2.37971971e-09  8.68118101e-11  2.37357405e-09
  8.02912278e-10  3.45270596e-09  1.25865314e-10  3.44380237e-09
  4.67697676e-10  2.01121238e-09  7.32802668e-11  2.00603126e-09
  1.09273181e-10  9.99992133e-10  8.68907089e-10  1.13977664e-09
  2.45564645e-11  2.06466956e-10  1.81758007e-10  2.38818256e-10
 -2.10401042e-11 -1.79786290e-10 -1.57865466e-10 -2.07358151e-10
  2.89204439e-11  2.39891495e-10  2.11667183e-10  2.78176340e-10
 -2.50223485e-11 -5.47282275e-11 -3.95546122e-11 -5.38931735e-11
  3.22695120e-11  3.11251669e-11  3.24297908e-11  2.96521589e-11
  7.34782692e-11  1.55967924e-10  1.14001876e-10  1.53598539e-10
  8.37346491e-12  6.89020673e-12  7.84704682e-12  6.51955598e-12
  1.05682808e-11 -2.21864551e-12  1.46672776e-11 -1.05139577e-11
  3.83154035e-11  6.42087553e-11  2.80350664e-11 -7.54093449e-12
 -4.05578447e-01]
supnorm grad right now is: 0.4055784474955385
Weights right now are: 
[-2.07884174e+00 -3.45263189e+00 -3.94796477e+00 -2.97273434e+00
  1.28862250e+00  3.46709555e+00  4.51927082e+00  4.38781739e+00
  3.27354457e-02 -1.30670864e+00  6.75880801e-01 -8.27855735e-01
 -3.68352561e-02 -2.38894355e+00  4.15929040e-01 -2.53289671e+00
 -1.24802167e+00 -2.12532708e+00 -6.11479993e-01 -2.30245798e+00
 -1.28765566e+00 -2.34411259e+00 -1.54148970e+00 -2.44996586e+00
  1.44229931e+00  5.69783861e-01  1.00988648e-02  5.78564913e-01
 -1.22144668e+00 -1.46333798e+00 -2.34448020e+00 -1.94605028e+00
  3.51680535e-01  1.08499148e+00  1.49325387e+00  1.22507118e+00
 -1.14183891e+00 -1.89153488e+00 -1.10567026e+00 -2.18502043e+00
  3.78707032e-01  3.45626744e-01  1.39100425e+00  1.73054938e+00
 -2.76909815e-02 -1.57743092e+00 -2.41307879e-01 -9.07606715e-01
 -4.19727978e-01 -1.16094391e-01 -6.88682768e-01 -7.43455411e-01
 -1.73298044e+00 -2.07751999e+00 -1.30547226e+00 -2.03465389e+00
  7.14164753e-01  1.48383087e+00 -9.69029508e-01 -1.22580730e+00
 -2.16495909e-01  7.91672830e-02 -8.40834542e-01 -1.41940368e+00
  2.49447830e+01]
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.759137454574
gradient value of function right now is: [ 3.83181856e-08  4.27198921e-08  4.26591421e-08  4.27871246e-08
 -3.83173986e-08 -4.27190148e-08 -4.26582661e-08 -4.27862460e-08
  3.29079252e-09  1.41454396e-08  5.15742787e-10  1.41089474e-08
  5.17615350e-10  2.22495683e-09  8.11654627e-11  2.21921066e-09
  7.50239773e-10  3.22491668e-09  1.17560649e-10  3.21660021e-09
  4.37400255e-10  1.88017657e-09  6.85053787e-11  1.87533284e-09
  1.02349267e-10  9.36236607e-10  8.13571465e-10  1.06718560e-09
  2.29733701e-11  1.93069719e-10  1.69978259e-10  2.23339941e-10
 -1.96278266e-11 -1.67641838e-10 -1.47214163e-10 -1.93367046e-10
  2.70668652e-11  2.24416729e-10  1.98029448e-10  2.60252932e-10
 -2.34890678e-11 -5.12816774e-11 -3.70868036e-11 -5.04964691e-11
  3.01648999e-11  2.90462506e-11  3.02893647e-11  2.76675793e-11
  6.87459959e-11  1.45741180e-10  1.06572910e-10  1.43520633e-10
  7.82899687e-12  6.43570059e-12  7.33311530e-12  6.08864762e-12
  9.88649038e-12 -2.09249323e-12  1.37130451e-11 -9.86147711e-12
  3.58502668e-11  5.99802310e-11  2.62355133e-11 -7.10281620e-12
 -1.17923721e+00]
supnorm grad right now is: 1.1792372077681703
Weights right now are: 
[-2.08690334e+00 -3.46162285e+00 -3.95694291e+00 -2.98173946e+00
  1.29668410e+00  3.47608651e+00  4.52824897e+00  4.39682251e+00
  3.20430407e-02 -1.30968573e+00  6.75772208e-01 -8.30825136e-01
 -3.69440717e-02 -2.38941142e+00  4.15911964e-01 -2.53336336e+00
 -1.24817948e+00 -2.12600560e+00 -6.11504738e-01 -2.30313474e+00
 -1.28774762e+00 -2.34450797e+00 -1.54150411e+00 -2.45036023e+00
  1.44227780e+00  5.69587133e-01  9.92795077e-03  5.78340706e-01
 -1.22145153e+00 -1.46337857e+00 -2.34451595e+00 -1.94609727e+00
  3.51684680e-01  1.08502678e+00  1.49328487e+00  1.22511191e+00
 -1.14184463e+00 -1.89158205e+00 -1.10571191e+00 -2.18507516e+00
  3.78711909e-01  3.45637519e-01  1.39101198e+00  1.73055999e+00
 -2.76974364e-02 -1.57743698e+00 -2.41314285e-01 -9.07612480e-01
 -4.19742424e-01 -1.16125087e-01 -6.88705137e-01 -7.43485645e-01
 -1.73298214e+00 -2.07752134e+00 -1.30547383e+00 -2.03465516e+00
  7.14162716e-01  1.48383130e+00 -9.69032355e-01 -1.22580518e+00
 -2.16503464e-01  7.91536559e-02 -8.40839949e-01 -1.41940218e+00
  2.49085464e+01]
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.649156303947
gradient value of function right now is: [ 3.57635284e-08  3.98475904e-08  3.97911474e-08  3.99102308e-08
 -3.57633364e-08 -3.98473764e-08 -3.97909337e-08 -3.99100165e-08
  3.07070952e-09  1.31944664e-08  4.80836118e-10  1.31604555e-08
  4.83713545e-10  2.07845115e-09  7.57839656e-11  2.07308776e-09
  7.00467413e-10  3.00984076e-09  1.09666725e-10  3.00208534e-09
  4.08719804e-10  1.75623438e-09  6.39582426e-11  1.75171369e-09
  9.56037172e-11  8.76066257e-10  7.61107194e-10  9.98309885e-10
  2.14227168e-11  1.80356417e-10  1.58746514e-10  2.08568732e-10
 -1.82561558e-11 -1.56202617e-10 -1.37135382e-10 -1.80117128e-10
  2.52480908e-11  2.09701686e-10  1.84999779e-10  2.43113232e-10
 -2.19016749e-11 -4.80443830e-11 -3.46894992e-11 -4.73164867e-11
  2.80208285e-11  2.70334391e-11  2.81688130e-11  2.57585804e-11
  6.39440202e-11  1.36194677e-10  9.94344025e-11  1.34144075e-10
  7.28350061e-12  5.99182225e-12  6.82673217e-12  5.67086161e-12
  9.21405682e-12 -1.88747521e-12  1.27562071e-11 -9.07386707e-12
  3.34820136e-11  5.63889328e-11  2.44551081e-11 -6.45027908e-12
  2.10461305e+00]
supnorm grad right now is: 2.1046130467594195
Weights right now are: 
[-2.09433013e+00 -3.46990053e+00 -3.96520885e+00 -2.99003016e+00
  1.30411089e+00  3.48436418e+00  4.53651489e+00  4.40511321e+00
  3.14053072e-02 -1.31242668e+00  6.75672275e-01 -8.33559021e-01
 -3.70444489e-02 -2.38984283e+00  4.15896227e-01 -2.53379366e+00
 -1.24832491e+00 -2.12663065e+00 -6.11527523e-01 -2.30375819e+00
 -1.28783244e+00 -2.34487252e+00 -1.54151739e+00 -2.45072384e+00
  1.44225793e+00  5.69405494e-01  9.77012427e-03  5.78133660e-01
 -1.22145599e+00 -1.46341602e+00 -2.34454891e+00 -1.94614057e+00
  3.51688480e-01  1.08505925e+00  1.49331338e+00  1.22514937e+00
 -1.14184987e+00 -1.89162558e+00 -1.10575031e+00 -2.18512563e+00
  3.78716474e-01  3.45647482e-01  1.39101919e+00  1.73056980e+00
 -2.77032532e-02 -1.57744262e+00 -2.41320145e-01 -9.07617855e-01
 -4.19755743e-01 -1.16153347e-01 -6.88725785e-01 -7.43513480e-01
 -1.73298365e+00 -2.07752259e+00 -1.30547525e+00 -2.03465634e+00
  7.14160805e-01  1.48383169e+00 -9.69034997e-01 -1.22580331e+00
 -2.16510403e-01  7.91419539e-02 -8.40845018e-01 -1.41940085e+00
  2.50926769e+01]
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15992.727594489488
gradient value of function right now is: [ 3.40578954e-08  3.79258374e-08  3.78723271e-08  3.79854178e-08
 -3.40587398e-08 -3.79267777e-08 -3.78732660e-08 -3.79863596e-08
  2.92368584e-09  1.25585020e-08  4.58064447e-10  1.25260775e-08
  4.61221294e-10  1.98113967e-09  7.22996293e-11  1.97601907e-09
  6.67297463e-10  2.86634871e-09  1.04530743e-10  2.85895095e-09
  3.89652967e-10  1.67374242e-09  6.10078183e-11  1.66942703e-09
  9.15544479e-11  8.35390500e-10  7.26220897e-10  9.52635912e-10
  2.05180340e-11  1.71972517e-10  1.51469800e-10  1.99030113e-10
 -1.74380781e-11 -1.48538521e-10 -1.30494799e-10 -1.71413477e-10
  2.41929740e-11  2.00054283e-10  1.76607803e-10  2.32111261e-10
 -2.11579258e-11 -4.58101173e-11 -3.32242842e-11 -4.50968958e-11
  2.69766975e-11  2.58071088e-11  2.69978394e-11  2.45669367e-11
  6.15325390e-11  1.29531967e-10  9.49498442e-11  1.27526000e-10
  6.99998369e-12  5.72949632e-12  6.54197223e-12  5.41696572e-12
  8.82981364e-12 -1.95262685e-12  1.22459804e-11 -8.95353971e-12
  3.19849025e-11  5.30035773e-11  2.34487568e-11 -6.57557160e-12
 -5.14800120e+00]
supnorm grad right now is: 5.1480012013058625
Weights right now are: 
[-2.10133413e+00 -3.47770244e+00 -3.97299973e+00 -2.99784434e+00
  1.31111485e+00  3.49216606e+00  4.54430574e+00  4.41292735e+00
  3.08040037e-02 -1.31501020e+00  6.75577963e-01 -8.36135855e-01
 -3.71392341e-02 -2.39025008e+00  4.15881352e-01 -2.53419986e+00
 -1.24846211e+00 -2.12722013e+00 -6.11549038e-01 -2.30434615e+00
 -1.28791252e+00 -2.34521659e+00 -1.54152995e+00 -2.45106701e+00
  1.44223907e+00  5.69233988e-01  9.62099120e-03  5.77937999e-01
 -1.22146022e+00 -1.46345138e+00 -2.34458007e+00 -1.94618152e+00
  3.51692084e-01  1.08508983e+00  1.49334026e+00  1.22518467e+00
 -1.14185487e+00 -1.89166670e+00 -1.10578663e+00 -2.18517338e+00
  3.78720840e-01  3.45656886e-01  1.39102601e+00  1.73057905e+00
 -2.77088638e-02 -1.57744793e+00 -2.41325732e-01 -9.07622909e-01
 -4.19768474e-01 -1.16179971e-01 -6.88745311e-01 -7.43539680e-01
 -1.73298510e+00 -2.07752376e+00 -1.30547660e+00 -2.03465746e+00
  7.14158987e-01  1.48383213e+00 -9.69037526e-01 -1.22580143e+00
 -2.16516979e-01  7.91306452e-02 -8.40849848e-01 -1.41939940e+00
  2.46267022e+01]
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.781664750766
gradient value of function right now is: [ 3.18317235e-08  3.54274047e-08  3.53775946e-08  3.54829939e-08
 -3.18305556e-08 -3.54261051e-08 -3.53762968e-08 -3.54816922e-08
  2.73183217e-09  1.17303243e-08  4.27464914e-10  1.17000869e-08
  4.31537831e-10  1.85299152e-09  6.75608453e-11  1.84820988e-09
  6.23848796e-10  2.67878469e-09  9.76009215e-11  2.67188221e-09
  3.64558162e-10  1.56540399e-09  5.70065976e-11  1.56137446e-09
  8.54862269e-11  7.82869495e-10  6.80220063e-10  8.92204292e-10
  1.91154120e-11  1.60826431e-10  1.41574314e-10  1.86005850e-10
 -1.62096760e-11 -1.38599689e-10 -1.21696753e-10 -1.59838513e-10
  2.25441801e-11  1.87124212e-10  1.65102218e-10  2.16963978e-10
 -1.96569511e-11 -4.29966737e-11 -3.10757849e-11 -4.23414042e-11
  2.49620988e-11  2.40187493e-11  2.50609538e-11  2.28806557e-11
  5.70585014e-11  1.21299383e-10  8.86178618e-11  1.19464196e-10
  6.49087538e-12  5.33172622e-12  6.07920663e-12  5.04501139e-12
  8.22379050e-12 -1.70630525e-12  1.13710882e-11 -8.12734179e-12
  2.98887958e-11  5.02048988e-11  2.18393332e-11 -5.81825748e-12
  8.49086958e-01]
supnorm grad right now is: 0.8490869578451379
Weights right now are: 
[-2.10808991e+00 -3.48522359e+00 -3.98051027e+00 -3.00537729e+00
  1.31787062e+00  3.49968719e+00  4.55181627e+00  4.42046029e+00
  3.02242812e-02 -1.31750055e+00  6.75487249e-01 -8.38619804e-01
 -3.72307393e-02 -2.39064316e+00  4.15867026e-01 -2.53459193e+00
 -1.24859446e+00 -2.12778871e+00 -6.11569746e-01 -2.30491326e+00
 -1.28798983e+00 -2.34554871e+00 -1.54154204e+00 -2.45139829e+00
  1.44222095e+00  5.69067957e-01  9.47684984e-03  5.77748861e-01
 -1.22146426e+00 -1.46348551e+00 -2.34461008e+00 -1.94622096e+00
  3.51695519e-01  1.08511928e+00  1.49336609e+00  1.22521861e+00
 -1.14185963e+00 -1.89170639e+00 -1.10582160e+00 -2.18521935e+00
  3.78724998e-01  3.45666041e-01  1.39103258e+00  1.73058807e+00
 -2.77140513e-02 -1.57745306e+00 -2.41330995e-01 -9.07627806e-01
 -4.19780483e-01 -1.16205778e-01 -6.88764019e-01 -7.43565108e-01
 -1.73298644e+00 -2.07752491e+00 -1.30547787e+00 -2.03465854e+00
  7.14157252e-01  1.48383247e+00 -9.69039909e-01 -1.22579978e+00
 -2.16523228e-01  7.91190875e-02 -8.40854446e-01 -1.41939825e+00
  2.50409219e+01]
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.662180165098
gradient value of function right now is: [ 3.03228401e-08  3.37314353e-08  3.36841700e-08  3.37843241e-08
 -3.03235041e-08 -3.37321739e-08 -3.36849076e-08 -3.37850638e-08
  2.60182135e-09  1.11686755e-08  4.07104566e-10  1.11398717e-08
  4.11529911e-10  1.76654309e-09  6.44257023e-11  1.76198228e-09
  5.94468079e-10  2.55185014e-09  9.30004443e-11  2.54527146e-09
  3.47620114e-10  1.49221911e-09  5.43556638e-11  1.48837605e-09
  8.16874415e-11  7.46949541e-10  6.49158427e-10  8.51484005e-10
  1.82547352e-11  1.53347473e-10  1.35023210e-10  1.77404671e-10
 -1.54443401e-11 -1.31848855e-10 -1.15797333e-10 -1.52095013e-10
  2.15362964e-11  1.78486656e-10  1.57518579e-10  2.07005294e-10
 -1.88575899e-11 -4.10407511e-11 -2.97135549e-11 -4.04084982e-11
  2.38624011e-11  2.28878817e-11  2.39158681e-11  2.17949030e-11
  5.45711067e-11  1.15525146e-10  8.45208952e-11  1.13758376e-10
  6.20083995e-12  5.08574422e-12  5.80191293e-12  4.81026818e-12
  7.85701005e-12 -1.67868260e-12  1.08670832e-11 -7.84931315e-12
  2.85269407e-11  4.76350589e-11  2.08730311e-11 -5.69277465e-12
 -2.03049411e+00]
supnorm grad right now is: 2.030494107173778
Weights right now are: 
[-2.11426133e+00 -3.49209061e+00 -3.98736765e+00 -3.01225508e+00
  1.32404203e+00  3.50655419e+00  4.55867363e+00  4.42733806e+00
  2.96946598e-02 -1.31977427e+00  6.75404399e-01 -8.40887662e-01
 -3.73144494e-02 -2.39100254e+00  4.15853925e-01 -2.53495037e+00
 -1.24871543e+00 -2.12830806e+00 -6.11588667e-01 -2.30543127e+00
 -1.28806055e+00 -2.34585230e+00 -1.54155309e+00 -2.45170109e+00
  1.44220436e+00  5.68916056e-01  9.34484740e-03  5.77575732e-01
 -1.22146797e+00 -1.46351670e+00 -2.34463754e+00 -1.94625703e+00
  3.51698658e-01  1.08514614e+00  1.49338967e+00  1.22524958e+00
 -1.14186400e+00 -1.89174269e+00 -1.10585363e+00 -2.18526143e+00
  3.78728821e-01  3.45674383e-01  1.39103862e+00  1.73059629e+00
 -2.77188807e-02 -1.57745772e+00 -2.41335854e-01 -9.07632245e-01
 -4.19791563e-01 -1.16229279e-01 -6.88781229e-01 -7.43588254e-01
 -1.73298770e+00 -2.07752594e+00 -1.30547905e+00 -2.03465952e+00
  7.14155644e-01  1.48383279e+00 -9.69042128e-01 -1.22579822e+00
 -2.16529054e-01  7.91093640e-02 -8.40858718e-01 -1.41939715e+00
  2.48348741e+01]
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.528570524037
gradient value of function right now is: [ 2.86034534e-08  3.18037001e-08  3.17592739e-08  3.18535168e-08
 -2.86039050e-08 -3.18042021e-08 -3.17597752e-08 -3.18540196e-08
  2.45370164e-09  1.05296391e-08  3.83560666e-10  1.05025137e-08
  3.88570930e-10  1.66747992e-09  6.07730790e-11  1.66317971e-09
  5.60908152e-10  2.40705463e-09  8.76660337e-11  2.40085623e-09
  3.28211402e-10  1.40847448e-09  5.12716131e-11  1.40485119e-09
  7.70285766e-11  7.06170916e-10  6.13501892e-10  8.04654298e-10
  1.71842649e-11  1.44733200e-10  1.27390927e-10  1.67362254e-10
 -1.45091299e-11 -1.24190604e-10 -1.09030981e-10 -1.43195601e-10
  2.02781714e-11  1.68492932e-10  1.48644397e-10  1.95325933e-10
 -1.77187823e-11 -3.88475207e-11 -2.80552880e-11 -3.82586023e-11
  2.23562348e-11  2.15154593e-11  2.24504851e-11  2.04985179e-11
  5.11946197e-11  1.09130288e-10  7.96548334e-11  1.07490327e-10
  5.82088570e-12  4.78090196e-12  5.45265869e-12  4.52460062e-12
  7.39115852e-12 -1.50422931e-12  1.01996753e-11 -7.24641395e-12
  2.69100940e-11  4.53686661e-11  1.96362869e-11 -5.15160981e-12
  2.89151353e+00]
supnorm grad right now is: 2.891513532882447
Weights right now are: 
[-2.12016574e+00 -3.49865730e+00 -3.99392515e+00 -3.01883206e+00
  1.32994644e+00  3.51312089e+00  4.56523114e+00  4.43391505e+00
  2.91881513e-02 -1.32194838e+00  6.75325267e-01 -8.43056189e-01
 -3.73946037e-02 -2.39134659e+00  4.15841396e-01 -2.53529354e+00
 -1.24883119e+00 -2.12880493e+00 -6.11606749e-01 -2.30592686e+00
 -1.28812826e+00 -2.34614294e+00 -1.54156366e+00 -2.45199099e+00
  1.44218851e+00  5.68770344e-01  9.21833233e-03  5.77409788e-01
 -1.22147150e+00 -1.46354657e+00 -2.34466379e+00 -1.94629153e+00
  3.51701643e-01  1.08517179e+00  1.49341218e+00  1.22527914e+00
 -1.14186816e+00 -1.89177744e+00 -1.10588425e+00 -2.18530168e+00
  3.78732460e-01  3.45682408e-01  1.39104440e+00  1.73060419e+00
 -2.77234236e-02 -1.57746218e+00 -2.41340449e-01 -9.07636491e-01
 -4.19802035e-01 -1.16251852e-01 -6.88797619e-01 -7.43610486e-01
 -1.73298887e+00 -2.07752693e+00 -1.30548016e+00 -2.03466046e+00
  7.14154126e-01  1.48383311e+00 -9.69044222e-01 -1.22579672e+00
 -2.16534588e-01  7.90995092e-02 -8.40862748e-01 -1.41939606e+00
  2.51806167e+01]
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15991.85893058771
gradient value of function right now is: [ 2.76786251e-08  3.07618713e-08  3.07190399e-08  3.08100390e-08
 -2.76776339e-08 -3.07607699e-08 -3.07179400e-08 -3.08089359e-08
  2.37384249e-09  1.01842357e-08  3.71440193e-10  1.01579401e-08
  3.76376806e-10  1.61472339e-09  5.89235942e-11  1.61054971e-09
  5.42907546e-10  2.32918942e-09  8.49357529e-11  2.32317777e-09
  3.17858378e-10  1.36368346e-09  4.97027790e-11  1.36016735e-09
  7.50094597e-11  6.83727082e-10  5.94497243e-10  7.79825706e-10
  1.67480725e-11  1.40209683e-10  1.23522485e-10  1.62304852e-10
 -1.41081918e-11 -1.20031920e-10 -1.05475637e-10 -1.38546742e-10
  1.97722894e-11  1.63307168e-10  1.44201134e-10  1.89516997e-10
 -1.74428040e-11 -3.75915828e-11 -2.73081573e-11 -3.70012458e-11
  2.19607596e-11  2.08968628e-11  2.19217896e-11  1.98843494e-11
  5.02199659e-11  1.05382511e-10  7.73348613e-11  1.03739043e-10
  5.70476503e-12  4.65213085e-12  5.32241231e-12  4.39659437e-12
  7.20592140e-12 -1.62211443e-12  9.97390252e-12 -7.35305899e-12
  2.61283826e-11  4.31050602e-11  1.91564761e-11 -5.45004300e-12
 -6.80961027e+00]
supnorm grad right now is: 6.809610266840565
Weights right now are: 
[-2.12577104e+00 -3.50488851e+00 -4.00014767e+00 -3.02507303e+00
  1.33555172e+00  3.51935207e+00  4.57145363e+00  4.44015599e+00
  2.87073176e-02 -1.32401137e+00  6.75250102e-01 -8.45113856e-01
 -3.74707896e-02 -2.39167345e+00  4.15829480e-01 -2.53561956e+00
 -1.24894113e+00 -2.12927661e+00 -6.11623932e-01 -2.30639733e+00
 -1.28819260e+00 -2.34641902e+00 -1.54157371e+00 -2.45226635e+00
  1.44217340e+00  5.68631880e-01  9.09800233e-03  5.77251986e-01
 -1.22147487e+00 -1.46357493e+00 -2.34468878e+00 -1.94632435e+00
  3.51704488e-01  1.08519611e+00  1.49343354e+00  1.22530719e+00
 -1.14187215e+00 -1.89181047e+00 -1.10591341e+00 -2.18533999e+00
  3.78735938e-01  3.45690014e-01  1.39104991e+00  1.73061168e+00
 -2.77278483e-02 -1.57746638e+00 -2.41344868e-01 -9.07640491e-01
 -4.19812102e-01 -1.16273222e-01 -6.88813259e-01 -7.43631532e-01
 -1.73299002e+00 -2.07752786e+00 -1.30548123e+00 -2.03466134e+00
  7.14152677e-01  1.48383342e+00 -9.69046230e-01 -1.22579526e+00
 -2.16539864e-01  7.90906217e-02 -8.40866601e-01 -1.41939501e+00
  2.44630370e+01]
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.206614640447
gradient value of function right now is: [ 2.59983704e-08  2.88822195e-08  2.88421100e-08  2.89273902e-08
 -2.59986992e-08 -2.88825846e-08 -2.88424747e-08 -2.89277559e-08
  2.22921819e-09  9.56105793e-09  3.48176535e-10  9.53643908e-09
  3.53825198e-10  1.51754204e-09  5.52921392e-11  1.51363031e-09
  5.10077127e-10  2.18771975e-09  7.96543414e-11  2.18208876e-09
  2.98820842e-10  1.28164523e-09  4.66410361e-11  1.27834974e-09
  7.01992208e-11  6.44011657e-10  5.59458036e-10  7.33743877e-10
  1.56289740e-11  1.31724931e-10  1.15932354e-10  1.52302204e-10
 -1.31440894e-11 -1.12583467e-10 -9.88332511e-11 -1.29797293e-10
  1.84524358e-11  1.53427359e-10  1.35343204e-10  1.77840298e-10
 -1.61610198e-11 -3.54783930e-11 -2.56111783e-11 -3.49421334e-11
  2.02716009e-11  1.95037390e-11  2.03567854e-11  1.85828761e-11
  4.64948636e-11  9.92833870e-11  7.24258871e-11  9.77975984e-11
  5.28358379e-12  4.33814600e-12  4.94938227e-12  4.10595970e-12
  6.72173496e-12 -1.35092233e-12  9.26059000e-12 -6.55479329e-12
  2.45052879e-11  4.14097411e-11  1.78647364e-11 -4.64030000e-12
  4.25619654e+00]
supnorm grad right now is: 4.256196543889612
Weights right now are: 
[-2.13103819e+00 -3.51074126e+00 -4.00599229e+00 -3.03093494e+00
  1.34081886e+00  3.52520482e+00  4.57729824e+00  4.44601789e+00
  2.82555346e-02 -1.32594891e+00  6.75179552e-01 -8.47046399e-01
 -3.75424531e-02 -2.39198079e+00  4.15818283e-01 -2.53592611e+00
 -1.24904447e+00 -2.12971981e+00 -6.11640067e-01 -2.30683939e+00
 -1.28825313e+00 -2.34667858e+00 -1.54158316e+00 -2.45252525e+00
  1.44215921e+00  5.68501540e-01  8.98470417e-03  5.77103445e-01
 -1.22147803e+00 -1.46360160e+00 -2.34471226e+00 -1.94635519e+00
  3.51707150e-01  1.08521893e+00  1.49345358e+00  1.22533351e+00
 -1.14187588e+00 -1.89184154e+00 -1.10594083e+00 -2.18537601e+00
  3.78739227e-01  3.45697164e-01  1.39105512e+00  1.73061872e+00
 -2.77319682e-02 -1.57747034e+00 -2.41349008e-01 -9.07644259e-01
 -4.19821558e-01 -1.16293282e-01 -6.88827999e-01 -7.43651285e-01
 -1.73299109e+00 -2.07752874e+00 -1.30548224e+00 -2.03466217e+00
  7.14151298e-01  1.48383370e+00 -9.69048135e-01 -1.22579389e+00
 -2.16544873e-01  7.90828643e-02 -8.40870269e-01 -1.41939404e+00
  2.53015444e+01]
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.476909625608
gradient value of function right now is: [ 2.49315912e-08  2.76860568e-08  2.76477147e-08  2.77293281e-08
 -2.49301310e-08 -2.76844355e-08 -2.76460957e-08 -2.77277043e-08
  2.13721706e-09  9.16414877e-09  3.33742587e-10  9.14054888e-09
  3.39585141e-10  1.45609873e-09  5.30565670e-11  1.45234490e-09
  4.89243329e-10  2.09783280e-09  7.63861440e-11  2.09243247e-09
  2.86770385e-10  1.22964948e-09  4.47515011e-11  1.22648727e-09
  6.74472345e-11  6.18425256e-10  5.37277907e-10  7.04657102e-10
  1.50057857e-11  1.26400771e-10  1.11256836e-10  1.46160988e-10
 -1.25963727e-11 -1.07830176e-10 -9.46693485e-11 -1.24329720e-10
  1.77212456e-11  1.47265493e-10  1.29919506e-10  1.70714921e-10
 -1.55576561e-11 -3.40853303e-11 -2.46223728e-11 -3.35680776e-11
  1.94596491e-11  1.86946157e-11  1.95262246e-11  1.78093132e-11
  4.46576227e-11  9.52129947e-11  6.94931007e-11  9.37828477e-11
  5.07176091e-12  4.16090525e-12  4.74880983e-12  3.93762512e-12
  6.45359952e-12 -1.31120587e-12  8.88882926e-12 -6.31565813e-12
  2.35239481e-11  3.96741432e-11  1.71562224e-11 -4.49450107e-12
  3.14150224e+00]
supnorm grad right now is: 3.141502238528488
Weights right now are: 
[-2.13610764e+00 -3.51637206e+00 -4.01161527e+00 -3.03657454e+00
  1.34588829e+00  3.53083559e+00  4.58292120e+00  4.45165747e+00
  2.78208818e-02 -1.32781290e+00  6.75111585e-01 -8.48905579e-01
 -3.76114772e-02 -2.39227680e+00  4.15807484e-01 -2.53622135e+00
 -1.24914394e+00 -2.13014640e+00 -6.11655619e-01 -2.30726488e+00
 -1.28831141e+00 -2.34692854e+00 -1.54159227e+00 -2.45277456e+00
  1.44214544e+00  5.68376040e-01  8.87556881e-03  5.76960290e-01
 -1.22148110e+00 -1.46362730e+00 -2.34473490e+00 -1.94638494e+00
  3.51709726e-01  1.08524088e+00  1.49347286e+00  1.22535883e+00
 -1.14187950e+00 -1.89187149e+00 -1.10596727e+00 -2.18541076e+00
  3.78742449e-01  3.45704072e-01  1.39106015e+00  1.73062552e+00
 -2.77359565e-02 -1.57747418e+00 -2.41353012e-01 -9.07647913e-01
 -4.19830771e-01 -1.16312576e-01 -6.88842188e-01 -7.43670276e-01
 -1.73299213e+00 -2.07752960e+00 -1.30548321e+00 -2.03466298e+00
  7.14149957e-01  1.48383399e+00 -9.69049991e-01 -1.22579256e+00
 -2.16549678e-01  7.90751130e-02 -8.40873836e-01 -1.41939306e+00
  2.51954802e+01]
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.645002252491
gradient value of function right now is: [ 2.39393095e-08  2.65739264e-08  2.65372230e-08  2.66154329e-08
 -2.39407760e-08 -2.65755542e-08 -2.65388485e-08 -2.66170632e-08
  2.05179781e-09  8.79571859e-09  3.20337580e-10  8.77306534e-09
  3.26358466e-10  1.39904060e-09  5.09794551e-11  1.39543353e-09
  4.69907656e-10  2.01442785e-09  7.33520363e-11  2.00924174e-09
  2.75583627e-10  1.18139096e-09  4.29968356e-11  1.17835257e-09
  6.48843135e-11  5.94663097e-10  5.16671570e-10  6.77632122e-10
  1.44252326e-11  1.21454032e-10  1.06911138e-10  1.40452502e-10
 -1.20866582e-11 -1.03417671e-10 -9.08026084e-11 -1.19251971e-10
  1.70399408e-11  1.41539081e-10  1.24877238e-10  1.64090073e-10
 -1.49923977e-11 -3.27919577e-11 -2.37019169e-11 -3.22927893e-11
  1.87007166e-11  1.79410801e-11  1.87515669e-11  1.70893992e-11
  4.29408233e-11  9.14355916e-11  6.67658251e-11  9.00583532e-11
  4.87425249e-12  3.99574836e-12  4.56193820e-12  3.78087584e-12
  6.20390061e-12 -1.27053840e-12  8.54084374e-12 -6.08720374e-12
  2.26114302e-11  3.80680007e-11  1.64959520e-11 -4.34849860e-12
  2.13619178e+00]
supnorm grad right now is: 2.1361917793616474
Weights right now are: 
[-2.14100751e+00 -3.52181232e+00 -4.01704801e+00 -3.04202330e+00
  1.35078815e+00  3.53627585e+00  4.58835393e+00  4.45710623e+00
  2.74009268e-02 -1.32961358e+00  6.75046044e-01 -8.50701633e-01
 -3.76782347e-02 -2.39256304e+00  4.15797060e-01 -2.53650686e+00
 -1.24924010e+00 -2.13055870e+00 -6.11670623e-01 -2.30767612e+00
 -1.28836779e+00 -2.34717028e+00 -1.54160106e+00 -2.45301568e+00
  1.44213219e+00  5.68254364e-01  8.76991318e-03  5.76821707e-01
 -1.22148404e+00 -1.46365215e+00 -2.34475676e+00 -1.94641366e+00
  3.51712194e-01  1.08526206e+00  1.49349145e+00  1.22538324e+00
 -1.14188297e+00 -1.89190044e+00 -1.10599279e+00 -2.18544429e+00
  3.78745495e-01  3.45710792e-01  1.39106499e+00  1.73063214e+00
 -2.77397322e-02 -1.57747786e+00 -2.41356819e-01 -9.07651419e-01
 -4.19839491e-01 -1.16331317e-01 -6.88855811e-01 -7.43688744e-01
 -1.73299311e+00 -2.07753041e+00 -1.30548413e+00 -2.03466375e+00
  7.14148694e-01  1.48383422e+00 -9.69051722e-01 -1.22579136e+00
 -2.16554269e-01  7.90672480e-02 -8.40877192e-01 -1.41939224e+00
  2.51221567e+01]
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.284599646795
gradient value of function right now is: [ 2.29200001e-08  2.54329704e-08  2.53979323e-08  2.54726665e-08
 -2.29209987e-08 -2.54340784e-08 -2.53990388e-08 -2.54737762e-08
  1.96397951e-09  8.41720647e-09  3.06475778e-10  8.39553693e-09
  3.12705293e-10  1.34018552e-09  4.88226182e-11  1.33673161e-09
  4.49992497e-10  1.92858482e-09  7.02086247e-11  1.92362175e-09
  2.64040180e-10  1.13163022e-09  4.11754828e-11  1.12872100e-09
  6.21644503e-11  5.70223440e-10  4.95383611e-10  6.49692147e-10
  1.38062194e-11  1.16341118e-10  1.02399058e-10  1.34520173e-10
 -1.15480887e-11 -9.88938486e-11 -8.68209785e-11 -1.14018981e-10
  1.63123231e-11  1.35608287e-10  1.19631595e-10  1.57191705e-10
 -1.43546837e-11 -3.14671203e-11 -2.27272981e-11 -3.09903144e-11
  1.78619736e-11  1.71467213e-11  1.79183664e-11  1.63348403e-11
  4.10456743e-11  8.75949213e-11  6.39137196e-11  8.62825363e-11
  4.65949744e-12  3.82001772e-12  4.36200109e-12  3.61516232e-12
  5.93717784e-12 -1.19694741e-12  8.16578318e-12 -5.79018582e-12
  2.16645700e-11  3.65771176e-11  1.57890493e-11 -4.11076337e-12
  3.94921425e+00]
supnorm grad right now is: 3.949214246940949
Weights right now are: 
[-2.14575497e+00 -3.52708140e+00 -4.02230982e+00 -3.04730061e+00
  1.35553563e+00  3.54154495e+00  4.59361576e+00  4.46238356e+00
  2.69940641e-02 -1.33135752e+00  6.74982490e-01 -8.52441076e-01
 -3.77429803e-02 -2.39284056e+00  4.15786941e-01 -2.53678366e+00
 -1.24933330e+00 -2.13095818e+00 -6.11685179e-01 -2.30807457e+00
 -1.28842246e+00 -2.34740460e+00 -1.54160959e+00 -2.45324940e+00
  1.44211929e+00  5.68136437e-01  8.66739940e-03  5.76687250e-01
 -1.22148691e+00 -1.46367625e+00 -2.34477798e+00 -1.94644154e+00
  3.51714596e-01  1.08528256e+00  1.49350946e+00  1.22540689e+00
 -1.14188636e+00 -1.89192853e+00 -1.10601759e+00 -2.18547687e+00
  3.78748500e-01  3.45717291e-01  1.39106971e+00  1.73063854e+00
 -2.77434620e-02 -1.57748143e+00 -2.41360555e-01 -9.07654818e-01
 -4.19848076e-01 -1.16349419e-01 -6.88869084e-01 -7.43706568e-01
 -1.73299408e+00 -2.07753121e+00 -1.30548504e+00 -2.03466450e+00
  7.14147451e-01  1.48383449e+00 -9.69053435e-01 -1.22579014e+00
 -2.16558745e-01  7.90598526e-02 -8.40880499e-01 -1.41939134e+00
  2.52757425e+01]
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.737469332547
gradient value of function right now is: [ 2.21200139e-08  2.45365370e-08  2.45028193e-08  2.45748128e-08
 -2.21208291e-08 -2.45374412e-08 -2.45037222e-08 -2.45757184e-08
  1.89501181e-09  8.11978783e-09  2.95706528e-10  8.09887631e-09
  3.02023597e-10  1.29411347e-09  4.71537350e-11  1.29077709e-09
  4.34376422e-10  1.86123590e-09  6.77705918e-11  1.85644439e-09
  2.55000703e-10  1.09264113e-09  3.97648919e-11  1.08983112e-09
  6.01330075e-11  5.50940419e-10  4.78714481e-10  6.27844595e-10
  1.33484693e-11  1.12352624e-10  9.89059866e-11  1.29935012e-10
 -1.11457925e-11 -9.53355004e-11 -8.37120020e-11 -1.09939052e-10
  1.57752533e-11  1.30994297e-10  1.15581095e-10  1.51873851e-10
 -1.39284855e-11 -3.04130265e-11 -2.19954612e-11 -2.99483644e-11
  1.72801090e-11  1.65529879e-11  1.73140738e-11  1.57649048e-11
  3.97317276e-11  8.45170442e-11  6.17356467e-11  8.32403416e-11
  4.50508300e-12  3.69049488e-12  4.21486919e-12  3.49159184e-12
  5.74293715e-12 -1.18445347e-12  7.89851154e-12 -5.64319946e-12
  2.09332229e-11  3.51905638e-11  1.52763113e-11 -4.04899492e-12
  1.43431971e+00]
supnorm grad right now is: 1.434319714247563
Weights right now are: 
[-2.15033627e+00 -3.53216418e+00 -4.02738561e+00 -3.05239133e+00
  1.36011698e+00  3.54662778e+00  4.59869160e+00  4.46747432e+00
  2.66014866e-02 -1.33303960e+00  6.74921257e-01 -8.54118826e-01
 -3.78055138e-02 -2.39310850e+00  4.15777182e-01 -2.53705091e+00
 -1.24942326e+00 -2.13134364e+00 -6.11699208e-01 -2.30845904e+00
 -1.28847526e+00 -2.34763083e+00 -1.54161782e+00 -2.45347505e+00
  1.44210687e+00  5.68022387e-01  8.56829236e-03  5.76557302e-01
 -1.22148967e+00 -1.46369950e+00 -2.34479845e+00 -1.94646843e+00
  3.51716901e-01  1.08530231e+00  1.49352680e+00  1.22542967e+00
 -1.14188962e+00 -1.89195564e+00 -1.10604151e+00 -2.18550831e+00
  3.78751369e-01  3.45723576e-01  1.39107426e+00  1.73064473e+00
 -2.77470412e-02 -1.57748484e+00 -2.41364145e-01 -9.07658073e-01
 -4.19856289e-01 -1.16366908e-01 -6.88881893e-01 -7.43723794e-01
 -1.73299501e+00 -2.07753197e+00 -1.30548591e+00 -2.03466522e+00
  7.14146253e-01  1.48383471e+00 -9.69055090e-01 -1.22578898e+00
 -2.16563130e-01  7.90528896e-02 -8.40883689e-01 -1.41939055e+00
  2.50343094e+01]
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.38876508118
gradient value of function right now is: [ 2.14665604e-08  2.38037208e-08  2.37710908e-08  2.38408385e-08
 -2.14666117e-08 -2.38037777e-08 -2.37711475e-08 -2.38408954e-08
  1.83863094e-09  7.87654070e-09  2.87010473e-10  7.85623444e-09
  2.93317142e-10  1.25654260e-09  4.58107109e-11  1.25329970e-09
  4.21623464e-10  1.80620943e-09  6.58042819e-11  1.80155471e-09
  2.47624604e-10  1.06081106e-09  3.86283317e-11  1.05808005e-09
  5.85594691e-11  5.35066256e-10  4.65105600e-10  6.10030766e-10
  1.30003774e-11  1.09110724e-10  9.60937358e-11  1.26249388e-10
 -1.08362292e-11 -9.24230702e-11 -8.11896373e-11 -1.06633693e-10
  1.53683383e-11  1.27254778e-10  1.12330008e-10  1.47612586e-10
 -1.36392160e-11 -2.95349699e-11 -2.14211006e-11 -2.90759365e-11
  1.68857414e-11  1.60870245e-11  1.68697697e-11  1.53117404e-11
  3.88109594e-11  8.19452346e-11  6.00095217e-11  8.06851658e-11
  4.39744634e-12  3.59052245e-12  4.10636843e-12  3.39471439e-12
  5.59365636e-12 -1.21228597e-12  7.70277592e-12 -5.60353427e-12
  2.03513820e-11  3.38692887e-11  1.48848792e-11 -4.10524374e-12
 -3.29011507e+00]
supnorm grad right now is: 3.2901150739304366
Weights right now are: 
[-2.15468346e+00 -3.53698557e+00 -4.03220038e+00 -3.05722023e+00
  1.36446416e+00  3.55144916e+00  4.60350636e+00  4.47230322e+00
  2.62291305e-02 -1.33463506e+00  6.74863124e-01 -8.55710167e-01
 -3.78648848e-02 -2.39336289e+00  4.15767908e-01 -2.53730464e+00
 -1.24950863e+00 -2.13170943e+00 -6.11712534e-01 -2.30882388e+00
 -1.28852538e+00 -2.34784560e+00 -1.54162564e+00 -2.45368927e+00
  1.44209502e+00  5.67914090e-01  8.47418079e-03  5.76433855e-01
 -1.22149230e+00 -1.46372159e+00 -2.34481790e+00 -1.94649398e+00
  3.51719097e-01  1.08532104e+00  1.49354325e+00  1.22545127e+00
 -1.14189273e+00 -1.89198140e+00 -1.10606425e+00 -2.18553818e+00
  3.78754119e-01  3.45729560e-01  1.39107858e+00  1.73065062e+00
 -2.77504638e-02 -1.57748810e+00 -2.41367558e-01 -9.07661168e-01
 -4.19864131e-01 -1.16383524e-01 -6.88894020e-01 -7.43740151e-01
 -1.73299591e+00 -2.07753270e+00 -1.30548674e+00 -2.03466591e+00
  7.14145119e-01  1.48383497e+00 -9.69056652e-01 -1.22578783e+00
 -2.16567275e-01  7.90456223e-02 -8.40886704e-01 -1.41938968e+00
  2.47515472e+01]
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.154723528827
gradient value of function right now is: [ 2.07273193e-08  2.29764889e-08  2.29450658e-08  2.30122969e-08
 -2.07276320e-08 -2.29768356e-08 -2.29454120e-08 -2.30126441e-08
  1.77494523e-09  7.60209938e-09  2.77024499e-10  7.58249840e-09
  2.83418432e-10  1.21387934e-09  4.42575549e-11  1.21074620e-09
  4.07185761e-10  1.74398816e-09  6.35406795e-11  1.73949327e-09
  2.39252932e-10  1.02472918e-09  3.73163539e-11  1.02209076e-09
  5.66344075e-11  5.17238817e-10  4.49642932e-10  5.89751867e-10
  1.25654672e-11  1.05410335e-10  9.28422721e-11  1.21978261e-10
 -1.04569546e-11 -8.91450487e-11 -7.83163882e-11 -1.02860549e-10
  1.48574715e-11  1.22966918e-10  1.08553677e-10  1.42650973e-10
 -1.32125478e-11 -2.85627078e-11 -2.07280566e-11 -2.81171848e-11
  1.63184241e-11  1.55262261e-11  1.62922404e-11  1.47759641e-11
  3.75247237e-11  7.91255033e-11  5.79709776e-11  7.79047282e-11
  4.24957644e-12  3.46728109e-12  3.96677671e-12  3.27775136e-12
  5.40732473e-12 -1.18211119e-12  7.44469683e-12 -5.43273439e-12
  1.96708367e-11  3.26740691e-11  1.43921235e-11 -3.99699377e-12
 -4.04905304e+00]
supnorm grad right now is: 4.0490530416654
Weights right now are: 
[-2.15890646e+00 -3.54166763e+00 -4.03687602e+00 -3.06190958e+00
  1.36868714e+00  3.55613120e+00  4.60818199e+00  4.47699255e+00
  2.58675146e-02 -1.33618419e+00  6.74806758e-01 -8.57255319e-01
 -3.79225945e-02 -2.39361011e+00  4.15758908e-01 -2.53755123e+00
 -1.24959157e+00 -2.13206474e+00 -6.11725460e-01 -2.30917829e+00
 -1.28857411e+00 -2.34805434e+00 -1.54163323e+00 -2.45389747e+00
  1.44208355e+00  5.67808648e-01  8.38263053e-03  5.76313771e-01
 -1.22149484e+00 -1.46374306e+00 -2.34483678e+00 -1.94651878e+00
  3.51721213e-01  1.08533921e+00  1.49355919e+00  1.22547221e+00
 -1.14189573e+00 -1.89200642e+00 -1.10608631e+00 -2.18556717e+00
  3.78756766e-01  3.45735401e-01  1.39108279e+00  1.73065637e+00
 -2.77537064e-02 -1.57749125e+00 -2.41370831e-01 -9.07664178e-01
 -4.19871647e-01 -1.16399702e-01 -6.88905767e-01 -7.43756090e-01
 -1.73299675e+00 -2.07753340e+00 -1.30548754e+00 -2.03466658e+00
  7.14144023e-01  1.48383518e+00 -9.69058155e-01 -1.22578679e+00
 -2.16571268e-01  7.90386848e-02 -8.40889621e-01 -1.41938897e+00
  2.46938907e+01]
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.796734141568
gradient value of function right now is: [ 1.98922110e-08  2.20436719e-08  2.20135900e-08  2.20780011e-08
 -1.98916484e-08 -2.20430485e-08 -2.20129674e-08 -2.20773768e-08
  1.70302059e-09  7.29246256e-09  2.65593045e-10  7.27367843e-09
  2.72174033e-10  1.16546654e-09  4.24686988e-11  1.16246131e-09
  3.90842365e-10  1.67362570e-09  6.09430471e-11  1.66931642e-09
  2.29754441e-10  9.83833351e-10  3.58071359e-11  9.81302723e-10
  5.43188154e-11  4.97192574e-10  4.32083931e-10  5.66686893e-10
  1.20349757e-11  1.01193752e-10  8.90985163e-11  1.17051292e-10
 -1.00010626e-11 -8.54555804e-11 -7.50501584e-11 -9.85638448e-11
  1.42322085e-11  1.18062299e-10  1.04189089e-10  1.36905500e-10
 -1.26338658e-11 -2.74818138e-11 -1.99016721e-11 -2.70588222e-11
  1.55639527e-11  1.48597225e-11  1.55685003e-11  1.41478727e-11
  3.58380458e-11  7.60212877e-11  5.55838872e-11  7.48652532e-11
  4.05849981e-12  3.31832788e-12  3.79325926e-12  3.13852151e-12
  5.17793559e-12 -1.08795877e-12  7.11477625e-12 -5.12045052e-12
  1.88744257e-11  3.16080825e-11  1.37813594e-11 -3.70718725e-12
 -4.91254192e-01]
supnorm grad right now is: 0.49125419150673294
Weights right now are: 
[-2.16304405e+00 -3.54625351e+00 -4.04145563e+00 -3.06650260e+00
  1.37282478e+00  3.56071713e+00  4.61276165e+00  4.48158562e+00
  2.55132811e-02 -1.33770134e+00  6.74751574e-01 -8.58768574e-01
 -3.79791773e-02 -2.39385245e+00  4.15750089e-01 -2.53779294e+00
 -1.24967285e+00 -2.13241287e+00 -6.11738120e-01 -2.30952551e+00
 -1.28862188e+00 -2.34825894e+00 -1.54164067e+00 -2.45410154e+00
  1.44207230e+00  5.67705188e-01  8.29280780e-03  5.76195967e-01
 -1.22149732e+00 -1.46376410e+00 -2.34485528e+00 -1.94654309e+00
  3.51723282e-01  1.08535700e+00  1.49357480e+00  1.22549270e+00
 -1.14189867e+00 -1.89203096e+00 -1.10610793e+00 -2.18559558e+00
  3.78759357e-01  3.45741131e-01  1.39108690e+00  1.73066202e+00
 -2.77568839e-02 -1.57749434e+00 -2.41374031e-01 -9.07667118e-01
 -4.19878994e-01 -1.16415565e-01 -6.88917274e-01 -7.43771718e-01
 -1.73299758e+00 -2.07753409e+00 -1.30548832e+00 -2.03466723e+00
  7.14142955e-01  1.48383540e+00 -9.69059611e-01 -1.22578576e+00
 -2.16575163e-01  7.90318173e-02 -8.40892458e-01 -1.41938823e+00
  2.49558829e+01]
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.784891545933
gradient value of function right now is: [ 1.92427891e-08  2.13175877e-08  2.12885590e-08  2.13507687e-08
 -1.92436620e-08 -2.13185546e-08 -2.12895245e-08 -2.13517370e-08
  1.64712665e-09  7.05172003e-09  2.56822330e-10  7.03355599e-09
  2.63469626e-10  1.12796974e-09  4.11018531e-11  1.12506120e-09
  3.78164897e-10  1.61901794e-09  5.89538847e-11  1.61484927e-09
  2.22395946e-10  9.52134303e-10  3.46530202e-11  9.49685213e-10
  5.26147671e-11  4.81515929e-10  4.18473712e-10  5.48834884e-10
  1.16499730e-11  9.79393125e-11  8.62360672e-11  1.13290543e-10
 -9.66666254e-12 -8.25830891e-11 -7.25300270e-11 -9.52539159e-11
  1.37796520e-11  1.14288418e-10  1.00862135e-10  1.32533553e-10
 -1.22505489e-11 -2.66270634e-11 -1.92879941e-11 -2.62165577e-11
  1.50580518e-11  1.43651835e-11  1.50565782e-11  1.36760831e-11
  3.46910149e-11  7.35504209e-11  5.37869899e-11  7.24305117e-11
  3.92712676e-12  3.20940511e-12  3.66964601e-12  3.03531245e-12
  5.01268650e-12 -1.05672322e-12  6.88497035e-12 -4.96134777e-12
  1.82738160e-11  3.05788426e-11  1.33439089e-11 -3.59887223e-12
 -7.79192020e-01]
supnorm grad right now is: 0.7791920199328757
Weights right now are: 
[-2.16696298e+00 -3.55059569e+00 -4.04579189e+00 -3.07085154e+00
  1.37674371e+00  3.56505932e+00  4.61709792e+00  4.48593457e+00
  2.51778153e-02 -1.33913773e+00  6.74699298e-01 -8.60201274e-01
 -3.80328105e-02 -2.39408209e+00  4.15741727e-01 -2.53802200e+00
 -1.24974986e+00 -2.13274258e+00 -6.11750118e-01 -2.30985438e+00
 -1.28866715e+00 -2.34845280e+00 -1.54164772e+00 -2.45429491e+00
  1.44206162e+00  5.67607124e-01  8.20763185e-03  5.76084261e-01
 -1.22149969e+00 -1.46378403e+00 -2.34487282e+00 -1.94656614e+00
  3.51725245e-01  1.08537383e+00  1.49358956e+00  1.22551210e+00
 -1.14190147e+00 -1.89205422e+00 -1.10612844e+00 -2.18562253e+00
  3.78761824e-01  3.45746558e-01  1.39109082e+00  1.73066736e+00
 -2.77599261e-02 -1.57749726e+00 -2.41377079e-01 -9.07669896e-01
 -4.19885998e-01 -1.16430568e-01 -6.88928199e-01 -7.43786499e-01
 -1.73299837e+00 -2.07753474e+00 -1.30548906e+00 -2.03466785e+00
  7.14141943e-01  1.48383559e+00 -9.69061007e-01 -1.22578477e+00
 -2.16578876e-01  7.90254615e-02 -8.40895155e-01 -1.41938754e+00
  2.49451061e+01]
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.643444647052
gradient value of function right now is: [ 1.86746738e-08  2.06822983e-08  2.06541927e-08  2.07144753e-08
 -1.86743747e-08 -2.06819670e-08 -2.06538619e-08 -2.07141435e-08
  1.59813750e-09  6.84070674e-09  2.49165200e-10  6.82308244e-09
  2.55843119e-10  1.09511428e-09  3.99090959e-11  1.09228986e-09
  3.67050846e-10  1.57114196e-09  5.72169838e-11  1.56709568e-09
  2.15944247e-10  9.24339903e-10  3.36452130e-11  9.21961791e-10
  5.11446731e-11  4.67731523e-10  4.06537877e-10  5.33186276e-10
  1.13194567e-11  9.50912647e-11  8.37379386e-11  1.10010253e-10
 -9.37898805e-12 -8.00664939e-11 -7.03278781e-11 -9.23630802e-11
  1.33913698e-11  1.10988273e-10  9.79607319e-11  1.28722990e-10
 -1.19319587e-11 -2.58724450e-11 -1.87567236e-11 -2.54715379e-11
  1.46351326e-11  1.39390792e-11  1.46209186e-11  1.32678682e-11
  3.37280656e-11  7.13692803e-11  5.22265588e-11  7.02771288e-11
  3.81593911e-12  3.11600206e-12  3.56393242e-12  2.94638546e-12
  4.87088549e-12 -1.04131103e-12  6.69077399e-12 -4.84593258e-12
  1.77507384e-11  2.96270731e-11  1.29692802e-11 -3.53735606e-12
 -2.11125605e+00]
supnorm grad right now is: 2.1112560499966917
Weights right now are: 
[-2.17070123e+00 -3.55473654e+00 -4.04992711e+00 -3.07499884e+00
  1.38048198e+00  3.56920018e+00  4.62123315e+00  4.49008188e+00
  2.48578105e-02 -1.34050755e+00  6.74649235e-01 -8.61567538e-01
 -3.80840217e-02 -2.39430131e+00  4.15733711e-01 -2.53824064e+00
 -1.24982333e+00 -2.13305712e+00 -6.11761611e-01 -2.31016810e+00
 -1.28871037e+00 -2.34863779e+00 -1.54165448e+00 -2.45447942e+00
  1.44205128e+00  5.67513785e-01  8.12633596e-03  5.75977620e-01
 -1.22150199e+00 -1.46380308e+00 -2.34488964e+00 -1.94658824e+00
  3.51727154e-01  1.08538987e+00  1.49360369e+00  1.22553065e+00
 -1.14190420e+00 -1.89207646e+00 -1.10614813e+00 -2.18564841e+00
  3.78764274e-01  3.45751699e-01  1.39109459e+00  1.73067242e+00
 -2.77629993e-02 -1.57750006e+00 -2.41380089e-01 -9.07672556e-01
 -4.19892973e-01 -1.16444758e-01 -6.88938741e-01 -7.43800461e-01
 -1.73299918e+00 -2.07753537e+00 -1.30548980e+00 -2.03466844e+00
  7.14140956e-01  1.48383583e+00 -9.69062373e-01 -1.22578372e+00
 -2.16582429e-01  7.90199875e-02 -8.40897784e-01 -1.41938676e+00
  2.48548139e+01]
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15992.346864905654
gradient value of function right now is: [ 1.78750591e-08  1.97912503e-08  1.97644034e-08  1.98220162e-08
 -1.78736665e-08 -1.97897086e-08 -1.97628638e-08 -1.98204721e-08
  1.52934541e-09  6.54494896e-09  2.38139675e-10  6.52811787e-09
  2.45014030e-10  1.04855300e-09  3.81717079e-11  1.04585367e-09
  3.51376075e-10  1.50374887e-09  5.47045032e-11  1.49988335e-09
  2.06806177e-10  8.85049606e-10  3.21808779e-11  8.82776812e-10
  4.88227190e-11  4.48528754e-10  3.89600892e-10  5.10911770e-10
  1.07854595e-11  9.10225336e-11  8.01017191e-11  1.05218354e-10
 -8.92620471e-12 -7.65542685e-11 -6.71981676e-11 -8.82406384e-11
  1.27607100e-11  1.06240296e-10  9.37086548e-11  1.23117947e-10
 -1.13041997e-11 -2.48426988e-11 -1.79281858e-11 -2.44688737e-11
  1.38465744e-11  1.32745572e-11  1.38849221e-11  1.26472239e-11
  3.19543467e-11  6.84505632e-11  4.98829739e-11  6.74352316e-11
  3.62154809e-12  2.96571304e-12  3.38965849e-12  2.80722206e-12
  4.63492181e-12 -9.08151960e-13  6.34674648e-12 -4.46537796e-12
  1.69696379e-11  2.88033346e-11  1.23386536e-11 -3.14050380e-12
  6.65078058e+00]
supnorm grad right now is: 6.650780575274675
Weights right now are: 
[-2.17425661e+00 -3.55867369e+00 -4.05385892e+00 -3.07894213e+00
  1.38403735e+00  3.57313733e+00  4.62516496e+00  4.49402516e+00
  2.45535550e-02 -1.34180980e+00  6.74601704e-01 -8.62866416e-01
 -3.81327496e-02 -2.39450987e+00  4.15726095e-01 -2.53844866e+00
 -1.24989322e+00 -2.13335625e+00 -6.11772527e-01 -2.31046647e+00
 -1.28875149e+00 -2.34881380e+00 -1.54166090e+00 -2.45465497e+00
  1.44204147e+00  5.67424843e-01  8.04893162e-03  5.75876080e-01
 -1.22150417e+00 -1.46382120e+00 -2.34490562e+00 -1.94660923e+00
  3.51728956e-01  1.08540511e+00  1.49361710e+00  1.22554827e+00
 -1.14190677e+00 -1.89209762e+00 -1.10616683e+00 -2.18567299e+00
  3.78766593e-01  3.45756614e-01  1.39109818e+00  1.73067726e+00
 -2.77658494e-02 -1.57750272e+00 -2.41382916e-01 -9.07675094e-01
 -4.19899532e-01 -1.16458288e-01 -6.88948736e-01 -7.43813777e-01
 -1.73299993e+00 -2.07753596e+00 -1.30549049e+00 -2.03466900e+00
  7.14140013e-01  1.48383603e+00 -9.69063671e-01 -1.22578277e+00
 -2.16585824e-01  7.90146036e-02 -8.40900297e-01 -1.41938606e+00
  2.54397231e+01]
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.641027010834
gradient value of function right now is: [ 1.78393632e-08  1.97491306e-08  1.97223712e-08  1.97798331e-08
 -1.78405057e-08 -1.97503952e-08 -1.97236341e-08 -1.97810997e-08
  1.52624722e-09  6.53121126e-09  2.37875755e-10  6.51438597e-09
  2.44624716e-10  1.04681049e-09  3.81460885e-11  1.04411092e-09
  3.50732542e-10  1.50088446e-09  5.46545701e-11  1.49701950e-09
  2.06462259e-10  8.83512537e-10  3.21568804e-11  8.81239688e-10
  4.89344513e-11  4.47524723e-10  3.88978710e-10  5.10151520e-10
  1.08200745e-11  9.08966441e-11  8.00449961e-11  1.05157605e-10
 -8.94698347e-12 -7.63783449e-11 -6.70891398e-11 -8.81086974e-11
  1.28039648e-11  1.06120609e-10  9.36654056e-11  1.23077573e-10
 -1.14280530e-11 -2.47708131e-11 -1.79605037e-11 -2.43867179e-11
  1.39742393e-11  1.33004872e-11  1.39563060e-11  1.26594928e-11
  3.22301676e-11  6.81961296e-11  4.99058072e-11  6.71523835e-11
  3.64482446e-12  2.97502341e-12  3.40352437e-12  2.81300054e-12
  4.65634567e-12 -9.95440186e-13  6.39141483e-12 -4.63016179e-12
  1.69742452e-11  2.83268016e-11  1.24007291e-11 -3.38205126e-12
 -2.12668219e+00]
supnorm grad right now is: 2.12668219258015
Weights right now are: 
[-2.17780555e+00 -3.56260259e+00 -4.05778249e+00 -3.08287713e+00
  1.38758629e+00  3.57706623e+00  4.62908853e+00  4.49796016e+00
  2.42499410e-02 -1.34310903e+00  6.74554467e-01 -8.64162310e-01
 -3.81814075e-02 -2.39471809e+00  4.15718521e-01 -2.53865634e+00
 -1.24996299e+00 -2.13365481e+00 -6.11783380e-01 -2.31076426e+00
 -1.28879256e+00 -2.34898956e+00 -1.54166728e+00 -2.45483028e+00
  1.44203179e+00  5.67335709e-01  7.97153106e-03  5.75774583e-01
 -1.22150630e+00 -1.46383927e+00 -2.34492152e+00 -1.94663011e+00
  3.51730720e-01  1.08542030e+00  1.49363043e+00  1.22556577e+00
 -1.14190930e+00 -1.89211871e+00 -1.10618543e+00 -2.18569742e+00
  3.78768838e-01  3.45761556e-01  1.39110175e+00  1.73068212e+00
 -2.77685640e-02 -1.57750537e+00 -2.41385656e-01 -9.07677609e-01
 -4.19905844e-01 -1.16471895e-01 -6.88958632e-01 -7.43827177e-01
 -1.73300063e+00 -2.07753655e+00 -1.30549116e+00 -2.03466956e+00
  7.14139079e-01  1.48383622e+00 -9.69064948e-01 -1.22578189e+00
 -2.16589213e-01  7.90088149e-02 -8.40902783e-01 -1.41938541e+00
  2.50466093e+01]
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.718955458697
gradient value of function right now is: [ 1.75492618e-08  1.94252880e-08  1.93989932e-08  1.94554789e-08
 -1.75477639e-08 -1.94236302e-08 -1.93973376e-08 -1.94538185e-08
  1.50118503e-09  6.42336398e-09  2.33926903e-10  6.40681899e-09
  2.40699826e-10  1.02991879e-09  3.75272029e-11  1.02726318e-09
  3.45029539e-10  1.47634194e-09  5.37560703e-11  1.47254075e-09
  2.03142816e-10  8.69226583e-10  3.16341121e-11  8.66990820e-10
  4.81482225e-11  4.40465796e-10  3.82828219e-10  5.02079766e-10
  1.06421831e-11  8.94287687e-11  7.87491739e-11  1.03454016e-10
 -8.79417355e-12 -7.50965675e-11 -6.59605621e-11 -8.66255053e-11
  1.25944832e-11  1.04414769e-10  9.21561188e-11  1.21092895e-10
 -1.12418460e-11 -2.43865555e-11 -1.76770465e-11 -2.40091729e-11
  1.37340677e-11  1.30748794e-11  1.37185555e-11  1.24454555e-11
  3.16853839e-11  6.70969667e-11  4.90880440e-11  6.60722944e-11
  3.58331570e-12  2.92493240e-12  3.34635497e-12  2.76582175e-12
  4.57882682e-12 -9.73301045e-13  6.28258553e-12 -4.54302130e-12
  1.66989774e-11  2.79026643e-11  1.21947626e-11 -3.31072199e-12
 -1.58215135e+00]
supnorm grad right now is: 1.582151346737424
Weights right now are: 
[-2.18142008e+00 -3.56660297e+00 -4.06177746e+00 -3.08688371e+00
  1.39120082e+00  3.58106660e+00  4.63308348e+00  4.50196674e+00
  2.39408929e-02 -1.34443166e+00  6.74506489e-01 -8.65481562e-01
 -3.82309721e-02 -2.39493021e+00  4.15710822e-01 -2.53886792e+00
 -1.25003404e+00 -2.13395889e+00 -6.11794409e-01 -2.31106756e+00
 -1.28883441e+00 -2.34916864e+00 -1.54167378e+00 -2.45500890e+00
  1.44202199e+00  5.67244642e-01  7.89263016e-03  5.75671098e-01
 -1.22150845e+00 -1.46385768e+00 -2.34493767e+00 -1.94665133e+00
  3.51732499e-01  1.08543576e+00  1.49364396e+00  1.22558354e+00
 -1.14191184e+00 -1.89214018e+00 -1.10620431e+00 -2.18572223e+00
  3.78771058e-01  3.45766638e-01  1.39110534e+00  1.73068713e+00
 -2.77712419e-02 -1.57750803e+00 -2.41388379e-01 -9.07680153e-01
 -4.19912082e-01 -1.16485868e-01 -6.88968592e-01 -7.43840951e-01
 -1.73300133e+00 -2.07753715e+00 -1.30549182e+00 -2.03467012e+00
  7.14138162e-01  1.48383640e+00 -9.69066198e-01 -1.22578102e+00
 -2.16592595e-01  7.90019105e-02 -8.40905223e-01 -1.41938481e+00
  2.50933717e+01]
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.804960933834
gradient value of function right now is: [ 1.72436075e-08  1.90843916e-08  1.90585823e-08  1.91140439e-08
 -1.72447881e-08 -1.90856982e-08 -1.90598871e-08 -1.91153524e-08
  1.47497570e-09  6.31063086e-09  2.29774831e-10  6.29438190e-09
  2.36592600e-10  1.01225034e-09  3.68759165e-11  1.00964120e-09
  3.39074431e-10  1.45072576e-09  5.28125852e-11  1.44699183e-09
  1.99676876e-10  8.54316739e-10  3.10851587e-11  8.52120096e-10
  4.73066362e-11  4.33117159e-10  3.76399851e-10  4.93637431e-10
  1.04504318e-11  8.78894786e-11  7.73847732e-11  1.01658804e-10
 -8.62999491e-12 -7.37549154e-11 -6.47746971e-11 -8.50658709e-11
  1.23684666e-11  1.02623735e-10  9.05650727e-11  1.18998948e-10
 -1.10332543e-11 -2.39890570e-11 -1.73753909e-11 -2.36196010e-11
  1.34663187e-11  1.28327743e-11  1.34592127e-11  1.22169639e-11
  3.10814933e-11  6.59594487e-11  4.82208688e-11  6.49575109e-11
  3.51570171e-12  2.87082601e-12  3.28435653e-12  2.71516356e-12
  4.49609578e-12 -9.41311819e-13  6.16415674e-12 -4.43372111e-12
  1.64100466e-11  2.74973894e-11  1.19746623e-11 -3.21148930e-12
  7.80800024e-03]
supnorm grad right now is: 0.007808000239378742
Weights right now are: 
[-2.18478734e+00 -3.57032873e+00 -4.06549819e+00 -3.09061526e+00
  1.39456809e+00  3.58479238e+00  4.63680424e+00  4.50569831e+00
  2.36528698e-02 -1.34566346e+00  6.74461679e-01 -8.66710196e-01
 -3.82772051e-02 -2.39512793e+00  4.15703626e-01 -2.53906514e+00
 -1.25010027e+00 -2.13424215e+00 -6.11804711e-01 -2.31135009e+00
 -1.28887342e+00 -2.34933551e+00 -1.54167984e+00 -2.45517534e+00
  1.44201277e+00  5.67159953e-01  7.81901618e-03  5.75574597e-01
 -1.22151049e+00 -1.46387484e+00 -2.34495278e+00 -1.94667117e+00
  3.51734175e-01  1.08545014e+00  1.49365659e+00  1.22560012e+00
 -1.14191424e+00 -1.89216023e+00 -1.10622199e+00 -2.18574546e+00
  3.78773214e-01  3.45771315e-01  1.39110875e+00  1.73069174e+00
 -2.77738465e-02 -1.57751054e+00 -2.41390998e-01 -9.07682539e-01
 -4.19918134e-01 -1.16498728e-01 -6.88978042e-01 -7.43853618e-01
 -1.73300200e+00 -2.07753771e+00 -1.30549245e+00 -2.03467065e+00
  7.14137278e-01  1.48383657e+00 -9.69067408e-01 -1.22578016e+00
 -2.16595810e-01  7.89970238e-02 -8.40907579e-01 -1.41938421e+00
  2.49631641e+01]
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.804839774288
gradient value of function right now is: [ 1.69967460e-08  1.88087507e-08  1.87833378e-08  1.88379678e-08
 -1.69980007e-08 -1.88101388e-08 -1.87847241e-08 -1.88393581e-08
  1.45372090e-09  6.21915451e-09  2.26439834e-10  6.20314151e-09
  2.33271404e-10  9.97954379e-10  3.63544133e-11  9.95382155e-10
  3.34246805e-10  1.42994701e-09  5.20551477e-11  1.42626666e-09
  1.96869533e-10  8.42232593e-10  3.06448715e-11  8.40067080e-10
  4.66528376e-11  4.27127128e-10  3.71196104e-10  4.86811425e-10
  1.03029419e-11  8.66481483e-11  7.62921767e-11  1.00223219e-10
 -8.50271189e-12 -7.26660127e-11 -6.38187364e-11 -8.38102297e-11
  1.21949164e-11  1.01182868e-10  8.92939078e-11  1.17328382e-10
 -1.08846436e-11 -2.36620355e-11 -1.71395415e-11 -2.32975119e-11
  1.32718404e-11  1.26447041e-11  1.32634235e-11  1.20376973e-11
  3.06403456e-11  6.50199258e-11  4.75349360e-11  6.40321026e-11
  3.46516742e-12  2.82931467e-12  3.23699475e-12  2.67586319e-12
  4.43259618e-12 -9.28490976e-13  6.07588930e-12 -4.37145596e-12
  1.61799298e-11  2.71101541e-11  1.18063484e-11 -3.16760550e-12
 -7.80659470e-02]
supnorm grad right now is: 0.07806594699391722
Weights right now are: 
[-2.18800306e+00 -3.57388596e+00 -4.06905062e+00 -3.09417801e+00
  1.39778380e+00  3.58834960e+00  4.64035666e+00  4.50926105e+00
  2.33778900e-02 -1.34683945e+00  6.74418843e-01 -8.67883154e-01
 -3.83213786e-02 -2.39531685e+00  4.15696741e-01 -2.53925357e+00
 -1.25016353e+00 -2.13451266e+00 -6.11814563e-01 -2.31161991e+00
 -1.28891070e+00 -2.34949492e+00 -1.54168564e+00 -2.45533435e+00
  1.44200392e+00  5.67079070e-01  7.74868354e-03  5.75482366e-01
 -1.22151244e+00 -1.46389124e+00 -2.34496723e+00 -1.94669015e+00
  3.51735784e-01  1.08546387e+00  1.49366865e+00  1.22561596e+00
 -1.14191656e+00 -1.89217939e+00 -1.10623892e+00 -2.18576769e+00
  3.78775294e-01  3.45775792e-01  1.39111201e+00  1.73069614e+00
 -2.77763784e-02 -1.57751293e+00 -2.41393522e-01 -9.07684814e-01
 -4.19923974e-01 -1.16511010e-01 -6.88987065e-01 -7.43865707e-01
 -1.73300266e+00 -2.07753825e+00 -1.30549307e+00 -2.03467116e+00
  7.14136428e-01  1.48383676e+00 -9.69068577e-01 -1.22577932e+00
 -2.16598909e-01  7.89920378e-02 -8.40909843e-01 -1.41938358e+00
  2.53505131e+01]
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -15993.799249028041
gradient value of function right now is: [ 1.67655708e-08  1.85505999e-08  1.85255587e-08  1.85794098e-08
 -1.67652988e-08 -1.85502990e-08 -1.85252582e-08 -1.85791084e-08
  1.43376157e-09  6.13325065e-09  2.23314940e-10  6.11745835e-09
  2.30151410e-10  9.84523998e-10  3.58656271e-11  9.81986313e-10
  3.29709654e-10  1.41041790e-09  5.13449044e-11  1.40678770e-09
  1.94230121e-10  8.30870953e-10  3.02318841e-11  8.28734585e-10
  4.60436282e-11  4.21486752e-10  3.66303286e-10  4.80394938e-10
  1.01659755e-11  8.54830224e-11  7.52682737e-11  9.88782792e-11
 -8.38445154e-12 -7.16443862e-11 -6.29231231e-11 -8.26341563e-11
  1.20338096e-11  9.98308686e-11  8.81030544e-11  1.15763826e-10
 -1.07486125e-11 -2.33533401e-11 -1.69192071e-11 -2.29932423e-11
  1.30939270e-11  1.24696279e-11  1.30826822e-11  1.18705650e-11
  3.02354967e-11  6.41339068e-11  4.68940720e-11  6.31587195e-11
  3.41879475e-12  2.79073630e-12  3.19324613e-12  2.63927466e-12
  4.37348355e-12 -9.18330221e-13  5.99407045e-12 -4.31686213e-12
  1.59640982e-11  2.67335362e-11  1.16496919e-11 -3.13160932e-12
 -4.09470876e-01]
supnorm grad right now is: 0.4094708760876667
Weights right now are: 
[-2.19117040e+00 -3.57738884e+00 -4.07254879e+00 -3.09768633e+00
  1.40095114e+00  3.59185247e+00  4.64385482e+00  4.51276936e+00
  2.31071339e-02 -1.34799739e+00  6.74376600e-01 -8.69038107e-01
 -3.83649066e-02 -2.39550300e+00  4.15689946e-01 -2.53943924e+00
 -1.25022584e+00 -2.13477913e+00 -6.11824282e-01 -2.31188569e+00
 -1.28894743e+00 -2.34965199e+00 -1.54169137e+00 -2.45549101e+00
  1.44199514e+00  5.66999419e-01  7.67938669e-03  5.75391458e-01
 -1.22151438e+00 -1.46390741e+00 -2.34498149e+00 -1.94670889e+00
  3.51737381e-01  1.08547739e+00  1.49368054e+00  1.22563158e+00
 -1.14191885e+00 -1.89219829e+00 -1.10625561e+00 -2.18578964e+00
  3.78777373e-01  3.45780203e-01  1.39111523e+00  1.73070048e+00
 -2.77789020e-02 -1.57751530e+00 -2.41396024e-01 -9.07687069e-01
 -4.19929790e-01 -1.16523093e-01 -6.88995954e-01 -7.43877602e-01
 -1.73300332e+00 -2.07753878e+00 -1.30549368e+00 -2.03467166e+00
  7.14135605e-01  1.48383695e+00 -9.69069720e-01 -1.22577845e+00
 -2.16601898e-01  7.89871582e-02 -8.40912042e-01 -1.41938292e+00
  2.45070400e+01]
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1550.7177017455886
W_T_median: 1404.9332849232974
W_T_pctile_5: 624.2405424993085
W_T_CVAR_5_pct: 486.62794855522515
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 10.0
F value: -15993.799249028041
-----------------------------------------------
