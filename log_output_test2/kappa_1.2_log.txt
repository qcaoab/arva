Starting at: 
2022-06-20 18:03:38
tracing parameter entered from terminal:  1.2


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[ 0.10347998  0.18844875 -0.3666709   0.62803316 -0.89369922 -0.17398511
  0.93797695  0.78704989 -0.60791207 -0.16293226 -0.31685198  0.28094308
  0.0404241   0.17453202  0.0940472   0.01169373  0.2300954  -0.23784803
  0.78511084 -0.41859022  0.4809118  -0.01155852  0.07219357 -0.14482284
  0.4701344  -0.18827011 -0.8138637  -0.24629474  0.28361272  0.33354483
 -0.63777411 -0.25343004 -0.81551088 -0.26234589  0.20198453 -0.15135741
  0.25264285 -0.29817275  0.41496663 -0.58895503 -0.60305385 -0.63454123
  0.3979274   0.74701442  0.57452389 -0.67377327  0.6493153   0.07340044
 -0.29694484  0.52758424 -0.14347696  0.04319718 -0.28527617 -0.63077443
  0.13133703 -0.58713125  0.12759166  0.87507529 -0.19770888 -0.66759109
  0.25529887 -0.48501395  0.58877641 -0.72315372] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1260.6521530687958
W_T_median: 1222.3920506735662
W_T_pctile_5: 834.1581876304141
W_T_CVAR_5_pct: 746.6575474940535
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2383.9299412564706
gradient value of function right now is: [ 4.73035002e-02  1.22489985e-01  1.63996752e-01  1.36896329e-01
 -4.73035002e-02 -1.22489985e-01 -1.63996752e-01 -1.36896329e-01
  6.28333167e-02 -5.71613247e-02  1.07876551e-02 -6.52626271e-02
  9.84881118e-03  1.54997419e-02  3.68744991e-02  1.80219811e-02
  7.59783469e-02  8.01688103e-03  2.89182626e-01  2.48652444e-02
  4.32685573e-02 -1.25279602e-02  1.49855543e-01 -3.33463814e-03
 -1.22966958e-01 -2.52671395e-02 -1.60432157e-02 -2.90381155e-02
  1.15462557e-01 -4.61528304e-03 -6.78511364e-04 -2.41208260e-03
 -1.83095040e-01  2.77855689e-02  1.20795945e-02  2.51965378e-02
  1.51071466e-01  9.91636011e-03  7.93234232e-03  1.35543691e-02
 -2.27579185e-01  1.91420446e-03 -1.54674100e-02  1.15209761e-02
  1.53243627e-01 -7.75604826e-03  9.02854612e-03 -1.67141092e-02
  2.77333677e-02 -5.15148285e-03  6.82441987e-04 -8.02272660e-03
  1.30626545e-01 -2.79493644e-03  7.98500740e-03 -8.56951612e-03
 -8.72617294e-02  5.58216996e-01 -1.05309170e-01  1.69237705e-02
 -6.16677154e-03 -1.14335568e-02 -1.52045036e-01  1.76509830e-02
 -4.87314696e+00]
supnorm grad right now is: 4.873146958439147
Weights right now are: 
[ 2.09883479e-01 -6.06377676e-01 -1.72841577e+00 -7.94681605e-01
 -1.00010272e+00  6.20841314e-01  2.29972181e+00  2.20976465e+00
  5.98861017e-01  1.31739889e+00  9.23528959e-01  1.81527102e+00
  1.91189954e+00 -7.77834322e-01  3.74071868e+00 -6.92312638e-01
  1.05966837e+00 -1.67486277e+00  3.32241270e+00 -1.57576022e+00
  1.85941252e+00 -1.68519277e+00  3.55074578e+00 -1.59466319e+00
  1.97630021e-02  2.16172816e+00  1.22584979e+00  1.83364693e+00
  4.01659317e+00 -3.25797674e+00 -1.17674661e+00 -2.25939072e+00
 -3.35534361e+00  2.53583290e+00  1.54520124e+00  1.84164322e+00
  3.55929346e+00 -3.12214222e+00 -2.27300039e-01 -2.14234564e+00
 -2.91650149e+00  2.39476476e+00  1.06524095e+00  4.43230436e+00
  3.65818932e+00 -4.11322069e+00 -7.35898625e-01 -3.89040053e+00
  3.88290049e+00 -1.38227387e+00 -4.55518927e-01 -2.59048128e+00
  3.35616994e+00 -3.55125269e+00  5.64862249e-01 -4.38495932e+00
  4.16237248e+00  2.08184758e+00 -2.05661520e+00 -2.64622058e+00
  3.08041234e-01 -2.82438944e+00 -2.82009738e+00 -2.66970180e+00
  2.57975144e+01]
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2385.1311799751843
gradient value of function right now is: [-0.4709437  -0.04902867 -0.1138269  -0.0754172   0.4709437   0.04902867
  0.1138269   0.0754172   0.2807922   0.00670085  0.56387811  0.01523654
 -0.01824429 -0.06069224 -0.07216311 -0.07007998 -0.10282807 -0.15228365
 -0.25838539 -0.17299009 -0.04785166 -0.1097271  -0.14732845 -0.12557921
  0.04740676  0.00689557  0.00388678  0.007259   -0.10909255 -0.06558382
 -0.03426418 -0.07029432  0.22601441  0.2150714   0.11098007  0.22968601
 -0.13444536 -0.04873639 -0.02594321 -0.05258716  0.25558148  0.07818887
  0.01527287  0.12568079 -0.15724773 -0.05516426 -0.01095732 -0.0883589
 -0.05099018 -0.01647723 -0.00366037 -0.02620449 -0.10780085 -0.0369087
 -0.0062088  -0.06017431  0.53053969 -0.9348423  -0.26611579  0.45657064
 -0.01338419  0.01799705 -0.54583817  0.9597681   1.62433066]
supnorm grad right now is: 1.6243306604529424
Weights right now are: 
[ 0.32470383 -1.17138452 -1.88791549 -1.06121016 -1.11492307  1.18584816
  2.45922153  2.47629321  0.72120837  2.69155436  1.20827053  3.24797367
  2.63248465 -1.14443274  4.29619536 -1.02116821  1.57680112 -1.35045007
  3.52416713 -1.34344526  2.31982998 -1.17194447  3.76816111 -1.14986308
 -0.10409965  3.07329176  1.97291112  2.73563633  3.72532279 -2.88989728
 -0.87219486 -1.9508653  -3.45750178  1.83312712  1.07790264  1.19642709
  3.15950984 -3.16732942 -0.27368597 -2.24197575 -2.68782166  2.38819744
  1.19515268  4.45775764  3.66228808 -3.88337385 -0.74097239 -3.65784269
  4.28720231 -0.88837886 -0.34743466 -2.04467583  3.37140708 -3.3803438
  0.49399413 -4.2047943   4.46674056  2.07115233 -1.79201716 -2.9624546
  0.85564566 -3.25986149 -2.70974221 -2.92418361 26.10772501]
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2383.0551889090407
gradient value of function right now is: [ 6.53872042e-01  1.29183692e-01  3.69701575e-01  2.31923263e-01
 -6.53872042e-01 -1.29183692e-01 -3.69701575e-01 -2.31923263e-01
 -3.44321985e-01 -1.80724316e-01 -1.29416874e+00 -2.80695286e-01
  2.58675192e-02  8.13175295e-02  1.33732900e-01  9.62014876e-02
  1.80119162e-01  1.94856710e-01  9.86151652e-01  3.16620074e-01
  8.32576450e-02  1.12852582e-01  4.38561582e-01  1.64388435e-01
 -3.64902666e-01 -1.12180591e-01 -3.32805307e-02 -1.16658975e-01
  5.66991964e-01  1.49414150e-01  4.76214487e-02  1.57053766e-01
 -4.52108444e-01 -1.07600733e-01 -7.72793723e-02 -1.16563722e-01
  8.66077926e-01  2.34160486e-01  7.20901434e-02  2.45379822e-01
 -1.54292430e+00 -1.07699169e-01 -9.03999036e-02 -1.22245672e-01
  1.07286485e+00  7.80801729e-02  6.38078644e-02  8.93179342e-02
  8.24236360e-02  5.63826516e-03  4.07319288e-03  6.82847653e-03
  8.23169233e-01  6.15978550e-02  4.95223709e-02  7.06445285e-02
 -1.70394883e+00  3.82156566e+00  4.23557373e-01 -1.22504369e+00
  1.21196888e-01 -4.73104362e-01  6.63025715e-01 -1.75618081e+00
 -1.03987557e+01]
supnorm grad right now is: 10.398755712746082
Weights right now are: 
[ 0.8366269  -1.24949991 -1.64977876 -0.93580415 -1.62684614  1.26396354
  2.2210848   2.3508872   0.51773918  3.56432066  1.14365722  4.00139809
  3.65561055 -0.37810342  5.11215019 -0.27446329  2.69049986 -1.23702714
  3.99442564 -1.32517054  3.35901277 -0.69360002  4.31306374 -0.75267573
 -0.29570376  4.48987894  2.67119679  4.00823364  4.00206511 -2.95497828
 -0.45534319 -1.97772387 -3.63607742  1.49631634  0.38169231  0.83991674
  3.54814364 -3.65604132 -0.2436769  -2.66334599 -2.03640704  3.67480283
  3.04994076  5.51025829  3.16119111 -4.96309998 -2.34010222 -4.50225669
  4.59745911 -1.0119106  -0.97204469 -1.93726696  3.00358365 -4.45139882
 -1.0795818  -5.04548701  4.25096957  2.38118118 -1.46232064 -2.99046491
  0.76402857 -2.5127963  -2.26051146 -3.16588567 25.71924394]
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2380.3769375782667
gradient value of function right now is: [ 2.98139843e-01  3.74058250e-02  1.48145524e-01  9.23031736e-02
 -2.98139843e-01 -3.74058250e-02 -1.48145524e-01 -9.23031736e-02
 -4.19535739e-02 -7.71792760e-02 -6.48431303e-01 -1.50925979e-01
  2.51914307e-02  1.44377876e-02  2.08732111e-01  4.24652380e-02
  7.69181028e-02  8.80113897e-02  6.29404634e-01  1.76854491e-01
  5.00962646e-02  5.20936580e-02  4.10461754e-01  1.09756722e-01
 -2.42668176e-01 -6.07359057e-02 -1.65671084e-02 -6.16598299e-02
  3.62740340e-01  8.87890018e-02  2.43240136e-02  9.15429813e-02
 -3.19061435e-01 -8.27066874e-02 -2.26922327e-02 -8.63808773e-02
  6.11749491e-01  1.52517052e-01  4.24355651e-02  1.56829456e-01
 -1.15453782e+00 -1.30374892e-01 -8.12942410e-02 -1.68992749e-01
  6.10341368e-01  6.67510256e-02  4.04719487e-02  8.74976304e-02
  5.12446608e-02  3.86989416e-03  1.90561297e-03  5.59049918e-03
  4.36545105e-01  4.78277072e-02  2.86584205e-02  6.29213549e-02
 -1.50097714e+00  2.30256648e+00  4.24813654e-01 -7.61822518e-01
  1.13275584e-01 -2.54549811e-01  7.43836360e-01 -1.25080562e+00
  3.12865883e+00]
supnorm grad right now is: 3.1286588277376164
Weights right now are: 
[ 0.80561511 -2.63302894 -2.02075591 -1.6505185  -1.59583435  2.64749257
  2.59206196  3.06560154  0.64411952  5.12424855  1.62657174  5.59456811
  3.61449898 -1.65409825  5.9013809  -0.98138753  2.67212771 -1.0906598
  4.52863344 -0.93876222  3.30925044 -1.15667067  4.93170061 -0.8009064
  0.42027912  4.73864031  2.60374179  4.20371186  4.26093658 -2.39154731
 -0.08155964 -1.38907264 -4.70081775  1.71412825  2.13705266  1.03790923
  3.49105877 -3.28739965  0.20398229 -2.26968835 -2.50025299  3.88306014
  3.29759908  5.70669504  3.84356709 -4.75116184 -2.21362781 -4.23616162
  5.56309064 -1.64878168 -1.96502169 -2.47090098  3.69317391 -4.125172
 -0.87689202 -4.63399611  3.91416633  3.11374652 -1.20241239 -3.83244577
  1.09462542 -3.35495827 -2.0599489  -3.97898544 26.83919085]
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2387.1121617309996
gradient value of function right now is: [-0.35473315  0.02486195  0.30530797  0.07672646  0.35473315 -0.02486195
 -0.30530797 -0.07672646  0.1745308   0.02731531  0.97948247  0.13155331
 -0.00768961  0.03335428  0.03870776  0.09243809 -0.09211011  0.25944344
  1.15881655  1.42375639 -0.03556637  0.0763704   0.26221952  0.39036451
  0.32684409  0.00252735 -0.00198526  0.00539003 -0.07294164  0.0418044
  0.02108114  0.04350343 -0.36604747 -0.15033316 -0.08150224 -0.16394079
 -0.65374531  0.03031136  0.01901391  0.02651213 -0.20538651 -0.06041838
 -0.04444975 -0.06299673 -0.10055971  0.03550397  0.02441941  0.03844751
  0.02367464 -0.00274197  0.00393215 -0.00717248 -0.17502553  0.02873019
  0.01926057  0.03158147 -0.51643683  0.58052268  0.07381429 -0.29009519
  0.01593608 -0.0748036   0.11747995 -0.44927781 -0.98797768]
supnorm grad right now is: 1.4237563904335697
Weights right now are: 
[ 1.074346   -2.40336398 -2.24266197 -1.7330393  -1.86456524  2.41782762
  2.81396801  3.14812235  0.40011974  6.35353249  1.66742085  7.37898486
  3.73202394 -0.56916621  5.94080774 -0.06565603  3.6887885  -0.57952711
  3.51232074 -1.17063724  4.08072533 -0.27056472  4.3294445  -0.42017771
  0.69206108  7.30098748  5.25601852  6.68354446  4.16711875 -1.62643101
  0.52095629 -0.72187919 -4.93076282  0.68654307  1.41675056  0.10066708
  2.78770269 -5.41695368 -1.65752452 -4.48225804 -2.32614105  3.16200338
  2.12054168  5.14332754  3.35739821 -4.26947469 -1.39581567 -3.88059507
  6.03004201 -0.67526127 -0.99993554 -1.48080586  3.11339694 -4.05512643
 -0.54341876 -4.65317567  5.01960733  2.31020628 -1.13371142 -3.82084311
  1.56805197 -3.78550388 -2.03308902 -3.95361754 26.33596939]
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2387.685417520866
gradient value of function right now is: [-3.59590592e-01 -2.10008516e-03  1.20650309e-01  1.31890214e-02
  3.59590592e-01  2.10008516e-03 -1.20650309e-01 -1.31890214e-02
  2.99408414e-01  1.22450022e-02  1.00360931e+00  1.02987862e-01
 -1.20405463e-02 -6.07476054e-03  5.26355050e-03  1.60380484e-02
 -1.75006023e-01  3.82246918e-02  5.59692157e-01  9.74250382e-01
 -5.27497782e-02  2.08045023e-04  9.97659521e-02  2.04356384e-01
  4.19758827e-01  1.93967270e-02  2.86054664e-03  2.03505555e-02
 -6.19105782e-02 -6.48345338e-03 -2.84449535e-03 -6.29438332e-03
 -1.28398697e-01  4.57566681e-02  3.54611124e-02  4.05805558e-02
 -6.38023103e-01 -1.85961933e-02 -2.98431553e-03 -1.47983021e-02
  3.11311323e-02 -1.87820698e-03 -1.51985139e-02  1.79226163e-02
 -2.46377303e-01  2.82852587e-02  2.35421126e-02  2.40615598e-02
 -6.99131747e-03 -1.22408577e-02 -1.91921460e-03 -2.08586793e-02
 -2.61765379e-01  3.02027165e-02  2.40543094e-02  2.74786135e-02
  3.20741244e-01 -1.08901516e+00  1.19403622e-03 -1.69968167e-01
  9.26439421e-03 -8.06012212e-02 -6.68389414e-02 -1.55462135e-01
  3.38337370e+00]
supnorm grad right now is: 3.3833737023028783
Weights right now are: 
[ 1.05219024e+00 -3.30274229e+00 -2.64543231e+00 -2.29420019e+00
 -1.84240948e+00  3.31720593e+00  3.21673835e+00  3.70928323e+00
  1.33130560e+00  6.43385961e+00  1.82141286e+00  7.49089613e+00
  4.28908012e+00 -1.08874680e+00  5.92548543e+00 -4.95471744e-01
  4.35326240e+00 -2.96441626e-01  3.10853599e+00 -1.30282266e+00
  4.86748193e+00 -3.17786688e-01  4.12937349e+00 -5.47449726e-01
 -2.67121816e-01  8.59440707e+00  6.54068145e+00  7.94352889e+00
  4.80491543e+00 -6.44798300e-01  8.14924120e-01  3.49577346e-01
 -5.86823700e+00  6.35764866e-01  1.96123497e+00 -2.11098934e-02
  3.13670378e+00 -6.13113552e+00 -1.86829418e+00 -5.22226381e+00
 -2.95764499e+00  2.13237630e+00  1.92183651e+00  3.97363878e+00
  3.41947088e+00 -4.31532529e+00 -2.22268388e+00 -3.65739962e+00
  6.70253290e+00 -4.71101668e-01 -2.39831500e+00 -8.91553243e-01
  3.13121963e+00 -5.33763062e+00 -2.53823614e+00 -5.51921352e+00
  5.10838716e+00  2.18555044e+00  2.84812180e-01 -4.37868813e+00
  2.92020275e+00 -4.22383511e+00 -7.12973898e-01 -4.80722472e+00
  2.66125769e+01]
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -2387.685867824417
gradient value of function right now is: [-2.44188786e-01 -2.65168904e-02 -3.86449276e-01 -5.90258403e-02
  2.44188786e-01  2.65168904e-02  3.86449276e-01  5.90258403e-02
  4.86690083e-01  5.05749668e-03  7.68628953e-01  5.33884382e-02
 -1.70243883e-03 -8.78527768e-03 -1.68653225e-01 -2.04030857e-01
 -8.23146130e-03 -4.89999489e-02 -1.58212076e+00 -1.72701916e+00
 -1.97106823e-03 -1.26140258e-02 -3.06177366e-01 -3.55354650e-01
 -2.90614594e-01 -2.43545286e-02 -1.12841536e-03 -3.96151600e-02
 -3.94333705e-02 -1.79553363e-02 -6.59232482e-03 -2.10849734e-02
  2.42250655e-01  4.57371120e-01  2.05649529e-01  5.19586803e-01
 -4.03389999e-01 -4.17267237e-02 -7.98854240e-03 -5.73445116e-02
  2.23982921e-01  1.28021830e-01  4.75053107e-02  1.17530194e-01
  3.33260946e-02 -1.11092267e-02  1.60491918e-03 -1.00643631e-02
 -3.34001743e-02 -3.90355249e-02 -1.26788001e-02 -3.70353417e-02
  1.02413538e-01  1.99321563e-03  1.00965503e-02 -6.19360946e-04
  2.22816241e-01 -1.75339683e-02 -2.28034119e-01  1.63726608e-01
 -7.27166493e-02  6.02957984e-03 -3.08741298e-01  2.57062448e-01
  8.01874247e+00]
supnorm grad right now is: 8.018742472751747
Weights right now are: 
[ 1.24732009 -4.01646996 -2.71592702 -2.44867607 -2.03753933  4.0309336
  3.28723307  3.86375912  1.26070747  6.2118654   1.79742878  7.37709338
  5.26804133 -1.19351219  5.83182471 -0.97306931  5.78362019 -0.26855789
  2.95714136 -1.52579152  6.04975943 -0.23010088  4.28142675 -0.54402643
 -1.59041768  8.67283175  7.22151199  8.23050726  5.37340941 -0.10246769
  0.93352421  0.91085695 -6.54706645  0.60197751  2.22523239 -0.08015139
  3.40323496 -6.59854997 -1.75417493 -6.03408492 -2.82355572  2.24812025
  2.46784084  4.15026216  3.67014014 -5.92981476 -4.45706255 -4.87663728
  7.34438753 -0.42056681 -3.43564592 -0.999731    3.21298948 -8.46385494
 -6.21672846 -8.33041706  5.31278947  2.72583883  0.08469619 -3.24728046
  2.96651759 -2.64395775 -0.77719252 -4.35282724 26.66120211]
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2383.388412319304
gradient value of function right now is: [-1.41163840e-01  3.47378181e-02  1.08041941e+00  1.15160222e-01
  1.41163840e-01 -3.47378181e-02 -1.08041941e+00 -1.15160222e-01
  3.35406216e-01  1.96962996e-03  3.73154478e-01  9.77056213e-03
  2.86108140e-03  3.13049275e-03  2.51959261e-01  2.45753438e-01
  5.47284919e-02  5.88906594e-02  4.69622842e+00  4.70950123e+00
  8.64161241e-03  8.00899042e-03  6.15519455e-01  6.09962039e-01
 -3.98618816e-01 -5.84061247e-02 -4.45835204e-03 -1.23448998e-01
 -1.21646909e-02  1.00522560e-03  4.15873797e-05  9.80352670e-04
 -4.57160824e-01 -8.98700840e-01 -1.82550534e-01 -1.00225110e+00
  6.16182040e-02  4.78862019e-02  4.68988979e-03  9.61662957e-02
 -5.46063922e-01 -4.01194492e-01 -2.13296146e-01 -4.39726461e-01
  3.67533639e-01  4.18554141e-02  2.02688534e-02  3.85567793e-02
  1.23631757e-01  9.43103415e-02  5.07445350e-02  1.03315333e-01
  6.01843119e-01  5.79828483e-02  3.45721223e-02  4.81943384e-02
 -1.68637986e+00  2.24436245e+00  4.70503664e-01 -8.14753445e-01
  1.28068961e-01 -3.02151490e-01  7.77441524e-01 -1.05949677e+00
 -2.68824250e+00]
supnorm grad right now is: 4.709501231648845
Weights right now are: 
[  0.97372618  -3.77316953  -2.3318327   -2.15038755  -1.76394541
   3.78763317   2.90313875   3.5654706    1.27831943   6.62802128
   2.25848674   8.37486722   5.8370525   -1.02747836   6.51835854
  -0.62830439   6.42220636   0.0303077    3.39451776  -1.27779307
   6.58752078  -0.04055327   4.82932543  -0.22186954  -2.13078244
   8.12362626   6.12533419   8.12456011   5.27772415   0.38418388
   0.68003255   1.36819397  -6.7184891    0.40771609   2.94528612
  -0.24987276   3.23144054  -6.32247338  -1.08355008  -6.12288108
  -3.88850192   1.49893992   0.79708132   3.61532416   4.02978566
  -6.30711188  -4.88010305  -5.64069882   8.63162265  -0.55132041
  -2.66106626  -1.18737938   3.21139238  -9.61330237  -7.68102394
 -10.27448225   5.26216913   3.34772779  -0.42471435  -3.26412438
   2.90862005  -2.80567687  -1.36402514  -3.8983846   26.64946068]
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2384.4780167115887
gradient value of function right now is: [-7.44051785e-02  1.51100648e-02  1.09515932e+00  6.67982182e-02
  7.44051785e-02 -1.51100648e-02 -1.09515932e+00 -6.67982182e-02
  1.20137681e-01  6.34642943e-04  2.01710841e-01  2.10965732e-02
  7.04813702e-04  6.11900880e-04  8.88062665e-02  9.16360740e-02
  5.05408780e-02  1.76390451e-02  5.15259206e+00  4.93200497e+00
  4.24248766e-03  1.53050509e-03  3.56763189e-01  3.42039405e-01
 -4.20727014e-01 -4.03129836e-02 -2.51178460e-03 -1.35137772e-01
 -4.35989804e-03  8.63428520e-05  2.24322932e-04 -3.15081896e-04
 -3.06012025e-01 -4.54745735e-01 -1.27896741e-01 -5.66899802e-01
  1.15652635e-01  4.22522878e-02  4.60262757e-03  1.18645082e-01
 -3.76861643e-01 -1.91222453e-01 -1.13607276e-01 -2.07355081e-01
  3.52050747e-01  2.79879242e-02  1.70847396e-02  2.70433207e-02
  1.10178396e-01  6.38056743e-02  3.54581695e-02  7.06382257e-02
  8.26841558e-01  4.52124358e-02  3.79204902e-02  3.69609283e-02
 -1.47349864e+00  2.32633676e+00  3.97101674e-01 -7.92297904e-01
  1.60553537e-01 -4.32788780e-01  5.67356610e-01 -9.48604611e-01
 -9.19301223e+00]
supnorm grad right now is: 9.193012229173807
Weights right now are: 
[  0.97586373  -3.5914076   -2.51439432  -2.18274193  -1.76608296
   3.60587124   3.08570036   3.59782497   1.18873906   6.70680072
   2.46979977   9.16002134   5.64512474  -0.97360516   6.95462878
  -0.19084807   6.34264282   0.03175194   3.28982222  -1.3247307
   6.53861405  -0.02990159   5.03893736   0.04814884  -1.45037858
   8.94505943   7.07491673   9.29692782   5.63103504   0.7607902
   0.78817432   1.80367696  -7.24683941   0.80205899   3.87821702
  -0.02916107   2.78583446  -6.35602828  -0.48190612  -6.5843006
  -4.29704903   2.11119971   1.35120755   4.26743078   3.91558061
  -5.95766634  -4.58515152  -5.30948362   8.50583452  -1.63419372
  -4.00474016  -2.21668504   2.33422564 -10.75699504  -9.1301096
 -11.51054945   5.84492476   3.4199986   -0.88206797  -3.46222524
   2.18123116  -2.73265476  -1.86060861  -4.03466353  26.05718827]
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2385.270570647518
gradient value of function right now is: [-6.41740998e-02 -2.35552436e-03 -3.23844705e-01 -1.65175227e-02
  6.41740998e-02  2.35552436e-03  3.23844705e-01  1.65175227e-02
  2.25191021e-01  5.23621374e-04  2.05633059e-01 -8.79518216e-03
  1.24820388e-03 -8.39677914e-05 -1.26037565e-02 -2.29889729e-02
  6.76619318e-02 -4.69623249e-03 -1.23125206e+00 -1.56552959e+00
  8.31677080e-03 -4.46224929e-04 -8.44425689e-02 -1.36603967e-01
 -4.77304515e-01 -4.08312938e-02 -4.58124995e-03 -1.06296125e-01
 -3.33102699e-03  2.72244270e-04  8.25035507e-05  5.01379243e-04
  1.51529287e-01  1.66580585e-01  7.29369387e-02  2.44606005e-01
  2.28740763e-02 -2.71823115e-02 -9.20222782e-03 -4.62149320e-02
  6.52533049e-02  4.03180595e-02  1.27983883e-02  6.58207413e-02
  1.75805241e-01 -6.68752507e-03  4.43105266e-04 -1.32569019e-02
 -1.85542524e-02 -1.33700482e-02 -3.47446811e-03 -2.33941635e-02
  5.71027267e-01  1.55772470e-02  1.75504203e-02  1.24311012e-02
 -1.80043736e-01  7.81010668e-01 -9.19359570e-02 -3.47589706e-02
 -8.33264949e-03 -9.59781704e-02 -2.48314555e-01  1.32296990e-01
  6.97046799e+00]
supnorm grad right now is: 6.9704679940102
Weights right now are: 
[  1.23045758  -3.65452955  -3.10157579  -2.5542751   -2.02067682
   3.66899318   3.67288183   3.96935815   1.5484321    6.62989948
   2.64199777   8.84808082   6.22230755  -0.89200429   6.69196512
  -0.09547043   7.43387542   0.09227909   2.77111355  -1.96043164
   7.49634962   0.05793153   4.54120424  -0.27586144  -1.84533975
   9.32689263   8.40644961   9.36351803   5.98297722   0.96047033
   0.78708449   2.17691147  -7.0243692    1.15846002   3.93075023
   0.28992144   3.85215984  -5.99562897  -0.67130586  -6.21837693
  -3.70748159   2.96375104   2.7795605    5.0177385    4.37604269
  -5.86087695  -4.74911595  -5.22568316   8.35271959  -1.95379212
  -4.8168089   -2.46880218   3.19467486 -11.01758797  -8.9809482
 -12.22030467   6.14864337   3.36613883  -0.61903675  -4.03563518
   2.78149571  -3.57109488  -1.90944422  -4.28410757  26.63046215]
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2387.427041401504
gradient value of function right now is: [-1.92952703e-01  7.39627799e-02  1.57440480e+00  9.52655836e-02
  1.92952703e-01 -7.39627799e-02 -1.57440480e+00 -9.52655836e-02
  4.77524320e-01  6.88056057e-04  8.75129764e-01  1.72275515e-02
  1.51306725e-04  1.89256857e-03  1.66937828e-01  5.00855185e-01
  1.12115037e-02  8.41438690e-03  5.84785449e+00  6.17510570e+00
  1.03424594e-03  1.38224407e-03  2.87147085e-01  4.84198652e-01
 -3.58444970e-01 -2.00854726e-02 -7.65740639e-04 -6.20474056e-02
 -3.64700367e-03  1.96094538e-03  2.07847147e-03  1.80709553e-03
 -3.19887831e-01 -1.51214822e+00 -1.25297800e+00 -1.66832993e+00
 -6.96465916e-02  2.45925951e-02  4.85187335e-03  7.69021845e-02
 -2.02435080e-01 -1.56962014e-01 -7.45131342e-02 -2.13723004e-01
  2.16657800e-01  1.23912600e-02  1.50423976e-02  1.07364277e-02
  4.27081223e-02  4.92752169e-02  2.03701608e-02  6.93980761e-02
  5.51462648e-01  2.08376215e-02  3.49407388e-02  1.24422110e-02
 -4.23597200e-01  8.85704218e-01  3.22350611e-01 -4.49141562e-01
  2.17003143e-01 -4.79773432e-01  5.86554535e-01 -5.46734429e-01
 -6.38349651e+00]
supnorm grad right now is: 6.383496505542425
Weights right now are: 
[ 2.00370626e+00 -4.14862615e+00 -2.42813072e+00 -2.23432479e+00
 -2.79392550e+00  4.16308978e+00  2.99943676e+00  3.64940783e+00
  1.00178551e+00  5.46670884e+00  2.12631864e+00  8.37590363e+00
  7.79257734e+00 -1.18478530e+00  7.07237683e+00 -1.20060984e-02
  8.22980493e+00  5.62249556e-02  2.96904947e+00 -1.35258395e+00
  8.67062957e+00 -4.88524724e-02  5.00480602e+00  5.42822498e-01
 -1.09794871e+00  1.04047804e+01  1.07399408e+01  1.03101191e+01
  7.35587363e+00  1.57295346e+00  9.56342333e-01  3.00121739e+00
 -8.31489236e+00  1.40039419e-01  2.16121107e+00 -9.14232217e-01
  3.96872745e+00 -6.34236794e+00 -1.93827798e+00 -6.59149754e+00
 -3.13748493e+00  3.11631837e+00  4.30896677e+00  4.58375125e+00
  4.06044087e+00 -6.13324896e+00 -6.12937567e+00 -5.04740573e+00
  8.37328776e+00 -1.60506802e+00 -5.81352948e+00 -1.59293658e+00
  2.81103233e+00 -1.21749605e+01 -1.00392481e+01 -1.35656878e+01
  6.84594453e+00  2.77920724e+00  7.91306156e-01 -4.25664427e+00
  3.45215541e+00 -3.20653035e+00 -2.89854496e-01 -4.94078613e+00
  2.62988355e+01]
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2388.2327543839724
gradient value of function right now is: [-1.30404970e-01  1.11363035e-03  3.75625395e-01  1.83499465e-02
  1.30404970e-01 -1.11363035e-03 -3.75625395e-01 -1.83499465e-02
  2.17997181e-01  2.04021782e-04  5.29823656e-01  3.91549597e-03
 -2.68661385e-04  1.39450089e-06  3.19485669e-02 -1.29307898e-03
 -7.87246250e-03  5.95547274e-04  1.89802134e+00  1.26057446e+00
 -7.24728660e-04  4.18026787e-05  1.41647642e-01  6.29605633e-02
 -2.56791941e-01 -1.71674536e-02 -1.56670369e-03 -7.39320176e-02
 -1.32338527e-03 -6.39461121e-05 -2.03618691e-05 -2.70530976e-04
 -6.52491932e-02  9.90139315e-03  2.36973185e-02 -1.89751102e-02
  2.15808895e-01  7.15889276e-02  1.80686078e-02  1.86307741e-01
 -1.93571062e-01 -9.58545361e-03 -1.76516726e-02 -3.76517532e-03
  2.23125518e-01  8.23391847e-03  1.07030115e-02  6.72976415e-03
  4.94898950e-03 -7.20383875e-03 -3.31934238e-03 -1.02126936e-02
  6.12353159e-01  1.96781185e-02  2.64200395e-02  1.70328551e-02
 -9.52589075e-01  1.91836121e+00  1.13137938e-01 -3.46643894e-01
  1.16149491e-01 -3.97837144e-01  9.66134206e-02 -3.20764274e-01
 -1.83748550e+00]
supnorm grad right now is: 1.9183612141144193
Weights right now are: 
[ 1.69852214e+00 -5.10392313e+00 -2.59273763e+00 -2.87546173e+00
 -2.48874138e+00  5.11838677e+00  3.16404367e+00  4.29054477e+00
  1.66626886e+00  5.63134342e+00  2.62230120e+00  9.38626668e+00
  8.22609639e+00 -1.41940429e+00  7.26409187e+00 -7.35616693e-01
  8.45070719e+00  4.15935107e-01  3.02024219e+00 -1.44749035e+00
  9.10727409e+00 -8.52989501e-02  5.06741283e+00  1.98846189e-01
 -1.15287904e+00  1.06473908e+01  1.06515639e+01  1.09987610e+01
  7.48291671e+00  2.00443530e+00  1.25394576e+00  3.50213928e+00
 -7.15087920e+00  1.60090709e+00  4.50109381e+00  4.65431967e-01
  4.21233320e+00 -4.59848287e+00  4.39569735e-01 -6.06842014e+00
 -3.92425598e+00  3.55107018e+00  4.09076691e+00  5.35768876e+00
  4.46980265e+00 -5.90326422e+00 -6.14323740e+00 -5.01170952e+00
  8.98907393e+00 -2.58718647e+00 -5.91852876e+00 -2.90085379e+00
  2.29012849e+00 -1.40204613e+01 -1.27920900e+01 -1.51521577e+01
  6.50209161e+00  3.29205578e+00 -3.24410220e-04 -3.37738663e+00
  2.87706442e+00 -2.06276210e+00 -1.34017400e+00 -4.06013090e+00
  2.62541366e+01]
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2388.8035267128375
gradient value of function right now is: [-1.69085459e-01  6.92104317e-03 -4.12553852e-01  7.50346904e-04
  1.69085459e-01 -6.92104317e-03  4.12553852e-01 -7.50346905e-04
  2.95734627e-01  1.80665156e-04  7.37255743e-01  3.62640537e-02
 -7.47147287e-05  8.89695912e-06 -7.00581159e-03  3.36540958e-02
 -1.17275605e-02 -3.00446797e-04 -1.66568559e+00 -1.63135887e+00
 -4.82882912e-04  4.91460711e-07 -1.95415889e-02 -3.47046684e-03
 -2.15281046e-01 -7.53404969e-03 -3.24076092e-05 -4.62660475e-02
 -8.91080063e-04  9.16069510e-06  2.02711290e-05 -8.69772091e-05
  8.08337779e-02  1.91176077e-01  1.07657055e-01  2.41714431e-01
 -5.16039397e-01 -6.09595404e-02 -1.46825875e-02 -1.65529562e-01
  1.22258107e-01  3.84320975e-02  1.52073910e-02  5.73977478e-02
 -3.37330507e-02 -6.83239026e-03 -2.91598930e-03 -9.30816044e-03
 -1.85805906e-02 -2.14338143e-02 -9.36539944e-03 -3.15214309e-02
 -3.01881339e-03 -2.83536397e-03  1.87401599e-03 -4.45076710e-03
  2.59389796e-01 -2.77762146e-01 -1.45905864e-01  1.30826387e-01
 -6.52509964e-02  2.28938164e-02 -2.54552482e-01  2.36211939e-01
  5.75360609e+00]
supnorm grad right now is: 5.753606085181195
Weights right now are: 
[ 1.84766140e+00 -4.20952859e+00 -2.68905303e+00 -2.25310607e+00
 -2.63788064e+00  4.22399223e+00  3.26035907e+00  3.66818912e+00
  1.31990003e+00  5.24405250e+00  2.62585911e+00  9.83909860e+00
  9.12230572e+00 -1.18503473e+00  8.51467728e+00  5.74329608e-01
  9.67765000e+00  1.26141765e-01  2.73026445e+00 -1.63834274e+00
  1.01223013e+01  5.52364868e-03  5.60297303e+00  1.13199441e+00
 -1.27996793e+00  1.09439315e+01  1.05862534e+01  1.09881516e+01
  8.02831340e+00  2.51186779e+00  1.59221071e+00  4.16960820e+00
 -8.14714283e+00  9.11835521e-01  3.39603952e+00 -4.50046984e-01
  3.90950518e+00 -5.00905446e+00  9.77249085e-02 -6.52762907e+00
 -3.68729581e+00  3.66185301e+00  4.85003086e+00  5.10618159e+00
  4.42217668e+00 -5.81488174e+00 -6.24585362e+00 -4.71999152e+00
  9.63860210e+00 -1.92687894e+00 -5.89104142e+00 -1.87558004e+00
  2.30752593e+00 -1.46108362e+01 -1.25819508e+01 -1.64053781e+01
  6.70517656e+00  3.03184099e+00  4.07850312e-01 -4.01059017e+00
  3.27593062e+00 -3.09075067e+00 -7.69165867e-01 -4.50621310e+00
  2.65700093e+01]
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -2388.8760793062193
gradient value of function right now is: [-1.23969625e-01 -2.64617485e-04 -6.59478596e-01 -6.04805436e-03
  1.23969625e-01  2.64617485e-04  6.59478596e-01  6.04805436e-03
  2.87731552e-01  1.32985019e-04  5.87734635e-01  6.22039005e-03
 -1.59023348e-05 -6.71247121e-07 -8.39661984e-03 -7.90888267e-03
  2.51678125e-03 -2.48266916e-04 -2.33994134e+00 -2.30278217e+00
  3.01586583e-04 -4.03437434e-06 -3.78561409e-02 -4.98936831e-02
 -3.46499627e-01 -1.16188534e-02 -2.12281073e-04 -6.30245522e-02
 -6.14524607e-04 -1.06818254e-05  2.81755212e-07 -4.45031517e-05
  1.41334787e-01  1.89624375e-01  1.29957676e-01  2.50165388e-01
 -3.72785433e-01 -1.55180118e-01 -8.02841355e-02 -2.31669881e-01
  1.56025326e-01  2.74342256e-02  1.56861428e-02  4.06663910e-02
  6.04983316e-04 -6.01044096e-03 -2.37979820e-03 -8.67946784e-03
 -2.10119451e-02 -9.17705552e-03 -4.36228535e-03 -1.46707601e-02
  3.76235525e-01  3.31225081e-03  1.47529433e-02  1.63788879e-04
  5.91758827e-01 -7.12731688e-01 -1.05187359e-01  3.43914338e-02
 -5.07339940e-02 -1.27487767e-01 -1.90557569e-01  1.37990639e-01
  2.43268856e+00]
supnorm grad right now is: 2.432688562387583
Weights right now are: 
[ 2.02877472e+00 -5.05998287e+00 -2.64556594e+00 -2.82372720e+00
 -2.81899395e+00  5.07444651e+00  3.21687198e+00  4.23881025e+00
  1.67410126e+00  4.94739788e+00  2.67534406e+00  1.00339703e+01
  9.17953861e+00 -1.45102476e+00  8.56624697e+00  1.46321625e-01
  9.98257246e+00  2.47508797e-02  2.50131596e+00 -1.84737299e+00
  1.05202656e+01 -1.33620116e-01  5.26718575e+00  8.50638848e-01
 -1.04658282e+00  1.20750848e+01  1.16255290e+01  1.16885680e+01
  8.52551777e+00  3.22127891e+00  1.74829759e+00  5.09653427e+00
 -8.15264439e+00  1.01771019e+00  3.01864758e+00 -2.73236182e-01
  4.63464030e+00 -4.55004006e+00 -6.86564099e-01 -5.67066939e+00
 -3.11660515e+00  4.33493545e+00  6.16040327e+00  5.45590596e+00
  4.60952054e+00 -5.88610918e+00 -6.57811733e+00 -4.63110702e+00
  9.01387514e+00 -1.83917019e+00 -6.36228342e+00 -1.60166955e+00
  2.80654819e+00 -1.47032897e+01 -1.28359926e+01 -1.65701776e+01
  7.23440633e+00  2.89245721e+00  1.00257389e+00 -4.20624072e+00
  3.68674204e+00 -2.98061378e+00 -2.44674934e-01 -4.70033342e+00
  2.62849512e+01]
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2387.6458437582132
gradient value of function right now is: [ 1.01144802e-01 -1.62949546e-03  1.02145133e-01  3.98472037e-03
 -1.01144802e-01  1.62949546e-03 -1.02145133e-01 -3.98472037e-03
  2.42624397e-02 -2.95875725e-05 -6.33538663e-01 -8.44779777e-02
  2.81725594e-04 -8.76465024e-08 -6.23024613e-03 -2.38696282e-02
  3.87220048e-02  2.61340371e-05  7.52363480e-01 -3.81945662e-02
  2.53109982e-03  1.25276903e-06  3.95598713e-02 -1.19191456e-02
 -4.77460532e-01 -1.53991125e-02 -6.06791828e-04 -1.33307407e-01
  9.92712778e-05  5.55666123e-06  5.81337031e-08  1.71085023e-05
  4.32548770e-02  1.37630421e-01  3.21137027e-02  2.00090099e-01
  7.92214291e-01  6.29847767e-02  6.21538925e-03  3.19671035e-01
 -2.47774536e-01  3.28242839e-02  1.21960232e-02  4.40122300e-02
  2.17013286e-01 -1.60964167e-03 -1.13089581e-04 -2.82252558e-03
 -1.98790621e-02 -1.46143531e-02 -5.29186042e-03 -1.98417950e-02
  1.76524097e+00  5.93738805e-02  4.43478703e-02  5.93222879e-02
 -1.04491382e+00  2.51330457e+00  3.44668097e-01 -1.32629282e+00
  1.19536440e-01 -7.94844057e-01  4.28397678e-01 -1.48246212e+00
 -7.25948159e+00]
supnorm grad right now is: 7.259481594238695
Weights right now are: 
[ 2.82867947e+00 -5.98922461e+00 -2.36238394e+00 -3.00759087e+00
 -3.61889870e+00  6.00368825e+00  2.93368999e+00  4.42267392e+00
  1.41809044e+00  4.30997466e+00  2.11462102e+00  9.27739416e+00
  1.13102987e+01 -1.44585268e+00  8.36006400e+00 -4.81952766e-01
  1.17983585e+01  5.87003620e-01  2.62751496e+00 -1.60203125e+00
  1.25696285e+01  2.96249635e-02  5.42134850e+00  6.47298148e-01
 -1.64247228e+00  1.12025863e+01  1.07345591e+01  1.14813621e+01
  9.17079959e+00  3.76564077e+00  1.94167090e+00  6.34514645e+00
 -7.84750343e+00  1.43619129e+00  4.25971085e+00 -1.59650089e-02
  4.77762880e+00 -4.24613475e+00 -1.93380874e-01 -6.24768315e+00
 -3.51817172e+00  4.31997750e+00  5.45757165e+00  5.80809602e+00
  4.94603685e+00 -5.78320204e+00 -6.91896670e+00 -4.45446019e+00
  1.05051819e+01 -1.91309264e+00 -5.80360063e+00 -1.93800326e+00
  2.61060139e+00 -1.70169862e+01 -1.43222488e+01 -1.91587774e+01
  6.81468696e+00  3.30047564e+00 -4.67523399e-01 -2.67949195e+00
  2.32073199e+00 -2.21995906e+00 -1.60547586e+00 -3.04820459e+00
  2.58745641e+01]
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2387.2651194144305
gradient value of function right now is: [-1.10892005e-01 -1.18654407e-02 -4.10066028e-01 -1.08852333e-02
  1.10892005e-01  1.18654407e-02  4.10066028e-01  1.08852333e-02
  2.61412806e-01  4.22068258e-05  7.18864922e-01 -2.98326337e-03
  8.34144392e-05 -5.54433254e-07 -1.17897483e-01 -1.67171753e-01
  5.08959128e-03 -2.19317765e-06 -1.09756672e+00 -1.42080996e+00
  5.26125697e-04 -6.19599198e-08 -6.47648648e-02 -1.03407487e-01
 -6.35134965e-01 -1.98830009e-02 -2.44129215e-04 -1.24559310e-01
 -1.71308736e-04 -5.36627099e-06  3.21287915e-07 -3.65159659e-05
  3.82648029e-01  3.59675297e-01  1.48491644e-01  6.22921775e-01
 -7.91593926e-02 -4.85553187e-02 -1.79859205e-02 -6.43851992e-02
  2.60832989e-01  7.50579907e-02  4.73358430e-02  8.51025694e-02
  7.69171042e-02 -2.37129254e-02 -1.32975037e-02 -2.76890819e-02
 -6.93935483e-02 -1.60893390e-02 -6.85401891e-03 -2.06704592e-02
  1.14761313e+00  1.69287263e-02  3.12529013e-02  8.90401389e-03
  6.98677941e-01 -6.79025597e-01 -1.88714026e-01  7.53794457e-03
 -8.70390165e-02 -3.23800236e-01 -2.88890702e-01  3.01674582e-01
  7.69853942e-02]
supnorm grad right now is: 1.4208099631256548
Weights right now are: 
[  2.96581798  -7.38990793  -2.40547969  -3.56904855  -3.75603722
   7.40437157   2.97678574   4.9841316    2.21067333   4.46300622
   2.17517941   9.48818546  12.7753076   -1.39893089   7.84643355
  -1.51885148  13.11415491   0.4513576    2.61742409  -1.71295793
  14.00784339   0.02954599   5.48400148   0.1551761   -1.61253187
  12.51000406  11.45877008  12.49959286   9.13294844   4.3705768
   2.17925862   7.71967585  -6.99187651   2.0672047    4.96960998
   0.42220575   5.28158316  -4.29847407  -1.67198182  -5.84278725
  -3.3648438    4.66951266   6.33211767   5.88873728   4.63770137
  -5.53300874  -7.40504357  -3.91931003  10.85030033  -1.75613932
  -5.28911157  -1.81930158   2.6550672  -17.09492593 -14.62233046
 -19.20024386   7.63781938   2.56561106  -0.05234967  -2.9447743
   2.72509248  -2.33462099  -1.26152157  -3.3666319   25.96142638]
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2387.0820975113324
gradient value of function right now is: [ 3.25206699e-01 -2.19997560e-02 -9.86337984e-01 -2.51048726e-02
 -3.25206699e-01  2.19997560e-02  9.86337984e-01  2.51048726e-02
 -2.12318950e+00 -3.14282833e-04 -3.03343386e+00  1.25802300e-01
 -2.56338434e-05 -3.22481810e-07 -1.07688441e-01 -2.48129414e-01
 -3.24204761e-03 -1.27015755e-05 -2.19841130e+00 -2.20437019e+00
 -2.28688335e-04 -5.05339180e-07 -9.40103362e-02 -1.30344881e-01
  4.76381350e+00  1.08286245e-01  1.54933652e-03  7.62852953e-01
  1.55708702e-03  3.23459927e-05 -1.33075419e-07  2.26146174e-04
  1.04855567e+00  1.07078938e+00  7.11406888e-01  1.57282474e+00
 -9.54076394e-01 -3.68142395e-01 -1.18426439e-01 -6.70485615e-01
  1.06206677e+00  1.34042998e-01  1.02376281e-01  1.03888904e-01
 -1.47910474e+00 -4.92427354e-02 -4.71990934e-02 -3.59265720e-02
 -2.59875226e-01 -7.62449066e-02 -5.58489204e-02 -6.11318249e-02
 -8.37904783e+00 -4.12400008e-02 -1.36155956e-01 -1.44780193e-02
  6.25389515e+00 -2.60648129e+01 -8.60364715e-01  3.38953927e+00
 -1.22957649e+00  7.79616696e+00 -6.37566970e-01  1.92033624e+00
  1.72468316e+00]
supnorm grad right now is: 26.06481287699754
Weights right now are: 
[  4.08121931  -6.10265538  -1.95869397  -2.57444613  -4.87143855
   6.11711902   2.53000002   3.98952918   3.98847834   5.11280268
   1.30279861   9.69026778  15.13913269  -1.39412708   9.0052003
  -0.07356519  15.58055874   0.70518437   3.24816448  -1.52258501
  16.08933541   0.07390858   6.37700059   1.19214383  -2.26537553
  13.75241872  11.877859    14.28725717   8.44871623   4.6163483
   2.14593795   9.19929719  -7.05406387   2.18117801   5.36141986
   0.36921471   6.18643514  -4.09901652  -2.43490613  -5.19944367
  -4.16206531   4.4994052    6.04600127   6.00197584   4.86016604
  -4.75628805  -6.89259055  -3.35394207  11.02162183  -2.08830013
  -5.8367514   -2.26639017   2.34424588 -18.59040143 -16.65058495
 -20.3393329    8.27872625   1.78260698  -0.02691931  -2.23775627
   2.68145105  -1.4101661   -1.45130549  -2.93905352  25.59686   ]
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2386.4112129215523
gradient value of function right now is: [-2.34209162e-01 -5.36319063e-03  3.07771865e-01 -7.19813493e-03
  2.34209162e-01  5.36319063e-03 -3.07771865e-01  7.19813493e-03
 -5.05589773e-02 -5.03587063e-05  1.66419783e+00  2.11516144e-01
 -3.67393028e-06 -1.48105286e-07 -1.56260223e-02 -7.46091282e-02
 -1.80309907e-03  1.10887726e-05  4.57494047e-01  2.23790103e+00
 -6.32214039e-05 -9.51679859e-08 -3.82851170e-02 -7.62571311e-03
  1.53454034e-01  1.18836562e-03  2.39964826e-05  3.35871346e-02
  3.45716326e-04  1.08900034e-05  2.02407550e-07  1.05400751e-05
 -1.86608913e-01 -2.76886988e-01 -6.61495589e-02 -5.74891231e-01
 -2.06529305e+00  1.75695934e-02  1.00313591e-02 -1.48364346e+00
  3.27750128e-01 -1.01018590e-01 -5.71662565e-02 -9.27693988e-02
  1.02099435e-02  2.51483519e-02  2.32178662e-02  2.09386054e-02
  3.89301842e-02  4.53216891e-03  7.26721815e-03 -5.41469854e-04
 -2.94287377e+00 -7.42982696e-02 -3.15431734e-01 -2.19387143e-02
 -9.18595401e-01  1.51078734e+00  7.16736549e-02  2.13896412e+00
 -2.97454368e-01  9.33924006e+00  1.88648029e-01  3.40705030e-01
 -3.41960949e+00]
supnorm grad right now is: 9.33924005924862
Weights right now are: 
[  3.31798067  -7.20274879  -1.62112675  -2.53526114  -4.10819991
   7.21721243   2.19243279   3.95034419   6.07782742   7.44846804
   2.19733829   9.94046292  15.63607363  -1.36307113  10.7336056
  -0.20211225  16.47680264   0.4730309    3.19484499  -1.32471281
  16.75280888   0.0679285    6.97646365   1.66638362  -3.0044747
  13.05609405  10.83857079  15.13983018   6.10230405   3.01133831
   1.42886246   9.13048852  -8.73721848   1.12063971   3.90758191
  -0.7456552    5.94124166  -3.33697748  -1.93871198  -5.67130389
  -3.9413742    4.62355928   6.89217202   5.79009567   5.70958283
  -4.35357977  -7.0559202   -2.68239258  11.28177476  -2.26453376
  -6.83003528  -2.09758649   2.18552819 -20.68372642 -18.47216282
 -22.66032376   6.96922077   3.00998585   0.53366343  -2.04645011
   2.27207732  -1.01490268  -0.59094171  -2.88231762  26.08084584]
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2397.1686684394863
gradient value of function right now is: [ 7.38267123e-03  3.25858750e-01  5.54457846e+00  9.94164141e-02
 -7.38267123e-03 -3.25858750e-01 -5.54457846e+00 -9.94164141e-02
  1.93448615e-01  2.37422493e-04 -3.67293721e-02 -1.96910377e-01
 -3.76720555e-06  1.23050950e-05  7.75979140e-01  4.43748806e+00
 -3.91327308e-03  2.56770307e-05  5.18376136e+00  7.62275512e+00
 -4.58119432e-05  1.45819629e-06  1.02884641e-01  5.22221564e-01
 -1.47856926e+00 -2.77273004e-02 -5.76472022e-05 -5.14716665e-01
 -1.87141625e-03  3.46849731e-06  9.63355695e-06 -6.86754361e-04
 -2.94438601e-01 -1.14942362e+01 -9.08550818e+00 -1.19907990e+01
  1.54214202e+00  1.30620843e-01  1.63159986e-02  1.57193825e+00
 -1.40130840e+00 -5.17105539e-01 -2.62965131e-01 -5.59491177e-01
  6.17054335e-01  8.86537135e-02  5.51741146e-02  8.74416754e-02
  1.73494867e-01  1.28494853e+00  5.73633914e-01  1.53302265e+00
  5.12431490e+00  1.70294469e-01  1.22690975e-01  1.24166430e-01
 -2.15942832e+00  8.93798573e+00  1.90200744e+00 -8.34325425e+00
  2.46738674e+00 -5.78389060e+00  1.86912818e+00 -7.47189861e+00
 -1.89265124e+01]
supnorm grad right now is: 18.926512439750674
Weights right now are: 
[  4.58282068  -7.72547582  -1.31033937  -1.98259554  -5.37303992
   7.73993946   1.88164541   3.39767859   7.39439212   7.98800393
   1.17337929   9.7556573   16.51578285  -1.29629318  12.20036112
   0.04410137  18.89273604   1.39585983   3.42252262  -1.92133517
  18.02305568   0.13119317   8.48803769   1.97968872  -3.26587652
  12.49850795  10.19194351  16.10360629   5.76740203   1.5614465
   0.7619474   10.56606846  -9.42067722   0.52592938   2.51029039
  -1.25984143   7.03554728  -4.81936443  -3.34228067  -4.40225828
  -4.1510754    4.3444662    7.49589758   5.20371187   5.31705908
  -4.41420161  -7.86435791  -2.46945675  11.8198903   -0.18020827
  -6.21238821   0.19686601   2.36560355 -21.74041652 -18.22459051
 -24.8781649    7.87820465   2.00724046  -0.08012943  -1.95537026
   2.01373459  -1.89109474  -0.7327968   -2.21538527  26.10800662]
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2402.2833311522627
gradient value of function right now is: [-3.31434849e-02 -5.35511518e-03  9.68759702e-01 -8.10096785e-04
  3.31434849e-02  5.35511518e-03 -9.68759702e-01  8.10096784e-04
  1.81499998e-01  5.35854803e-04  2.62333811e-01 -2.09172623e-01
 -5.39066443e-06 -1.25778735e-05 -1.57768308e-02 -8.27421255e-02
 -2.82350708e-03  1.38912211e-04  2.80138100e+00  2.77892834e+00
 -3.88502381e-05 -9.15420497e-07  2.18908881e-03 -6.12690274e-03
 -1.58855254e+00 -1.54606843e-02  1.35730911e-04 -5.60275233e-01
 -4.99182036e-03  2.82506013e-04  9.75697408e-05 -1.53342825e-03
 -2.48145653e-01 -3.94707038e-01 -1.83479138e-01 -7.52706666e-01
  1.76589456e+00  1.45940465e-01  3.19803702e-02  1.67633259e+00
 -1.27395224e+00 -2.55942378e-01 -1.32993909e-01 -2.93408826e-01
  4.26948199e-01  5.63918612e-02  3.21818374e-02  6.24464348e-02
  3.08084404e-02  7.22330020e-03 -3.17596034e-03  1.37918382e-02
  6.01309738e+00  1.70957380e-01  8.50235061e-02  1.69554320e-01
 -2.39045235e+00  9.23248211e+00  1.47626239e+00 -7.71073304e+00
  6.28540777e-01 -3.63923228e+00  1.82244667e+00 -8.98524820e+00
 -8.74601724e+00]
supnorm grad right now is: 9.23248211092074
Weights right now are: 
[  4.68908802  -8.01396168  -1.46198372  -2.1967361   -5.47930726
   8.02842532   2.03328977   3.61181914   8.13430935   9.16209789
   1.16485925  10.32601892  17.13574762  -2.21029295  11.95417823
  -0.2211646   19.84083809  -1.56059926   4.04572518  -1.78218581
  19.00783189  -0.10496111   8.81664048   1.77100997  -3.17276915
  11.85750313   7.77202516  16.81532325   4.93519473  -1.82897008
  -1.58330169  10.54720541 -10.2070245    1.34391754   3.31147252
  -0.78898548   6.66385822  -4.25618654  -2.62301073  -4.59944577
  -4.22839891   4.37565483   7.81433075   5.03037623   5.7955134
  -4.08606891  -8.23055282  -1.88512614  12.20818203  -0.87458988
  -7.0684279   -0.31758946   2.12232956 -22.78145162 -18.93430842
 -26.36843487   7.49575984   2.14999      0.02911543  -2.12013193
   1.78995037  -2.30436257  -0.55913473  -2.21546057  26.60717521]
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2399.049278540268
gradient value of function right now is: [-3.67020797e-01 -8.60417099e-03  3.93276467e-02 -2.72730597e-03
  3.67020797e-01  8.60417099e-03 -3.93276467e-02  2.72730597e-03
  3.45123672e-01  2.17993917e-03  3.40884380e+00  7.93263492e-02
 -2.60894729e-06 -3.61682769e-03 -2.39447297e-02 -1.17220671e-01
 -2.94473989e-03 -2.08300096e-03  7.34456864e-01  6.95233961e-01
 -1.84332546e-05 -3.09671233e-04 -3.00444272e-03 -1.14937673e-02
 -2.54650738e+00 -6.43394416e-03  1.17287197e-04 -8.92405397e-01
 -2.26177406e-02 -2.24236625e-02 -1.19384260e-02 -3.53027028e-02
 -2.55764364e-02  2.94415025e-01  1.23579245e-01  3.21365006e-01
 -7.84005008e-01  3.97515180e-02  7.96328996e-03 -4.84712342e-01
 -2.52698303e-01  2.22932109e-02 -2.88395768e-03  2.99309490e-02
  1.08252766e-01 -2.19802479e-02 -3.68137831e-03 -3.07652834e-02
 -2.22634510e-02 -7.92335059e-02 -2.00232678e-02 -1.09981127e-01
  8.59080444e+00  2.48240499e-01  1.28041911e-01  2.68717174e-01
 -8.12428507e-01  3.92363913e+00  1.03465043e+00 -1.04858568e+01
  2.28579208e-01 -4.40452448e+00  1.52223294e+00 -1.33147674e+01
 -5.10290915e+00]
supnorm grad right now is: 13.314767359354752
Weights right now are: 
[  4.73890036  -7.39961687  -1.41471199  -1.49985548  -5.5291196
   7.41408051   1.98601803   2.91493853   9.42131445  10.24873119
   1.26913864  11.22674858  17.27296606  -5.44006489  12.73165261
   0.53635035  21.45218844  -4.0282745    3.85632892  -2.19933707
  19.33259402  -2.71007485   9.33352338   2.41696904  -3.95671385
  10.34002562   5.90921057  16.65778454   3.94788004  -4.47806297
  -6.42550934   9.57730376  -9.56986381   1.37955077   3.58044551
  -0.60145108   6.25119247  -4.48951841  -3.12492466  -4.85136095
  -3.75221886   4.75945547   8.23889049   5.53953011   6.34028263
  -3.68047189  -8.02468785  -1.52389917  12.7650253   -0.44506722
  -6.56807604   0.04155604   2.65229803 -23.3986054  -19.67746413
 -27.00765711   7.26382129   2.46577341  -0.48975007  -2.03598545
   1.97121255  -2.16779711  -1.28972175  -2.0816908   26.40843267]
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2390.94172060383
gradient value of function right now is: [ 6.77408768e-01 -3.82948123e-02  3.98308198e-01 -6.21941777e-03
 -6.77408768e-01  3.82948123e-02 -3.98308198e-01  6.21941777e-03
 -5.92125441e-01 -3.18416262e-02 -6.20423480e+00  1.81651567e-01
  2.43219002e-06 -4.74562931e-02 -7.83788505e-02 -4.98573740e-01
  3.12838284e-03 -9.16493757e-03  8.58449470e-01  1.47797428e+00
  1.50109493e-05 -1.87526636e-03 -2.95645724e-03 -1.96328149e-02
  4.60025855e+00  6.95226211e-02  7.37902403e-04  1.62043751e+00
  3.79970267e-01 -2.29802962e-01 -1.50344521e-01 -1.50425445e-01
 -1.59971351e-01 -1.27024898e-01  3.26730345e-01 -5.33259937e-01
 -1.38549514e+00 -1.98998422e-01 -2.57577771e-02 -1.84334711e+00
  1.33432157e+00 -1.40561022e-01 -1.33031679e-01 -1.46832550e-01
 -5.53684595e-01 -8.45253361e-02  4.55962542e-02 -1.71118240e-01
  6.12762942e-02 -4.55814535e-01  6.17319333e-03 -7.19478192e-01
 -1.54534987e+01 -3.18614547e-01 -9.75674389e-02 -4.89881772e-01
  4.96873462e+00 -2.64429867e+01 -2.23198863e+00  1.62964221e+01
 -8.67436593e-01  3.74056313e+00 -3.65112272e+00  2.90652377e+01
  2.90162267e-01]
supnorm grad right now is: 29.065237692805233
Weights right now are: 
[ 5.05075989e+00 -7.11354239e+00 -1.00464802e+00 -9.03942298e-01
 -5.84097912e+00  7.12800603e+00  1.57595406e+00  2.31902535e+00
  9.89238992e+00  1.30659425e+01  1.07441140e+00  1.18976584e+01
  1.73018857e+01 -5.96109158e+00  1.34055753e+01  9.64915705e-01
  2.17890444e+01 -3.90221753e+00  4.25190147e+00 -2.14807203e+00
  1.94369049e+01 -2.85308433e+00  9.90122436e+00  3.09837512e+00
 -3.79666506e+00  7.87239067e+00  1.82147478e+00  1.72728113e+01
  2.47507571e+00 -4.76829864e+00 -6.81108871e+00  9.41740928e+00
 -1.09795963e+01  1.35983034e+00  3.51165219e+00 -8.66503403e-01
  6.36477450e+00 -6.04902049e+00 -4.32224206e+00 -4.34712716e+00
 -3.67811739e+00  3.28604921e+00  8.37140461e+00  3.71032277e+00
  5.98680066e+00 -2.56153468e+00 -8.21796022e+00 -1.79979880e-02
  1.37866978e+01  6.88396434e-02 -6.42962159e+00  6.47653550e-01
  2.22309450e+00 -2.45376840e+01 -2.06864947e+01 -2.82664847e+01
  7.71239528e+00  1.72677156e+00  2.43917569e-01 -1.83984073e+00
  2.91752852e+00 -2.12139737e+00 -6.67300167e-01 -1.75435869e+00
  2.61306651e+01]
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2398.3267895939944
gradient value of function right now is: [-3.94074174e-01  2.12585661e-01  7.37747757e+00  4.18926971e-02
  3.94074174e-01 -2.12585661e-01 -7.37747757e+00 -4.18926971e-02
  2.99530207e-01  1.77464180e-02  3.68050521e+00  2.65216474e-02
 -2.93915072e-07  2.26149702e-01  6.99283629e-02  1.92487491e+00
 -1.39073769e-03  3.20001031e-02  1.18142150e+00  2.40801972e+00
  8.35270014e-07 -1.83800539e-03 -9.59530222e-04 -2.17296314e-02
 -2.43763812e+00 -8.39521262e-03  3.71977262e-05 -8.61523953e-01
 -2.24254552e-01  9.07003102e-01  6.73712205e-01  1.00573320e+00
 -1.78903211e-01 -1.07321762e+00 -6.34544816e-01 -2.22993160e+00
 -2.31043827e-01  5.44617321e-03  4.73503856e-03  1.27221916e-01
 -8.68806008e-01 -1.89184073e-01 -9.53228568e-02 -2.68603441e-01
  1.45951973e-01  6.50425927e-01  1.95751665e-01  8.43680107e-01
  1.12007280e-01  1.68773372e+00  5.15730105e-01  2.16114082e+00
  8.86472326e+00  2.05990872e-01  9.27916503e-02  2.82387490e-01
 -1.39091021e+00  6.24148101e+00  1.17804749e+00 -9.84195604e+00
  2.49525443e+00 -3.80678831e+00  1.38192799e+00 -1.54810127e+01
 -1.64207399e+01]
supnorm grad right now is: 16.420739907875305
Weights right now are: 
[ 4.79592988e+00 -5.04242606e+00 -7.16239330e-01  9.46172658e-01
 -5.58614911e+00  5.05688970e+00  1.28754538e+00  4.68910389e-01
  1.00314241e+01  1.36950161e+01  1.37229910e+00  1.18931824e+01
  1.73026805e+01 -5.79644912e+00  1.47475416e+01  3.17964030e+00
  2.21646072e+01 -4.12078118e+00  4.30354292e+00 -2.55814064e+00
  1.94434354e+01 -2.06466348e+00  1.05386538e+01  4.63555330e+00
 -3.81334988e+00  7.04244946e+00 -3.11056994e-01  1.73806201e+01
  2.05398569e+00 -4.61071831e+00 -6.90265500e+00  9.89112754e+00
 -9.07012664e+00  1.64663381e+00  4.26061944e+00 -1.10223747e-02
  6.54523987e+00 -5.06219523e+00 -3.44803850e+00 -4.18271559e+00
 -3.41044964e+00  4.74421117e+00  9.77696752e+00  5.33935976e+00
  6.83607335e+00 -1.52405995e+00 -7.10817235e+00  7.99449923e-01
  1.37111096e+01  1.58282459e-01 -6.84903309e+00  7.00101280e-01
  2.49330561e+00 -2.45398958e+01 -2.09787367e+01 -2.80995340e+01
  7.67876528e+00  1.96006291e+00 -3.98309637e-01 -2.10006929e+00
  2.75469785e+00 -2.30425187e+00 -1.59318050e+00 -2.02972226e+00
  2.61903583e+01]
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2393.066770581631
gradient value of function right now is: [-4.85180027e-01 -1.01631786e-02 -2.43432193e+00 -4.85163518e-04
  4.85180027e-01  1.01631786e-02  2.43432193e+00  4.85163518e-04
  3.35890367e-01  3.91806001e-02  4.64207836e+00  1.87680353e-01
 -2.81399979e-07 -2.04035534e-02 -1.13980296e-02 -1.08550977e-01
 -4.55228474e-03 -8.71913285e-03 -2.62267744e+00 -2.38964760e+00
 -1.14274534e-06 -5.32750169e-05 -1.03617832e-04 -4.29097656e-04
 -2.49745046e+00 -5.84758032e-03  9.19248522e-06 -8.37666170e-01
 -4.99875673e-01 -8.51604705e-02 -6.93426531e-02 -3.20055481e-01
  1.32963953e-01  3.31911127e-01  1.74784473e-01  9.93219020e-01
 -2.21043831e+00 -2.23493343e-02  2.12935462e-04 -1.77391974e+00
  1.37743462e+00  1.91049246e-01  7.48516038e-02  5.06593614e-01
 -1.12424003e-01 -7.77346256e-02 -2.68401813e-02 -2.08457357e-01
 -4.76704563e-02 -9.85972497e-02 -2.70766049e-02 -2.87451949e-01
  8.37749942e+00  1.07361389e-01  4.27674837e-02  2.80160055e-01
  6.65642134e-01  2.69656906e-01 -1.38170526e-01 -3.71527635e+00
 -4.25726351e-01 -4.95370595e-01  5.26774894e-01 -1.24566777e+01
  6.25726986e+00]
supnorm grad right now is: 12.4566776522404
Weights right now are: 
[  4.7911102   -5.88672881  -1.04992587   0.2267287   -5.58132944
   5.90119244   1.62123191   1.18835434  10.30163288  14.23658781
   1.41699829  12.02566094  17.30493247  -7.0450091   15.19320734
   2.63670866  22.22628453  -4.52614579   3.62635606  -2.88169578
  19.44553094  -1.8741344   10.95547383   5.51995539  -3.75645921
   5.41350494  -2.30332679  17.62947486   1.79636301  -5.73507536
  -8.05515671   9.06221535 -10.30008861   1.45884125   3.61714053
  -0.09897952   6.34451341  -5.29090077  -3.2127303   -4.8957081
  -2.61439787   4.65118501  11.48229034   4.43438491   6.70126917
  -2.50533992  -8.68684398   0.40415139  14.6346174   -0.98613566
  -8.52561776   0.08433336   2.60805069 -24.74717795 -20.79966992
 -28.54334274   6.71338476   2.26423856  -0.27600314  -2.51087547
   1.36285293  -2.91146157  -1.92874818  -2.10627001  26.64943836]
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2400.7047980772873
gradient value of function right now is: [ 2.32612901e-01 -8.62640677e-03 -2.17824205e-02 -2.14047027e-04
 -2.32612901e-01  8.62640677e-03  2.17824205e-02  2.14047027e-04
  7.14374597e-03  2.28543498e-03 -2.26523414e+00 -2.53178313e-01
 -9.63372905e-08 -1.74744059e-02 -1.48379898e-02 -1.00200322e-01
 -3.15689958e-04 -1.48473619e-03  8.72503906e-01  5.55571233e-01
 -2.88665089e-07 -3.77615745e-05 -1.68801046e-05 -3.29767519e-04
 -1.55183225e-01  2.24519041e-04  6.31337904e-05 -9.01587375e-02
 -3.27737590e-02 -7.67339376e-02 -3.42225051e-02 -1.20109084e-01
 -5.04967607e-02  1.63736734e-01  4.17387543e-02  1.70914665e-01
  2.01376404e+00  9.95521820e-02  1.97108498e-02  2.27506868e+00
 -2.26315971e+00 -1.57871089e-01 -1.31429088e-01 -2.28742544e-01
  7.47154413e-02 -5.53607153e-02 -4.69845537e-02 -6.88272625e-02
 -5.34990996e-02 -7.30573391e-02 -5.97905099e-02 -9.88810606e-02
  1.27401403e+00  4.45275054e-02  3.16128709e-02  7.98389269e-02
 -1.88503601e+00  7.00138616e+00  6.67688859e-01 -2.74262258e+00
  3.52930940e-01 -2.62703705e+00  1.43561856e+00 -5.08383122e+00
 -1.85865688e+00]
supnorm grad right now is: 7.0013861629446845
Weights right now are: 
[ 4.92767580e+00 -6.44007247e+00 -9.27897739e-01  2.13313366e-02
 -5.71789504e+00  6.45453611e+00  1.49920378e+00  1.39375171e+00
  1.04132480e+01  1.38050080e+01  1.27016737e+00  1.09795918e+01
  1.73154329e+01 -8.12268129e+00  1.43584688e+01  2.20001979e+00
  2.40834178e+01 -4.87463744e+00  4.45877729e+00 -2.33755314e+00
  1.94884850e+01 -2.40847649e+00  1.09434374e+01  5.52079494e+00
 -3.47122181e+00  5.74696517e+00 -2.24904855e+00  1.83432224e+01
  2.40259930e+00 -6.51970718e+00 -9.27373297e+00  8.51659276e+00
 -1.15481584e+01  1.92474228e+00  3.66184444e+00  1.31734954e-01
  7.45993819e+00 -4.67734019e+00 -3.51569503e+00 -3.84842940e+00
 -3.31566521e+00  5.13908647e+00  1.24670086e+01  3.82627176e+00
  7.62409959e+00 -3.20059643e+00 -9.37311223e+00  1.95156354e-02
  1.51624314e+01 -1.77536022e+00 -9.16195168e+00 -4.72148010e-01
  2.34194030e+00 -2.58274618e+01 -2.26706543e+01 -2.92713152e+01
  6.91262010e+00  2.27849552e+00 -3.23652971e-01 -2.28224079e+00
  1.60122271e-01 -2.34178589e+00 -1.08049919e+00 -2.15094081e+00
  2.67583229e+01]
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2400.0788232294644
gradient value of function right now is: [-8.05287275e-01 -8.35357226e-03  3.67463701e-01  6.63256575e-06
  8.05287275e-01  8.35357226e-03 -3.67463701e-01 -6.63256576e-06
  3.12021103e-02  1.73250406e-02  7.20739509e+00  2.25187615e-01
 -1.77654172e-07 -6.43561331e-02 -2.83167973e-02 -8.82530226e-02
 -1.66630950e-03  2.60331231e-02 -6.04408004e-01 -8.85159503e-02
 -2.63865857e-07 -4.37490086e-06 -2.76020268e-05  3.90244809e-05
 -3.70630869e-01 -2.80207072e-03  1.90779312e-05 -2.04018337e-01
 -2.13411807e-01 -1.00198408e-01 -7.92503032e-02 -2.53614355e-01
  4.18366468e-02  1.45991937e-01  1.68985065e-01  1.95588750e-01
 -2.23041988e+00 -4.12340420e-02 -8.25205013e-05 -1.75602668e+00
  1.62487830e+00  1.20062327e-01  1.02418179e-01  1.71778407e-01
 -1.38315337e-01 -3.89118932e-02 -2.85782455e-02 -6.88219312e-02
 -6.22508312e-02 -8.23381256e-02 -6.58855613e-02 -1.29842206e-01
  1.80011077e-01 -1.67736715e-02 -1.66752423e-02 -1.78177289e-02
  1.03717222e+00 -2.35826772e+00 -4.83463350e-01  1.62657573e+00
 -1.15765853e+00  3.24107882e+00 -3.87652764e-01  1.34310400e+00
  1.74021456e+00]
supnorm grad right now is: 7.207395092399099
Weights right now are: 
[ 4.65961912e+00 -6.67114611e+00 -2.05429804e-01  3.26520727e-01
 -5.44983836e+00  6.68560975e+00  7.76735849e-01  1.08856232e+00
  1.05490545e+01  1.39249971e+01  1.61271595e+00  1.15473835e+01
  1.73247623e+01 -8.76913489e+00  1.50326551e+01  2.14922049e+00
  2.54244701e+01 -4.48267673e+00  3.09992334e+00 -3.15740018e+00
  1.95083461e+01 -2.59648867e+00  1.16610962e+01  5.90423693e+00
 -3.49176300e+00  4.91932031e+00 -3.50883852e+00  1.85879062e+01
  2.43450750e+00 -6.89745198e+00 -9.49608782e+00  8.38931027e+00
 -1.20575307e+01  1.57910915e+00  3.35306872e+00 -1.32473165e-01
  6.87937232e+00 -6.77300050e+00 -5.58621237e+00 -4.59287287e+00
 -3.07753075e+00  4.91103419e+00  1.22930497e+01  3.62876620e+00
  6.95028383e+00 -3.51767668e+00 -9.81685217e+00 -1.57644177e-01
  1.47500598e+01 -2.21406321e+00 -9.77559358e+00 -7.49886800e-01
  2.27262847e+00 -2.67540989e+01 -2.44039260e+01 -2.97659172e+01
  7.33584068e+00  2.04360684e+00 -6.48126743e-03 -2.20961966e+00
  4.20016212e-01 -2.19581913e+00 -9.31769250e-01 -2.23220416e+00
  2.63869501e+01]
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2399.8496276820106
gradient value of function right now is: [-7.52977370e-01 -2.39630568e-03 -2.94140012e+00 -3.94298774e-05
  7.52977370e-01  2.39630568e-03  2.94140012e+00  3.94298774e-05
 -1.70402591e-01 -1.86372852e-03  6.51203418e+00  1.38268060e-01
  5.18993953e-08 -7.82978421e-03 -3.45424389e-03 -2.44826822e-02
  3.81370578e-04 -6.90767374e-03 -5.27917155e+00 -4.28791183e+00
  3.53625598e-09 -2.98984114e-07 -1.29753202e-06 -1.47202811e-06
  1.39506643e+00  4.74127515e-04  3.11779232e-06  3.35472333e-01
  1.91782910e-02 -3.76684661e-02 -3.87470307e-02 -7.11224384e-02
  1.23135956e-01  2.43792314e-01  1.83985886e-01  8.18670811e-01
 -2.05075532e+00 -8.77305052e-02 -1.97348162e-02 -2.29396738e+00
  1.85526252e+00  2.40721641e-01  7.28748080e-02  8.31355688e-01
 -1.62518492e-01 -5.60207962e-02 -1.99998185e-02 -1.97016158e-01
 -4.90005342e-02 -6.37657374e-02 -2.53483767e-02 -2.25095606e-01
 -6.29299820e+00 -6.73058929e-02 -6.88034137e-03 -1.88439568e-01
  1.78822283e+00 -4.67172522e+00 -8.79436589e-01  4.63360596e+00
 -5.48531883e-01  1.14792831e+00 -1.93739000e+00  1.24491936e+01
  9.46334344e+00]
supnorm grad right now is: 12.449193603385432
Weights right now are: 
[  4.70567316  -5.44958247  -1.66193831   0.67904371  -5.49589239
   5.4640461    2.23324436   0.73603934  11.04298992  13.7016343
   1.63694585  11.83633832  17.35396229  -7.93552832  15.67823438
   3.32821653  26.15435639  -4.59960161   3.49868096  -3.42203585
  19.53190667  -1.16668472  12.74871398   6.66193109  -3.32435994
   5.57782631  -3.96060271  19.4159043    3.28124115  -5.50929176
  -8.68558334   9.88196858 -12.46452431   0.88411146   2.94763863
  -0.47645639   7.06736121  -6.67674348  -6.07811403  -4.1923114
  -3.16159669   4.81111024  12.45784766   3.33597531   8.39220491
  -2.12193732  -8.68106103   1.15182254  16.58883082  -1.10214401
  -8.92032216   0.17808737   2.06864736 -27.96529802 -24.91309048
 -30.88898792   6.68326181   2.22278455   0.71875597  -2.30638813
   1.49258023  -3.45806595  -1.58133568  -1.93475431  26.57795861]
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -2397.42030354847
gradient value of function right now is: [ 4.67450998e-01  1.96230005e-03 -3.01785847e-01  9.68601031e-06
 -4.67450998e-01 -1.96230005e-03  3.01785847e-01 -9.68601031e-06
  2.78220435e-01  6.68551670e-03 -4.49956213e+00 -4.25793100e-01
 -5.20516966e-08  3.29282312e-03 -1.27863483e-04  1.27496565e-03
 -1.82955343e-03  4.68380276e-04  1.34838872e-01 -6.62883579e-01
  5.30871547e-08 -4.35246941e-07 -5.00961788e-06 -1.39972959e-06
 -2.64008600e+00  7.11754777e-04  3.93468006e-05 -8.23453383e-01
 -9.55095782e-02 -2.86246611e-03 -2.18761492e-03 -2.76432769e-02
  7.78057771e-03  3.83936291e-02  8.72679220e-03  2.05245729e-01
  4.40956308e+00  5.48076288e-02  1.61149222e-03  3.97827529e+00
 -3.26528405e+00 -9.63263122e-02  1.42607220e-03 -2.16180557e-01
  1.43092359e-01 -8.69916444e-03 -7.32474290e-03 -3.89195038e-03
 -5.97801570e-04 -1.69410738e-02 -1.27348395e-02 -1.81021798e-02
  1.27304938e+01  2.90180560e-01  3.79076114e-02  4.72729664e-01
 -3.70232227e+00  1.14725803e+01  2.03960675e+00 -1.35450178e+01
  1.81723930e-01 -1.72912816e+00  4.63453169e+00 -2.35287386e+01
 -1.89535122e+00]
supnorm grad right now is: 23.52873855427074
Weights right now are: 
[  5.34684847  -5.05521351  -1.31639749   1.00719696  -6.13706771
   5.06967714   1.88770354   0.40788609  11.91980562  14.59634884
   1.15750727  13.15608047  17.35478865  -7.66702015  16.09763639
   3.89619391  26.98438933  -5.02422318   3.51911728  -3.52686148
  19.53149009  -1.04227658  12.99261795   6.83753227  -3.90220673
   2.93017731  -6.36002182  19.18938075   2.75076221  -5.12803675
  -8.18260117  10.31967234 -12.25328748   0.35852129   2.54790506
  -0.88097143   6.76004572  -6.91929611  -7.3760937   -4.13029299
  -3.18170873   4.27138626  12.25033251   2.79433705   8.91784084
  -1.28153142  -8.11734503   1.99843187  16.94658331  -0.58120708
  -8.65579339   0.69425019   2.37845306 -29.00213379 -25.91645342
 -31.29237927   6.43493639   2.54965352   1.2372992   -2.19476018
   2.04413687  -3.44053408  -0.94347439  -2.25688878  27.42729739]
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -2388.5329402243883
gradient value of function right now is: [ 3.82290293e-01 -4.70135564e-04 -5.24608514e+00 -1.02190459e-05
 -3.82290293e-01  4.70135564e-04  5.24608514e+00  1.02190459e-05
 -6.42699000e-01 -3.94392811e-02 -3.87327100e+00  3.76379619e-01
  1.31418406e-07 -2.24893964e-03 -9.05375575e-04 -5.25852170e-03
  1.18404992e-02 -1.06207119e-02 -1.80459536e+01 -1.53950913e+01
 -1.46112487e-07  9.11454041e-07  2.81002207e-06  6.29439774e-06
  5.80659795e+00  8.95908693e-03  4.49660615e-05  1.88129073e+00
  5.12525730e-01 -3.23196933e-02 -4.57678286e-02  7.80558295e-02
  2.70528282e-01  4.56499594e-01  5.16706196e-01  1.97017210e+00
 -6.52153945e+00 -3.27448667e-01 -5.35541487e-02 -8.51705439e+00
  8.25010777e+00  7.29778493e-01  2.45968554e-01  2.15549215e+00
 -6.85473661e-01 -8.88461147e-02 -3.01457588e-02 -3.11321712e-01
 -1.10620509e-01 -1.38667155e-01 -5.20679176e-02 -4.71657706e-01
 -2.62882387e+01 -3.32465630e-01 -6.61797878e-02 -9.67245079e-01
  9.67880798e+00 -3.82278712e+01 -3.38796436e+00  2.16690789e+01
 -1.68321232e+00  6.47318480e+00 -1.02556464e+01  6.28317327e+01
  3.65279352e+01]
supnorm grad right now is: 62.831732696192326
Weights right now are: 
[  5.3689459   -5.15441684  -2.57102682   1.05937314  -6.15916514
   5.16888048   3.14233286   0.35570991  12.08013419  14.99495056
   1.17254093  13.44341841  17.35561355  -7.6528727   16.33181312
   4.22453922  27.05007512  -7.94115727   3.86293712  -3.28863907
  19.53036089  -0.58544282  13.34234561   6.9260314   -3.73387405
   1.75042043  -7.89352257  19.55043872   2.58196877  -5.07257801
  -8.12986048  10.32213614 -12.62438666   0.26692644   2.73369732
  -0.90705868   6.58988269  -7.9822932   -7.71474874  -4.44589666
  -2.64556712   4.76410594  13.15657341   2.68324402   8.17073468
  -0.7753582   -7.58374782   2.49665499  17.74268389  -0.21592004
  -8.097738     0.66727286   2.27875059 -29.32946376 -26.5886877
 -32.05464272   7.00475792   1.93207934   0.6854743   -2.25594046
   1.76840084  -3.01045664  -1.48456924  -1.98031173  26.65363529]
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2402.273371233821
gradient value of function right now is: [ 3.84963904e-01  2.65808798e-03 -3.42292548e+00 -2.85020750e-06
 -3.84963904e-01 -2.65808798e-03  3.42292548e+00  2.85020750e-06
 -4.61511264e-01 -1.65297406e-02 -4.07753767e+00  1.31583655e-01
  1.48706224e-07  1.37791590e-02  3.02082978e-03  1.19317984e-02
  2.56734715e-03 -2.82715945e-02 -8.07878394e+00 -8.06343196e+00
 -7.61998778e-08  1.01697427e-07  6.87389899e-07  1.93466476e-06
  4.43591592e+00  3.09348018e-02  3.26059359e-04  1.45375329e+00
  1.97500799e-01 -6.49706343e-02 -1.15341877e-01 -1.35940421e-01
  1.68525375e-01  5.94544333e-01  9.33492577e-01  2.06525320e+00
 -1.70292529e+00 -2.60517800e-01 -3.83511560e-02 -2.35829834e+00
  2.63508771e+00  3.92578348e-01  1.56590132e-01  8.03658972e-01
 -4.89326800e-01 -9.86273148e-02 -4.00424775e-02 -1.84863600e-01
 -5.03610554e-02 -3.41582702e-01 -1.12722717e-01 -7.51068420e-01
 -1.64290180e+01 -2.79933995e-01 -1.15726883e-01 -3.72356890e-01
  7.24259969e+00 -3.10671213e+01 -2.95234046e+00  1.85002061e+01
 -2.72630194e+00  9.12043055e+00 -4.03712963e+00  2.54022636e+01
  1.22643751e+01]
supnorm grad right now is: 31.06712128898612
Weights right now are: 
[  5.5794519   -5.8586602   -1.85639008   1.01291939  -6.36967113
   5.87312384   2.42769613   0.40216366  12.38162719  14.85318677
   1.09371408  14.02483547  17.3509905   -8.32674694  16.0789871
   3.87999539  28.36004437  -7.67888913   4.26804701  -3.08660193
  19.52818936  -0.21623137  13.33629794   7.26948895  -3.96767815
   1.26990915  -8.13862603  19.61371096   2.93865382  -5.33281138
  -8.28356176  10.48277957 -12.72959486  -0.22388881   2.49031071
  -1.09096364   6.73431898  -8.13821992  -6.74062798  -4.24902161
  -3.19666508   4.96581703  13.08903869   2.88354086   7.35432655
  -0.50394838  -7.32966975   2.86439053  18.22869572   0.17148181
  -7.54501189   0.87301485   2.39815123 -30.23171573 -28.87617886
 -32.45131517   7.57092879   1.79188479   0.25578283  -2.08712894
   1.4680297   -2.39073357  -1.39602483  -2.1669258   26.47703344]
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2397.4467957957745
gradient value of function right now is: [-4.43520077e-01  3.17783787e-05  4.51296315e-02 -7.50410186e-06
  4.43520077e-01 -3.17783787e-05 -4.51296315e-02  7.50410186e-06
 -1.83462886e-01 -5.37896242e-03  3.91684792e+00  1.50133975e-01
  3.27393012e-07  1.41256543e-03 -7.36792006e-04 -1.14547326e-03
  1.16098685e-03 -2.51614064e-04  1.07960027e+00  1.07862266e+00
 -3.39590503e-08 -1.67971838e-09  3.00054698e-06  2.93472895e-06
  1.70994279e+00  6.89841456e-04  5.59359294e-07  4.70451086e-01
  7.68374910e-02  8.23132575e-03  4.63149130e-03  2.82273952e-02
 -8.95401685e-02 -3.28286355e-03  6.07140822e-02 -1.57056816e-01
 -1.67587951e+00  8.83094422e-03  5.45232669e-03 -1.34130044e+00
  9.17746013e-01 -6.30928060e-02 -5.13984779e-02 -1.17792906e-01
  4.42010209e-03  8.07319118e-03  1.43226083e-02  3.21847394e-03
  4.79839524e-03 -2.92767315e-02  4.07910689e-03 -7.98445516e-02
 -7.94833564e+00 -9.08588381e-02 -3.74484069e-02 -1.67987784e-01
  3.34109510e-01 -2.26669006e+00 -5.34709403e-01  5.39448634e+00
 -2.26475967e-01  1.96659455e+00 -1.08593859e+00  1.07475059e+01
 -3.11604905e+00]
supnorm grad right now is: 10.74750587737585
Weights right now are: 
[  4.62446066  -6.45634185  -1.42288342   1.09043496  -5.4146799
   6.47080549   1.99418947   0.32464809  11.54596484  14.9285088
   1.91587325  13.68488053  17.33987064 -10.2166598   15.0566631
   3.59107473  28.17246562  -6.74838609   4.843942    -2.65930337
  19.52968008   0.08719903  14.17880921   8.21583564  -3.1179443
   0.90145347  -8.67151313  20.30121242   3.43294982  -5.89681506
  -8.4268762   10.46640144 -12.56483004   1.1419912    3.30041221
   0.04817033   7.19740992  -7.40274925  -6.79310439  -3.8707697
  -3.15960396   5.34294055  13.57213697   3.22578741   8.24571149
  -0.45839351  -8.30828033   3.56100233  17.62406383  -0.0508609
  -8.61478956   0.89623535   1.8831253  -30.46238701 -29.32061843
 -32.80650177   7.04924035   2.21004561  -0.13112129  -2.12664684
   1.97762449  -2.3833312   -1.96243601  -2.00468105  26.2963429 ]
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2400.250076832108
gradient value of function right now is: [-3.48483813e-01 -1.54548827e-03 -1.52227321e+00 -3.71298932e-05
  3.48483813e-01  1.54548827e-03  1.52227321e+00  3.71298932e-05
 -2.31257470e-01 -2.94428055e-03  3.40350342e+00  2.96092293e-01
  9.66080322e-08  1.82195228e-03 -2.24497355e-03 -1.99377137e-02
  3.54496747e-04 -9.85278518e-04  6.23023407e-02 -8.86915403e-02
 -2.11911394e-08 -2.85433797e-07  4.86128238e-06  3.95697696e-05
  2.25123795e+00  1.70126606e-03  9.10290284e-06  6.09233143e-01
  4.11214718e-02  1.04774459e-02  8.05402157e-03  1.93117631e-02
  2.50484298e-02  7.32453097e-02  3.56522840e-01  5.45067861e-02
 -3.67697291e+00 -2.22153813e-02 -2.20678543e-03 -2.96830472e+00
  1.25146981e+00  1.33189292e-02 -7.33650448e-02  2.99269866e-01
 -3.19898228e-02  1.18984763e-03  3.44064914e-02 -7.20131589e-02
 -1.09978781e-02 -1.70735134e-01  1.15107734e-02 -4.80093014e-01
 -1.08862138e+01 -2.08940960e-01 -1.16748647e-02 -3.43136391e-01
  2.32365695e+00 -9.63858393e+00 -1.94891597e+00  1.25619032e+01
 -8.64421108e-02  4.07373068e-01 -3.59316946e+00  2.17796381e+01
  5.68094469e+00]
supnorm grad right now is: 21.77963808720051
Weights right now are: 
[  5.27762809  -5.43269027  -1.04546724   1.23906178  -6.06784732
   5.4471539    1.61677328   0.17602127  11.99432278  14.71054984
   1.44690739  14.60779366  17.34593018  -9.98152795  15.56279619
   4.79350863  28.96543745  -6.65566077   4.92011326  -2.64410728
  19.53009276   0.38997002  14.61231391   9.20789781  -3.48590496
   1.3528388   -8.6074658   20.23679241   3.62617038  -5.96731003
  -8.043391    11.04637881 -12.26810646   2.24400707   4.62958828
  -0.2254077    6.39546555  -7.72467168  -8.51563759  -4.65085569
  -3.86467343   4.32540412  11.32866169   3.42080789   8.58225013
  -0.57723118  -9.32123162   3.60809325  17.3471264   -0.36165557
  -9.06071486   0.23424849   2.27585734 -31.1606956  -30.3213159
 -33.14800836   7.25194869   2.1263889   -0.50664967  -2.19342568
   2.28780294  -3.49384234  -2.46325571  -2.2094755   26.74230203]
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2399.544257483381
gradient value of function right now is: [-6.49231081e-01 -1.81378705e-03  1.64292204e+00  8.08260233e-07
  6.49231081e-01  1.81378705e-03 -1.64292204e+00 -8.08260233e-07
  2.06497436e-01  8.38078542e-03  6.46649282e+00  1.52270573e-01
 -2.63522789e-07 -9.37002780e-03  1.19057281e-03 -1.55313512e-02
 -1.20125824e-03  1.97536473e-03  8.41037395e-01  1.20644500e+00
  1.21023780e-08 -1.18361158e-08  4.94309114e-07 -9.14714538e-07
 -2.07886860e+00 -1.61535701e-03  8.21336156e-07 -6.56591534e-01
 -1.18916282e-01 -1.99516811e-02 -4.83426294e-02 -1.02533005e-01
 -7.81277954e-02 -1.08078014e-01 -4.41936419e-02 -5.50816167e-01
 -1.89388182e+00  1.03071557e-02  1.68790179e-03 -1.19902003e+00
  4.60552839e-01 -4.91167804e-02 -2.47798930e-02 -1.55669651e-01
  4.95568602e-02 -7.25712463e-03  8.25863825e-03 -3.74433334e-02
  1.92685787e-02 -2.79886200e-02 -5.19744313e-03 -6.26690922e-02
  7.33920257e+00  1.21569506e-01  3.32433508e-02  1.33682578e-01
 -7.90643249e-01  2.26085272e+00  8.12838629e-01 -7.28546150e+00
  6.81069698e-02 -1.98616653e+00  1.51446153e+00 -9.03329151e+00
 -3.56627788e-01]
supnorm grad right now is: 9.033291513406917
Weights right now are: 
[  5.05154191  -6.49876358  -0.5676405    0.88335608  -5.84176115
   6.51322721   1.13894655   0.53172697  12.1756371   15.36342929
   1.7234845   14.78058352  17.32991207 -11.66870901  15.41607018
   4.03184675  28.47346638  -6.98021926   4.22099665  -3.00151498
  19.53025832   0.67118593  14.62862094   9.84105847  -3.54492716
  -1.30601736  -9.2718621   20.23281068   3.42335435  -8.13926193
  -9.29253829   9.77673069 -11.76946479   2.02082893   3.936466
   0.03546721   6.67913313  -7.05320518  -7.20519098  -4.74922565
  -2.87854095   5.3949322   13.07080413   4.28538617   7.43220387
  -2.03030954 -11.75537676   2.66429563  16.57395982  -0.86784737
 -11.0610368    0.22247891   2.48959399 -31.63592032 -31.46129292
 -33.34259759   6.8673373    2.75797432  -0.18146895  -2.22513042
   1.146505    -2.79886747  -2.39444851  -2.4161868   26.85403705]
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2400.9518836589027
gradient value of function right now is: [ 4.47759077e-01 -3.64194259e-04  3.42097570e+00  3.20668958e-06
 -4.47759077e-01  3.64194258e-04 -3.42097570e+00 -3.20668958e-06
 -2.48764668e-01 -5.92702751e-03 -4.74850818e+00 -1.18535956e-01
  9.34881962e-08 -7.52782953e-03  2.80300829e-03  4.12610714e-03
  4.72999209e-04  4.58689180e-03  1.51939153e+00  1.68779151e+00
 -1.05934151e-08 -1.22278807e-07 -7.54213031e-07 -1.63405415e-06
  2.33187154e+00  2.13912895e-03  1.42658617e-07  5.78234385e-01
  8.47270496e-02 -1.38767589e-02 -1.86032031e-02  4.98461671e-03
 -8.65104276e-02 -1.62948851e-01 -6.97528557e-02 -7.95843009e-01
  1.59960099e+00  1.95967343e-02  1.66906580e-03  1.45158648e+00
 -1.03803086e+00 -1.66292542e-01 -7.43733742e-02 -3.99155183e-01
  1.30654198e-01  1.98915794e-02  1.57802127e-02  5.81153809e-02
  9.23064707e-03 -1.89936802e-02 -1.45918689e-02  3.38408795e-02
 -8.11698526e+00 -8.90002703e-02 -1.58984677e-02 -7.87406171e-02
 -1.01606437e+00  2.28258438e+00 -1.18929648e-01  5.40202977e+00
  2.11105985e-02  4.46018776e-01  6.21227648e-01  4.57134813e+00
 -7.46481256e+00]
supnorm grad right now is: 8.11698525566449
Weights right now are: 
[  5.53977091  -6.58234937  -0.41366463   1.02918651  -6.32999015
   6.59681301   0.98497067   0.38589653  11.89987325  14.84335356
   1.27156382  14.83244908  17.32349818 -12.36450733  15.70909893
   4.14087046  28.72679684  -7.06477293   4.08837178  -3.16913854
  19.52987646   0.69968636  14.6219851    9.94090206  -3.0485067
  -0.42896605  -8.95945422  20.94397129   3.95187508  -8.76742675
  -9.8013527    9.43561266 -11.41437011   1.87562176   3.86142961
  -0.28299814   7.06549661  -8.31914674  -8.3607091   -4.56108326
  -3.1230279    5.05916042  13.03194373   4.11746781   7.20256415
  -2.32969829 -12.53108874   2.30115003  17.13550504  -0.94614964
 -11.50348111   0.06016266   2.21346173 -32.35761271 -32.84481949
 -33.70978826   6.73793375   2.65262172   0.08498293  -2.14152163
   1.06107396  -2.87045191  -2.85709067  -2.30112117  26.39910878]
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2392.1322718535907
gradient value of function right now is: [-4.58685759e-01  1.13423071e-03 -1.23611109e+00  4.59706337e-07
  4.58685759e-01 -1.13423071e-03  1.23611109e+00 -4.59706337e-07
  2.17083363e-01  4.40374533e-03  4.49985426e+00  9.23081939e-02
 -2.70174447e-07 -1.39684675e-03  3.92249544e-03  1.92848500e-02
 -3.54571111e-03  1.28391769e-03 -1.59057819e+00 -8.31657075e-01
  3.07579405e-08 -1.36751765e-07  8.96952185e-07 -1.61217318e-06
 -2.04039110e+00 -2.60140655e-03 -1.49823227e-07 -5.68142495e-01
 -5.96646186e-02 -8.64213051e-03  9.28973248e-03 -8.52894912e-03
  9.15159590e-03 -1.85472357e-02 -3.38336195e-02 -5.28028608e-02
 -1.65140242e+00 -6.02847000e-03 -5.47069855e-06 -1.61531153e+00
  1.36466894e+00  6.57462693e-02  3.47700891e-02  3.38073457e-01
 -4.32518009e-02  8.34332126e-03  5.41254092e-04  7.86264746e-02
  1.97879902e-02  2.63924056e-02  1.67732026e-02  1.17742250e-01
  7.53842398e+00  6.38589577e-02  2.72273915e-02  2.26013321e-01
 -6.36381054e-02 -4.91375156e-02  2.19613801e-01 -3.10683897e+00
  1.87734742e-01 -1.20590242e+00  1.16637003e+00 -1.18588128e+01
  6.62789618e+00]
supnorm grad right now is: 11.858812750910083
Weights right now are: 
[  4.85786866  -6.67498509  -0.42322603   1.14333318  -5.64808789
   6.68944873   0.99453207   0.27174987  12.4952912   14.78340334
   1.94517099  14.85932972  17.32462749 -12.85406317  15.41627568
   4.06178902  29.07442229  -6.22061391   2.72427477  -4.17236562
  19.52979798   0.72393652  14.60796682   9.96696219  -3.41212779
  -0.93087322  -9.29363992  20.83957587   4.43478151  -9.9231402
  -9.37769876   9.13033575 -11.30637545   2.62538016   3.36927994
  -0.62598781   7.09926633  -8.15348985  -9.54640167  -4.91993823
  -2.64122517   5.32317695  13.29517086   5.14844041   6.88452612
  -3.11139287 -14.10661049   2.30829657  16.90540008  -1.11485948
 -12.32102111   0.4387411    2.73267915 -32.22382457 -33.60921855
 -33.48245061   5.9631942    3.19760608   0.66830486  -2.76050224
   1.30535249  -3.22349612  -3.66701252  -2.43851065  26.89691125]
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2398.9197343243713
gradient value of function right now is: [ 2.26702201e-01 -1.05987421e-02 -5.24801039e+00 -4.72384832e-06
 -2.26702201e-01  1.05987421e-02  5.24801039e+00  4.72384832e-06
 -3.04552319e-01 -2.94266307e-03 -2.44840147e+00  6.94903117e-02
  1.38949677e-07 -2.10180615e-02 -1.16449401e-02 -1.34260166e-01
  1.49648990e-03 -2.06555997e-03 -3.19252560e+00 -2.80647171e+00
 -1.61706453e-08  3.16081104e-07  3.58392980e-07  3.66190401e-06
  2.87975284e+00  4.30606544e-03  3.79201981e-07  6.93028075e-01
  3.71930749e-02 -6.91754446e-02 -1.06170630e-01 -2.23048350e-01
  9.76907038e-02  1.27805828e-01  9.74002611e-02  9.13100350e-01
 -1.47314067e+00 -3.90634822e-02 -1.11429974e-03 -2.41524102e+00
  3.18753810e+00  1.77260440e-01  7.46306172e-02  1.05138299e+00
 -2.59601844e-01 -8.23224052e-02 -4.57441152e-02 -5.61351572e-01
 -6.28455805e-02 -7.48650321e-02 -4.20793774e-02 -5.88000141e-01
 -1.10270861e+01 -7.80711668e-02 -1.43081190e-02 -3.18802356e-01
  3.11348523e+00 -9.52131955e+00 -1.34395456e+00  7.27887536e+00
 -1.18740734e+00  3.18465020e+00 -5.27448487e+00  2.78870409e+01
  1.20378052e+01]
supnorm grad right now is: 27.887040920845347
Weights right now are: 
[  5.53251548  -6.75761464  -0.98522629   1.08803565  -6.32273472
   6.77207828   1.55653233   0.32704739  12.29421302  14.17846253
   1.36651604  14.36568547  17.32671303 -12.83023121  15.55979155
   4.00258459  30.16204585  -7.40025564   3.44078728  -4.01432505
  19.52924058   0.77822078  14.58132447  10.13430311  -3.07430111
  -0.66020783  -9.26311059  21.37931434   5.07858717  -9.79845399
  -9.9451836    9.14203217 -11.49151002   2.56892445   3.99816665
  -0.05449291   7.58773755  -8.96625026 -10.06069329  -4.6720169
  -2.9233758    6.65915241  15.15789321   5.07590096   6.88292901
  -3.36354586 -14.34466037   2.15529671  17.05416592  -1.71562393
 -12.99084436   0.05029516   2.47248803 -33.43877621 -35.08294899
 -34.04725375   6.57596357   2.34245452   0.54012634  -2.252025
   0.58664308  -3.02645226  -4.07015887  -2.22635858  26.34455711]
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2391.7859541201506
gradient value of function right now is: [ 4.04291919e-01 -1.13931168e-03  3.59894017e-01  6.87137621e-07
 -4.04291919e-01  1.13931168e-03 -3.59894017e-01 -6.87137621e-07
  1.87337490e-01  6.21237663e-04 -4.13047566e+00 -2.13398290e-01
 -4.14288564e-08 -2.69048213e-03 -1.07496662e-03 -1.42748261e-02
 -9.44115111e-05 -3.14919636e-04  1.56514704e+00  1.05448400e+00
 -3.18768074e-11 -1.32209598e-10  4.01807725e-09 -1.63003497e-09
 -1.77694647e+00 -1.67817044e-03 -5.31639368e-08 -4.01004382e-01
 -8.12421494e-03 -1.92720040e-02 -4.64548935e-03 -2.99070122e-02
 -4.49924282e-02  1.87253041e-02 -1.03161329e-03  3.09724768e-02
  2.89777582e+00  2.01325405e-02  4.83030260e-04  2.90927777e+00
 -3.14691575e+00 -9.31790588e-02 -4.49872434e-02 -5.56235068e-01
  6.53852232e-02 -2.02637144e-02 -1.92366846e-02 -1.02313729e-02
 -3.61221034e-03 -7.06435659e-03 -6.55589899e-03 -1.66062010e-02
  8.57731517e+00  1.31716549e-01  5.03865779e-02  3.15588300e-01
 -1.98378314e+00  5.62799376e+00  1.10787835e+00 -7.82683508e+00
  5.56269987e-01 -3.81769647e+00  4.94096237e+00 -2.01459912e+01
 -9.20701022e+00]
supnorm grad right now is: 20.14599124959724
Weights right now are: 
[ 5.68103771e+00 -6.66689511e+00 -1.17611394e+00  7.08228765e-01
 -6.47125695e+00  6.68135875e+00  1.74741999e+00  7.06854283e-01
  1.26087428e+01  1.39018883e+01  1.37402435e+00  1.51595205e+01
  1.73261919e+01 -1.26034839e+01  1.60707330e+01  4.28767382e+00
  3.06284871e+01 -9.26186050e+00  4.59655853e+00 -3.33256794e+00
  1.95291256e+01  7.91887410e-01  1.46042514e+01  1.04013280e+01
 -3.25602434e+00 -9.83912691e-01 -9.22731571e+00  2.14613663e+01
  5.48685760e+00 -9.50740224e+00 -1.00764745e+01  9.42723559e+00
 -1.14040131e+01  2.95603747e+00  4.40831444e+00 -1.88759964e-03
  7.45987629e+00 -8.78714073e+00 -1.05998475e+01 -4.80983635e+00
 -3.09452721e+00  7.49710923e+00  1.62051597e+01  4.90625158e+00
  7.25917687e+00 -3.07600709e+00 -1.42804921e+01  2.30958302e+00
  1.76747419e+01 -1.52299159e+00 -1.30590344e+01  8.31550391e-02
  2.75905381e+00 -3.40947784e+01 -3.79198397e+01 -3.42447419e+01
  5.91785847e+00  2.91685948e+00  8.77825205e-01 -2.45438828e+00
  4.45579366e-01 -3.12312273e+00 -3.65827284e+00 -2.68481930e+00
  2.65258751e+01]
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2401.9304684848535
gradient value of function right now is: [-4.34561373e-02 -2.16794324e-03 -2.31676486e+00 -2.32844558e-06
  4.34561373e-02  2.16794324e-03  2.31676486e+00  2.32844558e-06
 -1.07601703e-01 -3.09330121e-04  3.92063700e-01  8.76209435e-02
  1.10111537e-08 -5.15105774e-03 -1.66560395e-03 -2.40073084e-02
  2.20822189e-04 -2.54178188e-03 -2.00375193e+00 -2.57859623e+00
 -5.70902351e-09  9.94309344e-08  3.92635456e-07  1.48886649e-06
  1.07286142e+00  7.69468633e-04  6.38179327e-08  2.70713487e-01
  3.71153955e-03 -2.76736677e-02 -2.62146342e-02 -6.71199886e-02
  1.08926527e-01  2.19215119e-01  8.86234400e-02  2.19261440e+00
 -1.23423474e+00 -1.80914142e-03 -1.11633333e-04 -1.35315482e+00
  2.00101625e+00  2.73515063e-01  9.57735117e-02  5.75151758e-01
 -1.91930144e-01 -1.05583157e-01 -6.53531579e-02 -3.69687311e-01
 -4.62179681e-02 -4.55368006e-02 -2.86692906e-02 -2.86543534e-01
 -5.28386582e+00 -2.13468076e-01 -2.35886123e-02 -3.98498430e-02
  6.49522639e-01 -1.02992639e+00 -1.10959776e+00  1.41750122e+01
 -1.04445657e+00  3.28004351e+00  6.15678172e-01  2.34071745e+00
  1.42126108e+01]
supnorm grad right now is: 14.21261078491965
Weights right now are: 
[  5.83412379  -5.92267743  -1.33570423   1.06775817  -6.62434303
   5.93714107   1.90701028   0.34732487  12.76837788  13.60020625
   1.30334031  15.64371842  17.32705385 -12.32329173  16.87721433
   5.05903861  31.38945956  -9.0557265    4.75530689  -3.11839627
  19.52916083   0.7780763   14.6226461   10.48280827  -3.25921445
  -0.63565867  -9.22751375  21.73528585   6.10394562  -9.77351996
  -9.45485764   9.75968252 -11.79803389   2.91812854   4.12663895
  -0.29427546   7.10085971  -8.46292963 -11.37388678  -5.18292875
  -2.91990604   7.4447567   15.98202384   4.86075668   7.45784307
  -3.15362595 -14.54632089   2.83627574  17.85788982  -1.19724329
 -12.80890623   0.70377604   2.63593057 -35.46391311 -39.49959087
 -34.73525161   5.85210974   2.75761285   1.27670793  -1.88505885
   0.90166213  -3.25227353  -3.77654425  -2.70519019  27.04312782]
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2396.221778233625
gradient value of function right now is: [-5.05943854e-01 -5.65486484e-03 -1.77066689e-01 -1.58515033e-06
  5.05943854e-01  5.65486484e-03  1.77066689e-01  1.58515033e-06
  2.34524762e-01  3.06568281e-03  5.31838196e+00  3.33508711e-02
 -5.74151237e-07 -1.60408623e-02 -1.32623753e-02 -7.78212285e-02
 -6.91503885e-04 -4.30306216e-03  4.27937513e-01  4.09221701e-01
  1.22064566e-08  1.42482269e-08  4.47296078e-07  9.70755109e-08
 -2.62856571e+00 -5.50412652e-03  6.58473526e-07 -7.40038186e-01
 -5.62718265e-02 -8.91010267e-02 -4.46449280e-02 -2.21368924e-01
 -5.62779798e-03  8.72776181e-02  4.34813890e-02  1.66865949e-01
 -4.28433317e-01  2.49271834e-03  6.51338118e-04 -2.18167486e-01
 -2.35323174e-01 -2.51106191e-02 -1.29844614e-02  5.27439851e-02
 -1.70155509e-01 -6.50442720e-02 -5.80473199e-02 -2.94298259e-01
 -8.05854587e-02 -3.44052446e-02 -3.01479536e-02 -2.35137567e-01
  1.05758081e+01  1.96807475e-01  6.62610244e-02  2.25376110e-01
  6.31672067e-01  1.04271972e+00  6.69170146e-01 -1.15796060e+01
 -2.43294777e-01 -3.72315721e+00  1.15819541e+00 -1.38188775e+01
  3.07935981e+00]
supnorm grad right now is: 13.81887750919698
Weights right now are: 
[  5.39399491  -7.47844411  -0.65440081   0.8739217   -6.18421415
   7.49290774   1.22570686   0.54116135  13.03202701  14.60352619
   1.79391754  15.66866774  17.32427273 -13.7133767   14.80025343
   3.36482047  31.46969344  -9.56383631   4.77594393  -3.13469741
  19.52917028   0.85092214  14.60912445  10.69928172  -3.46918607
  -3.76152239  -9.81253894  21.51709072   5.04687484 -10.87116181
 -11.28756679   8.23909493 -12.20268248   3.37538438   5.62243919
  -0.33943828   7.48406215 -11.47774434 -13.80590484  -4.48877442
  -3.8702939    5.63235785  14.6664775    4.55975468   6.68868699
  -4.01488682 -15.35461416   1.36563333  16.87043812  -2.80066754
 -14.30759259  -1.15221321   2.73052513 -35.50843103 -40.33459082
 -35.33786433   7.00851373   2.34369605   0.74889468  -2.25440143
  -0.24621668  -2.97727462  -4.08893144  -2.55151451  26.7414905 ]
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2398.8465718040393
gradient value of function right now is: [-3.46861418e-01 -2.37212461e-03 -1.36598284e+00 -1.57364139e-06
  3.46861418e-01  2.37212461e-03  1.36598284e+00  1.57364139e-06
  1.47776713e-01  3.03716828e-04  3.58386481e+00 -4.35248209e-02
 -8.67089341e-08 -5.56396594e-03 -1.99651657e-03 -2.90643060e-02
 -2.58309265e-03 -2.91864930e-04 -1.69680943e-01 -3.21834730e-01
  1.76313798e-08  3.36862266e-08  5.15912347e-07  4.41914318e-07
 -1.63814957e+00 -2.90072532e-03 -7.09364470e-08 -4.60329545e-01
 -4.63921987e-03 -2.39775172e-02 -1.87867633e-02 -6.06302065e-02
  2.06040088e-02  2.84985086e-02  1.14179458e-02  1.76795538e-01
  6.13146042e-01  5.28307568e-03  1.18540571e-05  7.39901370e-01
 -8.04706236e-01 -1.75786240e-02 -4.36991811e-03  5.85642284e-03
 -9.78135548e-03 -2.01675086e-02 -1.92374762e-02 -1.18149447e-01
 -2.81912360e-02 -1.47524765e-02 -1.46196382e-02 -1.08229051e-01
  7.37121825e+00  1.00054801e-01  3.38653509e-02  1.74619079e-01
 -1.55598750e-01  1.67973119e+00  4.61660454e-01 -6.65618781e+00
 -7.10400760e-02 -2.36863011e+00  1.79746100e+00 -1.25956809e+01
 -7.98870950e+00]
supnorm grad right now is: 12.595680898841744
Weights right now are: 
[ 5.39089478e+00 -6.75382740e+00 -8.04079357e-01  9.93697710e-01
 -6.18111402e+00  6.76829104e+00  1.37538540e+00  4.21385338e-01
  1.27681378e+01  1.41170933e+01  1.80563576e+00  1.53853782e+01
  1.73298334e+01 -1.33814289e+01  1.62852940e+01  4.30734338e+00
  3.25130094e+01 -8.35604006e+00  3.43394591e+00 -4.40879392e+00
  1.95289409e+01  8.48412359e-01  1.45953601e+01  1.06643057e+01
 -3.01403546e+00 -3.48472701e+00 -9.78407682e+00  2.21382802e+01
  7.34955203e+00 -1.05264466e+01 -1.06559403e+01  8.95778157e+00
 -1.10292838e+01  3.10028968e+00  5.30204703e+00 -1.89014963e-02
  7.74503991e+00 -1.32117767e+01 -1.48511464e+01 -4.59569372e+00
 -3.26984832e+00  6.86902346e+00  1.59202356e+01  5.38496745e+00
  6.64973683e+00 -4.20622367e+00 -1.54752853e+01  1.79224629e+00
  1.75435271e+01 -2.91274235e+00 -1.42645318e+01 -8.49754188e-01
  2.39737232e+00 -3.61049654e+01 -4.19862301e+01 -3.57609483e+01
  6.76206953e+00  2.60631735e+00  1.06280843e+00 -2.12464171e+00
  1.25226460e-01 -2.81703612e+00 -4.30469281e+00 -2.42255410e+00
  2.60416963e+01]
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2397.2407166384423
gradient value of function right now is: [-5.04195846e-02  9.79518333e-03  6.39740690e+00  4.05994240e-06
  5.04195846e-02 -9.79518333e-03 -6.39740690e+00 -4.05994240e-06
 -2.31842320e-02  2.91326727e-05  3.24800885e-01 -1.55678945e-01
 -3.56383698e-09  1.79108084e-02  1.38587031e-02  1.24374033e-01
 -9.29826939e-05  2.63644208e-03  1.16280780e+00  1.39132521e+00
  4.33063306e-10 -5.13741518e-08 -6.70845175e-08 -5.37531305e-07
  1.65780208e-01  1.99003571e-04 -4.18928866e-09 -7.09287202e-03
  7.41622777e-04  1.24078039e-01  3.62884275e-02  2.17360653e-01
 -5.84395773e-02 -2.37900749e-01 -8.10060402e-02 -1.04592516e+00
  1.86784322e+00  1.67012933e-02  2.56566369e-04  2.32262532e+00
 -2.37427961e+00 -1.56064044e-01 -1.28217948e-01 -6.61007500e-01
  5.01591375e-01  1.46136739e-01  1.44739895e-01  5.27764771e-01
  1.20779984e-01  5.09189861e-02  5.51130297e-02  3.61804580e-01
 -6.21212041e-02  7.01985822e-03  5.82022397e-03  3.60286158e-02
 -2.32741129e+00  4.88494548e+00  6.16381689e-01 -1.87189929e+00
  1.52767737e+00 -4.01755378e+00  1.51802780e+00 -5.04475038e+00
 -1.37318097e+01]
supnorm grad right now is: 13.731809652832279
Weights right now are: 
[  5.46462691  -6.31720536  -0.09373614   0.77575876  -6.25484615
   6.331669     0.66504218   0.63932429  12.88014291  14.12232046
   1.8367811   14.96618653  17.33141026 -12.75865646  16.33862141
   4.64714225  34.22056489  -8.96566406   4.51443948  -3.52407564
  19.52830979   0.8814043   14.56441431  10.91654669  -2.97758893
  -2.99282297  -9.77408094  22.42321206   8.1536527  -10.3623616
  -9.99990185   9.50675904 -11.87185455   3.19924175   5.07167953
  -0.71322338   8.16007255 -13.47026045 -15.80572807  -4.36270182
  -3.59122409   7.49751139  16.16218565   5.0256385    6.73817478
  -4.78320144 -15.9360082    2.05391429  16.85716051  -4.65537971
 -15.56672582  -0.41556658   2.40573851 -36.42547451 -43.44338031
 -36.27369129   6.49335166   3.01397263   0.95753421  -2.27343051
   0.22316891  -2.66109919  -4.30429155  -2.47025607  26.2644933 ]
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2401.687481479257
gradient value of function right now is: [ 3.26368228e-01 -1.08806379e-02 -2.15676891e+00  1.30510754e-06
 -3.26368228e-01  1.08806379e-02  2.15676891e+00 -1.30510754e-06
 -2.77913680e-01 -4.55415569e-05 -3.67060963e+00  5.78014687e-02
  6.18102462e-08 -3.57700027e-02 -7.17158850e-04 -1.07171555e-01
  7.75828401e-04  8.86892275e-05 -5.37916429e-01 -4.09438234e-01
  3.99372306e-10 -1.09815246e-09  6.85640220e-09  9.49234678e-09
  3.10646805e+00  6.75906098e-03  4.37488291e-07  8.36519072e-01
 -7.57316275e-04 -9.58748893e-02 -1.73578367e-01 -3.11903389e-01
  1.89625292e-02 -6.77950057e-03  2.88773875e-02  1.10682146e-01
 -7.93412187e-01 -8.62149098e-03 -2.14479720e-05 -1.19049011e+00
  2.16486491e+00  6.35471440e-02  6.81376034e-02  4.14424479e-01
 -1.38798332e-01 -2.83385019e-02 -4.60268609e-02 -6.07387384e-01
 -1.46828890e-01 -6.24532831e-02 -8.27048069e-02 -7.26975367e-01
 -1.37807489e+01 -1.15910682e-01 -1.04001283e-01 -3.40737380e-01
  2.33535959e+00 -4.54195091e+00 -1.34905793e+00  9.61894033e+00
 -2.83013078e+00  1.27228493e+01 -3.90168393e+00  2.71853090e+01
  1.11937600e+01]
supnorm grad right now is: 27.185308997202753
Weights right now are: 
[  5.78493495  -6.39119369  -0.08243894   0.69488922  -6.57515419
   6.40565733   0.65374499   0.72019383  13.42995644  14.25538654
   1.60158146  15.26424366  17.32970196 -12.78180523  16.52353254
   4.68687282  34.57989828  -9.00264424   3.60408207  -4.90282235
  19.52821963   0.88870814  14.59012266  11.08073173  -3.32682427
  -3.08461128  -9.74544805  22.38404139   9.53581382 -10.10623228
 -10.51131988   9.55103205  -9.87507639   3.22570413   5.36855169
  -0.1158814    8.20426331 -14.33582986 -16.42680748  -4.458546
  -3.15713051   9.52727771  18.75271285   5.3114822    6.32915436
  -5.23191572 -16.1583013    1.6965812   16.34388031  -5.73494968
 -16.33996539  -1.01342608   2.63690347 -36.7093249  -44.20669097
 -36.64877684   6.68974284   2.98527038   0.7169795   -2.31107954
   0.09569365  -2.37679322  -4.62228512  -2.40185206  26.60767741]
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2385.572611814917
gradient value of function right now is: [ 6.59029773e-02 -1.32062987e-02 -8.95425528e-01 -1.60021741e-06
 -6.59029773e-02  1.32062987e-02  8.95425528e-01  1.60021741e-06
  7.78371498e-02  4.04025874e-06 -6.71571085e-01 -4.70901502e-02
 -8.55213718e-08 -2.70736754e-02 -7.71360940e-03 -1.64868957e-01
 -1.56447555e-04 -6.60925337e-04  2.16134455e-01  3.49647812e-02
 -5.55005747e-09 -7.22136861e-08  1.16197319e-07 -7.70193351e-07
 -8.93199275e-01 -5.49911391e-03 -8.39004052e-08 -2.62993322e-01
 -7.10808939e-03 -1.56966617e-01 -5.90840888e-02 -2.96003117e-01
  1.48283952e-02  9.48938169e-02  1.95756566e-02  2.74137825e-01
  6.81893527e-01  2.22951219e-02  2.19095879e-04  7.12764717e-01
 -8.12677625e-01 -4.15075326e-03 -1.76140046e-03 -1.87752750e-02
 -1.30236578e-01 -7.80877071e-02 -9.02509813e-02 -3.58793298e-01
 -1.07372094e-01 -2.70602388e-02 -3.45358051e-02 -2.63497564e-01
  4.27290645e+00  6.83276532e-02  6.66389346e-02  1.46740182e-01
  2.67938808e-01  1.00435671e+00  2.91657659e-01 -3.41818352e+00
 -1.37473573e-01 -3.31153606e+00  1.85358315e+00 -8.49309633e+00
  7.94430383e+00]
supnorm grad right now is: 8.493096327560366
Weights right now are: 
[  5.39407292  -7.00440524  -0.56980386   0.50666456  -6.18429216
   7.01886888   1.1411099    0.90841849  14.23779246  14.46098758
   2.07470992  15.8747171   17.32523052 -13.30579113  15.7249246
   4.06925334  33.74324157  -9.91396368   4.73600406  -3.95026346
  19.52811072   0.89222023  14.59290134  11.15405297  -4.07600433
  -4.18867168  -9.73335025  21.64494553  10.18594253 -10.40178573
 -11.30435761   9.02800815 -10.80469092   4.37342655   5.96345295
   0.06812303   8.06576535 -15.17390708 -17.21232946  -4.52415338
  -3.40414081   8.93443059  18.2723994    5.36144858   5.66027263
  -6.11521304 -16.78362275   0.91953042  16.40614605  -6.15993887
 -16.48168282  -1.86887066   3.32339631 -36.80534182 -44.49809984
 -35.89396689   6.90816014   3.07036817   0.84674913  -2.64673522
   0.16215558  -2.7368279   -4.54971253  -3.07961197  26.84301336]
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2395.9442321383845
gradient value of function right now is: [ 8.53113038e-01 -9.91525763e-03 -8.09051042e-01  7.13500990e-07
 -8.53113038e-01  9.91525763e-03  8.09051042e-01 -7.13500990e-07
 -3.96095622e-01 -1.61540193e-05 -9.54353591e+00  7.68080832e-02
  3.19369257e-08 -3.20946703e-02 -2.15272479e-03 -9.88354020e-02
  3.29140209e-04  1.11920708e-04 -4.37724684e-01 -3.96304976e-01
 -4.51389201e-08  2.12134636e-07 -1.52341665e-06  7.50102856e-07
  4.63462551e+00  4.02816340e-03  4.59351899e-07  1.29197305e+00
 -5.74544437e-04 -5.88102009e-02 -1.65758488e-01 -2.69737741e-01
  1.96202586e-02 -2.44801060e-04  3.44484546e-02  1.72699648e-01
 -8.43244185e-01 -4.13231400e-03 -5.91574204e-05 -1.44545294e+00
  2.50420838e+00  1.83523019e-02  1.27759301e-02  4.72107806e-01
 -7.40554789e-02 -8.96525071e-03 -9.55146343e-03 -4.00054419e-01
 -1.24531970e-01 -3.73675334e-02 -3.69311489e-02 -6.79244677e-01
 -2.06694716e+01 -2.10258030e-01 -1.38089394e-01 -5.17747657e-01
  2.81348585e+00 -8.11756330e+00 -1.85390423e+00  1.76594698e+01
 -2.12554386e+00  1.53500551e+01 -7.27980074e+00  4.65715716e+01
  7.81360610e+00]
supnorm grad right now is: 46.571571580251714
Weights right now are: 
[  6.22958283  -5.68216161  -0.1827468    1.2655054   -7.01980207
   5.69662525   0.75405285   0.14957765  13.87930689  14.31725981
   1.31253539  16.25727604  17.32839363 -12.70394321  17.16166643
   5.5627641   35.6109896   -7.38867477   4.73331869  -4.02519352
  19.52795823   0.89565794  14.5750808   11.1914573   -3.51911382
  -3.12585049  -9.7168185   22.64593892  11.08548503  -9.10693531
 -11.63828971   9.86060247 -10.03742026   3.06122793   5.8782533
  -0.55599041   8.10610462 -15.38821501 -18.5232988   -4.78195106
  -3.1629736    8.07514343  17.17697768   6.77557446   7.37705891
  -4.51963173 -15.22955911   1.38871727  17.01326352  -6.00952504
 -16.28881634  -2.19662168   2.66272292 -38.50682689 -46.83809689
 -36.82057191   7.17492685   2.69320173   0.76556673  -2.10235679
   0.38072322  -2.34906403  -5.76729667  -2.39171612  25.96266595]
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2392.0246555173976
gradient value of function right now is: [-2.43225355e-01 -4.38222697e-03  1.41040224e+00 -1.78575375e-07
  2.43225355e-01  4.38222697e-03 -1.41040224e+00  1.78575375e-07
  1.01471620e-01  4.87558463e-06  2.76118599e+00  2.79382855e-02
 -8.61925447e-08 -2.12208427e-02 -1.88679261e-03 -4.23135868e-02
 -6.50312424e-06  2.21454562e-04  3.37734383e-03  1.36686210e-02
  1.65238291e-08 -3.55547006e-08  5.33499414e-07 -4.22562543e-07
 -1.24581484e+00 -4.53640237e-03  1.28071201e-05 -3.76801200e-01
 -3.18188096e-02 -1.01027491e-01 -6.21363383e-02 -1.83527305e-01
  5.87799407e-03  1.28808209e-02  1.94345136e-02  1.45824596e-02
 -2.79298369e-01 -2.69056594e-02 -9.04352268e-04 -2.25512101e-01
 -1.64438987e-02  2.14614942e-03  1.27388108e-02  5.93104480e-02
 -2.73579294e-01 -2.50230313e-02 -3.74961258e-02 -7.40076304e-02
 -7.13503061e-02 -1.04206132e-02 -2.20652628e-02 -7.56589011e-02
  5.45477044e+00  9.10178296e-02  1.36559234e-01  2.91759829e-02
  1.39612157e+00 -2.91279980e+00  2.00216285e-01 -6.18881707e+00
 -1.18623054e-01 -9.81866291e+00 -3.98334415e-01 -7.94033522e-01
 -2.93591462e+00]
supnorm grad right now is: 9.818662914738887
Weights right now are: 
[  5.916432    -6.8446327    0.23458629   1.2266505   -6.70665124
   6.85909634   0.33671976   0.18843255  14.26145553  14.531165
   1.6713386   16.01432638  17.32776414 -14.07252175  15.76040493
   4.56329468  35.88652504  -7.32471475   4.99211104  -3.80934644
  19.52801661   0.92405729  14.56982018  11.33692201  -3.78401981
  -4.38988288 -10.9558636   22.49556931  11.23576561 -10.62593474
 -12.71084227   8.59320985  -9.54535622   3.84310382   7.81494029
  -0.78101498   8.35510222 -15.72179642 -22.3172482   -4.73071089
  -3.36796847   8.64175429  17.43663862   7.12424392   6.39331069
  -6.0007592  -16.76517133   0.22486269  15.13246689  -8.09688037
 -18.44391669  -3.36059861   3.05379966 -38.66989118 -47.04516682
 -36.50772327   8.33187154   1.8918438    0.1300993   -2.13928543
  -0.61189821  -1.9554628   -5.45780082  -2.96841263  25.83199989]
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2392.572667790661
gradient value of function right now is: [ 2.57869831e-02  5.67510738e-03  2.57861755e+00  7.52593755e-07
 -2.57869831e-02 -5.67510738e-03 -2.57861755e+00 -7.52593755e-07
  1.54823689e-01  2.65664608e-05 -2.24521148e-01 -8.53601528e-02
 -6.63616163e-07  1.22732376e-02  1.22781982e-02  7.99780266e-02
 -5.76576984e-05  1.92472853e-03  3.67837713e-01  4.18222182e-01
  2.18523926e-08 -4.65946829e-08 -4.45731803e-07 -4.25358796e-07
 -1.82973725e+00 -7.80836253e-03 -5.58694216e-07 -4.64565433e-01
  1.36176277e-02  6.80422243e-02  2.38402025e-02  1.63416652e-01
 -5.45283088e-02 -1.21554886e-01 -2.87701800e-02 -3.74243312e-01
  1.12821562e+00  2.72856210e-02  2.83082408e-04  1.13122661e+00
 -1.39194934e+00 -8.41604356e-02 -7.08116325e-02 -1.90268842e-01
  5.66908961e-01  7.79952717e-02  7.29674965e-02  2.45180995e-01
  1.04422707e-01  1.55479367e-02  1.58344919e-02  1.24610559e-01
  8.24845420e+00  1.46146931e-01  9.87287849e-02  1.12905437e-01
 -2.32466179e+00  7.82287199e+00  1.38268256e+00 -1.22400424e+01
  1.67904440e+00 -1.18470288e+01  1.98323230e+00 -1.02884023e+01
 -1.53574476e+01]
supnorm grad right now is: 15.357447590300218
Weights right now are: 
[  6.09873224  -5.72836001  -0.65309359   1.26177405  -6.88895148
   5.74282365   1.22439963   0.153309    13.49997396  13.36621155
   1.52885473  16.32375202  17.39671418 -13.14274453  15.19083213
   5.4608483   36.92227249  -5.05368956   3.93475132  -4.82331
  19.52735973   0.91818421  14.54363723  11.32863992  -2.92279535
  -3.33963875  -8.88619475  23.44982317  10.08214547 -10.53377259
 -11.70446644   9.35988753 -10.07747856   3.88870375   7.36035087
  -2.29852724   8.00717306 -14.26427589 -20.01314806  -5.28435014
  -4.07232913   8.71461965  17.25297463   6.31930256   7.026042
  -6.5143409  -17.31593637   2.45127707  16.86685938  -6.34503558
 -16.7678858   -1.79861696   2.12761199 -40.11681205 -47.66607388
 -38.49127786   6.51664968   3.74612511   1.65325024  -2.44504163
   1.20083502  -3.28149336  -5.38574366  -2.81907702  26.64112741]
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2398.4604946061017
gradient value of function right now is: [ 1.24989026e-01  4.13662101e-03  3.89921932e+00  1.66260590e-06
 -1.24989026e-01 -4.13662101e-03 -3.89921932e+00 -1.66260590e-06
  1.76655037e-01  1.68099182e-05 -1.38410258e+00 -1.78309540e-01
 -2.64326106e-07  9.48691567e-03  4.42258530e-03  4.09379981e-02
 -2.08205100e-04  1.34272816e-03  1.48117229e+00  1.43369148e+00
  2.96553180e-08 -1.09676271e-07 -1.11947484e-06 -1.10439408e-06
 -2.13156714e+00 -3.63194530e-03 -2.75145381e-07 -5.28103181e-01
  2.93380025e-04  4.63142381e-02  2.29235126e-02  9.88801781e-02
 -3.49563626e-02 -9.19767530e-02 -3.22117405e-02 -5.73562613e-01
  2.60462062e+00  1.68331563e-02  1.56066962e-04  2.81254079e+00
 -2.29939809e+00 -1.23133057e-01 -6.73741092e-02 -4.67211881e-01
  3.91217215e-01  8.06735595e-02  6.24348215e-02  2.71301678e-01
  9.26534898e-02  2.56553521e-02  2.07911649e-02  2.20302354e-01
  1.00104256e+01  1.58011367e-01  5.07362346e-02  1.95077436e-01
 -1.77685055e+00  4.48495901e+00  1.43742625e+00 -1.24935920e+01
  9.69328825e-01 -6.09663132e+00  3.30714305e+00 -1.63265546e+01
 -1.63678605e+01]
supnorm grad right now is: 16.367860494039554
Weights right now are: 
[  5.821873    -3.3871079   -0.9075805    1.72553921  -6.61209224
   3.40157154   1.47888655  -0.31045616  14.3563275   13.35242301
   1.89336337  16.82652714  17.38686813 -10.02949122  16.79697738
   8.17438205  38.50360902  -4.73468432   3.99772434  -5.05446674
  19.52678834   0.6760941   14.51721955  10.83525817  -3.4892457
  -3.37535982  -8.84109057  23.45618362  10.10115     -8.07121185
  -8.64801772  12.19093764 -10.07092687   2.568085     4.68863219
  -2.65650989   7.84561557 -14.29919482 -20.1058924   -5.23237999
  -4.29708922   8.22169617  16.91794544   5.61303363   7.64143161
  -5.02880176 -15.51185189   4.82433359  18.73850446  -3.69912216
 -13.97859375   0.84047342   2.38150484 -41.69481304 -48.59025196
 -38.6516766    5.36225548   4.25215786   3.35528302  -2.30760782
   3.55317231  -3.66256228  -5.09235601  -3.02790833  27.23888224]
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2401.461488259399
gradient value of function right now is: [ 2.16550947e-02  2.97745139e-03  3.37308499e+00  2.19357446e-06
 -2.16550947e-02 -2.97745139e-03 -3.37308499e+00 -2.19357446e-06
  1.81423673e-01  1.42951645e-05 -2.34931875e-01 -1.68575986e-01
 -1.43931243e-07  4.13257301e-03  9.17154497e-04  2.63563490e-02
 -3.23007920e-04  9.03102484e-04  2.02546004e+00  1.95035103e+00
  3.63352130e-08 -2.55474702e-07 -8.58365427e-07 -2.32367003e-06
 -2.23889116e+00 -2.49630614e-03 -1.24122257e-07 -5.65200930e-01
 -6.60241287e-05  6.14944588e-03  3.18504331e-02  5.09284709e-02
 -3.26940078e-02 -6.34242903e-02 -4.07853042e-02 -7.63512866e-01
  2.63738460e+00  7.97072204e-03  1.18148641e-04  2.89269136e+00
 -2.30097921e+00 -1.16637983e-01 -5.00369043e-02 -6.09108829e-01
  1.90453959e-01  4.20368969e-02  2.78546945e-02  2.06355802e-01
  6.74424756e-02  2.35490703e-02  1.55145850e-02  2.90715404e-01
  1.07376443e+01  1.62845946e-01  3.17210567e-02  2.18136495e-01
 -1.58628354e+00  3.14955023e+00  1.43805042e+00 -1.24737159e+01
  7.04585296e-01 -3.74752785e+00  3.74931547e+00 -1.80317804e+01
 -1.41957040e+01]
supnorm grad right now is: 18.031780394558716
Weights right now are: 
[  6.52404863  -4.50776982  -1.02057187   1.84261933  -7.31426787
   4.52223346   1.59187792  -0.42753628  14.30036868  13.31768428
   1.29260312  17.73596569  17.35391569 -10.82656919  16.61569326
   7.80696256  40.26818851  -3.6560572    4.92037408  -4.36156509
  19.52586473   0.78169857  14.47910749  11.02142553  -3.32027251
  -3.34655729  -8.73214351  23.86951117  10.10602664  -8.68028029
  -9.02194321  11.94187713  -9.62521143   2.85076114   7.3456093
  -0.51456583   7.31236929 -14.41250086 -19.92533788  -5.62285754
  -4.07780891   8.39771982  17.21735324   5.52376111   7.66196436
  -5.34689251 -16.22222508   4.32600236  18.44890566  -4.07981412
 -14.39630198  -0.21254311   2.25865232 -42.58913902 -49.48481062
 -38.92901918   5.84317445   4.12296439   2.47199665  -1.99776171
   2.84976987  -3.75886182  -4.58190243  -3.08908184  26.84223893]
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2403.166714185736
gradient value of function right now is: [-4.92776154e-02  4.30805275e-03  2.75410317e+00  5.85204024e-06
  4.92776154e-02 -4.30805275e-03 -2.75410317e+00 -5.85204024e-06
  1.84302919e-01  1.20149952e-05  6.15243517e-01 -1.11826504e-01
 -9.70976917e-08  4.51662432e-03  1.26380178e-04  3.89074768e-02
 -3.46007728e-04  1.04089335e-03  1.64770623e+00  1.55629787e+00
  3.28606769e-08 -7.53549487e-07 -4.66754833e-07 -7.02121455e-06
 -2.28117815e+00 -2.11975294e-03 -1.57075793e-07 -5.73455393e-01
 -7.30214072e-05 -1.17253332e-02  6.26350725e-02  6.18540391e-02
 -2.78171639e-02 -2.93067210e-02 -2.82675513e-02 -6.03816253e-01
  1.88363644e+00  4.12422787e-03  8.59737158e-05  2.03842967e+00
 -1.74274773e+00 -7.62546587e-02 -3.38902117e-02 -4.73356807e-01
  9.36661627e-02  2.40910557e-02  1.59338172e-02  1.51093872e-01
  2.29991706e-02  8.27413121e-03  3.10775894e-03  2.46839556e-01
  1.09233442e+01  1.47908189e-01  3.19156635e-02  2.25190663e-01
 -1.12503636e+00  2.30091055e+00  1.24778312e+00 -1.10942286e+01
  6.02206110e-01 -3.35382149e+00  3.60458057e+00 -1.80481668e+01
 -1.21404710e+01]
supnorm grad right now is: 18.048166763288073
Weights right now are: 
[  6.0532431   -5.06007967  -1.37092503   0.69910245  -6.84346233
   5.07454331   1.94223108   0.71598059  14.349767    13.3426913
   1.77885951  17.09459173  17.30605732 -10.65485057  16.6253903
   8.42194376  40.89479787  -5.25116948   5.23802728  -3.91109992
  19.52581912   0.54569742  14.55184485  11.86691264  -3.29294519
  -3.18290516  -8.17730123  24.02088906  10.10745144  -8.12985288
  -7.8905401   12.99782267 -10.73385239   2.62296318   8.66973184
  -1.59618123   7.36328042 -14.57493908 -19.96392796  -5.83290064
  -3.62589829   7.97704249  16.3817365    6.28194601   7.784676
  -4.16536162 -14.93336668   5.81947661  17.59784303  -4.44885873
 -14.74795892  -1.20829395   2.27423298 -42.24729009 -49.51739977
 -39.53122739   7.60017861   2.50504687   3.68028486  -2.25512306
   4.65096451  -2.46207174  -5.94498557  -2.37090936  26.49854344]
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2403.8406428501776
gradient value of function right now is: [-6.13009118e-02  2.45968110e-02  2.51756444e+00  7.22128309e-06
  6.13009118e-02 -2.45968110e-02 -2.51756444e+00 -7.22128309e-06
  1.75529188e-01  1.04556540e-05  7.51067325e-01 -1.06297021e-01
 -1.48540840e-08  8.87994057e-02  6.60782883e-04  2.22464864e-01
 -3.41282766e-04  1.10780468e-03  1.55492327e+00  1.47031825e+00
  2.46491361e-08 -8.84069660e-07 -2.71992091e-07 -6.84566544e-06
 -2.19965275e+00 -1.72397852e-03 -1.20307335e-06 -5.59417548e-01
  3.15518152e-05  8.86324803e-02  5.75605616e-01  6.13883564e-01
 -2.57311493e-02 -2.64734136e-02 -3.16117918e-02 -5.99461324e-01
  1.78835566e+00  3.18585501e-03  9.10471763e-05  1.94010338e+00
 -1.67840857e+00 -7.29362659e-02 -3.36089318e-02 -4.49792460e-01
  6.68921981e-02  8.00737298e-02  6.67951023e-02  7.59974930e-01
  3.15881446e-02  3.96823185e-02  3.22808621e-02  4.61403868e-01
  1.06477676e+01  1.38137914e-01  3.34862202e-02  2.24446280e-01
 -9.34514699e-01  2.11988375e+00  1.60216795e+00 -1.04038553e+01
  1.70248450e+00 -3.39578873e+00  3.55739999e+00 -1.81058245e+01
 -1.21026545e+01]
supnorm grad right now is: 18.10582445095309
Weights right now are: 
[  6.13738116  -5.82699997  -1.30808416   0.54827569  -6.9276004
   5.84146361   1.87939021   0.86680736  14.34826679  13.30498293
   1.71860633  16.89637175  17.30002806 -11.30978532  16.66704785
   7.61179663  42.62683872  -7.60074969   5.08909323  -4.18695458
  19.52603737   0.553533    14.55659982  11.99961421  -3.16619574
  -2.86299158  -8.04036207  24.45159339  10.11303607  -8.99211368
  -8.7072455   12.22025744 -11.22908975   3.1896174    7.41213706
  -0.88110428   7.86051144 -14.60645186 -20.20421873  -5.256566
  -4.02623209   9.45696364  18.32004166   5.44790506   7.65545356
  -5.49688856 -15.9344723    4.90115619  18.3275433   -4.64956193
 -15.15540727  -0.23268041   2.14111313 -43.02853918 -50.51499782
 -39.68767114   6.23206198   4.04345572   2.11129751  -2.05728369
   3.18271394  -2.77931632  -4.9663544   -2.8800211   26.52685979]
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1485.6777836367098
W_T_median: 1305.2258903813402
W_T_pctile_5: 722.8156208342742
W_T_CVAR_5_pct: 623.0747420462502
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.2
F value: -2403.8406428501776
-----------------------------------------------
