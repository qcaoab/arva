Starting at: 
14-06-23_17:15

 numpy seed:  2  


 pytorch seed:  2  

Key parameters-------
paths: 256000
iterations: 20000
batchsize: 1000
remove neg:  False
w constaint activation:  yy_fix_jan29


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor2
timeseries_basket['basket_desc'] = Factor2 portfolio for paper: Basic, size and value
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'B10_real_ret', 'VWD_real_ret', 'Size_Lo30_real_ret', 'Value_Hi30_real_ret']
############# End: defined asset  basket #################
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
192601                  0.0                NaN  ...     0.000561     0.023174
192602                  0.0                NaN  ...    -0.033046    -0.053510
192603                  0.0                NaN  ...    -0.064002    -0.096824
192604                  0.0                NaN  ...     0.037029     0.032975
192605                  0.0                NaN  ...     0.012095     0.001035

[5 rows x 16 columns]
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
202208                  NaN            -0.0020  ...    -0.036240    -0.011556
202209                  NaN            -0.0955  ...    -0.091324    -0.099903
202210                  NaN             0.0883  ...     0.077403     0.049863
202211                  NaN            -0.0076  ...     0.052365     0.028123
202212                  NaN            -0.0457  ...    -0.057116    -0.047241

[5 rows x 16 columns]


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor2
timeseries_basket['basket_desc'] = Factor2 portfolio for paper: Basic, size and value
timeseries_basket['basket_columns'] = 
['T30_nom_ret', 'B10_nom_ret', 'VWD_nom_ret', 'Size_Lo30_nom_ret', 'Value_Hi30_nom_ret']
############# End: defined asset  basket #################
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
192607                    0.0014              0.0154  ...     0.005383     0.031411
192608                    0.0319              0.0561  ...     0.005363     0.028647
192609                   -0.0173             -0.0071  ...     0.005343     0.005787
192610                   -0.0294             -0.0355  ...     0.005323    -0.028996
192611                   -0.0038              0.0294  ...     0.005303     0.028554

[5 rows x 6 columns]
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
202208                   -0.0020             -0.0164  ...    -0.043289    -0.036240
202209                   -0.0955             -0.0871  ...    -0.050056    -0.091324
202210                    0.0883              0.1486  ...    -0.014968     0.077403
202211                   -0.0076              0.0462  ...     0.040789     0.052365
202212                   -0.0457             -0.0499  ...    -0.018566    -0.057116

[5 rows x 6 columns]
Indices constructed with column names:
Index(['date_for_plt', 'Size_Lo30_nom_ret_ind', 'Value_Hi30_nom_ret_ind',
       'CPI_nom_ret_ind', 'T30_nom_ret_ind', 'B10_nom_ret_ind',
       'VWD_nom_ret_ind'],
      dtype='object')
############# Updated: defined asset basket #################
timeseries_basket['data_df_mean'] = 
T30_real_ret           0.000229
B10_real_ret           0.001637
VWD_real_ret           0.006759
Size_Lo30_real_ret     0.009939
Value_Hi30_real_ret    0.010052
dtype: float64


timeseries_basket['data_df_stdev'] = 
T30_real_ret           0.005227
B10_real_ret           0.019258
VWD_real_ret           0.053610
Size_Lo30_real_ret     0.082598
Value_Hi30_real_ret    0.072063
dtype: float64


timeseries_basket['data_df_corr'] = 
                     T30_real_ret  ...  Value_Hi30_real_ret
T30_real_ret             1.000000  ...             0.018239
B10_real_ret             0.351722  ...             0.031301
VWD_real_ret             0.068448  ...             0.909335
Size_Lo30_real_ret       0.014412  ...             0.908542
Value_Hi30_real_ret      0.018239  ...             1.000000

[5 rows x 5 columns]


timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names', 'data_df', 'data_df_mean', 'data_df_stdev', 'data_df_corr'])
############# End: updated: defined asset basket #################
-----------------------------------------------
Dates to be REMOVED due to missing values (should be at *start* only due to trading signals):
Int64Index([], dtype='int64')
-----------------------------------------------
Dates from available data for bootstrapping:
Start: 192607
End: 202212
-----------------------------------------------
Bootstrap block size: 6
-----------------------------------------------
Dates USED bootstrapping:
Start: 196307
End: 199201
-----------------------------------------------
0.0% of bootstrap sample done.
5.0% of bootstrap sample done.
10.0% of bootstrap sample done.
15.0% of bootstrap sample done.
20.0% of bootstrap sample done.
25.0% of bootstrap sample done.
30.0% of bootstrap sample done.
35.0% of bootstrap sample done.
40.0% of bootstrap sample done.
45.0% of bootstrap sample done.
50.0% of bootstrap sample done.
55.00000000000001% of bootstrap sample done.
60.0% of bootstrap sample done.
65.0% of bootstrap sample done.
70.0% of bootstrap sample done.
75.0% of bootstrap sample done.
80.0% of bootstrap sample done.
85.0% of bootstrap sample done.
90.0% of bootstrap sample done.
95.0% of bootstrap sample done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      13  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      13  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 13)     True          13  
2     (13, 13)     True          13  
3      (13, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       5       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      13  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      13  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       5           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 13)     True          13  
2     (13, 13)     True          13  
3      (13, 5)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       13  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       13  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 13)      True          13  
0     (13, 13)      True          13  
0      (13, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       13  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       13  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        5           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 13)      True          13  
0     (13, 13)      True          13  
0      (13, 5)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 2000, 'itbound_SGD_algorithms': 20000, 'nit_IterateAveragingStart': 18000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       13  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       13  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 13)      True          13  
0     (13, 13)      True          13  
0      (13, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       13  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       13  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        5           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 13)      True          13  
0     (13, 13)      True          13  
0      (13, 5)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[  7.9775,   2.9851],
        [  2.5531,  29.8728],
        [ -0.9327,  -0.5216],
        [ 16.0186,  -1.4325],
        [ -0.9009,  -0.5257],
        [ 11.3073,  -6.4122],
        [-15.9750,   1.4366],
        [ 15.1605, -13.7134],
        [-16.6405,   1.5885],
        [  5.5163, -20.8629],
        [  6.2094, -21.8266],
        [-25.0272,   5.1020],
        [ -0.9327,  -0.5216]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-13.0440,  -5.6582,  -3.3215, -11.4108,  -3.3886,  -4.4538,  10.7587,
         -3.2673,  11.4242,  -2.7748,  -2.9113,   2.1215,  -3.3215],
       device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ 3.5947e+00, -6.5387e+00,  8.6093e-02,  1.6516e+01,  1.5040e-02,
          5.5686e+00, -1.1055e+01,  6.9901e+00, -1.4943e+01,  1.4345e+01,
          1.3589e+01,  5.1440e+00,  8.6093e-02],
        [ 2.4965e-02, -5.1686e-01, -2.9629e-03, -2.1503e-01, -2.7609e-03,
         -1.6869e-01, -8.4917e-01, -2.9396e-01, -8.9056e-01, -2.5025e-01,
         -2.4787e-01, -3.8385e-01, -2.9629e-03],
        [ 2.4965e-02, -5.1686e-01, -2.9629e-03, -2.1503e-01, -2.7609e-03,
         -1.6869e-01, -8.4917e-01, -2.9396e-01, -8.9056e-01, -2.5025e-01,
         -2.4787e-01, -3.8385e-01, -2.9629e-03],
        [ 2.4965e-02, -5.1686e-01, -2.9629e-03, -2.1503e-01, -2.7609e-03,
         -1.6869e-01, -8.4917e-01, -2.9396e-01, -8.9056e-01, -2.5025e-01,
         -2.4787e-01, -3.8385e-01, -2.9629e-03],
        [ 2.4965e-02, -5.1686e-01, -2.9629e-03, -2.1503e-01, -2.7609e-03,
         -1.6869e-01, -8.4917e-01, -2.9396e-01, -8.9056e-01, -2.5025e-01,
         -2.4787e-01, -3.8385e-01, -2.9629e-03],
        [-1.6183e-02, -1.6097e+01, -1.0866e-01, -2.1752e+00, -1.8715e-01,
          7.8805e-01, -3.9336e+00,  1.0061e+01, -6.6200e+00,  1.2362e+01,
          1.3844e+01, -1.3607e+01, -1.0866e-01],
        [ 4.7205e+00, -1.3311e+01,  1.2014e-01,  1.5790e+01,  2.3635e-01,
          3.0547e+00, -3.6979e+00,  1.1101e+01, -6.5681e+00,  1.5125e+01,
          1.5085e+01, -1.0038e+01,  1.2014e-01],
        [ 2.4965e-02, -5.1686e-01, -2.9629e-03, -2.1503e-01, -2.7609e-03,
         -1.6869e-01, -8.4917e-01, -2.9396e-01, -8.9056e-01, -2.5025e-01,
         -2.4787e-01, -3.8385e-01, -2.9629e-03],
        [-4.2217e-02, -9.3496e+00, -1.9202e-01, -3.0426e+00, -2.0787e-01,
         -4.0516e+00,  2.4742e+00, -5.1032e-01,  1.4584e+00,  5.0798e-01,
          2.5522e-01, -5.3292e-01, -1.9202e-01],
        [ 2.2788e-01,  1.7979e+00,  7.0063e-02,  9.6925e-01,  6.7828e-02,
          4.9018e-01,  1.6774e+00,  5.3761e-01,  1.7978e+00,  5.8403e-01,
          5.8954e-01,  8.5549e-01,  7.0063e-02],
        [ 2.4965e-02, -5.1686e-01, -2.9629e-03, -2.1503e-01, -2.7609e-03,
         -1.6869e-01, -8.4917e-01, -2.9396e-01, -8.9056e-01, -2.5025e-01,
         -2.4787e-01, -3.8385e-01, -2.9629e-03],
        [ 2.4965e-02, -5.1686e-01, -2.9629e-03, -2.1503e-01, -2.7609e-03,
         -1.6869e-01, -8.4917e-01, -2.9396e-01, -8.9056e-01, -2.5025e-01,
         -2.4787e-01, -3.8385e-01, -2.9629e-03],
        [ 2.4965e-02, -5.1686e-01, -2.9629e-03, -2.1503e-01, -2.7609e-03,
         -1.6869e-01, -8.4917e-01, -2.9396e-01, -8.9056e-01, -2.5025e-01,
         -2.4787e-01, -3.8385e-01, -2.9629e-03]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([ 2.5809, -1.3188, -1.3188, -1.3188, -1.3188,  0.8373,  3.2251, -1.3188,
         1.8060,  3.0532, -1.3188, -1.3188, -1.3188], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-15.7115,   0.0359,   0.0359,   0.0359,   0.0359,  -9.8108, -10.3854,
           0.0359,  -1.7957,  13.0043,   0.0359,   0.0359,   0.0359]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  2.6400,   4.8946],
        [ -2.4965,   0.2171],
        [-14.9756,  -4.0659],
        [ -9.9949,  -5.4884],
        [-13.0723,  -5.5689],
        [ -0.9058,   6.6268],
        [-15.0195,  -6.0646],
        [-17.8449,  -7.0168],
        [-18.3742,  -4.4337],
        [  7.3984,  -1.3882],
        [ -0.4119,  -0.1213],
        [ -8.3240,   1.3847],
        [-21.7699,   8.8634]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-12.1585,  -5.6315,  -3.6808,   3.2874,  -0.4879, -10.7540,  -1.7035,
         -1.8260,  -3.5133,  -9.9031,   9.1469,   2.1171,   1.7494],
       device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 2.1295e-01,  2.2052e-01,  8.7081e+00,  7.6886e+00,  7.6289e+00,
          2.5475e-01,  1.8337e+00,  3.9202e+00,  7.1780e+00, -9.8400e+00,
         -5.9337e+00, -5.9189e+00, -1.7501e+01],
        [-3.2178e-01, -9.8714e-03, -2.0175e-02,  1.0321e-01, -2.2700e-01,
         -9.3834e-02, -2.3404e-01, -2.5285e-01, -2.7345e-02, -1.5140e+00,
         -2.3563e+00, -5.9449e-01, -6.5546e-01],
        [-3.9362e-01,  4.5157e-03, -1.8809e-03, -1.4955e+00, -3.1797e-03,
         -3.8103e-01, -1.1279e-02, -2.4747e-02, -4.4468e-03,  4.2072e-01,
         -3.3883e+00, -4.8800e-01, -4.2842e-01],
        [ 2.8627e+00, -4.7007e-02,  4.7227e-01,  7.3824e-01, -8.1787e-01,
          4.3674e+00, -4.7547e-01,  1.7591e+00,  4.6686e-01, -3.7754e-01,
          2.7057e+00, -2.6333e+00, -3.1052e+00],
        [-9.6755e+00,  2.9104e-01, -4.3281e+00, -1.3225e-01, -4.4596e+00,
         -1.3597e+01, -3.4061e+00, -7.4784e+00, -3.8741e+00, -6.2932e+00,
          4.5227e+00,  4.7322e+00,  1.4005e+01],
        [-4.1169e-01,  4.2038e-03, -1.9159e-03, -1.5503e+00,  1.5657e-02,
         -3.9627e-01,  2.5818e-04, -1.4734e-02, -4.2415e-03,  4.7303e-01,
         -3.3979e+00, -5.0668e-01, -4.4238e-01],
        [-5.5819e-01, -1.8889e-03, -2.1434e-03, -2.0210e+00,  9.8739e-02,
         -5.3023e-01,  1.1432e-01,  7.8741e-02, -4.4020e-03,  1.1111e+00,
         -4.2473e+00, -7.1740e-01, -5.9947e-01],
        [-2.7485e-01, -7.8524e-03, -5.2615e-02,  4.1118e-01, -5.9048e-01,
         -1.5618e-01, -4.9667e-01, -5.3675e-01, -6.7678e-02, -1.3288e+00,
         -2.6833e+00, -4.1651e-01, -6.5554e-01],
        [-4.1298e-01,  4.1794e-03, -1.9181e-03, -1.5541e+00,  1.6978e-02,
         -3.9735e-01,  1.1035e-03, -1.4008e-02, -4.2274e-03,  4.7687e-01,
         -3.3983e+00, -5.0798e-01, -4.4339e-01],
        [-3.5487e-04, -3.4774e-01,  1.0514e+01, -8.5833e+00,  1.1861e+01,
         -1.0608e-05,  1.5417e+01,  2.5233e+01,  1.8156e+01, -1.5135e+01,
         -3.3234e+01, -3.0958e+01, -1.1934e-01],
        [-4.1004e-01,  4.2351e-03, -1.9130e-03, -1.5453e+00,  1.3965e-02,
         -3.9489e-01, -8.1817e-04, -1.5659e-02, -4.2594e-03,  4.6812e-01,
         -3.3972e+00, -5.0499e-01, -4.4107e-01],
        [ 1.1361e+00, -1.2504e+00,  1.6778e+00,  2.7384e+00,  1.2798e+00,
          2.9687e+00,  1.2054e+01,  2.0842e+01,  1.0445e+00,  1.0996e+00,
         -2.1639e+00, -4.1088e+01,  5.0948e+00],
        [-4.1136e-01,  4.2103e-03, -1.9153e-03, -1.5492e+00,  1.5313e-02,
         -3.9599e-01,  3.8169e-05, -1.4923e-02, -4.2451e-03,  4.7203e-01,
         -3.3977e+00, -5.0633e-01, -4.4211e-01]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-3.9347, -6.8648, -4.6576, -4.3655, -6.4239, -4.6206, -3.3536, -6.3014,
        -4.6181, -4.1353, -4.6237, -1.0633, -4.6212], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-1.0722e+02, -4.3978e-01, -3.8418e-01, -5.1325e-01,  3.4982e+00,
         -3.9654e-01, -3.7509e-01, -8.7065e-01, -3.9739e-01,  3.2558e-11,
         -3.9545e-01, -3.7812e+01, -3.9632e-01],
        [-1.3928e-01,  9.7234e-02,  5.8235e-01,  3.3134e+00, -3.9049e-02,
          5.8653e-01,  1.2415e+00,  9.3288e-01,  5.8692e-01,  1.5348e+01,
          5.8600e-01,  2.2126e+00,  5.8641e-01],
        [-1.3166e+01, -2.6277e-02, -6.5970e-02, -3.7122e+01, -2.8464e+01,
         -6.7395e-02, -9.5348e-02, -3.3844e-02, -6.7499e-02, -1.3052e-12,
         -6.7261e-02, -7.2075e+00, -6.7367e-02],
        [-1.5309e+01, -2.3461e-02, -5.9590e-02, -3.5584e+01, -2.9058e+01,
         -6.0681e-02, -8.6011e-02, -3.2004e-02, -6.0763e-02, -5.4943e-13,
         -6.0577e-02, -6.6250e+00, -6.0659e-02],
        [ 8.7752e+00,  1.0983e+00,  1.7812e-01,  3.3637e+00,  9.3711e-01,
          1.4154e-01,  2.9257e-01,  1.7576e+00,  1.3891e-01, -1.2969e+01,
          1.4486e-01,  3.1375e+00,  1.4221e-01]], device='cuda:0'))])
loaded xi:  750.04913
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.2 0.2 0.2 0.2 0.2]
W_T_mean: 833.9454981193105
W_T_median: 579.7709853217282
W_T_pctile_5: -323.51989722579935
W_T_CVAR_5_pct: -452.446956541955
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -29594.611036704682
Current xi:  [759.1442]
objective value function right now is: -29594.611036704682
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -29741.302333795047
Current xi:  [772.7334]
objective value function right now is: -29741.302333795047
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -30314.625586321396
Current xi:  [786.8893]
objective value function right now is: -30314.625586321396
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -30642.644661222876
Current xi:  [800.42163]
objective value function right now is: -30642.644661222876
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -30828.439041363672
Current xi:  [813.517]
objective value function right now is: -30828.439041363672
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [827.12506]
objective value function right now is: -30804.761494351565
14.000000000000002% of gradient descent iterations done. Method = Adam
new min fval:  -31287.19624585271
Current xi:  [840.3521]
objective value function right now is: -31287.19624585271
16.0% of gradient descent iterations done. Method = Adam
new min fval:  -31506.390334309326
Current xi:  [853.4141]
objective value function right now is: -31506.390334309326
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -31721.34687367724
Current xi:  [866.7958]
objective value function right now is: -31721.34687367724
20.0% of gradient descent iterations done. Method = Adam
new min fval:  -31834.87967201758
Current xi:  [879.81683]
objective value function right now is: -31834.87967201758
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -31836.672942993326
Current xi:  [892.07227]
objective value function right now is: -31836.672942993326
24.0% of gradient descent iterations done. Method = Adam
new min fval:  -32142.639787279855
Current xi:  [904.97864]
objective value function right now is: -32142.639787279855
26.0% of gradient descent iterations done. Method = Adam
new min fval:  -32430.456181534657
Current xi:  [917.0678]
objective value function right now is: -32430.456181534657
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [928.85626]
objective value function right now is: -32149.16391179446
30.0% of gradient descent iterations done. Method = Adam
new min fval:  -32708.881548253536
Current xi:  [940.07385]
objective value function right now is: -32708.881548253536
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [950.5563]
objective value function right now is: -32261.867266140358
34.0% of gradient descent iterations done. Method = Adam
new min fval:  -32765.613035512648
Current xi:  [962.046]
objective value function right now is: -32765.613035512648
36.0% of gradient descent iterations done. Method = Adam
new min fval:  -32812.63700956598
Current xi:  [972.5349]
objective value function right now is: -32812.63700956598
38.0% of gradient descent iterations done. Method = Adam
new min fval:  -33045.29370713586
Current xi:  [982.9329]
objective value function right now is: -33045.29370713586
40.0% of gradient descent iterations done. Method = Adam
new min fval:  -33053.169631041375
Current xi:  [991.74396]
objective value function right now is: -33053.169631041375
42.0% of gradient descent iterations done. Method = Adam
new min fval:  -33117.766531779256
Current xi:  [1000.2245]
objective value function right now is: -33117.766531779256
44.0% of gradient descent iterations done. Method = Adam
new min fval:  -33180.362583477225
Current xi:  [1010.0984]
objective value function right now is: -33180.362583477225
46.0% of gradient descent iterations done. Method = Adam
new min fval:  -33225.57088511704
Current xi:  [1018.9567]
objective value function right now is: -33225.57088511704
48.0% of gradient descent iterations done. Method = Adam
new min fval:  -33377.65879228236
Current xi:  [1026.1088]
objective value function right now is: -33377.65879228236
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [1032.9586]
objective value function right now is: -32895.00473349743
52.0% of gradient descent iterations done. Method = Adam
new min fval:  -33400.72139497375
Current xi:  [1039.8827]
objective value function right now is: -33400.72139497375
54.0% of gradient descent iterations done. Method = Adam
new min fval:  -33408.51843769345
Current xi:  [1046.1755]
objective value function right now is: -33408.51843769345
56.00000000000001% of gradient descent iterations done. Method = Adam
new min fval:  -33521.46070606968
Current xi:  [1051.9724]
objective value function right now is: -33521.46070606968
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [1057.9857]
objective value function right now is: -32919.74989794296
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [1063.8651]
objective value function right now is: -33314.28744642741
62.0% of gradient descent iterations done. Method = Adam
new min fval:  -33583.2241787218
Current xi:  [1069.3358]
objective value function right now is: -33583.2241787218
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [1073.5524]
objective value function right now is: -33397.04919307302
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [1076.9949]
objective value function right now is: -33423.72908525072
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [1082.2734]
objective value function right now is: -33577.206064476275
70.0% of gradient descent iterations done. Method = Adam
new min fval:  -33600.896453181515
Current xi:  [1086.5184]
objective value function right now is: -33600.896453181515
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -33658.478091664
Current xi:  [1087.1753]
objective value function right now is: -33658.478091664
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -33672.00388206178
Current xi:  [1087.8916]
objective value function right now is: -33672.00388206178
76.0% of gradient descent iterations done. Method = Adam
new min fval:  -33677.06791436319
Current xi:  [1088.6675]
objective value function right now is: -33677.06791436319
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [1089.3389]
objective value function right now is: -33671.54959826383
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [1089.8755]
objective value function right now is: -33663.662239968944
82.0% of gradient descent iterations done. Method = Adam
new min fval:  -33695.76037776409
Current xi:  [1090.5968]
objective value function right now is: -33695.76037776409
84.0% of gradient descent iterations done. Method = Adam
new min fval:  -33707.07746147713
Current xi:  [1091.3251]
objective value function right now is: -33707.07746147713
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [1092.3215]
objective value function right now is: -33673.3929720944
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [1093.176]
objective value function right now is: -33643.09232056514
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [1093.8251]
objective value function right now is: -33687.82981724696
new min fval from sgd:  -33709.74828375605
new min fval from sgd:  -33713.588345036434
new min fval from sgd:  -33715.44066153146
new min fval from sgd:  -33715.72028690463
new min fval from sgd:  -33717.272674664084
new min fval from sgd:  -33717.71439027761
new min fval from sgd:  -33718.008880736306
new min fval from sgd:  -33718.126390159014
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [1094.478]
objective value function right now is: -33701.361579523065
new min fval from sgd:  -33718.16092083542
new min fval from sgd:  -33721.17779329019
new min fval from sgd:  -33721.91709137415
new min fval from sgd:  -33722.48064452788
new min fval from sgd:  -33722.51760577524
new min fval from sgd:  -33722.62305968088
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [1095.0969]
objective value function right now is: -33709.40536385822
new min fval from sgd:  -33723.8629678088
new min fval from sgd:  -33725.799834535166
new min fval from sgd:  -33726.79843438549
new min fval from sgd:  -33727.02323617109
new min fval from sgd:  -33727.260097176695
new min fval from sgd:  -33727.434618924424
new min fval from sgd:  -33727.58617356534
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [1095.7408]
objective value function right now is: -33701.81684764329
new min fval from sgd:  -33728.49206775336
new min fval from sgd:  -33728.65584394212
new min fval from sgd:  -33729.71006613931
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [1096.3865]
objective value function right now is: -33712.52535775901
new min fval from sgd:  -33729.717599661686
new min fval from sgd:  -33730.2774572523
new min fval from sgd:  -33730.94589170775
new min fval from sgd:  -33731.41140784772
new min fval from sgd:  -33731.85607439326
new min fval from sgd:  -33732.0028704308
new min fval from sgd:  -33732.14187714845
new min fval from sgd:  -33732.14759909014
new min fval from sgd:  -33732.23646723357
new min fval from sgd:  -33732.291381015166
new min fval from sgd:  -33732.35206733186
new min fval from sgd:  -33732.438332495214
new min fval from sgd:  -33732.64087909942
new min fval from sgd:  -33732.79970234588
new min fval from sgd:  -33732.894085385
new min fval from sgd:  -33733.012426777364
new min fval from sgd:  -33733.085305055574
new min fval from sgd:  -33733.23241042488
new min fval from sgd:  -33733.2784374232
new min fval from sgd:  -33733.46930348785
new min fval from sgd:  -33733.52889206908
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [1096.5392]
objective value function right now is: -33730.676390677945
min fval:  -33733.52889206908
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -0.2548,  -1.2448],
        [ -6.8146,  21.9291],
        [  0.3123,  -0.9588],
        [ 17.6871,  -0.9039],
        [  0.6554,  -0.7809],
        [  0.4199,  -2.5099],
        [-17.8557,   1.4380],
        [ 17.1118, -15.9842],
        [-18.4408,   1.2698],
        [ 17.5647, -16.8510],
        [ 18.1622, -17.4171],
        [-24.3570,  10.3193],
        [  0.3124,  -0.9587]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ -3.7944, -12.8048,  -4.9297, -12.8338,  -5.2469,  -3.2890,  11.3588,
          1.8044,  12.4609,   3.8833,   4.1298,  -0.9206,  -4.9298],
       device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-2.0734e-01, -3.5161e+00, -7.1378e-01,  1.9637e+01, -1.3982e+00,
         -6.6453e-02, -1.1909e+01,  2.6977e+00, -1.5578e+01,  2.9622e+00,
          1.1071e+00, -1.2888e+01, -7.1396e-01],
        [-1.0590e-02, -7.1184e-01, -6.8442e-03, -1.6817e-01, -8.3583e-03,
         -6.4486e-03, -1.1906e+00, -3.9141e-02, -1.2829e+00, -2.7554e-01,
         -2.9488e-01, -5.7544e-01, -6.8439e-03],
        [-1.0590e-02, -7.1184e-01, -6.8442e-03, -1.6817e-01, -8.3583e-03,
         -6.4486e-03, -1.1906e+00, -3.9140e-02, -1.2829e+00, -2.7554e-01,
         -2.9488e-01, -5.7544e-01, -6.8439e-03],
        [-1.0590e-02, -7.1184e-01, -6.8442e-03, -1.6817e-01, -8.3583e-03,
         -6.4486e-03, -1.1906e+00, -3.9140e-02, -1.2829e+00, -2.7554e-01,
         -2.9488e-01, -5.7544e-01, -6.8439e-03],
        [-1.0590e-02, -7.1184e-01, -6.8442e-03, -1.6817e-01, -8.3583e-03,
         -6.4486e-03, -1.1906e+00, -3.9140e-02, -1.2829e+00, -2.7554e-01,
         -2.9488e-01, -5.7544e-01, -6.8439e-03],
        [ 1.2170e-01, -1.1877e+01,  1.9699e-01, -3.3121e-01,  2.2471e-01,
          4.7412e-01, -2.2949e+00,  1.4002e+01, -5.0238e+00,  2.0362e+01,
          2.2082e+01, -1.1357e+01,  1.9700e-01],
        [ 1.8237e-01, -1.1306e+01,  1.2277e+00,  1.7620e+01,  1.6561e+00,
          2.3642e-01, -1.7584e+00,  1.5311e+01, -5.1364e+00,  2.1198e+01,
          2.1202e+01, -8.6679e+00,  1.2278e+00],
        [-1.0590e-02, -7.1184e-01, -6.8442e-03, -1.6817e-01, -8.3583e-03,
         -6.4486e-03, -1.1906e+00, -3.9140e-02, -1.2829e+00, -2.7554e-01,
         -2.9488e-01, -5.7544e-01, -6.8439e-03],
        [-1.0575e-02, -7.1271e-01, -6.8128e-03, -1.6831e-01, -8.3201e-03,
         -6.4529e-03, -1.1942e+00, -3.9246e-02, -1.2841e+00, -2.7567e-01,
         -2.9501e-01, -5.7440e-01, -6.8126e-03],
        [-2.3349e-02,  1.2286e+00, -2.1770e-02, -1.7092e+00, -1.3860e-02,
         -1.5034e-01,  1.8671e+00, -2.8234e+00,  3.1537e+00, -2.2006e+00,
         -2.2440e+00,  2.7379e+00, -2.1767e-02],
        [-1.0590e-02, -7.1184e-01, -6.8442e-03, -1.6817e-01, -8.3583e-03,
         -6.4486e-03, -1.1906e+00, -3.9140e-02, -1.2829e+00, -2.7554e-01,
         -2.9488e-01, -5.7544e-01, -6.8439e-03],
        [-1.0590e-02, -7.1184e-01, -6.8442e-03, -1.6817e-01, -8.3583e-03,
         -6.4486e-03, -1.1906e+00, -3.9140e-02, -1.2829e+00, -2.7554e-01,
         -2.9488e-01, -5.7544e-01, -6.8439e-03],
        [-1.0590e-02, -7.1184e-01, -6.8442e-03, -1.6817e-01, -8.3583e-03,
         -6.4486e-03, -1.1906e+00, -3.9140e-02, -1.2829e+00, -2.7554e-01,
         -2.9488e-01, -5.7544e-01, -6.8439e-03]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([ 5.6130, -1.4739, -1.4739, -1.4739, -1.4739,  2.5798,  5.6973, -1.4739,
        -1.4731,  2.2096, -1.4739, -1.4739, -1.4739], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-1.7991e+01,  3.4587e-03,  3.4588e-03,  3.4588e-03,  3.4588e-03,
         -1.4845e+01, -1.1007e+01,  3.4588e-03,  3.3292e-03,  1.1351e+01,
          3.4588e-03,  3.4588e-03,  3.4588e-03]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  2.7151,   4.3217],
        [ -2.6027,  -0.1676],
        [-32.4977,   5.8362],
        [ -6.6566,  -5.4855],
        [-14.4936,  -7.0232],
        [ -1.2911,   5.9878],
        [-13.9075,  -7.4967],
        [-18.8452,  -8.1235],
        [-20.5855,  -7.2965],
        [ 10.5689,  -0.9568],
        [  3.5517,   1.0569],
        [ -8.8045,   3.2469],
        [-22.9693,   7.6626]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-12.7225,  -7.9062,  -1.7736,   2.7481,   1.9760, -11.8253,  -3.9344,
          0.6986,  -6.4664, -10.9702,   8.0707,   1.7597,   0.0664],
       device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-2.9563e-01,  9.6580e-02, -1.5997e+00,  5.8626e+00,  1.0963e+01,
         -4.1307e-01,  7.7095e+00,  9.9085e+00,  2.1388e+00, -2.2343e+01,
         -7.5898e+00, -2.5284e+00, -7.6365e+00],
        [-2.2359e-01,  4.2711e-04, -3.7732e-03, -8.5805e-01, -5.8268e-02,
         -2.3067e-01,  6.7422e-04, -6.0086e-03, -1.4372e-04, -2.7602e-01,
         -5.0168e+00, -4.5656e-01, -3.1631e-01],
        [-2.2361e-01,  4.2774e-04, -3.7840e-03, -8.5812e-01, -5.8263e-02,
         -2.3070e-01,  5.3037e-04, -5.9235e-03,  7.1715e-05, -2.7597e-01,
         -5.0165e+00, -4.5663e-01, -3.1637e-01],
        [ 6.9366e+00, -1.5862e-01, -1.3360e+01,  3.8108e+00,  7.7539e+00,
          8.1305e+00,  1.0518e+01,  1.0361e+01,  9.2168e-01,  9.2930e+00,
          3.9896e+00, -3.1856e+00, -5.9310e+00],
        [ 1.1515e+00, -2.1852e-01,  4.3971e+00, -2.9302e+00, -5.1705e+00,
          3.9929e+00, -6.6431e+00, -3.7149e+00,  8.3117e-01,  1.7713e+00,
          7.0863e+00,  2.1684e+00,  2.0699e+01],
        [-2.2359e-01,  4.2629e-04, -3.7721e-03, -8.5802e-01, -5.8206e-02,
         -2.3067e-01,  4.7519e-04, -5.8794e-03,  2.4876e-04, -2.7604e-01,
         -5.0165e+00, -4.5655e-01, -3.1630e-01],
        [-2.2359e-01,  4.2637e-04, -3.7775e-03, -8.5805e-01, -5.8185e-02,
         -2.3068e-01,  3.2254e-04, -5.7955e-03,  1.3545e-04, -2.7602e-01,
         -5.0168e+00, -4.5659e-01, -3.1633e-01],
        [-2.2363e-01,  4.2952e-04, -3.7936e-03, -8.5822e-01, -5.8359e-02,
         -2.3072e-01,  7.3168e-04, -6.0683e-03, -1.8459e-04, -2.7590e-01,
         -5.0165e+00, -4.5669e-01, -3.1644e-01],
        [-2.2357e-01,  4.2488e-04, -3.7615e-03, -8.5794e-01, -5.8145e-02,
         -2.3064e-01,  3.8833e-04, -5.8191e-03,  2.8264e-04, -2.7610e-01,
         -5.0167e+00, -4.5649e-01, -3.1623e-01],
        [-2.1838e-03,  1.6670e-02,  6.7103e-01, -9.3089e+00,  1.1469e+01,
          5.8249e-04,  1.5971e+01,  2.4615e+01,  2.3012e+01, -2.2368e+01,
         -3.3860e+01, -3.3058e+01,  9.8510e-01],
        [-2.2354e-01,  4.2338e-04, -3.7454e-03, -8.5782e-01, -5.8106e-02,
         -2.3061e-01,  4.5114e-04, -5.8418e-03,  2.9352e-04, -2.7618e-01,
         -5.0165e+00, -4.5639e-01, -3.1613e-01],
        [-2.1582e-01,  2.7061e-01,  2.8623e-03, -4.6976e+00, -6.7478e+00,
          7.3230e-01,  1.4141e+01,  1.4425e+01, -5.1402e-01, -6.2736e+00,
         -3.1723e+00, -6.2290e+01, -8.6974e-03],
        [-2.2360e-01,  4.2708e-04, -3.7794e-03, -8.5808e-01, -5.8233e-02,
         -2.3069e-01,  4.8088e-04, -5.8892e-03,  2.3407e-04, -2.7600e-01,
         -5.0165e+00, -4.5660e-01, -3.1634e-01]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-5.5917, -5.0169, -5.0173, -3.0809, -3.8585, -5.0172, -5.0169, -5.0174,
        -5.0169, -4.9017, -5.0170, -2.0724, -5.0172], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-9.9227e+01,  8.6920e-02,  5.5476e-02,  9.8233e-01,  4.2894e+00,
          4.4258e-02,  1.4528e-02,  1.0078e-01,  2.7206e-02, -1.2834e-09,
          3.9549e-02, -3.4710e+01,  4.5382e-02],
        [-2.4397e+00,  1.5491e-03,  1.5469e-03, -7.4597e+00, -9.3376e+00,
          1.5469e-03,  1.5450e-03,  1.5486e-03,  1.5465e-03,  2.5636e+01,
          1.5480e-03,  1.8855e+00,  1.5465e-03],
        [-3.8394e-01, -2.5235e-04, -2.5228e-04, -1.0013e+01, -9.6564e+00,
         -2.5239e-04, -2.5237e-04, -2.5218e-04, -2.5248e-04, -3.7775e-04,
         -2.5260e-04, -1.0560e-02, -2.5232e-04],
        [-3.3152e-01, -2.6628e-04, -2.6624e-04, -1.0009e+01, -9.5493e+00,
         -2.6627e-04, -2.6624e-04, -2.6623e-04, -2.6629e-04, -2.2445e-04,
         -2.6635e-04, -1.8496e-02, -2.6625e-04],
        [ 9.2333e+00,  1.0155e-01,  7.0127e-02,  4.1754e+00,  1.2643e+00,
          5.8878e-02,  2.9159e-02,  1.1546e-01,  4.1799e-02, -2.3454e+01,
          5.4104e-02,  3.1695e+00,  6.0021e-02]], device='cuda:0'))])
xi:  [1096.482]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 1253.0125089295714
W_T_median: 1239.500433099656
W_T_pctile_5: 1099.6078105406355
W_T_CVAR_5_pct: 648.4666250358811
Average q (qsum/M+1):  42.358697706653224
Optimal xi:  [1096.482]
Expected(across Rb) median(across samples) p_equity:  2.824124988295984e-07
obj fun:  tensor(-33733.5289, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/factor_decumulation/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/factor_decumulation/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: Paper_FactorInv_Factor2
Objective function: mean_cvar_single_level
Tracing param: 50.0
-----------------------------------------------
