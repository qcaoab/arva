Starting at: 
08-06-23_14:35

 numpy seed:  2  


 pytorch seed:  2  

Key parameters-------
paths: 256000
iterations: 10000
batchsize: 1000
remove neg:  False
w constaint activation:  yy_fix_jan29


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor2
timeseries_basket['basket_desc'] = Factor2 portfolio for paper: Basic, size and value
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'B10_real_ret', 'VWD_real_ret', 'Size_Lo30_real_ret', 'Value_Hi30_real_ret']
############# End: defined asset  basket #################
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
192601                  0.0                NaN  ...     0.000561     0.023174
192602                  0.0                NaN  ...    -0.033046    -0.053510
192603                  0.0                NaN  ...    -0.064002    -0.096824
192604                  0.0                NaN  ...     0.037029     0.032975
192605                  0.0                NaN  ...     0.012095     0.001035

[5 rows x 16 columns]
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
202208                  NaN            -0.0020  ...    -0.036240    -0.011556
202209                  NaN            -0.0955  ...    -0.091324    -0.099903
202210                  NaN             0.0883  ...     0.077403     0.049863
202211                  NaN            -0.0076  ...     0.052365     0.028123
202212                  NaN            -0.0457  ...    -0.057116    -0.047241

[5 rows x 16 columns]


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor2
timeseries_basket['basket_desc'] = Factor2 portfolio for paper: Basic, size and value
timeseries_basket['basket_columns'] = 
['T30_nom_ret', 'B10_nom_ret', 'VWD_nom_ret', 'Size_Lo30_nom_ret', 'Value_Hi30_nom_ret']
############# End: defined asset  basket #################
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
192607                    0.0014              0.0154  ...     0.005383     0.031411
192608                    0.0319              0.0561  ...     0.005363     0.028647
192609                   -0.0173             -0.0071  ...     0.005343     0.005787
192610                   -0.0294             -0.0355  ...     0.005323    -0.028996
192611                   -0.0038              0.0294  ...     0.005303     0.028554

[5 rows x 6 columns]
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
202208                   -0.0020             -0.0164  ...    -0.043289    -0.036240
202209                   -0.0955             -0.0871  ...    -0.050056    -0.091324
202210                    0.0883              0.1486  ...    -0.014968     0.077403
202211                   -0.0076              0.0462  ...     0.040789     0.052365
202212                   -0.0457             -0.0499  ...    -0.018566    -0.057116

[5 rows x 6 columns]
Indices constructed with column names:
Index(['date_for_plt', 'Size_Lo30_nom_ret_ind', 'Value_Hi30_nom_ret_ind',
       'CPI_nom_ret_ind', 'T30_nom_ret_ind', 'B10_nom_ret_ind',
       'VWD_nom_ret_ind'],
      dtype='object')
############# Updated: defined asset basket #################
timeseries_basket['data_df_mean'] = 
T30_real_ret           0.000229
B10_real_ret           0.001637
VWD_real_ret           0.006759
Size_Lo30_real_ret     0.009939
Value_Hi30_real_ret    0.010052
dtype: float64


timeseries_basket['data_df_stdev'] = 
T30_real_ret           0.005227
B10_real_ret           0.019258
VWD_real_ret           0.053610
Size_Lo30_real_ret     0.082598
Value_Hi30_real_ret    0.072063
dtype: float64


timeseries_basket['data_df_corr'] = 
                     T30_real_ret  ...  Value_Hi30_real_ret
T30_real_ret             1.000000  ...             0.018239
B10_real_ret             0.351722  ...             0.031301
VWD_real_ret             0.068448  ...             0.909335
Size_Lo30_real_ret       0.014412  ...             0.908542
Value_Hi30_real_ret      0.018239  ...             1.000000

[5 rows x 5 columns]


timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names', 'data_df', 'data_df_mean', 'data_df_stdev', 'data_df_corr'])
############# End: updated: defined asset basket #################
-----------------------------------------------
Dates to be REMOVED due to missing values (should be at *start* only due to trading signals):
Int64Index([], dtype='int64')
-----------------------------------------------
Dates from available data for bootstrapping:
Start: 192607
End: 202212
-----------------------------------------------
Bootstrap block size: 6
-----------------------------------------------
Dates USED bootstrapping:
Start: 196307
End: 202212
-----------------------------------------------
0.0% of bootstrap sample done.
5.0% of bootstrap sample done.
10.0% of bootstrap sample done.
15.0% of bootstrap sample done.
20.0% of bootstrap sample done.
25.0% of bootstrap sample done.
30.0% of bootstrap sample done.
35.0% of bootstrap sample done.
40.0% of bootstrap sample done.
45.0% of bootstrap sample done.
50.0% of bootstrap sample done.
55.00000000000001% of bootstrap sample done.
60.0% of bootstrap sample done.
65.0% of bootstrap sample done.
70.0% of bootstrap sample done.
75.0% of bootstrap sample done.
80.0% of bootstrap sample done.
85.0% of bootstrap sample done.
90.0% of bootstrap sample done.
95.0% of bootstrap sample done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      13  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      13  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 13)     True          13  
2     (13, 13)     True          13  
3      (13, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       5       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      13  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      13  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       5           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 13)     True          13  
2     (13, 13)     True          13  
3      (13, 5)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       13  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       13  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 13)      True          13  
0     (13, 13)      True          13  
0      (13, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       13  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       13  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        5           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 13)      True          13  
0     (13, 13)      True          13  
0      (13, 5)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 1000, 'itbound_SGD_algorithms': 10000, 'nit_IterateAveragingStart': 9000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       13  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       13  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 13)      True          13  
0     (13, 13)      True          13  
0      (13, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       13  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       13  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        5           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 13)      True          13  
0     (13, 13)      True          13  
0      (13, 5)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ 12.2183,  -1.0046],
        [-23.8274, -12.0814],
        [ -1.1918,   0.0547],
        [ -1.1909,   0.0542],
        [ -1.1918,   0.0547],
        [ -5.9744, -12.5412],
        [ -3.7587,  11.1208],
        [ -1.1918,   0.0547],
        [-19.9120,   6.7577],
        [ -1.1918,   0.0547],
        [-11.2001,   4.6390],
        [ -1.1918,   0.0547],
        [ -1.1918,   0.0547]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-10.6712,  -3.8268,  -3.0881,  -3.0869,  -3.0881,  -1.8783,   2.3098,
         -3.0881,   3.9609,  -3.0881,   0.8609,  -3.0881,  -3.0882],
       device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-7.4769e+00,  4.2819e-03, -8.7627e-02, -8.6414e-02, -8.7631e-02,
         -1.1745e+01, -1.1518e-01, -8.7622e-02, -5.1411e-01, -8.7629e-02,
         -1.9461e+00, -8.7626e-02, -8.7681e-02],
        [ 1.4854e+01,  8.2277e+00, -1.3007e-01, -1.2437e-01, -1.3009e-01,
          6.8216e+00, -4.5209e+00, -1.3004e-01, -5.4447e+00, -1.3009e-01,
         -1.6158e+00, -1.3006e-01, -1.3035e-01],
        [-2.5211e-01, -1.7279e-02, -6.6487e-03, -6.6653e-03, -6.6487e-03,
         -3.0614e-01, -6.1513e-01, -6.6487e-03, -8.1939e-02, -6.6487e-03,
         -3.8596e-02, -6.6487e-03, -6.6482e-03],
        [-2.5211e-01, -1.7278e-02, -6.6487e-03, -6.6653e-03, -6.6487e-03,
         -3.0614e-01, -6.1513e-01, -6.6487e-03, -8.1939e-02, -6.6487e-03,
         -3.8596e-02, -6.6487e-03, -6.6482e-03],
        [ 1.3854e+01,  7.5629e+00, -7.6041e-02, -7.5505e-02, -7.6035e-02,
          6.8077e+00, -4.4027e+00, -7.6047e-02, -5.4098e+00, -7.6037e-02,
         -1.4601e+00, -7.6042e-02, -7.5990e-02],
        [-1.3458e+01, -5.6117e+00, -3.3803e-02, -3.2063e-02, -3.3807e-02,
         -1.0801e+01,  4.3827e+00, -3.3798e-02,  6.0944e+00, -3.3806e-02,
          1.6878e+00, -3.3802e-02, -3.3858e-02],
        [-2.5211e-01, -1.7278e-02, -6.6487e-03, -6.6653e-03, -6.6487e-03,
         -3.0614e-01, -6.1513e-01, -6.6487e-03, -8.1939e-02, -6.6487e-03,
         -3.8596e-02, -6.6487e-03, -6.6482e-03],
        [-2.5211e-01, -1.7278e-02, -6.6487e-03, -6.6653e-03, -6.6487e-03,
         -3.0614e-01, -6.1513e-01, -6.6487e-03, -8.1939e-02, -6.6487e-03,
         -3.8596e-02, -6.6487e-03, -6.6482e-03],
        [-2.5211e-01, -1.7278e-02, -6.6487e-03, -6.6652e-03, -6.6486e-03,
         -3.0614e-01, -6.1513e-01, -6.6487e-03, -8.1939e-02, -6.6487e-03,
         -3.8596e-02, -6.6487e-03, -6.6482e-03],
        [-2.5211e-01, -1.7279e-02, -6.6487e-03, -6.6653e-03, -6.6487e-03,
         -3.0614e-01, -6.1513e-01, -6.6488e-03, -8.1939e-02, -6.6487e-03,
         -3.8596e-02, -6.6487e-03, -6.6482e-03],
        [ 4.4568e-01, -1.5292e+01,  9.4492e-02,  9.7662e-02,  9.4484e-02,
          6.9497e+00, -7.7324e-01,  9.4500e-02, -1.1082e+01,  9.4486e-02,
         -5.5618e+00,  9.4493e-02,  9.4390e-02],
        [ 1.2822e+01,  7.2135e+00, -3.7742e-02, -3.8192e-02, -3.7736e-02,
          6.8476e+00, -4.2788e+00, -3.7748e-02, -5.4557e+00, -3.7738e-02,
         -1.4904e+00, -3.7743e-02, -3.7679e-02],
        [-2.5211e-01, -1.7278e-02, -6.6487e-03, -6.6653e-03, -6.6487e-03,
         -3.0614e-01, -6.1513e-01, -6.6487e-03, -8.1939e-02, -6.6487e-03,
         -3.8596e-02, -6.6487e-03, -6.6482e-03]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([ 2.6231, -3.6689, -1.7101, -1.7101, -3.5868,  2.4147, -1.7101, -1.7101,
        -1.7101, -1.7101,  6.4571, -3.5231, -1.7101], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 7.3683, -7.6111,  0.0479,  0.0479, -6.5409, 17.5487,  0.0479,  0.0479,
          0.0479,  0.0479, -7.5788, -5.9340,  0.0479]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  6.9060, -13.1393],
        [  6.5569,   7.4352],
        [ 10.8370,   3.1342],
        [  4.6287,   8.2918],
        [-12.3089,  -3.7201],
        [-12.9486,  -3.9281],
        [ -1.3979,   1.5832],
        [ -9.6740,  -3.1890],
        [  2.3974,   1.3759],
        [ 13.7493,   0.2184],
        [ -9.8710,   6.8881],
        [ -1.4980,   1.5649],
        [ 11.5294,   3.5855]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ -6.0787,   4.8552,  -2.7106,   0.7299,  -2.0636,  -1.9967,  -4.7390,
         -3.9057,  -7.9278, -11.7126,   3.1082,  -4.3530,  -1.7238],
       device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 1.5835e+00,  1.8219e+00,  1.5848e+00,  6.5152e-01,  4.2584e-02,
          4.0530e-02, -1.0365e+00, -4.3691e-02, -1.1745e+00,  2.7027e-01,
          3.7579e-01, -6.9279e-01,  1.6918e+00],
        [-9.0503e-02, -2.4694e+00, -2.1141e+00, -4.5862e-01,  8.6515e-01,
          9.2735e-01, -2.2800e-01,  2.1796e-01, -2.0569e-01, -2.4456e+00,
          1.4580e+00, -2.3988e-01, -2.2155e+00],
        [-3.1614e+00, -1.3319e+00, -5.5159e-01,  5.9841e-01,  1.0496e+00,
          1.1100e+00, -1.9071e+00,  1.9319e-01, -2.0276e+00,  5.7285e-01,
          1.2198e-01, -1.4772e+00, -9.7850e-01],
        [-7.4473e+00,  1.2093e+01,  4.5157e+00,  5.9305e+00, -5.7380e+00,
         -5.0542e+00,  2.9444e-01, -2.3661e+00,  4.3936e-03,  1.3828e+01,
         -3.2799e+00,  3.0955e-01,  4.6879e+00],
        [ 2.0831e+00, -2.0666e+00, -9.4523e-01, -1.2460e+01,  6.9661e+00,
          8.8951e+00,  5.2429e-02,  3.8686e+00, -1.8138e-01, -2.6600e+00,
         -7.9105e+00,  6.5349e-02, -1.1281e+00],
        [ 8.9788e+00,  2.9741e+00,  5.4133e+00,  3.8404e+00, -5.7712e+00,
         -6.5655e+00,  1.0683e-01, -1.5875e+00,  2.6670e-02,  1.4100e-03,
         -4.1878e+00,  1.3283e-01,  7.2853e+00],
        [-7.2816e+00,  1.3473e+00, -2.5587e-01,  1.5604e+00,  4.3643e+00,
          4.6484e+00, -2.3821e-01,  1.4273e+00, -3.1800e-01, -1.5107e+01,
          3.8307e+00, -2.7448e-01, -1.9318e+00],
        [-3.1601e+00, -1.3327e+00, -5.5237e-01,  5.9749e-01,  1.0485e+00,
          1.1088e+00, -1.9059e+00,  1.9267e-01, -2.0260e+00,  5.7191e-01,
          1.2111e-01, -1.4767e+00, -9.7938e-01],
        [ 6.8244e-01, -3.3595e+01, -5.1693e+00, -2.8374e-02,  2.1202e+00,
          2.4812e+00, -1.6544e-01,  2.8516e+00, -1.0808e-02, -7.9209e+00,
          2.0815e-01, -2.6191e-01, -7.0965e+00],
        [-3.1504e+00, -1.3389e+00, -5.5817e-01,  5.9085e-01,  1.0403e+00,
          1.1007e+00, -1.8977e+00,  1.8895e-01, -2.0143e+00,  5.6513e-01,
          1.1501e-01, -1.4729e+00, -9.8584e-01],
        [ 3.4269e+00, -2.8349e+00, -1.9392e-01,  1.2434e+00,  5.0546e+00,
          7.2169e+00,  1.3041e-02,  3.5124e+00,  9.7944e-01,  6.8438e+00,
         -3.8644e+00, -2.7882e-01,  2.9933e-01],
        [ 1.6145e+00,  1.8551e+00,  1.6008e+00,  6.6210e-01,  5.5826e-02,
          5.4792e-02, -1.0251e+00, -3.7516e-02, -1.1552e+00,  2.7404e-01,
          3.9900e-01, -6.8915e-01,  1.7099e+00],
        [-3.1684e+00, -1.3277e+00, -5.4732e-01,  6.0331e-01,  1.0544e+00,
          1.1146e+00, -1.9127e+00,  1.9553e-01, -2.0353e+00,  5.7762e-01,
          1.2516e-01, -1.4798e+00, -9.7366e-01]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([ 3.2017, -1.6666, -2.5139, -1.4171, -0.5566,  1.8048, -2.7823, -2.5146,
        -1.0899, -2.5195, -2.7297,  3.2397, -2.5103], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-6.6453e-01,  2.1610e+00,  1.3901e+00,  5.5678e+00, -1.7378e+01,
         -2.0654e+00,  2.8692e+00,  1.3897e+00,  1.1524e-09,  1.3875e+00,
         -3.8119e+01, -7.9954e-01,  1.3923e+00],
        [-3.4266e-01, -1.5739e+00, -1.3518e+00,  3.1535e+00, -1.5064e+00,
         -5.5120e-01, -1.6127e-01, -1.3511e+00,  1.5022e+01, -1.3447e+00,
          5.5519e-01, -5.1008e-01, -1.3542e+00],
        [-2.8194e+00, -7.8775e-03, -4.9443e-03, -2.7107e+00, -2.4081e-01,
         -2.8180e+00, -5.3132e-02, -4.9275e-03, -1.7333e-03, -4.8085e-03,
         -9.1884e-01, -2.8195e+00, -5.0330e-03],
        [-2.7510e+00, -4.3007e-03, -7.0306e-03, -2.6887e+00, -2.0580e-01,
         -2.7481e+00, -7.1591e-02, -7.0050e-03, -3.9829e-03, -6.8183e-03,
         -8.1437e-01, -2.7511e+00, -7.1631e-03],
        [ 1.6098e+00,  4.3462e-01,  4.9823e-01, -3.0751e+00,  1.6901e+00,
          1.8956e+00,  2.4249e-01,  4.9735e-01, -1.5052e+01,  4.9191e-01,
          5.2908e-01,  1.5787e+00,  5.0376e-01]], device='cuda:0'))])
loaded xi:  599.9581
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.2 0.2 0.2 0.2 0.2]
W_T_mean: 946.50330641104
W_T_median: 707.5512584605915
W_T_pctile_5: -238.22847581189643
W_T_CVAR_5_pct: -367.3344080824147
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -2220.575486306204
Current xi:  [598.8726]
objective value function right now is: -2220.575486306204
4.0% of gradient descent iterations done. Method = Adam
Current xi:  [597.29144]
objective value function right now is: -2215.9073129956946
6.0% of gradient descent iterations done. Method = Adam
Current xi:  [595.3916]
objective value function right now is: -2218.602148148206
8.0% of gradient descent iterations done. Method = Adam
Current xi:  [593.40765]
objective value function right now is: -2212.602617523325
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -2224.4079252509755
Current xi:  [591.62866]
objective value function right now is: -2224.4079252509755
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [589.2841]
objective value function right now is: -2193.176723050017
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [587.0102]
objective value function right now is: -2204.2488177420564
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [584.72296]
objective value function right now is: -2222.3833755604105
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [582.814]
objective value function right now is: -2214.893291249614
20.0% of gradient descent iterations done. Method = Adam
new min fval:  -2225.663702396368
Current xi:  [581.1308]
objective value function right now is: -2225.663702396368
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [579.05035]
objective value function right now is: -2223.6790483634254
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [577.27435]
objective value function right now is: -2224.3204366783607
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [574.9507]
objective value function right now is: -2221.5626832300027
28.000000000000004% of gradient descent iterations done. Method = Adam
new min fval:  -2225.7559286410215
Current xi:  [573.3664]
objective value function right now is: -2225.7559286410215
30.0% of gradient descent iterations done. Method = Adam
new min fval:  -2226.943669058167
Current xi:  [571.7278]
objective value function right now is: -2226.943669058167
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [569.77075]
objective value function right now is: -2223.148902786422
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [567.8142]
objective value function right now is: -2221.947899512054
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [566.333]
objective value function right now is: -2220.190296322031
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [564.6303]
objective value function right now is: -2221.9710139963554
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [563.23596]
objective value function right now is: -2217.855995108853
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [561.57245]
objective value function right now is: -2225.37143076868
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [559.9366]
objective value function right now is: -2211.4011798282527
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [558.47284]
objective value function right now is: -2215.549137504372
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [556.7318]
objective value function right now is: -2221.3181594013395
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [555.59686]
objective value function right now is: -2222.732405056053
52.0% of gradient descent iterations done. Method = Adam
new min fval:  -2228.436161693557
Current xi:  [554.2903]
objective value function right now is: -2228.436161693557
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [553.301]
objective value function right now is: -2227.508640116455
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [552.269]
objective value function right now is: -2225.911848039955
57.99999999999999% of gradient descent iterations done. Method = Adam
new min fval:  -2228.6934557388604
Current xi:  [551.1001]
objective value function right now is: -2228.6934557388604
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [549.6385]
objective value function right now is: -2225.2088187642776
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [548.18823]
objective value function right now is: -2225.0168054060955
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [546.9793]
objective value function right now is: -2223.5301098194586
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [545.7069]
objective value function right now is: -2210.438702279785
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [544.86865]
objective value function right now is: -2228.487855270543
70.0% of gradient descent iterations done. Method = Adam
new min fval:  -2229.9435004868656
Current xi:  [543.52545]
objective value function right now is: -2229.9435004868656
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -2232.0551367231183
Current xi:  [543.35004]
objective value function right now is: -2232.0551367231183
74.0% of gradient descent iterations done. Method = Adam
Current xi:  [543.0193]
objective value function right now is: -2231.3744812997315
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [542.84375]
objective value function right now is: -2230.5175419254438
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [542.68176]
objective value function right now is: -2231.796679699059
80.0% of gradient descent iterations done. Method = Adam
new min fval:  -2232.651566585144
Current xi:  [542.4782]
objective value function right now is: -2232.651566585144
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [542.24603]
objective value function right now is: -2232.650024449656
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [542.06006]
objective value function right now is: -2228.56696017682
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [541.8779]
objective value function right now is: -2230.397718582996
88.0% of gradient descent iterations done. Method = Adam
new min fval:  -2232.848006539841
Current xi:  [541.716]
objective value function right now is: -2232.848006539841
new min fval from sgd:  -2232.964958048135
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [541.4555]
objective value function right now is: -2232.964958048135
new min fval from sgd:  -2233.061699922123
new min fval from sgd:  -2233.0772471434957
new min fval from sgd:  -2233.1920808656355
new min fval from sgd:  -2233.2775040837755
new min fval from sgd:  -2233.379616422702
new min fval from sgd:  -2233.3818993887035
new min fval from sgd:  -2233.4139708213957
new min fval from sgd:  -2233.463125579035
new min fval from sgd:  -2233.4936666837557
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [541.179]
objective value function right now is: -2233.1165030667185
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [540.9374]
objective value function right now is: -2233.105734628482
new min fval from sgd:  -2233.516233998651
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [540.6905]
objective value function right now is: -2232.7867013268437
new min fval from sgd:  -2233.5816576317725
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [540.6048]
objective value function right now is: -2232.880162796582
new min fval from sgd:  -2233.6008636536653
new min fval from sgd:  -2233.622997625222
new min fval from sgd:  -2233.6641900918617
new min fval from sgd:  -2233.7228862418237
new min fval from sgd:  -2233.7735182938704
new min fval from sgd:  -2233.808632795898
new min fval from sgd:  -2233.820684585752
new min fval from sgd:  -2233.840261391636
new min fval from sgd:  -2233.8518087584016
new min fval from sgd:  -2233.856963566785
new min fval from sgd:  -2233.861788153192
new min fval from sgd:  -2233.863251703698
new min fval from sgd:  -2233.8699327683453
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [540.57935]
objective value function right now is: -2233.498277179622
min fval:  -2233.8699327683453
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ 13.8106,  -0.9305],
        [-21.0210, -13.6240],
        [ -1.0144,  -0.0509],
        [ -1.0144,  -0.0509],
        [ -1.0144,  -0.0509],
        [ -2.7727, -12.3952],
        [ -5.9749,  10.0107],
        [ -1.0144,  -0.0509],
        [-21.5356,   6.6625],
        [ -1.0144,  -0.0509],
        [-12.3075,   4.1606],
        [ -1.0144,  -0.0509],
        [ -1.0144,  -0.0509]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-11.5515,  -4.5729,  -3.3019,  -3.3019,  -3.3019,  -2.7377,   2.8689,
         -3.3019,   3.8462,  -3.3019,  -0.1949,  -3.3019,  -3.3019],
       device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-7.2853e+00,  4.2459e-02, -1.8496e-01, -1.8496e-01, -1.8496e-01,
         -1.0248e+01,  4.0595e-01, -1.8496e-01,  5.0953e-02, -1.8496e-01,
         -1.9243e-01, -1.8496e-01, -1.8496e-01],
        [ 1.6393e+01,  1.0623e+01, -5.9821e-02, -5.9791e-02, -5.9821e-02,
          6.6170e+00, -5.4176e+00, -5.9821e-02, -7.2492e+00, -5.9821e-02,
         -2.7092e+00, -5.9821e-02, -5.9823e-02],
        [-2.5316e-01,  4.6612e-02,  1.3053e-02,  1.3053e-02,  1.3053e-02,
         -1.5772e-01, -5.8055e-01,  1.3053e-02, -1.3100e-01,  1.3053e-02,
         -6.0729e-02,  1.3053e-02,  1.3053e-02],
        [-2.5316e-01,  4.6611e-02,  1.3053e-02,  1.3053e-02,  1.3053e-02,
         -1.5772e-01, -5.8055e-01,  1.3053e-02, -1.3100e-01,  1.3053e-02,
         -6.0728e-02,  1.3053e-02,  1.3053e-02],
        [ 1.4031e+01,  9.8925e+00,  2.2832e-03,  2.2588e-03,  2.2833e-03,
          6.5846e+00, -5.6708e+00,  2.2832e-03, -7.0143e+00,  2.2835e-03,
         -2.5003e+00,  2.2834e-03,  2.2846e-03],
        [-1.4550e+01, -7.2663e+00, -3.5311e-02, -3.5305e-02, -3.5311e-02,
         -1.1168e+01,  4.7036e+00, -3.5311e-02,  6.3629e+00, -3.5311e-02,
          5.8811e-01, -3.5311e-02, -3.5311e-02],
        [-2.5316e-01,  4.6611e-02,  1.3053e-02,  1.3053e-02,  1.3053e-02,
         -1.5772e-01, -5.8055e-01,  1.3053e-02, -1.3100e-01,  1.3053e-02,
         -6.0728e-02,  1.3053e-02,  1.3053e-02],
        [-2.5316e-01,  4.6611e-02,  1.3053e-02,  1.3053e-02,  1.3053e-02,
         -1.5772e-01, -5.8055e-01,  1.3053e-02, -1.3100e-01,  1.3053e-02,
         -6.0728e-02,  1.3053e-02,  1.3053e-02],
        [-2.5316e-01,  4.6612e-02,  1.3053e-02,  1.3053e-02,  1.3053e-02,
         -1.5772e-01, -5.8055e-01,  1.3053e-02, -1.3100e-01,  1.3053e-02,
         -6.0728e-02,  1.3053e-02,  1.3053e-02],
        [-2.5316e-01,  4.6612e-02,  1.3053e-02,  1.3053e-02,  1.3053e-02,
         -1.5772e-01, -5.8055e-01,  1.3053e-02, -1.3100e-01,  1.3053e-02,
         -6.0729e-02,  1.3053e-02,  1.3053e-02],
        [ 1.6833e+00, -1.2687e+01, -1.3754e-02, -1.3747e-02, -1.3754e-02,
          4.7510e+00, -1.6332e+00, -1.3754e-02, -1.0698e+01, -1.3754e-02,
         -4.3904e+00, -1.3754e-02, -1.3754e-02],
        [ 8.5581e+00,  9.7430e+00,  5.5505e-02,  5.5496e-02,  5.5505e-02,
          6.8067e+00, -6.6311e+00,  5.5505e-02, -6.7779e+00,  5.5505e-02,
         -2.4158e+00,  5.5505e-02,  5.5505e-02],
        [-2.5316e-01,  4.6611e-02,  1.3053e-02,  1.3053e-02,  1.3053e-02,
         -1.5772e-01, -5.8055e-01,  1.3053e-02, -1.3100e-01,  1.3053e-02,
         -6.0729e-02,  1.3053e-02,  1.3053e-02]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.4204, -4.7861, -2.3941, -2.3941, -4.6416,  2.0759, -2.3941, -2.3941,
        -2.3941, -2.3941,  5.6585, -4.5893, -2.3941], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 3.4553, -9.8189,  0.2808,  0.2808, -8.0282, 16.6688,  0.2808,  0.2808,
          0.2808,  0.2808, -5.4334, -7.1699,  0.2808]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  6.8186,  -8.7477],
        [  8.3228,   7.4741],
        [  9.0908,   3.6098],
        [  9.8673,   7.4383],
        [-14.1175,  -4.2158],
        [-13.3707,  -4.3436],
        [ -1.9716,   0.2240],
        [ -1.7087,   0.2055],
        [  0.5021,   2.7283],
        [ 14.0634,  -0.2812],
        [-12.1305,   9.2815],
        [ -1.9391,   0.2989],
        [ 12.5895,   3.1639]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ -6.0658,   5.3083,  -7.6035,  -0.6138,  -1.0844,  -2.5027,  -4.9386,
         -4.8439,  -8.0822, -12.8210,   3.9538,  -4.8082,  -4.0858],
       device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 1.9116e+00, -1.2458e+00,  4.6276e+00,  1.4232e+00,  4.0136e+00,
          3.6807e+00,  7.3850e-03, -7.0957e-02, -5.8617e-03,  3.5254e+00,
          6.4366e+00, -4.1151e-02,  2.3248e+00],
        [-8.5339e+00, -3.0985e+00, -3.0793e+00,  7.9233e-01,  1.5559e+00,
          2.0818e+00,  2.6616e-01,  1.3772e-01, -2.3798e+00,  2.6526e+00,
          7.0217e+00,  2.6557e-01, -3.0367e+00],
        [-5.0675e+00, -2.7300e+00, -1.2259e+00,  8.1165e-01,  3.6145e+00,
          2.4482e+00,  4.7281e-03,  1.1205e-03, -4.2291e+00,  2.8004e+00,
          2.5258e-02, -1.2335e-05, -1.7080e+00],
        [-7.2984e+00,  1.2535e+01,  2.6375e+00,  8.4582e+00, -1.1185e+01,
         -9.3829e+00,  1.5147e-01,  2.5592e-01,  4.2476e-02,  1.5785e+01,
          6.4121e+00,  2.0574e-01,  4.5253e+00],
        [ 2.1645e+00, -2.3029e+00, -1.6677e+00, -1.3700e+01,  6.4049e+00,
          6.6502e+00,  4.5657e-01,  3.0319e-01,  4.1065e-02, -3.2821e+00,
         -1.2049e+01,  4.2266e-01, -1.6429e+00],
        [ 7.3067e+00,  3.5879e+00,  1.1437e-01,  4.7488e+00, -5.1069e+00,
         -5.6170e+00,  7.1920e-02,  7.6977e-02, -8.3460e-02,  5.0275e-01,
         -1.2005e+00,  8.2005e-02,  9.6175e-01],
        [-3.1847e+00,  1.9211e+00, -1.6555e+00,  4.3050e-01,  6.5939e+00,
          6.7384e+00,  6.9444e-01,  3.7136e-01,  2.6607e+00, -1.7991e+01,
          4.6199e+00,  6.1264e-01, -5.6763e-01],
        [-9.2649e+00, -1.7976e+00,  1.5312e-01,  1.3931e+00,  4.3567e+00,
          3.2975e+00,  8.0131e-02,  2.8014e-02, -2.5543e+00,  3.2247e+00,
         -4.0283e-01,  6.0533e-02, -7.3129e-01],
        [ 2.5747e-01, -3.1500e+01, -4.1842e-03,  2.4326e-02,  4.7257e+00,
          3.3700e+00,  5.5429e-03,  8.5138e-03,  3.8821e-03, -8.9369e+00,
         -2.8232e-01,  5.9367e-03, -1.0396e+01],
        [-6.5599e+00, -2.9962e+00, -1.3319e+00, -1.0761e+00,  4.8769e+00,
          4.4722e+00, -5.3829e-02, -5.7650e-02, -1.3395e-02,  3.8359e-01,
          3.6150e-01, -6.2656e-02, -1.5533e+00],
        [ 1.7092e+00, -4.5141e-01, -5.9465e-01,  6.7206e-01, -5.7034e+00,
         -3.3424e+00,  4.6643e-01, -5.4998e-02,  4.2932e+00,  3.7698e+00,
         -2.2016e+00,  8.8893e-02,  1.4796e-02],
        [ 1.9937e+00, -1.1463e+00,  4.2606e+00,  1.4199e+00,  4.0567e+00,
          3.5618e+00,  4.7815e-03, -6.4585e-02, -6.1011e-03,  3.4014e+00,
          6.4237e+00, -3.6405e-02,  2.4475e+00],
        [-5.0428e+00, -2.3425e+00, -3.2953e-01,  2.4678e-01,  8.8895e-01,
          2.5556e-01,  5.3166e-02,  4.5824e-02, -2.5495e+00,  2.1776e+00,
         -9.0356e-01,  6.3786e-02, -1.5392e+00]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([ 1.9050, -2.7816, -4.0120, -0.9666, -0.3927,  2.9566, -2.1972, -3.1498,
        -1.6793, -4.2354, -3.5067,  2.0042, -3.4954], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-1.7843e+00,  4.4560e+00,  4.5964e+00,  4.1781e+00, -2.2698e+01,
         -3.4191e+00,  5.5170e+00,  5.2841e+00, -1.8475e-08,  4.2395e+00,
         -4.3139e+01, -1.9609e+00,  1.1831e+00],
        [-3.4967e-01, -3.0229e+00, -2.3968e+00,  3.2504e+00, -1.0585e+00,
         -5.5307e-01, -9.9079e-02, -2.7611e+00,  1.2991e+01,  7.4720e-01,
          8.6274e-01, -5.1923e-01, -2.0800e+00],
        [-2.8572e+00, -1.1438e-02, -7.3752e-04, -2.7157e+00, -2.4506e-01,
         -2.8840e+00, -3.9707e-01, -1.4674e-02, -4.0815e-03, -7.5256e-04,
         -4.9393e-01, -2.8641e+00, -4.6166e-04],
        [-2.7508e+00, -1.7914e-02, -1.1279e-03, -2.6996e+00, -1.7828e-01,
         -2.7781e+00, -3.9274e-01, -1.8638e-02, -8.0096e-03, -1.3672e-03,
         -4.7507e-01, -2.7580e+00,  2.8868e-04],
        [ 1.7561e+00, -2.3795e-01, -1.6506e-01, -3.0123e+00,  1.5818e+00,
          2.0561e+00, -7.3057e-01,  2.5250e-01, -1.2988e+01, -1.2856e+00,
          2.7805e-01,  1.7304e+00,  1.0714e+00]], device='cuda:0'))])
xi:  [540.58014]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 893.9736303916322
W_T_median: 654.0115994977843
W_T_pctile_5: 540.6664911615923
W_T_CVAR_5_pct: 258.3840384649131
Average q (qsum/M+1):  63.725491431451616
Optimal xi:  [540.58014]
Expected(across Rb) median(across samples) p_equity:  0.23778682039895405
obj fun:  tensor(-2233.8699, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/factor_decumulation/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/factor_decumulation/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: Paper_FactorInv_Factor2
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
