Starting at: 
11-06-23_17:44

 numpy seed:  2  


 pytorch seed:  2  

Key parameters-------
paths: 256000
iterations: 20000
batchsize: 1000
remove neg:  False
w constaint activation:  yy_fix_jan29


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = MC_everything
timeseries_basket['basket_desc'] = marc_test1_all_assets_longfactors
timeseries_basket['basket_columns'] = 
['Size_Lo30_real_ret', 'Value_Hi30_real_ret', 'Oprof_Hi30_real_ret', 'Inv_Lo30_real_ret', 'Mom_Hi30_real_ret', 'EP_Hi30_real_ret', 'Vol_Lo20_real_ret', 'Div_Hi30_real_ret', 'EQWFact_real_ret', 'T30_real_ret', 'T90_real_ret', 'B10_real_ret', 'VWD_real_ret', 'EWD_real_ret']
############# End: defined asset  basket #################
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
192601                  0.0                NaN  ...     0.000561     0.023174
192602                  0.0                NaN  ...    -0.033046    -0.053510
192603                  0.0                NaN  ...    -0.064002    -0.096824
192604                  0.0                NaN  ...     0.037029     0.032975
192605                  0.0                NaN  ...     0.012095     0.001035

[5 rows x 16 columns]
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
202208                  NaN            -0.0020  ...    -0.036240    -0.011556
202209                  NaN            -0.0955  ...    -0.091324    -0.099903
202210                  NaN             0.0883  ...     0.077403     0.049863
202211                  NaN            -0.0076  ...     0.052365     0.028123
202212                  NaN            -0.0457  ...    -0.057116    -0.047241

[5 rows x 16 columns]


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = MC_everything
timeseries_basket['basket_desc'] = marc_test1_all_assets_longfactors
timeseries_basket['basket_columns'] = 
['Size_Lo30_nom_ret', 'Value_Hi30_nom_ret', 'Oprof_Hi30_nom_ret', 'Inv_Lo30_nom_ret', 'Mom_Hi30_nom_ret', 'EP_Hi30_nom_ret', 'Vol_Lo20_nom_ret', 'Div_Hi30_nom_ret', 'EQWFact_nom_ret', 'T30_nom_ret', 'T90_nom_ret', 'B10_nom_ret', 'VWD_nom_ret', 'EWD_nom_ret']
############# End: defined asset  basket #################
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                         ...                          
192607                    0.0014              0.0154  ...     0.031411     0.013051
192608                    0.0319              0.0561  ...     0.028647     0.031002
192609                   -0.0173             -0.0071  ...     0.005787    -0.006499
192610                   -0.0294             -0.0355  ...    -0.028996    -0.034630
192611                   -0.0038              0.0294  ...     0.028554     0.024776

[5 rows x 15 columns]
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                         ...                          
202208                   -0.0020             -0.0164  ...    -0.036240    -0.011556
202209                   -0.0955             -0.0871  ...    -0.091324    -0.099903
202210                    0.0883              0.1486  ...     0.077403     0.049863
202211                   -0.0076              0.0462  ...     0.052365     0.028123
202212                   -0.0457             -0.0499  ...    -0.057116    -0.047241

[5 rows x 15 columns]
Indices constructed with column names:
Index(['date_for_plt', 'Size_Lo30_nom_ret_ind', 'Value_Hi30_nom_ret_ind',
       'Oprof_Hi30_nom_ret_ind', 'Inv_Lo30_nom_ret_ind',
       'Mom_Hi30_nom_ret_ind', 'EP_Hi30_nom_ret_ind', 'Vol_Lo20_nom_ret_ind',
       'Div_Hi30_nom_ret_ind', 'EQWFact_nom_ret_ind', 'CPI_nom_ret_ind',
       'T30_nom_ret_ind', 'T90_nom_ret_ind', 'B10_nom_ret_ind',
       'VWD_nom_ret_ind', 'EWD_nom_ret_ind'],
      dtype='object')
############# Updated: defined asset basket #################
timeseries_basket['data_df_mean'] = 
Size_Lo30_real_ret     0.009939
Value_Hi30_real_ret    0.010052
Oprof_Hi30_real_ret    0.003948
Inv_Lo30_real_ret      0.004513
Mom_Hi30_real_ret      0.011386
EP_Hi30_real_ret       0.007033
Vol_Lo20_real_ret      0.003529
Div_Hi30_real_ret      0.007888
EQWFact_real_ret       0.004508
T30_real_ret           0.000229
T90_real_ret           0.000501
B10_real_ret           0.001637
VWD_real_ret           0.006759
EWD_real_ret           0.009545
dtype: float64


timeseries_basket['data_df_stdev'] = 
Size_Lo30_real_ret     0.082598
Value_Hi30_real_ret    0.072063
Oprof_Hi30_real_ret    0.037444
Inv_Lo30_real_ret      0.037639
Mom_Hi30_real_ret      0.061421
EP_Hi30_real_ret       0.041390
Vol_Lo20_real_ret      0.030737
Div_Hi30_real_ret      0.056728
EQWFact_real_ret       0.037131
T30_real_ret           0.005227
T90_real_ret           0.005373
B10_real_ret           0.019258
VWD_real_ret           0.053610
EWD_real_ret           0.071360
dtype: float64


timeseries_basket['data_df_corr'] = 
                     Size_Lo30_real_ret  ...  EWD_real_ret
Size_Lo30_real_ret             1.000000  ...      0.977206
Value_Hi30_real_ret            0.908542  ...      0.919912
Oprof_Hi30_real_ret            0.433774  ...      0.462336
Inv_Lo30_real_ret              0.455237  ...      0.479661
Mom_Hi30_real_ret              0.903222  ...      0.912002
EP_Hi30_real_ret               0.476966  ...      0.506661
Vol_Lo20_real_ret              0.360014  ...      0.382411
Div_Hi30_real_ret              0.816292  ...      0.849068
EQWFact_real_ret               0.494572  ...      0.513359
T30_real_ret                   0.014412  ...      0.029084
T90_real_ret                   0.021968  ...      0.037909
B10_real_ret                   0.012916  ...      0.024853
VWD_real_ret                   0.865290  ...      0.907369
EWD_real_ret                   0.977206  ...      1.000000

[14 rows x 14 columns]


timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names', 'data_df', 'data_df_mean', 'data_df_stdev', 'data_df_corr'])
############# End: updated: defined asset basket #################
-----------------------------------------------
Dates to be REMOVED due to missing values (should be at *start* only due to trading signals):
Int64Index([], dtype='int64')
-----------------------------------------------
Dates from available data for bootstrapping:
Start: 192607
End: 202212
-----------------------------------------------
Bootstrap block size: 6
-----------------------------------------------
Dates USED bootstrapping:
Start: 196307
End: 202212
-----------------------------------------------
0.0% of bootstrap sample done.
5.0% of bootstrap sample done.
10.0% of bootstrap sample done.
15.0% of bootstrap sample done.
20.0% of bootstrap sample done.
25.0% of bootstrap sample done.
30.0% of bootstrap sample done.
35.0% of bootstrap sample done.
40.0% of bootstrap sample done.
45.0% of bootstrap sample done.
50.0% of bootstrap sample done.
55.00000000000001% of bootstrap sample done.
60.0% of bootstrap sample done.
65.0% of bootstrap sample done.
70.0% of bootstrap sample done.
75.0% of bootstrap sample done.
80.0% of bootstrap sample done.
85.0% of bootstrap sample done.
90.0% of bootstrap sample done.
95.0% of bootstrap sample done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      22  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      22  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 22)     True          22  
2     (22, 22)     True          22  
3      (22, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer      14       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/factor_decumulation/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      22  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      22  logistic_sigmoid   
3        obj.layers[3]        3  output_layer      14           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 22)     True          22  
2     (22, 22)     True          22  
3     (22, 14)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       22  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       22  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 22)      True          22  
0     (22, 22)      True          22  
0      (22, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       22  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       22  logistic_sigmoid   
0        obj.layers[3]         3  output_layer       14           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 22)      True          22  
0     (22, 22)      True          22  
0     (22, 14)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 2000, 'itbound_SGD_algorithms': 20000, 'nit_IterateAveragingStart': 18000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       22  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       22  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 22)      True          22  
0     (22, 22)      True          22  
0      (22, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       22  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       22  logistic_sigmoid   
0        obj.layers[3]         3  output_layer       14           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 22)      True          22  
0     (22, 22)      True          22  
0     (22, 14)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -8.5715,   6.4621],
        [ -8.3669,  -9.0182],
        [ -5.1223,   3.2445],
        [  8.0669,   4.1508],
        [-11.4280,  -6.0457],
        [ -6.4858,   4.0851],
        [  6.0779,   4.9126],
        [  9.1747,   0.7713],
        [ -8.3119,   6.0846],
        [ -8.3147,   6.0977],
        [ -8.4882,   6.6116],
        [ -8.6931,   5.7529],
        [  7.8819,   3.3034],
        [ -1.2974,   1.0853],
        [  5.4594,  -0.3288],
        [  5.2299,   5.2824],
        [-11.7613,  -7.4762],
        [  7.7973,   4.2640],
        [ -8.5799,   5.8746],
        [ -7.8535,   5.7472],
        [ -1.2944,   1.0845],
        [-21.4386,  -5.7294]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ 4.8764, -5.7404, -3.0406, -9.5323, -3.7687, -2.3429, -8.4043, -9.1228,
         4.2727,  3.0356,  5.1757,  1.5461, -8.9288, -3.8883, -8.9159, -8.5427,
        -4.0692, -9.2749,  1.8685,  2.4405, -3.8889, -4.6902], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1574e-03, -1.6502e-02, -2.2728e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1088e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [-9.2453e+00,  1.2482e+01, -7.2066e-01,  7.0332e+00,  4.6981e+00,
         -1.2007e+00,  4.5523e+00,  6.2080e+00, -7.5674e+00, -3.0869e+00,
         -1.0021e+01, -1.8126e+00,  5.8578e+00, -1.6237e-01,  6.8999e-01,
          5.4520e+00,  8.4865e+00,  8.0426e+00, -2.2762e+00, -3.8127e+00,
         -1.9618e-01,  8.7135e+00],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2751e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-9.6515e+00,  1.3280e+01, -9.1434e-01,  9.3871e+00,  5.7620e+00,
         -1.3190e+00,  6.4927e+00,  6.8045e+00, -8.3770e+00, -3.3906e+00,
         -1.0939e+01, -2.1716e+00,  6.5179e+00, -2.1870e-01,  2.0491e+00,
          4.1453e+00,  9.2888e+00,  7.8384e+00, -2.6898e+00, -4.4743e+00,
         -1.9003e-01,  9.7752e+00],
        [-7.9773e+00,  1.0315e+01,  2.5895e-01,  4.6608e+00,  4.9211e+00,
          1.7041e-02,  2.1882e+00,  6.8647e+00, -6.6734e+00, -4.8263e+00,
         -8.8073e+00, -2.8795e+00,  6.4311e+00,  1.6629e-01,  1.1111e+00,
          5.0411e+00,  7.6765e+00,  1.1081e+01, -3.5739e+00, -4.0927e+00,
          1.6082e-01,  8.5887e+00],
        [-7.6589e+00,  9.2592e+00,  7.9739e-02,  3.9257e+00,  4.5700e+00,
          1.0005e-01,  2.1053e+00,  4.6166e+00, -6.0015e+00, -3.8545e+00,
         -9.2106e+00, -1.7570e+00,  5.7099e+00, -1.2986e-02,  5.9836e-02,
          4.9159e+00,  7.0161e+00,  9.4703e+00, -2.3319e+00, -3.1763e+00,
         -1.3208e-02,  7.3285e+00],
        [-2.2581e-01, -1.6549e-01,  1.7511e-03, -1.2938e-02, -1.1903e-01,
          1.1578e-03, -1.6509e-02, -2.2839e-03, -1.8738e-01, -6.9338e-02,
         -2.5288e-01, -1.2692e-02, -9.1165e-03,  1.2292e-02,  1.9855e-02,
         -1.7662e-02, -1.7966e-01, -1.2937e-02, -1.9683e-02, -4.9682e-02,
          1.2307e-02, -3.1400e-02],
        [-2.2584e-01, -1.6546e-01,  1.7508e-03, -1.2931e-02, -1.1901e-01,
          1.1573e-03, -1.6502e-02, -2.2704e-03, -1.8735e-01, -6.9322e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9856e-02,
         -1.7657e-02, -1.7959e-01, -1.2929e-02, -1.9678e-02, -4.9672e-02,
          1.2308e-02, -3.1398e-02],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2752e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2730e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1088e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [-7.4230e+00,  9.2761e+00,  8.2691e-02,  4.6883e+00,  4.4150e+00,
          1.2211e-01,  2.9895e+00,  3.5408e+00, -6.2114e+00, -3.5923e+00,
         -9.4198e+00, -1.8627e+00,  4.7011e+00, -1.9985e-02, -6.0281e-02,
          5.2032e+00,  7.0797e+00,  8.3206e+00, -2.3235e+00, -3.3515e+00,
         -1.9947e-02,  7.4397e+00],
        [ 7.9326e+00, -1.0706e+01,  4.0837e-01, -9.2089e+00, -5.7725e+00,
          6.6403e-01, -4.8629e+00, -5.8385e+00,  6.6214e+00,  5.0109e+00,
          9.6232e+00,  3.3999e+00, -5.8456e+00, -1.3669e-01, -1.4453e+00,
         -3.3601e+00, -8.4017e+00, -9.5444e+00,  3.9084e+00,  4.3412e+00,
         -1.3169e-01, -9.7519e+00],
        [-2.2583e-01, -1.6545e-01,  1.7507e-03, -1.2931e-02, -1.1900e-01,
          1.1572e-03, -1.6503e-02, -2.2678e-03, -1.8733e-01, -6.9320e-02,
         -2.5297e-01, -1.2687e-02, -9.1093e-03,  1.2293e-02,  1.9856e-02,
         -1.7657e-02, -1.7958e-01, -1.2930e-02, -1.9677e-02, -4.9670e-02,
          1.2308e-02, -3.1399e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2931e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2732e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [ 6.5891e-01,  3.0868e-01,  8.3566e-03,  3.5747e-02,  2.1159e-01,
          5.3475e-03,  5.7464e-02,  2.6629e-01,  5.5272e-01,  2.6083e-01,
          7.4008e-01,  8.5701e-02,  7.1654e-02,  3.7717e-02,  5.6900e-02,
          8.1005e-02,  2.9146e-01,  3.6840e-02,  1.1119e-01,  2.1066e-01,
          3.7716e-02,  1.3910e-01],
        [-2.2585e-01, -1.6548e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2733e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1087e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2307e-02, -3.1398e-02],
        [-7.5648e+00,  9.6323e+00,  3.4567e-02,  4.2023e+00,  4.4635e+00,
         -1.3328e-01,  2.0401e+00,  5.3264e+00, -6.2784e+00, -3.7048e+00,
         -9.3470e+00, -2.0562e+00,  5.8618e+00, -3.3635e-02,  2.0363e-01,
          5.0433e+00,  7.2814e+00,  9.5323e+00, -2.4148e+00, -3.3678e+00,
         -3.5727e-02,  7.7623e+00],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2750e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2744e-03, -1.8737e-01, -6.9326e-02,
         -2.5298e-01, -1.2689e-02, -9.1087e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2931e-02, -1.1901e-01,
          1.1574e-03, -1.6502e-02, -2.2722e-03, -1.8735e-01, -6.9324e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9673e-02,
          1.2308e-02, -3.1398e-02],
        [ 6.6450e-01,  3.1201e-01,  8.4127e-03,  3.4696e-02,  2.1235e-01,
          5.3877e-03,  5.6376e-02,  2.6891e-01,  5.5678e-01,  2.6166e-01,
          7.4701e-01,  8.5769e-02,  7.1346e-02,  3.8211e-02,  5.7275e-02,
          8.0058e-02,  2.9347e-01,  3.5786e-02,  1.1132e-01,  2.1139e-01,
          3.8209e-02,  1.3913e-01],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2753e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-2.4313,  0.0078, -2.4313,  0.0873, -0.2625, -0.5234, -2.4313, -2.4314,
        -2.4313, -2.4313, -0.4369, -0.2571, -2.4314, -2.4313,  4.5769, -2.4313,
        -0.4006, -2.4313, -2.4313, -2.4313,  4.6668, -2.4313], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[  0.0334, -10.4940,   0.0334, -15.8008,  -9.7979,  -6.9452,   0.0334,
           0.0334,   0.0334,   0.0334,  -7.0927,  14.9535,   0.0334,   0.0334,
           4.2936,   0.0334,  -7.0565,   0.0334,   0.0334,   0.0334,   4.7631,
           0.0334]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 1.0813e+01,  2.9656e+00],
        [ 5.5664e-01,  1.1757e+01],
        [ 1.8618e+01,  2.3664e+00],
        [ 1.0637e+01,  1.5273e-02],
        [-1.4941e+01, -2.2181e+00],
        [-1.2849e+00,  1.3570e+00],
        [-1.2800e+00,  1.3116e+00],
        [-1.7122e+00,  6.5637e-01],
        [-2.0284e+00,  2.5259e-01],
        [ 9.3477e+00, -5.2188e-01],
        [-1.9314e+00,  2.3251e-01],
        [-1.8788e+00,  4.0167e-01],
        [-1.0523e+01, -1.6251e+00],
        [-8.3398e+00,  5.3496e+00],
        [-7.4426e+00,  1.0247e+01],
        [-1.2446e+01, -2.8588e+00],
        [-1.4240e+01, -3.1016e+00],
        [-1.0901e+01, -2.0063e+00],
        [-1.0106e+01, -2.4687e+00],
        [ 3.1771e+00,  1.1429e+01],
        [ 1.0907e+01,  2.2476e+00],
        [ 1.1102e+01,  1.0847e+01]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-5.5365,  7.0663,  2.9709, -9.6018, -1.5848, -4.5127, -4.5185, -4.9090,
        -4.9531, -9.4875, -4.9847, -4.9560,  5.4223,  3.0397,  6.7011, -3.5168,
        -2.9913,  3.2472,  0.4201,  7.7652, -4.3018,  6.4326], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 6.1957e-01, -3.4634e+00, -1.7479e+00,  1.1905e+00,  1.2460e-02,
          1.1948e-01,  1.3226e-01,  4.3984e-02, -1.1598e-02,  1.0215e+00,
         -6.1706e-03,  2.4414e-03, -2.5313e+00,  1.1746e+00, -7.8526e-01,
         -9.2734e-03,  2.7572e-03, -2.7562e+00, -1.8971e+00, -2.6434e+00,
         -4.2419e-01,  3.0293e-02],
        [-4.6968e-01, -1.5418e-01, -2.2179e+00, -4.7229e-01, -1.4815e-02,
         -2.6861e-02, -2.4100e-02,  6.5293e-03, -1.5585e-02, -3.8766e-01,
         -1.6068e-02, -1.1227e-02, -1.0214e+00, -1.1716e-01, -1.0616e-01,
         -5.8386e-03, -7.9498e-03, -5.2026e-01, -1.9652e-01, -4.4158e-01,
         -1.2068e+00, -1.2289e+00],
        [-9.0043e-01, -3.1328e-01, -2.4749e+00, -1.0214e+00, -5.5072e-03,
         -2.2407e-02, -1.9453e-02, -7.7448e-03,  4.4606e-03, -9.3610e-01,
          4.1020e-03,  2.5876e-03, -1.2488e+00, -4.6992e-02, -9.2699e-02,
         -2.2626e-03, -3.5666e-03, -6.7176e-01, -2.4800e-01, -8.7567e-01,
         -1.3802e+00, -7.7155e-01],
        [-4.7184e-01, -1.5540e-01, -2.2143e+00, -4.7815e-01, -1.4473e-02,
         -2.7281e-02, -2.4476e-02,  6.5809e-03, -1.5495e-02, -3.9563e-01,
         -1.5975e-02, -1.1107e-02, -1.0396e+00, -1.1822e-01, -1.0605e-01,
         -5.8775e-03, -7.9716e-03, -5.2621e-01, -1.9589e-01, -4.4421e-01,
         -1.2127e+00, -1.2341e+00],
        [-4.8450e-01, -1.6921e-01, -2.2399e+00, -4.9569e-01, -1.4212e-02,
         -2.5472e-02, -2.2971e-02,  5.3544e-03, -1.0943e-02, -4.2767e-01,
         -1.1482e-02, -7.9784e-03, -1.0434e+00, -1.0826e-01, -9.0719e-02,
         -6.2509e-03, -8.3116e-03, -5.2892e-01, -2.1129e-01, -4.5420e-01,
         -1.2241e+00, -1.0613e+00],
        [ 3.0119e-01,  9.1885e-01, -1.5837e+00, -8.5542e-01, -1.1953e-02,
         -1.9274e+00, -1.8752e+00, -1.4092e+00, -5.5076e-01,  1.0780e+00,
         -4.5548e-01, -9.9188e-01, -3.9286e+00,  1.1415e+00,  2.2999e+00,
         -1.2239e-02, -1.3323e-02, -2.7068e+00, -9.7625e-01,  4.2057e-01,
         -1.0808e+00, -1.2393e+00],
        [ 2.4582e-01, -1.1721e+01,  5.7285e-01, -6.6182e+00,  3.3458e+00,
          1.7362e-01,  1.7999e-01,  2.0080e-01,  2.8786e-01, -4.5146e+00,
          2.9196e-01,  1.9339e-01,  3.6973e+00, -2.2846e+00, -8.2839e+00,
          2.5629e+00,  2.7897e+00,  3.3397e+00,  3.6998e+00, -1.2216e+01,
          1.0269e-01, -7.8724e+00],
        [-2.7710e+00,  3.8384e+00, -3.8614e+00, -5.2497e+00,  1.4955e-01,
         -5.1488e-01, -5.0931e-01, -4.0831e-01, -1.3933e-01, -4.9036e+00,
         -1.0681e-01, -2.8754e-01,  2.6586e+00,  3.1018e+00,  6.0454e+00,
          5.3721e-01,  5.1709e-01,  2.4000e+00,  1.7467e+00,  2.8980e+00,
         -1.8615e+00,  1.3298e+00],
        [ 5.3996e+00,  1.7695e+01,  2.7980e+00,  6.7002e+00, -6.8933e+00,
          1.9716e-02,  1.5955e-02,  1.6031e-02, -1.9886e-01,  4.1219e+00,
         -1.8883e-01,  2.3240e-02, -8.0362e+00,  3.0849e+00,  1.4710e+01,
         -3.3033e+00, -3.8057e+00, -7.4740e+00, -6.2744e+00,  1.9113e+01,
          5.0855e+00,  2.1580e+01],
        [-4.6054e-01, -1.5864e-01, -2.1828e+00, -4.7962e-01, -1.3132e-02,
         -2.7434e-02, -2.4527e-02,  7.6509e-03, -1.3661e-02, -3.9854e-01,
         -1.4154e-02, -9.5939e-03, -1.0591e+00, -1.2246e-01, -9.9910e-02,
         -5.2767e-03, -7.3107e-03, -5.5050e-01, -2.1282e-01, -4.5037e-01,
         -1.2105e+00, -1.2384e+00],
        [-9.3210e-01, -5.0637e-01, -2.5650e+00, -1.2297e+00,  5.1007e-03,
         -1.3266e-02, -1.0812e-02, -6.5037e-03, -1.3910e-03, -1.1288e+00,
         -1.7836e-03, -1.9456e-03, -7.9371e-01, -5.5349e-02, -8.6527e-02,
          5.2059e-03,  5.8080e-03, -8.8163e-01, -4.5943e-01, -1.6628e+00,
         -1.1149e+00, -5.6400e-01],
        [-2.8460e+00, -1.8825e+01, -9.7046e+00, -3.0631e+00,  6.2381e+00,
          2.2284e-02,  2.2216e-02,  3.8058e-02,  1.2254e-02, -4.6393e+00,
          2.0356e-03,  4.3669e-02,  7.6060e+00, -3.1393e+00, -1.1899e+01,
          2.9927e+00,  3.5772e+00,  7.5127e+00,  7.0486e+00, -2.2653e+01,
         -1.0357e+01, -2.5603e+01],
        [-4.7448e-01, -1.5413e-01, -2.2021e+00, -4.7761e-01, -1.5017e-02,
         -2.6936e-02, -2.4189e-02,  6.2971e-03, -1.5709e-02, -3.9518e-01,
         -1.6194e-02, -1.1365e-02, -1.0353e+00, -1.1675e-01, -1.0676e-01,
         -6.0131e-03, -8.0879e-03, -5.2030e-01, -1.9318e-01, -4.4328e-01,
         -1.2192e+00, -1.2259e+00],
        [-6.9231e-01,  3.0014e+00,  2.7786e+00, -1.3175e+00,  3.0620e-04,
         -1.3308e-01, -1.3059e-01, -4.6677e-03, -1.5150e-02, -1.3574e+00,
         -1.8928e-02, -2.6791e-03,  2.1880e+00, -4.4040e-01,  8.1953e-01,
         -1.8323e-02, -1.1176e-02,  1.4720e+00,  4.3629e-01,  2.4554e+00,
          8.6002e-02, -2.4341e-01],
        [ 3.0175e+00, -1.5929e-01,  3.1082e+00,  1.6836e+00, -3.7655e+00,
          1.7569e-01,  1.8810e-01,  2.3150e-01, -5.4313e-01,  3.8072e+00,
         -5.3327e-01,  1.6719e-01,  6.0672e-02, -2.5586e+00, -3.6155e+00,
         -4.5190e+00, -4.8662e+00,  1.6404e-01, -1.7814e-01, -2.9936e-01,
          2.7050e+00, -1.8862e+00],
        [-6.1343e-01, -2.0997e-01, -2.3786e+00, -7.6186e-01, -1.9840e-02,
         -3.2273e-02, -3.0458e-02, -4.7454e-03,  5.8161e-03, -6.4208e-01,
          6.0534e-03,  3.5540e-03, -1.0330e+00, -6.3106e-02, -1.0050e-01,
         -7.6629e-03, -1.3412e-02, -4.8643e-01, -1.8407e-01, -5.2743e-01,
         -1.3866e+00, -9.2565e-01],
        [ 2.3232e-01,  3.1081e+00,  2.1861e+00,  1.7924e+00,  8.3474e-01,
         -4.2057e-01, -3.7750e-01, -8.6959e-02, -6.3586e-02,  1.4179e+00,
         -6.1088e-02, -4.4329e-02,  1.9436e-01, -4.4091e-01,  1.1123e+00,
          4.9760e-01,  7.0823e-01, -1.6870e-01, -3.9429e-01, -1.1351e+00,
          1.7979e-02, -1.2019e+00],
        [-9.3911e-03, -3.8280e+00, -3.1866e-01, -2.0025e+00, -3.0075e-02,
          4.3973e-02,  5.3990e-02,  1.0353e-01,  1.4874e-01, -1.8588e+00,
          1.5683e-01,  1.3914e-01, -1.0725e-01, -2.1520e-01, -2.7783e-01,
          5.4541e-02,  7.3731e-03, -1.3880e+00, -8.0744e-01, -5.4071e+00,
         -9.3933e-01,  6.6525e-02],
        [-2.0923e+00,  1.6783e+00,  2.1031e+00, -6.6800e+00,  1.9109e-04,
         -8.2756e-01, -7.5222e-01, -4.3503e-01, -1.2713e-01, -3.5556e+00,
         -7.5366e-02, -3.3382e-01,  9.4887e+00, -1.2212e+00,  5.7869e+00,
         -6.4339e-04, -3.5999e-03,  9.1765e+00,  6.6382e+00,  6.8362e-01,
          2.7993e-01, -2.2562e+00],
        [-5.5183e+00, -1.5095e+01, -2.8824e-01, -4.9346e+00,  5.3321e+00,
          1.5448e-01,  1.5735e-01,  1.6104e-01,  5.9928e-01, -2.7075e+00,
          5.5855e-01,  1.3923e-01,  3.0535e+00,  8.4196e-01, -6.5453e+00,
          4.6053e+00,  5.0922e+00,  3.6158e+00,  3.8865e+00, -1.4997e+01,
         -2.8857e+00, -4.2056e+00],
        [ 4.0156e-01, -1.0952e+00, -1.5738e+00, -4.3123e-01, -8.5229e-03,
         -6.6402e-01, -6.0136e-01, -2.4497e-01, -5.3144e-02, -2.8255e-01,
         -5.5575e-02, -9.1214e-02, -2.1121e+00,  1.5978e+00,  1.4435e+00,
         -1.0813e-03, -1.8711e-03, -2.1573e+00, -8.6345e-01, -1.7321e+00,
         -7.5512e-01,  5.2300e-01],
        [-1.9858e+00,  2.9033e+00, -2.5269e+00, -2.1485e+00,  2.2962e+00,
         -1.4441e+00, -1.3739e+00, -7.3427e-01,  6.2891e-02,  2.1944e-01,
          6.1358e-02, -2.6440e-01,  7.4516e-02,  1.7016e+00,  3.0581e+00,
          1.5196e+00,  1.8766e+00,  6.5632e-01,  1.1298e+00,  1.3664e+00,
         -2.7325e+00, -7.5516e-01]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-1.8466, -2.2256, -2.5068, -2.1943, -2.2514, -1.8834,  0.6255, -4.9456,
        -2.2024, -2.2158, -2.5964,  0.0491, -2.2135,  3.0825,  3.0734, -2.4047,
         2.5296, -1.0040,  2.4991, -0.5295, -2.0766, -2.4070], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-1.5234e-02,  7.2296e-05, -1.5502e-04,  5.9106e-05,  9.2680e-05,
         -2.2228e-02, -7.7352e-03, -1.5990e-01, -1.5103e+00,  6.1218e-05,
         -1.5306e-04, -1.3007e-05,  6.3929e-05, -1.5060e+00, -1.5008e+00,
         -2.1007e-04, -1.4999e+00, -5.4381e-03, -6.9054e-01, -3.7369e-03,
         -4.7102e-03, -3.5212e-02],
        [-8.7292e-03, -1.4222e-03,  7.6021e-04, -1.3898e-03, -1.5771e-03,
         -1.3307e-02, -5.1882e-03, -1.0878e-01, -8.2132e-01, -1.3260e-03,
          8.8522e-04, -2.6449e-04, -1.4244e-03, -8.2289e-01, -8.1366e-01,
          5.1250e-04, -8.1735e-01,  1.2221e-03, -3.1415e-01, -6.8756e-03,
          4.4122e-03, -3.5269e-02],
        [-2.1229e-02, -5.1093e-04, -3.4543e-04, -5.1941e-04, -5.4632e-04,
         -1.8385e-02, -9.4420e-03, -1.3731e-01, -1.4218e+00, -5.2075e-04,
         -3.2211e-04,  2.3184e-05, -5.1689e-04, -1.4173e+00, -1.4127e+00,
         -3.8173e-04, -1.4125e+00, -6.1909e-03, -6.2055e-01, -3.7929e-03,
         -7.1839e-03, -2.7972e-02],
        [-9.4172e-03, -2.1938e-04, -2.2482e-04, -2.0759e-04, -2.8288e-04,
         -1.6622e-02, -7.4112e-03, -1.3137e-01, -1.2415e+00, -2.0252e-04,
         -2.1593e-04, -7.4338e-05, -2.1553e-04, -1.2385e+00, -1.2343e+00,
         -1.4845e-04, -1.2328e+00, -5.0361e-03, -5.7108e-01, -3.7365e-03,
         -7.0540e-03, -2.5170e-02],
        [-1.0969e+00,  7.0714e-02,  2.8031e-01,  4.2693e-02,  2.8583e-01,
          5.4877e-01,  3.6379e+00, -1.3225e+00, -3.0535e+00,  2.8854e-01,
          9.2331e-01, -1.4907e+01,  2.7428e-02,  3.6135e+00,  3.4661e+00,
         -2.3553e-02,  3.3911e+00,  1.2464e+00,  2.0600e+00,  5.6362e+00,
         -4.8358e-01,  4.4222e-01],
        [-1.1325e-02, -1.4138e-04,  1.4500e-04, -1.5008e-04, -1.0196e-03,
         -8.7395e-03, -5.0212e-04, -1.4891e-01, -9.6424e-01, -1.5847e-04,
          8.4481e-05, -6.7668e-04, -1.4540e-04, -9.6261e-01, -9.4804e-01,
         -9.4017e-05, -9.5700e-01,  4.4294e-03, -4.5741e-01, -5.5136e-03,
          2.2288e-03, -3.6784e-02],
        [-2.4271e-02, -7.7962e-04, -2.2040e-04, -7.9007e-04, -5.4691e-04,
         -1.4880e-02, -9.2166e-03, -1.1032e-01, -1.2944e+00, -7.8678e-04,
         -1.4609e-04, -3.3668e-05, -7.9327e-04, -1.2897e+00, -1.2879e+00,
         -3.7474e-04, -1.2861e+00, -9.7262e-03, -5.3746e-01, -3.8536e-03,
         -1.0548e-02, -2.4508e-02],
        [ 3.9237e+00, -6.2937e-02,  8.2976e-01, -8.9553e-02,  1.8773e-01,
          2.5280e+00,  4.4063e+00, -5.1176e-01,  2.7121e+00,  1.5038e-01,
          2.1898e+00, -6.3975e+00, -1.0291e-01,  9.8757e-01,  1.1535e+00,
          5.7770e-02,  9.4780e-01,  2.9512e+00,  2.3504e+00,  1.6411e+00,
          3.1498e+00,  1.2727e-01],
        [-1.4494e-02, -1.9430e-04, -1.7724e-04, -2.0127e-04, -2.0117e-04,
         -1.5493e-02, -8.1680e-03, -1.3258e-01, -1.3345e+00, -2.0053e-04,
         -1.8098e-04, -1.8463e-05, -1.9899e-04, -1.3303e+00, -1.3262e+00,
         -2.7675e-04, -1.3255e+00, -6.2074e-03, -5.8710e-01, -4.1919e-03,
         -7.5895e-03, -2.9301e-02],
        [-2.1892e-02, -3.5780e-04, -4.8405e-04, -3.6317e-04, -3.6356e-04,
         -2.3657e-02, -1.6951e-02, -9.6588e-02, -1.1849e+00, -3.5150e-04,
         -4.0838e-04, -1.7243e-05, -3.6464e-04, -1.1843e+00, -1.1795e+00,
         -3.3804e-04, -1.1790e+00, -7.4055e-03, -5.7283e-01, -5.4422e-03,
         -1.0076e-02, -3.1398e-02],
        [-2.3028e+00, -2.1890e-02, -8.3502e-03, -5.3786e-02,  9.5685e-02,
         -8.9290e-01, -1.4767e+01,  7.5055e+00,  3.0752e+00,  1.1812e-01,
         -7.0438e-02,  2.1906e-03, -5.7019e-02, -7.6423e-01, -1.3833e+00,
         -7.3209e-03, -7.3795e-01, -2.2229e+00,  1.8670e+00, -1.4910e+01,
         -1.6032e+00,  1.4609e+00],
        [ 2.4319e+00,  1.1747e-01, -1.6596e-01,  8.9778e-02,  3.1240e-01,
         -1.2941e+00, -9.2455e-01, -5.3120e-01,  5.2163e+00,  3.3676e-01,
         -2.0670e-01,  2.2187e+01,  7.3275e-02,  3.7788e-01,  7.5700e-01,
         -1.2275e-01,  4.8364e-01, -2.5823e+00,  1.5965e+00, -2.2668e+00,
         -6.5383e-01, -2.8611e+00],
        [-2.1115e-02, -3.0744e-04, -1.4460e-04, -2.9289e-04, -3.5131e-04,
         -2.2539e-02, -1.0971e-02, -1.5511e-01, -1.5086e+00, -2.8377e-04,
         -1.2594e-04,  2.8039e-05, -3.0274e-04, -1.5044e+00, -1.4994e+00,
         -3.7557e-04, -1.4986e+00, -6.5951e-03, -6.8458e-01, -3.5928e-03,
         -7.8039e-03, -3.0722e-02],
        [-1.4210e-02,  2.7210e-04, -1.6876e-04,  2.6752e-04,  2.9104e-04,
         -2.2712e-02, -5.7647e-03, -1.5704e-01, -1.4740e+00,  2.7486e-04,
         -1.6774e-04, -4.4364e-05,  2.6776e-04, -1.4699e+00, -1.4648e+00,
         -1.4749e-04, -1.4640e+00, -5.0059e-03, -6.6920e-01, -3.9010e-03,
         -5.3125e-03, -3.3932e-02]], device='cuda:0'))])
loaded xi:  855.6613
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857
 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857
 0.07142857 0.07142857]
W_T_mean: 8576.841924009083
W_T_median: 5042.380921625826
W_T_pctile_5: 103.64169553244135
W_T_CVAR_5_pct: -371.9331258181762
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1802.434748742596
Current xi:  [841.41895]
objective value function right now is: -1802.434748742596
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1803.123775682906
Current xi:  [826.3942]
objective value function right now is: -1803.123775682906
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1804.1119113995233
Current xi:  [810.9699]
objective value function right now is: -1804.1119113995233
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -1805.1272992483407
Current xi:  [795.5538]
objective value function right now is: -1805.1272992483407
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1805.9609253672352
Current xi:  [780.71094]
objective value function right now is: -1805.9609253672352
12.0% of gradient descent iterations done. Method = Adam
new min fval:  -1807.0431190763616
Current xi:  [765.98975]
objective value function right now is: -1807.0431190763616
14.000000000000002% of gradient descent iterations done. Method = Adam
new min fval:  -1807.2797845650018
Current xi:  [751.05963]
objective value function right now is: -1807.2797845650018
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [736.16394]
objective value function right now is: -1806.4916405263039
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [721.2686]
objective value function right now is: -1806.8012641550959
20.0% of gradient descent iterations done. Method = Adam
new min fval:  -1809.0629897656238
Current xi:  [706.48865]
objective value function right now is: -1809.0629897656238
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [691.97455]
objective value function right now is: -1808.2808639010764
24.0% of gradient descent iterations done. Method = Adam
new min fval:  -1809.4382400773186
Current xi:  [677.15875]
objective value function right now is: -1809.4382400773186
26.0% of gradient descent iterations done. Method = Adam
new min fval:  -1811.5272290688026
Current xi:  [662.60846]
objective value function right now is: -1811.5272290688026
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [648.31683]
objective value function right now is: -1811.4562641287905
30.0% of gradient descent iterations done. Method = Adam
new min fval:  -1811.6865129474877
Current xi:  [633.7467]
objective value function right now is: -1811.6865129474877
32.0% of gradient descent iterations done. Method = Adam
new min fval:  -1812.733877747066
Current xi:  [619.26514]
objective value function right now is: -1812.733877747066
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [605.0607]
objective value function right now is: -1812.4064014247901
36.0% of gradient descent iterations done. Method = Adam
new min fval:  -1814.3592085095659
Current xi:  [590.5211]
objective value function right now is: -1814.3592085095659
38.0% of gradient descent iterations done. Method = Adam
new min fval:  -1814.3715503711153
Current xi:  [575.9014]
objective value function right now is: -1814.3715503711153
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [561.36536]
objective value function right now is: -1811.4585331534079
42.0% of gradient descent iterations done. Method = Adam
new min fval:  -1815.6472042160742
Current xi:  [546.94855]
objective value function right now is: -1815.6472042160742
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [532.6294]
objective value function right now is: -1815.1050268018748
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [518.374]
objective value function right now is: -1814.689399182618
48.0% of gradient descent iterations done. Method = Adam
new min fval:  -1815.7459448731013
Current xi:  [504.25308]
objective value function right now is: -1815.7459448731013
50.0% of gradient descent iterations done. Method = Adam
new min fval:  -1817.4450124764965
Current xi:  [490.36877]
objective value function right now is: -1817.4450124764965
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [476.0632]
objective value function right now is: -1817.2546028616773
54.0% of gradient descent iterations done. Method = Adam
new min fval:  -1817.5695415682144
Current xi:  [461.89554]
objective value function right now is: -1817.5695415682144
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [448.12378]
objective value function right now is: -1817.1146331462182
57.99999999999999% of gradient descent iterations done. Method = Adam
new min fval:  -1818.3988673086267
Current xi:  [434.1931]
objective value function right now is: -1818.3988673086267
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [420.04996]
objective value function right now is: -1817.766975143499
62.0% of gradient descent iterations done. Method = Adam
new min fval:  -1819.1412241687965
Current xi:  [406.1268]
objective value function right now is: -1819.1412241687965
64.0% of gradient descent iterations done. Method = Adam
new min fval:  -1819.9189880180884
Current xi:  [392.59747]
objective value function right now is: -1819.9189880180884
66.0% of gradient descent iterations done. Method = Adam
new min fval:  -1820.513644762714
Current xi:  [378.9258]
objective value function right now is: -1820.513644762714
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [365.0521]
objective value function right now is: -1819.8786877311277
70.0% of gradient descent iterations done. Method = Adam
new min fval:  -1821.0572718057724
Current xi:  [351.41254]
objective value function right now is: -1821.0572718057724
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -1821.6132084024136
Current xi:  [348.63052]
objective value function right now is: -1821.6132084024136
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -1821.6600786923786
Current xi:  [345.83807]
objective value function right now is: -1821.6600786923786
76.0% of gradient descent iterations done. Method = Adam
new min fval:  -1821.6975218048237
Current xi:  [343.072]
objective value function right now is: -1821.6975218048237
78.0% of gradient descent iterations done. Method = Adam
new min fval:  -1821.7401315917482
Current xi:  [340.23187]
objective value function right now is: -1821.7401315917482
80.0% of gradient descent iterations done. Method = Adam
new min fval:  -1821.9091845043913
Current xi:  [337.31265]
objective value function right now is: -1821.9091845043913
82.0% of gradient descent iterations done. Method = Adam
new min fval:  -1822.027617142184
Current xi:  [334.36426]
objective value function right now is: -1822.027617142184
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [331.39777]
objective value function right now is: -1821.9548352681531
86.0% of gradient descent iterations done. Method = Adam
new min fval:  -1822.1803554644935
Current xi:  [328.51514]
objective value function right now is: -1822.1803554644935
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [325.58484]
objective value function right now is: -1822.140081761922
new min fval from sgd:  -1822.2108923854219
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [322.63788]
objective value function right now is: -1822.2108923854219
new min fval from sgd:  -1822.276422920429
new min fval from sgd:  -1822.347168316086
new min fval from sgd:  -1822.3495431219058
new min fval from sgd:  -1822.3500432932526
new min fval from sgd:  -1822.3869418931981
new min fval from sgd:  -1822.3919166169935
new min fval from sgd:  -1822.415809685751
new min fval from sgd:  -1822.44851967188
new min fval from sgd:  -1822.453192939429
new min fval from sgd:  -1822.4654970066404
new min fval from sgd:  -1822.4755954891655
new min fval from sgd:  -1822.4803437140995
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [319.6906]
objective value function right now is: -1822.3745855628538
new min fval from sgd:  -1822.4874176681237
new min fval from sgd:  -1822.5047003156994
new min fval from sgd:  -1822.510946455775
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [316.84558]
objective value function right now is: -1822.4009135911208
new min fval from sgd:  -1822.5195181802774
new min fval from sgd:  -1822.5197019571688
new min fval from sgd:  -1822.5312146660028
new min fval from sgd:  -1822.542690951102
new min fval from sgd:  -1822.546213297607
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [313.92123]
objective value function right now is: -1822.3536232821234
new min fval from sgd:  -1822.5568755045633
new min fval from sgd:  -1822.576649032583
new min fval from sgd:  -1822.5772361034167
new min fval from sgd:  -1822.5793074843516
new min fval from sgd:  -1822.584720844192
new min fval from sgd:  -1822.5917326405738
new min fval from sgd:  -1822.6030643127735
new min fval from sgd:  -1822.6069202195513
new min fval from sgd:  -1822.6089597066286
new min fval from sgd:  -1822.6112957205391
new min fval from sgd:  -1822.613661845451
new min fval from sgd:  -1822.61655364384
new min fval from sgd:  -1822.6173354795985
new min fval from sgd:  -1822.6179297626197
new min fval from sgd:  -1822.6205898959097
new min fval from sgd:  -1822.6218776401827
new min fval from sgd:  -1822.6230393374522
new min fval from sgd:  -1822.6244629071193
new min fval from sgd:  -1822.6264074134992
new min fval from sgd:  -1822.6286315928212
new min fval from sgd:  -1822.6316280104786
new min fval from sgd:  -1822.6345701180246
new min fval from sgd:  -1822.638100164926
new min fval from sgd:  -1822.6396605883767
new min fval from sgd:  -1822.640592909613
new min fval from sgd:  -1822.6423682668396
new min fval from sgd:  -1822.643413901316
new min fval from sgd:  -1822.6438207458336
new min fval from sgd:  -1822.6441800908015
new min fval from sgd:  -1822.644479246399
new min fval from sgd:  -1822.645287574092
new min fval from sgd:  -1822.646154365384
new min fval from sgd:  -1822.6475540059535
new min fval from sgd:  -1822.6492601976545
new min fval from sgd:  -1822.64998168607
new min fval from sgd:  -1822.651037794143
new min fval from sgd:  -1822.6532047222197
new min fval from sgd:  -1822.6538341058279
new min fval from sgd:  -1822.6545800385904
new min fval from sgd:  -1822.6581410184735
new min fval from sgd:  -1822.6621076119236
new min fval from sgd:  -1822.6677753026677
new min fval from sgd:  -1822.6725353602956
new min fval from sgd:  -1822.6769060188021
new min fval from sgd:  -1822.6797948319
new min fval from sgd:  -1822.6808057864362
new min fval from sgd:  -1822.6808290271895
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [312.167]
objective value function right now is: -1822.6267868788957
new min fval from sgd:  -1822.6820101174605
new min fval from sgd:  -1822.685064829311
new min fval from sgd:  -1822.6868251670985
new min fval from sgd:  -1822.688177064875
new min fval from sgd:  -1822.6892567377863
new min fval from sgd:  -1822.6909352233172
new min fval from sgd:  -1822.6924305405755
new min fval from sgd:  -1822.6934665567458
new min fval from sgd:  -1822.693949838112
new min fval from sgd:  -1822.6945136792212
new min fval from sgd:  -1822.6973769835045
new min fval from sgd:  -1822.6977450275222
new min fval from sgd:  -1822.701031813817
new min fval from sgd:  -1822.7027529660863
new min fval from sgd:  -1822.7030072938762
new min fval from sgd:  -1822.703220488532
new min fval from sgd:  -1822.7034818668658
new min fval from sgd:  -1822.704328713276
new min fval from sgd:  -1822.7043612132961
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [311.59164]
objective value function right now is: -1822.6162592584742
min fval:  -1822.7043612132961
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -0.6783,   8.5742],
        [-12.3049,  -6.0366],
        [ -0.2602,   1.0796],
        [ -0.2602,   1.0796],
        [-10.9232,  -5.1457],
        [ -0.2602,   1.0796],
        [ -0.2602,   1.0796],
        [ -0.2602,   1.0796],
        [ -0.1836,   8.1312],
        [  3.4577,   6.6262],
        [  0.4805,   8.1837],
        [ -0.2602,   1.0796],
        [ -0.2602,   1.0796],
        [ -0.2602,   1.0796],
        [  5.9152,  -3.8141],
        [ -0.2602,   1.0796],
        [-13.2102,  -6.2372],
        [ -0.2602,   1.0796],
        [ -0.2602,   1.0796],
        [  1.3603,   5.1454],
        [ -0.2602,   1.0796],
        [-14.3336,  -7.7900]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([  6.4194,  -4.6591,  -1.2189,  -1.2189,  -2.9290,  -1.2189,  -1.2189,
         -1.2189,   5.9624,   4.1015,   6.0670,  -1.2189,  -1.2189,  -1.2189,
        -13.4298,  -1.2189,  -2.9951,  -1.2189,  -1.2189,   1.8167,  -1.2189,
         -1.0059], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-1.6854e-02, -1.7118e-02, -8.4453e-03, -8.4453e-03, -3.5940e-02,
         -8.4453e-03, -8.4453e-03, -8.4453e-03, -1.7219e-02, -4.8219e-02,
         -2.1636e-02, -8.4453e-03, -8.4453e-03, -8.4453e-03,  1.4574e-02,
         -8.4453e-03, -4.7103e-02, -8.4453e-03, -8.4453e-03, -3.9548e-03,
         -8.4453e-03, -2.4816e-01],
        [-5.2895e+00,  1.8901e+00, -7.6282e-03, -7.6263e-03,  2.3499e+00,
         -7.6283e-03, -7.6277e-03, -7.6208e-03, -4.5023e+00, -2.8956e+00,
         -6.1966e+00, -7.6280e-03, -7.6262e-03, -7.6282e-03, -7.0979e+00,
         -7.6279e-03,  4.0857e+00, -7.6260e-03, -7.6238e-03, -9.0455e-01,
         -7.6281e-03,  4.1609e+00],
        [-1.6854e-02, -1.7118e-02, -8.4453e-03, -8.4453e-03, -3.5940e-02,
         -8.4453e-03, -8.4453e-03, -8.4454e-03, -1.7219e-02, -4.8219e-02,
         -2.1636e-02, -8.4453e-03, -8.4453e-03, -8.4453e-03,  1.4574e-02,
         -8.4453e-03, -4.7103e-02, -8.4453e-03, -8.4453e-03, -3.9548e-03,
         -8.4453e-03, -2.4816e-01],
        [-8.4193e+00,  4.1456e+00,  8.8587e-03,  8.8569e-03,  3.7933e+00,
          8.8588e-03,  8.8580e-03,  8.8549e-03, -7.3245e+00, -4.2099e+00,
         -9.3796e+00,  8.8588e-03,  8.8567e-03,  8.8570e-03, -1.0157e+01,
          8.8583e-03,  6.2419e+00,  8.8562e-03,  8.8514e-03, -1.7518e+00,
          8.8570e-03,  5.9364e+00],
        [-3.4435e+00,  8.7504e-01, -1.1701e-03, -1.1698e-03,  1.6098e+00,
         -1.1701e-03, -1.1700e-03, -1.1686e-03, -2.9897e+00, -2.1479e+00,
         -4.2561e+00, -1.1701e-03, -1.1697e-03, -1.1702e-03, -4.8557e+00,
         -1.1700e-03,  2.6867e+00, -1.1697e-03, -1.1693e-03, -4.9288e-01,
         -1.1701e-03,  3.1955e+00],
        [-1.6854e-02, -1.7118e-02, -8.4454e-03, -8.4453e-03, -3.5940e-02,
         -8.4453e-03, -8.4453e-03, -8.4453e-03, -1.7219e-02, -4.8219e-02,
         -2.1636e-02, -8.4453e-03, -8.4453e-03, -8.4453e-03,  1.4574e-02,
         -8.4453e-03, -4.7103e-02, -8.4453e-03, -8.4453e-03, -3.9548e-03,
         -8.4453e-03, -2.4816e-01],
        [-1.6854e-02, -1.7118e-02, -8.4453e-03, -8.4453e-03, -3.5940e-02,
         -8.4453e-03, -8.4453e-03, -8.4454e-03, -1.7219e-02, -4.8219e-02,
         -2.1636e-02, -8.4453e-03, -8.4453e-03, -8.4453e-03,  1.4574e-02,
         -8.4454e-03, -4.7103e-02, -8.4453e-03, -8.4453e-03, -3.9548e-03,
         -8.4453e-03, -2.4816e-01],
        [-1.6854e-02, -1.7118e-02, -8.4453e-03, -8.4453e-03, -3.5940e-02,
         -8.4453e-03, -8.4453e-03, -8.4453e-03, -1.7219e-02, -4.8219e-02,
         -2.1636e-02, -8.4453e-03, -8.4453e-03, -8.4453e-03,  1.4574e-02,
         -8.4453e-03, -4.7103e-02, -8.4453e-03, -8.4453e-03, -3.9548e-03,
         -8.4453e-03, -2.4816e-01],
        [-1.6854e-02, -1.7118e-02, -8.4453e-03, -8.4453e-03, -3.5940e-02,
         -8.4453e-03, -8.4453e-03, -8.4453e-03, -1.7219e-02, -4.8219e-02,
         -2.1636e-02, -8.4454e-03, -8.4453e-03, -8.4453e-03,  1.4574e-02,
         -8.4453e-03, -4.7103e-02, -8.4453e-03, -8.4453e-03, -3.9548e-03,
         -8.4453e-03, -2.4816e-01],
        [-1.6854e-02, -1.7118e-02, -8.4453e-03, -8.4453e-03, -3.5940e-02,
         -8.4453e-03, -8.4453e-03, -8.4453e-03, -1.7219e-02, -4.8219e-02,
         -2.1636e-02, -8.4453e-03, -8.4453e-03, -8.4453e-03,  1.4574e-02,
         -8.4453e-03, -4.7103e-02, -8.4453e-03, -8.4453e-03, -3.9548e-03,
         -8.4453e-03, -2.4816e-01],
        [-1.6854e-02, -1.7118e-02, -8.4453e-03, -8.4453e-03, -3.5940e-02,
         -8.4453e-03, -8.4453e-03, -8.4453e-03, -1.7219e-02, -4.8219e-02,
         -2.1636e-02, -8.4453e-03, -8.4453e-03, -8.4453e-03,  1.4574e-02,
         -8.4453e-03, -4.7103e-02, -8.4453e-03, -8.4453e-03, -3.9548e-03,
         -8.4453e-03, -2.4816e-01],
        [ 7.7795e+00, -3.4670e+00,  7.9719e-03,  7.9713e-03, -3.6820e+00,
          7.9719e-03,  7.9715e-03,  7.9727e-03,  6.7569e+00,  4.2613e+00,
          8.7706e+00,  7.9721e-03,  7.9711e-03,  7.9702e-03,  1.0252e+01,
          7.9716e-03, -5.7146e+00,  7.9708e-03,  7.9674e-03,  1.7196e+00,
          7.9702e-03, -5.5524e+00],
        [-1.6854e-02, -1.7118e-02, -8.4453e-03, -8.4453e-03, -3.5940e-02,
         -8.4453e-03, -8.4453e-03, -8.4453e-03, -1.7219e-02, -4.8219e-02,
         -2.1636e-02, -8.4454e-03, -8.4453e-03, -8.4453e-03,  1.4574e-02,
         -8.4453e-03, -4.7103e-02, -8.4453e-03, -8.4453e-03, -3.9548e-03,
         -8.4453e-03, -2.4816e-01],
        [-1.6854e-02, -1.7118e-02, -8.4453e-03, -8.4453e-03, -3.5940e-02,
         -8.4453e-03, -8.4453e-03, -8.4453e-03, -1.7219e-02, -4.8219e-02,
         -2.1636e-02, -8.4453e-03, -8.4453e-03, -8.4453e-03,  1.4574e-02,
         -8.4453e-03, -4.7103e-02, -8.4453e-03, -8.4453e-03, -3.9548e-03,
         -8.4453e-03, -2.4816e-01],
        [ 2.8860e-01,  3.6230e-02,  6.1762e-02,  6.1762e-02,  1.3124e-01,
          6.1762e-02,  6.1762e-02,  6.1762e-02,  2.7954e-01,  3.1503e-01,
          3.0952e-01,  6.1762e-02,  6.1762e-02,  6.1762e-02,  3.0259e-01,
          6.1762e-02,  1.7184e-01,  6.1762e-02,  6.1762e-02,  7.5289e-02,
          6.1762e-02,  6.2648e-01],
        [-1.6854e-02, -1.7118e-02, -8.4453e-03, -8.4453e-03, -3.5940e-02,
         -8.4453e-03, -8.4453e-03, -8.4454e-03, -1.7219e-02, -4.8219e-02,
         -2.1636e-02, -8.4453e-03, -8.4453e-03, -8.4453e-03,  1.4574e-02,
         -8.4453e-03, -4.7103e-02, -8.4453e-03, -8.4453e-03, -3.9548e-03,
         -8.4453e-03, -2.4816e-01],
        [-1.6854e-02, -1.7118e-02, -8.4453e-03, -8.4453e-03, -3.5940e-02,
         -8.4453e-03, -8.4454e-03, -8.4453e-03, -1.7219e-02, -4.8219e-02,
         -2.1636e-02, -8.4453e-03, -8.4454e-03, -8.4454e-03,  1.4574e-02,
         -8.4453e-03, -4.7103e-02, -8.4453e-03, -8.4453e-03, -3.9548e-03,
         -8.4454e-03, -2.4816e-01],
        [-1.6854e-02, -1.7118e-02, -8.4453e-03, -8.4453e-03, -3.5940e-02,
         -8.4453e-03, -8.4453e-03, -8.4453e-03, -1.7219e-02, -4.8219e-02,
         -2.1636e-02, -8.4453e-03, -8.4453e-03, -8.4454e-03,  1.4574e-02,
         -8.4453e-03, -4.7103e-02, -8.4453e-03, -8.4453e-03, -3.9548e-03,
         -8.4453e-03, -2.4816e-01],
        [-1.6854e-02, -1.7118e-02, -8.4453e-03, -8.4453e-03, -3.5940e-02,
         -8.4453e-03, -8.4453e-03, -8.4453e-03, -1.7219e-02, -4.8219e-02,
         -2.1636e-02, -8.4453e-03, -8.4453e-03, -8.4453e-03,  1.4574e-02,
         -8.4453e-03, -4.7103e-02, -8.4453e-03, -8.4453e-03, -3.9548e-03,
         -8.4453e-03, -2.4816e-01],
        [-1.6854e-02, -1.7118e-02, -8.4453e-03, -8.4453e-03, -3.5940e-02,
         -8.4453e-03, -8.4453e-03, -8.4453e-03, -1.7219e-02, -4.8219e-02,
         -2.1636e-02, -8.4453e-03, -8.4453e-03, -8.4453e-03,  1.4574e-02,
         -8.4453e-03, -4.7103e-02, -8.4453e-03, -8.4453e-03, -3.9548e-03,
         -8.4453e-03, -2.4816e-01],
        [ 2.8912e-01,  3.5869e-02,  6.3622e-02,  6.3622e-02,  1.3084e-01,
          6.3623e-02,  6.3623e-02,  6.3622e-02,  2.8019e-01,  3.2202e-01,
          3.1061e-01,  6.3623e-02,  6.3622e-02,  6.3623e-02,  3.0906e-01,
          6.3623e-02,  1.7102e-01,  6.3623e-02,  6.3623e-02,  7.5972e-02,
          6.3623e-02,  6.4304e-01],
        [-1.6854e-02, -1.7118e-02, -8.4453e-03, -8.4453e-03, -3.5940e-02,
         -8.4453e-03, -8.4453e-03, -8.4453e-03, -1.7219e-02, -4.8219e-02,
         -2.1636e-02, -8.4454e-03, -8.4453e-03, -8.4454e-03,  1.4574e-02,
         -8.4453e-03, -4.7103e-02, -8.4453e-03, -8.4453e-03, -3.9548e-03,
         -8.4453e-03, -2.4816e-01]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.5666, -0.4967, -0.5666, -0.4472, -0.6657, -0.5666, -0.5666, -0.5666,
        -0.5666, -0.5666, -0.5666,  0.2678, -0.5666, -0.5666,  2.3415, -0.5666,
        -0.5666, -0.5666, -0.5666, -0.5666,  2.4203, -0.5666], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[  0.0376,  -7.9977,   0.0376, -14.3648,  -4.8345,   0.0376,   0.0376,
           0.0376,   0.0376,   0.0376,   0.0376,  14.6676,   0.0376,   0.0376,
           2.9122,   0.0376,   0.0376,   0.0376,   0.0376,   0.0376,   3.2027,
           0.0376]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -1.1652,   0.6857],
        [  2.9752,  12.3551],
        [  1.6081,   0.5880],
        [ 12.3692,   0.2001],
        [ -2.4312,   3.9179],
        [ -1.1723,   0.6868],
        [ -1.1723,   0.6868],
        [ -1.1723,   0.6868],
        [ -1.1723,   0.6868],
        [  9.2522,  -1.2510],
        [ -1.1723,   0.6868],
        [ -1.1723,   0.6868],
        [ -8.7646,   0.3999],
        [ -4.9958,   6.3723],
        [ -1.8544,  10.4627],
        [ -1.5200,  -0.6562],
        [ -1.5137,  -0.6680],
        [-10.9508,  -1.6935],
        [-11.2996,  -3.3958],
        [  5.4518,  12.7262],
        [  8.8120,   0.4331],
        [ 14.4654,  10.6018]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ -2.4268,   9.0746,   4.3198, -11.6355,  -2.7162,  -2.4172,  -2.4172,
         -2.4172,  -2.4172, -11.6907,  -2.4172,  -2.4172,   6.5833,   4.1634,
          7.4686,  -3.8851,  -3.9419,   4.1866,  -1.0314,   9.1769,  -5.4990,
          6.6007], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-5.4256e-02, -1.7736e+00, -1.4629e+00,  1.8922e+00, -2.3472e-01,
         -5.0145e-02, -5.0145e-02, -5.0145e-02, -5.0145e-02,  8.2056e-01,
         -5.0145e-02, -5.0145e-02, -2.5086e+00, -1.2807e+00, -8.5121e-01,
         -8.0797e-01, -8.3296e-01, -2.4237e+00, -1.3845e+00, -2.6046e+00,
          7.4337e-02,  1.8608e+00],
        [-5.8966e-02, -8.1766e-01, -2.7673e+00, -5.8376e-01, -1.1719e-02,
         -5.9293e-02, -5.9293e-02, -5.9293e-02, -5.9293e-02,  1.3743e+00,
         -5.9293e-02, -5.9293e-02, -1.4388e+00, -3.4021e-01, -5.0371e-01,
          1.9439e+00,  1.9265e+00,  5.4699e-01,  1.2128e+00, -8.6366e-01,
         -1.2434e+00, -1.1909e+00],
        [-2.4316e-02, -3.9820e-01, -1.0568e+00, -2.0977e-01,  1.0634e-03,
         -2.4340e-02, -2.4340e-02, -2.4340e-02, -2.4340e-02, -6.0062e-01,
         -2.4340e-02, -2.4340e-02, -4.0042e-01,  9.8304e-03, -1.6532e-01,
         -4.8161e-01, -4.8121e-01, -6.4096e-01, -4.9036e-01, -5.1388e-01,
         -7.0732e-01, -9.4400e-01],
        [-5.9802e-02, -8.1358e-01, -2.6960e+00, -5.5897e-01, -1.0871e-02,
         -6.0122e-02, -6.0122e-02, -6.0122e-02, -6.0122e-02,  1.3777e+00,
         -6.0122e-02, -6.0122e-02, -1.4184e+00, -3.3196e-01, -4.9348e-01,
          1.8973e+00,  1.8855e+00,  5.4245e-01,  1.1918e+00, -8.6132e-01,
         -1.2019e+00, -1.2173e+00],
        [-2.4316e-02, -3.9820e-01, -1.0568e+00, -2.0977e-01,  1.0627e-03,
         -2.4340e-02, -2.4340e-02, -2.4340e-02, -2.4340e-02, -6.0062e-01,
         -2.4340e-02, -2.4340e-02, -4.0042e-01,  9.8303e-03, -1.6532e-01,
         -4.8161e-01, -4.8121e-01, -6.4096e-01, -4.9036e-01, -5.1388e-01,
         -7.0732e-01, -9.4400e-01],
        [-1.2401e-02,  1.8927e-01, -1.8744e+00, -5.9587e-01, -3.3255e-01,
          4.1558e-03,  4.1556e-03,  4.1557e-03,  4.1564e-03,  6.8002e-01,
          4.1564e-03,  4.1566e-03,  1.8018e-02,  1.0779e+00,  1.6795e+00,
          5.3426e-01,  5.7534e-01,  2.6474e+00,  2.2944e+00, -2.7947e-01,
         -2.2493e+00, -2.1301e+00],
        [-3.8730e-02, -1.0950e+01,  1.3493e+00, -7.7669e+00, -5.3536e-02,
         -3.8864e-02, -3.8864e-02, -3.8864e-02, -3.8864e-02, -3.4741e+00,
         -3.8863e-02, -3.8863e-02,  4.1553e+00, -2.0689e+00, -7.5714e+00,
          1.1235e+00,  1.0568e+00,  2.5570e+00,  4.4594e+00, -9.6056e+00,
          5.2700e-01, -3.5792e+00],
        [ 1.1259e-02,  4.7705e+00, -3.8068e+00, -4.2248e+00, -1.4780e-01,
          1.2720e-02,  1.2720e-02,  1.2720e-02,  1.2721e-02, -1.5580e+00,
          1.2721e-02,  1.2721e-02,  1.5928e+00,  2.3368e+00,  2.2756e+00,
         -1.8245e-01, -2.0923e-01,  2.7839e+00, -1.0812e+00,  4.1438e+00,
         -2.9262e+00,  2.1776e+00],
        [-5.5689e-02,  1.2136e+01,  7.5207e-01,  4.2608e+00,  2.7590e-02,
         -6.7693e-02, -6.7693e-02, -6.7693e-02, -6.7694e-02,  4.1884e+00,
         -6.7694e-02, -6.7694e-02, -7.2005e+00,  1.5835e+00,  7.5828e+00,
         -4.4943e-02,  3.7956e-03, -6.4212e+00, -4.4178e+00,  1.3346e+01,
          3.2374e+00,  1.0006e+01],
        [-5.7305e-02, -8.2416e-01, -2.7856e+00, -5.9812e-01, -1.2892e-02,
         -5.7639e-02, -5.7639e-02, -5.7639e-02, -5.7639e-02,  1.3345e+00,
         -5.7639e-02, -5.7639e-02, -1.4379e+00, -3.5449e-01, -5.1801e-01,
          1.9602e+00,  1.9391e+00,  5.3647e-01,  1.2066e+00, -8.6581e-01,
         -1.2515e+00, -1.1380e+00],
        [-2.4316e-02, -3.9820e-01, -1.0568e+00, -2.0977e-01,  1.0628e-03,
         -2.4340e-02, -2.4340e-02, -2.4340e-02, -2.4340e-02, -6.0062e-01,
         -2.4340e-02, -2.4340e-02, -4.0042e-01,  9.8303e-03, -1.6532e-01,
         -4.8161e-01, -4.8121e-01, -6.4096e-01, -4.9036e-01, -5.1388e-01,
         -7.0732e-01, -9.4400e-01],
        [ 1.1073e-01, -9.4624e+00, -5.8559e+00, -8.9172e-02, -6.3236e-03,
          1.1258e-01,  1.1258e-01,  1.1258e-01,  1.1258e-01, -5.6708e-02,
          1.1258e-01,  1.1258e-01,  6.1754e+00, -4.7904e-01, -3.7554e+00,
          1.2699e-01,  1.0744e-01,  7.4864e+00,  7.0837e+00, -1.2467e+01,
         -5.6397e+00, -1.0605e+01],
        [-2.4200e-02, -3.9780e-01, -1.0568e+00, -2.0977e-01,  8.3530e-04,
         -2.4224e-02, -2.4224e-02, -2.4224e-02, -2.4224e-02, -6.0058e-01,
         -2.4224e-02, -2.4224e-02, -4.0057e-01,  9.7377e-03, -1.6447e-01,
         -4.8142e-01, -4.8103e-01, -6.4090e-01, -4.9039e-01, -5.1360e-01,
         -7.0707e-01, -9.4337e-01],
        [-1.0859e-01,  4.1988e-01,  7.3245e-01, -1.2553e+00, -3.4206e-02,
         -1.0923e-01, -1.0923e-01, -1.0923e-01, -1.0923e-01, -5.0677e-02,
         -1.0923e-01, -1.0923e-01,  6.2207e-01, -5.9692e-01,  1.1205e-01,
          1.2673e+00,  1.2454e+00,  9.5033e-01,  9.2023e-01,  5.9773e-01,
          2.4351e-01,  2.5165e+00],
        [-9.9601e-03, -5.2627e-01, -1.1426e+00, -2.4291e-01, -1.8900e-02,
         -1.0045e-02, -1.0045e-02, -1.0045e-02, -1.0045e-02, -6.3256e-01,
         -1.0045e-02, -1.0045e-02, -6.1214e-01, -1.8168e-01, -3.2638e-01,
         -4.7222e-01, -4.7206e-01, -8.1272e-01, -5.5583e-01, -6.4546e-01,
         -6.5222e-01, -1.0013e+00],
        [-7.5477e-02, -8.2206e-01, -2.4358e+00, -4.2256e-01, -4.9019e-03,
         -7.5764e-02, -7.5764e-02, -7.5764e-02, -7.5764e-02,  1.6374e+00,
         -7.5764e-02, -7.5764e-02, -1.3979e+00, -3.2415e-01, -4.7917e-01,
          1.7302e+00,  1.7344e+00,  5.3961e-01,  1.0877e+00, -8.7090e-01,
         -1.0301e+00, -1.5299e+00],
        [-1.1281e-01,  4.1450e-01,  7.2060e-01, -1.2546e+00, -3.3710e-02,
         -1.1345e-01, -1.1345e-01, -1.1345e-01, -1.1345e-01, -5.5046e-02,
         -1.1345e-01, -1.1345e-01,  6.1104e-01, -6.1312e-01,  9.8643e-02,
          1.2588e+00,  1.2371e+00,  9.3221e-01,  9.0192e-01,  5.8682e-01,
          2.3905e-01,  2.5031e+00],
        [ 5.7503e-02, -4.1536e+00, -5.9910e-01, -4.2700e+00,  5.7274e-02,
          6.1410e-02,  6.1411e-02,  6.1410e-02,  6.1410e-02, -2.6510e+00,
          6.1410e-02,  6.1409e-02, -7.0574e-01,  1.5164e-01, -1.2091e+00,
         -3.0923e-01, -2.9698e-01, -1.9585e+00, -6.4026e-01,  2.0782e-01,
          4.0253e-01,  1.2744e+00],
        [-3.4161e-02,  4.6498e-01,  5.7550e-01, -6.0628e-01,  6.6250e-02,
         -3.4484e-02, -3.4483e-02, -3.4484e-02, -3.4483e-02,  3.7477e-01,
         -3.4483e-02, -3.4483e-02,  4.5131e-02, -1.3881e-01,  2.5125e-01,
          1.0645e+00,  1.0526e+00,  4.0767e-01,  5.4271e-01,  6.7642e-01,
          4.9070e-01,  1.8962e+00],
        [-5.6645e-03, -9.6390e+00,  6.4867e-01, -4.7040e+00, -1.6533e-02,
         -1.0496e-02, -1.0496e-02, -1.0496e-02, -1.0497e-02, -2.9210e+00,
         -1.0497e-02, -1.0497e-02,  1.3890e+00, -1.7189e-01, -2.8138e+00,
          1.3840e-01,  8.6538e-02,  4.0756e+00,  7.5866e+00, -1.4132e+01,
         -1.6721e+00, -1.9905e+00],
        [-2.4316e-02, -3.9820e-01, -1.0568e+00, -2.0977e-01,  1.0627e-03,
         -2.4340e-02, -2.4340e-02, -2.4340e-02, -2.4340e-02, -6.0062e-01,
         -2.4340e-02, -2.4340e-02, -4.0042e-01,  9.8303e-03, -1.6532e-01,
         -4.8161e-01, -4.8121e-01, -6.4096e-01, -4.9036e-01, -5.1388e-01,
         -7.0732e-01, -9.4400e-01],
        [ 5.7569e-02,  4.0570e+00, -5.7481e+00, -3.0787e+00,  2.7622e+00,
          5.4435e-02,  5.4435e-02,  5.4435e-02,  5.4434e-02,  1.3881e+00,
          5.4434e-02,  5.4434e-02,  2.3512e-01,  2.5584e+00,  3.3583e+00,
          2.0082e+00,  1.7047e+00,  3.7591e+00,  8.5462e-01,  3.3446e+00,
         -4.7172e+00,  6.9659e-02]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-2.2005, -0.8584, -1.5911, -0.8435, -1.5911, -1.2816,  2.7464, -4.9518,
        -2.7329, -0.8635, -1.5911, -0.0992, -1.5908,  1.9910, -1.6533, -0.7568,
         1.9704, -1.2454,  1.7003,  0.9207, -1.5911, -4.1848], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-2.0371e-02, -7.3142e-04, -6.8242e-03, -8.9656e-04, -6.8242e-03,
         -1.0168e-02, -2.6892e-02, -4.1316e-01, -9.6769e-01, -7.3070e-04,
         -6.8242e-03, -6.0424e-05, -6.8332e-03, -9.6590e-01, -4.6709e-03,
         -1.3793e-03, -9.6572e-01, -2.4594e-02, -9.6356e-01, -3.3055e-03,
         -6.8242e-03, -3.1617e-02],
        [-7.9449e-04, -1.4169e-03, -4.8606e-03, -1.6828e-03, -4.8606e-03,
         -4.0296e-03, -1.8029e-02, -1.9832e-01, -4.0052e-01, -1.4017e-03,
         -4.8606e-03,  3.4392e-04, -4.8672e-03, -4.0041e-01, -3.5206e-03,
         -2.3988e-03, -4.0036e-01, -1.2165e-02, -3.9943e-01, -1.2607e-03,
         -4.8606e-03, -1.1590e-03],
        [-2.0569e-02, -6.7275e-04, -4.9044e-03, -7.5019e-04, -4.9045e-03,
         -9.6851e-03, -2.4408e-02, -3.5366e-01, -8.3908e-01, -6.8227e-04,
         -4.9045e-03, -2.1066e-04, -4.9146e-03, -8.3752e-01, -2.8622e-03,
         -6.1078e-04, -8.3736e-01, -2.2912e-02, -8.3542e-01, -1.0767e-03,
         -4.9045e-03, -2.2849e-02],
        [-1.5013e-02, -5.7945e-04, -3.6033e-03, -5.6813e-04, -3.6033e-03,
         -7.0032e-03, -1.4547e-02, -3.2822e-01, -7.1023e-01, -5.8935e-04,
         -3.6033e-03,  1.7700e-04, -3.6084e-03, -7.0930e-01, -2.2482e-03,
         -8.2192e-04, -7.0918e-01, -1.9527e-02, -7.0753e-01, -1.7705e-04,
         -3.6033e-03, -2.0186e-02],
        [ 1.1674e+00,  1.7870e+00,  3.5723e-02,  1.6441e+00,  3.5772e-02,
          4.7384e-01,  4.2847e+00, -3.2938e-01, -2.8936e+00,  1.9839e+00,
          3.5771e-02, -1.3187e+01,  5.0046e-02,  4.4740e+00,  1.3209e+00,
          1.3646e+00,  4.2536e+00,  2.4124e+00,  2.7752e+00,  6.8626e+00,
          3.5773e-02,  5.5127e-02],
        [-9.6287e-04, -8.4343e-04, -2.4221e-03, -6.9989e-04, -2.4222e-03,
         -7.6629e-03, -5.8419e-03, -2.7576e-01, -4.7629e-01, -8.8306e-04,
         -2.4222e-03,  4.0151e-04, -2.4318e-03, -4.7578e-01, -1.0845e-03,
         -4.6544e-04, -4.7572e-01, -3.8875e-03, -4.7470e-01, -7.8757e-04,
         -2.4222e-03, -2.2456e-02],
        [-1.8977e-02, -2.5820e-04, -5.2454e-03, -3.0731e-04, -5.2454e-03,
         -7.3320e-03, -1.9421e-02, -2.8054e-01, -6.9192e-01, -2.5092e-04,
         -5.2454e-03,  7.8180e-05, -5.2520e-03, -6.9068e-01, -3.1467e-03,
         -6.4002e-04, -6.9054e-01, -1.7833e-02, -6.8880e-01, -1.6794e-03,
         -5.2454e-03, -1.3704e-02],
        [-2.7679e+00,  1.5112e+00,  3.3671e-02,  1.4699e+00,  3.3719e-02,
          1.2597e+00,  4.6857e+00,  3.7049e-02,  3.4923e+00,  1.6230e+00,
          3.3718e-02, -2.8964e+00,  4.7794e-02,  8.9645e-01,  1.2739e+00,
          1.5745e+00,  8.6028e-01,  2.0133e+00,  2.2871e+00,  1.3436e+00,
          3.3720e-02,  1.4002e+00],
        [-1.8494e-02, -6.8986e-04, -5.3158e-03, -8.4573e-04, -5.3158e-03,
         -7.9624e-03, -2.0114e-02, -3.4045e-01, -7.8457e-01, -6.8253e-04,
         -5.3158e-03, -5.5135e-05, -5.3237e-03, -7.8315e-01, -3.3245e-03,
         -8.6033e-04, -7.8301e-01, -2.2150e-02, -7.8120e-01, -1.6264e-03,
         -5.3158e-03, -2.2989e-02],
        [-2.4707e-02,  1.0711e-03, -3.0122e-03,  1.0376e-03, -3.0123e-03,
         -8.1356e-03, -3.8281e-02, -1.8661e-01, -6.2176e-01,  1.0443e-03,
         -3.0123e-03, -3.4434e-04, -3.0211e-03, -6.2129e-01, -8.8930e-04,
          9.0751e-04, -6.2115e-01, -2.8210e-02, -6.1941e-01, -1.6852e-03,
         -3.0123e-03, -1.2349e-02],
        [-4.2025e-01,  3.1244e-01,  3.7125e-02,  3.3880e-01,  3.7168e-02,
          4.8927e+00, -9.4951e+00,  7.0135e+00,  2.7101e+00,  3.0109e-01,
          3.7168e-02, -1.7573e+00,  4.9717e-02, -1.3314e+00,  3.9591e-01,
          4.1632e-01, -1.3064e+00,  6.4284e-02,  1.1636e+00, -1.7390e+00,
          3.7169e-02,  4.2449e+00],
        [ 2.3998e+00, -1.4741e+00,  1.2251e-02, -1.3070e+00,  1.2300e-02,
          2.4115e+00, -3.8314e-01,  1.3552e-01,  5.2337e+00, -1.2073e+00,
          1.2300e-02,  2.0828e+01,  2.6725e-02,  3.2644e-01,  1.3072e+00,
         -1.1624e+00,  4.3225e-01, -3.8502e+00,  1.7707e+00, -2.1415e+00,
          1.2302e-02, -2.0280e+00],
        [-2.1193e-02, -6.4838e-04, -5.9365e-03, -6.5881e-04, -5.9365e-03,
         -1.0968e-02, -2.5592e-02, -3.9923e-01, -9.3710e-01, -6.5808e-04,
         -5.9365e-03, -1.3006e-04, -5.9454e-03, -9.3537e-01, -3.6674e-03,
         -9.4568e-04, -9.3520e-01, -2.4627e-02, -9.3307e-01, -1.8539e-03,
         -5.9365e-03, -2.7236e-02],
        [-2.0231e-02, -7.7877e-04, -5.8933e-03, -1.0079e-03, -5.8933e-03,
         -1.0068e-02, -2.4645e-02, -4.0319e-01, -9.3312e-01, -7.6796e-04,
         -5.8933e-03,  7.4015e-05, -5.8994e-03, -9.3150e-01, -4.4404e-03,
         -1.2975e-03, -9.3133e-01, -2.4327e-02, -9.2923e-01, -2.6599e-03,
         -5.8933e-03, -3.2702e-02]], device='cuda:0'))])
xi:  [311.62762]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 505.44679499194206
W_T_median: 495.8592606925604
W_T_pctile_5: 239.2000274924849
W_T_CVAR_5_pct: -40.52677316487614
Average q (qsum/M+1):  58.882265152469756
Optimal xi:  [311.62762]
Expected(across Rb) median(across samples) p_equity:  5.849687410049617e-06
obj fun:  tensor(-1822.7044, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/factor_decumulation/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/factor_decumulation/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: MC_everything
Objective function: mean_cvar_single_level
Tracing param: 0.05
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       22  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       22  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 22)      True          22  
0     (22, 22)      True          22  
0      (22, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       22  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       22  logistic_sigmoid   
0        obj.layers[3]         3  output_layer       14           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 22)      True          22  
0     (22, 22)      True          22  
0     (22, 14)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -8.5715,   6.4621],
        [ -8.3669,  -9.0182],
        [ -5.1223,   3.2445],
        [  8.0669,   4.1508],
        [-11.4280,  -6.0457],
        [ -6.4858,   4.0851],
        [  6.0779,   4.9126],
        [  9.1747,   0.7713],
        [ -8.3119,   6.0846],
        [ -8.3147,   6.0977],
        [ -8.4882,   6.6116],
        [ -8.6931,   5.7529],
        [  7.8819,   3.3034],
        [ -1.2974,   1.0853],
        [  5.4594,  -0.3288],
        [  5.2299,   5.2824],
        [-11.7613,  -7.4762],
        [  7.7973,   4.2640],
        [ -8.5799,   5.8746],
        [ -7.8535,   5.7472],
        [ -1.2944,   1.0845],
        [-21.4386,  -5.7294]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ 4.8764, -5.7404, -3.0406, -9.5323, -3.7687, -2.3429, -8.4043, -9.1228,
         4.2727,  3.0356,  5.1757,  1.5461, -8.9288, -3.8883, -8.9159, -8.5427,
        -4.0692, -9.2749,  1.8685,  2.4405, -3.8889, -4.6902], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1574e-03, -1.6502e-02, -2.2728e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1088e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [-9.2453e+00,  1.2482e+01, -7.2066e-01,  7.0332e+00,  4.6981e+00,
         -1.2007e+00,  4.5523e+00,  6.2080e+00, -7.5674e+00, -3.0869e+00,
         -1.0021e+01, -1.8126e+00,  5.8578e+00, -1.6237e-01,  6.8999e-01,
          5.4520e+00,  8.4865e+00,  8.0426e+00, -2.2762e+00, -3.8127e+00,
         -1.9618e-01,  8.7135e+00],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2751e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-9.6515e+00,  1.3280e+01, -9.1434e-01,  9.3871e+00,  5.7620e+00,
         -1.3190e+00,  6.4927e+00,  6.8045e+00, -8.3770e+00, -3.3906e+00,
         -1.0939e+01, -2.1716e+00,  6.5179e+00, -2.1870e-01,  2.0491e+00,
          4.1453e+00,  9.2888e+00,  7.8384e+00, -2.6898e+00, -4.4743e+00,
         -1.9003e-01,  9.7752e+00],
        [-7.9773e+00,  1.0315e+01,  2.5895e-01,  4.6608e+00,  4.9211e+00,
          1.7041e-02,  2.1882e+00,  6.8647e+00, -6.6734e+00, -4.8263e+00,
         -8.8073e+00, -2.8795e+00,  6.4311e+00,  1.6629e-01,  1.1111e+00,
          5.0411e+00,  7.6765e+00,  1.1081e+01, -3.5739e+00, -4.0927e+00,
          1.6082e-01,  8.5887e+00],
        [-7.6589e+00,  9.2592e+00,  7.9739e-02,  3.9257e+00,  4.5700e+00,
          1.0005e-01,  2.1053e+00,  4.6166e+00, -6.0015e+00, -3.8545e+00,
         -9.2106e+00, -1.7570e+00,  5.7099e+00, -1.2986e-02,  5.9836e-02,
          4.9159e+00,  7.0161e+00,  9.4703e+00, -2.3319e+00, -3.1763e+00,
         -1.3208e-02,  7.3285e+00],
        [-2.2581e-01, -1.6549e-01,  1.7511e-03, -1.2938e-02, -1.1903e-01,
          1.1578e-03, -1.6509e-02, -2.2839e-03, -1.8738e-01, -6.9338e-02,
         -2.5288e-01, -1.2692e-02, -9.1165e-03,  1.2292e-02,  1.9855e-02,
         -1.7662e-02, -1.7966e-01, -1.2937e-02, -1.9683e-02, -4.9682e-02,
          1.2307e-02, -3.1400e-02],
        [-2.2584e-01, -1.6546e-01,  1.7508e-03, -1.2931e-02, -1.1901e-01,
          1.1573e-03, -1.6502e-02, -2.2704e-03, -1.8735e-01, -6.9322e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9856e-02,
         -1.7657e-02, -1.7959e-01, -1.2929e-02, -1.9678e-02, -4.9672e-02,
          1.2308e-02, -3.1398e-02],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2752e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2730e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1088e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [-7.4230e+00,  9.2761e+00,  8.2691e-02,  4.6883e+00,  4.4150e+00,
          1.2211e-01,  2.9895e+00,  3.5408e+00, -6.2114e+00, -3.5923e+00,
         -9.4198e+00, -1.8627e+00,  4.7011e+00, -1.9985e-02, -6.0281e-02,
          5.2032e+00,  7.0797e+00,  8.3206e+00, -2.3235e+00, -3.3515e+00,
         -1.9947e-02,  7.4397e+00],
        [ 7.9326e+00, -1.0706e+01,  4.0837e-01, -9.2089e+00, -5.7725e+00,
          6.6403e-01, -4.8629e+00, -5.8385e+00,  6.6214e+00,  5.0109e+00,
          9.6232e+00,  3.3999e+00, -5.8456e+00, -1.3669e-01, -1.4453e+00,
         -3.3601e+00, -8.4017e+00, -9.5444e+00,  3.9084e+00,  4.3412e+00,
         -1.3169e-01, -9.7519e+00],
        [-2.2583e-01, -1.6545e-01,  1.7507e-03, -1.2931e-02, -1.1900e-01,
          1.1572e-03, -1.6503e-02, -2.2678e-03, -1.8733e-01, -6.9320e-02,
         -2.5297e-01, -1.2687e-02, -9.1093e-03,  1.2293e-02,  1.9856e-02,
         -1.7657e-02, -1.7958e-01, -1.2930e-02, -1.9677e-02, -4.9670e-02,
          1.2308e-02, -3.1399e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2931e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2732e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [ 6.5891e-01,  3.0868e-01,  8.3566e-03,  3.5747e-02,  2.1159e-01,
          5.3475e-03,  5.7464e-02,  2.6629e-01,  5.5272e-01,  2.6083e-01,
          7.4008e-01,  8.5701e-02,  7.1654e-02,  3.7717e-02,  5.6900e-02,
          8.1005e-02,  2.9146e-01,  3.6840e-02,  1.1119e-01,  2.1066e-01,
          3.7716e-02,  1.3910e-01],
        [-2.2585e-01, -1.6548e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2733e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1087e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2307e-02, -3.1398e-02],
        [-7.5648e+00,  9.6323e+00,  3.4567e-02,  4.2023e+00,  4.4635e+00,
         -1.3328e-01,  2.0401e+00,  5.3264e+00, -6.2784e+00, -3.7048e+00,
         -9.3470e+00, -2.0562e+00,  5.8618e+00, -3.3635e-02,  2.0363e-01,
          5.0433e+00,  7.2814e+00,  9.5323e+00, -2.4148e+00, -3.3678e+00,
         -3.5727e-02,  7.7623e+00],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2750e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2744e-03, -1.8737e-01, -6.9326e-02,
         -2.5298e-01, -1.2689e-02, -9.1087e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2931e-02, -1.1901e-01,
          1.1574e-03, -1.6502e-02, -2.2722e-03, -1.8735e-01, -6.9324e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9673e-02,
          1.2308e-02, -3.1398e-02],
        [ 6.6450e-01,  3.1201e-01,  8.4127e-03,  3.4696e-02,  2.1235e-01,
          5.3877e-03,  5.6376e-02,  2.6891e-01,  5.5678e-01,  2.6166e-01,
          7.4701e-01,  8.5769e-02,  7.1346e-02,  3.8211e-02,  5.7275e-02,
          8.0058e-02,  2.9347e-01,  3.5786e-02,  1.1132e-01,  2.1139e-01,
          3.8209e-02,  1.3913e-01],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2753e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-2.4313,  0.0078, -2.4313,  0.0873, -0.2625, -0.5234, -2.4313, -2.4314,
        -2.4313, -2.4313, -0.4369, -0.2571, -2.4314, -2.4313,  4.5769, -2.4313,
        -0.4006, -2.4313, -2.4313, -2.4313,  4.6668, -2.4313], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[  0.0334, -10.4940,   0.0334, -15.8008,  -9.7979,  -6.9452,   0.0334,
           0.0334,   0.0334,   0.0334,  -7.0927,  14.9535,   0.0334,   0.0334,
           4.2936,   0.0334,  -7.0565,   0.0334,   0.0334,   0.0334,   4.7631,
           0.0334]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 1.0813e+01,  2.9656e+00],
        [ 5.5664e-01,  1.1757e+01],
        [ 1.8618e+01,  2.3664e+00],
        [ 1.0637e+01,  1.5273e-02],
        [-1.4941e+01, -2.2181e+00],
        [-1.2849e+00,  1.3570e+00],
        [-1.2800e+00,  1.3116e+00],
        [-1.7122e+00,  6.5637e-01],
        [-2.0284e+00,  2.5259e-01],
        [ 9.3477e+00, -5.2188e-01],
        [-1.9314e+00,  2.3251e-01],
        [-1.8788e+00,  4.0167e-01],
        [-1.0523e+01, -1.6251e+00],
        [-8.3398e+00,  5.3496e+00],
        [-7.4426e+00,  1.0247e+01],
        [-1.2446e+01, -2.8588e+00],
        [-1.4240e+01, -3.1016e+00],
        [-1.0901e+01, -2.0063e+00],
        [-1.0106e+01, -2.4687e+00],
        [ 3.1771e+00,  1.1429e+01],
        [ 1.0907e+01,  2.2476e+00],
        [ 1.1102e+01,  1.0847e+01]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-5.5365,  7.0663,  2.9709, -9.6018, -1.5848, -4.5127, -4.5185, -4.9090,
        -4.9531, -9.4875, -4.9847, -4.9560,  5.4223,  3.0397,  6.7011, -3.5168,
        -2.9913,  3.2472,  0.4201,  7.7652, -4.3018,  6.4326], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 6.1957e-01, -3.4634e+00, -1.7479e+00,  1.1905e+00,  1.2460e-02,
          1.1948e-01,  1.3226e-01,  4.3984e-02, -1.1598e-02,  1.0215e+00,
         -6.1706e-03,  2.4414e-03, -2.5313e+00,  1.1746e+00, -7.8526e-01,
         -9.2734e-03,  2.7572e-03, -2.7562e+00, -1.8971e+00, -2.6434e+00,
         -4.2419e-01,  3.0293e-02],
        [-4.6968e-01, -1.5418e-01, -2.2179e+00, -4.7229e-01, -1.4815e-02,
         -2.6861e-02, -2.4100e-02,  6.5293e-03, -1.5585e-02, -3.8766e-01,
         -1.6068e-02, -1.1227e-02, -1.0214e+00, -1.1716e-01, -1.0616e-01,
         -5.8386e-03, -7.9498e-03, -5.2026e-01, -1.9652e-01, -4.4158e-01,
         -1.2068e+00, -1.2289e+00],
        [-9.0043e-01, -3.1328e-01, -2.4749e+00, -1.0214e+00, -5.5072e-03,
         -2.2407e-02, -1.9453e-02, -7.7448e-03,  4.4606e-03, -9.3610e-01,
          4.1020e-03,  2.5876e-03, -1.2488e+00, -4.6992e-02, -9.2699e-02,
         -2.2626e-03, -3.5666e-03, -6.7176e-01, -2.4800e-01, -8.7567e-01,
         -1.3802e+00, -7.7155e-01],
        [-4.7184e-01, -1.5540e-01, -2.2143e+00, -4.7815e-01, -1.4473e-02,
         -2.7281e-02, -2.4476e-02,  6.5809e-03, -1.5495e-02, -3.9563e-01,
         -1.5975e-02, -1.1107e-02, -1.0396e+00, -1.1822e-01, -1.0605e-01,
         -5.8775e-03, -7.9716e-03, -5.2621e-01, -1.9589e-01, -4.4421e-01,
         -1.2127e+00, -1.2341e+00],
        [-4.8450e-01, -1.6921e-01, -2.2399e+00, -4.9569e-01, -1.4212e-02,
         -2.5472e-02, -2.2971e-02,  5.3544e-03, -1.0943e-02, -4.2767e-01,
         -1.1482e-02, -7.9784e-03, -1.0434e+00, -1.0826e-01, -9.0719e-02,
         -6.2509e-03, -8.3116e-03, -5.2892e-01, -2.1129e-01, -4.5420e-01,
         -1.2241e+00, -1.0613e+00],
        [ 3.0119e-01,  9.1885e-01, -1.5837e+00, -8.5542e-01, -1.1953e-02,
         -1.9274e+00, -1.8752e+00, -1.4092e+00, -5.5076e-01,  1.0780e+00,
         -4.5548e-01, -9.9188e-01, -3.9286e+00,  1.1415e+00,  2.2999e+00,
         -1.2239e-02, -1.3323e-02, -2.7068e+00, -9.7625e-01,  4.2057e-01,
         -1.0808e+00, -1.2393e+00],
        [ 2.4582e-01, -1.1721e+01,  5.7285e-01, -6.6182e+00,  3.3458e+00,
          1.7362e-01,  1.7999e-01,  2.0080e-01,  2.8786e-01, -4.5146e+00,
          2.9196e-01,  1.9339e-01,  3.6973e+00, -2.2846e+00, -8.2839e+00,
          2.5629e+00,  2.7897e+00,  3.3397e+00,  3.6998e+00, -1.2216e+01,
          1.0269e-01, -7.8724e+00],
        [-2.7710e+00,  3.8384e+00, -3.8614e+00, -5.2497e+00,  1.4955e-01,
         -5.1488e-01, -5.0931e-01, -4.0831e-01, -1.3933e-01, -4.9036e+00,
         -1.0681e-01, -2.8754e-01,  2.6586e+00,  3.1018e+00,  6.0454e+00,
          5.3721e-01,  5.1709e-01,  2.4000e+00,  1.7467e+00,  2.8980e+00,
         -1.8615e+00,  1.3298e+00],
        [ 5.3996e+00,  1.7695e+01,  2.7980e+00,  6.7002e+00, -6.8933e+00,
          1.9716e-02,  1.5955e-02,  1.6031e-02, -1.9886e-01,  4.1219e+00,
         -1.8883e-01,  2.3240e-02, -8.0362e+00,  3.0849e+00,  1.4710e+01,
         -3.3033e+00, -3.8057e+00, -7.4740e+00, -6.2744e+00,  1.9113e+01,
          5.0855e+00,  2.1580e+01],
        [-4.6054e-01, -1.5864e-01, -2.1828e+00, -4.7962e-01, -1.3132e-02,
         -2.7434e-02, -2.4527e-02,  7.6509e-03, -1.3661e-02, -3.9854e-01,
         -1.4154e-02, -9.5939e-03, -1.0591e+00, -1.2246e-01, -9.9910e-02,
         -5.2767e-03, -7.3107e-03, -5.5050e-01, -2.1282e-01, -4.5037e-01,
         -1.2105e+00, -1.2384e+00],
        [-9.3210e-01, -5.0637e-01, -2.5650e+00, -1.2297e+00,  5.1007e-03,
         -1.3266e-02, -1.0812e-02, -6.5037e-03, -1.3910e-03, -1.1288e+00,
         -1.7836e-03, -1.9456e-03, -7.9371e-01, -5.5349e-02, -8.6527e-02,
          5.2059e-03,  5.8080e-03, -8.8163e-01, -4.5943e-01, -1.6628e+00,
         -1.1149e+00, -5.6400e-01],
        [-2.8460e+00, -1.8825e+01, -9.7046e+00, -3.0631e+00,  6.2381e+00,
          2.2284e-02,  2.2216e-02,  3.8058e-02,  1.2254e-02, -4.6393e+00,
          2.0356e-03,  4.3669e-02,  7.6060e+00, -3.1393e+00, -1.1899e+01,
          2.9927e+00,  3.5772e+00,  7.5127e+00,  7.0486e+00, -2.2653e+01,
         -1.0357e+01, -2.5603e+01],
        [-4.7448e-01, -1.5413e-01, -2.2021e+00, -4.7761e-01, -1.5017e-02,
         -2.6936e-02, -2.4189e-02,  6.2971e-03, -1.5709e-02, -3.9518e-01,
         -1.6194e-02, -1.1365e-02, -1.0353e+00, -1.1675e-01, -1.0676e-01,
         -6.0131e-03, -8.0879e-03, -5.2030e-01, -1.9318e-01, -4.4328e-01,
         -1.2192e+00, -1.2259e+00],
        [-6.9231e-01,  3.0014e+00,  2.7786e+00, -1.3175e+00,  3.0620e-04,
         -1.3308e-01, -1.3059e-01, -4.6677e-03, -1.5150e-02, -1.3574e+00,
         -1.8928e-02, -2.6791e-03,  2.1880e+00, -4.4040e-01,  8.1953e-01,
         -1.8323e-02, -1.1176e-02,  1.4720e+00,  4.3629e-01,  2.4554e+00,
          8.6002e-02, -2.4341e-01],
        [ 3.0175e+00, -1.5929e-01,  3.1082e+00,  1.6836e+00, -3.7655e+00,
          1.7569e-01,  1.8810e-01,  2.3150e-01, -5.4313e-01,  3.8072e+00,
         -5.3327e-01,  1.6719e-01,  6.0672e-02, -2.5586e+00, -3.6155e+00,
         -4.5190e+00, -4.8662e+00,  1.6404e-01, -1.7814e-01, -2.9936e-01,
          2.7050e+00, -1.8862e+00],
        [-6.1343e-01, -2.0997e-01, -2.3786e+00, -7.6186e-01, -1.9840e-02,
         -3.2273e-02, -3.0458e-02, -4.7454e-03,  5.8161e-03, -6.4208e-01,
          6.0534e-03,  3.5540e-03, -1.0330e+00, -6.3106e-02, -1.0050e-01,
         -7.6629e-03, -1.3412e-02, -4.8643e-01, -1.8407e-01, -5.2743e-01,
         -1.3866e+00, -9.2565e-01],
        [ 2.3232e-01,  3.1081e+00,  2.1861e+00,  1.7924e+00,  8.3474e-01,
         -4.2057e-01, -3.7750e-01, -8.6959e-02, -6.3586e-02,  1.4179e+00,
         -6.1088e-02, -4.4329e-02,  1.9436e-01, -4.4091e-01,  1.1123e+00,
          4.9760e-01,  7.0823e-01, -1.6870e-01, -3.9429e-01, -1.1351e+00,
          1.7979e-02, -1.2019e+00],
        [-9.3911e-03, -3.8280e+00, -3.1866e-01, -2.0025e+00, -3.0075e-02,
          4.3973e-02,  5.3990e-02,  1.0353e-01,  1.4874e-01, -1.8588e+00,
          1.5683e-01,  1.3914e-01, -1.0725e-01, -2.1520e-01, -2.7783e-01,
          5.4541e-02,  7.3731e-03, -1.3880e+00, -8.0744e-01, -5.4071e+00,
         -9.3933e-01,  6.6525e-02],
        [-2.0923e+00,  1.6783e+00,  2.1031e+00, -6.6800e+00,  1.9109e-04,
         -8.2756e-01, -7.5222e-01, -4.3503e-01, -1.2713e-01, -3.5556e+00,
         -7.5366e-02, -3.3382e-01,  9.4887e+00, -1.2212e+00,  5.7869e+00,
         -6.4339e-04, -3.5999e-03,  9.1765e+00,  6.6382e+00,  6.8362e-01,
          2.7993e-01, -2.2562e+00],
        [-5.5183e+00, -1.5095e+01, -2.8824e-01, -4.9346e+00,  5.3321e+00,
          1.5448e-01,  1.5735e-01,  1.6104e-01,  5.9928e-01, -2.7075e+00,
          5.5855e-01,  1.3923e-01,  3.0535e+00,  8.4196e-01, -6.5453e+00,
          4.6053e+00,  5.0922e+00,  3.6158e+00,  3.8865e+00, -1.4997e+01,
         -2.8857e+00, -4.2056e+00],
        [ 4.0156e-01, -1.0952e+00, -1.5738e+00, -4.3123e-01, -8.5229e-03,
         -6.6402e-01, -6.0136e-01, -2.4497e-01, -5.3144e-02, -2.8255e-01,
         -5.5575e-02, -9.1214e-02, -2.1121e+00,  1.5978e+00,  1.4435e+00,
         -1.0813e-03, -1.8711e-03, -2.1573e+00, -8.6345e-01, -1.7321e+00,
         -7.5512e-01,  5.2300e-01],
        [-1.9858e+00,  2.9033e+00, -2.5269e+00, -2.1485e+00,  2.2962e+00,
         -1.4441e+00, -1.3739e+00, -7.3427e-01,  6.2891e-02,  2.1944e-01,
          6.1358e-02, -2.6440e-01,  7.4516e-02,  1.7016e+00,  3.0581e+00,
          1.5196e+00,  1.8766e+00,  6.5632e-01,  1.1298e+00,  1.3664e+00,
         -2.7325e+00, -7.5516e-01]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-1.8466, -2.2256, -2.5068, -2.1943, -2.2514, -1.8834,  0.6255, -4.9456,
        -2.2024, -2.2158, -2.5964,  0.0491, -2.2135,  3.0825,  3.0734, -2.4047,
         2.5296, -1.0040,  2.4991, -0.5295, -2.0766, -2.4070], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-1.5234e-02,  7.2296e-05, -1.5502e-04,  5.9106e-05,  9.2680e-05,
         -2.2228e-02, -7.7352e-03, -1.5990e-01, -1.5103e+00,  6.1218e-05,
         -1.5306e-04, -1.3007e-05,  6.3929e-05, -1.5060e+00, -1.5008e+00,
         -2.1007e-04, -1.4999e+00, -5.4381e-03, -6.9054e-01, -3.7369e-03,
         -4.7102e-03, -3.5212e-02],
        [-8.7292e-03, -1.4222e-03,  7.6021e-04, -1.3898e-03, -1.5771e-03,
         -1.3307e-02, -5.1882e-03, -1.0878e-01, -8.2132e-01, -1.3260e-03,
          8.8522e-04, -2.6449e-04, -1.4244e-03, -8.2289e-01, -8.1366e-01,
          5.1250e-04, -8.1735e-01,  1.2221e-03, -3.1415e-01, -6.8756e-03,
          4.4122e-03, -3.5269e-02],
        [-2.1229e-02, -5.1093e-04, -3.4543e-04, -5.1941e-04, -5.4632e-04,
         -1.8385e-02, -9.4420e-03, -1.3731e-01, -1.4218e+00, -5.2075e-04,
         -3.2211e-04,  2.3184e-05, -5.1689e-04, -1.4173e+00, -1.4127e+00,
         -3.8173e-04, -1.4125e+00, -6.1909e-03, -6.2055e-01, -3.7929e-03,
         -7.1839e-03, -2.7972e-02],
        [-9.4172e-03, -2.1938e-04, -2.2482e-04, -2.0759e-04, -2.8288e-04,
         -1.6622e-02, -7.4112e-03, -1.3137e-01, -1.2415e+00, -2.0252e-04,
         -2.1593e-04, -7.4338e-05, -2.1553e-04, -1.2385e+00, -1.2343e+00,
         -1.4845e-04, -1.2328e+00, -5.0361e-03, -5.7108e-01, -3.7365e-03,
         -7.0540e-03, -2.5170e-02],
        [-1.0969e+00,  7.0714e-02,  2.8031e-01,  4.2693e-02,  2.8583e-01,
          5.4877e-01,  3.6379e+00, -1.3225e+00, -3.0535e+00,  2.8854e-01,
          9.2331e-01, -1.4907e+01,  2.7428e-02,  3.6135e+00,  3.4661e+00,
         -2.3553e-02,  3.3911e+00,  1.2464e+00,  2.0600e+00,  5.6362e+00,
         -4.8358e-01,  4.4222e-01],
        [-1.1325e-02, -1.4138e-04,  1.4500e-04, -1.5008e-04, -1.0196e-03,
         -8.7395e-03, -5.0212e-04, -1.4891e-01, -9.6424e-01, -1.5847e-04,
          8.4481e-05, -6.7668e-04, -1.4540e-04, -9.6261e-01, -9.4804e-01,
         -9.4017e-05, -9.5700e-01,  4.4294e-03, -4.5741e-01, -5.5136e-03,
          2.2288e-03, -3.6784e-02],
        [-2.4271e-02, -7.7962e-04, -2.2040e-04, -7.9007e-04, -5.4691e-04,
         -1.4880e-02, -9.2166e-03, -1.1032e-01, -1.2944e+00, -7.8678e-04,
         -1.4609e-04, -3.3668e-05, -7.9327e-04, -1.2897e+00, -1.2879e+00,
         -3.7474e-04, -1.2861e+00, -9.7262e-03, -5.3746e-01, -3.8536e-03,
         -1.0548e-02, -2.4508e-02],
        [ 3.9237e+00, -6.2937e-02,  8.2976e-01, -8.9553e-02,  1.8773e-01,
          2.5280e+00,  4.4063e+00, -5.1176e-01,  2.7121e+00,  1.5038e-01,
          2.1898e+00, -6.3975e+00, -1.0291e-01,  9.8757e-01,  1.1535e+00,
          5.7770e-02,  9.4780e-01,  2.9512e+00,  2.3504e+00,  1.6411e+00,
          3.1498e+00,  1.2727e-01],
        [-1.4494e-02, -1.9430e-04, -1.7724e-04, -2.0127e-04, -2.0117e-04,
         -1.5493e-02, -8.1680e-03, -1.3258e-01, -1.3345e+00, -2.0053e-04,
         -1.8098e-04, -1.8463e-05, -1.9899e-04, -1.3303e+00, -1.3262e+00,
         -2.7675e-04, -1.3255e+00, -6.2074e-03, -5.8710e-01, -4.1919e-03,
         -7.5895e-03, -2.9301e-02],
        [-2.1892e-02, -3.5780e-04, -4.8405e-04, -3.6317e-04, -3.6356e-04,
         -2.3657e-02, -1.6951e-02, -9.6588e-02, -1.1849e+00, -3.5150e-04,
         -4.0838e-04, -1.7243e-05, -3.6464e-04, -1.1843e+00, -1.1795e+00,
         -3.3804e-04, -1.1790e+00, -7.4055e-03, -5.7283e-01, -5.4422e-03,
         -1.0076e-02, -3.1398e-02],
        [-2.3028e+00, -2.1890e-02, -8.3502e-03, -5.3786e-02,  9.5685e-02,
         -8.9290e-01, -1.4767e+01,  7.5055e+00,  3.0752e+00,  1.1812e-01,
         -7.0438e-02,  2.1906e-03, -5.7019e-02, -7.6423e-01, -1.3833e+00,
         -7.3209e-03, -7.3795e-01, -2.2229e+00,  1.8670e+00, -1.4910e+01,
         -1.6032e+00,  1.4609e+00],
        [ 2.4319e+00,  1.1747e-01, -1.6596e-01,  8.9778e-02,  3.1240e-01,
         -1.2941e+00, -9.2455e-01, -5.3120e-01,  5.2163e+00,  3.3676e-01,
         -2.0670e-01,  2.2187e+01,  7.3275e-02,  3.7788e-01,  7.5700e-01,
         -1.2275e-01,  4.8364e-01, -2.5823e+00,  1.5965e+00, -2.2668e+00,
         -6.5383e-01, -2.8611e+00],
        [-2.1115e-02, -3.0744e-04, -1.4460e-04, -2.9289e-04, -3.5131e-04,
         -2.2539e-02, -1.0971e-02, -1.5511e-01, -1.5086e+00, -2.8377e-04,
         -1.2594e-04,  2.8039e-05, -3.0274e-04, -1.5044e+00, -1.4994e+00,
         -3.7557e-04, -1.4986e+00, -6.5951e-03, -6.8458e-01, -3.5928e-03,
         -7.8039e-03, -3.0722e-02],
        [-1.4210e-02,  2.7210e-04, -1.6876e-04,  2.6752e-04,  2.9104e-04,
         -2.2712e-02, -5.7647e-03, -1.5704e-01, -1.4740e+00,  2.7486e-04,
         -1.6774e-04, -4.4364e-05,  2.6776e-04, -1.4699e+00, -1.4648e+00,
         -1.4749e-04, -1.4640e+00, -5.0059e-03, -6.6920e-01, -3.9010e-03,
         -5.3125e-03, -3.3932e-02]], device='cuda:0'))])
loaded xi:  855.6613
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857
 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857
 0.07142857 0.07142857]
W_T_mean: 8576.841924009083
W_T_median: 5042.380921625826
W_T_pctile_5: 103.64169553244135
W_T_CVAR_5_pct: -371.9331258181762
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1795.1206652733554
Current xi:  [842.85913]
objective value function right now is: -1795.1206652733554
4.0% of gradient descent iterations done. Method = Adam
Current xi:  [829.8408]
objective value function right now is: -1793.6543677140055
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1796.814956323398
Current xi:  [817.48157]
objective value function right now is: -1796.814956323398
8.0% of gradient descent iterations done. Method = Adam
Current xi:  [805.33136]
objective value function right now is: -1793.2393743039431
10.0% of gradient descent iterations done. Method = Adam
Current xi:  [793.20557]
objective value function right now is: -1795.161281361037
12.0% of gradient descent iterations done. Method = Adam
new min fval:  -1798.5905758847703
Current xi:  [782.2084]
objective value function right now is: -1798.5905758847703
14.000000000000002% of gradient descent iterations done. Method = Adam
new min fval:  -1799.0717810626286
Current xi:  [770.7018]
objective value function right now is: -1799.0717810626286
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [759.5441]
objective value function right now is: -1794.2445165641805
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -1823.2579027214094
Current xi:  [750.9344]
objective value function right now is: -1823.2579027214094
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [744.8837]
objective value function right now is: -1820.5378564432913
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -1823.2937334195124
Current xi:  [738.3584]
objective value function right now is: -1823.2937334195124
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [732.4629]
objective value function right now is: -1820.0147160164836
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [725.44586]
objective value function right now is: -1822.0205872381623
28.000000000000004% of gradient descent iterations done. Method = Adam
new min fval:  -1823.612935091037
Current xi:  [718.9052]
objective value function right now is: -1823.612935091037
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [712.6216]
objective value function right now is: -1819.0227787582241
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [705.27966]
objective value function right now is: -1816.8630228098064
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [699.1213]
objective value function right now is: -1821.7298004538327
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [692.04474]
objective value function right now is: -1823.20238751836
38.0% of gradient descent iterations done. Method = Adam
new min fval:  -1824.0525973841413
Current xi:  [685.21716]
objective value function right now is: -1824.0525973841413
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [678.2371]
objective value function right now is: -1823.0314018567326
42.0% of gradient descent iterations done. Method = Adam
new min fval:  -1824.2503106241022
Current xi:  [671.60626]
objective value function right now is: -1824.2503106241022
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [665.96356]
objective value function right now is: -1819.9415148951773
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [660.77704]
objective value function right now is: -1823.8552403915976
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [653.4969]
objective value function right now is: -1814.5083988879448
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [641.4769]
objective value function right now is: -1803.3249697931572
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [637.1755]
objective value function right now is: -1820.9524976495136
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [633.17554]
objective value function right now is: -1823.488870429301
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [631.5781]
objective value function right now is: -1823.2818689685207
57.99999999999999% of gradient descent iterations done. Method = Adam
new min fval:  -1825.1908910383022
Current xi:  [627.7741]
objective value function right now is: -1825.1908910383022
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [623.2607]
objective value function right now is: -1823.7888139753506
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [618.30994]
objective value function right now is: -1810.0488693630487
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [610.87805]
objective value function right now is: -1815.6635187917946
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [605.9539]
objective value function right now is: -1804.4980001014756
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [592.32935]
objective value function right now is: -1778.1295251961526
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [590.36847]
objective value function right now is: -1813.065156073774
72.0% of gradient descent iterations done. Method = Adam
Current xi:  [590.02014]
objective value function right now is: -1816.5910548947552
74.0% of gradient descent iterations done. Method = Adam
Current xi:  [589.4382]
objective value function right now is: -1816.8669005061772
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [588.7588]
objective value function right now is: -1817.0277707717755
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [587.81177]
objective value function right now is: -1817.444167393689
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [587.22424]
objective value function right now is: -1816.06359905683
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [586.35443]
objective value function right now is: -1817.0822233775216
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [585.4531]
objective value function right now is: -1816.6304105469071
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [584.53503]
objective value function right now is: -1819.3365455988485
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [584.054]
objective value function right now is: -1819.7783712887422
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [583.42303]
objective value function right now is: -1819.871193304219
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [583.14813]
objective value function right now is: -1823.4965863570394
new min fval from sgd:  -1825.204438221695
new min fval from sgd:  -1825.2435132151293
new min fval from sgd:  -1825.3290451873686
new min fval from sgd:  -1825.3512482251176
new min fval from sgd:  -1825.3747117769478
new min fval from sgd:  -1825.4233401070237
new min fval from sgd:  -1825.4693860165946
new min fval from sgd:  -1825.4739600407058
new min fval from sgd:  -1825.6309940676801
new min fval from sgd:  -1825.6865818185322
new min fval from sgd:  -1825.7085068962185
new min fval from sgd:  -1825.7699193033106
new min fval from sgd:  -1825.8597535020867
new min fval from sgd:  -1825.9747349653771
new min fval from sgd:  -1825.9884705049299
new min fval from sgd:  -1826.182216165848
new min fval from sgd:  -1826.216104499194
new min fval from sgd:  -1826.2817757639525
new min fval from sgd:  -1826.3364151196233
new min fval from sgd:  -1826.3938062990865
new min fval from sgd:  -1826.5062648957862
new min fval from sgd:  -1826.5555533863535
new min fval from sgd:  -1826.5626702057473
new min fval from sgd:  -1826.5664534108487
new min fval from sgd:  -1826.6468357332494
new min fval from sgd:  -1826.660902844078
new min fval from sgd:  -1826.7159922268247
new min fval from sgd:  -1826.7784630948217
new min fval from sgd:  -1826.7925030782703
new min fval from sgd:  -1826.7993674335632
new min fval from sgd:  -1826.8302614029503
new min fval from sgd:  -1826.8387869513424
new min fval from sgd:  -1826.8492295728465
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [583.0625]
objective value function right now is: -1826.8492295728465
new min fval from sgd:  -1826.9139992491655
new min fval from sgd:  -1826.9666154721174
new min fval from sgd:  -1827.005225474089
new min fval from sgd:  -1827.0336253339428
new min fval from sgd:  -1827.15381040396
new min fval from sgd:  -1827.1910750316774
new min fval from sgd:  -1827.2757573487354
new min fval from sgd:  -1827.284131959672
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [583.2519]
objective value function right now is: -1826.2636483069064
new min fval from sgd:  -1827.2974085440435
new min fval from sgd:  -1827.3162503411975
new min fval from sgd:  -1827.3357736875587
new min fval from sgd:  -1827.3490790084256
new min fval from sgd:  -1827.349187424646
new min fval from sgd:  -1827.3501831185288
new min fval from sgd:  -1827.3626228699009
new min fval from sgd:  -1827.3704993325307
new min fval from sgd:  -1827.3901103416283
new min fval from sgd:  -1827.43210941197
new min fval from sgd:  -1827.4376525394057
new min fval from sgd:  -1827.4406725903802
new min fval from sgd:  -1827.4569339554016
new min fval from sgd:  -1827.4651781646103
new min fval from sgd:  -1827.4652202534148
new min fval from sgd:  -1827.4676383769895
new min fval from sgd:  -1827.4758309869394
new min fval from sgd:  -1827.4816086454346
new min fval from sgd:  -1827.4865544779027
new min fval from sgd:  -1827.4936794520854
new min fval from sgd:  -1827.5038717099255
new min fval from sgd:  -1827.5052562282676
new min fval from sgd:  -1827.509244465869
new min fval from sgd:  -1827.5121124340492
new min fval from sgd:  -1827.521257903541
new min fval from sgd:  -1827.5286448406268
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [583.3897]
objective value function right now is: -1827.3898561491756
new min fval from sgd:  -1827.5340534741465
new min fval from sgd:  -1827.53986353831
new min fval from sgd:  -1827.5599290360674
new min fval from sgd:  -1827.562032980715
new min fval from sgd:  -1827.5759246649009
new min fval from sgd:  -1827.5829981738752
new min fval from sgd:  -1827.5921423184102
new min fval from sgd:  -1827.594466083585
new min fval from sgd:  -1827.5956221600964
new min fval from sgd:  -1827.5982349486067
new min fval from sgd:  -1827.6029022392524
new min fval from sgd:  -1827.6048148097127
new min fval from sgd:  -1827.6067651328165
new min fval from sgd:  -1827.611341924315
new min fval from sgd:  -1827.6207912396903
new min fval from sgd:  -1827.6260570213399
new min fval from sgd:  -1827.633894597994
new min fval from sgd:  -1827.6442849229093
new min fval from sgd:  -1827.6624436367144
new min fval from sgd:  -1827.6695121029209
new min fval from sgd:  -1827.6794734013395
new min fval from sgd:  -1827.684062621683
new min fval from sgd:  -1827.7025593772946
new min fval from sgd:  -1827.7100460761292
new min fval from sgd:  -1827.7270846781673
new min fval from sgd:  -1827.7303881873586
new min fval from sgd:  -1827.7392811835477
new min fval from sgd:  -1827.7433562498866
new min fval from sgd:  -1827.7456695233623
new min fval from sgd:  -1827.7458962497083
new min fval from sgd:  -1827.746563919157
new min fval from sgd:  -1827.7488956894615
new min fval from sgd:  -1827.7491347159232
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [583.43835]
objective value function right now is: -1827.7227047106187
min fval:  -1827.7491347159232
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -0.5507,   7.7617],
        [ -3.1868, -11.1883],
        [  0.3316,   1.5961],
        [  0.3316,   1.5961],
        [ -6.2735,  -7.7310],
        [  0.3316,   1.5961],
        [  0.3316,   1.5961],
        [  0.3318,   1.5960],
        [  0.2119,   7.6891],
        [  1.3138,   8.2108],
        [ -7.0329,   4.6564],
        [  0.8163,   6.4957],
        [  0.3316,   1.5961],
        [  0.3316,   1.5961],
        [  0.3316,   1.5961],
        [  0.3316,   1.5961],
        [ -6.4474,  -8.9752],
        [  0.3316,   1.5961],
        [  1.1312,   7.5223],
        [  1.2639,   7.9341],
        [  0.3316,   1.5961],
        [ -7.3316,  -8.0750]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ 6.5581, -7.1235, -2.3917, -2.3918, -5.3019, -2.3917, -2.3917, -2.3921,
         5.5046,  3.5191, 10.8918,  0.9495, -2.3918, -2.3917, -2.3917, -2.3917,
        -6.0253, -2.3918,  1.9108,  2.8151, -2.3917, -5.0398], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-1.6472e-01, -3.3723e-01, -3.8451e-03, -3.8448e-03, -7.4113e-02,
         -3.8451e-03, -3.8449e-03, -3.8436e-03, -1.0587e-01, -1.1707e-02,
         -4.3340e-01, -2.5716e-03, -3.8448e-03, -3.8450e-03, -3.8449e-03,
         -3.8449e-03, -8.9129e-02, -3.8447e-03, -3.3999e-03, -6.4584e-03,
         -3.8450e-03, -9.1101e-02],
        [-8.8094e+00,  1.2958e+01, -1.7175e-01, -1.7196e-01,  5.1711e+00,
         -1.7165e-01, -1.7193e-01, -1.7209e-01, -6.8832e+00, -2.6841e+00,
         -1.0314e+01, -4.7747e-01, -1.7196e-01, -1.7184e-01, -1.7195e-01,
         -1.7191e-01,  8.8059e+00, -1.7197e-01, -1.0072e+00, -2.3569e+00,
         -1.7185e-01,  7.8777e+00],
        [-1.6472e-01, -3.3723e-01, -3.8451e-03, -3.8448e-03, -7.4113e-02,
         -3.8451e-03, -3.8449e-03, -3.8436e-03, -1.0587e-01, -1.1707e-02,
         -4.3340e-01, -2.5716e-03, -3.8448e-03, -3.8450e-03, -3.8449e-03,
         -3.8449e-03, -8.9129e-02, -3.8447e-03, -3.3999e-03, -6.4584e-03,
         -3.8450e-03, -9.1101e-02],
        [-9.8953e+00,  1.4541e+01, -2.6956e-01, -2.6935e-01,  6.2541e+00,
         -2.6968e-01, -2.6920e-01, -2.6944e-01, -8.2695e+00, -3.5298e+00,
         -1.1654e+01, -1.0204e+00, -2.6936e-01, -2.6953e-01, -2.6922e-01,
         -2.6923e-01,  9.8716e+00, -2.6939e-01, -1.7885e+00, -3.5372e+00,
         -2.6950e-01,  9.2375e+00],
        [-7.5286e+00,  1.0772e+01, -7.0943e-02, -7.1013e-02,  5.0291e+00,
         -7.0907e-02, -7.1013e-02, -7.1099e-02, -5.9644e+00, -3.2124e+00,
         -8.9848e+00, -3.4706e-01, -7.1014e-02, -7.0971e-02, -7.1022e-02,
         -7.1005e-02,  7.6932e+00, -7.1018e-02, -8.8785e-01, -2.0593e+00,
         -7.0975e-02,  7.1574e+00],
        [-7.6000e-01,  1.1086e+00, -1.1618e-02, -1.1618e-02,  5.0761e-02,
         -1.1618e-02, -1.1618e-02, -1.1616e-02, -3.1902e-01, -4.4555e-02,
         -3.0822e+00, -2.4501e-02, -1.1618e-02, -1.1618e-02, -1.1618e-02,
         -1.1618e-02,  1.4853e-01, -1.1618e-02, -3.1840e-02, -4.0027e-02,
         -1.1618e-02,  1.2009e-01],
        [-1.6472e-01, -3.3723e-01, -3.8451e-03, -3.8448e-03, -7.4113e-02,
         -3.8451e-03, -3.8449e-03, -3.8436e-03, -1.0587e-01, -1.1707e-02,
         -4.3340e-01, -2.5716e-03, -3.8448e-03, -3.8450e-03, -3.8449e-03,
         -3.8449e-03, -8.9129e-02, -3.8447e-03, -3.3999e-03, -6.4584e-03,
         -3.8450e-03, -9.1101e-02],
        [-1.6472e-01, -3.3723e-01, -3.8451e-03, -3.8448e-03, -7.4113e-02,
         -3.8451e-03, -3.8449e-03, -3.8436e-03, -1.0587e-01, -1.1707e-02,
         -4.3340e-01, -2.5716e-03, -3.8448e-03, -3.8450e-03, -3.8449e-03,
         -3.8449e-03, -8.9129e-02, -3.8447e-03, -3.3999e-03, -6.4584e-03,
         -3.8450e-03, -9.1101e-02],
        [-1.6472e-01, -3.3723e-01, -3.8451e-03, -3.8448e-03, -7.4113e-02,
         -3.8451e-03, -3.8449e-03, -3.8436e-03, -1.0587e-01, -1.1707e-02,
         -4.3340e-01, -2.5716e-03, -3.8448e-03, -3.8450e-03, -3.8449e-03,
         -3.8449e-03, -8.9129e-02, -3.8447e-03, -3.3999e-03, -6.4584e-03,
         -3.8450e-03, -9.1101e-02],
        [-1.6472e-01, -3.3723e-01, -3.8451e-03, -3.8448e-03, -7.4113e-02,
         -3.8451e-03, -3.8449e-03, -3.8436e-03, -1.0587e-01, -1.1707e-02,
         -4.3340e-01, -2.5716e-03, -3.8448e-03, -3.8450e-03, -3.8449e-03,
         -3.8449e-03, -8.9129e-02, -3.8447e-03, -3.3999e-03, -6.4584e-03,
         -3.8450e-03, -9.1101e-02],
        [-1.4925e+00,  2.4874e+00,  1.3168e-02,  1.3167e-02,  1.1373e+00,
          1.3168e-02,  1.3167e-02,  1.3166e-02, -6.9185e-01, -7.4061e-03,
         -4.7636e+00, -1.2363e-02,  1.3167e-02,  1.3167e-02,  1.3167e-02,
          1.3168e-02,  1.7519e+00,  1.3167e-02, -1.2869e-02, -8.3037e-03,
          1.3167e-02,  1.4716e+00],
        [ 8.7307e+00, -1.2185e+01,  3.0545e-01,  3.0553e-01, -5.8644e+00,
          3.0543e-01,  3.0569e-01,  3.0570e-01,  7.1165e+00,  4.8078e+00,
          1.0617e+01,  1.2967e+00,  3.0552e-01,  3.0538e-01,  3.0563e-01,
          3.0567e-01, -8.6787e+00,  3.0551e-01,  2.2596e+00,  3.6215e+00,
          3.0540e-01, -8.6797e+00],
        [-1.6472e-01, -3.3723e-01, -3.8451e-03, -3.8448e-03, -7.4113e-02,
         -3.8451e-03, -3.8449e-03, -3.8436e-03, -1.0587e-01, -1.1707e-02,
         -4.3340e-01, -2.5716e-03, -3.8448e-03, -3.8450e-03, -3.8449e-03,
         -3.8449e-03, -8.9129e-02, -3.8447e-03, -3.3999e-03, -6.4584e-03,
         -3.8450e-03, -9.1101e-02],
        [-1.6472e-01, -3.3723e-01, -3.8451e-03, -3.8448e-03, -7.4113e-02,
         -3.8451e-03, -3.8449e-03, -3.8436e-03, -1.0587e-01, -1.1707e-02,
         -4.3340e-01, -2.5716e-03, -3.8448e-03, -3.8450e-03, -3.8449e-03,
         -3.8449e-03, -8.9129e-02, -3.8447e-03, -3.3999e-03, -6.4584e-03,
         -3.8450e-03, -9.1101e-02],
        [ 6.1744e-01,  7.0503e-01,  5.7205e-03,  5.7202e-03,  2.5190e-01,
          5.7206e-03,  5.7194e-03,  5.7147e-03,  4.1599e-01,  7.4856e-02,
          1.8619e+00,  4.0377e-02,  5.7201e-03,  5.7210e-03,  5.7195e-03,
          5.7195e-03,  2.5831e-01,  5.7198e-03,  4.7246e-02,  5.6101e-02,
          5.7208e-03,  3.3121e-01],
        [-1.6472e-01, -3.3723e-01, -3.8451e-03, -3.8448e-03, -7.4113e-02,
         -3.8451e-03, -3.8449e-03, -3.8436e-03, -1.0587e-01, -1.1707e-02,
         -4.3340e-01, -2.5716e-03, -3.8448e-03, -3.8450e-03, -3.8449e-03,
         -3.8449e-03, -8.9129e-02, -3.8447e-03, -3.3999e-03, -6.4584e-03,
         -3.8450e-03, -9.1101e-02],
        [-4.1154e+00,  6.8928e+00,  1.2121e-04,  1.3067e-04,  3.6596e+00,
          1.2252e-04,  1.3077e-04,  2.4543e-04, -2.7878e+00, -3.5331e-01,
         -7.7250e+00,  5.7389e-02,  1.3111e-04,  1.1750e-04,  1.2974e-04,
          1.3004e-04,  5.5387e+00,  1.3784e-04,  7.0179e-02, -2.7208e-02,
          1.1935e-04,  4.6120e+00],
        [-1.6472e-01, -3.3723e-01, -3.8451e-03, -3.8448e-03, -7.4113e-02,
         -3.8451e-03, -3.8449e-03, -3.8436e-03, -1.0587e-01, -1.1707e-02,
         -4.3340e-01, -2.5716e-03, -3.8448e-03, -3.8450e-03, -3.8449e-03,
         -3.8449e-03, -8.9129e-02, -3.8447e-03, -3.3999e-03, -6.4584e-03,
         -3.8450e-03, -9.1101e-02],
        [-1.6472e-01, -3.3723e-01, -3.8451e-03, -3.8448e-03, -7.4113e-02,
         -3.8451e-03, -3.8449e-03, -3.8436e-03, -1.0587e-01, -1.1707e-02,
         -4.3340e-01, -2.5716e-03, -3.8448e-03, -3.8450e-03, -3.8449e-03,
         -3.8449e-03, -8.9129e-02, -3.8447e-03, -3.3999e-03, -6.4584e-03,
         -3.8450e-03, -9.1101e-02],
        [-1.6472e-01, -3.3723e-01, -3.8451e-03, -3.8448e-03, -7.4113e-02,
         -3.8451e-03, -3.8449e-03, -3.8436e-03, -1.0587e-01, -1.1707e-02,
         -4.3340e-01, -2.5716e-03, -3.8448e-03, -3.8450e-03, -3.8449e-03,
         -3.8449e-03, -8.9129e-02, -3.8447e-03, -3.3999e-03, -6.4584e-03,
         -3.8450e-03, -9.1101e-02],
        [ 6.2438e-01,  7.1540e-01,  5.5524e-03,  5.5520e-03,  2.5265e-01,
          5.5524e-03,  5.5512e-03,  5.5464e-03,  4.2072e-01,  7.4994e-02,
          1.8721e+00,  4.0763e-02,  5.5520e-03,  5.5529e-03,  5.5513e-03,
          5.5513e-03,  2.5900e-01,  5.5517e-03,  4.7503e-02,  5.6127e-02,
          5.5526e-03,  3.3209e-01],
        [-1.6472e-01, -3.3723e-01, -3.8451e-03, -3.8448e-03, -7.4113e-02,
         -3.8451e-03, -3.8449e-03, -3.8436e-03, -1.0587e-01, -1.1707e-02,
         -4.3340e-01, -2.5716e-03, -3.8448e-03, -3.8450e-03, -3.8449e-03,
         -3.8449e-03, -8.9129e-02, -3.8447e-03, -3.3999e-03, -6.4584e-03,
         -3.8450e-03, -9.1101e-02]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.5279,  0.3178, -0.5279,  0.4965,  0.0044, -0.7880, -0.5279, -0.5279,
        -0.5279, -0.5279, -0.6982, -0.8073, -0.5279, -0.5279,  1.4331, -0.5279,
        -0.3220, -0.5279, -0.5279, -0.5279,  1.4848, -0.5279], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 3.6569e-03, -1.1468e+01,  3.6569e-03, -1.6694e+01, -8.8765e+00,
         -9.3096e-01,  3.6569e-03,  3.6569e-03,  3.6569e-03,  3.6569e-03,
         -1.4179e+00,  1.5940e+01,  3.6569e-03,  3.6569e-03,  4.3954e+00,
          3.6569e-03, -4.0872e+00,  3.6569e-03,  3.6569e-03,  3.6569e-03,
          4.7711e+00,  3.6569e-03]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -0.2440,   0.8537],
        [  0.0902,  12.6122],
        [  5.4243,   1.0410],
        [ 11.0310,   0.2302],
        [ -5.0864,  -1.3670],
        [ -1.9566,   0.6206],
        [  1.7169,  -2.2533],
        [ -0.1463,  -0.7260],
        [ -2.8468,   0.2558],
        [  7.7972,  -1.1100],
        [ -2.8535,   0.2508],
        [ -2.8389,   0.2614],
        [-10.0546,  -1.3997],
        [ -7.5659,   1.4813],
        [ -7.5035,   9.1419],
        [ -2.8178,   0.2777],
        [ -1.5825,   0.1681],
        [-12.8351,  -1.7881],
        [-11.8677,  -3.5899],
        [  5.2930,  11.3822],
        [  7.2620,   0.2876],
        [ 18.5807,   9.7952]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ -5.8438,   9.0517,   1.5477, -13.5191,  -1.8760,  -3.9560,  -2.6727,
         -3.2536,  -1.9857, -10.6162,  -1.9864,  -1.9860,   9.0743,   5.3846,
          6.5709,  -1.9873,  -4.0318,   5.9789,   0.3664,   9.7692, -10.9031,
          7.6819], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-1.9656e-01,  1.0677e+00, -2.3388e+00, -6.9248e-01,  1.9299e+00,
          2.3160e-01, -9.9200e-01, -3.3017e-01,  1.1168e+00, -5.4835e-01,
          1.1186e+00,  1.1144e+00, -1.2276e-01,  1.1969e+00,  6.0306e-01,
          1.1076e+00,  4.7254e-01,  1.3007e+00,  2.3081e+00,  5.0014e-01,
         -5.6600e-01, -1.1390e+00],
        [-3.6754e-03,  6.3538e-01, -5.0259e+00, -1.5248e-02,  3.0471e+00,
         -3.0970e-02, -5.8626e-01, -8.1143e-01,  2.2149e-01, -3.4887e-01,
          2.2188e-01,  2.2122e-01, -8.7189e-02,  1.7367e-01,  9.3547e-01,
          2.2108e-01, -3.5934e-02, -3.8051e-02,  2.6220e+00,  2.3736e-01,
         -3.5101e-02, -1.0765e+00],
        [-2.3401e-02,  4.1282e-01, -2.4792e+00, -1.3123e+00,  9.4744e-01,
         -3.0803e-02,  2.9510e+00,  3.1800e+00, -1.4361e-01, -1.5555e+00,
         -1.4189e-01, -1.4541e-01,  5.9197e-02, -3.5552e+00,  3.0093e-02,
         -1.5035e-01, -6.2788e-02,  2.5260e+00,  2.1319e+00, -5.6315e-01,
         -6.7499e-01, -4.4493e+00],
        [-8.0539e-03, -4.1371e-01, -2.7048e+00, -9.3009e-02,  2.0415e+00,
         -2.4451e-03, -9.2133e-01, -9.1276e-01,  6.9762e-02, -3.9251e-01,
          6.9304e-02,  7.0353e-02, -1.1880e+00, -3.3086e-01, -3.8083e-01,
          7.2127e-02, -4.0212e-04, -9.7597e-01,  1.2577e+00, -3.1021e-01,
         -4.4645e-02, -7.1664e-01],
        [ 1.4728e-01,  3.5128e+00, -3.9385e+00, -4.4205e+00,  3.0862e+00,
          4.2785e-01, -1.3858e-01, -6.0788e-01,  2.4397e+00, -8.8503e-01,
          2.4338e+00,  2.4466e+00,  1.2367e+00,  2.2828e+00,  1.1678e+00,
          2.4712e+00,  3.7023e-02,  1.6213e+00, -3.5546e-01,  1.2494e+00,
         -4.9275e+00, -8.2899e-01],
        [-3.8948e-02,  6.1096e-02, -3.4334e+00, -1.5882e+00,  1.2816e+00,
         -5.1251e-02,  4.0058e+00,  4.2212e+00, -1.3612e-01, -1.5643e+00,
         -1.3336e-01, -1.3906e-01,  6.0131e-01, -4.6012e+00,  1.6288e-01,
         -1.4724e-01, -5.4337e-02,  3.8152e+00,  2.3406e+00, -4.1470e-01,
         -9.1155e-01, -4.5074e+00],
        [ 3.7536e-02, -1.0465e+01,  2.3238e+00, -6.8793e+00,  4.7605e+00,
          3.1870e-01, -3.5971e+00, -2.5681e+00,  5.8628e-01, -3.5906e+00,
          5.8766e-01,  5.8462e-01,  3.8672e+00,  1.7617e+00, -4.7715e+00,
          5.7977e-01,  1.8905e-01,  5.6806e+00,  6.8958e+00, -9.8943e+00,
         -2.4852e+00, -6.9641e+00],
        [-4.8069e-03,  2.5259e+00, -1.0767e+00, -1.1753e+00,  5.1874e-02,
         -1.8952e-02,  3.3340e-02, -9.1188e-02, -7.0656e-02, -4.8852e-01,
         -7.0754e-02, -7.0563e-02,  3.5362e+00,  5.7332e-02,  5.4554e-01,
         -7.0295e-02, -5.8767e-02,  1.9316e+00, -5.2979e-01,  3.6181e+00,
         -4.9908e-01,  6.0226e+00],
        [ 2.2338e-03,  2.8930e+00,  1.7773e+00,  3.5901e+00, -1.1460e+00,
          3.0489e-03,  1.0372e+00,  5.6530e-01, -4.8939e-01, -2.7248e-01,
         -4.9135e-01, -4.8752e-01, -8.5168e+00,  7.8890e-01,  1.5109e+00,
         -4.8302e-01, -5.9502e-02, -6.7213e+00, -2.3990e+00,  4.5192e+00,
          5.2148e-01,  1.8672e+01],
        [-3.3309e-02, -7.3921e-01, -1.2656e+00,  2.5489e-01,  5.9359e-02,
         -2.7958e-02, -6.7064e-02,  1.8491e-01, -1.5958e-02,  4.7978e-01,
         -1.5567e-02, -1.6389e-02, -6.0322e-01, -6.6554e-01, -5.4883e-01,
         -1.7702e-02,  1.4696e-02, -3.6200e-01, -2.3269e-02, -7.1790e-01,
          1.4952e-01, -1.4689e+00],
        [ 1.6693e-02,  1.3112e+00,  1.0599e+00,  1.6996e-01,  2.7748e-02,
          1.2179e-02,  1.6910e+00,  9.7418e-01,  9.8216e-03,  3.0501e-01,
          9.6960e-03,  9.9593e-03,  3.4489e+00,  7.8886e-01,  2.4356e+00,
          1.0360e-02,  9.5811e-03,  1.8815e+00,  2.7306e-01,  1.3388e+00,
          3.3092e-02,  1.1049e+00],
        [ 3.1595e-02, -1.3337e+01, -1.0889e+01, -3.6530e-01,  4.0843e+00,
          4.1795e-01,  6.1477e+00,  6.1853e+00,  4.6089e+00, -2.3203e+00,
          4.6113e+00,  4.6053e+00,  7.1599e+00,  6.0096e+00, -6.1857e+00,
          4.5960e+00,  9.9624e-01,  1.1871e+01,  1.0726e+01, -1.4649e+01,
         -4.5379e-01, -1.7089e+01],
        [-1.0273e-01,  1.7269e+00, -4.5845e+00,  7.0601e-02,  3.3051e+00,
          8.0453e-02, -1.5331e+00, -1.5226e+00, -1.9974e-01, -1.3100e-01,
         -2.0042e-01, -1.9850e-01,  6.9401e-01,  8.2644e-01,  1.3457e+00,
         -1.9402e-01, -4.3642e-02,  6.9055e-01,  2.9898e+00,  1.0805e+00,
         -1.3356e-01, -2.3942e+00],
        [-2.4756e-02,  5.3810e-01,  2.0715e+00, -2.3006e+00, -9.8561e-02,
         -2.6794e-02, -8.3102e-01, -5.2384e-01, -4.9326e-02, -4.7595e-01,
         -4.9412e-02, -4.9222e-02,  1.3593e+00,  3.2977e-01,  2.2280e-01,
         -4.8898e-02, -4.7686e-02,  5.1509e-01, -2.8069e-02,  1.2302e+00,
         -1.0980e-01,  2.3517e+00],
        [-1.2219e-02, -8.9875e-01,  9.1316e-02,  3.4898e-01, -4.1768e-02,
         -1.4649e-02,  9.5866e-01,  7.0360e-01, -2.8664e-02, -4.7572e-01,
         -2.8691e-02, -2.8628e-02, -3.6918e+00, -3.1228e-01, -1.3780e+00,
         -2.8510e-02, -2.2614e-02, -8.3716e-02,  5.7449e-02, -1.7465e+00,
          9.3539e-01, -5.9159e+00],
        [-1.2094e-01, -7.3775e-01, -9.5133e-01, -7.5753e-01, -1.3573e+00,
         -3.6973e-01,  5.0923e+00,  4.6909e+00, -1.6650e+00, -1.0785e+00,
         -1.6652e+00, -1.6646e+00, -1.0589e+00, -9.7590e+00,  8.4583e-04,
         -1.6639e+00, -4.4754e-01, -1.8861e+00, -1.6448e+00, -6.1686e+00,
         -2.6962e-01, -5.2615e+00],
        [-3.3185e-01, -1.3861e+00,  3.0372e+00, -1.0232e+00, -5.4583e-03,
         -1.8973e-02,  1.3741e-01,  2.4681e-01,  2.4850e-01,  2.0739e-01,
          2.4930e-01,  2.4703e-01,  6.3343e+00, -2.7663e+00, -2.0628e+00,
          2.3952e-01,  5.0470e-02,  1.1761e+00, -6.5498e-03,  3.0671e-01,
          1.7693e-01,  3.1121e+00],
        [-1.8676e-02, -8.9881e-01, -1.5906e+00, -6.4008e-02,  2.9976e-02,
         -1.9045e-02, -3.3334e-01, -6.6159e-02, -2.4085e-02,  2.8126e-01,
         -2.3751e-02, -2.4449e-02, -1.6182e+00, -3.3852e-01, -4.9572e-01,
         -2.5501e-02, -7.8339e-03, -8.9714e-02, -2.0478e-03, -8.0305e-01,
         -4.0257e-02, -5.2847e-01],
        [ 8.0245e-02, -5.0631e+00, -1.7337e+00, -2.0799e+00,  4.2937e-01,
          1.2039e-01,  2.4211e+00,  1.9597e+00,  4.1178e-01, -1.7206e+00,
          4.1273e-01,  4.1065e-01,  4.1391e-01,  1.0950e+00, -3.1664e+00,
          4.0672e-01,  2.7786e-01,  2.5882e+00,  1.4450e-02,  1.5141e+00,
         -1.2259e+00, -1.8726e+00],
        [-2.3559e-02, -1.0720e+00,  6.2671e-02, -3.0518e+00, -1.9908e-01,
         -1.0025e-01,  5.0441e+00,  3.6750e+00, -2.2936e+00, -1.9513e+00,
         -2.2980e+00, -2.2839e+00,  1.5533e+00, -1.7307e+00, -8.1647e-01,
         -2.2459e+00, -3.8960e-02,  4.8772e+00,  9.8740e-01, -3.9603e+00,
         -8.2689e-01, -1.2098e+01],
        [-1.6210e-02, -4.7701e-01, -1.4588e+00,  1.6607e-01,  1.6225e-02,
         -9.7913e-03,  3.5331e-01,  2.5609e-01, -2.1540e-02,  4.0934e-01,
         -2.1225e-02, -2.1882e-02, -9.4730e-01, -4.0609e-01, -2.8178e-01,
         -2.2875e-02, -3.1930e-03, -1.6194e-01,  6.3760e-04, -5.2212e-01,
          6.8142e-02, -1.4701e+00],
        [ 5.9347e-03,  4.4696e+00, -8.8530e-01, -2.7644e-01,  6.8593e-02,
          1.6430e-02,  3.2050e+00,  1.9293e+00,  5.2057e-02,  5.3310e-01,
          5.2095e-02,  5.1988e-02,  3.9833e+00,  4.2611e-02,  1.6388e+00,
          5.1715e-02,  3.7027e-02,  4.0655e+00,  4.0061e-02,  3.6442e+00,
         -3.9749e-01,  1.4417e+00]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-2.2904, -2.6293, -2.4862, -3.2811, -2.3624, -2.7720,  0.7781, -2.0614,
        -2.9086, -1.5003,  0.7815, -2.6333, -1.9304,  2.6654,  0.5046, -3.4559,
         4.3113, -1.9548, -1.9379, -1.9737, -2.1202, -0.8254], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-4.2363e-03, -6.8306e-05, -3.2102e-04, -7.8362e-05, -3.3852e-02,
         -4.2373e-04, -1.1054e-03, -2.3049e-01, -2.3052e-01, -1.6098e-03,
         -2.3052e-01, -1.0755e-05, -6.7326e-04, -2.3052e-01, -1.2196e-05,
          5.1476e-05, -2.3054e-01, -5.2685e-04, -2.1710e-02, -1.9008e-06,
         -1.0861e-03, -2.3052e-01],
        [ 5.0329e-01, -1.1285e+00,  1.0054e+00,  1.5395e-01,  2.2683e+00,
          1.4766e+00,  2.0986e+00,  1.3515e+00,  1.2844e+00,  1.3622e-01,
          4.5359e+00, -6.9865e+00, -1.9670e+00,  1.1491e+00,  1.6992e-03,
          1.8032e+00,  1.1567e+00,  2.6687e-01,  1.7557e+00,  6.2853e-01,
          4.8197e-01,  2.4415e+00],
        [-2.7845e-03, -9.1697e-05, -3.2372e-04, -5.6306e-05, -2.2684e-02,
         -3.9020e-04, -1.1317e-03, -1.5963e-01, -1.5965e-01, -1.2174e-03,
         -1.5967e-01, -7.1761e-06, -6.4749e-04, -1.5966e-01, -5.7306e-05,
          1.2331e-04, -1.5968e-01, -7.3865e-04, -1.1787e-02, -3.8077e-05,
         -1.0871e-03, -1.5966e-01],
        [-2.7750e-03, -4.8764e-05, -1.0988e-04, -7.1081e-05, -1.7428e-02,
         -1.6346e-04, -7.7123e-05, -8.9348e-02, -8.9346e-02, -3.5002e-04,
         -8.9353e-02, -1.3320e-05, -5.2294e-04, -8.9356e-02, -1.9175e-05,
         -5.0110e-05, -8.9365e-02, -6.3881e-04, -2.0248e-03, -8.8679e-05,
         -1.8875e-04, -8.9349e-02],
        [-1.0254e+00,  1.4601e+00,  1.9303e+00,  1.6169e+00,  4.1835e-01,
          2.7431e+00,  7.4253e+00,  1.6120e+00, -7.8501e-01,  3.2642e-01,
          1.9719e-01, -1.1291e+01,  1.2129e+00,  5.9082e+00,  3.2242e+00,
          4.5177e+00,  5.7870e+00,  3.8301e-01,  2.5026e+00,  8.5887e+00,
          5.6099e-01,  1.0095e+00],
        [-1.9603e-03, -5.2245e-04, -9.0106e-04,  8.1472e-06, -2.2302e-01,
          7.1424e-05,  5.5764e-01, -1.1033e-01,  2.6707e-01, -5.7576e-03,
          3.1301e-02, -4.6064e-05, -2.6776e-03,  1.7346e-01, -6.7417e-05,
         -4.5521e-05,  1.7855e-01, -1.4600e-03, -3.6136e-03, -3.4175e-06,
         -3.6301e-03,  9.2631e-01],
        [-2.1181e-03, -8.3501e-05,  2.9384e-05, -9.3968e-05, -1.1996e-02,
          5.6971e-05, -1.6186e-03, -9.3823e-02, -9.3832e-02, -6.9954e-05,
         -9.3843e-02, -2.8473e-06, -9.2564e-04, -9.3845e-02,  5.0480e-06,
          3.4804e-05, -9.3862e-02, -7.9459e-04, -4.8994e-03, -2.1698e-04,
         -4.3191e-04, -9.3815e-02],
        [ 1.2940e-03,  3.8695e+00, -8.4501e-01,  3.4476e+00, -1.9833e-01,
         -3.0529e-01,  3.1260e+00, -1.3406e+00,  1.2689e+00,  1.2970e-02,
         -6.1632e-02,  2.3373e+00,  4.1013e+00,  1.7342e-01,  7.3831e-01,
         -2.4157e+00,  1.4634e-01,  2.3205e-04, -2.9757e-02,  1.1859e+00,
         -1.6951e-02, -2.7152e-01],
        [-3.0885e-03, -3.6841e-05, -2.0791e-04, -5.4575e-05, -1.9795e-02,
         -2.4528e-04, -1.3246e-03, -1.3438e-01, -1.3439e-01, -9.0626e-04,
         -1.3439e-01, -6.3535e-06, -6.4713e-04, -1.3440e-01, -4.4543e-05,
         -3.0557e-05, -1.3440e-01, -6.8769e-04, -8.8469e-03, -5.0107e-05,
         -9.6615e-04, -1.3439e-01],
        [-2.0739e-03, -1.8914e-05, -8.9744e-05,  8.0988e-05, -5.3063e-03,
         -2.3721e-04, -3.3146e-03, -1.0132e-01, -1.0131e-01, -2.4858e-04,
         -1.0132e-01, -3.3793e-06, -3.0835e-04, -1.0133e-01, -2.0586e-05,
         -4.1559e-05, -1.0135e-01, -9.3073e-04, -9.8866e-03, -2.5322e-04,
         -1.3992e-04, -1.0131e-01],
        [ 1.8466e+00,  2.5648e+00,  2.1830e+00, -1.6080e-02,  6.7834e+00,
          2.9088e+00, -1.3528e+01,  5.8190e+00,  1.8447e+00, -2.8927e-01,
          4.7363e+00, -3.3558e+00,  3.4413e+00, -2.4181e+00,  1.2189e+00,
          5.9339e+00, -2.3524e+00,  2.0327e-02, -1.0406e+00, -8.4797e-01,
          4.2189e-01,  2.1312e+00],
        [ 2.0078e+00, -2.9249e+00, -3.6523e+00, -1.0011e+00,  1.4985e+00,
         -3.7670e+00, -1.1528e+00,  7.2449e-01,  6.1771e+00,  6.5115e-01,
          1.9975e+00,  1.6556e+01, -3.8331e+00,  9.4529e-01,  1.6731e+00,
         -4.7273e+00,  8.6956e-01,  5.9732e-01,  1.0404e+00, -2.7497e+00,
          8.1167e-01,  2.0240e+00],
        [-3.5655e-03, -1.1178e-04, -3.7359e-04, -6.9717e-05, -2.6960e-02,
         -4.7226e-04, -1.3904e-03, -2.0842e-01, -2.0845e-01, -1.6787e-03,
         -2.0846e-01, -5.6959e-06, -9.4443e-04, -2.0845e-01, -3.4224e-05,
          2.7804e-05, -2.0848e-01, -4.1272e-04, -1.9744e-02, -8.1798e-05,
         -9.5887e-04, -2.0845e-01],
        [-4.1865e-03, -7.7856e-05, -3.4715e-04, -8.0911e-05, -3.0758e-02,
         -5.1034e-04, -6.0976e-04, -2.1263e-01, -2.1266e-01, -1.4986e-03,
         -2.1266e-01, -1.1866e-05, -6.7972e-04, -2.1266e-01, -3.7569e-05,
          1.3924e-04, -2.1268e-01, -5.2013e-04, -2.0031e-02,  1.7357e-05,
         -1.1605e-03, -2.1266e-01]], device='cuda:0'))])
xi:  [583.43915]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 979.8346187507476
W_T_median: 909.9803699624752
W_T_pctile_5: 583.7836135799589
W_T_CVAR_5_pct: 221.72418015654185
Average q (qsum/M+1):  57.52916299143145
Optimal xi:  [583.43915]
Expected(across Rb) median(across samples) p_equity:  0.08712396426755335
obj fun:  tensor(-1827.7491, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/factor_decumulation/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:262: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/factor_decumulation/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/factor_decumulation/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: MC_everything
Objective function: mean_cvar_single_level
Tracing param: 0.2
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       22  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       22  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 22)      True          22  
0     (22, 22)      True          22  
0      (22, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       22  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       22  logistic_sigmoid   
0        obj.layers[3]         3  output_layer       14           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 22)      True          22  
0     (22, 22)      True          22  
0     (22, 14)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -8.5715,   6.4621],
        [ -8.3669,  -9.0182],
        [ -5.1223,   3.2445],
        [  8.0669,   4.1508],
        [-11.4280,  -6.0457],
        [ -6.4858,   4.0851],
        [  6.0779,   4.9126],
        [  9.1747,   0.7713],
        [ -8.3119,   6.0846],
        [ -8.3147,   6.0977],
        [ -8.4882,   6.6116],
        [ -8.6931,   5.7529],
        [  7.8819,   3.3034],
        [ -1.2974,   1.0853],
        [  5.4594,  -0.3288],
        [  5.2299,   5.2824],
        [-11.7613,  -7.4762],
        [  7.7973,   4.2640],
        [ -8.5799,   5.8746],
        [ -7.8535,   5.7472],
        [ -1.2944,   1.0845],
        [-21.4386,  -5.7294]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ 4.8764, -5.7404, -3.0406, -9.5323, -3.7687, -2.3429, -8.4043, -9.1228,
         4.2727,  3.0356,  5.1757,  1.5461, -8.9288, -3.8883, -8.9159, -8.5427,
        -4.0692, -9.2749,  1.8685,  2.4405, -3.8889, -4.6902], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1574e-03, -1.6502e-02, -2.2728e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1088e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [-9.2453e+00,  1.2482e+01, -7.2066e-01,  7.0332e+00,  4.6981e+00,
         -1.2007e+00,  4.5523e+00,  6.2080e+00, -7.5674e+00, -3.0869e+00,
         -1.0021e+01, -1.8126e+00,  5.8578e+00, -1.6237e-01,  6.8999e-01,
          5.4520e+00,  8.4865e+00,  8.0426e+00, -2.2762e+00, -3.8127e+00,
         -1.9618e-01,  8.7135e+00],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2751e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-9.6515e+00,  1.3280e+01, -9.1434e-01,  9.3871e+00,  5.7620e+00,
         -1.3190e+00,  6.4927e+00,  6.8045e+00, -8.3770e+00, -3.3906e+00,
         -1.0939e+01, -2.1716e+00,  6.5179e+00, -2.1870e-01,  2.0491e+00,
          4.1453e+00,  9.2888e+00,  7.8384e+00, -2.6898e+00, -4.4743e+00,
         -1.9003e-01,  9.7752e+00],
        [-7.9773e+00,  1.0315e+01,  2.5895e-01,  4.6608e+00,  4.9211e+00,
          1.7041e-02,  2.1882e+00,  6.8647e+00, -6.6734e+00, -4.8263e+00,
         -8.8073e+00, -2.8795e+00,  6.4311e+00,  1.6629e-01,  1.1111e+00,
          5.0411e+00,  7.6765e+00,  1.1081e+01, -3.5739e+00, -4.0927e+00,
          1.6082e-01,  8.5887e+00],
        [-7.6589e+00,  9.2592e+00,  7.9739e-02,  3.9257e+00,  4.5700e+00,
          1.0005e-01,  2.1053e+00,  4.6166e+00, -6.0015e+00, -3.8545e+00,
         -9.2106e+00, -1.7570e+00,  5.7099e+00, -1.2986e-02,  5.9836e-02,
          4.9159e+00,  7.0161e+00,  9.4703e+00, -2.3319e+00, -3.1763e+00,
         -1.3208e-02,  7.3285e+00],
        [-2.2581e-01, -1.6549e-01,  1.7511e-03, -1.2938e-02, -1.1903e-01,
          1.1578e-03, -1.6509e-02, -2.2839e-03, -1.8738e-01, -6.9338e-02,
         -2.5288e-01, -1.2692e-02, -9.1165e-03,  1.2292e-02,  1.9855e-02,
         -1.7662e-02, -1.7966e-01, -1.2937e-02, -1.9683e-02, -4.9682e-02,
          1.2307e-02, -3.1400e-02],
        [-2.2584e-01, -1.6546e-01,  1.7508e-03, -1.2931e-02, -1.1901e-01,
          1.1573e-03, -1.6502e-02, -2.2704e-03, -1.8735e-01, -6.9322e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9856e-02,
         -1.7657e-02, -1.7959e-01, -1.2929e-02, -1.9678e-02, -4.9672e-02,
          1.2308e-02, -3.1398e-02],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2752e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2730e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1088e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [-7.4230e+00,  9.2761e+00,  8.2691e-02,  4.6883e+00,  4.4150e+00,
          1.2211e-01,  2.9895e+00,  3.5408e+00, -6.2114e+00, -3.5923e+00,
         -9.4198e+00, -1.8627e+00,  4.7011e+00, -1.9985e-02, -6.0281e-02,
          5.2032e+00,  7.0797e+00,  8.3206e+00, -2.3235e+00, -3.3515e+00,
         -1.9947e-02,  7.4397e+00],
        [ 7.9326e+00, -1.0706e+01,  4.0837e-01, -9.2089e+00, -5.7725e+00,
          6.6403e-01, -4.8629e+00, -5.8385e+00,  6.6214e+00,  5.0109e+00,
          9.6232e+00,  3.3999e+00, -5.8456e+00, -1.3669e-01, -1.4453e+00,
         -3.3601e+00, -8.4017e+00, -9.5444e+00,  3.9084e+00,  4.3412e+00,
         -1.3169e-01, -9.7519e+00],
        [-2.2583e-01, -1.6545e-01,  1.7507e-03, -1.2931e-02, -1.1900e-01,
          1.1572e-03, -1.6503e-02, -2.2678e-03, -1.8733e-01, -6.9320e-02,
         -2.5297e-01, -1.2687e-02, -9.1093e-03,  1.2293e-02,  1.9856e-02,
         -1.7657e-02, -1.7958e-01, -1.2930e-02, -1.9677e-02, -4.9670e-02,
          1.2308e-02, -3.1399e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2931e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2732e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [ 6.5891e-01,  3.0868e-01,  8.3566e-03,  3.5747e-02,  2.1159e-01,
          5.3475e-03,  5.7464e-02,  2.6629e-01,  5.5272e-01,  2.6083e-01,
          7.4008e-01,  8.5701e-02,  7.1654e-02,  3.7717e-02,  5.6900e-02,
          8.1005e-02,  2.9146e-01,  3.6840e-02,  1.1119e-01,  2.1066e-01,
          3.7716e-02,  1.3910e-01],
        [-2.2585e-01, -1.6548e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2733e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1087e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2307e-02, -3.1398e-02],
        [-7.5648e+00,  9.6323e+00,  3.4567e-02,  4.2023e+00,  4.4635e+00,
         -1.3328e-01,  2.0401e+00,  5.3264e+00, -6.2784e+00, -3.7048e+00,
         -9.3470e+00, -2.0562e+00,  5.8618e+00, -3.3635e-02,  2.0363e-01,
          5.0433e+00,  7.2814e+00,  9.5323e+00, -2.4148e+00, -3.3678e+00,
         -3.5727e-02,  7.7623e+00],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2750e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2744e-03, -1.8737e-01, -6.9326e-02,
         -2.5298e-01, -1.2689e-02, -9.1087e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2931e-02, -1.1901e-01,
          1.1574e-03, -1.6502e-02, -2.2722e-03, -1.8735e-01, -6.9324e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9673e-02,
          1.2308e-02, -3.1398e-02],
        [ 6.6450e-01,  3.1201e-01,  8.4127e-03,  3.4696e-02,  2.1235e-01,
          5.3877e-03,  5.6376e-02,  2.6891e-01,  5.5678e-01,  2.6166e-01,
          7.4701e-01,  8.5769e-02,  7.1346e-02,  3.8211e-02,  5.7275e-02,
          8.0058e-02,  2.9347e-01,  3.5786e-02,  1.1132e-01,  2.1139e-01,
          3.8209e-02,  1.3913e-01],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2753e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-2.4313,  0.0078, -2.4313,  0.0873, -0.2625, -0.5234, -2.4313, -2.4314,
        -2.4313, -2.4313, -0.4369, -0.2571, -2.4314, -2.4313,  4.5769, -2.4313,
        -0.4006, -2.4313, -2.4313, -2.4313,  4.6668, -2.4313], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[  0.0334, -10.4940,   0.0334, -15.8008,  -9.7979,  -6.9452,   0.0334,
           0.0334,   0.0334,   0.0334,  -7.0927,  14.9535,   0.0334,   0.0334,
           4.2936,   0.0334,  -7.0565,   0.0334,   0.0334,   0.0334,   4.7631,
           0.0334]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 1.0813e+01,  2.9656e+00],
        [ 5.5664e-01,  1.1757e+01],
        [ 1.8618e+01,  2.3664e+00],
        [ 1.0637e+01,  1.5273e-02],
        [-1.4941e+01, -2.2181e+00],
        [-1.2849e+00,  1.3570e+00],
        [-1.2800e+00,  1.3116e+00],
        [-1.7122e+00,  6.5637e-01],
        [-2.0284e+00,  2.5259e-01],
        [ 9.3477e+00, -5.2188e-01],
        [-1.9314e+00,  2.3251e-01],
        [-1.8788e+00,  4.0167e-01],
        [-1.0523e+01, -1.6251e+00],
        [-8.3398e+00,  5.3496e+00],
        [-7.4426e+00,  1.0247e+01],
        [-1.2446e+01, -2.8588e+00],
        [-1.4240e+01, -3.1016e+00],
        [-1.0901e+01, -2.0063e+00],
        [-1.0106e+01, -2.4687e+00],
        [ 3.1771e+00,  1.1429e+01],
        [ 1.0907e+01,  2.2476e+00],
        [ 1.1102e+01,  1.0847e+01]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-5.5365,  7.0663,  2.9709, -9.6018, -1.5848, -4.5127, -4.5185, -4.9090,
        -4.9531, -9.4875, -4.9847, -4.9560,  5.4223,  3.0397,  6.7011, -3.5168,
        -2.9913,  3.2472,  0.4201,  7.7652, -4.3018,  6.4326], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 6.1957e-01, -3.4634e+00, -1.7479e+00,  1.1905e+00,  1.2460e-02,
          1.1948e-01,  1.3226e-01,  4.3984e-02, -1.1598e-02,  1.0215e+00,
         -6.1706e-03,  2.4414e-03, -2.5313e+00,  1.1746e+00, -7.8526e-01,
         -9.2734e-03,  2.7572e-03, -2.7562e+00, -1.8971e+00, -2.6434e+00,
         -4.2419e-01,  3.0293e-02],
        [-4.6968e-01, -1.5418e-01, -2.2179e+00, -4.7229e-01, -1.4815e-02,
         -2.6861e-02, -2.4100e-02,  6.5293e-03, -1.5585e-02, -3.8766e-01,
         -1.6068e-02, -1.1227e-02, -1.0214e+00, -1.1716e-01, -1.0616e-01,
         -5.8386e-03, -7.9498e-03, -5.2026e-01, -1.9652e-01, -4.4158e-01,
         -1.2068e+00, -1.2289e+00],
        [-9.0043e-01, -3.1328e-01, -2.4749e+00, -1.0214e+00, -5.5072e-03,
         -2.2407e-02, -1.9453e-02, -7.7448e-03,  4.4606e-03, -9.3610e-01,
          4.1020e-03,  2.5876e-03, -1.2488e+00, -4.6992e-02, -9.2699e-02,
         -2.2626e-03, -3.5666e-03, -6.7176e-01, -2.4800e-01, -8.7567e-01,
         -1.3802e+00, -7.7155e-01],
        [-4.7184e-01, -1.5540e-01, -2.2143e+00, -4.7815e-01, -1.4473e-02,
         -2.7281e-02, -2.4476e-02,  6.5809e-03, -1.5495e-02, -3.9563e-01,
         -1.5975e-02, -1.1107e-02, -1.0396e+00, -1.1822e-01, -1.0605e-01,
         -5.8775e-03, -7.9716e-03, -5.2621e-01, -1.9589e-01, -4.4421e-01,
         -1.2127e+00, -1.2341e+00],
        [-4.8450e-01, -1.6921e-01, -2.2399e+00, -4.9569e-01, -1.4212e-02,
         -2.5472e-02, -2.2971e-02,  5.3544e-03, -1.0943e-02, -4.2767e-01,
         -1.1482e-02, -7.9784e-03, -1.0434e+00, -1.0826e-01, -9.0719e-02,
         -6.2509e-03, -8.3116e-03, -5.2892e-01, -2.1129e-01, -4.5420e-01,
         -1.2241e+00, -1.0613e+00],
        [ 3.0119e-01,  9.1885e-01, -1.5837e+00, -8.5542e-01, -1.1953e-02,
         -1.9274e+00, -1.8752e+00, -1.4092e+00, -5.5076e-01,  1.0780e+00,
         -4.5548e-01, -9.9188e-01, -3.9286e+00,  1.1415e+00,  2.2999e+00,
         -1.2239e-02, -1.3323e-02, -2.7068e+00, -9.7625e-01,  4.2057e-01,
         -1.0808e+00, -1.2393e+00],
        [ 2.4582e-01, -1.1721e+01,  5.7285e-01, -6.6182e+00,  3.3458e+00,
          1.7362e-01,  1.7999e-01,  2.0080e-01,  2.8786e-01, -4.5146e+00,
          2.9196e-01,  1.9339e-01,  3.6973e+00, -2.2846e+00, -8.2839e+00,
          2.5629e+00,  2.7897e+00,  3.3397e+00,  3.6998e+00, -1.2216e+01,
          1.0269e-01, -7.8724e+00],
        [-2.7710e+00,  3.8384e+00, -3.8614e+00, -5.2497e+00,  1.4955e-01,
         -5.1488e-01, -5.0931e-01, -4.0831e-01, -1.3933e-01, -4.9036e+00,
         -1.0681e-01, -2.8754e-01,  2.6586e+00,  3.1018e+00,  6.0454e+00,
          5.3721e-01,  5.1709e-01,  2.4000e+00,  1.7467e+00,  2.8980e+00,
         -1.8615e+00,  1.3298e+00],
        [ 5.3996e+00,  1.7695e+01,  2.7980e+00,  6.7002e+00, -6.8933e+00,
          1.9716e-02,  1.5955e-02,  1.6031e-02, -1.9886e-01,  4.1219e+00,
         -1.8883e-01,  2.3240e-02, -8.0362e+00,  3.0849e+00,  1.4710e+01,
         -3.3033e+00, -3.8057e+00, -7.4740e+00, -6.2744e+00,  1.9113e+01,
          5.0855e+00,  2.1580e+01],
        [-4.6054e-01, -1.5864e-01, -2.1828e+00, -4.7962e-01, -1.3132e-02,
         -2.7434e-02, -2.4527e-02,  7.6509e-03, -1.3661e-02, -3.9854e-01,
         -1.4154e-02, -9.5939e-03, -1.0591e+00, -1.2246e-01, -9.9910e-02,
         -5.2767e-03, -7.3107e-03, -5.5050e-01, -2.1282e-01, -4.5037e-01,
         -1.2105e+00, -1.2384e+00],
        [-9.3210e-01, -5.0637e-01, -2.5650e+00, -1.2297e+00,  5.1007e-03,
         -1.3266e-02, -1.0812e-02, -6.5037e-03, -1.3910e-03, -1.1288e+00,
         -1.7836e-03, -1.9456e-03, -7.9371e-01, -5.5349e-02, -8.6527e-02,
          5.2059e-03,  5.8080e-03, -8.8163e-01, -4.5943e-01, -1.6628e+00,
         -1.1149e+00, -5.6400e-01],
        [-2.8460e+00, -1.8825e+01, -9.7046e+00, -3.0631e+00,  6.2381e+00,
          2.2284e-02,  2.2216e-02,  3.8058e-02,  1.2254e-02, -4.6393e+00,
          2.0356e-03,  4.3669e-02,  7.6060e+00, -3.1393e+00, -1.1899e+01,
          2.9927e+00,  3.5772e+00,  7.5127e+00,  7.0486e+00, -2.2653e+01,
         -1.0357e+01, -2.5603e+01],
        [-4.7448e-01, -1.5413e-01, -2.2021e+00, -4.7761e-01, -1.5017e-02,
         -2.6936e-02, -2.4189e-02,  6.2971e-03, -1.5709e-02, -3.9518e-01,
         -1.6194e-02, -1.1365e-02, -1.0353e+00, -1.1675e-01, -1.0676e-01,
         -6.0131e-03, -8.0879e-03, -5.2030e-01, -1.9318e-01, -4.4328e-01,
         -1.2192e+00, -1.2259e+00],
        [-6.9231e-01,  3.0014e+00,  2.7786e+00, -1.3175e+00,  3.0620e-04,
         -1.3308e-01, -1.3059e-01, -4.6677e-03, -1.5150e-02, -1.3574e+00,
         -1.8928e-02, -2.6791e-03,  2.1880e+00, -4.4040e-01,  8.1953e-01,
         -1.8323e-02, -1.1176e-02,  1.4720e+00,  4.3629e-01,  2.4554e+00,
          8.6002e-02, -2.4341e-01],
        [ 3.0175e+00, -1.5929e-01,  3.1082e+00,  1.6836e+00, -3.7655e+00,
          1.7569e-01,  1.8810e-01,  2.3150e-01, -5.4313e-01,  3.8072e+00,
         -5.3327e-01,  1.6719e-01,  6.0672e-02, -2.5586e+00, -3.6155e+00,
         -4.5190e+00, -4.8662e+00,  1.6404e-01, -1.7814e-01, -2.9936e-01,
          2.7050e+00, -1.8862e+00],
        [-6.1343e-01, -2.0997e-01, -2.3786e+00, -7.6186e-01, -1.9840e-02,
         -3.2273e-02, -3.0458e-02, -4.7454e-03,  5.8161e-03, -6.4208e-01,
          6.0534e-03,  3.5540e-03, -1.0330e+00, -6.3106e-02, -1.0050e-01,
         -7.6629e-03, -1.3412e-02, -4.8643e-01, -1.8407e-01, -5.2743e-01,
         -1.3866e+00, -9.2565e-01],
        [ 2.3232e-01,  3.1081e+00,  2.1861e+00,  1.7924e+00,  8.3474e-01,
         -4.2057e-01, -3.7750e-01, -8.6959e-02, -6.3586e-02,  1.4179e+00,
         -6.1088e-02, -4.4329e-02,  1.9436e-01, -4.4091e-01,  1.1123e+00,
          4.9760e-01,  7.0823e-01, -1.6870e-01, -3.9429e-01, -1.1351e+00,
          1.7979e-02, -1.2019e+00],
        [-9.3911e-03, -3.8280e+00, -3.1866e-01, -2.0025e+00, -3.0075e-02,
          4.3973e-02,  5.3990e-02,  1.0353e-01,  1.4874e-01, -1.8588e+00,
          1.5683e-01,  1.3914e-01, -1.0725e-01, -2.1520e-01, -2.7783e-01,
          5.4541e-02,  7.3731e-03, -1.3880e+00, -8.0744e-01, -5.4071e+00,
         -9.3933e-01,  6.6525e-02],
        [-2.0923e+00,  1.6783e+00,  2.1031e+00, -6.6800e+00,  1.9109e-04,
         -8.2756e-01, -7.5222e-01, -4.3503e-01, -1.2713e-01, -3.5556e+00,
         -7.5366e-02, -3.3382e-01,  9.4887e+00, -1.2212e+00,  5.7869e+00,
         -6.4339e-04, -3.5999e-03,  9.1765e+00,  6.6382e+00,  6.8362e-01,
          2.7993e-01, -2.2562e+00],
        [-5.5183e+00, -1.5095e+01, -2.8824e-01, -4.9346e+00,  5.3321e+00,
          1.5448e-01,  1.5735e-01,  1.6104e-01,  5.9928e-01, -2.7075e+00,
          5.5855e-01,  1.3923e-01,  3.0535e+00,  8.4196e-01, -6.5453e+00,
          4.6053e+00,  5.0922e+00,  3.6158e+00,  3.8865e+00, -1.4997e+01,
         -2.8857e+00, -4.2056e+00],
        [ 4.0156e-01, -1.0952e+00, -1.5738e+00, -4.3123e-01, -8.5229e-03,
         -6.6402e-01, -6.0136e-01, -2.4497e-01, -5.3144e-02, -2.8255e-01,
         -5.5575e-02, -9.1214e-02, -2.1121e+00,  1.5978e+00,  1.4435e+00,
         -1.0813e-03, -1.8711e-03, -2.1573e+00, -8.6345e-01, -1.7321e+00,
         -7.5512e-01,  5.2300e-01],
        [-1.9858e+00,  2.9033e+00, -2.5269e+00, -2.1485e+00,  2.2962e+00,
         -1.4441e+00, -1.3739e+00, -7.3427e-01,  6.2891e-02,  2.1944e-01,
          6.1358e-02, -2.6440e-01,  7.4516e-02,  1.7016e+00,  3.0581e+00,
          1.5196e+00,  1.8766e+00,  6.5632e-01,  1.1298e+00,  1.3664e+00,
         -2.7325e+00, -7.5516e-01]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-1.8466, -2.2256, -2.5068, -2.1943, -2.2514, -1.8834,  0.6255, -4.9456,
        -2.2024, -2.2158, -2.5964,  0.0491, -2.2135,  3.0825,  3.0734, -2.4047,
         2.5296, -1.0040,  2.4991, -0.5295, -2.0766, -2.4070], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-1.5234e-02,  7.2296e-05, -1.5502e-04,  5.9106e-05,  9.2680e-05,
         -2.2228e-02, -7.7352e-03, -1.5990e-01, -1.5103e+00,  6.1218e-05,
         -1.5306e-04, -1.3007e-05,  6.3929e-05, -1.5060e+00, -1.5008e+00,
         -2.1007e-04, -1.4999e+00, -5.4381e-03, -6.9054e-01, -3.7369e-03,
         -4.7102e-03, -3.5212e-02],
        [-8.7292e-03, -1.4222e-03,  7.6021e-04, -1.3898e-03, -1.5771e-03,
         -1.3307e-02, -5.1882e-03, -1.0878e-01, -8.2132e-01, -1.3260e-03,
          8.8522e-04, -2.6449e-04, -1.4244e-03, -8.2289e-01, -8.1366e-01,
          5.1250e-04, -8.1735e-01,  1.2221e-03, -3.1415e-01, -6.8756e-03,
          4.4122e-03, -3.5269e-02],
        [-2.1229e-02, -5.1093e-04, -3.4543e-04, -5.1941e-04, -5.4632e-04,
         -1.8385e-02, -9.4420e-03, -1.3731e-01, -1.4218e+00, -5.2075e-04,
         -3.2211e-04,  2.3184e-05, -5.1689e-04, -1.4173e+00, -1.4127e+00,
         -3.8173e-04, -1.4125e+00, -6.1909e-03, -6.2055e-01, -3.7929e-03,
         -7.1839e-03, -2.7972e-02],
        [-9.4172e-03, -2.1938e-04, -2.2482e-04, -2.0759e-04, -2.8288e-04,
         -1.6622e-02, -7.4112e-03, -1.3137e-01, -1.2415e+00, -2.0252e-04,
         -2.1593e-04, -7.4338e-05, -2.1553e-04, -1.2385e+00, -1.2343e+00,
         -1.4845e-04, -1.2328e+00, -5.0361e-03, -5.7108e-01, -3.7365e-03,
         -7.0540e-03, -2.5170e-02],
        [-1.0969e+00,  7.0714e-02,  2.8031e-01,  4.2693e-02,  2.8583e-01,
          5.4877e-01,  3.6379e+00, -1.3225e+00, -3.0535e+00,  2.8854e-01,
          9.2331e-01, -1.4907e+01,  2.7428e-02,  3.6135e+00,  3.4661e+00,
         -2.3553e-02,  3.3911e+00,  1.2464e+00,  2.0600e+00,  5.6362e+00,
         -4.8358e-01,  4.4222e-01],
        [-1.1325e-02, -1.4138e-04,  1.4500e-04, -1.5008e-04, -1.0196e-03,
         -8.7395e-03, -5.0212e-04, -1.4891e-01, -9.6424e-01, -1.5847e-04,
          8.4481e-05, -6.7668e-04, -1.4540e-04, -9.6261e-01, -9.4804e-01,
         -9.4017e-05, -9.5700e-01,  4.4294e-03, -4.5741e-01, -5.5136e-03,
          2.2288e-03, -3.6784e-02],
        [-2.4271e-02, -7.7962e-04, -2.2040e-04, -7.9007e-04, -5.4691e-04,
         -1.4880e-02, -9.2166e-03, -1.1032e-01, -1.2944e+00, -7.8678e-04,
         -1.4609e-04, -3.3668e-05, -7.9327e-04, -1.2897e+00, -1.2879e+00,
         -3.7474e-04, -1.2861e+00, -9.7262e-03, -5.3746e-01, -3.8536e-03,
         -1.0548e-02, -2.4508e-02],
        [ 3.9237e+00, -6.2937e-02,  8.2976e-01, -8.9553e-02,  1.8773e-01,
          2.5280e+00,  4.4063e+00, -5.1176e-01,  2.7121e+00,  1.5038e-01,
          2.1898e+00, -6.3975e+00, -1.0291e-01,  9.8757e-01,  1.1535e+00,
          5.7770e-02,  9.4780e-01,  2.9512e+00,  2.3504e+00,  1.6411e+00,
          3.1498e+00,  1.2727e-01],
        [-1.4494e-02, -1.9430e-04, -1.7724e-04, -2.0127e-04, -2.0117e-04,
         -1.5493e-02, -8.1680e-03, -1.3258e-01, -1.3345e+00, -2.0053e-04,
         -1.8098e-04, -1.8463e-05, -1.9899e-04, -1.3303e+00, -1.3262e+00,
         -2.7675e-04, -1.3255e+00, -6.2074e-03, -5.8710e-01, -4.1919e-03,
         -7.5895e-03, -2.9301e-02],
        [-2.1892e-02, -3.5780e-04, -4.8405e-04, -3.6317e-04, -3.6356e-04,
         -2.3657e-02, -1.6951e-02, -9.6588e-02, -1.1849e+00, -3.5150e-04,
         -4.0838e-04, -1.7243e-05, -3.6464e-04, -1.1843e+00, -1.1795e+00,
         -3.3804e-04, -1.1790e+00, -7.4055e-03, -5.7283e-01, -5.4422e-03,
         -1.0076e-02, -3.1398e-02],
        [-2.3028e+00, -2.1890e-02, -8.3502e-03, -5.3786e-02,  9.5685e-02,
         -8.9290e-01, -1.4767e+01,  7.5055e+00,  3.0752e+00,  1.1812e-01,
         -7.0438e-02,  2.1906e-03, -5.7019e-02, -7.6423e-01, -1.3833e+00,
         -7.3209e-03, -7.3795e-01, -2.2229e+00,  1.8670e+00, -1.4910e+01,
         -1.6032e+00,  1.4609e+00],
        [ 2.4319e+00,  1.1747e-01, -1.6596e-01,  8.9778e-02,  3.1240e-01,
         -1.2941e+00, -9.2455e-01, -5.3120e-01,  5.2163e+00,  3.3676e-01,
         -2.0670e-01,  2.2187e+01,  7.3275e-02,  3.7788e-01,  7.5700e-01,
         -1.2275e-01,  4.8364e-01, -2.5823e+00,  1.5965e+00, -2.2668e+00,
         -6.5383e-01, -2.8611e+00],
        [-2.1115e-02, -3.0744e-04, -1.4460e-04, -2.9289e-04, -3.5131e-04,
         -2.2539e-02, -1.0971e-02, -1.5511e-01, -1.5086e+00, -2.8377e-04,
         -1.2594e-04,  2.8039e-05, -3.0274e-04, -1.5044e+00, -1.4994e+00,
         -3.7557e-04, -1.4986e+00, -6.5951e-03, -6.8458e-01, -3.5928e-03,
         -7.8039e-03, -3.0722e-02],
        [-1.4210e-02,  2.7210e-04, -1.6876e-04,  2.6752e-04,  2.9104e-04,
         -2.2712e-02, -5.7647e-03, -1.5704e-01, -1.4740e+00,  2.7486e-04,
         -1.6774e-04, -4.4364e-05,  2.6776e-04, -1.4699e+00, -1.4648e+00,
         -1.4749e-04, -1.4640e+00, -5.0059e-03, -6.6920e-01, -3.9010e-03,
         -5.3125e-03, -3.3932e-02]], device='cuda:0'))])
loaded xi:  855.6613
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857
 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857
 0.07142857 0.07142857]
W_T_mean: 8576.841924009083
W_T_median: 5042.380921625826
W_T_pctile_5: 103.64169553244135
W_T_CVAR_5_pct: -371.9331258181762
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1958.3946316238432
Current xi:  [867.2122]
objective value function right now is: -1958.3946316238432
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1971.138667352439
Current xi:  [877.9366]
objective value function right now is: -1971.138667352439
6.0% of gradient descent iterations done. Method = Adam
Current xi:  [888.7991]
objective value function right now is: -1968.6566938190945
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -1972.5256644573092
Current xi:  [899.0381]
objective value function right now is: -1972.5256644573092
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1974.402729104097
Current xi:  [908.9623]
objective value function right now is: -1974.402729104097
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [918.1201]
objective value function right now is: -1972.8530232261023
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [927.32947]
objective value function right now is: -1974.020304872364
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [936.86304]
objective value function right now is: -1970.514151522798
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -1976.7134386144323
Current xi:  [945.7629]
objective value function right now is: -1976.7134386144323
20.0% of gradient descent iterations done. Method = Adam
new min fval:  -1977.7901340439023
Current xi:  [955.1019]
objective value function right now is: -1977.7901340439023
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [963.51434]
objective value function right now is: -1973.2215426465307
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [972.6682]
objective value function right now is: -1974.8537706691702
26.0% of gradient descent iterations done. Method = Adam
new min fval:  -1978.304388319995
Current xi:  [980.53296]
objective value function right now is: -1978.304388319995
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [989.64215]
objective value function right now is: -1972.1015159159786
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [993.4367]
objective value function right now is: -1978.0614837267362
32.0% of gradient descent iterations done. Method = Adam
new min fval:  -1980.2598032836452
Current xi:  [1000.35944]
objective value function right now is: -1980.2598032836452
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [1007.7657]
objective value function right now is: -1978.036419185695
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [1014.837]
objective value function right now is: -1979.647404575735
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [1021.6325]
objective value function right now is: -1978.081056644776
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [1028.615]
objective value function right now is: -1969.9970739087316
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [1034.424]
objective value function right now is: -1980.1431699479454
44.0% of gradient descent iterations done. Method = Adam
new min fval:  -1981.3272903759848
Current xi:  [1040.6555]
objective value function right now is: -1981.3272903759848
46.0% of gradient descent iterations done. Method = Adam
new min fval:  -1983.1607330735158
Current xi:  [1046.9474]
objective value function right now is: -1983.1607330735158
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [1053.5714]
objective value function right now is: -1976.2463499452
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [1059.1935]
objective value function right now is: -1975.8601763178283
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [1063.023]
objective value function right now is: -1979.6028228892912
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [1067.2109]
objective value function right now is: -1983.1445217991536
56.00000000000001% of gradient descent iterations done. Method = Adam
new min fval:  -1985.6475576031473
Current xi:  [1071.7413]
objective value function right now is: -1985.6475576031473
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [1075.1469]
objective value function right now is: -1981.7723100693559
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [1079.2324]
objective value function right now is: -1982.173557117261
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [1083.0266]
objective value function right now is: -1979.5644684722713
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [1087.4706]
objective value function right now is: -1982.0109125566046
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [1091.578]
objective value function right now is: -1978.7754956237475
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [1095.502]
objective value function right now is: -1969.6946617793349
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [1098.6797]
objective value function right now is: -1982.0061727179634
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -1988.5689833186614
Current xi:  [1099.5304]
objective value function right now is: -1988.5689833186614
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -1988.931521366839
Current xi:  [1100.4227]
objective value function right now is: -1988.931521366839
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [1101.3748]
objective value function right now is: -1988.3007318599946
78.0% of gradient descent iterations done. Method = Adam
new min fval:  -1989.1618082233538
Current xi:  [1102.4738]
objective value function right now is: -1989.1618082233538
80.0% of gradient descent iterations done. Method = Adam
new min fval:  -1989.2976596917085
Current xi:  [1103.3668]
objective value function right now is: -1989.2976596917085
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [1104.3331]
objective value function right now is: -1988.5303352925291
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [1105.3354]
objective value function right now is: -1986.9388649227321
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [1106.1646]
objective value function right now is: -1988.8392102444375
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [1107.087]
objective value function right now is: -1988.5309247213424
new min fval from sgd:  -1989.7966969888723
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [1108.0096]
objective value function right now is: -1989.7966969888723
new min fval from sgd:  -1989.875797412008
new min fval from sgd:  -1989.9767480068092
new min fval from sgd:  -1990.0074369379072
new min fval from sgd:  -1990.0200396182659
new min fval from sgd:  -1990.0746164913146
new min fval from sgd:  -1990.1306263657125
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [1108.7942]
objective value function right now is: -1989.2924564841112
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [1109.7407]
objective value function right now is: -1986.798423534385
new min fval from sgd:  -1990.1634009409304
new min fval from sgd:  -1990.1841305556543
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [1110.4504]
objective value function right now is: -1989.1873705388657
new min fval from sgd:  -1990.2290542372157
new min fval from sgd:  -1990.2932599081614
new min fval from sgd:  -1990.3135780581238
new min fval from sgd:  -1990.3872678650716
new min fval from sgd:  -1990.4112274483086
new min fval from sgd:  -1990.4190724434093
new min fval from sgd:  -1990.4352719161338
new min fval from sgd:  -1990.4441611009706
new min fval from sgd:  -1990.4504194524427
new min fval from sgd:  -1990.4547878285582
new min fval from sgd:  -1990.462734960687
new min fval from sgd:  -1990.4767815811178
new min fval from sgd:  -1990.4814317389873
new min fval from sgd:  -1990.4893452501522
new min fval from sgd:  -1990.4938975444022
new min fval from sgd:  -1990.494203358435
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [1111.023]
objective value function right now is: -1990.123503074039
new min fval from sgd:  -1990.5003806552816
new min fval from sgd:  -1990.513538111683
new min fval from sgd:  -1990.518454954378
new min fval from sgd:  -1990.5214819824002
new min fval from sgd:  -1990.5257710218987
new min fval from sgd:  -1990.5406046340288
new min fval from sgd:  -1990.5524119005909
new min fval from sgd:  -1990.5587601141633
new min fval from sgd:  -1990.5654779883967
new min fval from sgd:  -1990.5689864659337
new min fval from sgd:  -1990.5699447458344
new min fval from sgd:  -1990.579200136263
new min fval from sgd:  -1990.581800898219
new min fval from sgd:  -1990.5832563424353
new min fval from sgd:  -1990.5909338523843
new min fval from sgd:  -1990.6057690484254
new min fval from sgd:  -1990.6202995389601
new min fval from sgd:  -1990.626156032133
new min fval from sgd:  -1990.6366171356076
new min fval from sgd:  -1990.646484815875
new min fval from sgd:  -1990.651809098653
new min fval from sgd:  -1990.653527058839
new min fval from sgd:  -1990.6556519964902
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [1111.2572]
objective value function right now is: -1990.5842124296166
min fval:  -1990.6556519964902
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -7.9739,   7.1464],
        [ -9.5236, -10.6797],
        [ -1.2553,   1.2711],
        [  8.7799,   7.6828],
        [-10.3126,  -7.9553],
        [ -1.2552,   1.2712],
        [ -1.2555,   1.2696],
        [ 11.0592,   2.8908],
        [ -7.6660,   6.6343],
        [ -9.0618,   6.9769],
        [ -7.9959,   7.2333],
        [ -4.6426,   4.3548],
        [  8.6978,   5.9413],
        [ -1.2553,   1.2711],
        [ -1.2553,   1.2710],
        [ -1.2554,   1.2709],
        [-11.7878,  -9.4359],
        [  8.4937,   7.5400],
        [ -7.4313,   6.2059],
        [ -8.8365,   6.8838],
        [ -1.2553,   1.2711],
        [-27.1665,  -6.5739]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([  5.4356,  -6.4517,  -2.9574, -10.8186,  -4.1923,  -2.9574,  -2.9586,
        -10.1798,   5.0965,   3.2777,   5.5971,  -0.8797,  -9.8425,  -2.9575,
         -2.9575,  -2.9576,  -4.4821, -10.5191,   0.5465,   2.2056,  -2.9575,
         -5.6665], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ 9.4973e-02, -6.0457e-02, -3.5107e-02,  5.3315e-01, -6.7486e-02,
         -3.5109e-02, -3.5091e-02,  1.5646e-01,  8.8398e-02,  1.3256e-01,
          6.8771e-02, -2.2216e-02,  4.4693e-01, -3.5107e-02, -3.5105e-02,
         -3.5103e-02, -8.9688e-02,  5.2972e-01, -1.4007e-02,  5.7797e-02,
         -3.5106e-02, -1.4191e-02],
        [-9.8677e+00,  1.3481e+01, -6.0735e-02,  4.0773e+00,  4.8918e+00,
         -6.0775e-02, -6.1521e-02,  7.3744e+00, -8.1700e+00, -3.1313e+00,
         -1.0598e+01, -3.3121e-01,  2.9742e+00, -6.0724e-02, -6.0696e-02,
         -6.0687e-02,  8.8912e+00,  3.9307e+00, -8.3657e-01, -2.7476e+00,
         -6.0723e-02,  6.9351e+00],
        [ 9.4973e-02, -6.0457e-02, -3.5107e-02,  5.3315e-01, -6.7486e-02,
         -3.5109e-02, -3.5091e-02,  1.5646e-01,  8.8398e-02,  1.3256e-01,
          6.8770e-02, -2.2216e-02,  4.4693e-01, -3.5107e-02, -3.5105e-02,
         -3.5103e-02, -8.9688e-02,  5.2972e-01, -1.4007e-02,  5.7797e-02,
         -3.5106e-02, -1.4191e-02],
        [-1.0653e+01,  1.4443e+01, -5.9021e-02,  8.7033e+00,  5.7436e+00,
         -5.9248e-02, -5.7087e-02,  1.0155e+01, -9.2962e+00, -3.6865e+00,
         -1.1872e+01, -2.6335e-01,  5.5553e+00, -5.8918e-02, -5.8766e-02,
         -5.8500e-02,  9.6089e+00,  7.0122e+00, -1.1893e+00, -3.6943e+00,
         -5.8909e-02,  8.2463e+00],
        [-8.6158e+00,  1.1342e+01, -2.4026e-02,  2.0007e+00,  5.1059e+00,
         -2.4107e-02, -2.2901e-02,  6.6831e+00, -7.2901e+00, -4.2408e+00,
         -9.3683e+00, -2.9072e-01,  2.2368e+00, -2.3987e-02, -2.3941e-02,
         -2.3826e-02,  8.1217e+00,  3.3895e+00, -8.3682e-01, -2.6694e+00,
         -2.3984e-02,  6.1149e+00],
        [-5.4642e+00,  6.8362e+00,  2.2120e-02,  1.7770e-01,  3.3982e+00,
          2.2106e-02,  2.2781e-02,  2.0075e+00, -4.3191e+00, -9.5349e-01,
         -6.5707e+00,  1.7664e-02,  2.1262e-01,  2.2130e-02,  2.2142e-02,
          2.2174e-02,  5.5202e+00,  1.7499e-01,  2.0535e-02, -1.3445e-01,
          2.2131e-02,  1.7397e+00],
        [ 9.4973e-02, -6.0457e-02, -3.5107e-02,  5.3315e-01, -6.7486e-02,
         -3.5109e-02, -3.5091e-02,  1.5646e-01,  8.8398e-02,  1.3256e-01,
          6.8771e-02, -2.2216e-02,  4.4693e-01, -3.5107e-02, -3.5105e-02,
         -3.5103e-02, -8.9688e-02,  5.2972e-01, -1.4007e-02,  5.7797e-02,
         -3.5106e-02, -1.4191e-02],
        [ 9.4973e-02, -6.0457e-02, -3.5107e-02,  5.3315e-01, -6.7486e-02,
         -3.5109e-02, -3.5091e-02,  1.5646e-01,  8.8398e-02,  1.3256e-01,
          6.8771e-02, -2.2216e-02,  4.4693e-01, -3.5107e-02, -3.5105e-02,
         -3.5103e-02, -8.9688e-02,  5.2972e-01, -1.4007e-02,  5.7797e-02,
         -3.5106e-02, -1.4191e-02],
        [ 9.4973e-02, -6.0457e-02, -3.5107e-02,  5.3315e-01, -6.7486e-02,
         -3.5109e-02, -3.5091e-02,  1.5646e-01,  8.8398e-02,  1.3256e-01,
          6.8771e-02, -2.2216e-02,  4.4693e-01, -3.5107e-02, -3.5105e-02,
         -3.5103e-02, -8.9688e-02,  5.2972e-01, -1.4007e-02,  5.7797e-02,
         -3.5106e-02, -1.4191e-02],
        [ 9.4973e-02, -6.0457e-02, -3.5107e-02,  5.3315e-01, -6.7486e-02,
         -3.5109e-02, -3.5091e-02,  1.5646e-01,  8.8398e-02,  1.3256e-01,
          6.8771e-02, -2.2216e-02,  4.4693e-01, -3.5107e-02, -3.5105e-02,
         -3.5103e-02, -8.9688e-02,  5.2972e-01, -1.4007e-02,  5.7797e-02,
         -3.5106e-02, -1.4191e-02],
        [-5.5103e+00,  7.2226e+00,  4.3793e-02,  2.3062e-01,  3.4874e+00,
          4.3777e-02,  4.4568e-02,  2.6747e+00, -4.5838e+00, -1.0031e+00,
         -6.9314e+00,  2.8476e-02,  3.1099e-01,  4.3806e-02,  4.3819e-02,
          4.3857e-02,  5.8024e+00,  2.2123e-01,  3.3445e-02, -1.7893e-01,
          4.3807e-02,  2.0639e+00],
        [ 9.1698e+00, -1.1917e+01,  1.5835e-01, -7.8903e+00, -5.6218e+00,
          1.5800e-01,  1.6128e-01, -8.5748e+00,  7.8100e+00,  5.2209e+00,
          1.0704e+01,  7.4932e-01, -4.7856e+00,  1.5850e-01,  1.5873e-01,
          1.5914e-01, -8.6481e+00, -7.6854e+00,  1.8092e+00,  3.7961e+00,
          1.5852e-01, -7.8587e+00],
        [ 9.4973e-02, -6.0457e-02, -3.5107e-02,  5.3315e-01, -6.7486e-02,
         -3.5109e-02, -3.5091e-02,  1.5646e-01,  8.8398e-02,  1.3256e-01,
          6.8771e-02, -2.2216e-02,  4.4693e-01, -3.5107e-02, -3.5105e-02,
         -3.5103e-02, -8.9688e-02,  5.2972e-01, -1.4007e-02,  5.7797e-02,
         -3.5106e-02, -1.4191e-02],
        [ 9.4973e-02, -6.0457e-02, -3.5107e-02,  5.3315e-01, -6.7486e-02,
         -3.5109e-02, -3.5091e-02,  1.5646e-01,  8.8398e-02,  1.3256e-01,
          6.8770e-02, -2.2216e-02,  4.4693e-01, -3.5107e-02, -3.5105e-02,
         -3.5103e-02, -8.9688e-02,  5.2972e-01, -1.4007e-02,  5.7797e-02,
         -3.5106e-02, -1.4191e-02],
        [ 6.1811e-01,  2.1518e-01,  4.5333e-02,  1.5846e-01,  2.6788e-01,
          4.5330e-02,  4.5331e-02,  4.1527e-02,  6.2024e-01,  1.4922e-01,
          6.5252e-01,  1.4721e-02,  1.0596e-01,  4.5333e-02,  4.5335e-02,
          4.5337e-02,  2.8041e-01,  1.5502e-01,  1.0340e-02,  6.5633e-02,
          4.5334e-02,  4.8082e-02],
        [ 9.4973e-02, -6.0457e-02, -3.5107e-02,  5.3315e-01, -6.7486e-02,
         -3.5109e-02, -3.5091e-02,  1.5646e-01,  8.8398e-02,  1.3256e-01,
          6.8771e-02, -2.2216e-02,  4.4693e-01, -3.5107e-02, -3.5105e-02,
         -3.5103e-02, -8.9688e-02,  5.2972e-01, -1.4007e-02,  5.7797e-02,
         -3.5106e-02, -1.4191e-02],
        [-6.8497e+00,  9.2222e+00,  8.3993e-02,  1.0088e+00,  4.1637e+00,
          8.3962e-02,  8.5528e-02,  5.0323e+00, -5.6905e+00, -2.0464e+00,
         -8.3072e+00,  1.5106e-02,  1.2576e+00,  8.4017e-02,  8.4042e-02,
          8.4113e-02,  6.9336e+00,  9.5367e-01, -3.2218e-02, -8.7343e-01,
          8.4018e-02,  3.7861e+00],
        [ 9.4973e-02, -6.0457e-02, -3.5107e-02,  5.3315e-01, -6.7486e-02,
         -3.5109e-02, -3.5091e-02,  1.5646e-01,  8.8398e-02,  1.3256e-01,
          6.8770e-02, -2.2216e-02,  4.4693e-01, -3.5107e-02, -3.5105e-02,
         -3.5103e-02, -8.9688e-02,  5.2972e-01, -1.4007e-02,  5.7797e-02,
         -3.5106e-02, -1.4191e-02],
        [ 9.4973e-02, -6.0457e-02, -3.5107e-02,  5.3315e-01, -6.7486e-02,
         -3.5109e-02, -3.5091e-02,  1.5646e-01,  8.8397e-02,  1.3256e-01,
          6.8770e-02, -2.2216e-02,  4.4693e-01, -3.5107e-02, -3.5105e-02,
         -3.5103e-02, -8.9687e-02,  5.2972e-01, -1.4007e-02,  5.7797e-02,
         -3.5106e-02, -1.4191e-02],
        [ 9.4973e-02, -6.0457e-02, -3.5107e-02,  5.3315e-01, -6.7486e-02,
         -3.5109e-02, -3.5091e-02,  1.5646e-01,  8.8398e-02,  1.3256e-01,
          6.8771e-02, -2.2216e-02,  4.4693e-01, -3.5107e-02, -3.5105e-02,
         -3.5103e-02, -8.9688e-02,  5.2972e-01, -1.4007e-02,  5.7797e-02,
         -3.5106e-02, -1.4191e-02],
        [ 6.2128e-01,  2.1611e-01,  4.6017e-02,  1.5785e-01,  2.6889e-01,
          4.6015e-02,  4.6015e-02,  4.1762e-02,  6.2363e-01,  1.4934e-01,
          6.5609e-01,  1.4955e-02,  1.0527e-01,  4.6018e-02,  4.6020e-02,
          4.6022e-02,  2.8139e-01,  1.5440e-01,  1.0382e-02,  6.5665e-02,
          4.6018e-02,  4.8019e-02],
        [ 9.4973e-02, -6.0457e-02, -3.5107e-02,  5.3315e-01, -6.7486e-02,
         -3.5109e-02, -3.5091e-02,  1.5646e-01,  8.8398e-02,  1.3256e-01,
          6.8771e-02, -2.2216e-02,  4.4693e-01, -3.5107e-02, -3.5105e-02,
         -3.5103e-02, -8.9688e-02,  5.2972e-01, -1.4007e-02,  5.7797e-02,
         -3.5106e-02, -1.4191e-02]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-1.8240,  0.4379, -1.8240,  0.7334,  0.1599, -1.3365, -1.8240, -1.8240,
        -1.8240, -1.8240, -1.2165, -0.7308, -1.8240, -1.8240,  4.1601, -1.8240,
        -0.4967, -1.8240, -1.8240, -1.8240,  4.2294, -1.8240], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[  0.0562, -13.2345,   0.0562, -19.2280, -10.3282,  -3.6799,   0.0562,
           0.0562,   0.0562,   0.0562,  -3.9570,  18.4640,   0.0562,   0.0562,
           5.1745,   0.0562,  -5.8709,   0.0562,   0.0562,   0.0562,   5.5956,
           0.0562]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 1.0498e+01,  3.2876e+00],
        [-7.6923e-01,  1.3132e+01],
        [ 1.8492e+00,  1.2079e-02],
        [ 1.3249e+01,  3.3985e-02],
        [-1.9756e+00,  3.0181e-01],
        [-4.0331e+00,  1.0923e+00],
        [-1.6016e+00,  2.6231e-01],
        [-3.3266e+00,  8.6306e-01],
        [-2.8651e+00,  5.1942e+00],
        [ 9.4171e+00,  8.5554e-01],
        [-1.5090e+00,  2.7711e-01],
        [-1.5751e+00,  2.6923e-01],
        [-1.2335e+01, -3.1705e-01],
        [-8.6173e+00,  7.2939e+00],
        [-7.4807e+00,  1.0943e+01],
        [-1.4875e+00,  1.9067e-01],
        [-1.5259e+00,  2.7469e-01],
        [-1.3387e+01, -3.0669e+00],
        [-1.1981e+01, -3.8936e+00],
        [ 5.5291e+00,  1.3596e+01],
        [ 1.2428e+01,  2.1493e+00],
        [ 1.4523e+01,  1.2198e+01]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ -7.3943,   8.2249,   5.8899, -11.6922,  -4.4165,  -6.1955,  -4.3841,
         -5.6170,  -6.1984, -12.2856,  -4.3255,  -4.3765,   7.2686,   3.5927,
          7.4064,  -4.6143,  -4.3373,   3.6022,  -2.5136,   8.7572,  -5.7294,
          7.0111], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 9.6186e-01,  7.8765e-01, -1.8461e+00, -8.4170e-02, -1.4801e-01,
         -3.7344e-01, -1.2022e-01, -3.4673e-01, -3.2264e-01, -9.2590e-01,
         -1.0314e-01, -1.1943e-01, -1.9843e+00,  1.7005e+00,  1.4960e+00,
         -7.2090e-02, -1.0560e-01, -1.4594e+00, -4.5525e-01, -2.2368e-01,
         -6.8766e-01, -1.3529e+00],
        [ 2.8169e-01,  1.0867e-01, -2.3926e+00, -7.5467e-01, -1.4683e-02,
         -9.8628e-03, -1.4424e-02, -1.2770e-02, -2.4120e-01, -4.7399e-01,
         -1.6078e-02, -1.4702e-02, -8.2033e-01,  8.3812e-01,  7.3089e-01,
         -1.0874e-02, -1.5699e-02, -7.7546e-01, -1.6706e-01, -4.6542e-01,
         -1.3071e+00, -1.6101e+00],
        [ 4.3648e-01,  2.4615e-01, -2.3870e+00, -6.3198e-01, -2.2024e-02,
         -3.2604e-02, -2.0290e-02, -3.4578e-02, -2.5762e-01, -6.1844e-01,
         -2.2594e-02, -2.0924e-02, -9.8224e-01,  1.0862e+00,  9.2356e-01,
         -1.4188e-02, -2.2115e-02, -8.9077e-01, -1.9686e-01, -4.6817e-01,
         -1.2613e+00, -1.6468e+00],
        [ 2.9317e-01,  1.1799e-01, -2.3941e+00, -7.4725e-01, -1.5238e-02,
         -1.1107e-02, -1.4865e-02, -1.4008e-02, -2.4256e-01, -4.8476e-01,
         -1.6615e-02, -1.5153e-02, -8.2903e-01,  8.5732e-01,  7.4560e-01,
         -1.1228e-02, -1.6210e-02, -7.8288e-01, -1.6911e-01, -4.6631e-01,
         -1.3059e+00, -1.6140e+00],
        [ 2.5917e-01,  9.0694e-02, -2.3892e+00, -7.6824e-01, -1.3590e-02,
         -7.5872e-03, -1.3529e-02, -1.0475e-02, -2.3848e-01, -4.5297e-01,
         -1.4996e-02, -1.3790e-02, -8.0421e-01,  7.9996e-01,  7.0178e-01,
         -1.0144e-02, -1.4669e-02, -7.6113e-01, -1.6304e-01, -4.6339e-01,
         -1.3091e+00, -1.6019e+00],
        [ 4.0880e-01,  2.1987e-01, -2.3933e+00, -6.5728e-01, -2.0631e-02,
         -2.7440e-02, -1.8955e-02, -2.9774e-02, -2.5450e-01, -5.9288e-01,
         -2.1375e-02, -1.9460e-02, -9.4439e-01,  1.0441e+00,  8.8996e-01,
         -1.3780e-02, -2.0822e-02, -8.6718e-01, -1.9110e-01, -4.6955e-01,
         -1.2751e+00, -1.6438e+00],
        [ 4.0001e-01, -1.3229e+01,  1.5229e+00, -8.0879e+00,  2.7662e-01,
         -2.4838e-02,  8.1842e-02, -3.0408e-02,  3.8667e-03, -1.6538e+00,
          4.2058e-02,  5.9417e-02,  5.4716e+00,  5.4774e-01, -6.2831e+00,
          3.1412e-02,  5.3069e-02,  3.9620e+00,  4.3345e+00, -1.4030e+01,
         -2.3683e+00, -7.2157e+00],
        [-2.4925e+00,  5.8928e+00, -4.6354e+00, -8.5094e+00, -1.3491e-01,
         -1.7695e+00, -5.1950e-02, -1.2427e+00, -1.1907e-01, -1.9533e+00,
         -4.9161e-03, -4.7913e-02,  2.7004e+00,  6.0800e+00,  5.6985e+00,
         -4.7818e-02, -2.3376e-02,  2.7572e+00, -1.5344e+00,  3.6233e+00,
         -3.0429e+00,  2.5564e+00],
        [ 6.6711e-01,  1.6401e+01,  1.4220e+00,  8.0152e+00, -6.8245e-02,
          3.6397e-02, -2.3304e-02,  2.6945e-02, -5.8809e-03,  1.0313e+00,
         -1.8042e-03, -9.5755e-03, -9.4896e+00, -5.2808e-01,  9.2620e+00,
         -2.4924e-02, -3.7604e-03, -8.8905e+00, -6.0137e+00,  2.1190e+01,
          5.6586e+00,  1.8327e+01],
        [ 3.2608e-01,  1.4551e-01, -2.3972e+00, -7.2443e-01, -1.6818e-02,
         -1.5014e-02, -1.6072e-02, -1.7847e-02, -2.4620e-01, -5.1570e-01,
         -1.8090e-02, -1.6391e-02, -8.5625e-01,  9.1178e-01,  7.8734e-01,
         -1.2163e-02, -1.7612e-02, -8.0491e-01, -1.7510e-01, -4.6835e-01,
         -1.3007e+00, -1.6246e+00],
        [ 2.5645e-01,  8.8565e-02, -2.3887e+00, -7.6982e-01, -1.3458e-02,
         -7.3279e-03, -1.3419e-02, -1.0210e-02, -2.3813e-01, -4.5044e-01,
         -1.4864e-02, -1.3678e-02, -8.0235e-01,  7.9533e-01,  6.9824e-01,
         -1.0054e-02, -1.4543e-02, -7.5943e-01, -1.6255e-01, -4.6313e-01,
         -1.3093e+00, -1.6009e+00],
        [-1.6219e-01, -1.0455e+01, -9.8279e+00, -1.4276e+00, -5.6860e-02,
         -7.3959e-02, -3.6556e-02, -9.7078e-02, -7.7856e-03, -1.3031e-02,
         -3.1836e-02, -3.3190e-02,  9.1028e+00,  7.3468e-01, -2.5231e+00,
         -2.7884e-02, -3.3503e-02,  8.5970e+00,  3.8921e+00, -2.3609e+01,
         -1.1443e+01, -1.9736e+01],
        [ 2.8102e-01,  1.0813e-01, -2.3925e+00, -7.5510e-01, -1.4650e-02,
         -9.7916e-03, -1.4398e-02, -1.2698e-02, -2.4111e-01, -4.7336e-01,
         -1.6046e-02, -1.4675e-02, -8.1983e-01,  8.3699e-01,  7.3002e-01,
         -1.0853e-02, -1.5669e-02, -7.7503e-01, -1.6694e-01, -4.6537e-01,
         -1.3072e+00, -1.6099e+00],
        [-2.1625e-02,  7.9288e-01,  2.5095e+00, -3.0381e+00, -1.5900e-01,
         -3.0428e-01, -7.3004e-02, -3.2481e-01, -2.6435e-01, -1.0409e+00,
         -6.8276e-03, -6.6591e-02,  8.9462e+00, -5.8880e-01,  3.1795e+00,
         -5.5206e-02, -2.6644e-02,  5.0162e+00, -2.4341e-01,  7.9022e-01,
         -1.2714e+00, -7.9158e-01],
        [ 2.8263e+00, -1.1586e+00,  4.8578e+00,  2.5953e+00, -5.9448e-01,
         -3.1450e-02, -2.0025e-01, -9.6273e-02,  6.5061e-01, -6.6329e-01,
         -1.0416e-01, -1.2854e-01, -6.0622e-02, -4.1661e+00, -6.6219e+00,
         -2.1821e-01, -1.1604e-01, -1.8246e+00, -3.4023e+00, -2.0989e+00,
          8.2338e+00, -1.9215e+00],
        [ 2.5059e-01,  8.4096e-02, -2.3876e+00, -7.7339e-01, -1.3178e-02,
         -6.7869e-03, -1.3184e-02, -9.6558e-03, -2.3724e-01, -4.4499e-01,
         -1.4582e-02, -1.3438e-02, -7.9850e-01,  7.8550e-01,  6.9062e-01,
         -9.8605e-03, -1.4274e-02, -7.5585e-01, -1.6154e-01, -4.6260e-01,
         -1.3095e+00, -1.5989e+00],
        [ 2.9693e-01,  4.5306e-02,  2.8769e+00,  6.4040e-01,  4.4415e-03,
          2.7162e-03,  5.3143e-03,  3.7961e-03, -1.1710e-02,  1.9231e-02,
          5.4150e-03,  5.3781e-03,  6.4013e-01,  1.4011e-01,  2.0804e-01,
          5.0110e-03,  5.4542e-03,  3.3912e-01,  5.2280e-02,  9.5045e-01,
          1.7054e+00,  1.4477e+00],
        [-5.1684e+00, -5.8661e-01,  8.5529e-02, -6.7338e+00,  2.8716e-02,
         -2.3576e-03,  4.1876e-02, -6.3589e-03, -3.7594e-04, -2.9032e+00,
          4.6088e-02,  4.1632e-02, -2.5320e+00, -2.9154e-02, -7.3496e-02,
          4.3001e-02,  4.1715e-02, -1.3286e+00, -2.5298e-01, -1.3252e+01,
         -4.1212e-01, -7.3357e-02],
        [-4.1882e+00, -5.1129e+00,  1.9143e+00, -1.0314e+01,  1.4481e-01,
          6.4987e-02,  1.5234e-01,  8.3900e-02, -2.5860e+00, -2.8793e+00,
          1.3029e-01,  1.3125e-01,  1.0031e-01,  3.8144e+00,  3.1031e+00,
          2.1059e-01,  1.2170e-01,  1.1734e+00,  6.1145e+00, -2.0468e+00,
          9.8763e-01, -2.1977e+00],
        [-2.8714e-01, -1.0601e+01, -3.1728e-01, -3.0431e+00,  9.3810e-02,
          3.6028e-02,  7.9104e-02,  8.3218e-02, -4.2057e-03, -3.5815e-01,
          5.0924e-02,  6.9660e-02,  3.2383e+00,  3.2135e+00, -6.2511e-01,
          6.4498e-02,  5.3889e-02,  2.9716e+00,  6.8786e+00, -1.5807e+01,
         -2.8357e+00, -1.8050e+00],
        [ 3.3631e-02, -6.5905e-02, -2.3343e+00, -8.3944e-01, -3.0319e-03,
          2.9496e-03, -4.0421e-03,  2.4077e-03, -1.9793e-01, -2.5234e-01,
         -4.0299e-03, -4.1762e-03, -6.8701e-01,  3.7546e-01,  3.8210e-01,
         -2.2323e-03, -4.1053e-03, -6.1677e-01, -1.1710e-01, -4.2549e-01,
         -1.3013e+00, -1.5170e+00],
        [-1.9829e+00,  6.1701e+00, -5.1204e+00, -9.9409e+00, -2.5018e-01,
         -1.1048e-01, -2.0104e-01, -5.6281e-02,  5.2761e+00, -6.5383e+00,
         -1.4796e-01, -1.4988e-01,  8.2522e-01,  5.4546e+00,  6.0200e+00,
         -5.1578e-01, -1.4107e-01,  1.9957e+00, -6.5523e-01,  3.9642e+00,
         -7.2489e+00,  2.9317e-01]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-1.8486, -2.3944, -2.3889, -2.3959, -2.3909, -2.3952,  1.8107, -5.8116,
        -3.4268, -2.3990, -2.3905, -0.8065, -2.3943,  2.8009,  5.0528, -2.3894,
         2.8793, -0.5450,  2.2870, -0.3162, -2.3360, -5.0861], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-5.1403e-02, -5.5646e-04, -4.8528e-04, -5.6658e-04, -5.2983e-04,
         -3.8812e-04, -2.4414e-03, -3.5092e-01, -1.6102e+00, -5.4943e-04,
         -5.2635e-04, -1.8150e-05, -5.5576e-04, -1.5600e+00, -1.6070e+00,
         -5.1874e-04, -1.6104e+00, -2.1810e-03, -1.4512e-01, -7.6150e-04,
         -3.9256e-04, -4.5830e-02],
        [-8.7474e-03, -1.2666e-03, -2.2251e-03, -1.2922e-03, -1.2410e-03,
         -2.0767e-03, -1.0390e-03, -2.1628e-01, -8.6055e-01, -1.4254e-03,
         -1.2398e-03,  1.4537e-04, -1.2654e-03, -8.2985e-01, -8.5923e-01,
         -1.2383e-03, -8.6082e-01, -9.5711e-04, -1.2114e-01, -6.8374e-04,
         -1.3959e-03, -6.1759e-02],
        [-4.8423e-02, -3.6721e-04, -2.9874e-04, -3.6751e-04, -3.5851e-04,
         -2.5882e-04, -3.6966e-03, -3.2497e-01, -1.4678e+00, -3.6149e-04,
         -3.5680e-04, -1.0062e-05, -3.6712e-04, -1.4193e+00, -1.4648e+00,
         -3.5279e-04, -1.4680e+00, -1.0619e-03, -1.4917e-01,  2.5878e-04,
         -1.8320e-04, -4.4021e-02],
        [-3.2557e-02,  1.0115e-05, -5.4138e-04, -2.3681e-05,  7.7511e-05,
         -4.3880e-04, -3.3428e-03, -3.0515e-01, -1.2826e+00, -1.1979e-04,
          8.4723e-05,  1.5197e-05,  1.2154e-05, -1.2453e+00, -1.2799e+00,
          9.8871e-05, -1.2827e+00, -2.5893e-03, -1.2505e-01, -1.1215e-03,
          1.3172e-04, -3.7322e-02],
        [-2.1057e-01, -7.4715e-02, -1.0160e-01, -7.6165e-02, -7.2050e-02,
         -9.5816e-02,  4.4679e+00, -6.6520e-01, -2.8482e+00, -8.0756e-02,
         -7.1740e-02, -1.5706e+01, -7.4633e-02,  3.4249e+00,  3.6571e+00,
         -7.1115e-02,  3.8676e+00,  7.0465e-01,  2.0362e+00,  5.3489e+00,
         -5.3376e-02,  2.1588e-01],
        [-2.3939e-02, -1.4531e-03, -6.8153e-04, -1.4379e-03, -1.4556e-03,
         -8.1025e-04,  1.8110e-03, -2.9006e-01, -9.9322e-01, -1.3481e-03,
         -1.4532e-03,  1.1664e-04, -1.4537e-03, -9.6138e-01, -9.8817e-01,
         -1.4462e-03, -9.9341e-01,  5.1810e-04, -9.7091e-02,  1.9037e-03,
         -1.0976e-03, -6.9463e-02],
        [-4.0323e-02,  3.9285e-05, -2.8733e-04,  7.4916e-06,  8.6878e-05,
         -3.9042e-04, -5.7627e-03, -2.5948e-01, -1.3061e+00, -1.4540e-04,
          9.1597e-05,  1.6260e-05,  4.0961e-05, -1.2566e+00, -1.3039e+00,
          1.0106e-04, -1.3064e+00, -2.2642e-03, -1.3615e-01, -9.8918e-04,
          1.0610e-04, -3.4703e-02],
        [ 1.5286e+00,  3.9170e-01,  6.4716e-01,  4.0814e-01,  3.6045e-01,
          5.9624e-01,  4.5570e+00,  5.6800e-02,  2.9912e+00,  4.5751e-01,
          3.5678e-01, -7.9347e+00,  3.9074e-01,  1.9280e+00,  1.0705e+00,
          3.4906e-01,  7.5165e-01,  5.6541e+00,  2.0948e+00,  2.8360e+00,
          1.1899e-01,  2.0348e-01],
        [-4.0807e-02, -3.1848e-04, -2.6484e-04, -2.8419e-04, -3.7374e-04,
         -1.1637e-04, -2.6741e-03, -3.1100e-01, -1.3942e+00, -1.7296e-04,
         -3.7872e-04, -1.1501e-05, -3.2039e-04, -1.3483e+00, -1.3912e+00,
         -3.8749e-04, -1.3944e+00, -2.3003e-03, -1.3685e-01, -7.9050e-04,
         -2.2895e-04, -3.7092e-02],
        [-4.7999e-02, -3.1425e-04, -2.0325e-04, -2.7915e-04, -3.7342e-04,
          4.1712e-05, -4.3797e-03, -2.0072e-01, -1.2399e+00, -1.5215e-04,
         -3.7980e-04, -3.2395e-05, -3.1619e-04, -1.2000e+00, -1.2390e+00,
         -3.9284e-04, -1.2407e+00, -4.7936e-03, -1.6616e-01, -2.7788e-03,
         -5.6378e-04, -3.9253e-02],
        [-4.9398e-01, -1.4010e-01, -2.2283e-01, -1.4625e-01, -1.2794e-01,
         -2.0831e-01, -1.8056e+01,  7.0532e+00,  3.0401e+00, -1.6389e-01,
         -1.2647e-01, -1.2289e-04, -1.3974e-01, -1.1669e+00, -1.3623e+00,
         -1.2339e-01, -1.1580e+00, -8.1553e-01,  3.4519e+00, -5.3045e+00,
          4.1540e-04,  2.4207e+00],
        [-6.6399e-01, -3.3311e-01, -4.3787e-01, -3.4067e-01, -3.1834e-01,
         -4.1875e-01, -2.2933e+00, -3.4327e-01,  5.2033e+00, -3.6252e-01,
         -3.1656e-01,  2.3604e+01, -3.3267e-01,  5.6480e-01,  9.1962e-01,
         -3.1280e-01,  4.9348e-01, -4.4717e+00,  1.5283e+00, -2.7452e+00,
         -1.8095e-01, -6.2341e-01],
        [-5.1664e-02, -8.5253e-04, -1.0407e-03, -8.4457e-04, -8.6037e-04,
         -1.0056e-03, -2.0746e-03, -3.4359e-01, -1.5861e+00, -8.6624e-04,
         -8.5999e-04, -9.8939e-06, -8.5310e-04, -1.5338e+00, -1.5828e+00,
         -8.5888e-04, -1.5862e+00,  4.7779e-04, -1.4493e-01, -4.0610e-04,
         -7.2921e-04, -4.9175e-02],
        [-4.9485e-02, -5.1276e-04, -5.6689e-04, -5.1788e-04, -4.9111e-04,
         -3.9476e-04, -2.4041e-03, -3.3908e-01, -1.5681e+00, -4.6060e-04,
         -4.8805e-04, -1.9724e-05, -5.1228e-04, -1.5196e+00, -1.5648e+00,
         -4.8134e-04, -1.5683e+00, -2.0157e-03, -1.3992e-01, -3.9300e-04,
         -3.4567e-04, -5.0462e-02]], device='cuda:0'))])
xi:  [1111.2144]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 1500.6816850726193
W_T_median: 1469.8932608609748
W_T_pctile_5: 1112.6208613813324
W_T_CVAR_5_pct: 632.010599342671
Average q (qsum/M+1):  54.021744266633064
Optimal xi:  [1111.2144]
Expected(across Rb) median(across samples) p_equity:  2.9749638777332167e-06
obj fun:  tensor(-1990.6557, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/factor_decumulation/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:262: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/factor_decumulation/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/factor_decumulation/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: MC_everything
Objective function: mean_cvar_single_level
Tracing param: 0.5
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       22  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       22  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 22)      True          22  
0     (22, 22)      True          22  
0      (22, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       22  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       22  logistic_sigmoid   
0        obj.layers[3]         3  output_layer       14           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 22)      True          22  
0     (22, 22)      True          22  
0     (22, 14)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -8.5715,   6.4621],
        [ -8.3669,  -9.0182],
        [ -5.1223,   3.2445],
        [  8.0669,   4.1508],
        [-11.4280,  -6.0457],
        [ -6.4858,   4.0851],
        [  6.0779,   4.9126],
        [  9.1747,   0.7713],
        [ -8.3119,   6.0846],
        [ -8.3147,   6.0977],
        [ -8.4882,   6.6116],
        [ -8.6931,   5.7529],
        [  7.8819,   3.3034],
        [ -1.2974,   1.0853],
        [  5.4594,  -0.3288],
        [  5.2299,   5.2824],
        [-11.7613,  -7.4762],
        [  7.7973,   4.2640],
        [ -8.5799,   5.8746],
        [ -7.8535,   5.7472],
        [ -1.2944,   1.0845],
        [-21.4386,  -5.7294]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ 4.8764, -5.7404, -3.0406, -9.5323, -3.7687, -2.3429, -8.4043, -9.1228,
         4.2727,  3.0356,  5.1757,  1.5461, -8.9288, -3.8883, -8.9159, -8.5427,
        -4.0692, -9.2749,  1.8685,  2.4405, -3.8889, -4.6902], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1574e-03, -1.6502e-02, -2.2728e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1088e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [-9.2453e+00,  1.2482e+01, -7.2066e-01,  7.0332e+00,  4.6981e+00,
         -1.2007e+00,  4.5523e+00,  6.2080e+00, -7.5674e+00, -3.0869e+00,
         -1.0021e+01, -1.8126e+00,  5.8578e+00, -1.6237e-01,  6.8999e-01,
          5.4520e+00,  8.4865e+00,  8.0426e+00, -2.2762e+00, -3.8127e+00,
         -1.9618e-01,  8.7135e+00],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2751e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-9.6515e+00,  1.3280e+01, -9.1434e-01,  9.3871e+00,  5.7620e+00,
         -1.3190e+00,  6.4927e+00,  6.8045e+00, -8.3770e+00, -3.3906e+00,
         -1.0939e+01, -2.1716e+00,  6.5179e+00, -2.1870e-01,  2.0491e+00,
          4.1453e+00,  9.2888e+00,  7.8384e+00, -2.6898e+00, -4.4743e+00,
         -1.9003e-01,  9.7752e+00],
        [-7.9773e+00,  1.0315e+01,  2.5895e-01,  4.6608e+00,  4.9211e+00,
          1.7041e-02,  2.1882e+00,  6.8647e+00, -6.6734e+00, -4.8263e+00,
         -8.8073e+00, -2.8795e+00,  6.4311e+00,  1.6629e-01,  1.1111e+00,
          5.0411e+00,  7.6765e+00,  1.1081e+01, -3.5739e+00, -4.0927e+00,
          1.6082e-01,  8.5887e+00],
        [-7.6589e+00,  9.2592e+00,  7.9739e-02,  3.9257e+00,  4.5700e+00,
          1.0005e-01,  2.1053e+00,  4.6166e+00, -6.0015e+00, -3.8545e+00,
         -9.2106e+00, -1.7570e+00,  5.7099e+00, -1.2986e-02,  5.9836e-02,
          4.9159e+00,  7.0161e+00,  9.4703e+00, -2.3319e+00, -3.1763e+00,
         -1.3208e-02,  7.3285e+00],
        [-2.2581e-01, -1.6549e-01,  1.7511e-03, -1.2938e-02, -1.1903e-01,
          1.1578e-03, -1.6509e-02, -2.2839e-03, -1.8738e-01, -6.9338e-02,
         -2.5288e-01, -1.2692e-02, -9.1165e-03,  1.2292e-02,  1.9855e-02,
         -1.7662e-02, -1.7966e-01, -1.2937e-02, -1.9683e-02, -4.9682e-02,
          1.2307e-02, -3.1400e-02],
        [-2.2584e-01, -1.6546e-01,  1.7508e-03, -1.2931e-02, -1.1901e-01,
          1.1573e-03, -1.6502e-02, -2.2704e-03, -1.8735e-01, -6.9322e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9856e-02,
         -1.7657e-02, -1.7959e-01, -1.2929e-02, -1.9678e-02, -4.9672e-02,
          1.2308e-02, -3.1398e-02],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2752e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2730e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1088e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [-7.4230e+00,  9.2761e+00,  8.2691e-02,  4.6883e+00,  4.4150e+00,
          1.2211e-01,  2.9895e+00,  3.5408e+00, -6.2114e+00, -3.5923e+00,
         -9.4198e+00, -1.8627e+00,  4.7011e+00, -1.9985e-02, -6.0281e-02,
          5.2032e+00,  7.0797e+00,  8.3206e+00, -2.3235e+00, -3.3515e+00,
         -1.9947e-02,  7.4397e+00],
        [ 7.9326e+00, -1.0706e+01,  4.0837e-01, -9.2089e+00, -5.7725e+00,
          6.6403e-01, -4.8629e+00, -5.8385e+00,  6.6214e+00,  5.0109e+00,
          9.6232e+00,  3.3999e+00, -5.8456e+00, -1.3669e-01, -1.4453e+00,
         -3.3601e+00, -8.4017e+00, -9.5444e+00,  3.9084e+00,  4.3412e+00,
         -1.3169e-01, -9.7519e+00],
        [-2.2583e-01, -1.6545e-01,  1.7507e-03, -1.2931e-02, -1.1900e-01,
          1.1572e-03, -1.6503e-02, -2.2678e-03, -1.8733e-01, -6.9320e-02,
         -2.5297e-01, -1.2687e-02, -9.1093e-03,  1.2293e-02,  1.9856e-02,
         -1.7657e-02, -1.7958e-01, -1.2930e-02, -1.9677e-02, -4.9670e-02,
          1.2308e-02, -3.1399e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2931e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2732e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [ 6.5891e-01,  3.0868e-01,  8.3566e-03,  3.5747e-02,  2.1159e-01,
          5.3475e-03,  5.7464e-02,  2.6629e-01,  5.5272e-01,  2.6083e-01,
          7.4008e-01,  8.5701e-02,  7.1654e-02,  3.7717e-02,  5.6900e-02,
          8.1005e-02,  2.9146e-01,  3.6840e-02,  1.1119e-01,  2.1066e-01,
          3.7716e-02,  1.3910e-01],
        [-2.2585e-01, -1.6548e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2733e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1087e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2307e-02, -3.1398e-02],
        [-7.5648e+00,  9.6323e+00,  3.4567e-02,  4.2023e+00,  4.4635e+00,
         -1.3328e-01,  2.0401e+00,  5.3264e+00, -6.2784e+00, -3.7048e+00,
         -9.3470e+00, -2.0562e+00,  5.8618e+00, -3.3635e-02,  2.0363e-01,
          5.0433e+00,  7.2814e+00,  9.5323e+00, -2.4148e+00, -3.3678e+00,
         -3.5727e-02,  7.7623e+00],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2750e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2744e-03, -1.8737e-01, -6.9326e-02,
         -2.5298e-01, -1.2689e-02, -9.1087e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2931e-02, -1.1901e-01,
          1.1574e-03, -1.6502e-02, -2.2722e-03, -1.8735e-01, -6.9324e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9673e-02,
          1.2308e-02, -3.1398e-02],
        [ 6.6450e-01,  3.1201e-01,  8.4127e-03,  3.4696e-02,  2.1235e-01,
          5.3877e-03,  5.6376e-02,  2.6891e-01,  5.5678e-01,  2.6166e-01,
          7.4701e-01,  8.5769e-02,  7.1346e-02,  3.8211e-02,  5.7275e-02,
          8.0058e-02,  2.9347e-01,  3.5786e-02,  1.1132e-01,  2.1139e-01,
          3.8209e-02,  1.3913e-01],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2753e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-2.4313,  0.0078, -2.4313,  0.0873, -0.2625, -0.5234, -2.4313, -2.4314,
        -2.4313, -2.4313, -0.4369, -0.2571, -2.4314, -2.4313,  4.5769, -2.4313,
        -0.4006, -2.4313, -2.4313, -2.4313,  4.6668, -2.4313], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[  0.0334, -10.4940,   0.0334, -15.8008,  -9.7979,  -6.9452,   0.0334,
           0.0334,   0.0334,   0.0334,  -7.0927,  14.9535,   0.0334,   0.0334,
           4.2936,   0.0334,  -7.0565,   0.0334,   0.0334,   0.0334,   4.7631,
           0.0334]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 1.0813e+01,  2.9656e+00],
        [ 5.5664e-01,  1.1757e+01],
        [ 1.8618e+01,  2.3664e+00],
        [ 1.0637e+01,  1.5273e-02],
        [-1.4941e+01, -2.2181e+00],
        [-1.2849e+00,  1.3570e+00],
        [-1.2800e+00,  1.3116e+00],
        [-1.7122e+00,  6.5637e-01],
        [-2.0284e+00,  2.5259e-01],
        [ 9.3477e+00, -5.2188e-01],
        [-1.9314e+00,  2.3251e-01],
        [-1.8788e+00,  4.0167e-01],
        [-1.0523e+01, -1.6251e+00],
        [-8.3398e+00,  5.3496e+00],
        [-7.4426e+00,  1.0247e+01],
        [-1.2446e+01, -2.8588e+00],
        [-1.4240e+01, -3.1016e+00],
        [-1.0901e+01, -2.0063e+00],
        [-1.0106e+01, -2.4687e+00],
        [ 3.1771e+00,  1.1429e+01],
        [ 1.0907e+01,  2.2476e+00],
        [ 1.1102e+01,  1.0847e+01]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-5.5365,  7.0663,  2.9709, -9.6018, -1.5848, -4.5127, -4.5185, -4.9090,
        -4.9531, -9.4875, -4.9847, -4.9560,  5.4223,  3.0397,  6.7011, -3.5168,
        -2.9913,  3.2472,  0.4201,  7.7652, -4.3018,  6.4326], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 6.1957e-01, -3.4634e+00, -1.7479e+00,  1.1905e+00,  1.2460e-02,
          1.1948e-01,  1.3226e-01,  4.3984e-02, -1.1598e-02,  1.0215e+00,
         -6.1706e-03,  2.4414e-03, -2.5313e+00,  1.1746e+00, -7.8526e-01,
         -9.2734e-03,  2.7572e-03, -2.7562e+00, -1.8971e+00, -2.6434e+00,
         -4.2419e-01,  3.0293e-02],
        [-4.6968e-01, -1.5418e-01, -2.2179e+00, -4.7229e-01, -1.4815e-02,
         -2.6861e-02, -2.4100e-02,  6.5293e-03, -1.5585e-02, -3.8766e-01,
         -1.6068e-02, -1.1227e-02, -1.0214e+00, -1.1716e-01, -1.0616e-01,
         -5.8386e-03, -7.9498e-03, -5.2026e-01, -1.9652e-01, -4.4158e-01,
         -1.2068e+00, -1.2289e+00],
        [-9.0043e-01, -3.1328e-01, -2.4749e+00, -1.0214e+00, -5.5072e-03,
         -2.2407e-02, -1.9453e-02, -7.7448e-03,  4.4606e-03, -9.3610e-01,
          4.1020e-03,  2.5876e-03, -1.2488e+00, -4.6992e-02, -9.2699e-02,
         -2.2626e-03, -3.5666e-03, -6.7176e-01, -2.4800e-01, -8.7567e-01,
         -1.3802e+00, -7.7155e-01],
        [-4.7184e-01, -1.5540e-01, -2.2143e+00, -4.7815e-01, -1.4473e-02,
         -2.7281e-02, -2.4476e-02,  6.5809e-03, -1.5495e-02, -3.9563e-01,
         -1.5975e-02, -1.1107e-02, -1.0396e+00, -1.1822e-01, -1.0605e-01,
         -5.8775e-03, -7.9716e-03, -5.2621e-01, -1.9589e-01, -4.4421e-01,
         -1.2127e+00, -1.2341e+00],
        [-4.8450e-01, -1.6921e-01, -2.2399e+00, -4.9569e-01, -1.4212e-02,
         -2.5472e-02, -2.2971e-02,  5.3544e-03, -1.0943e-02, -4.2767e-01,
         -1.1482e-02, -7.9784e-03, -1.0434e+00, -1.0826e-01, -9.0719e-02,
         -6.2509e-03, -8.3116e-03, -5.2892e-01, -2.1129e-01, -4.5420e-01,
         -1.2241e+00, -1.0613e+00],
        [ 3.0119e-01,  9.1885e-01, -1.5837e+00, -8.5542e-01, -1.1953e-02,
         -1.9274e+00, -1.8752e+00, -1.4092e+00, -5.5076e-01,  1.0780e+00,
         -4.5548e-01, -9.9188e-01, -3.9286e+00,  1.1415e+00,  2.2999e+00,
         -1.2239e-02, -1.3323e-02, -2.7068e+00, -9.7625e-01,  4.2057e-01,
         -1.0808e+00, -1.2393e+00],
        [ 2.4582e-01, -1.1721e+01,  5.7285e-01, -6.6182e+00,  3.3458e+00,
          1.7362e-01,  1.7999e-01,  2.0080e-01,  2.8786e-01, -4.5146e+00,
          2.9196e-01,  1.9339e-01,  3.6973e+00, -2.2846e+00, -8.2839e+00,
          2.5629e+00,  2.7897e+00,  3.3397e+00,  3.6998e+00, -1.2216e+01,
          1.0269e-01, -7.8724e+00],
        [-2.7710e+00,  3.8384e+00, -3.8614e+00, -5.2497e+00,  1.4955e-01,
         -5.1488e-01, -5.0931e-01, -4.0831e-01, -1.3933e-01, -4.9036e+00,
         -1.0681e-01, -2.8754e-01,  2.6586e+00,  3.1018e+00,  6.0454e+00,
          5.3721e-01,  5.1709e-01,  2.4000e+00,  1.7467e+00,  2.8980e+00,
         -1.8615e+00,  1.3298e+00],
        [ 5.3996e+00,  1.7695e+01,  2.7980e+00,  6.7002e+00, -6.8933e+00,
          1.9716e-02,  1.5955e-02,  1.6031e-02, -1.9886e-01,  4.1219e+00,
         -1.8883e-01,  2.3240e-02, -8.0362e+00,  3.0849e+00,  1.4710e+01,
         -3.3033e+00, -3.8057e+00, -7.4740e+00, -6.2744e+00,  1.9113e+01,
          5.0855e+00,  2.1580e+01],
        [-4.6054e-01, -1.5864e-01, -2.1828e+00, -4.7962e-01, -1.3132e-02,
         -2.7434e-02, -2.4527e-02,  7.6509e-03, -1.3661e-02, -3.9854e-01,
         -1.4154e-02, -9.5939e-03, -1.0591e+00, -1.2246e-01, -9.9910e-02,
         -5.2767e-03, -7.3107e-03, -5.5050e-01, -2.1282e-01, -4.5037e-01,
         -1.2105e+00, -1.2384e+00],
        [-9.3210e-01, -5.0637e-01, -2.5650e+00, -1.2297e+00,  5.1007e-03,
         -1.3266e-02, -1.0812e-02, -6.5037e-03, -1.3910e-03, -1.1288e+00,
         -1.7836e-03, -1.9456e-03, -7.9371e-01, -5.5349e-02, -8.6527e-02,
          5.2059e-03,  5.8080e-03, -8.8163e-01, -4.5943e-01, -1.6628e+00,
         -1.1149e+00, -5.6400e-01],
        [-2.8460e+00, -1.8825e+01, -9.7046e+00, -3.0631e+00,  6.2381e+00,
          2.2284e-02,  2.2216e-02,  3.8058e-02,  1.2254e-02, -4.6393e+00,
          2.0356e-03,  4.3669e-02,  7.6060e+00, -3.1393e+00, -1.1899e+01,
          2.9927e+00,  3.5772e+00,  7.5127e+00,  7.0486e+00, -2.2653e+01,
         -1.0357e+01, -2.5603e+01],
        [-4.7448e-01, -1.5413e-01, -2.2021e+00, -4.7761e-01, -1.5017e-02,
         -2.6936e-02, -2.4189e-02,  6.2971e-03, -1.5709e-02, -3.9518e-01,
         -1.6194e-02, -1.1365e-02, -1.0353e+00, -1.1675e-01, -1.0676e-01,
         -6.0131e-03, -8.0879e-03, -5.2030e-01, -1.9318e-01, -4.4328e-01,
         -1.2192e+00, -1.2259e+00],
        [-6.9231e-01,  3.0014e+00,  2.7786e+00, -1.3175e+00,  3.0620e-04,
         -1.3308e-01, -1.3059e-01, -4.6677e-03, -1.5150e-02, -1.3574e+00,
         -1.8928e-02, -2.6791e-03,  2.1880e+00, -4.4040e-01,  8.1953e-01,
         -1.8323e-02, -1.1176e-02,  1.4720e+00,  4.3629e-01,  2.4554e+00,
          8.6002e-02, -2.4341e-01],
        [ 3.0175e+00, -1.5929e-01,  3.1082e+00,  1.6836e+00, -3.7655e+00,
          1.7569e-01,  1.8810e-01,  2.3150e-01, -5.4313e-01,  3.8072e+00,
         -5.3327e-01,  1.6719e-01,  6.0672e-02, -2.5586e+00, -3.6155e+00,
         -4.5190e+00, -4.8662e+00,  1.6404e-01, -1.7814e-01, -2.9936e-01,
          2.7050e+00, -1.8862e+00],
        [-6.1343e-01, -2.0997e-01, -2.3786e+00, -7.6186e-01, -1.9840e-02,
         -3.2273e-02, -3.0458e-02, -4.7454e-03,  5.8161e-03, -6.4208e-01,
          6.0534e-03,  3.5540e-03, -1.0330e+00, -6.3106e-02, -1.0050e-01,
         -7.6629e-03, -1.3412e-02, -4.8643e-01, -1.8407e-01, -5.2743e-01,
         -1.3866e+00, -9.2565e-01],
        [ 2.3232e-01,  3.1081e+00,  2.1861e+00,  1.7924e+00,  8.3474e-01,
         -4.2057e-01, -3.7750e-01, -8.6959e-02, -6.3586e-02,  1.4179e+00,
         -6.1088e-02, -4.4329e-02,  1.9436e-01, -4.4091e-01,  1.1123e+00,
          4.9760e-01,  7.0823e-01, -1.6870e-01, -3.9429e-01, -1.1351e+00,
          1.7979e-02, -1.2019e+00],
        [-9.3911e-03, -3.8280e+00, -3.1866e-01, -2.0025e+00, -3.0075e-02,
          4.3973e-02,  5.3990e-02,  1.0353e-01,  1.4874e-01, -1.8588e+00,
          1.5683e-01,  1.3914e-01, -1.0725e-01, -2.1520e-01, -2.7783e-01,
          5.4541e-02,  7.3731e-03, -1.3880e+00, -8.0744e-01, -5.4071e+00,
         -9.3933e-01,  6.6525e-02],
        [-2.0923e+00,  1.6783e+00,  2.1031e+00, -6.6800e+00,  1.9109e-04,
         -8.2756e-01, -7.5222e-01, -4.3503e-01, -1.2713e-01, -3.5556e+00,
         -7.5366e-02, -3.3382e-01,  9.4887e+00, -1.2212e+00,  5.7869e+00,
         -6.4339e-04, -3.5999e-03,  9.1765e+00,  6.6382e+00,  6.8362e-01,
          2.7993e-01, -2.2562e+00],
        [-5.5183e+00, -1.5095e+01, -2.8824e-01, -4.9346e+00,  5.3321e+00,
          1.5448e-01,  1.5735e-01,  1.6104e-01,  5.9928e-01, -2.7075e+00,
          5.5855e-01,  1.3923e-01,  3.0535e+00,  8.4196e-01, -6.5453e+00,
          4.6053e+00,  5.0922e+00,  3.6158e+00,  3.8865e+00, -1.4997e+01,
         -2.8857e+00, -4.2056e+00],
        [ 4.0156e-01, -1.0952e+00, -1.5738e+00, -4.3123e-01, -8.5229e-03,
         -6.6402e-01, -6.0136e-01, -2.4497e-01, -5.3144e-02, -2.8255e-01,
         -5.5575e-02, -9.1214e-02, -2.1121e+00,  1.5978e+00,  1.4435e+00,
         -1.0813e-03, -1.8711e-03, -2.1573e+00, -8.6345e-01, -1.7321e+00,
         -7.5512e-01,  5.2300e-01],
        [-1.9858e+00,  2.9033e+00, -2.5269e+00, -2.1485e+00,  2.2962e+00,
         -1.4441e+00, -1.3739e+00, -7.3427e-01,  6.2891e-02,  2.1944e-01,
          6.1358e-02, -2.6440e-01,  7.4516e-02,  1.7016e+00,  3.0581e+00,
          1.5196e+00,  1.8766e+00,  6.5632e-01,  1.1298e+00,  1.3664e+00,
         -2.7325e+00, -7.5516e-01]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-1.8466, -2.2256, -2.5068, -2.1943, -2.2514, -1.8834,  0.6255, -4.9456,
        -2.2024, -2.2158, -2.5964,  0.0491, -2.2135,  3.0825,  3.0734, -2.4047,
         2.5296, -1.0040,  2.4991, -0.5295, -2.0766, -2.4070], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-1.5234e-02,  7.2296e-05, -1.5502e-04,  5.9106e-05,  9.2680e-05,
         -2.2228e-02, -7.7352e-03, -1.5990e-01, -1.5103e+00,  6.1218e-05,
         -1.5306e-04, -1.3007e-05,  6.3929e-05, -1.5060e+00, -1.5008e+00,
         -2.1007e-04, -1.4999e+00, -5.4381e-03, -6.9054e-01, -3.7369e-03,
         -4.7102e-03, -3.5212e-02],
        [-8.7292e-03, -1.4222e-03,  7.6021e-04, -1.3898e-03, -1.5771e-03,
         -1.3307e-02, -5.1882e-03, -1.0878e-01, -8.2132e-01, -1.3260e-03,
          8.8522e-04, -2.6449e-04, -1.4244e-03, -8.2289e-01, -8.1366e-01,
          5.1250e-04, -8.1735e-01,  1.2221e-03, -3.1415e-01, -6.8756e-03,
          4.4122e-03, -3.5269e-02],
        [-2.1229e-02, -5.1093e-04, -3.4543e-04, -5.1941e-04, -5.4632e-04,
         -1.8385e-02, -9.4420e-03, -1.3731e-01, -1.4218e+00, -5.2075e-04,
         -3.2211e-04,  2.3184e-05, -5.1689e-04, -1.4173e+00, -1.4127e+00,
         -3.8173e-04, -1.4125e+00, -6.1909e-03, -6.2055e-01, -3.7929e-03,
         -7.1839e-03, -2.7972e-02],
        [-9.4172e-03, -2.1938e-04, -2.2482e-04, -2.0759e-04, -2.8288e-04,
         -1.6622e-02, -7.4112e-03, -1.3137e-01, -1.2415e+00, -2.0252e-04,
         -2.1593e-04, -7.4338e-05, -2.1553e-04, -1.2385e+00, -1.2343e+00,
         -1.4845e-04, -1.2328e+00, -5.0361e-03, -5.7108e-01, -3.7365e-03,
         -7.0540e-03, -2.5170e-02],
        [-1.0969e+00,  7.0714e-02,  2.8031e-01,  4.2693e-02,  2.8583e-01,
          5.4877e-01,  3.6379e+00, -1.3225e+00, -3.0535e+00,  2.8854e-01,
          9.2331e-01, -1.4907e+01,  2.7428e-02,  3.6135e+00,  3.4661e+00,
         -2.3553e-02,  3.3911e+00,  1.2464e+00,  2.0600e+00,  5.6362e+00,
         -4.8358e-01,  4.4222e-01],
        [-1.1325e-02, -1.4138e-04,  1.4500e-04, -1.5008e-04, -1.0196e-03,
         -8.7395e-03, -5.0212e-04, -1.4891e-01, -9.6424e-01, -1.5847e-04,
          8.4481e-05, -6.7668e-04, -1.4540e-04, -9.6261e-01, -9.4804e-01,
         -9.4017e-05, -9.5700e-01,  4.4294e-03, -4.5741e-01, -5.5136e-03,
          2.2288e-03, -3.6784e-02],
        [-2.4271e-02, -7.7962e-04, -2.2040e-04, -7.9007e-04, -5.4691e-04,
         -1.4880e-02, -9.2166e-03, -1.1032e-01, -1.2944e+00, -7.8678e-04,
         -1.4609e-04, -3.3668e-05, -7.9327e-04, -1.2897e+00, -1.2879e+00,
         -3.7474e-04, -1.2861e+00, -9.7262e-03, -5.3746e-01, -3.8536e-03,
         -1.0548e-02, -2.4508e-02],
        [ 3.9237e+00, -6.2937e-02,  8.2976e-01, -8.9553e-02,  1.8773e-01,
          2.5280e+00,  4.4063e+00, -5.1176e-01,  2.7121e+00,  1.5038e-01,
          2.1898e+00, -6.3975e+00, -1.0291e-01,  9.8757e-01,  1.1535e+00,
          5.7770e-02,  9.4780e-01,  2.9512e+00,  2.3504e+00,  1.6411e+00,
          3.1498e+00,  1.2727e-01],
        [-1.4494e-02, -1.9430e-04, -1.7724e-04, -2.0127e-04, -2.0117e-04,
         -1.5493e-02, -8.1680e-03, -1.3258e-01, -1.3345e+00, -2.0053e-04,
         -1.8098e-04, -1.8463e-05, -1.9899e-04, -1.3303e+00, -1.3262e+00,
         -2.7675e-04, -1.3255e+00, -6.2074e-03, -5.8710e-01, -4.1919e-03,
         -7.5895e-03, -2.9301e-02],
        [-2.1892e-02, -3.5780e-04, -4.8405e-04, -3.6317e-04, -3.6356e-04,
         -2.3657e-02, -1.6951e-02, -9.6588e-02, -1.1849e+00, -3.5150e-04,
         -4.0838e-04, -1.7243e-05, -3.6464e-04, -1.1843e+00, -1.1795e+00,
         -3.3804e-04, -1.1790e+00, -7.4055e-03, -5.7283e-01, -5.4422e-03,
         -1.0076e-02, -3.1398e-02],
        [-2.3028e+00, -2.1890e-02, -8.3502e-03, -5.3786e-02,  9.5685e-02,
         -8.9290e-01, -1.4767e+01,  7.5055e+00,  3.0752e+00,  1.1812e-01,
         -7.0438e-02,  2.1906e-03, -5.7019e-02, -7.6423e-01, -1.3833e+00,
         -7.3209e-03, -7.3795e-01, -2.2229e+00,  1.8670e+00, -1.4910e+01,
         -1.6032e+00,  1.4609e+00],
        [ 2.4319e+00,  1.1747e-01, -1.6596e-01,  8.9778e-02,  3.1240e-01,
         -1.2941e+00, -9.2455e-01, -5.3120e-01,  5.2163e+00,  3.3676e-01,
         -2.0670e-01,  2.2187e+01,  7.3275e-02,  3.7788e-01,  7.5700e-01,
         -1.2275e-01,  4.8364e-01, -2.5823e+00,  1.5965e+00, -2.2668e+00,
         -6.5383e-01, -2.8611e+00],
        [-2.1115e-02, -3.0744e-04, -1.4460e-04, -2.9289e-04, -3.5131e-04,
         -2.2539e-02, -1.0971e-02, -1.5511e-01, -1.5086e+00, -2.8377e-04,
         -1.2594e-04,  2.8039e-05, -3.0274e-04, -1.5044e+00, -1.4994e+00,
         -3.7557e-04, -1.4986e+00, -6.5951e-03, -6.8458e-01, -3.5928e-03,
         -7.8039e-03, -3.0722e-02],
        [-1.4210e-02,  2.7210e-04, -1.6876e-04,  2.6752e-04,  2.9104e-04,
         -2.2712e-02, -5.7647e-03, -1.5704e-01, -1.4740e+00,  2.7486e-04,
         -1.6774e-04, -4.4364e-05,  2.6776e-04, -1.4699e+00, -1.4648e+00,
         -1.4749e-04, -1.4640e+00, -5.0059e-03, -6.6920e-01, -3.9010e-03,
         -5.3125e-03, -3.3932e-02]], device='cuda:0'))])
loaded xi:  855.6613
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857
 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857
 0.07142857 0.07142857]
W_T_mean: 8576.841924009083
W_T_median: 5042.380921625826
W_T_pctile_5: 103.64169553244135
W_T_CVAR_5_pct: -371.9331258181762
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -2250.986042083691
Current xi:  [869.0008]
objective value function right now is: -2250.986042083691
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -2253.053073043051
Current xi:  [882.3871]
objective value function right now is: -2253.053073043051
6.0% of gradient descent iterations done. Method = Adam
Current xi:  [895.91956]
objective value function right now is: -2251.7451697793426
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -2254.6652504012927
Current xi:  [909.69336]
objective value function right now is: -2254.6652504012927
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -2269.8490608011093
Current xi:  [923.492]
objective value function right now is: -2269.8490608011093
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [935.9052]
objective value function right now is: -2261.9656173400986
14.000000000000002% of gradient descent iterations done. Method = Adam
new min fval:  -2280.973270474904
Current xi:  [949.11816]
objective value function right now is: -2280.973270474904
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [962.31396]
objective value function right now is: -2274.4342219834325
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -2281.673055913653
Current xi:  [975.05707]
objective value function right now is: -2281.673055913653
20.0% of gradient descent iterations done. Method = Adam
new min fval:  -2284.842610901998
Current xi:  [986.70856]
objective value function right now is: -2284.842610901998
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [998.8637]
objective value function right now is: -2284.1245751607507
24.0% of gradient descent iterations done. Method = Adam
new min fval:  -2291.6809031026505
Current xi:  [1011.30347]
objective value function right now is: -2291.6809031026505
26.0% of gradient descent iterations done. Method = Adam
new min fval:  -2293.4465187032447
Current xi:  [1023.50323]
objective value function right now is: -2293.4465187032447
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [1035.2382]
objective value function right now is: -2287.6758394469916
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [1046.7643]
objective value function right now is: -2277.4230058271464
32.0% of gradient descent iterations done. Method = Adam
new min fval:  -2295.031795929101
Current xi:  [1057.9907]
objective value function right now is: -2295.031795929101
34.0% of gradient descent iterations done. Method = Adam
new min fval:  -2300.0442640711217
Current xi:  [1069.4741]
objective value function right now is: -2300.0442640711217
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [1080.1732]
objective value function right now is: -2294.1355242601244
38.0% of gradient descent iterations done. Method = Adam
new min fval:  -2311.584723561297
Current xi:  [1090.3848]
objective value function right now is: -2311.584723561297
40.0% of gradient descent iterations done. Method = Adam
new min fval:  -2319.856835876589
Current xi:  [1101.1655]
objective value function right now is: -2319.856835876589
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [1111.8016]
objective value function right now is: -2312.585506262676
44.0% of gradient descent iterations done. Method = Adam
new min fval:  -2320.3851489082226
Current xi:  [1121.9343]
objective value function right now is: -2320.3851489082226
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [1131.2745]
objective value function right now is: -2312.3099380407657
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [1141.419]
objective value function right now is: -2319.565179363279
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [1150.8755]
objective value function right now is: -2318.989340343476
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [1159.6534]
objective value function right now is: -2299.182739444423
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [1168.05]
objective value function right now is: -2306.4789596212227
56.00000000000001% of gradient descent iterations done. Method = Adam
new min fval:  -2327.5775628089273
Current xi:  [1177.0874]
objective value function right now is: -2327.5775628089273
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [1185.3173]
objective value function right now is: -2319.580563121318
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [1193.7067]
objective value function right now is: -2325.24675825004
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [1201.255]
objective value function right now is: -2311.6988831051217
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [1208.1567]
objective value function right now is: -2314.610078309617
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [1215.357]
objective value function right now is: -2297.8878156658125
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [1222.1199]
objective value function right now is: -2318.6150077874786
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [1227.7128]
objective value function right now is: -2307.2385035895277
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -2339.9868577292496
Current xi:  [1229.3038]
objective value function right now is: -2339.9868577292496
74.0% of gradient descent iterations done. Method = Adam
Current xi:  [1230.9923]
objective value function right now is: -2339.9037196849085
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [1232.5367]
objective value function right now is: -2339.0977661702523
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [1234.2238]
objective value function right now is: -2338.117431940488
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [1235.5812]
objective value function right now is: -2339.0938972426143
82.0% of gradient descent iterations done. Method = Adam
new min fval:  -2340.250385387093
Current xi:  [1237.2596]
objective value function right now is: -2340.250385387093
84.0% of gradient descent iterations done. Method = Adam
new min fval:  -2342.310831978325
Current xi:  [1238.7631]
objective value function right now is: -2342.310831978325
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [1240.01]
objective value function right now is: -2340.4909656312057
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [1241.6534]
objective value function right now is: -2341.3354997149117
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [1243.2114]
objective value function right now is: -2340.794622702708
new min fval from sgd:  -2342.574768605701
new min fval from sgd:  -2342.86938770222
new min fval from sgd:  -2342.991404142836
new min fval from sgd:  -2342.994777543885
new min fval from sgd:  -2343.2993506804337
new min fval from sgd:  -2343.3244051108363
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [1244.6459]
objective value function right now is: -2339.0511098879865
new min fval from sgd:  -2343.377978357292
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [1245.9429]
objective value function right now is: -2341.988334154183
new min fval from sgd:  -2343.5496901806246
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [1247.11]
objective value function right now is: -2339.0443316790693
new min fval from sgd:  -2343.67089289628
new min fval from sgd:  -2343.675725419706
new min fval from sgd:  -2343.7030153768555
new min fval from sgd:  -2343.7086749459477
new min fval from sgd:  -2343.709571662501
new min fval from sgd:  -2343.710479585658
new min fval from sgd:  -2343.7777490698118
new min fval from sgd:  -2343.821672057029
new min fval from sgd:  -2343.8466348412767
new min fval from sgd:  -2343.8525413388497
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [1247.9169]
objective value function right now is: -2343.3595290620497
new min fval from sgd:  -2343.8808875736117
new min fval from sgd:  -2343.91164378397
new min fval from sgd:  -2343.938097579186
new min fval from sgd:  -2343.959245747942
new min fval from sgd:  -2343.9806758414006
new min fval from sgd:  -2344.0091720935397
new min fval from sgd:  -2344.0136005681293
new min fval from sgd:  -2344.015818892879
new min fval from sgd:  -2344.05450423253
new min fval from sgd:  -2344.0904102990403
new min fval from sgd:  -2344.117962137378
new min fval from sgd:  -2344.1316974306455
new min fval from sgd:  -2344.143711146779
new min fval from sgd:  -2344.1470616941974
new min fval from sgd:  -2344.157224666669
new min fval from sgd:  -2344.160083863014
new min fval from sgd:  -2344.1709359434076
new min fval from sgd:  -2344.19096158374
new min fval from sgd:  -2344.2071406536465
new min fval from sgd:  -2344.2103966716045
new min fval from sgd:  -2344.226949948391
new min fval from sgd:  -2344.2396380250048
new min fval from sgd:  -2344.26341195891
new min fval from sgd:  -2344.2839857762247
new min fval from sgd:  -2344.2945702948095
new min fval from sgd:  -2344.299584079006
new min fval from sgd:  -2344.310755564317
new min fval from sgd:  -2344.331876198281
new min fval from sgd:  -2344.3429056950213
new min fval from sgd:  -2344.3460555508864
new min fval from sgd:  -2344.351416481196
new min fval from sgd:  -2344.365486718732
new min fval from sgd:  -2344.3860981281177
new min fval from sgd:  -2344.397611622041
new min fval from sgd:  -2344.399850418969
new min fval from sgd:  -2344.4075765797215
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [1248.251]
objective value function right now is: -2343.6977435602043
min fval:  -2344.4075765797215
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-10.2701,   6.2163],
        [ -6.9339, -10.9900],
        [ -1.6944,   0.8066],
        [  9.2601,   3.8873],
        [-10.1041,  -8.1406],
        [ -1.6944,   0.8066],
        [  3.8811,   0.6006],
        [ 11.4022,   1.4928],
        [-10.2043,   5.9417],
        [-11.8390,   6.8575],
        [-10.2626,   6.3335],
        [-10.4777,   6.0618],
        [  9.1017,   3.5263],
        [ -1.6944,   0.8066],
        [ -1.6944,   0.8067],
        [ -1.6295,   0.7941],
        [-11.0358,  -9.3555],
        [  8.8326,   4.2259],
        [-11.1649,   6.4620],
        [-11.3038,   6.5897],
        [ -1.6944,   0.8066],
        [-19.1025,  -6.7972]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([  5.1752,  -6.4597,  -3.6730, -11.7189,  -4.3004,  -3.6730,  -8.3405,
        -11.3542,   4.7071,   2.0071,   5.3633,  -0.3081, -11.2254,  -3.6730,
         -3.6730,  -3.7245,  -4.8771, -11.6393,   0.4128,   1.2516,  -3.6730,
         -5.7920], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-1.9182e-01, -1.0068e-01, -2.8121e-03, -3.1196e-02, -8.3383e-02,
         -2.8121e-03, -3.3823e-03, -4.6687e-02, -1.6070e-01, -2.0344e-02,
         -2.0743e-01, -2.2075e-03, -3.0410e-02, -2.8121e-03, -2.8123e-03,
         -2.8162e-03, -8.5853e-02, -3.1902e-02, -7.9474e-03, -1.9974e-02,
         -2.8121e-03,  3.4869e-03],
        [-9.7772e+00,  1.4777e+01, -2.8218e-01,  7.3971e+00,  5.4663e+00,
         -2.8209e-01,  4.6320e-01,  9.7805e+00, -8.0999e+00, -3.4403e+00,
         -1.0499e+01, -7.9477e-01,  6.6852e+00, -2.8222e-01, -2.8212e-01,
         -1.7812e-01,  9.6439e+00,  7.8263e+00, -1.7750e+00, -3.4281e+00,
         -2.8221e-01,  6.9533e+00],
        [-1.9182e-01, -1.0068e-01, -2.8121e-03, -3.1196e-02, -8.3383e-02,
         -2.8121e-03, -3.3823e-03, -4.6687e-02, -1.6070e-01, -2.0344e-02,
         -2.0743e-01, -2.2075e-03, -3.0410e-02, -2.8121e-03, -2.8123e-03,
         -2.8162e-03, -8.5853e-02, -3.1903e-02, -7.9474e-03, -1.9974e-02,
         -2.8121e-03,  3.4869e-03],
        [-1.0622e+01,  1.5958e+01, -2.9455e-01,  9.5014e+00,  6.6568e+00,
         -2.9466e-01,  1.2720e+00,  1.0677e+01, -9.3316e+00, -4.3762e+00,
         -1.1818e+01, -1.4574e+00,  7.4334e+00, -2.9450e-01, -2.9420e-01,
         -1.6670e-01,  1.0670e+01,  8.3666e+00, -2.6798e+00, -4.6637e+00,
         -2.9447e-01,  8.4056e+00],
        [-8.7961e+00,  1.2798e+01,  2.3394e-01,  4.7991e+00,  5.7965e+00,
          2.3391e-01, -5.4712e-01,  9.5139e+00, -7.5346e+00, -5.0143e+00,
         -9.5255e+00, -1.9359e+00,  5.9295e+00,  2.3393e-01,  2.3417e-01,
          1.2211e-01,  8.9785e+00,  9.5230e+00, -2.7876e+00, -3.8243e+00,
          2.3395e-01,  6.5241e+00],
        [-6.7712e+00,  9.8856e+00,  1.0443e-01,  4.3799e+00,  4.8126e+00,
          1.0442e-01,  6.9588e-02,  5.9499e+00, -5.2185e+00, -1.5522e+00,
         -8.1037e+00, -8.4562e-02,  4.4904e+00,  1.0444e-01,  1.0446e-01,
          8.6963e-02,  7.2834e+00,  5.2131e+00, -2.6786e-01, -8.3371e-01,
          1.0444e-01,  3.6931e+00],
        [-1.9182e-01, -1.0068e-01, -2.8121e-03, -3.1196e-02, -8.3383e-02,
         -2.8121e-03, -3.3823e-03, -4.6687e-02, -1.6070e-01, -2.0344e-02,
         -2.0743e-01, -2.2075e-03, -3.0410e-02, -2.8121e-03, -2.8123e-03,
         -2.8162e-03, -8.5853e-02, -3.1903e-02, -7.9473e-03, -1.9974e-02,
         -2.8121e-03,  3.4869e-03],
        [-1.9182e-01, -1.0068e-01, -2.8121e-03, -3.1196e-02, -8.3383e-02,
         -2.8121e-03, -3.3823e-03, -4.6687e-02, -1.6070e-01, -2.0344e-02,
         -2.0743e-01, -2.2075e-03, -3.0410e-02, -2.8121e-03, -2.8123e-03,
         -2.8162e-03, -8.5853e-02, -3.1903e-02, -7.9474e-03, -1.9974e-02,
         -2.8121e-03,  3.4869e-03],
        [-1.9182e-01, -1.0068e-01, -2.8121e-03, -3.1196e-02, -8.3383e-02,
         -2.8121e-03, -3.3823e-03, -4.6687e-02, -1.6070e-01, -2.0344e-02,
         -2.0743e-01, -2.2075e-03, -3.0410e-02, -2.8121e-03, -2.8123e-03,
         -2.8162e-03, -8.5853e-02, -3.1903e-02, -7.9474e-03, -1.9974e-02,
         -2.8121e-03,  3.4869e-03],
        [-1.9182e-01, -1.0068e-01, -2.8121e-03, -3.1196e-02, -8.3383e-02,
         -2.8121e-03, -3.3823e-03, -4.6687e-02, -1.6070e-01, -2.0344e-02,
         -2.0743e-01, -2.2075e-03, -3.0410e-02, -2.8121e-03, -2.8123e-03,
         -2.8162e-03, -8.5853e-02, -3.1903e-02, -7.9474e-03, -1.9974e-02,
         -2.8121e-03,  3.4869e-03],
        [-5.9001e+00,  8.2671e+00,  3.9649e-02,  7.1208e-02,  4.0660e+00,
          3.9643e-02,  1.1732e-01,  8.2722e-01, -4.6774e+00,  2.7217e-02,
         -7.4030e+00,  3.0409e-02,  1.4959e-01,  3.9652e-02,  3.9658e-02,
          3.4835e-02,  6.3532e+00,  3.2423e-02,  5.9087e-02,  1.0934e-01,
          3.9652e-02,  2.6225e+00],
        [ 9.3030e+00, -1.3308e+01, -1.6491e-01, -8.9659e+00, -6.4402e+00,
         -1.6499e-01, -4.6453e-01, -9.4437e+00,  8.0057e+00,  5.9621e+00,
          1.0870e+01,  3.0638e+00, -5.9475e+00, -1.6488e-01, -1.6439e-01,
         -4.9543e-02, -9.6017e+00, -9.0254e+00,  3.9086e+00,  4.8397e+00,
         -1.6484e-01, -8.0096e+00],
        [-1.9182e-01, -1.0068e-01, -2.8121e-03, -3.1196e-02, -8.3383e-02,
         -2.8121e-03, -3.3823e-03, -4.6687e-02, -1.6070e-01, -2.0344e-02,
         -2.0743e-01, -2.2075e-03, -3.0410e-02, -2.8121e-03, -2.8123e-03,
         -2.8162e-03, -8.5853e-02, -3.1903e-02, -7.9474e-03, -1.9974e-02,
         -2.8121e-03,  3.4869e-03],
        [-1.9182e-01, -1.0068e-01, -2.8121e-03, -3.1196e-02, -8.3383e-02,
         -2.8121e-03, -3.3823e-03, -4.6687e-02, -1.6070e-01, -2.0344e-02,
         -2.0743e-01, -2.2075e-03, -3.0410e-02, -2.8121e-03, -2.8123e-03,
         -2.8162e-03, -8.5853e-02, -3.1903e-02, -7.9474e-03, -1.9974e-02,
         -2.8121e-03,  3.4869e-03],
        [ 6.6462e-01,  2.6281e-01,  2.2260e-02,  1.9656e-01,  2.4358e-01,
          2.2260e-02, -5.7348e-03,  7.9832e-02,  5.9131e-01,  1.1093e-01,
          6.9577e-01,  5.0747e-03,  1.9755e-01,  2.2260e-02,  2.2260e-02,
          2.1740e-02,  2.3158e-01,  1.9494e-01,  2.4992e-02,  7.2265e-02,
          2.2260e-02,  4.8660e-02],
        [-1.9182e-01, -1.0068e-01, -2.8121e-03, -3.1196e-02, -8.3383e-02,
         -2.8121e-03, -3.3823e-03, -4.6687e-02, -1.6070e-01, -2.0344e-02,
         -2.0743e-01, -2.2075e-03, -3.0410e-02, -2.8121e-03, -2.8123e-03,
         -2.8162e-03, -8.5853e-02, -3.1903e-02, -7.9474e-03, -1.9974e-02,
         -2.8121e-03,  3.4869e-03],
        [-7.4813e+00,  1.1274e+01,  1.2833e-01,  4.8732e+00,  5.0856e+00,
          1.2829e-01, -4.3403e-02,  8.0989e+00, -6.1868e+00, -2.2805e+00,
         -9.0724e+00, -1.0888e+00,  5.3599e+00,  1.2834e-01,  1.2842e-01,
          8.9987e-02,  8.1072e+00,  6.9853e+00, -1.2007e+00, -1.5979e+00,
          1.2834e-01,  4.9242e+00],
        [-1.9182e-01, -1.0068e-01, -2.8121e-03, -3.1196e-02, -8.3383e-02,
         -2.8121e-03, -3.3823e-03, -4.6687e-02, -1.6070e-01, -2.0344e-02,
         -2.0743e-01, -2.2075e-03, -3.0410e-02, -2.8121e-03, -2.8123e-03,
         -2.8162e-03, -8.5853e-02, -3.1903e-02, -7.9474e-03, -1.9974e-02,
         -2.8121e-03,  3.4869e-03],
        [-1.9182e-01, -1.0068e-01, -2.8121e-03, -3.1196e-02, -8.3383e-02,
         -2.8121e-03, -3.3823e-03, -4.6687e-02, -1.6070e-01, -2.0344e-02,
         -2.0743e-01, -2.2075e-03, -3.0410e-02, -2.8121e-03, -2.8123e-03,
         -2.8162e-03, -8.5853e-02, -3.1903e-02, -7.9474e-03, -1.9974e-02,
         -2.8121e-03,  3.4869e-03],
        [-1.9182e-01, -1.0068e-01, -2.8121e-03, -3.1196e-02, -8.3383e-02,
         -2.8121e-03, -3.3823e-03, -4.6687e-02, -1.6070e-01, -2.0344e-02,
         -2.0743e-01, -2.2075e-03, -3.0410e-02, -2.8121e-03, -2.8123e-03,
         -2.8162e-03, -8.5853e-02, -3.1902e-02, -7.9474e-03, -1.9974e-02,
         -2.8121e-03,  3.4869e-03],
        [-6.6943e-01,  6.2841e-01, -6.7300e-02, -2.6761e+00,  7.4804e-01,
         -6.7301e-02, -7.9443e-02, -2.8464e+00, -7.7135e-01,  2.0655e-01,
         -5.7019e-01, -1.7407e-02, -2.5510e+00, -6.7299e-02, -6.7296e-02,
         -6.8411e-02,  7.7292e-01, -2.6200e+00,  2.5902e-02,  1.3219e-01,
         -6.7299e-02,  1.3396e-01],
        [-1.9182e-01, -1.0068e-01, -2.8121e-03, -3.1196e-02, -8.3383e-02,
         -2.8121e-03, -3.3823e-03, -4.6687e-02, -1.6070e-01, -2.0344e-02,
         -2.0743e-01, -2.2075e-03, -3.0410e-02, -2.8121e-03, -2.8123e-03,
         -2.8162e-03, -8.5853e-02, -3.1902e-02, -7.9473e-03, -1.9974e-02,
         -2.8121e-03,  3.4869e-03]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-2.1708,  0.4726, -2.1708,  0.7054,  0.1709, -0.9583, -2.1708, -2.1708,
        -2.1708, -2.1708, -1.4610, -0.6953, -2.1708, -2.1708,  4.3923, -2.1708,
        -0.3748, -2.1708, -2.1708, -2.1708,  5.3129, -2.1708], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 1.5786e-02, -1.3786e+01,  1.5786e-02, -2.0138e+01, -1.1804e+01,
         -5.3012e+00,  1.5786e-02,  1.5786e-02,  1.5786e-02,  1.5786e-02,
         -4.4745e+00,  1.9772e+01,  1.5786e-02,  1.5786e-02,  5.2928e+00,
          1.5786e-02, -7.5852e+00,  1.5786e-02,  1.5786e-02,  1.5786e-02,
          5.4722e+00,  1.5786e-02]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 12.1521,   3.0511],
        [  0.9507,  13.2334],
        [ 16.4952,   0.8478],
        [ 13.8755,   0.0487],
        [ -1.6931,   0.4745],
        [ -0.7779,   1.4992],
        [ -1.4970,   0.5850],
        [ -1.5478,   0.5419],
        [ -1.7239,   0.4415],
        [  6.2279,  -0.3631],
        [ -1.7234,   0.4342],
        [ -1.5375,   0.6534],
        [-12.8124,  -1.0882],
        [ -8.3886,   6.6926],
        [ -8.3721,  11.0837],
        [ -1.5415,   0.5505],
        [ -1.7011,   0.4060],
        [-13.6188,  -3.1792],
        [-11.4994,  -4.3033],
        [  4.6808,  13.6034],
        [ 12.8863,   2.2865],
        [ 13.6308,  12.5190]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ -8.4865,   8.2435,   3.8326, -11.9402,  -5.0058,  -5.1827,  -5.1778,
         -5.1620,  -5.0260, -11.5532,  -5.0291,  -5.1233,   6.8039,   3.0830,
          7.4410,  -5.1376,  -5.2351,   3.4373,  -2.2434,   8.5422,  -6.1592,
          7.0288], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 3.1484e-01, -7.5545e-01, -2.3084e+00, -3.7309e-01, -2.1521e-03,
         -8.2062e-02, -5.0069e-04, -1.3646e-03, -2.5857e-03, -4.3428e-02,
         -2.6616e-03,  1.2217e-03, -1.2001e+00, -6.9162e-01, -1.1618e+00,
         -1.1158e-03, -3.2436e-03, -1.1570e+00, -4.9851e-01, -1.1399e+00,
         -7.2520e-01, -1.0281e+00],
        [-1.4848e-02, -5.8688e-01, -2.4466e+00, -6.7127e-01, -5.5720e-03,
         -3.2556e-02, -5.1104e-03, -5.4441e-03, -5.6889e-03, -2.3867e-02,
         -5.7067e-03, -4.1975e-03, -1.1068e+00, -3.8075e-01, -6.9723e-01,
         -5.3519e-03, -5.8816e-03, -9.3285e-01, -2.9282e-01, -9.7416e-01,
         -1.0013e+00, -1.1803e+00],
        [-1.4172e-02, -5.8729e-01, -2.4462e+00, -6.7071e-01, -5.5689e-03,
         -3.2654e-02, -5.1054e-03, -5.4406e-03, -5.6867e-03, -2.3970e-02,
         -5.7046e-03, -4.1901e-03, -1.1073e+00, -3.8153e-01, -6.9853e-01,
         -5.3478e-03, -5.8826e-03, -9.3378e-01, -2.9343e-01, -9.7467e-01,
         -1.0007e+00, -1.1800e+00],
        [-1.3618e-02, -5.8772e-01, -2.4460e+00, -6.7009e-01, -5.5662e-03,
         -3.2731e-02, -5.1009e-03, -5.4373e-03, -5.6846e-03, -2.4050e-02,
         -5.7026e-03, -4.1833e-03, -1.1074e+00, -3.8216e-01, -6.9955e-01,
         -5.3440e-03, -5.8831e-03, -9.3433e-01, -2.9383e-01, -9.7509e-01,
         -9.9970e-01, -1.1797e+00],
        [-6.5969e-03, -5.9240e-01, -2.4424e+00, -6.6359e-01, -5.5313e-03,
         -3.3738e-02, -5.0459e-03, -5.3972e-03, -5.6582e-03, -2.5091e-02,
         -5.6768e-03, -4.1030e-03, -1.1109e+00, -3.9015e-01, -7.1265e-01,
         -5.2980e-03, -5.8890e-03, -9.4281e-01, -2.9965e-01, -9.8033e-01,
         -9.9088e-01, -1.1769e+00],
        [ 8.7755e-03, -6.0252e-01, -2.4352e+00, -6.4919e-01, -5.4435e-03,
         -3.5899e-02, -4.9170e-03, -5.2987e-03, -5.5876e-03, -2.7306e-02,
         -5.6075e-03, -3.9225e-03, -1.1177e+00, -4.0711e-01, -7.4016e-01,
         -5.1872e-03, -5.8846e-03, -9.5977e-01, -3.1188e-01, -9.9128e-01,
         -9.7150e-01, -1.1707e+00],
        [-2.1323e-01, -1.3111e+01,  7.9228e-01, -8.4838e+00,  2.4089e-01,
          2.0610e-01,  2.5951e-01,  2.6288e-01,  2.2700e-01, -1.2796e+00,
          2.2708e-01,  2.6124e-01,  5.4947e+00,  4.8908e-01, -6.7632e+00,
          2.5913e-01,  3.4504e-01,  4.4480e+00,  3.3482e+00, -1.2880e+01,
         -2.0212e+00, -7.1949e+00],
        [-3.1655e+00,  4.7048e+00, -4.6359e+00, -7.3580e+00, -1.2638e-01,
         -2.2493e-01, -2.1962e-01, -2.1343e-01, -1.1522e-01, -2.2574e-01,
         -1.1228e-01, -2.1434e-01,  2.8066e+00,  6.1272e+00,  7.0429e+00,
         -2.0274e-01, -8.8610e-02,  3.1329e+00, -7.1012e-01,  3.6097e+00,
         -2.9462e+00,  1.9856e+00],
        [ 2.6586e+00,  1.8974e+01,  2.4762e+00,  8.3697e+00, -2.5358e-01,
         -4.6484e-02, -1.9895e-01, -2.0529e-01, -2.4681e-01, -7.4192e-02,
         -2.4391e-01, -2.0045e-01, -1.0257e+01, -7.6353e-02,  1.0658e+01,
         -2.0871e-01, -2.3976e-01, -1.0133e+01, -6.4462e+00,  2.1411e+01,
          6.7003e+00,  1.9679e+01],
        [-1.0748e-02, -5.8968e-01, -2.4446e+00, -6.6736e-01, -5.5522e-03,
         -3.3142e-02, -5.0784e-03, -5.4211e-03, -5.6742e-03, -2.4476e-02,
         -5.6924e-03, -4.1503e-03, -1.1088e+00, -3.8543e-01, -7.0493e-01,
         -5.3254e-03, -5.8861e-03, -9.3777e-01, -2.9618e-01, -9.7726e-01,
         -9.9593e-01, -1.1786e+00],
        [-6.6493e-03, -5.9236e-01, -2.4425e+00, -6.6365e-01, -5.5316e-03,
         -3.3732e-02, -5.0463e-03, -5.3976e-03, -5.6584e-03, -2.5084e-02,
         -5.6770e-03, -4.1036e-03, -1.1109e+00, -3.9010e-01, -7.1256e-01,
         -5.2984e-03, -5.8890e-03, -9.4276e-01, -2.9961e-01, -9.8029e-01,
         -9.9095e-01, -1.1769e+00],
        [-3.3648e-01, -1.8791e+01, -1.0662e+01, -6.5261e+00, -1.2121e-02,
         -6.5770e-03,  8.1046e-04, -7.0011e-04, -1.1147e-02, -1.1784e-02,
         -1.0207e-02, -4.5814e-03,  8.4091e+00,  2.7379e+00, -2.8887e+00,
         -1.0345e-03, -2.7878e-02,  7.8626e+00,  7.2781e+00, -2.8286e+01,
         -1.3323e+01, -2.4766e+01],
        [-1.5134e-02, -5.8668e-01, -2.4468e+00, -6.7154e-01, -5.5733e-03,
         -3.2514e-02, -5.1126e-03, -5.4456e-03, -5.6899e-03, -2.3824e-02,
         -5.7077e-03, -4.2008e-03, -1.1067e+00, -3.8042e-01, -6.9669e-01,
         -5.3537e-03, -5.8812e-03, -9.3250e-01, -2.9259e-01, -9.7394e-01,
         -1.0017e+00, -1.1804e+00],
        [-4.6370e-01,  2.4843e-02,  2.9967e+00, -3.7767e+00,  2.6706e-02,
         -6.4778e-01, -4.7040e-01, -4.3609e-01,  7.3329e-02, -1.4965e-01,
          7.0866e-02, -5.2171e-01,  1.2652e+01, -2.7893e-01,  3.4079e+00,
         -4.1224e-01,  7.7655e-02,  1.0018e+01,  1.5960e-01,  1.4334e+00,
         -9.0248e-01, -9.9792e-01],
        [ 2.3669e-01, -6.4395e-01,  4.0347e+00,  1.3368e+00, -3.6840e-01,
         -2.0507e+00, -7.0487e-01, -6.2846e-01, -3.4971e-01, -1.0597e-01,
         -3.4687e-01, -7.5666e-01,  1.1711e-01, -4.3994e+00, -6.4540e+00,
         -6.1351e-01, -2.1384e-01, -1.2823e+00, -2.1670e+00, -1.4111e+00,
          9.7010e+00, -2.0384e+00],
        [ 1.5062e-02, -6.0632e-01, -2.4317e+00, -6.4406e-01, -5.4044e-03,
         -3.6845e-02, -4.8635e-03, -5.2560e-03, -5.5549e-03, -2.8233e-02,
         -5.5753e-03, -3.8506e-03, -1.1207e+00, -4.1417e-01, -7.5154e-01,
         -5.1399e-03, -5.8773e-03, -9.6698e-01, -3.1718e-01, -9.9542e-01,
         -9.6425e-01, -1.1685e+00],
        [-2.8327e-01,  1.0658e-01,  3.0430e+00,  7.1752e-01, -1.4622e-02,
         -6.2196e-01, -5.5591e-02, -3.9033e-02, -1.0544e-02, -7.1631e-03,
         -9.7561e-03, -8.0766e-02,  2.1356e-01, -7.7105e-01, -3.5806e-01,
         -4.1206e-02, -1.1480e-02, -5.0354e-01, -6.9738e-01,  3.6034e-01,
          2.0505e+00,  1.4967e+00],
        [-7.0113e+00, -3.4759e+00,  4.2332e-01, -6.1561e+00,  2.6484e-02,
         -4.7874e-02,  2.9697e-02,  3.2561e-02,  2.0751e-02, -8.3695e-01,
          2.0681e-02,  2.4326e-02, -2.8532e+00, -7.9336e-02, -7.9868e-02,
          3.4690e-02, -1.2423e-03, -3.4634e+00, -9.9363e-01, -1.5582e+01,
         -1.2616e-01, -3.8914e-01],
        [-1.3417e+00, -5.4737e+00,  2.1128e+00, -1.0756e+01, -8.6558e-02,
         -3.1079e-01, -9.6284e-02, -8.0638e-02, -6.6470e-02, -1.6921e+00,
         -4.4082e-02, -1.4160e-01, -6.2991e-01,  2.5198e+00,  2.1007e+00,
         -5.7986e-02, -3.1202e-01,  3.2582e+00,  5.2959e+00, -2.0634e+00,
          1.8075e+00, -2.2978e+00],
        [-2.2284e+00, -1.4447e+01, -1.2298e+00, -7.7160e+00, -4.0183e-02,
         -5.1514e-02, -4.2744e-02, -4.7553e-02, -1.7655e-02,  1.4747e-03,
         -1.5263e-02, -4.2689e-02,  3.7521e+00,  3.1771e+00, -9.5476e-01,
         -4.6464e-02, -4.8790e-02,  2.9959e+00,  7.0028e+00, -1.8299e+01,
         -4.2876e+00, -2.6971e+00],
        [ 8.2424e-03, -6.0262e-01, -2.4372e+00, -6.4836e-01, -5.4466e-03,
         -3.5978e-02, -4.9194e-03, -5.3010e-03, -5.5905e-03, -2.7269e-02,
         -5.6104e-03, -3.9248e-03, -1.1162e+00, -4.0718e-01, -7.4010e-01,
         -5.1897e-03, -5.8857e-03, -9.5881e-01, -3.1152e-01, -9.9065e-01,
         -9.6849e-01, -1.1704e+00],
        [-1.9387e+00,  6.3574e+00, -4.9696e+00, -9.1926e+00, -8.8846e-02,
         -1.0701e-01,  2.1350e-03,  4.4944e-04, -1.5129e-01,  3.5385e-02,
         -1.6276e-01, -1.1334e-02,  5.1928e-01,  5.0354e+00,  7.3517e+00,
         -2.1972e-02,  1.4487e-01,  1.2973e+00,  3.0471e-01,  3.4561e+00,
         -8.3439e+00, -1.1318e-01]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-2.3212, -2.4518, -2.4514, -2.4512, -2.4477, -2.4405,  1.9840, -5.9133,
        -3.1607, -2.4498, -2.4477, -1.0294, -2.4520,  3.2929,  4.8326, -2.4369,
         3.0726, -0.2557,  2.5111, -0.6790, -2.4424, -5.2901], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-8.5409e-04, -3.0647e-04, -3.0829e-04, -3.0987e-04, -3.2975e-04,
         -3.7538e-04, -2.7604e-03, -3.7934e-01, -1.7657e+00, -3.1792e-04,
         -3.2960e-04,  1.2684e-06, -3.0568e-04, -1.7225e+00, -1.7569e+00,
         -3.9520e-04, -1.7657e+00, -1.6584e-03, -1.5188e-01, -6.0369e-05,
         -3.7491e-04, -3.6150e-02],
        [-5.9288e-04, -1.8225e-04, -1.8978e-04, -1.9620e-04, -2.7233e-04,
         -4.1943e-04,  2.1964e-03, -2.3005e-01, -9.3492e-01, -2.2809e-04,
         -2.7181e-04,  4.7290e-05, -1.7896e-04, -8.8271e-01, -9.3476e-01,
         -4.7284e-04, -9.3521e-01, -5.4455e-03, -1.1063e-01,  1.0896e-03,
         -4.1934e-04, -2.5017e-02],
        [-1.4337e-03, -6.1503e-04, -6.1269e-04, -6.1057e-04, -5.8590e-04,
         -5.4710e-04, -3.2934e-03, -3.1670e-01, -1.6316e+00, -6.0019e-04,
         -5.8607e-04,  2.6505e-06, -6.1606e-04, -1.5877e+00, -1.6239e+00,
         -5.3873e-04, -1.6317e+00, -3.4607e-03, -1.3698e-01, -9.1999e-05,
         -5.4724e-04, -3.8432e-02],
        [ 2.0636e-04, -1.7786e-04, -1.7742e-04, -1.7701e-04, -1.7214e-04,
         -1.6129e-04,  7.5248e-04, -3.0259e-01, -1.4485e+00, -1.7500e-04,
         -1.7218e-04,  4.1930e-06, -1.7806e-04, -1.4136e+00, -1.4425e+00,
         -1.5693e-04, -1.4486e+00, -1.1684e-03, -1.1805e-01, -1.1212e-04,
         -1.6125e-04, -3.6183e-02],
        [ 4.2982e-01,  2.3885e-01,  2.3883e-01,  2.3968e-01,  2.4356e-01,
          2.5248e-01,  4.5533e+00, -4.3345e-01, -2.8920e+00,  2.4158e-01,
          2.4352e-01, -1.7424e+01,  2.3865e-01,  3.5049e+00,  3.6137e+00,
          2.5646e-01,  3.7002e+00,  2.7175e+00,  2.1045e+00,  5.9581e+00,
          2.5161e-01,  4.9959e-02],
        [-1.0271e-03,  2.8703e-04,  2.8625e-04,  2.8558e-04,  2.7690e-04,
          2.5539e-04,  2.4508e-03, -2.7194e-01, -1.1999e+00,  2.8211e-04,
          2.7696e-04,  3.6002e-05,  2.8737e-04, -1.1672e+00, -1.1933e+00,
          2.4546e-04, -1.1999e+00, -2.6764e-03, -7.5213e-02,  3.3395e-05,
          2.5497e-04, -3.1846e-02],
        [-1.2309e-03, -4.4384e-04, -4.4580e-04, -4.4747e-04, -4.6754e-04,
         -5.0865e-04, -3.7992e-03, -2.4424e-01, -1.4637e+00, -4.5582e-04,
         -4.6740e-04,  1.9382e-06, -4.4299e-04, -1.4181e+00, -1.4578e+00,
         -5.2501e-04, -1.4639e+00, -4.2255e-03, -1.2145e-01, -8.2050e-05,
         -5.0819e-04, -3.0739e-02],
        [-7.6702e-01, -5.0344e-01, -5.0485e-01, -5.0509e-01, -5.1525e-01,
         -5.3561e-01,  4.4329e+00,  2.9984e-01,  2.9257e+00, -5.0895e-01,
         -5.1519e-01, -4.1022e+00, -5.0305e-01,  1.6999e+00,  1.1586e+00,
         -5.4368e-01,  9.5748e-01,  4.8916e+00,  1.9885e+00,  1.2765e+00,
         -5.3649e-01,  5.0344e-03],
        [-6.4650e-04, -5.4140e-04, -5.4190e-04, -5.4229e-04, -5.4720e-04,
         -5.5645e-04, -1.4184e-03, -3.1322e-01, -1.5523e+00, -5.4434e-04,
         -5.4717e-04,  7.5683e-07, -5.4119e-04, -1.5113e+00, -1.5451e+00,
         -5.6055e-04, -1.5525e+00, -2.0642e-03, -1.2770e-01, -5.4007e-05,
         -5.5635e-04, -3.4342e-02],
        [-3.9957e-04, -2.4893e-04, -2.4890e-04, -2.4881e-04, -2.4606e-04,
         -2.2764e-04, -8.2730e-03, -2.2712e-01, -1.3242e+00, -2.4810e-04,
         -2.4610e-04, -7.8835e-06, -2.4894e-04, -1.2933e+00, -1.3211e+00,
         -2.1565e-04, -1.3251e+00, -3.5842e-03, -1.9014e-01, -5.1676e-04,
         -2.2747e-04, -2.8722e-02],
        [-3.2214e-01, -2.3345e-01, -2.3391e-01, -2.3387e-01, -2.3662e-01,
         -2.4190e-01, -2.5609e+01,  6.3598e+00,  3.1287e+00, -2.3487e-01,
         -2.3661e-01,  1.2947e-05, -2.3335e-01, -9.7259e-01, -9.6826e-01,
         -2.4414e-01, -9.9083e-01, -4.0120e+00,  3.4441e+00, -2.4508e+00,
         -2.4180e-01,  2.5837e+00],
        [ 2.0413e-01,  5.4023e-02,  5.3751e-02,  5.4441e-02,  5.6007e-02,
          6.0380e-02, -1.1396e+00, -1.9169e-01,  5.2817e+00,  5.5398e-02,
          5.5980e-02,  2.4085e+01,  5.3921e-02,  5.6292e-01,  8.6227e-01,
          6.2338e-02,  5.4653e-01, -6.6001e+00,  1.5128e+00, -1.3006e+00,
          5.9411e-02, -1.0001e+00],
        [-1.2197e-03, -4.6382e-04, -4.6529e-04, -4.6652e-04, -4.8250e-04,
         -5.2175e-04, -2.6459e-03, -3.5535e-01, -1.7456e+00, -4.7294e-04,
         -4.8238e-04,  1.4155e-06, -4.6320e-04, -1.6993e+00, -1.7369e+00,
         -5.4036e-04, -1.7457e+00, -1.9698e-03, -1.5107e-01, -1.0212e-04,
         -5.2123e-04, -4.1554e-02],
        [-6.3224e-04, -2.8204e-04, -2.8265e-04, -2.8315e-04, -2.9022e-04,
         -3.1040e-04, -1.1687e-03, -3.7521e-01, -1.7272e+00, -2.8589e-04,
         -2.9016e-04,  2.4451e-06, -2.8178e-04, -1.6854e+00, -1.7186e+00,
         -3.2101e-04, -1.7272e+00, -5.7330e-04, -1.4910e-01, -6.8928e-05,
         -3.1017e-04, -3.6621e-02]], device='cuda:0'))])
xi:  [1248.217]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 1637.3798891272038
W_T_median: 1594.879378047758
W_T_pctile_5: 1252.866680661143
W_T_CVAR_5_pct: 734.7350416759971
Average q (qsum/M+1):  51.93457425025202
Optimal xi:  [1248.217]
Expected(across Rb) median(across samples) p_equity:  2.382607173601059e-06
obj fun:  tensor(-2344.4076, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/factor_decumulation/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:262: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/factor_decumulation/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/factor_decumulation/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: MC_everything
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       22  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       22  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 22)      True          22  
0     (22, 22)      True          22  
0      (22, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       22  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       22  logistic_sigmoid   
0        obj.layers[3]         3  output_layer       14           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 22)      True          22  
0     (22, 22)      True          22  
0     (22, 14)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -8.5715,   6.4621],
        [ -8.3669,  -9.0182],
        [ -5.1223,   3.2445],
        [  8.0669,   4.1508],
        [-11.4280,  -6.0457],
        [ -6.4858,   4.0851],
        [  6.0779,   4.9126],
        [  9.1747,   0.7713],
        [ -8.3119,   6.0846],
        [ -8.3147,   6.0977],
        [ -8.4882,   6.6116],
        [ -8.6931,   5.7529],
        [  7.8819,   3.3034],
        [ -1.2974,   1.0853],
        [  5.4594,  -0.3288],
        [  5.2299,   5.2824],
        [-11.7613,  -7.4762],
        [  7.7973,   4.2640],
        [ -8.5799,   5.8746],
        [ -7.8535,   5.7472],
        [ -1.2944,   1.0845],
        [-21.4386,  -5.7294]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ 4.8764, -5.7404, -3.0406, -9.5323, -3.7687, -2.3429, -8.4043, -9.1228,
         4.2727,  3.0356,  5.1757,  1.5461, -8.9288, -3.8883, -8.9159, -8.5427,
        -4.0692, -9.2749,  1.8685,  2.4405, -3.8889, -4.6902], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1574e-03, -1.6502e-02, -2.2728e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1088e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [-9.2453e+00,  1.2482e+01, -7.2066e-01,  7.0332e+00,  4.6981e+00,
         -1.2007e+00,  4.5523e+00,  6.2080e+00, -7.5674e+00, -3.0869e+00,
         -1.0021e+01, -1.8126e+00,  5.8578e+00, -1.6237e-01,  6.8999e-01,
          5.4520e+00,  8.4865e+00,  8.0426e+00, -2.2762e+00, -3.8127e+00,
         -1.9618e-01,  8.7135e+00],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2751e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-9.6515e+00,  1.3280e+01, -9.1434e-01,  9.3871e+00,  5.7620e+00,
         -1.3190e+00,  6.4927e+00,  6.8045e+00, -8.3770e+00, -3.3906e+00,
         -1.0939e+01, -2.1716e+00,  6.5179e+00, -2.1870e-01,  2.0491e+00,
          4.1453e+00,  9.2888e+00,  7.8384e+00, -2.6898e+00, -4.4743e+00,
         -1.9003e-01,  9.7752e+00],
        [-7.9773e+00,  1.0315e+01,  2.5895e-01,  4.6608e+00,  4.9211e+00,
          1.7041e-02,  2.1882e+00,  6.8647e+00, -6.6734e+00, -4.8263e+00,
         -8.8073e+00, -2.8795e+00,  6.4311e+00,  1.6629e-01,  1.1111e+00,
          5.0411e+00,  7.6765e+00,  1.1081e+01, -3.5739e+00, -4.0927e+00,
          1.6082e-01,  8.5887e+00],
        [-7.6589e+00,  9.2592e+00,  7.9739e-02,  3.9257e+00,  4.5700e+00,
          1.0005e-01,  2.1053e+00,  4.6166e+00, -6.0015e+00, -3.8545e+00,
         -9.2106e+00, -1.7570e+00,  5.7099e+00, -1.2986e-02,  5.9836e-02,
          4.9159e+00,  7.0161e+00,  9.4703e+00, -2.3319e+00, -3.1763e+00,
         -1.3208e-02,  7.3285e+00],
        [-2.2581e-01, -1.6549e-01,  1.7511e-03, -1.2938e-02, -1.1903e-01,
          1.1578e-03, -1.6509e-02, -2.2839e-03, -1.8738e-01, -6.9338e-02,
         -2.5288e-01, -1.2692e-02, -9.1165e-03,  1.2292e-02,  1.9855e-02,
         -1.7662e-02, -1.7966e-01, -1.2937e-02, -1.9683e-02, -4.9682e-02,
          1.2307e-02, -3.1400e-02],
        [-2.2584e-01, -1.6546e-01,  1.7508e-03, -1.2931e-02, -1.1901e-01,
          1.1573e-03, -1.6502e-02, -2.2704e-03, -1.8735e-01, -6.9322e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9856e-02,
         -1.7657e-02, -1.7959e-01, -1.2929e-02, -1.9678e-02, -4.9672e-02,
          1.2308e-02, -3.1398e-02],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2752e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2730e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1088e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [-7.4230e+00,  9.2761e+00,  8.2691e-02,  4.6883e+00,  4.4150e+00,
          1.2211e-01,  2.9895e+00,  3.5408e+00, -6.2114e+00, -3.5923e+00,
         -9.4198e+00, -1.8627e+00,  4.7011e+00, -1.9985e-02, -6.0281e-02,
          5.2032e+00,  7.0797e+00,  8.3206e+00, -2.3235e+00, -3.3515e+00,
         -1.9947e-02,  7.4397e+00],
        [ 7.9326e+00, -1.0706e+01,  4.0837e-01, -9.2089e+00, -5.7725e+00,
          6.6403e-01, -4.8629e+00, -5.8385e+00,  6.6214e+00,  5.0109e+00,
          9.6232e+00,  3.3999e+00, -5.8456e+00, -1.3669e-01, -1.4453e+00,
         -3.3601e+00, -8.4017e+00, -9.5444e+00,  3.9084e+00,  4.3412e+00,
         -1.3169e-01, -9.7519e+00],
        [-2.2583e-01, -1.6545e-01,  1.7507e-03, -1.2931e-02, -1.1900e-01,
          1.1572e-03, -1.6503e-02, -2.2678e-03, -1.8733e-01, -6.9320e-02,
         -2.5297e-01, -1.2687e-02, -9.1093e-03,  1.2293e-02,  1.9856e-02,
         -1.7657e-02, -1.7958e-01, -1.2930e-02, -1.9677e-02, -4.9670e-02,
          1.2308e-02, -3.1399e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2931e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2732e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [ 6.5891e-01,  3.0868e-01,  8.3566e-03,  3.5747e-02,  2.1159e-01,
          5.3475e-03,  5.7464e-02,  2.6629e-01,  5.5272e-01,  2.6083e-01,
          7.4008e-01,  8.5701e-02,  7.1654e-02,  3.7717e-02,  5.6900e-02,
          8.1005e-02,  2.9146e-01,  3.6840e-02,  1.1119e-01,  2.1066e-01,
          3.7716e-02,  1.3910e-01],
        [-2.2585e-01, -1.6548e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2733e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1087e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2307e-02, -3.1398e-02],
        [-7.5648e+00,  9.6323e+00,  3.4567e-02,  4.2023e+00,  4.4635e+00,
         -1.3328e-01,  2.0401e+00,  5.3264e+00, -6.2784e+00, -3.7048e+00,
         -9.3470e+00, -2.0562e+00,  5.8618e+00, -3.3635e-02,  2.0363e-01,
          5.0433e+00,  7.2814e+00,  9.5323e+00, -2.4148e+00, -3.3678e+00,
         -3.5727e-02,  7.7623e+00],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2750e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2744e-03, -1.8737e-01, -6.9326e-02,
         -2.5298e-01, -1.2689e-02, -9.1087e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2931e-02, -1.1901e-01,
          1.1574e-03, -1.6502e-02, -2.2722e-03, -1.8735e-01, -6.9324e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9673e-02,
          1.2308e-02, -3.1398e-02],
        [ 6.6450e-01,  3.1201e-01,  8.4127e-03,  3.4696e-02,  2.1235e-01,
          5.3877e-03,  5.6376e-02,  2.6891e-01,  5.5678e-01,  2.6166e-01,
          7.4701e-01,  8.5769e-02,  7.1346e-02,  3.8211e-02,  5.7275e-02,
          8.0058e-02,  2.9347e-01,  3.5786e-02,  1.1132e-01,  2.1139e-01,
          3.8209e-02,  1.3913e-01],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2753e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-2.4313,  0.0078, -2.4313,  0.0873, -0.2625, -0.5234, -2.4313, -2.4314,
        -2.4313, -2.4313, -0.4369, -0.2571, -2.4314, -2.4313,  4.5769, -2.4313,
        -0.4006, -2.4313, -2.4313, -2.4313,  4.6668, -2.4313], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[  0.0334, -10.4940,   0.0334, -15.8008,  -9.7979,  -6.9452,   0.0334,
           0.0334,   0.0334,   0.0334,  -7.0927,  14.9535,   0.0334,   0.0334,
           4.2936,   0.0334,  -7.0565,   0.0334,   0.0334,   0.0334,   4.7631,
           0.0334]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 1.0813e+01,  2.9656e+00],
        [ 5.5664e-01,  1.1757e+01],
        [ 1.8618e+01,  2.3664e+00],
        [ 1.0637e+01,  1.5273e-02],
        [-1.4941e+01, -2.2181e+00],
        [-1.2849e+00,  1.3570e+00],
        [-1.2800e+00,  1.3116e+00],
        [-1.7122e+00,  6.5637e-01],
        [-2.0284e+00,  2.5259e-01],
        [ 9.3477e+00, -5.2188e-01],
        [-1.9314e+00,  2.3251e-01],
        [-1.8788e+00,  4.0167e-01],
        [-1.0523e+01, -1.6251e+00],
        [-8.3398e+00,  5.3496e+00],
        [-7.4426e+00,  1.0247e+01],
        [-1.2446e+01, -2.8588e+00],
        [-1.4240e+01, -3.1016e+00],
        [-1.0901e+01, -2.0063e+00],
        [-1.0106e+01, -2.4687e+00],
        [ 3.1771e+00,  1.1429e+01],
        [ 1.0907e+01,  2.2476e+00],
        [ 1.1102e+01,  1.0847e+01]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-5.5365,  7.0663,  2.9709, -9.6018, -1.5848, -4.5127, -4.5185, -4.9090,
        -4.9531, -9.4875, -4.9847, -4.9560,  5.4223,  3.0397,  6.7011, -3.5168,
        -2.9913,  3.2472,  0.4201,  7.7652, -4.3018,  6.4326], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 6.1957e-01, -3.4634e+00, -1.7479e+00,  1.1905e+00,  1.2460e-02,
          1.1948e-01,  1.3226e-01,  4.3984e-02, -1.1598e-02,  1.0215e+00,
         -6.1706e-03,  2.4414e-03, -2.5313e+00,  1.1746e+00, -7.8526e-01,
         -9.2734e-03,  2.7572e-03, -2.7562e+00, -1.8971e+00, -2.6434e+00,
         -4.2419e-01,  3.0293e-02],
        [-4.6968e-01, -1.5418e-01, -2.2179e+00, -4.7229e-01, -1.4815e-02,
         -2.6861e-02, -2.4100e-02,  6.5293e-03, -1.5585e-02, -3.8766e-01,
         -1.6068e-02, -1.1227e-02, -1.0214e+00, -1.1716e-01, -1.0616e-01,
         -5.8386e-03, -7.9498e-03, -5.2026e-01, -1.9652e-01, -4.4158e-01,
         -1.2068e+00, -1.2289e+00],
        [-9.0043e-01, -3.1328e-01, -2.4749e+00, -1.0214e+00, -5.5072e-03,
         -2.2407e-02, -1.9453e-02, -7.7448e-03,  4.4606e-03, -9.3610e-01,
          4.1020e-03,  2.5876e-03, -1.2488e+00, -4.6992e-02, -9.2699e-02,
         -2.2626e-03, -3.5666e-03, -6.7176e-01, -2.4800e-01, -8.7567e-01,
         -1.3802e+00, -7.7155e-01],
        [-4.7184e-01, -1.5540e-01, -2.2143e+00, -4.7815e-01, -1.4473e-02,
         -2.7281e-02, -2.4476e-02,  6.5809e-03, -1.5495e-02, -3.9563e-01,
         -1.5975e-02, -1.1107e-02, -1.0396e+00, -1.1822e-01, -1.0605e-01,
         -5.8775e-03, -7.9716e-03, -5.2621e-01, -1.9589e-01, -4.4421e-01,
         -1.2127e+00, -1.2341e+00],
        [-4.8450e-01, -1.6921e-01, -2.2399e+00, -4.9569e-01, -1.4212e-02,
         -2.5472e-02, -2.2971e-02,  5.3544e-03, -1.0943e-02, -4.2767e-01,
         -1.1482e-02, -7.9784e-03, -1.0434e+00, -1.0826e-01, -9.0719e-02,
         -6.2509e-03, -8.3116e-03, -5.2892e-01, -2.1129e-01, -4.5420e-01,
         -1.2241e+00, -1.0613e+00],
        [ 3.0119e-01,  9.1885e-01, -1.5837e+00, -8.5542e-01, -1.1953e-02,
         -1.9274e+00, -1.8752e+00, -1.4092e+00, -5.5076e-01,  1.0780e+00,
         -4.5548e-01, -9.9188e-01, -3.9286e+00,  1.1415e+00,  2.2999e+00,
         -1.2239e-02, -1.3323e-02, -2.7068e+00, -9.7625e-01,  4.2057e-01,
         -1.0808e+00, -1.2393e+00],
        [ 2.4582e-01, -1.1721e+01,  5.7285e-01, -6.6182e+00,  3.3458e+00,
          1.7362e-01,  1.7999e-01,  2.0080e-01,  2.8786e-01, -4.5146e+00,
          2.9196e-01,  1.9339e-01,  3.6973e+00, -2.2846e+00, -8.2839e+00,
          2.5629e+00,  2.7897e+00,  3.3397e+00,  3.6998e+00, -1.2216e+01,
          1.0269e-01, -7.8724e+00],
        [-2.7710e+00,  3.8384e+00, -3.8614e+00, -5.2497e+00,  1.4955e-01,
         -5.1488e-01, -5.0931e-01, -4.0831e-01, -1.3933e-01, -4.9036e+00,
         -1.0681e-01, -2.8754e-01,  2.6586e+00,  3.1018e+00,  6.0454e+00,
          5.3721e-01,  5.1709e-01,  2.4000e+00,  1.7467e+00,  2.8980e+00,
         -1.8615e+00,  1.3298e+00],
        [ 5.3996e+00,  1.7695e+01,  2.7980e+00,  6.7002e+00, -6.8933e+00,
          1.9716e-02,  1.5955e-02,  1.6031e-02, -1.9886e-01,  4.1219e+00,
         -1.8883e-01,  2.3240e-02, -8.0362e+00,  3.0849e+00,  1.4710e+01,
         -3.3033e+00, -3.8057e+00, -7.4740e+00, -6.2744e+00,  1.9113e+01,
          5.0855e+00,  2.1580e+01],
        [-4.6054e-01, -1.5864e-01, -2.1828e+00, -4.7962e-01, -1.3132e-02,
         -2.7434e-02, -2.4527e-02,  7.6509e-03, -1.3661e-02, -3.9854e-01,
         -1.4154e-02, -9.5939e-03, -1.0591e+00, -1.2246e-01, -9.9910e-02,
         -5.2767e-03, -7.3107e-03, -5.5050e-01, -2.1282e-01, -4.5037e-01,
         -1.2105e+00, -1.2384e+00],
        [-9.3210e-01, -5.0637e-01, -2.5650e+00, -1.2297e+00,  5.1007e-03,
         -1.3266e-02, -1.0812e-02, -6.5037e-03, -1.3910e-03, -1.1288e+00,
         -1.7836e-03, -1.9456e-03, -7.9371e-01, -5.5349e-02, -8.6527e-02,
          5.2059e-03,  5.8080e-03, -8.8163e-01, -4.5943e-01, -1.6628e+00,
         -1.1149e+00, -5.6400e-01],
        [-2.8460e+00, -1.8825e+01, -9.7046e+00, -3.0631e+00,  6.2381e+00,
          2.2284e-02,  2.2216e-02,  3.8058e-02,  1.2254e-02, -4.6393e+00,
          2.0356e-03,  4.3669e-02,  7.6060e+00, -3.1393e+00, -1.1899e+01,
          2.9927e+00,  3.5772e+00,  7.5127e+00,  7.0486e+00, -2.2653e+01,
         -1.0357e+01, -2.5603e+01],
        [-4.7448e-01, -1.5413e-01, -2.2021e+00, -4.7761e-01, -1.5017e-02,
         -2.6936e-02, -2.4189e-02,  6.2971e-03, -1.5709e-02, -3.9518e-01,
         -1.6194e-02, -1.1365e-02, -1.0353e+00, -1.1675e-01, -1.0676e-01,
         -6.0131e-03, -8.0879e-03, -5.2030e-01, -1.9318e-01, -4.4328e-01,
         -1.2192e+00, -1.2259e+00],
        [-6.9231e-01,  3.0014e+00,  2.7786e+00, -1.3175e+00,  3.0620e-04,
         -1.3308e-01, -1.3059e-01, -4.6677e-03, -1.5150e-02, -1.3574e+00,
         -1.8928e-02, -2.6791e-03,  2.1880e+00, -4.4040e-01,  8.1953e-01,
         -1.8323e-02, -1.1176e-02,  1.4720e+00,  4.3629e-01,  2.4554e+00,
          8.6002e-02, -2.4341e-01],
        [ 3.0175e+00, -1.5929e-01,  3.1082e+00,  1.6836e+00, -3.7655e+00,
          1.7569e-01,  1.8810e-01,  2.3150e-01, -5.4313e-01,  3.8072e+00,
         -5.3327e-01,  1.6719e-01,  6.0672e-02, -2.5586e+00, -3.6155e+00,
         -4.5190e+00, -4.8662e+00,  1.6404e-01, -1.7814e-01, -2.9936e-01,
          2.7050e+00, -1.8862e+00],
        [-6.1343e-01, -2.0997e-01, -2.3786e+00, -7.6186e-01, -1.9840e-02,
         -3.2273e-02, -3.0458e-02, -4.7454e-03,  5.8161e-03, -6.4208e-01,
          6.0534e-03,  3.5540e-03, -1.0330e+00, -6.3106e-02, -1.0050e-01,
         -7.6629e-03, -1.3412e-02, -4.8643e-01, -1.8407e-01, -5.2743e-01,
         -1.3866e+00, -9.2565e-01],
        [ 2.3232e-01,  3.1081e+00,  2.1861e+00,  1.7924e+00,  8.3474e-01,
         -4.2057e-01, -3.7750e-01, -8.6959e-02, -6.3586e-02,  1.4179e+00,
         -6.1088e-02, -4.4329e-02,  1.9436e-01, -4.4091e-01,  1.1123e+00,
          4.9760e-01,  7.0823e-01, -1.6870e-01, -3.9429e-01, -1.1351e+00,
          1.7979e-02, -1.2019e+00],
        [-9.3911e-03, -3.8280e+00, -3.1866e-01, -2.0025e+00, -3.0075e-02,
          4.3973e-02,  5.3990e-02,  1.0353e-01,  1.4874e-01, -1.8588e+00,
          1.5683e-01,  1.3914e-01, -1.0725e-01, -2.1520e-01, -2.7783e-01,
          5.4541e-02,  7.3731e-03, -1.3880e+00, -8.0744e-01, -5.4071e+00,
         -9.3933e-01,  6.6525e-02],
        [-2.0923e+00,  1.6783e+00,  2.1031e+00, -6.6800e+00,  1.9109e-04,
         -8.2756e-01, -7.5222e-01, -4.3503e-01, -1.2713e-01, -3.5556e+00,
         -7.5366e-02, -3.3382e-01,  9.4887e+00, -1.2212e+00,  5.7869e+00,
         -6.4339e-04, -3.5999e-03,  9.1765e+00,  6.6382e+00,  6.8362e-01,
          2.7993e-01, -2.2562e+00],
        [-5.5183e+00, -1.5095e+01, -2.8824e-01, -4.9346e+00,  5.3321e+00,
          1.5448e-01,  1.5735e-01,  1.6104e-01,  5.9928e-01, -2.7075e+00,
          5.5855e-01,  1.3923e-01,  3.0535e+00,  8.4196e-01, -6.5453e+00,
          4.6053e+00,  5.0922e+00,  3.6158e+00,  3.8865e+00, -1.4997e+01,
         -2.8857e+00, -4.2056e+00],
        [ 4.0156e-01, -1.0952e+00, -1.5738e+00, -4.3123e-01, -8.5229e-03,
         -6.6402e-01, -6.0136e-01, -2.4497e-01, -5.3144e-02, -2.8255e-01,
         -5.5575e-02, -9.1214e-02, -2.1121e+00,  1.5978e+00,  1.4435e+00,
         -1.0813e-03, -1.8711e-03, -2.1573e+00, -8.6345e-01, -1.7321e+00,
         -7.5512e-01,  5.2300e-01],
        [-1.9858e+00,  2.9033e+00, -2.5269e+00, -2.1485e+00,  2.2962e+00,
         -1.4441e+00, -1.3739e+00, -7.3427e-01,  6.2891e-02,  2.1944e-01,
          6.1358e-02, -2.6440e-01,  7.4516e-02,  1.7016e+00,  3.0581e+00,
          1.5196e+00,  1.8766e+00,  6.5632e-01,  1.1298e+00,  1.3664e+00,
         -2.7325e+00, -7.5516e-01]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-1.8466, -2.2256, -2.5068, -2.1943, -2.2514, -1.8834,  0.6255, -4.9456,
        -2.2024, -2.2158, -2.5964,  0.0491, -2.2135,  3.0825,  3.0734, -2.4047,
         2.5296, -1.0040,  2.4991, -0.5295, -2.0766, -2.4070], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-1.5234e-02,  7.2296e-05, -1.5502e-04,  5.9106e-05,  9.2680e-05,
         -2.2228e-02, -7.7352e-03, -1.5990e-01, -1.5103e+00,  6.1218e-05,
         -1.5306e-04, -1.3007e-05,  6.3929e-05, -1.5060e+00, -1.5008e+00,
         -2.1007e-04, -1.4999e+00, -5.4381e-03, -6.9054e-01, -3.7369e-03,
         -4.7102e-03, -3.5212e-02],
        [-8.7292e-03, -1.4222e-03,  7.6021e-04, -1.3898e-03, -1.5771e-03,
         -1.3307e-02, -5.1882e-03, -1.0878e-01, -8.2132e-01, -1.3260e-03,
          8.8522e-04, -2.6449e-04, -1.4244e-03, -8.2289e-01, -8.1366e-01,
          5.1250e-04, -8.1735e-01,  1.2221e-03, -3.1415e-01, -6.8756e-03,
          4.4122e-03, -3.5269e-02],
        [-2.1229e-02, -5.1093e-04, -3.4543e-04, -5.1941e-04, -5.4632e-04,
         -1.8385e-02, -9.4420e-03, -1.3731e-01, -1.4218e+00, -5.2075e-04,
         -3.2211e-04,  2.3184e-05, -5.1689e-04, -1.4173e+00, -1.4127e+00,
         -3.8173e-04, -1.4125e+00, -6.1909e-03, -6.2055e-01, -3.7929e-03,
         -7.1839e-03, -2.7972e-02],
        [-9.4172e-03, -2.1938e-04, -2.2482e-04, -2.0759e-04, -2.8288e-04,
         -1.6622e-02, -7.4112e-03, -1.3137e-01, -1.2415e+00, -2.0252e-04,
         -2.1593e-04, -7.4338e-05, -2.1553e-04, -1.2385e+00, -1.2343e+00,
         -1.4845e-04, -1.2328e+00, -5.0361e-03, -5.7108e-01, -3.7365e-03,
         -7.0540e-03, -2.5170e-02],
        [-1.0969e+00,  7.0714e-02,  2.8031e-01,  4.2693e-02,  2.8583e-01,
          5.4877e-01,  3.6379e+00, -1.3225e+00, -3.0535e+00,  2.8854e-01,
          9.2331e-01, -1.4907e+01,  2.7428e-02,  3.6135e+00,  3.4661e+00,
         -2.3553e-02,  3.3911e+00,  1.2464e+00,  2.0600e+00,  5.6362e+00,
         -4.8358e-01,  4.4222e-01],
        [-1.1325e-02, -1.4138e-04,  1.4500e-04, -1.5008e-04, -1.0196e-03,
         -8.7395e-03, -5.0212e-04, -1.4891e-01, -9.6424e-01, -1.5847e-04,
          8.4481e-05, -6.7668e-04, -1.4540e-04, -9.6261e-01, -9.4804e-01,
         -9.4017e-05, -9.5700e-01,  4.4294e-03, -4.5741e-01, -5.5136e-03,
          2.2288e-03, -3.6784e-02],
        [-2.4271e-02, -7.7962e-04, -2.2040e-04, -7.9007e-04, -5.4691e-04,
         -1.4880e-02, -9.2166e-03, -1.1032e-01, -1.2944e+00, -7.8678e-04,
         -1.4609e-04, -3.3668e-05, -7.9327e-04, -1.2897e+00, -1.2879e+00,
         -3.7474e-04, -1.2861e+00, -9.7262e-03, -5.3746e-01, -3.8536e-03,
         -1.0548e-02, -2.4508e-02],
        [ 3.9237e+00, -6.2937e-02,  8.2976e-01, -8.9553e-02,  1.8773e-01,
          2.5280e+00,  4.4063e+00, -5.1176e-01,  2.7121e+00,  1.5038e-01,
          2.1898e+00, -6.3975e+00, -1.0291e-01,  9.8757e-01,  1.1535e+00,
          5.7770e-02,  9.4780e-01,  2.9512e+00,  2.3504e+00,  1.6411e+00,
          3.1498e+00,  1.2727e-01],
        [-1.4494e-02, -1.9430e-04, -1.7724e-04, -2.0127e-04, -2.0117e-04,
         -1.5493e-02, -8.1680e-03, -1.3258e-01, -1.3345e+00, -2.0053e-04,
         -1.8098e-04, -1.8463e-05, -1.9899e-04, -1.3303e+00, -1.3262e+00,
         -2.7675e-04, -1.3255e+00, -6.2074e-03, -5.8710e-01, -4.1919e-03,
         -7.5895e-03, -2.9301e-02],
        [-2.1892e-02, -3.5780e-04, -4.8405e-04, -3.6317e-04, -3.6356e-04,
         -2.3657e-02, -1.6951e-02, -9.6588e-02, -1.1849e+00, -3.5150e-04,
         -4.0838e-04, -1.7243e-05, -3.6464e-04, -1.1843e+00, -1.1795e+00,
         -3.3804e-04, -1.1790e+00, -7.4055e-03, -5.7283e-01, -5.4422e-03,
         -1.0076e-02, -3.1398e-02],
        [-2.3028e+00, -2.1890e-02, -8.3502e-03, -5.3786e-02,  9.5685e-02,
         -8.9290e-01, -1.4767e+01,  7.5055e+00,  3.0752e+00,  1.1812e-01,
         -7.0438e-02,  2.1906e-03, -5.7019e-02, -7.6423e-01, -1.3833e+00,
         -7.3209e-03, -7.3795e-01, -2.2229e+00,  1.8670e+00, -1.4910e+01,
         -1.6032e+00,  1.4609e+00],
        [ 2.4319e+00,  1.1747e-01, -1.6596e-01,  8.9778e-02,  3.1240e-01,
         -1.2941e+00, -9.2455e-01, -5.3120e-01,  5.2163e+00,  3.3676e-01,
         -2.0670e-01,  2.2187e+01,  7.3275e-02,  3.7788e-01,  7.5700e-01,
         -1.2275e-01,  4.8364e-01, -2.5823e+00,  1.5965e+00, -2.2668e+00,
         -6.5383e-01, -2.8611e+00],
        [-2.1115e-02, -3.0744e-04, -1.4460e-04, -2.9289e-04, -3.5131e-04,
         -2.2539e-02, -1.0971e-02, -1.5511e-01, -1.5086e+00, -2.8377e-04,
         -1.2594e-04,  2.8039e-05, -3.0274e-04, -1.5044e+00, -1.4994e+00,
         -3.7557e-04, -1.4986e+00, -6.5951e-03, -6.8458e-01, -3.5928e-03,
         -7.8039e-03, -3.0722e-02],
        [-1.4210e-02,  2.7210e-04, -1.6876e-04,  2.6752e-04,  2.9104e-04,
         -2.2712e-02, -5.7647e-03, -1.5704e-01, -1.4740e+00,  2.7486e-04,
         -1.6774e-04, -4.4364e-05,  2.6776e-04, -1.4699e+00, -1.4648e+00,
         -1.4749e-04, -1.4640e+00, -5.0059e-03, -6.6920e-01, -3.9010e-03,
         -5.3125e-03, -3.3932e-02]], device='cuda:0'))])
loaded xi:  855.6613
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857
 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857
 0.07142857 0.07142857]
W_T_mean: 8576.841924009083
W_T_median: 5042.380921625826
W_T_pctile_5: 103.64169553244135
W_T_CVAR_5_pct: -371.9331258181762
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -2551.637676649728
Current xi:  [869.6523]
objective value function right now is: -2551.637676649728
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -2561.977866071771
Current xi:  [883.8763]
objective value function right now is: -2561.977866071771
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -2573.541811256448
Current xi:  [897.8343]
objective value function right now is: -2573.541811256448
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -2579.158065195567
Current xi:  [911.906]
objective value function right now is: -2579.158065195567
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -2584.9909623344224
Current xi:  [926.1244]
objective value function right now is: -2584.9909623344224
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [939.2034]
objective value function right now is: -2572.908371234482
14.000000000000002% of gradient descent iterations done. Method = Adam
new min fval:  -2590.065936337822
Current xi:  [953.39496]
objective value function right now is: -2590.065936337822
16.0% of gradient descent iterations done. Method = Adam
new min fval:  -2597.337237277948
Current xi:  [967.0776]
objective value function right now is: -2597.337237277948
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -2598.3617109627353
Current xi:  [979.90607]
objective value function right now is: -2598.3617109627353
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [993.37054]
objective value function right now is: -2585.4235795609698
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -2617.383286914084
Current xi:  [1006.5754]
objective value function right now is: -2617.383286914084
24.0% of gradient descent iterations done. Method = Adam
new min fval:  -2627.2163282921324
Current xi:  [1019.803]
objective value function right now is: -2627.2163282921324
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [1033.1466]
objective value function right now is: -2625.188438511505
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [1045.1708]
objective value function right now is: -2623.412813228612
30.0% of gradient descent iterations done. Method = Adam
new min fval:  -2649.037779170098
Current xi:  [1057.8463]
objective value function right now is: -2649.037779170098
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [1070.436]
objective value function right now is: -2632.4690558941866
34.0% of gradient descent iterations done. Method = Adam
new min fval:  -2664.021019872378
Current xi:  [1083.2404]
objective value function right now is: -2664.021019872378
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [1095.441]
objective value function right now is: -2646.71801573034
38.0% of gradient descent iterations done. Method = Adam
new min fval:  -2664.7968715645575
Current xi:  [1106.6578]
objective value function right now is: -2664.7968715645575
40.0% of gradient descent iterations done. Method = Adam
new min fval:  -2669.797342580879
Current xi:  [1118.3175]
objective value function right now is: -2669.797342580879
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [1130.3835]
objective value function right now is: -2663.0368427365065
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [1141.8806]
objective value function right now is: -2667.065743709673
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [1153.0554]
objective value function right now is: -2655.4733923842564
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [1163.6482]
objective value function right now is: -2661.151979729527
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [1174.3098]
objective value function right now is: -2641.314106520411
52.0% of gradient descent iterations done. Method = Adam
new min fval:  -2685.3343653775037
Current xi:  [1184.1663]
objective value function right now is: -2685.3343653775037
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [1194.3352]
objective value function right now is: -2684.3610769020247
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [1203.6136]
objective value function right now is: -2682.4398701534114
57.99999999999999% of gradient descent iterations done. Method = Adam
new min fval:  -2696.934058511935
Current xi:  [1212.8207]
objective value function right now is: -2696.934058511935
60.0% of gradient descent iterations done. Method = Adam
new min fval:  -2702.7918921106407
Current xi:  [1221.9556]
objective value function right now is: -2702.7918921106407
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [1230.4122]
objective value function right now is: -2675.496688979189
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [1239.1682]
objective value function right now is: -2675.4334758798336
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [1247.9194]
objective value function right now is: -2669.9774633843163
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [1255.8707]
objective value function right now is: -2698.0630869718093
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [1263.1115]
objective value function right now is: -2699.7263931940893
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -2717.0811870889356
Current xi:  [1264.6798]
objective value function right now is: -2717.0811870889356
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -2717.7043266041082
Current xi:  [1266.3743]
objective value function right now is: -2717.7043266041082
76.0% of gradient descent iterations done. Method = Adam
new min fval:  -2719.414222287133
Current xi:  [1268.2383]
objective value function right now is: -2719.414222287133
78.0% of gradient descent iterations done. Method = Adam
new min fval:  -2720.618842165006
Current xi:  [1270.1477]
objective value function right now is: -2720.618842165006
80.0% of gradient descent iterations done. Method = Adam
new min fval:  -2721.1374864518316
Current xi:  [1271.9244]
objective value function right now is: -2721.1374864518316
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [1273.7206]
objective value function right now is: -2719.203894810133
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [1275.497]
objective value function right now is: -2714.2192980260033
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [1277.199]
objective value function right now is: -2721.1022594528145
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [1278.6854]
objective value function right now is: -2720.6925599167203
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [1280.3969]
objective value function right now is: -2717.8914087383814
new min fval from sgd:  -2721.557235066466
new min fval from sgd:  -2721.5850554552694
new min fval from sgd:  -2721.6502471936437
new min fval from sgd:  -2721.6672153101795
new min fval from sgd:  -2722.100888872967
new min fval from sgd:  -2722.25949168568
new min fval from sgd:  -2722.4480131063146
new min fval from sgd:  -2722.5144315803695
new min fval from sgd:  -2722.540508728495
new min fval from sgd:  -2722.603536248114
new min fval from sgd:  -2722.6467125633676
new min fval from sgd:  -2722.891798877474
new min fval from sgd:  -2722.9459035958644
new min fval from sgd:  -2723.3480037735385
new min fval from sgd:  -2723.8966054242264
new min fval from sgd:  -2724.129483023834
new min fval from sgd:  -2724.6995720269774
new min fval from sgd:  -2724.99021988983
new min fval from sgd:  -2725.0965802903074
new min fval from sgd:  -2725.104093931897
new min fval from sgd:  -2725.3071128520037
new min fval from sgd:  -2725.542970501739
new min fval from sgd:  -2725.5990518750345
new min fval from sgd:  -2725.63442913033
new min fval from sgd:  -2725.7309911825178
new min fval from sgd:  -2725.8517340635717
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [1281.9921]
objective value function right now is: -2725.345357973766
new min fval from sgd:  -2725.978919952413
new min fval from sgd:  -2726.1216909750337
new min fval from sgd:  -2726.1715354765106
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [1283.9113]
objective value function right now is: -2723.040652938795
new min fval from sgd:  -2726.324603171371
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [1285.7131]
objective value function right now is: -2721.115972473629
new min fval from sgd:  -2726.3461161049313
new min fval from sgd:  -2726.383105600616
new min fval from sgd:  -2726.391473983137
new min fval from sgd:  -2726.4198680443
new min fval from sgd:  -2726.451031856542
new min fval from sgd:  -2726.5369253842823
new min fval from sgd:  -2726.6077868580446
new min fval from sgd:  -2726.686428638574
new min fval from sgd:  -2726.7381364224016
new min fval from sgd:  -2726.794444925366
new min fval from sgd:  -2726.841169074387
new min fval from sgd:  -2726.8757580744114
new min fval from sgd:  -2726.9090862157645
new min fval from sgd:  -2726.9267420324486
new min fval from sgd:  -2726.9473005357377
new min fval from sgd:  -2726.952948945181
new min fval from sgd:  -2726.960782838977
new min fval from sgd:  -2726.9738635207946
new min fval from sgd:  -2726.9752788309743
new min fval from sgd:  -2726.9758756868846
new min fval from sgd:  -2726.976121082967
new min fval from sgd:  -2726.9797348115276
new min fval from sgd:  -2726.98179870338
new min fval from sgd:  -2726.982413880107
new min fval from sgd:  -2726.9929768374136
new min fval from sgd:  -2726.996330019103
new min fval from sgd:  -2726.9974539232685
new min fval from sgd:  -2727.0022285717937
new min fval from sgd:  -2727.021678107911
new min fval from sgd:  -2727.0283832003365
new min fval from sgd:  -2727.0472156364854
new min fval from sgd:  -2727.0993429575547
new min fval from sgd:  -2727.1227310087315
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [1286.7904]
objective value function right now is: -2727.1195578738657
new min fval from sgd:  -2727.1325283701876
new min fval from sgd:  -2727.148311933485
new min fval from sgd:  -2727.1585779097773
new min fval from sgd:  -2727.1644153138063
new min fval from sgd:  -2727.172277357082
new min fval from sgd:  -2727.1842592380012
new min fval from sgd:  -2727.19614483946
new min fval from sgd:  -2727.2689298002033
new min fval from sgd:  -2727.346288147715
new min fval from sgd:  -2727.392890531232
new min fval from sgd:  -2727.443722140676
new min fval from sgd:  -2727.479116426451
new min fval from sgd:  -2727.502998045364
new min fval from sgd:  -2727.509603418767
new min fval from sgd:  -2727.5133636934675
new min fval from sgd:  -2727.5295642820497
new min fval from sgd:  -2727.5568147731697
new min fval from sgd:  -2727.5910071159374
new min fval from sgd:  -2727.619759107865
new min fval from sgd:  -2727.662760605076
new min fval from sgd:  -2727.7164582144987
new min fval from sgd:  -2727.754549312135
new min fval from sgd:  -2727.785907316698
new min fval from sgd:  -2727.8047920137124
new min fval from sgd:  -2727.8058528592737
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [1287.1857]
objective value function right now is: -2727.2981344216205
min fval:  -2727.8058528592737
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-11.3075,   5.7584],
        [ -5.3850, -11.1565],
        [ -1.5275,   1.2168],
        [  9.4352,   3.7750],
        [-11.2196,  -8.3964],
        [ -1.6216,   1.2396],
        [  6.9404,   5.4004],
        [ 11.9737,   0.7496],
        [-11.0376,   5.5794],
        [-12.3584,   6.3712],
        [-11.2570,   6.1051],
        [-12.1346,   5.9956],
        [  9.3919,   3.0402],
        [ -1.5271,   1.2167],
        [ -1.5268,   1.2166],
        [  6.1060,   5.2814],
        [-12.1662,  -9.6327],
        [  9.0219,   4.1986],
        [-12.2955,   6.1015],
        [-11.9760,   5.9589],
        [ -1.5271,   1.2167],
        [-16.4370,  -7.2688]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([  5.0587,  -6.5686,  -3.9321, -12.2385,  -4.3352,  -3.8581, -11.1544,
        -11.2347,   4.6115,   1.5993,   5.2086,   0.0928, -11.6071,  -3.9324,
         -3.9325, -10.8817,  -4.9023, -12.1530,   0.4394,   0.8325,  -3.9324,
         -5.6412], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-1.2863e-01, -1.4135e-01, -1.4342e-02,  1.3814e-01, -6.6872e-02,
         -1.4553e-02,  1.6885e-01,  8.6312e-02, -9.7193e-02, -4.0620e-02,
         -1.2052e-01, -6.9099e-02,  1.2169e-01, -1.4339e-02, -1.4338e-02,
          1.4232e-01, -7.2917e-02,  1.4822e-01, -7.6563e-02, -7.1883e-02,
         -1.4339e-02,  6.6535e-02],
        [-1.0291e+01,  1.5523e+01, -5.9634e-02,  6.8267e+00,  5.7849e+00,
          6.1043e-02,  3.3240e+00,  8.3437e+00, -8.5401e+00, -3.8716e+00,
         -1.0977e+01, -2.2584e+00,  5.4753e+00, -5.9621e-02, -5.9668e-02,
          3.1310e+00,  1.0126e+01,  7.5527e+00, -2.6779e+00, -3.6855e+00,
         -5.9621e-02,  7.4842e+00],
        [-1.2863e-01, -1.4135e-01, -1.4342e-02,  1.3814e-01, -6.6873e-02,
         -1.4553e-02,  1.6885e-01,  8.6312e-02, -9.7193e-02, -4.0620e-02,
         -1.2052e-01, -6.9099e-02,  1.2169e-01, -1.4339e-02, -1.4338e-02,
          1.4232e-01, -7.2918e-02,  1.4822e-01, -7.6563e-02, -7.1883e-02,
         -1.4339e-02,  6.6535e-02],
        [-1.1009e+01,  1.6617e+01, -2.8168e-02,  9.1472e+00,  6.8995e+00,
         -1.0102e-01,  4.9525e+00,  9.2451e+00, -9.7482e+00, -4.7922e+00,
         -1.2189e+01, -3.5518e+00,  6.1761e+00, -2.6764e-02, -2.5664e-02,
          1.9792e+00,  1.1064e+01,  7.7005e+00, -3.9957e+00, -5.0853e+00,
         -2.6738e-02,  8.7763e+00],
        [-8.9791e+00,  1.3130e+01,  7.7393e-02,  4.6398e+00,  5.7528e+00,
          1.7714e-01,  1.2112e+00,  8.7887e+00, -7.6383e+00, -4.2834e+00,
         -9.7383e+00, -1.5760e+00,  5.5454e+00,  7.6854e-02,  7.6526e-02,
          2.5422e+00,  9.0775e+00,  9.2967e+00, -2.1935e+00, -2.8675e+00,
          7.6845e-02,  6.8467e+00],
        [-6.5156e+00,  9.0339e+00,  1.5414e-02,  3.5593e+00,  4.2839e+00,
          1.6638e-02,  2.2705e+00,  4.8664e+00, -4.7680e+00,  4.6150e-02,
         -7.9440e+00,  4.2225e-01,  3.5622e+00,  1.5330e-02,  1.5271e-02,
          2.1262e+00,  6.6870e+00,  4.7030e+00,  4.2353e-01,  4.0473e-01,
          1.5329e-02,  3.7159e+00],
        [-1.2863e-01, -1.4135e-01, -1.4341e-02,  1.3814e-01, -6.6873e-02,
         -1.4553e-02,  1.6885e-01,  8.6311e-02, -9.7194e-02, -4.0621e-02,
         -1.2052e-01, -6.9099e-02,  1.2169e-01, -1.4339e-02, -1.4338e-02,
          1.4232e-01, -7.2918e-02,  1.4822e-01, -7.6563e-02, -7.1883e-02,
         -1.4339e-02,  6.6535e-02],
        [-1.2863e-01, -1.4135e-01, -1.4342e-02,  1.3815e-01, -6.6872e-02,
         -1.4553e-02,  1.6885e-01,  8.6315e-02, -9.7191e-02, -4.0619e-02,
         -1.2052e-01, -6.9099e-02,  1.2169e-01, -1.4340e-02, -1.4338e-02,
          1.4233e-01, -7.2917e-02,  1.4822e-01, -7.6563e-02, -7.1882e-02,
         -1.4340e-02,  6.6536e-02],
        [-1.2863e-01, -1.4135e-01, -1.4342e-02,  1.3814e-01, -6.6872e-02,
         -1.4553e-02,  1.6885e-01,  8.6313e-02, -9.7193e-02, -4.0620e-02,
         -1.2052e-01, -6.9099e-02,  1.2169e-01, -1.4340e-02, -1.4338e-02,
          1.4232e-01, -7.2917e-02,  1.4822e-01, -7.6563e-02, -7.1883e-02,
         -1.4339e-02,  6.6535e-02],
        [-1.2863e-01, -1.4135e-01, -1.4342e-02,  1.3814e-01, -6.6872e-02,
         -1.4553e-02,  1.6885e-01,  8.6313e-02, -9.7193e-02, -4.0620e-02,
         -1.2052e-01, -6.9099e-02,  1.2169e-01, -1.4339e-02, -1.4338e-02,
          1.4232e-01, -7.2917e-02,  1.4822e-01, -7.6563e-02, -7.1883e-02,
         -1.4339e-02,  6.6535e-02],
        [-6.3248e+00,  8.1090e+00, -4.1264e-02,  2.6697e-01,  4.0797e+00,
         -3.2800e-02,  2.4675e-01,  1.0081e+00, -5.0534e+00,  3.1827e-02,
         -7.7711e+00,  4.5661e-02,  2.6336e-01, -4.1315e-02, -4.1345e-02,
          1.8129e-01,  6.4074e+00,  2.6600e-01,  6.2736e-02,  8.6816e-02,
         -4.1316e-02,  3.3289e+00],
        [ 9.6682e+00, -1.3868e+01,  1.2162e-02, -8.6575e+00, -6.5646e+00,
          1.0270e-01, -3.2295e+00, -8.3116e+00,  8.2736e+00,  5.9696e+00,
          1.1236e+01,  3.6092e+00, -5.3008e+00,  1.3366e-02,  1.4342e-02,
         -1.0964e+00, -9.8648e+00, -8.8819e+00,  4.1816e+00,  4.5935e+00,
          1.3389e-02, -8.2320e+00],
        [-1.2863e-01, -1.4135e-01, -1.4342e-02,  1.3814e-01, -6.6872e-02,
         -1.4553e-02,  1.6885e-01,  8.6313e-02, -9.7193e-02, -4.0620e-02,
         -1.2052e-01, -6.9099e-02,  1.2169e-01, -1.4339e-02, -1.4338e-02,
          1.4232e-01, -7.2917e-02,  1.4822e-01, -7.6563e-02, -7.1883e-02,
         -1.4339e-02,  6.6535e-02],
        [-1.2863e-01, -1.4135e-01, -1.4341e-02,  1.3814e-01, -6.6873e-02,
         -1.4553e-02,  1.6885e-01,  8.6310e-02, -9.7195e-02, -4.0621e-02,
         -1.2053e-01, -6.9099e-02,  1.2169e-01, -1.4339e-02, -1.4338e-02,
          1.4232e-01, -7.2918e-02,  1.4822e-01, -7.6564e-02, -7.1884e-02,
         -1.4339e-02,  6.6535e-02],
        [ 6.3817e-01,  2.6577e-01,  3.9200e-02,  5.9728e-02,  2.6836e-01,
          3.8592e-02,  1.2092e-01, -1.1948e-01,  5.6213e-01,  2.4492e-02,
          6.3285e-01, -2.5682e-02,  1.8400e-02,  3.9200e-02,  3.9200e-02,
          1.2066e-01,  2.6444e-01,  7.9009e-02, -2.6544e-02, -1.3355e-02,
          3.9200e-02,  6.4212e-02],
        [-1.2863e-01, -1.4135e-01, -1.4342e-02,  1.3814e-01, -6.6873e-02,
         -1.4553e-02,  1.6885e-01,  8.6312e-02, -9.7194e-02, -4.0620e-02,
         -1.2052e-01, -6.9099e-02,  1.2169e-01, -1.4339e-02, -1.4338e-02,
          1.4232e-01, -7.2918e-02,  1.4822e-01, -7.6563e-02, -7.1883e-02,
         -1.4339e-02,  6.6535e-02],
        [-7.3494e+00,  1.0983e+01,  1.2614e-01,  4.2822e+00,  4.9126e+00,
          1.4904e-01,  2.2446e+00,  7.0336e+00, -5.9891e+00, -1.6586e+00,
         -8.9258e+00, -3.2544e-01,  4.4368e+00,  1.2588e-01,  1.2571e-01,
          2.1579e+00,  7.9545e+00,  6.2967e+00, -5.7791e-01, -9.7727e-01,
          1.2587e-01,  5.2953e+00],
        [-1.2863e-01, -1.4135e-01, -1.4342e-02,  1.3814e-01, -6.6873e-02,
         -1.4553e-02,  1.6885e-01,  8.6312e-02, -9.7193e-02, -4.0620e-02,
         -1.2052e-01, -6.9099e-02,  1.2169e-01, -1.4339e-02, -1.4338e-02,
          1.4232e-01, -7.2918e-02,  1.4822e-01, -7.6563e-02, -7.1883e-02,
         -1.4339e-02,  6.6535e-02],
        [-1.2863e-01, -1.4135e-01, -1.4342e-02,  1.3814e-01, -6.6872e-02,
         -1.4553e-02,  1.6885e-01,  8.6314e-02, -9.7192e-02, -4.0619e-02,
         -1.2052e-01, -6.9099e-02,  1.2169e-01, -1.4340e-02, -1.4338e-02,
          1.4232e-01, -7.2917e-02,  1.4822e-01, -7.6563e-02, -7.1883e-02,
         -1.4339e-02,  6.6536e-02],
        [-1.2863e-01, -1.4135e-01, -1.4342e-02,  1.3814e-01, -6.6873e-02,
         -1.4553e-02,  1.6885e-01,  8.6312e-02, -9.7194e-02, -4.0620e-02,
         -1.2052e-01, -6.9099e-02,  1.2169e-01, -1.4339e-02, -1.4338e-02,
          1.4232e-01, -7.2918e-02,  1.4822e-01, -7.6563e-02, -7.1883e-02,
         -1.4339e-02,  6.6535e-02],
        [ 6.4151e-01,  2.6718e-01,  3.9340e-02,  5.9116e-02,  2.6945e-01,
          3.8726e-02,  1.2043e-01, -1.1967e-01,  5.6474e-01,  2.4736e-02,
          6.3639e-01, -2.5715e-02,  1.7664e-02,  3.9339e-02,  3.9339e-02,
          1.2043e-01,  2.6551e-01,  7.8433e-02, -2.6556e-02, -1.3286e-02,
          3.9339e-02,  6.3890e-02],
        [-1.2863e-01, -1.4135e-01, -1.4342e-02,  1.3814e-01, -6.6873e-02,
         -1.4553e-02,  1.6885e-01,  8.6312e-02, -9.7194e-02, -4.0620e-02,
         -1.2052e-01, -6.9099e-02,  1.2169e-01, -1.4339e-02, -1.4338e-02,
          1.4232e-01, -7.2918e-02,  1.4822e-01, -7.6563e-02, -7.1883e-02,
         -1.4339e-02,  6.6535e-02]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-2.6553,  0.4773, -2.6553,  0.6652,  0.0920, -1.5507, -2.6553, -2.6553,
        -2.6553, -2.6553, -1.5831, -0.7007, -2.6553, -2.6553,  4.6479, -2.6553,
        -0.8902, -2.6553, -2.6553, -2.6553,  4.7212, -2.6553], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[  0.0753, -14.4434,   0.0753, -21.5358, -11.3286,  -4.8393,   0.0753,
           0.0753,   0.0753,   0.0753,  -4.8575,  19.0031,   0.0753,   0.0753,
           5.3349,   0.0753,  -7.0455,   0.0753,   0.0753,   0.0753,   5.7920,
           0.0753]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 12.2998,   2.2542],
        [  0.6210,  13.2236],
        [ 21.5594,   1.6072],
        [ 13.4861,  -0.2108],
        [ -2.2890,   0.5833],
        [ -1.3749,   1.3675],
        [ -1.3556,   1.2983],
        [ -1.7609,   0.5580],
        [ -1.5318,   1.7875],
        [  9.6497,   0.2131],
        [ -1.4540,   1.1541],
        [ -1.7751,   0.5527],
        [-13.4789,  -1.0778],
        [ -9.9749,   6.3061],
        [ -9.4554,  11.1685],
        [ -1.4397,   1.1520],
        [ -1.3936,   1.2768],
        [-14.0657,  -3.6137],
        [-12.0088,  -4.8072],
        [  4.1985,  13.6311],
        [ 11.3349,   5.2113],
        [ 13.5681,  12.6959]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ -9.6048,   8.2656,   2.9985, -11.8676,  -5.1462,  -4.9837,  -5.0062,
         -5.2312,  -6.0581, -12.2078,  -5.0957,  -5.2153,   6.5733,   2.4496,
          6.8505,  -5.1083,  -4.9825,   3.4461,  -2.4185,   8.5266,  -5.8797,
          7.1281], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 6.3719e-01,  3.0747e-02, -2.4084e+00,  5.6348e-02, -1.6692e-01,
         -1.0077e+00, -9.1484e-01, -4.0080e-02, -2.6561e+00,  1.5673e+00,
         -7.1339e-01, -3.5499e-02, -2.7001e+00,  1.4596e+00,  1.9823e+00,
         -7.1968e-01, -8.5934e-01, -8.5319e-01,  7.9029e-01,  9.3554e-01,
          3.2187e-01, -8.5437e-01],
        [-8.7538e-01, -4.7923e-01, -2.4786e+00, -1.6734e+00, -3.7491e-02,
         -5.2534e-01, -3.8780e-01, -3.2944e-02, -1.0570e+00, -2.1446e-01,
         -2.0842e-01, -3.3527e-02, -1.6699e+00,  3.2240e-01,  1.6776e-01,
         -2.0719e-01, -3.5220e-01, -1.3342e+00, -1.6348e-01,  9.5734e-01,
         -6.2464e-01, -9.7473e-01],
        [-8.8475e-01, -4.7765e-01, -2.4791e+00, -1.6761e+00, -3.7737e-02,
         -5.1644e-01, -3.8063e-01, -3.3353e-02, -1.0313e+00, -2.1239e-01,
         -2.0503e-01, -3.3937e-02, -1.6672e+00,  2.9960e-01,  1.4546e-01,
         -2.0383e-01, -3.4578e-01, -1.3360e+00, -1.7739e-01,  9.5831e-01,
         -6.2668e-01, -9.7760e-01],
        [-8.7500e-01, -4.7930e-01, -2.4786e+00, -1.6733e+00, -3.7476e-02,
         -5.2564e-01, -3.8804e-01, -3.2926e-02, -1.0579e+00, -2.1452e-01,
         -2.0853e-01, -3.3509e-02, -1.6700e+00,  3.2322e-01,  1.6860e-01,
         -2.0731e-01, -3.5241e-01, -1.3340e+00, -1.6296e-01,  9.5724e-01,
         -6.2455e-01, -9.7465e-01],
        [-8.7585e-01, -4.7913e-01, -2.4786e+00, -1.6735e+00, -3.7510e-02,
         -5.2496e-01, -3.8749e-01, -3.2968e-02, -1.0558e+00, -2.1438e-01,
         -2.0827e-01, -3.3551e-02, -1.6698e+00,  3.2136e-01,  1.6669e-01,
         -2.0705e-01, -3.5192e-01, -1.3343e+00, -1.6415e-01,  9.5745e-01,
         -6.2476e-01, -9.7482e-01],
        [ 1.9061e-01, -2.8273e-01, -2.6694e+00, -5.7115e-01, -1.2089e-01,
         -9.3400e-01, -8.3497e-01, -6.9654e-02, -2.3982e+00,  8.8577e-01,
         -6.3617e-01, -7.1604e-02, -2.0110e+00,  9.6001e-01,  1.5167e+00,
         -6.3931e-01, -7.8295e-01, -7.5731e-01,  7.7681e-01,  6.5611e-01,
         -1.6548e-02, -1.1335e+00],
        [-1.2614e+00, -1.3145e+01, -8.9565e-02, -6.4475e+00,  9.9509e-01,
          1.3322e-01,  1.4055e-01,  1.6215e-01,  3.0466e-02,  2.1150e-02,
          1.4790e-01,  1.6380e-01,  5.4586e+00,  9.1886e-01, -6.5030e+00,
          1.5111e-01,  1.2254e-01,  3.9638e+00,  3.5108e+00, -1.2582e+01,
          1.0562e+00, -5.5188e+00],
        [-3.4509e+00,  5.3581e+00, -4.4108e+00, -5.6472e+00,  2.5918e-01,
          4.6045e-01,  4.1009e-01,  4.7803e-03, -1.8153e-01,  2.3972e+00,
          3.7204e-01, -2.3219e-02,  1.8080e+00,  8.7944e+00,  6.4059e+00,
          3.7323e-01,  3.8867e-01,  3.8710e+00,  4.4368e-01,  4.8403e+00,
         -2.2478e+00,  1.7462e+00],
        [ 5.9527e+00,  1.9731e+01,  3.8954e+00,  1.0694e+01, -2.4572e-01,
         -3.5962e-02, -2.8655e-02, -3.1515e-02,  5.6449e-02,  1.2530e+00,
         -4.5428e-02, -3.1315e-02, -1.0596e+01, -1.4305e-01,  1.0870e+01,
         -3.5694e-02, -4.2869e-02, -9.9871e+00, -6.4568e+00,  2.2321e+01,
          4.8173e+00,  1.8655e+01],
        [-8.7466e-01, -4.7938e-01, -2.4786e+00, -1.6732e+00, -3.7461e-02,
         -5.2590e-01, -3.8825e-01, -3.2908e-02, -1.0586e+00, -2.1457e-01,
         -2.0862e-01, -3.3491e-02, -1.6701e+00,  3.2392e-01,  1.6936e-01,
         -2.0740e-01, -3.5259e-01, -1.3339e+00, -1.6248e-01,  9.5714e-01,
         -6.2446e-01, -9.7460e-01],
        [-1.4096e+00,  1.3149e+00, -1.8101e+00,  4.8459e-01,  1.5779e-01,
         -1.1418e-01, -4.9624e-03,  1.9303e-01, -2.6675e-01,  3.5025e-01,
          8.9552e-02,  1.9373e-01, -1.1594e+00, -8.2783e-01, -2.5014e+00,
          9.0193e-02,  1.5796e-02, -1.7498e+00, -9.5594e-01,  1.7844e+00,
         -2.5176e+00, -2.6237e+00],
        [-9.4922e-01, -2.0550e+01, -1.1008e+01, -7.7061e+00,  1.7275e-01,
          1.8355e-01,  1.8480e-01,  1.4822e-01,  9.6235e-02, -1.9745e-01,
          1.7794e-01,  1.4607e-01,  8.4421e+00,  1.4037e+00, -5.4791e+00,
          1.7873e-01,  1.7900e-01,  8.5309e+00,  7.3694e+00, -2.7966e+01,
         -4.5584e-01, -2.6620e+01],
        [-8.7490e-01, -4.7932e-01, -2.4786e+00, -1.6733e+00, -3.7472e-02,
         -5.2573e-01, -3.8811e-01, -3.2921e-02, -1.0581e+00, -2.1454e-01,
         -2.0856e-01, -3.3504e-02, -1.6700e+00,  3.2344e-01,  1.6884e-01,
         -2.0734e-01, -3.5247e-01, -1.3340e+00, -1.6281e-01,  9.5721e-01,
         -6.2452e-01, -9.7463e-01],
        [-1.4335e+00,  4.5296e-01,  3.4310e+00, -4.1370e+00, -3.4741e-02,
         -3.1579e-02,  3.8651e-02, -4.5979e-02,  1.5633e-01, -6.0991e-01,
          3.0372e-02, -5.3115e-02,  9.4271e+00,  1.0700e+00,  5.1831e+00,
          3.5254e-02,  2.9214e-02,  4.5583e+00,  7.0109e-01,  2.3498e+00,
         -1.2918e+00, -1.0575e+00],
        [ 2.8454e+00, -7.6421e-01,  3.3981e+00,  3.4117e+00, -1.9297e+00,
         -1.3495e-01, -1.1404e-01, -2.2515e-01,  1.4889e+00,  4.6226e-01,
         -1.4987e-01, -2.3852e-01,  2.3870e-01, -5.4206e+00, -6.6933e+00,
         -1.4939e-01, -8.5931e-02, -1.5552e+00, -2.8390e+00, -2.2782e+00,
          1.0777e+01, -2.4713e+00],
        [ 2.9497e-01, -2.1688e-01, -2.5994e+00, -4.1434e-01, -1.7371e-01,
         -9.5999e-01, -8.6514e-01, -9.7574e-02, -2.4851e+00,  1.0744e+00,
         -6.7689e-01, -9.8817e-02, -2.1677e+00,  1.0411e+00,  1.6134e+00,
         -6.8126e-01, -8.1315e-01, -7.9940e-01,  7.8563e-01,  7.2023e-01,
          6.5845e-02, -1.0642e+00],
        [ 4.0489e-01, -1.5562e-01,  3.4089e+00,  1.7550e+00, -6.2972e-02,
          7.8936e-02,  5.7974e-02, -6.0152e-02,  1.1018e-01,  1.3755e-01,
          1.2344e-02, -6.1150e-02, -4.5464e-01,  1.3717e-01,  5.6075e-02,
          1.2195e-02,  4.8741e-02, -1.1573e+00, -6.9698e-01,  4.4222e-01,
          2.6037e-01,  1.7807e+00],
        [-3.4367e+00, -7.3090e+00, -4.7801e-01, -4.7668e+00, -1.9078e-02,
         -7.1734e-02, -6.0710e-02, -1.3421e-02, -2.3506e-02, -3.7307e+00,
         -3.5474e-02, -1.7506e-02, -2.5349e+00, -5.4518e-02, -5.4737e-02,
         -3.7041e-02, -4.7102e-02, -6.7630e-01, -4.3855e-01, -1.4206e+01,
         -2.8593e+00,  4.6112e-01],
        [-1.3858e+00, -6.0814e+00,  2.4572e+00, -8.9025e+00, -2.6684e-02,
         -1.4134e-01, -8.1209e-02, -1.1317e-02,  9.8402e-04, -6.2123e+00,
         -4.4388e-02, -9.4358e-03, -2.0355e+00,  1.6820e-01,  4.3594e+00,
         -4.6300e-02, -1.0718e-01,  2.9697e+00,  6.1244e+00, -1.4313e+00,
          2.7715e-01, -1.7031e+00],
        [-5.0512e+00, -1.5700e+01, -1.8082e+00, -3.7707e+00,  1.4209e-01,
         -4.1183e-02, -4.5987e-02, -5.4210e-02, -5.8737e-02,  2.5532e+00,
         -5.2863e-02, -5.6612e-02,  4.7896e+00,  4.9466e+00, -2.0759e+00,
         -4.9042e-02, -4.9436e-02,  4.6389e+00,  7.2250e+00, -1.7815e+01,
         -3.2271e+00, -4.1681e+00],
        [-5.8634e-01, -4.9749e-01, -2.3274e+00, -1.4418e+00, -2.9829e-02,
         -8.1863e-01, -6.5945e-01, -1.5114e-02, -1.8822e+00, -9.5703e-02,
         -3.9296e-01, -1.5026e-02, -1.8310e+00,  1.0260e+00,  7.4061e-01,
         -3.9205e-01, -6.0317e-01, -1.4045e+00,  2.2845e-01,  1.0360e+00,
         -5.5068e-01, -8.8345e-01],
        [-3.0833e+00,  5.0814e+00, -4.6103e+00, -1.0345e+01, -5.2489e-01,
         -1.2524e-01, -2.0171e-01, -3.7643e-02, -3.0929e-01, -1.6658e+00,
         -1.8821e-01, -4.8371e-02,  1.6550e+00,  6.7207e+00,  9.6045e+00,
         -1.8183e-01, -1.9079e-01,  2.2398e+00, -1.6733e+00,  2.9029e+00,
         -7.5250e+00,  1.6299e-01]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-2.4240, -2.4904, -2.4905, -2.4904, -2.4903, -2.6942,  1.6793, -5.6938,
        -2.3416, -2.4905, -1.8313, -1.7521, -2.4905,  3.6966,  4.8516, -2.6507,
         3.4841, -1.1538,  2.8495, -0.7580, -2.4135, -4.9453], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-5.1838e-02, -7.5950e-04, -7.6174e-04, -7.5944e-04, -7.5957e-04,
         -2.7778e-03, -6.7942e-03, -5.0078e-01, -1.8057e+00, -7.5940e-04,
         -4.0997e-03,  1.5358e-05, -7.5942e-04, -1.7847e+00, -1.7904e+00,
         -6.3550e-03, -1.8057e+00, -4.4281e-04, -1.8773e-01, -5.4080e-04,
         -1.8106e-03, -7.4710e-02],
        [-2.4657e-02, -5.9110e-03, -5.8563e-03, -5.9116e-03, -5.9101e-03,
         -5.8135e-03,  1.5679e-03, -1.5889e-01, -9.1444e-01, -5.9116e-03,
         -7.4705e-03,  2.7356e-05, -5.9117e-03, -8.9962e-01, -9.1035e-01,
         -5.1214e-03, -9.1482e-01,  3.9341e-03, -1.9045e-01, -9.3757e-04,
         -9.2954e-03, -1.7278e-01],
        [-3.7524e-02, -9.3514e-04, -9.2686e-04, -9.3535e-04, -9.3486e-04,
         -2.0078e-03, -8.2605e-03, -4.3762e-01, -1.6725e+00, -9.3551e-04,
         -5.3052e-03,  3.9002e-05, -9.3540e-04, -1.6499e+00, -1.6585e+00,
         -4.7900e-03, -1.6725e+00, -1.0931e-03, -1.7359e-01, -6.0181e-04,
         -1.5211e-03, -7.5913e-02],
        [-4.0288e-02, -4.5964e-04, -4.5711e-04, -4.5953e-04, -4.5976e-04,
         -1.6203e-03, -7.6117e-03, -4.0730e-01, -1.5042e+00, -4.5936e-04,
         -4.4171e-03,  2.4799e-05, -4.5949e-04, -1.4861e+00, -1.4915e+00,
         -3.0032e-03, -1.5043e+00, -2.3038e-03, -1.4666e-01, -9.7577e-04,
         -1.2845e-03, -7.3318e-02],
        [-1.3835e-01,  3.5357e-01,  3.5763e-01,  3.5344e-01,  3.5376e-01,
         -8.5848e-02,  4.5372e+00,  1.4919e-02, -2.9067e+00,  3.5334e-01,
          2.2411e+00, -1.8219e+01,  3.5340e-01,  3.8044e+00,  3.2721e+00,
         -5.0258e-02,  3.6626e+00,  2.8565e+00,  2.1352e+00,  5.9004e+00,
          1.7555e-01,  2.1038e-02],
        [-3.2512e-02, -1.0146e-03, -9.9803e-04, -1.0147e-03, -1.0144e-03,
         -1.9580e-03, -1.3323e-03, -4.1781e-01, -1.2667e+00, -1.0146e-03,
         -6.3886e-03,  1.3240e-06, -1.0147e-03, -1.2539e+00, -1.2491e+00,
         -6.0199e-03, -1.2667e+00, -1.6519e-03, -1.0514e-01, -5.9888e-04,
         -1.9773e-03, -9.5828e-02],
        [-3.3407e-02, -1.4808e-03, -1.4735e-03, -1.4810e-03, -1.4805e-03,
         -1.3982e-03, -6.3885e-03, -3.4570e-01, -1.5187e+00, -1.4812e-03,
         -7.5659e-03, -1.0435e-05, -1.4810e-03, -1.4949e+00, -1.5078e+00,
         -3.6723e-03, -1.5188e+00, -3.1010e-03, -1.5632e-01, -4.9228e-04,
         -1.9546e-03, -5.8531e-02],
        [ 2.1257e+00,  1.0480e+00,  1.0348e+00,  1.0484e+00,  1.0474e+00,
          1.6922e+00,  4.4071e+00,  4.8047e-01,  2.9604e+00,  1.0488e+00,
         -1.0744e+00, -1.0441e+01,  1.0485e+00,  1.2285e+00,  1.3554e+00,
          1.8606e+00,  1.0294e+00,  4.1709e+00,  2.1717e+00,  3.2782e+00,
          1.5168e+00, -2.0432e-01],
        [-3.9825e-02, -6.0716e-04, -5.9883e-04, -6.0725e-04, -6.0704e-04,
         -1.0627e-03, -7.9899e-03, -4.1151e-01, -1.6005e+00, -6.0724e-04,
         -4.2281e-03,  2.7710e-05, -6.0726e-04, -1.5790e+00, -1.5873e+00,
         -4.1744e-03, -1.6006e+00, -1.2038e-03, -1.6556e-01, -5.2093e-04,
         -1.3377e-03, -6.9726e-02],
        [-2.8008e-02, -3.7012e-03, -3.7049e-03, -3.7011e-03, -3.7013e-03,
         -2.5276e-03, -1.3550e-02, -3.4950e-01, -1.3625e+00, -3.7010e-03,
         -8.1859e-03,  1.1435e-04, -3.7010e-03, -1.3518e+00, -1.3541e+00,
         -2.1832e-03, -1.3631e+00, -6.2569e-03, -2.5553e-01, -1.5479e-03,
         -5.0665e-03, -3.0204e-02],
        [-1.3151e-01,  3.9463e-01,  3.9680e-01,  3.9454e-01,  3.9475e-01,
          4.7741e-02, -2.6247e+01,  5.1748e+00,  3.1986e+00,  3.9446e-01,
          5.8933e-01,  6.0180e-06,  3.9451e-01, -9.2003e-01, -5.2649e-01,
          4.1247e-02, -8.8883e-01, -6.7230e+00,  3.4860e+00, -1.6791e+01,
          3.7374e-01,  2.5611e+00],
        [-8.6466e-01, -1.1679e+00, -1.1613e+00, -1.1680e+00, -1.1677e+00,
         -8.7610e-01, -1.1702e+00,  1.2081e-02,  5.2868e+00, -1.1681e+00,
         -1.7999e+00,  2.6266e+01, -1.1681e+00,  4.6146e-01,  1.0641e+00,
         -8.3589e-01,  5.4921e-01, -5.0842e+00,  1.4638e+00, -5.6844e+00,
         -1.4955e+00, -8.8090e-01],
        [-4.3805e-02, -1.0492e-03, -1.0382e-03, -1.0494e-03, -1.0489e-03,
         -2.8691e-03, -7.1875e-03, -4.8334e-01, -1.7803e+00, -1.0495e-03,
         -4.8857e-03,  5.0951e-05, -1.0495e-03, -1.7572e+00, -1.7653e+00,
         -5.5198e-03, -1.7803e+00, -1.5825e-03, -1.8474e-01, -2.7810e-04,
         -2.1622e-03, -7.7642e-02],
        [-4.9247e-02, -5.5016e-04, -5.5293e-04, -5.5008e-04, -5.5027e-04,
         -2.8475e-03, -6.5928e-03, -4.9145e-01, -1.7672e+00, -5.5001e-04,
         -4.3962e-03,  1.1337e-05, -5.5005e-04, -1.7465e+00, -1.7521e+00,
         -6.9248e-03, -1.7672e+00, -8.1107e-04, -1.7967e-01, -4.5109e-04,
         -1.5916e-03, -7.3895e-02]], device='cuda:0'))])
xi:  [1287.1366]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 1699.9831552659127
W_T_median: 1644.3141225981033
W_T_pctile_5: 1294.4753737287106
W_T_CVAR_5_pct: 770.1978797990192
Average q (qsum/M+1):  50.74873204385081
Optimal xi:  [1287.1366]
Expected(across Rb) median(across samples) p_equity:  2.1746165498844524e-06
obj fun:  tensor(-2727.8059, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/factor_decumulation/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:262: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/factor_decumulation/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/factor_decumulation/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: MC_everything
Objective function: mean_cvar_single_level
Tracing param: 1.5
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       22  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       22  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 22)      True          22  
0     (22, 22)      True          22  
0      (22, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       22  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       22  logistic_sigmoid   
0        obj.layers[3]         3  output_layer       14           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 22)      True          22  
0     (22, 22)      True          22  
0     (22, 14)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -8.5715,   6.4621],
        [ -8.3669,  -9.0182],
        [ -5.1223,   3.2445],
        [  8.0669,   4.1508],
        [-11.4280,  -6.0457],
        [ -6.4858,   4.0851],
        [  6.0779,   4.9126],
        [  9.1747,   0.7713],
        [ -8.3119,   6.0846],
        [ -8.3147,   6.0977],
        [ -8.4882,   6.6116],
        [ -8.6931,   5.7529],
        [  7.8819,   3.3034],
        [ -1.2974,   1.0853],
        [  5.4594,  -0.3288],
        [  5.2299,   5.2824],
        [-11.7613,  -7.4762],
        [  7.7973,   4.2640],
        [ -8.5799,   5.8746],
        [ -7.8535,   5.7472],
        [ -1.2944,   1.0845],
        [-21.4386,  -5.7294]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ 4.8764, -5.7404, -3.0406, -9.5323, -3.7687, -2.3429, -8.4043, -9.1228,
         4.2727,  3.0356,  5.1757,  1.5461, -8.9288, -3.8883, -8.9159, -8.5427,
        -4.0692, -9.2749,  1.8685,  2.4405, -3.8889, -4.6902], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1574e-03, -1.6502e-02, -2.2728e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1088e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [-9.2453e+00,  1.2482e+01, -7.2066e-01,  7.0332e+00,  4.6981e+00,
         -1.2007e+00,  4.5523e+00,  6.2080e+00, -7.5674e+00, -3.0869e+00,
         -1.0021e+01, -1.8126e+00,  5.8578e+00, -1.6237e-01,  6.8999e-01,
          5.4520e+00,  8.4865e+00,  8.0426e+00, -2.2762e+00, -3.8127e+00,
         -1.9618e-01,  8.7135e+00],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2751e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-9.6515e+00,  1.3280e+01, -9.1434e-01,  9.3871e+00,  5.7620e+00,
         -1.3190e+00,  6.4927e+00,  6.8045e+00, -8.3770e+00, -3.3906e+00,
         -1.0939e+01, -2.1716e+00,  6.5179e+00, -2.1870e-01,  2.0491e+00,
          4.1453e+00,  9.2888e+00,  7.8384e+00, -2.6898e+00, -4.4743e+00,
         -1.9003e-01,  9.7752e+00],
        [-7.9773e+00,  1.0315e+01,  2.5895e-01,  4.6608e+00,  4.9211e+00,
          1.7041e-02,  2.1882e+00,  6.8647e+00, -6.6734e+00, -4.8263e+00,
         -8.8073e+00, -2.8795e+00,  6.4311e+00,  1.6629e-01,  1.1111e+00,
          5.0411e+00,  7.6765e+00,  1.1081e+01, -3.5739e+00, -4.0927e+00,
          1.6082e-01,  8.5887e+00],
        [-7.6589e+00,  9.2592e+00,  7.9739e-02,  3.9257e+00,  4.5700e+00,
          1.0005e-01,  2.1053e+00,  4.6166e+00, -6.0015e+00, -3.8545e+00,
         -9.2106e+00, -1.7570e+00,  5.7099e+00, -1.2986e-02,  5.9836e-02,
          4.9159e+00,  7.0161e+00,  9.4703e+00, -2.3319e+00, -3.1763e+00,
         -1.3208e-02,  7.3285e+00],
        [-2.2581e-01, -1.6549e-01,  1.7511e-03, -1.2938e-02, -1.1903e-01,
          1.1578e-03, -1.6509e-02, -2.2839e-03, -1.8738e-01, -6.9338e-02,
         -2.5288e-01, -1.2692e-02, -9.1165e-03,  1.2292e-02,  1.9855e-02,
         -1.7662e-02, -1.7966e-01, -1.2937e-02, -1.9683e-02, -4.9682e-02,
          1.2307e-02, -3.1400e-02],
        [-2.2584e-01, -1.6546e-01,  1.7508e-03, -1.2931e-02, -1.1901e-01,
          1.1573e-03, -1.6502e-02, -2.2704e-03, -1.8735e-01, -6.9322e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9856e-02,
         -1.7657e-02, -1.7959e-01, -1.2929e-02, -1.9678e-02, -4.9672e-02,
          1.2308e-02, -3.1398e-02],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2752e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2730e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1088e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [-7.4230e+00,  9.2761e+00,  8.2691e-02,  4.6883e+00,  4.4150e+00,
          1.2211e-01,  2.9895e+00,  3.5408e+00, -6.2114e+00, -3.5923e+00,
         -9.4198e+00, -1.8627e+00,  4.7011e+00, -1.9985e-02, -6.0281e-02,
          5.2032e+00,  7.0797e+00,  8.3206e+00, -2.3235e+00, -3.3515e+00,
         -1.9947e-02,  7.4397e+00],
        [ 7.9326e+00, -1.0706e+01,  4.0837e-01, -9.2089e+00, -5.7725e+00,
          6.6403e-01, -4.8629e+00, -5.8385e+00,  6.6214e+00,  5.0109e+00,
          9.6232e+00,  3.3999e+00, -5.8456e+00, -1.3669e-01, -1.4453e+00,
         -3.3601e+00, -8.4017e+00, -9.5444e+00,  3.9084e+00,  4.3412e+00,
         -1.3169e-01, -9.7519e+00],
        [-2.2583e-01, -1.6545e-01,  1.7507e-03, -1.2931e-02, -1.1900e-01,
          1.1572e-03, -1.6503e-02, -2.2678e-03, -1.8733e-01, -6.9320e-02,
         -2.5297e-01, -1.2687e-02, -9.1093e-03,  1.2293e-02,  1.9856e-02,
         -1.7657e-02, -1.7958e-01, -1.2930e-02, -1.9677e-02, -4.9670e-02,
          1.2308e-02, -3.1399e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2931e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2732e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [ 6.5891e-01,  3.0868e-01,  8.3566e-03,  3.5747e-02,  2.1159e-01,
          5.3475e-03,  5.7464e-02,  2.6629e-01,  5.5272e-01,  2.6083e-01,
          7.4008e-01,  8.5701e-02,  7.1654e-02,  3.7717e-02,  5.6900e-02,
          8.1005e-02,  2.9146e-01,  3.6840e-02,  1.1119e-01,  2.1066e-01,
          3.7716e-02,  1.3910e-01],
        [-2.2585e-01, -1.6548e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2733e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1087e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2307e-02, -3.1398e-02],
        [-7.5648e+00,  9.6323e+00,  3.4567e-02,  4.2023e+00,  4.4635e+00,
         -1.3328e-01,  2.0401e+00,  5.3264e+00, -6.2784e+00, -3.7048e+00,
         -9.3470e+00, -2.0562e+00,  5.8618e+00, -3.3635e-02,  2.0363e-01,
          5.0433e+00,  7.2814e+00,  9.5323e+00, -2.4148e+00, -3.3678e+00,
         -3.5727e-02,  7.7623e+00],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2750e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2744e-03, -1.8737e-01, -6.9326e-02,
         -2.5298e-01, -1.2689e-02, -9.1087e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2931e-02, -1.1901e-01,
          1.1574e-03, -1.6502e-02, -2.2722e-03, -1.8735e-01, -6.9324e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9673e-02,
          1.2308e-02, -3.1398e-02],
        [ 6.6450e-01,  3.1201e-01,  8.4127e-03,  3.4696e-02,  2.1235e-01,
          5.3877e-03,  5.6376e-02,  2.6891e-01,  5.5678e-01,  2.6166e-01,
          7.4701e-01,  8.5769e-02,  7.1346e-02,  3.8211e-02,  5.7275e-02,
          8.0058e-02,  2.9347e-01,  3.5786e-02,  1.1132e-01,  2.1139e-01,
          3.8209e-02,  1.3913e-01],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2753e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-2.4313,  0.0078, -2.4313,  0.0873, -0.2625, -0.5234, -2.4313, -2.4314,
        -2.4313, -2.4313, -0.4369, -0.2571, -2.4314, -2.4313,  4.5769, -2.4313,
        -0.4006, -2.4313, -2.4313, -2.4313,  4.6668, -2.4313], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[  0.0334, -10.4940,   0.0334, -15.8008,  -9.7979,  -6.9452,   0.0334,
           0.0334,   0.0334,   0.0334,  -7.0927,  14.9535,   0.0334,   0.0334,
           4.2936,   0.0334,  -7.0565,   0.0334,   0.0334,   0.0334,   4.7631,
           0.0334]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 1.0813e+01,  2.9656e+00],
        [ 5.5664e-01,  1.1757e+01],
        [ 1.8618e+01,  2.3664e+00],
        [ 1.0637e+01,  1.5273e-02],
        [-1.4941e+01, -2.2181e+00],
        [-1.2849e+00,  1.3570e+00],
        [-1.2800e+00,  1.3116e+00],
        [-1.7122e+00,  6.5637e-01],
        [-2.0284e+00,  2.5259e-01],
        [ 9.3477e+00, -5.2188e-01],
        [-1.9314e+00,  2.3251e-01],
        [-1.8788e+00,  4.0167e-01],
        [-1.0523e+01, -1.6251e+00],
        [-8.3398e+00,  5.3496e+00],
        [-7.4426e+00,  1.0247e+01],
        [-1.2446e+01, -2.8588e+00],
        [-1.4240e+01, -3.1016e+00],
        [-1.0901e+01, -2.0063e+00],
        [-1.0106e+01, -2.4687e+00],
        [ 3.1771e+00,  1.1429e+01],
        [ 1.0907e+01,  2.2476e+00],
        [ 1.1102e+01,  1.0847e+01]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-5.5365,  7.0663,  2.9709, -9.6018, -1.5848, -4.5127, -4.5185, -4.9090,
        -4.9531, -9.4875, -4.9847, -4.9560,  5.4223,  3.0397,  6.7011, -3.5168,
        -2.9913,  3.2472,  0.4201,  7.7652, -4.3018,  6.4326], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 6.1957e-01, -3.4634e+00, -1.7479e+00,  1.1905e+00,  1.2460e-02,
          1.1948e-01,  1.3226e-01,  4.3984e-02, -1.1598e-02,  1.0215e+00,
         -6.1706e-03,  2.4414e-03, -2.5313e+00,  1.1746e+00, -7.8526e-01,
         -9.2734e-03,  2.7572e-03, -2.7562e+00, -1.8971e+00, -2.6434e+00,
         -4.2419e-01,  3.0293e-02],
        [-4.6968e-01, -1.5418e-01, -2.2179e+00, -4.7229e-01, -1.4815e-02,
         -2.6861e-02, -2.4100e-02,  6.5293e-03, -1.5585e-02, -3.8766e-01,
         -1.6068e-02, -1.1227e-02, -1.0214e+00, -1.1716e-01, -1.0616e-01,
         -5.8386e-03, -7.9498e-03, -5.2026e-01, -1.9652e-01, -4.4158e-01,
         -1.2068e+00, -1.2289e+00],
        [-9.0043e-01, -3.1328e-01, -2.4749e+00, -1.0214e+00, -5.5072e-03,
         -2.2407e-02, -1.9453e-02, -7.7448e-03,  4.4606e-03, -9.3610e-01,
          4.1020e-03,  2.5876e-03, -1.2488e+00, -4.6992e-02, -9.2699e-02,
         -2.2626e-03, -3.5666e-03, -6.7176e-01, -2.4800e-01, -8.7567e-01,
         -1.3802e+00, -7.7155e-01],
        [-4.7184e-01, -1.5540e-01, -2.2143e+00, -4.7815e-01, -1.4473e-02,
         -2.7281e-02, -2.4476e-02,  6.5809e-03, -1.5495e-02, -3.9563e-01,
         -1.5975e-02, -1.1107e-02, -1.0396e+00, -1.1822e-01, -1.0605e-01,
         -5.8775e-03, -7.9716e-03, -5.2621e-01, -1.9589e-01, -4.4421e-01,
         -1.2127e+00, -1.2341e+00],
        [-4.8450e-01, -1.6921e-01, -2.2399e+00, -4.9569e-01, -1.4212e-02,
         -2.5472e-02, -2.2971e-02,  5.3544e-03, -1.0943e-02, -4.2767e-01,
         -1.1482e-02, -7.9784e-03, -1.0434e+00, -1.0826e-01, -9.0719e-02,
         -6.2509e-03, -8.3116e-03, -5.2892e-01, -2.1129e-01, -4.5420e-01,
         -1.2241e+00, -1.0613e+00],
        [ 3.0119e-01,  9.1885e-01, -1.5837e+00, -8.5542e-01, -1.1953e-02,
         -1.9274e+00, -1.8752e+00, -1.4092e+00, -5.5076e-01,  1.0780e+00,
         -4.5548e-01, -9.9188e-01, -3.9286e+00,  1.1415e+00,  2.2999e+00,
         -1.2239e-02, -1.3323e-02, -2.7068e+00, -9.7625e-01,  4.2057e-01,
         -1.0808e+00, -1.2393e+00],
        [ 2.4582e-01, -1.1721e+01,  5.7285e-01, -6.6182e+00,  3.3458e+00,
          1.7362e-01,  1.7999e-01,  2.0080e-01,  2.8786e-01, -4.5146e+00,
          2.9196e-01,  1.9339e-01,  3.6973e+00, -2.2846e+00, -8.2839e+00,
          2.5629e+00,  2.7897e+00,  3.3397e+00,  3.6998e+00, -1.2216e+01,
          1.0269e-01, -7.8724e+00],
        [-2.7710e+00,  3.8384e+00, -3.8614e+00, -5.2497e+00,  1.4955e-01,
         -5.1488e-01, -5.0931e-01, -4.0831e-01, -1.3933e-01, -4.9036e+00,
         -1.0681e-01, -2.8754e-01,  2.6586e+00,  3.1018e+00,  6.0454e+00,
          5.3721e-01,  5.1709e-01,  2.4000e+00,  1.7467e+00,  2.8980e+00,
         -1.8615e+00,  1.3298e+00],
        [ 5.3996e+00,  1.7695e+01,  2.7980e+00,  6.7002e+00, -6.8933e+00,
          1.9716e-02,  1.5955e-02,  1.6031e-02, -1.9886e-01,  4.1219e+00,
         -1.8883e-01,  2.3240e-02, -8.0362e+00,  3.0849e+00,  1.4710e+01,
         -3.3033e+00, -3.8057e+00, -7.4740e+00, -6.2744e+00,  1.9113e+01,
          5.0855e+00,  2.1580e+01],
        [-4.6054e-01, -1.5864e-01, -2.1828e+00, -4.7962e-01, -1.3132e-02,
         -2.7434e-02, -2.4527e-02,  7.6509e-03, -1.3661e-02, -3.9854e-01,
         -1.4154e-02, -9.5939e-03, -1.0591e+00, -1.2246e-01, -9.9910e-02,
         -5.2767e-03, -7.3107e-03, -5.5050e-01, -2.1282e-01, -4.5037e-01,
         -1.2105e+00, -1.2384e+00],
        [-9.3210e-01, -5.0637e-01, -2.5650e+00, -1.2297e+00,  5.1007e-03,
         -1.3266e-02, -1.0812e-02, -6.5037e-03, -1.3910e-03, -1.1288e+00,
         -1.7836e-03, -1.9456e-03, -7.9371e-01, -5.5349e-02, -8.6527e-02,
          5.2059e-03,  5.8080e-03, -8.8163e-01, -4.5943e-01, -1.6628e+00,
         -1.1149e+00, -5.6400e-01],
        [-2.8460e+00, -1.8825e+01, -9.7046e+00, -3.0631e+00,  6.2381e+00,
          2.2284e-02,  2.2216e-02,  3.8058e-02,  1.2254e-02, -4.6393e+00,
          2.0356e-03,  4.3669e-02,  7.6060e+00, -3.1393e+00, -1.1899e+01,
          2.9927e+00,  3.5772e+00,  7.5127e+00,  7.0486e+00, -2.2653e+01,
         -1.0357e+01, -2.5603e+01],
        [-4.7448e-01, -1.5413e-01, -2.2021e+00, -4.7761e-01, -1.5017e-02,
         -2.6936e-02, -2.4189e-02,  6.2971e-03, -1.5709e-02, -3.9518e-01,
         -1.6194e-02, -1.1365e-02, -1.0353e+00, -1.1675e-01, -1.0676e-01,
         -6.0131e-03, -8.0879e-03, -5.2030e-01, -1.9318e-01, -4.4328e-01,
         -1.2192e+00, -1.2259e+00],
        [-6.9231e-01,  3.0014e+00,  2.7786e+00, -1.3175e+00,  3.0620e-04,
         -1.3308e-01, -1.3059e-01, -4.6677e-03, -1.5150e-02, -1.3574e+00,
         -1.8928e-02, -2.6791e-03,  2.1880e+00, -4.4040e-01,  8.1953e-01,
         -1.8323e-02, -1.1176e-02,  1.4720e+00,  4.3629e-01,  2.4554e+00,
          8.6002e-02, -2.4341e-01],
        [ 3.0175e+00, -1.5929e-01,  3.1082e+00,  1.6836e+00, -3.7655e+00,
          1.7569e-01,  1.8810e-01,  2.3150e-01, -5.4313e-01,  3.8072e+00,
         -5.3327e-01,  1.6719e-01,  6.0672e-02, -2.5586e+00, -3.6155e+00,
         -4.5190e+00, -4.8662e+00,  1.6404e-01, -1.7814e-01, -2.9936e-01,
          2.7050e+00, -1.8862e+00],
        [-6.1343e-01, -2.0997e-01, -2.3786e+00, -7.6186e-01, -1.9840e-02,
         -3.2273e-02, -3.0458e-02, -4.7454e-03,  5.8161e-03, -6.4208e-01,
          6.0534e-03,  3.5540e-03, -1.0330e+00, -6.3106e-02, -1.0050e-01,
         -7.6629e-03, -1.3412e-02, -4.8643e-01, -1.8407e-01, -5.2743e-01,
         -1.3866e+00, -9.2565e-01],
        [ 2.3232e-01,  3.1081e+00,  2.1861e+00,  1.7924e+00,  8.3474e-01,
         -4.2057e-01, -3.7750e-01, -8.6959e-02, -6.3586e-02,  1.4179e+00,
         -6.1088e-02, -4.4329e-02,  1.9436e-01, -4.4091e-01,  1.1123e+00,
          4.9760e-01,  7.0823e-01, -1.6870e-01, -3.9429e-01, -1.1351e+00,
          1.7979e-02, -1.2019e+00],
        [-9.3911e-03, -3.8280e+00, -3.1866e-01, -2.0025e+00, -3.0075e-02,
          4.3973e-02,  5.3990e-02,  1.0353e-01,  1.4874e-01, -1.8588e+00,
          1.5683e-01,  1.3914e-01, -1.0725e-01, -2.1520e-01, -2.7783e-01,
          5.4541e-02,  7.3731e-03, -1.3880e+00, -8.0744e-01, -5.4071e+00,
         -9.3933e-01,  6.6525e-02],
        [-2.0923e+00,  1.6783e+00,  2.1031e+00, -6.6800e+00,  1.9109e-04,
         -8.2756e-01, -7.5222e-01, -4.3503e-01, -1.2713e-01, -3.5556e+00,
         -7.5366e-02, -3.3382e-01,  9.4887e+00, -1.2212e+00,  5.7869e+00,
         -6.4339e-04, -3.5999e-03,  9.1765e+00,  6.6382e+00,  6.8362e-01,
          2.7993e-01, -2.2562e+00],
        [-5.5183e+00, -1.5095e+01, -2.8824e-01, -4.9346e+00,  5.3321e+00,
          1.5448e-01,  1.5735e-01,  1.6104e-01,  5.9928e-01, -2.7075e+00,
          5.5855e-01,  1.3923e-01,  3.0535e+00,  8.4196e-01, -6.5453e+00,
          4.6053e+00,  5.0922e+00,  3.6158e+00,  3.8865e+00, -1.4997e+01,
         -2.8857e+00, -4.2056e+00],
        [ 4.0156e-01, -1.0952e+00, -1.5738e+00, -4.3123e-01, -8.5229e-03,
         -6.6402e-01, -6.0136e-01, -2.4497e-01, -5.3144e-02, -2.8255e-01,
         -5.5575e-02, -9.1214e-02, -2.1121e+00,  1.5978e+00,  1.4435e+00,
         -1.0813e-03, -1.8711e-03, -2.1573e+00, -8.6345e-01, -1.7321e+00,
         -7.5512e-01,  5.2300e-01],
        [-1.9858e+00,  2.9033e+00, -2.5269e+00, -2.1485e+00,  2.2962e+00,
         -1.4441e+00, -1.3739e+00, -7.3427e-01,  6.2891e-02,  2.1944e-01,
          6.1358e-02, -2.6440e-01,  7.4516e-02,  1.7016e+00,  3.0581e+00,
          1.5196e+00,  1.8766e+00,  6.5632e-01,  1.1298e+00,  1.3664e+00,
         -2.7325e+00, -7.5516e-01]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-1.8466, -2.2256, -2.5068, -2.1943, -2.2514, -1.8834,  0.6255, -4.9456,
        -2.2024, -2.2158, -2.5964,  0.0491, -2.2135,  3.0825,  3.0734, -2.4047,
         2.5296, -1.0040,  2.4991, -0.5295, -2.0766, -2.4070], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-1.5234e-02,  7.2296e-05, -1.5502e-04,  5.9106e-05,  9.2680e-05,
         -2.2228e-02, -7.7352e-03, -1.5990e-01, -1.5103e+00,  6.1218e-05,
         -1.5306e-04, -1.3007e-05,  6.3929e-05, -1.5060e+00, -1.5008e+00,
         -2.1007e-04, -1.4999e+00, -5.4381e-03, -6.9054e-01, -3.7369e-03,
         -4.7102e-03, -3.5212e-02],
        [-8.7292e-03, -1.4222e-03,  7.6021e-04, -1.3898e-03, -1.5771e-03,
         -1.3307e-02, -5.1882e-03, -1.0878e-01, -8.2132e-01, -1.3260e-03,
          8.8522e-04, -2.6449e-04, -1.4244e-03, -8.2289e-01, -8.1366e-01,
          5.1250e-04, -8.1735e-01,  1.2221e-03, -3.1415e-01, -6.8756e-03,
          4.4122e-03, -3.5269e-02],
        [-2.1229e-02, -5.1093e-04, -3.4543e-04, -5.1941e-04, -5.4632e-04,
         -1.8385e-02, -9.4420e-03, -1.3731e-01, -1.4218e+00, -5.2075e-04,
         -3.2211e-04,  2.3184e-05, -5.1689e-04, -1.4173e+00, -1.4127e+00,
         -3.8173e-04, -1.4125e+00, -6.1909e-03, -6.2055e-01, -3.7929e-03,
         -7.1839e-03, -2.7972e-02],
        [-9.4172e-03, -2.1938e-04, -2.2482e-04, -2.0759e-04, -2.8288e-04,
         -1.6622e-02, -7.4112e-03, -1.3137e-01, -1.2415e+00, -2.0252e-04,
         -2.1593e-04, -7.4338e-05, -2.1553e-04, -1.2385e+00, -1.2343e+00,
         -1.4845e-04, -1.2328e+00, -5.0361e-03, -5.7108e-01, -3.7365e-03,
         -7.0540e-03, -2.5170e-02],
        [-1.0969e+00,  7.0714e-02,  2.8031e-01,  4.2693e-02,  2.8583e-01,
          5.4877e-01,  3.6379e+00, -1.3225e+00, -3.0535e+00,  2.8854e-01,
          9.2331e-01, -1.4907e+01,  2.7428e-02,  3.6135e+00,  3.4661e+00,
         -2.3553e-02,  3.3911e+00,  1.2464e+00,  2.0600e+00,  5.6362e+00,
         -4.8358e-01,  4.4222e-01],
        [-1.1325e-02, -1.4138e-04,  1.4500e-04, -1.5008e-04, -1.0196e-03,
         -8.7395e-03, -5.0212e-04, -1.4891e-01, -9.6424e-01, -1.5847e-04,
          8.4481e-05, -6.7668e-04, -1.4540e-04, -9.6261e-01, -9.4804e-01,
         -9.4017e-05, -9.5700e-01,  4.4294e-03, -4.5741e-01, -5.5136e-03,
          2.2288e-03, -3.6784e-02],
        [-2.4271e-02, -7.7962e-04, -2.2040e-04, -7.9007e-04, -5.4691e-04,
         -1.4880e-02, -9.2166e-03, -1.1032e-01, -1.2944e+00, -7.8678e-04,
         -1.4609e-04, -3.3668e-05, -7.9327e-04, -1.2897e+00, -1.2879e+00,
         -3.7474e-04, -1.2861e+00, -9.7262e-03, -5.3746e-01, -3.8536e-03,
         -1.0548e-02, -2.4508e-02],
        [ 3.9237e+00, -6.2937e-02,  8.2976e-01, -8.9553e-02,  1.8773e-01,
          2.5280e+00,  4.4063e+00, -5.1176e-01,  2.7121e+00,  1.5038e-01,
          2.1898e+00, -6.3975e+00, -1.0291e-01,  9.8757e-01,  1.1535e+00,
          5.7770e-02,  9.4780e-01,  2.9512e+00,  2.3504e+00,  1.6411e+00,
          3.1498e+00,  1.2727e-01],
        [-1.4494e-02, -1.9430e-04, -1.7724e-04, -2.0127e-04, -2.0117e-04,
         -1.5493e-02, -8.1680e-03, -1.3258e-01, -1.3345e+00, -2.0053e-04,
         -1.8098e-04, -1.8463e-05, -1.9899e-04, -1.3303e+00, -1.3262e+00,
         -2.7675e-04, -1.3255e+00, -6.2074e-03, -5.8710e-01, -4.1919e-03,
         -7.5895e-03, -2.9301e-02],
        [-2.1892e-02, -3.5780e-04, -4.8405e-04, -3.6317e-04, -3.6356e-04,
         -2.3657e-02, -1.6951e-02, -9.6588e-02, -1.1849e+00, -3.5150e-04,
         -4.0838e-04, -1.7243e-05, -3.6464e-04, -1.1843e+00, -1.1795e+00,
         -3.3804e-04, -1.1790e+00, -7.4055e-03, -5.7283e-01, -5.4422e-03,
         -1.0076e-02, -3.1398e-02],
        [-2.3028e+00, -2.1890e-02, -8.3502e-03, -5.3786e-02,  9.5685e-02,
         -8.9290e-01, -1.4767e+01,  7.5055e+00,  3.0752e+00,  1.1812e-01,
         -7.0438e-02,  2.1906e-03, -5.7019e-02, -7.6423e-01, -1.3833e+00,
         -7.3209e-03, -7.3795e-01, -2.2229e+00,  1.8670e+00, -1.4910e+01,
         -1.6032e+00,  1.4609e+00],
        [ 2.4319e+00,  1.1747e-01, -1.6596e-01,  8.9778e-02,  3.1240e-01,
         -1.2941e+00, -9.2455e-01, -5.3120e-01,  5.2163e+00,  3.3676e-01,
         -2.0670e-01,  2.2187e+01,  7.3275e-02,  3.7788e-01,  7.5700e-01,
         -1.2275e-01,  4.8364e-01, -2.5823e+00,  1.5965e+00, -2.2668e+00,
         -6.5383e-01, -2.8611e+00],
        [-2.1115e-02, -3.0744e-04, -1.4460e-04, -2.9289e-04, -3.5131e-04,
         -2.2539e-02, -1.0971e-02, -1.5511e-01, -1.5086e+00, -2.8377e-04,
         -1.2594e-04,  2.8039e-05, -3.0274e-04, -1.5044e+00, -1.4994e+00,
         -3.7557e-04, -1.4986e+00, -6.5951e-03, -6.8458e-01, -3.5928e-03,
         -7.8039e-03, -3.0722e-02],
        [-1.4210e-02,  2.7210e-04, -1.6876e-04,  2.6752e-04,  2.9104e-04,
         -2.2712e-02, -5.7647e-03, -1.5704e-01, -1.4740e+00,  2.7486e-04,
         -1.6774e-04, -4.4364e-05,  2.6776e-04, -1.4699e+00, -1.4648e+00,
         -1.4749e-04, -1.4640e+00, -5.0059e-03, -6.6920e-01, -3.9010e-03,
         -5.3125e-03, -3.3932e-02]], device='cuda:0'))])
loaded xi:  855.6613
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857
 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857
 0.07142857 0.07142857]
W_T_mean: 8576.841924009083
W_T_median: 5042.380921625826
W_T_pctile_5: 103.64169553244135
W_T_CVAR_5_pct: -371.9331258181762
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -3486.95144123016
Current xi:  [870.4096]
objective value function right now is: -3486.95144123016
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -3487.2275153705173
Current xi:  [885.2677]
objective value function right now is: -3487.2275153705173
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -3539.49527332284
Current xi:  [900.0293]
objective value function right now is: -3539.49527332284
8.0% of gradient descent iterations done. Method = Adam
Current xi:  [914.8022]
objective value function right now is: -3530.5790264998227
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -3582.6964990754527
Current xi:  [929.38904]
objective value function right now is: -3582.6964990754527
12.0% of gradient descent iterations done. Method = Adam
new min fval:  -3594.4474232624902
Current xi:  [943.57684]
objective value function right now is: -3594.4474232624902
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [957.2372]
objective value function right now is: -3580.1724597910406
16.0% of gradient descent iterations done. Method = Adam
new min fval:  -3602.8882631639144
Current xi:  [971.227]
objective value function right now is: -3602.8882631639144
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -3650.6932897669885
Current xi:  [985.5575]
objective value function right now is: -3650.6932897669885
20.0% of gradient descent iterations done. Method = Adam
new min fval:  -3654.8174104648615
Current xi:  [999.2969]
objective value function right now is: -3654.8174104648615
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -3681.1430100346724
Current xi:  [1012.74774]
objective value function right now is: -3681.1430100346724
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [1026.4324]
objective value function right now is: -3661.05973289626
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [1039.7162]
objective value function right now is: -3666.8209500113317
28.000000000000004% of gradient descent iterations done. Method = Adam
new min fval:  -3714.6867986470575
Current xi:  [1053.0037]
objective value function right now is: -3714.6867986470575
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [1066.5516]
objective value function right now is: -3710.1826703368674
32.0% of gradient descent iterations done. Method = Adam
new min fval:  -3728.6733382482603
Current xi:  [1079.5907]
objective value function right now is: -3728.6733382482603
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [1092.5886]
objective value function right now is: -3726.5438651754357
36.0% of gradient descent iterations done. Method = Adam
new min fval:  -3736.028264852708
Current xi:  [1104.8513]
objective value function right now is: -3736.028264852708
38.0% of gradient descent iterations done. Method = Adam
new min fval:  -3774.951797254728
Current xi:  [1117.8146]
objective value function right now is: -3774.951797254728
40.0% of gradient descent iterations done. Method = Adam
new min fval:  -3788.6777896555313
Current xi:  [1129.8667]
objective value function right now is: -3788.6777896555313
42.0% of gradient descent iterations done. Method = Adam
new min fval:  -3797.7429562324683
Current xi:  [1142.1984]
objective value function right now is: -3797.7429562324683
44.0% of gradient descent iterations done. Method = Adam
new min fval:  -3807.5779946191305
Current xi:  [1154.715]
objective value function right now is: -3807.5779946191305
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [1167.1774]
objective value function right now is: -3805.299992865991
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [1179.0532]
objective value function right now is: -3751.760250909103
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [1190.061]
objective value function right now is: -3762.4432666864736
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [1201.0361]
objective value function right now is: -3803.6268879601557
54.0% of gradient descent iterations done. Method = Adam
new min fval:  -3819.6198776045267
Current xi:  [1211.4476]
objective value function right now is: -3819.6198776045267
56.00000000000001% of gradient descent iterations done. Method = Adam
new min fval:  -3844.7399031402388
Current xi:  [1221.7439]
objective value function right now is: -3844.7399031402388
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [1232.2426]
objective value function right now is: -3828.788853205989
60.0% of gradient descent iterations done. Method = Adam
new min fval:  -3850.6662157909295
Current xi:  [1242.3644]
objective value function right now is: -3850.6662157909295
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [1252.0414]
objective value function right now is: -3818.570099746063
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [1262.1898]
objective value function right now is: -3848.419217265393
66.0% of gradient descent iterations done. Method = Adam
new min fval:  -3869.080362559339
Current xi:  [1271.7926]
objective value function right now is: -3869.080362559339
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [1281.556]
objective value function right now is: -3821.080201238654
70.0% of gradient descent iterations done. Method = Adam
new min fval:  -3874.689440129229
Current xi:  [1290.2771]
objective value function right now is: -3874.689440129229
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -3900.823196539151
Current xi:  [1292.035]
objective value function right now is: -3900.823196539151
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -3903.2867580866714
Current xi:  [1294.1497]
objective value function right now is: -3903.2867580866714
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [1296.1113]
objective value function right now is: -3895.2825680020323
78.0% of gradient descent iterations done. Method = Adam
new min fval:  -3905.9475290737387
Current xi:  [1298.0876]
objective value function right now is: -3905.9475290737387
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [1300.0128]
objective value function right now is: -3904.9594244040127
82.0% of gradient descent iterations done. Method = Adam
new min fval:  -3906.5340144376282
Current xi:  [1302.1279]
objective value function right now is: -3906.5340144376282
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [1304.2335]
objective value function right now is: -3903.1164971221333
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [1306.3838]
objective value function right now is: -3902.7272068321595
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [1308.1113]
objective value function right now is: -3903.96611876756
new min fval from sgd:  -3908.950864022416
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [1310.2668]
objective value function right now is: -3908.950864022416
new min fval from sgd:  -3909.1551925192643
new min fval from sgd:  -3909.321890086229
new min fval from sgd:  -3909.7942871368837
new min fval from sgd:  -3910.7412082406404
new min fval from sgd:  -3911.519113004562
new min fval from sgd:  -3912.101874043625
new min fval from sgd:  -3912.2772595261054
new min fval from sgd:  -3912.8705035333187
new min fval from sgd:  -3913.258964496967
new min fval from sgd:  -3914.391023253956
new min fval from sgd:  -3914.7865888759893
new min fval from sgd:  -3914.962459670015
new min fval from sgd:  -3915.138751176485
new min fval from sgd:  -3915.2685105827554
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [1312.2034]
objective value function right now is: -3914.97184599459
new min fval from sgd:  -3915.452169010995
new min fval from sgd:  -3915.853054276192
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [1313.9988]
objective value function right now is: -3906.5156749484863
new min fval from sgd:  -3915.9614514125446
new min fval from sgd:  -3916.0774841974976
new min fval from sgd:  -3916.223914959808
new min fval from sgd:  -3916.4722812159034
new min fval from sgd:  -3916.7678745383037
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [1315.9741]
objective value function right now is: -3894.6831611467846
new min fval from sgd:  -3917.0806714102036
new min fval from sgd:  -3917.1561474932973
new min fval from sgd:  -3917.7782014449213
new min fval from sgd:  -3918.1313959935464
new min fval from sgd:  -3918.3765921132067
new min fval from sgd:  -3918.561573861217
new min fval from sgd:  -3918.7727994724714
new min fval from sgd:  -3918.961262192697
new min fval from sgd:  -3918.965014899703
new min fval from sgd:  -3918.9653543955083
new min fval from sgd:  -3919.082399969052
new min fval from sgd:  -3919.1994451096334
new min fval from sgd:  -3919.338977523539
new min fval from sgd:  -3919.426758110844
new min fval from sgd:  -3919.5574822908707
new min fval from sgd:  -3919.6085412244006
new min fval from sgd:  -3919.6538528193896
new min fval from sgd:  -3919.679187322692
new min fval from sgd:  -3919.682398811858
new min fval from sgd:  -3919.7116451812685
new min fval from sgd:  -3919.7141771298066
new min fval from sgd:  -3919.737938069614
new min fval from sgd:  -3919.7662515451043
new min fval from sgd:  -3919.7829800043473
new min fval from sgd:  -3919.823536153814
new min fval from sgd:  -3919.833774816102
new min fval from sgd:  -3919.8411751462727
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [1317.2288]
objective value function right now is: -3919.831926565011
new min fval from sgd:  -3919.8918309705937
new min fval from sgd:  -3919.9544111083997
new min fval from sgd:  -3919.960826220963
new min fval from sgd:  -3920.0055700500766
new min fval from sgd:  -3920.060449657639
new min fval from sgd:  -3920.106810583501
new min fval from sgd:  -3920.152454103267
new min fval from sgd:  -3920.173581639314
new min fval from sgd:  -3920.1799843598815
new min fval from sgd:  -3920.183246793037
new min fval from sgd:  -3920.186732190029
new min fval from sgd:  -3920.245572099136
new min fval from sgd:  -3920.271323536999
new min fval from sgd:  -3920.4093432506816
new min fval from sgd:  -3920.489945671189
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [1317.6278]
objective value function right now is: -3920.489945671189
min fval:  -3920.489945671189
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-11.9279,   6.3374],
        [ -4.2012, -11.2113],
        [ -7.5156,   4.5846],
        [ 10.9750,   1.4016],
        [-12.7341,  -8.4441],
        [ -9.0222,   5.9287],
        [  8.0209,   2.5005],
        [ 12.8909,   0.4223],
        [-11.3637,   5.7452],
        [-11.8162,   6.4851],
        [-12.1208,   6.5986],
        [-12.6773,   4.9550],
        [ 10.8019,   1.2899],
        [ -1.7263,   0.8098],
        [ -1.6577,   0.7451],
        [  6.7993,   2.8340],
        [-13.8624,  -9.8718],
        [ 10.6043,   1.5398],
        [-12.6122,   5.0326],
        [-12.1860,   5.1077],
        [ -1.7256,   0.8099],
        [-18.0599,  -6.9449]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ 5.1624e+00, -6.7953e+00, -2.0243e+00, -1.0947e+01, -4.6642e+00,
        -1.4573e-01, -1.0180e+01, -1.1302e+01,  4.8116e+00,  1.4778e+00,
         5.2726e+00, -8.0719e-01, -1.0614e+01, -4.3832e+00, -4.3288e+00,
        -1.0330e+01, -5.1006e+00, -1.0818e+01, -5.4534e-01, -4.2899e-03,
        -4.3858e+00, -6.2064e+00], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-1.8889e-01, -1.3107e-01, -5.4661e-03, -1.2494e-02,  2.7731e-02,
          5.9519e-03, -5.6725e-03, -2.0984e-02, -2.2189e-01,  1.4838e-02,
         -1.6847e-01,  1.7916e-02, -1.4349e-02, -7.9640e-03, -8.7678e-03,
          2.1683e-04,  1.6167e-02, -1.1632e-02,  1.6103e-02,  1.2344e-03,
         -7.9480e-03,  1.5723e-02],
        [-9.3801e+00,  1.5626e+01, -2.9194e+00,  8.8031e+00,  5.3268e+00,
         -4.6059e+00,  4.1173e+00,  1.2553e+01, -7.5991e+00, -3.1632e+00,
         -1.0155e+01, -3.5690e+00,  8.0386e+00, -2.9117e-01, -1.3200e-01,
          4.3038e+00,  1.0036e+01,  9.2898e+00, -3.5096e+00, -3.6820e+00,
         -2.9715e-01,  6.8882e+00],
        [-1.8889e-01, -1.3107e-01, -5.4663e-03, -1.2495e-02,  2.7730e-02,
          5.9519e-03, -5.6727e-03, -2.0984e-02, -2.2189e-01,  1.4838e-02,
         -1.6847e-01,  1.7916e-02, -1.4349e-02, -7.9640e-03, -8.7678e-03,
          2.1673e-04,  1.6166e-02, -1.1632e-02,  1.6103e-02,  1.2342e-03,
         -7.9480e-03,  1.5723e-02],
        [-9.9643e+00,  1.6562e+01, -3.7127e+00,  1.1201e+01,  6.2872e+00,
         -5.3690e+00,  5.9082e+00,  1.3549e+01, -8.5827e+00, -3.7722e+00,
         -1.1231e+01, -4.0107e+00,  8.8582e+00, -2.9763e-01, -1.4095e-01,
          3.1567e+00,  1.0801e+01,  9.3881e+00, -4.0227e+00, -4.5382e+00,
         -2.9966e-01,  7.9948e+00],
        [-8.3219e+00,  1.3503e+01, -2.2713e+00,  6.4763e+00,  5.4966e+00,
         -3.9884e+00,  1.5772e+00,  1.3365e+01, -6.9688e+00, -4.4841e+00,
         -9.0836e+00, -3.2220e+00,  8.3237e+00,  2.3126e-01,  6.3682e-02,
          3.5068e+00,  9.1943e+00,  1.1463e+01, -3.5171e+00, -3.4207e+00,
          2.3437e-01,  6.3457e+00],
        [-7.3429e+00,  1.0178e+01, -1.0603e-01, -6.5882e-01,  5.2089e+00,
         -3.2555e-01, -3.5419e-01, -5.5617e-01, -5.5408e+00, -7.7509e-02,
         -8.7094e+00,  1.0915e-01, -6.4739e-01,  6.6919e-02,  8.3994e-02,
         -9.6427e-02,  7.9724e+00, -4.7181e-01,  1.4065e-01,  1.8410e-01,
          6.5368e-02,  3.7295e+00],
        [-1.8889e-01, -1.3107e-01, -5.4660e-03, -1.2494e-02,  2.7731e-02,
          5.9520e-03, -5.6725e-03, -2.0983e-02, -2.2189e-01,  1.4839e-02,
         -1.6847e-01,  1.7916e-02, -1.4349e-02, -7.9640e-03, -8.7678e-03,
          2.1688e-04,  1.6167e-02, -1.1632e-02,  1.6103e-02,  1.2345e-03,
         -7.9480e-03,  1.5723e-02],
        [-1.8889e-01, -1.3107e-01, -5.4656e-03, -1.2494e-02,  2.7731e-02,
          5.9522e-03, -5.6719e-03, -2.0983e-02, -2.2189e-01,  1.4839e-02,
         -1.6847e-01,  1.7916e-02, -1.4349e-02, -7.9640e-03, -8.7678e-03,
          2.1719e-04,  1.6167e-02, -1.1632e-02,  1.6103e-02,  1.2349e-03,
         -7.9480e-03,  1.5723e-02],
        [-1.8889e-01, -1.3107e-01, -5.4666e-03, -1.2495e-02,  2.7730e-02,
          5.9517e-03, -5.6729e-03, -2.0984e-02, -2.2189e-01,  1.4838e-02,
         -1.6847e-01,  1.7916e-02, -1.4350e-02, -7.9640e-03, -8.7678e-03,
          2.1651e-04,  1.6166e-02, -1.1633e-02,  1.6103e-02,  1.2339e-03,
         -7.9480e-03,  1.5723e-02],
        [-1.8889e-01, -1.3107e-01, -5.4662e-03, -1.2494e-02,  2.7731e-02,
          5.9519e-03, -5.6725e-03, -2.0983e-02, -2.2189e-01,  1.4838e-02,
         -1.6847e-01,  1.7916e-02, -1.4349e-02, -7.9640e-03, -8.7678e-03,
          2.1678e-04,  1.6167e-02, -1.1632e-02,  1.6103e-02,  1.2344e-03,
         -7.9480e-03,  1.5723e-02],
        [-6.6393e+00,  8.7339e+00, -5.7399e-02, -1.0152e+00,  4.5374e+00,
         -1.0208e-01, -3.2962e-01, -2.2401e+00, -5.2541e+00,  7.6205e-02,
         -8.2046e+00,  5.0166e-02, -1.2642e+00,  2.0788e-02,  3.1114e-02,
         -7.4016e-02,  7.1560e+00, -9.1650e-01,  6.3480e-02,  1.0780e-01,
          1.9818e-02,  2.4741e+00],
        [ 8.6511e+00, -1.3812e+01,  3.9807e+00, -1.0773e+01, -5.9233e+00,
          4.9539e+00, -4.2011e+00, -1.2346e+01,  7.2717e+00,  5.5933e+00,
          1.0290e+01,  4.0313e+00, -7.9804e+00, -2.2144e-01, -4.2692e-02,
         -2.2693e+00, -9.5683e+00, -1.0685e+01,  4.2644e+00,  4.2044e+00,
         -2.2691e-01, -7.4354e+00],
        [-1.8889e-01, -1.3107e-01, -5.4657e-03, -1.2494e-02,  2.7731e-02,
          5.9520e-03, -5.6718e-03, -2.0983e-02, -2.2189e-01,  1.4839e-02,
         -1.6847e-01,  1.7916e-02, -1.4348e-02, -7.9640e-03, -8.7678e-03,
          2.1704e-04,  1.6168e-02, -1.1631e-02,  1.6103e-02,  1.2350e-03,
         -7.9480e-03,  1.5723e-02],
        [-1.8889e-01, -1.3107e-01, -5.4663e-03, -1.2494e-02,  2.7731e-02,
          5.9518e-03, -5.6726e-03, -2.0984e-02, -2.2189e-01,  1.4838e-02,
         -1.6847e-01,  1.7916e-02, -1.4349e-02, -7.9640e-03, -8.7678e-03,
          2.1667e-04,  1.6167e-02, -1.1632e-02,  1.6103e-02,  1.2342e-03,
         -7.9480e-03,  1.5723e-02],
        [ 6.3905e-01,  2.4022e-01,  7.3777e-02,  4.3901e-02,  2.0998e-01,
          7.7618e-02,  6.4557e-02,  8.0773e-02,  6.6568e-01,  1.0885e-01,
          6.1567e-01,  4.8505e-02,  5.5410e-02,  6.5169e-03,  1.3178e-02,
          6.7322e-02,  2.3964e-01,  4.5600e-02,  6.8561e-02,  8.6572e-02,
          6.4155e-03,  4.3958e-02],
        [-1.8889e-01, -1.3107e-01, -5.4659e-03, -1.2494e-02,  2.7730e-02,
          5.9520e-03, -5.6724e-03, -2.0983e-02, -2.2189e-01,  1.4839e-02,
         -1.6847e-01,  1.7916e-02, -1.4349e-02, -7.9640e-03, -8.7678e-03,
          2.1693e-04,  1.6167e-02, -1.1632e-02,  1.6103e-02,  1.2346e-03,
         -7.9480e-03,  1.5723e-02],
        [-7.3167e+00,  1.1902e+01,  5.4300e-03,  5.1625e+00,  4.8863e+00,
         -1.2808e+00,  1.4515e+00,  9.0998e+00, -5.9075e+00, -1.8770e+00,
         -8.9504e+00, -7.3796e-01,  6.4323e+00,  1.5210e-01,  5.7726e-02,
          2.7112e+00,  8.4274e+00,  8.3657e+00, -9.9958e-01, -1.2277e+00,
          1.5049e-01,  5.1968e+00],
        [-1.8889e-01, -1.3107e-01, -5.4664e-03, -1.2495e-02,  2.7730e-02,
          5.9519e-03, -5.6728e-03, -2.0984e-02, -2.2189e-01,  1.4838e-02,
         -1.6847e-01,  1.7916e-02, -1.4349e-02, -7.9640e-03, -8.7678e-03,
          2.1668e-04,  1.6166e-02, -1.1632e-02,  1.6103e-02,  1.2341e-03,
         -7.9480e-03,  1.5723e-02],
        [-1.8889e-01, -1.3107e-01, -5.4665e-03, -1.2495e-02,  2.7730e-02,
          5.9518e-03, -5.6728e-03, -2.0984e-02, -2.2189e-01,  1.4838e-02,
         -1.6847e-01,  1.7916e-02, -1.4350e-02, -7.9640e-03, -8.7678e-03,
          2.1660e-04,  1.6166e-02, -1.1633e-02,  1.6103e-02,  1.2340e-03,
         -7.9480e-03,  1.5723e-02],
        [-1.8889e-01, -1.3107e-01, -5.4658e-03, -1.2494e-02,  2.7731e-02,
          5.9520e-03, -5.6722e-03, -2.0983e-02, -2.2189e-01,  1.4839e-02,
         -1.6847e-01,  1.7916e-02, -1.4349e-02, -7.9640e-03, -8.7678e-03,
          2.1699e-04,  1.6167e-02, -1.1632e-02,  1.6103e-02,  1.2348e-03,
         -7.9480e-03,  1.5723e-02],
        [ 6.4287e-01,  2.4211e-01,  7.3602e-02,  4.3111e-02,  2.1038e-01,
          7.7180e-02,  6.3789e-02,  8.0991e-02,  6.6995e-01,  1.0849e-01,
          6.1918e-01,  4.8603e-02,  5.4816e-02,  6.8893e-03,  1.3655e-02,
          6.6855e-02,  2.4026e-01,  4.4783e-02,  6.8648e-02,  8.6502e-02,
          6.7863e-03,  4.3605e-02],
        [-1.8889e-01, -1.3107e-01, -5.4664e-03, -1.2495e-02,  2.7730e-02,
          5.9518e-03, -5.6728e-03, -2.0984e-02, -2.2189e-01,  1.4838e-02,
         -1.6847e-01,  1.7916e-02, -1.4350e-02, -7.9640e-03, -8.7678e-03,
          2.1661e-04,  1.6166e-02, -1.1633e-02,  1.6103e-02,  1.2340e-03,
         -7.9480e-03,  1.5723e-02]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-2.7413,  0.4407, -2.7413,  0.7276,  0.0292, -1.1912, -2.7413, -2.7413,
        -2.7413, -2.7413, -1.1446, -0.7510, -2.7413, -2.7413,  4.8895, -2.7413,
        -0.4537, -2.7413, -2.7413, -2.7413,  4.9618, -2.7413], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[  0.0736, -14.3774,   0.0736, -21.3437, -11.4935,  -6.9416,   0.0736,
           0.0736,   0.0736,   0.0736,  -5.5235,  18.7365,   0.0736,   0.0736,
           5.3331,   0.0736,  -7.5042,   0.0736,   0.0736,   0.0736,   5.7863,
           0.0736]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -1.8089,   0.5364],
        [ -0.6464,  13.4032],
        [ 23.4298,   3.4840],
        [ 13.1889,  -0.0986],
        [ -1.5244,   1.2728],
        [ -1.8199,   0.9626],
        [ -1.4887,   1.4286],
        [ -2.5844,   4.7423],
        [ -1.3648,   1.4032],
        [ 11.9019,   1.3061],
        [ -1.3490,   1.3767],
        [ -2.2088,   4.3685],
        [-14.0259,  -2.3347],
        [-10.1705,   7.2058],
        [ -8.8006,  11.7184],
        [ -1.3710,   1.4082],
        [ -1.1553,   4.3001],
        [-13.6373,  -4.1811],
        [-12.2245,  -3.2064],
        [  3.4796,  13.6844],
        [ 11.2346,   3.3898],
        [ 13.4926,  12.6336]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ -6.1333,   8.1456,   1.6791, -11.7780,  -5.7994,  -5.9347,  -5.6374,
         -6.0823,  -5.7315, -11.4577,  -5.7647,  -5.9958,   5.3750,   3.1208,
          6.6743,  -5.7186,  -6.3842,   1.3720,  -3.3442,   8.6479,  -6.6753,
          6.7472], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 3.2525e-03, -2.2562e-01, -3.1755e+00, -4.7404e-01, -5.4108e-02,
         -8.1029e-03, -6.3213e-02, -7.4503e-02, -6.1508e-02, -4.5789e-01,
         -6.0932e-02, -7.7824e-02, -6.3006e-01, -2.3031e-01, -6.3978e-02,
         -6.1906e-02, -7.4793e-02, -4.6072e-01,  2.8980e-02, -4.0975e-01,
         -6.9392e-01, -2.3438e+00],
        [ 3.3737e-03, -2.2212e-01, -3.1752e+00, -4.7074e-01, -5.4398e-02,
         -8.1498e-03, -6.3588e-02, -7.5277e-02, -6.1867e-02, -4.5905e-01,
         -6.1282e-02, -7.8614e-02, -6.2891e-01, -2.3188e-01, -6.2810e-02,
         -6.2270e-02, -7.5607e-02, -4.5775e-01,  3.0413e-02, -4.0894e-01,
         -6.9507e-01, -2.3457e+00],
        [ 3.3738e-03, -2.2212e-01, -3.1752e+00, -4.7074e-01, -5.4398e-02,
         -8.1498e-03, -6.3588e-02, -7.5277e-02, -6.1867e-02, -4.5905e-01,
         -6.1282e-02, -7.8614e-02, -6.2891e-01, -2.3188e-01, -6.2810e-02,
         -6.2270e-02, -7.5607e-02, -4.5775e-01,  3.0413e-02, -4.0894e-01,
         -6.9507e-01, -2.3457e+00],
        [ 3.3737e-03, -2.2212e-01, -3.1752e+00, -4.7074e-01, -5.4398e-02,
         -8.1498e-03, -6.3587e-02, -7.5277e-02, -6.1867e-02, -4.5905e-01,
         -6.1282e-02, -7.8614e-02, -6.2891e-01, -2.3188e-01, -6.2810e-02,
         -6.2270e-02, -7.5607e-02, -4.5775e-01,  3.0413e-02, -4.0894e-01,
         -6.9507e-01, -2.3457e+00],
        [ 3.3737e-03, -2.2213e-01, -3.1752e+00, -4.7074e-01, -5.4398e-02,
         -8.1498e-03, -6.3587e-02, -7.5277e-02, -6.1867e-02, -4.5905e-01,
         -6.1282e-02, -7.8613e-02, -6.2891e-01, -2.3188e-01, -6.2813e-02,
         -6.2270e-02, -7.5606e-02, -4.5775e-01,  3.0411e-02, -4.0894e-01,
         -6.9507e-01, -2.3457e+00],
        [ 1.3302e-05, -3.0956e-01, -3.2030e+00, -6.4966e-01, -4.5483e-02,
         -7.2759e-03, -5.1401e-02, -5.3704e-02, -5.0112e-02, -4.4254e-01,
         -4.9981e-02, -5.6508e-02, -6.6902e-01, -1.8530e-01, -1.4336e-02,
         -5.0379e-02, -5.3086e-02, -5.2973e-01,  5.2990e-03, -4.4243e-01,
         -6.7161e-01, -2.2590e+00],
        [ 4.3070e-02, -1.2285e+01, -1.3257e+00, -6.2783e+00,  1.3797e-01,
          6.4312e-02,  6.4771e-02,  1.7456e-02,  3.8828e-02, -2.8393e+00,
          3.8721e-02, -3.5812e-02,  5.1900e+00, -2.0648e-02, -6.7562e+00,
          4.4769e-02,  1.0320e-02,  4.0134e+00,  2.8434e+00, -1.2283e+01,
          1.8491e-01, -5.1305e+00],
        [ 6.1405e-02,  4.3387e+00, -3.2486e+00, -6.7837e+00,  1.0101e-01,
          8.5895e-02,  1.3546e-01, -5.7212e-02,  1.3344e-01, -5.9948e+00,
          1.2825e-01,  1.0702e-02,  1.6592e+00,  4.4482e+00,  1.3438e+01,
          1.3644e-01, -2.2107e-01,  1.7915e+00, -3.3577e+00,  4.7933e+00,
         -2.1771e-01,  3.1502e+00],
        [-6.9731e-02,  2.1431e+01,  4.2050e+00,  1.0611e+01, -7.0580e-02,
         -8.0599e-02, -6.7188e-02,  1.0478e-02, -6.5918e-02,  7.6927e+00,
         -6.7565e-02,  2.3695e-02, -1.1292e+01,  3.3128e-01,  1.1241e+01,
         -6.5628e-02,  1.8811e-02, -9.7212e+00, -6.3995e+00,  2.3044e+01,
          9.6912e+00,  1.8147e+01],
        [ 3.3737e-03, -2.2213e-01, -3.1752e+00, -4.7074e-01, -5.4398e-02,
         -8.1498e-03, -6.3587e-02, -7.5276e-02, -6.1867e-02, -4.5905e-01,
         -6.1282e-02, -7.8613e-02, -6.2891e-01, -2.3188e-01, -6.2815e-02,
         -6.2269e-02, -7.5606e-02, -4.5775e-01,  3.0411e-02, -4.0894e-01,
         -6.9507e-01, -2.3457e+00],
        [ 3.3738e-03, -2.2212e-01, -3.1752e+00, -4.7074e-01, -5.4398e-02,
         -8.1498e-03, -6.3588e-02, -7.5277e-02, -6.1867e-02, -4.5905e-01,
         -6.1282e-02, -7.8614e-02, -6.2891e-01, -2.3188e-01, -6.2812e-02,
         -6.2270e-02, -7.5607e-02, -4.5775e-01,  3.0413e-02, -4.0894e-01,
         -6.9507e-01, -2.3457e+00],
        [ 1.0781e-01, -2.9671e+01, -8.3627e+00, -1.1149e+01,  1.4150e-01,
          1.4997e-01,  1.5472e-01, -1.5044e-02,  1.3898e-01, -5.1960e-01,
          1.3527e-01, -2.4752e-03,  8.1638e+00, -3.7765e+00, -1.3586e+01,
          1.4037e-01, -8.5898e-03,  8.5287e+00,  5.3300e+00, -3.5078e+01,
         -2.2219e+00, -2.9333e+01],
        [ 3.3737e-03, -2.2212e-01, -3.1752e+00, -4.7074e-01, -5.4398e-02,
         -8.1498e-03, -6.3588e-02, -7.5277e-02, -6.1867e-02, -4.5905e-01,
         -6.1282e-02, -7.8614e-02, -6.2891e-01, -2.3188e-01, -6.2809e-02,
         -6.2270e-02, -7.5607e-02, -4.5775e-01,  3.0413e-02, -4.0894e-01,
         -6.9507e-01, -2.3457e+00],
        [-8.5764e-02,  3.3871e+00,  3.8351e+00, -4.0397e+00, -1.5204e-01,
         -1.1778e-01, -1.4967e-01,  6.6557e-01, -1.5018e-01, -2.6753e+00,
         -1.4946e-01,  7.0803e-01,  5.6488e+00,  6.3794e-01,  1.2335e+00,
         -1.4974e-01,  6.0934e-01,  2.7242e+00,  3.2336e-02,  3.5215e+00,
         -2.2706e+00, -1.0311e+00],
        [-2.0444e-01, -5.3479e-01,  3.3927e+00,  4.0647e+00, -3.5304e-01,
         -2.6973e-01, -2.7410e-01,  8.4805e-02, -2.9027e-01,  1.6213e+00,
         -2.8475e-01,  3.5863e-01, -1.1336e-01, -6.3481e+00, -3.6828e+00,
         -2.8887e-01,  2.3384e-01, -1.7631e+00, -4.6302e+00, -2.1582e+00,
          1.3622e+01, -2.4533e+00],
        [ 3.3738e-03, -2.2212e-01, -3.1752e+00, -4.7074e-01, -5.4398e-02,
         -8.1499e-03, -6.3588e-02, -7.5278e-02, -6.1867e-02, -4.5905e-01,
         -6.1282e-02, -7.8615e-02, -6.2891e-01, -2.3188e-01, -6.2810e-02,
         -6.2270e-02, -7.5607e-02, -4.5774e-01,  3.0414e-02, -4.0894e-01,
         -6.9507e-01, -2.3457e+00],
        [-4.1060e-04,  4.6241e-01,  3.8875e+00,  1.5796e+00,  1.0491e-02,
          1.8576e-04,  3.1068e-02,  1.0463e-01,  2.8692e-02,  2.2385e-01,
          2.5076e-02,  1.0317e-01,  9.9526e-01,  1.2754e-01,  1.9146e-01,
          2.9522e-02,  1.0707e-01,  5.7642e-01,  3.5478e-02,  9.4689e-01,
          4.3589e-01,  1.5928e+00],
        [ 8.6988e-02, -1.0383e+01, -9.8530e-01, -2.8162e+00,  2.2277e-01,
          2.2077e-01,  2.1471e-01, -4.6268e-02,  2.0249e-01, -3.8591e+00,
          1.9993e-01, -4.5748e-02,  2.9114e+00,  3.0686e+00,  2.1337e+00,
          2.0287e-01, -5.3217e-02,  3.9731e+00,  5.1076e+00, -1.3486e+01,
         -2.7506e+00,  3.6855e-01],
        [-1.6977e-01, -4.0111e+00,  2.7228e+00, -8.9500e+00, -2.0314e-01,
         -2.4362e-01, -2.0739e-01, -1.3504e+00, -1.7993e-01, -4.0013e+00,
         -1.7909e-01, -2.6195e+00,  7.0363e-01, -2.5426e-02,  3.0216e+00,
         -1.8329e-01, -2.3446e+00,  3.1606e+00,  4.3276e-01, -2.7307e+00,
          1.0883e+00, -1.7693e+00],
        [-4.9506e-02, -1.6340e+01, -2.0610e+00, -3.6319e+00, -8.4525e-02,
         -7.5587e-02, -8.8792e-02, -5.3223e-03, -8.4776e-02, -1.1545e+00,
         -8.3430e-02, -1.3296e-02,  5.7492e+00,  4.3133e+00, -1.9308e+00,
         -8.5189e-02, -5.6267e-03,  6.1080e+00,  6.8144e+00, -1.8270e+01,
         -8.5158e+00, -5.9758e+00],
        [ 1.0263e-01, -5.6967e-01, -2.2187e+00, -2.1648e+00, -4.0539e-01,
         -2.0179e-01, -4.7729e-01,  2.0864e-01, -5.0482e-01,  3.2136e-01,
         -4.8833e-01,  3.7807e-03, -6.3854e+00, -1.2510e-01,  2.3641e+00,
         -5.0290e-01,  2.9846e-01, -1.0811e+00, -8.0662e-02,  6.4114e-01,
          3.5530e-01, -3.6645e-01],
        [-2.9574e-01,  4.7866e+00, -3.7871e+00, -1.1290e+01, -6.9369e-01,
         -4.0977e-01, -7.7836e-01,  2.4935e+00, -8.1065e-01, -2.8658e+00,
         -7.8780e-01,  7.2682e-01,  1.7658e+00,  5.4596e+00,  4.9382e+00,
         -8.0592e-01,  1.9613e+00,  2.8265e+00, -2.6494e-01,  3.0417e+00,
         -6.9914e+00, -1.7141e-01]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-3.2790, -3.2785, -3.2785, -3.2785, -3.2785, -3.3146,  2.2187, -4.8378,
        -2.6116, -3.2785, -3.2785, -1.7864, -3.2785,  4.0959,  4.5455, -3.2785,
         4.3714, -1.4818,  3.1167, -0.1653, -2.6326, -4.5930], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-3.4951e-04, -3.4891e-04, -3.4891e-04, -3.4891e-04, -3.4891e-04,
         -3.5337e-04, -6.0804e-03, -7.8232e-01, -1.8625e+00, -3.4891e-04,
         -3.4891e-04,  1.5545e-05, -3.4891e-04, -1.8486e+00, -1.8553e+00,
         -3.4891e-04, -1.8627e+00, -4.9415e-03, -3.0119e-01, -1.6042e-03,
         -1.0581e-02, -3.4561e-02],
        [ 7.7210e-04,  7.7365e-04,  7.7365e-04,  7.7365e-04,  7.7365e-04,
          6.3077e-04, -7.6469e-03, -3.7466e-01, -1.0273e+00,  7.7365e-04,
          7.7365e-04, -6.5258e-05,  7.7365e-04, -1.0435e+00, -1.0165e+00,
          7.7365e-04, -1.0279e+00, -9.0744e-03, -2.0892e-01, -2.2977e-03,
          9.4515e-03, -2.6835e-02],
        [-1.9398e-04, -1.9338e-04, -1.9338e-04, -1.9338e-04, -1.9338e-04,
         -2.3000e-04, -6.0253e-03, -7.1208e-01, -1.7390e+00, -1.9338e-04,
         -1.9338e-04, -1.1833e-05, -1.9338e-04, -1.7228e+00, -1.7321e+00,
         -1.9338e-04, -1.7392e+00, -6.5164e-03, -2.6588e-01, -4.1763e-05,
         -7.9638e-03, -3.3242e-02],
        [-2.2123e-04, -2.2133e-04, -2.2133e-04, -2.2133e-04, -2.2133e-04,
         -2.1151e-04, -7.4468e-03, -6.5333e-01, -1.5574e+00, -2.2133e-04,
         -2.2133e-04, -1.4224e-05, -2.2133e-04, -1.5433e+00, -1.5515e+00,
         -2.2133e-04, -1.5577e+00, -6.3271e-03, -2.4821e-01, -6.1929e-06,
         -7.9806e-03, -2.7619e-02],
        [ 7.5551e-01,  7.5662e-01,  7.5662e-01,  7.5662e-01,  7.5662e-01,
          6.9282e-01,  4.1624e+00, -7.7102e-02, -3.0174e+00,  7.5662e-01,
          7.5663e-01, -2.2525e+01,  7.5662e-01,  3.7388e+00,  3.4103e+00,
          7.5662e-01,  3.5571e+00,  3.7465e+00,  2.1622e+00,  6.5354e+00,
          8.9724e-01,  1.2891e-01],
        [-6.0224e-04, -6.0544e-04, -6.0544e-04, -6.0544e-04, -6.0544e-04,
         -3.3998e-04, -3.4434e-03, -5.7027e-01, -1.3266e+00, -6.0544e-04,
         -6.0544e-04,  1.1355e-04, -6.0543e-04, -1.3149e+00, -1.3182e+00,
         -6.0544e-04, -1.3268e+00, -4.1681e-03, -1.8826e-01, -5.2687e-04,
         -1.3226e-02, -2.7995e-02],
        [-2.7673e-04, -2.7728e-04, -2.7728e-04, -2.7728e-04, -2.7728e-04,
         -1.9212e-04, -8.0040e-03, -6.0619e-01, -1.5837e+00, -2.7728e-04,
         -2.7728e-04, -2.5792e-05, -2.7728e-04, -1.5639e+00, -1.5782e+00,
         -2.7728e-04, -1.5840e+00, -8.2417e-03, -2.5663e-01, -2.2691e-04,
         -6.7371e-03, -2.5781e-02],
        [-7.0372e-01, -7.0761e-01, -7.0761e-01, -7.0762e-01, -7.0761e-01,
         -6.0800e-01,  4.6457e+00,  3.9455e-01,  2.8918e+00, -7.0761e-01,
         -7.0761e-01, -1.4234e+01, -7.0761e-01,  1.0832e+00,  1.4067e+00,
         -7.0762e-01,  1.0107e+00,  2.3405e+00,  2.2410e+00,  3.4811e+00,
          4.0023e+00,  2.1016e-01],
        [-2.4214e-04, -2.4239e-04, -2.4239e-04, -2.4239e-04, -2.4239e-04,
         -2.1609e-04, -8.1841e-03, -6.7978e-01, -1.6582e+00, -2.4239e-04,
         -2.4239e-04, -1.1619e-05, -2.4239e-04, -1.6429e+00, -1.6516e+00,
         -2.4239e-04, -1.6584e+00, -6.5568e-03, -2.6834e-01, -1.3480e-04,
         -8.0536e-03, -2.9993e-02],
        [ 9.4613e-04,  9.4859e-04,  9.4859e-04,  9.4859e-04,  9.4859e-04,
          4.7859e-04, -1.7873e-02, -5.4497e-01, -1.4009e+00,  9.4859e-04,
          9.4859e-04,  2.8794e-05,  9.4858e-04, -1.3923e+00, -1.3976e+00,
          9.4859e-04, -1.4018e+00, -1.0259e-02, -3.5296e-01, -1.0746e-03,
         -4.6924e-03, -3.3285e-02],
        [ 1.2472e-01,  1.2511e-01,  1.2511e-01,  1.2511e-01,  1.2511e-01,
          1.1732e-01, -2.9101e+01,  5.2367e+00,  3.3750e+00,  1.2511e-01,
          1.2511e-01,  1.2988e-05,  1.2511e-01, -7.1890e-01, -9.8266e-01,
          1.2511e-01, -6.8787e-01, -1.6814e+01,  3.2356e+00, -1.8973e+01,
          8.0438e-01,  2.4821e+00],
        [-3.3042e-01, -3.3205e-01, -3.3205e-01, -3.3205e-01, -3.3204e-01,
         -3.7656e-01,  7.8810e-01, -1.8486e-01,  5.3404e+00, -3.3204e-01,
         -3.3204e-01,  3.1242e+01, -3.3205e-01,  5.1358e-01,  9.6071e-01,
         -3.3205e-01,  5.8378e-01, -4.5616e+00,  1.4762e+00, -7.4349e+00,
         -2.8148e+00, -2.7746e-01],
        [-2.2180e-04, -2.2250e-04, -2.2250e-04, -2.2250e-04, -2.2250e-04,
         -1.8115e-04, -3.6593e-03, -7.5409e-01, -1.8392e+00, -2.2250e-04,
         -2.2250e-04, -1.4328e-05, -2.2250e-04, -1.8245e+00, -1.8322e+00,
         -2.2250e-04, -1.8394e+00, -4.3383e-03, -2.8834e-01, -6.2157e-04,
         -8.8285e-03, -3.3905e-02],
        [-2.3104e-04, -2.3044e-04, -2.3044e-04, -2.3044e-04, -2.3044e-04,
         -2.5036e-04, -5.8401e-03, -7.6604e-01, -1.8245e+00, -2.3044e-04,
         -2.3044e-04,  1.0395e-05, -2.3044e-04, -1.8103e+00, -1.8176e+00,
         -2.3044e-04, -1.8247e+00, -5.1359e-03, -2.8774e-01, -8.1415e-04,
         -1.0277e-02, -3.4288e-02]], device='cuda:0'))])
xi:  [1317.6278]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 1727.5239364570693
W_T_median: 1690.4745784024835
W_T_pctile_5: 1329.193497496973
W_T_CVAR_5_pct: 804.7847932495389
Average q (qsum/M+1):  48.66785849294355
Optimal xi:  [1317.6278]
Expected(across Rb) median(across samples) p_equity:  8.02992103506502e-07
obj fun:  tensor(-3920.4899, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/factor_decumulation/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:262: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/factor_decumulation/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/factor_decumulation/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: MC_everything
Objective function: mean_cvar_single_level
Tracing param: 3.0
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       22  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       22  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 22)      True          22  
0     (22, 22)      True          22  
0      (22, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       22  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       22  logistic_sigmoid   
0        obj.layers[3]         3  output_layer       14           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 22)      True          22  
0     (22, 22)      True          22  
0     (22, 14)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -8.5715,   6.4621],
        [ -8.3669,  -9.0182],
        [ -5.1223,   3.2445],
        [  8.0669,   4.1508],
        [-11.4280,  -6.0457],
        [ -6.4858,   4.0851],
        [  6.0779,   4.9126],
        [  9.1747,   0.7713],
        [ -8.3119,   6.0846],
        [ -8.3147,   6.0977],
        [ -8.4882,   6.6116],
        [ -8.6931,   5.7529],
        [  7.8819,   3.3034],
        [ -1.2974,   1.0853],
        [  5.4594,  -0.3288],
        [  5.2299,   5.2824],
        [-11.7613,  -7.4762],
        [  7.7973,   4.2640],
        [ -8.5799,   5.8746],
        [ -7.8535,   5.7472],
        [ -1.2944,   1.0845],
        [-21.4386,  -5.7294]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ 4.8764, -5.7404, -3.0406, -9.5323, -3.7687, -2.3429, -8.4043, -9.1228,
         4.2727,  3.0356,  5.1757,  1.5461, -8.9288, -3.8883, -8.9159, -8.5427,
        -4.0692, -9.2749,  1.8685,  2.4405, -3.8889, -4.6902], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1574e-03, -1.6502e-02, -2.2728e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1088e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [-9.2453e+00,  1.2482e+01, -7.2066e-01,  7.0332e+00,  4.6981e+00,
         -1.2007e+00,  4.5523e+00,  6.2080e+00, -7.5674e+00, -3.0869e+00,
         -1.0021e+01, -1.8126e+00,  5.8578e+00, -1.6237e-01,  6.8999e-01,
          5.4520e+00,  8.4865e+00,  8.0426e+00, -2.2762e+00, -3.8127e+00,
         -1.9618e-01,  8.7135e+00],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2751e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-9.6515e+00,  1.3280e+01, -9.1434e-01,  9.3871e+00,  5.7620e+00,
         -1.3190e+00,  6.4927e+00,  6.8045e+00, -8.3770e+00, -3.3906e+00,
         -1.0939e+01, -2.1716e+00,  6.5179e+00, -2.1870e-01,  2.0491e+00,
          4.1453e+00,  9.2888e+00,  7.8384e+00, -2.6898e+00, -4.4743e+00,
         -1.9003e-01,  9.7752e+00],
        [-7.9773e+00,  1.0315e+01,  2.5895e-01,  4.6608e+00,  4.9211e+00,
          1.7041e-02,  2.1882e+00,  6.8647e+00, -6.6734e+00, -4.8263e+00,
         -8.8073e+00, -2.8795e+00,  6.4311e+00,  1.6629e-01,  1.1111e+00,
          5.0411e+00,  7.6765e+00,  1.1081e+01, -3.5739e+00, -4.0927e+00,
          1.6082e-01,  8.5887e+00],
        [-7.6589e+00,  9.2592e+00,  7.9739e-02,  3.9257e+00,  4.5700e+00,
          1.0005e-01,  2.1053e+00,  4.6166e+00, -6.0015e+00, -3.8545e+00,
         -9.2106e+00, -1.7570e+00,  5.7099e+00, -1.2986e-02,  5.9836e-02,
          4.9159e+00,  7.0161e+00,  9.4703e+00, -2.3319e+00, -3.1763e+00,
         -1.3208e-02,  7.3285e+00],
        [-2.2581e-01, -1.6549e-01,  1.7511e-03, -1.2938e-02, -1.1903e-01,
          1.1578e-03, -1.6509e-02, -2.2839e-03, -1.8738e-01, -6.9338e-02,
         -2.5288e-01, -1.2692e-02, -9.1165e-03,  1.2292e-02,  1.9855e-02,
         -1.7662e-02, -1.7966e-01, -1.2937e-02, -1.9683e-02, -4.9682e-02,
          1.2307e-02, -3.1400e-02],
        [-2.2584e-01, -1.6546e-01,  1.7508e-03, -1.2931e-02, -1.1901e-01,
          1.1573e-03, -1.6502e-02, -2.2704e-03, -1.8735e-01, -6.9322e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9856e-02,
         -1.7657e-02, -1.7959e-01, -1.2929e-02, -1.9678e-02, -4.9672e-02,
          1.2308e-02, -3.1398e-02],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2752e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2730e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1088e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [-7.4230e+00,  9.2761e+00,  8.2691e-02,  4.6883e+00,  4.4150e+00,
          1.2211e-01,  2.9895e+00,  3.5408e+00, -6.2114e+00, -3.5923e+00,
         -9.4198e+00, -1.8627e+00,  4.7011e+00, -1.9985e-02, -6.0281e-02,
          5.2032e+00,  7.0797e+00,  8.3206e+00, -2.3235e+00, -3.3515e+00,
         -1.9947e-02,  7.4397e+00],
        [ 7.9326e+00, -1.0706e+01,  4.0837e-01, -9.2089e+00, -5.7725e+00,
          6.6403e-01, -4.8629e+00, -5.8385e+00,  6.6214e+00,  5.0109e+00,
          9.6232e+00,  3.3999e+00, -5.8456e+00, -1.3669e-01, -1.4453e+00,
         -3.3601e+00, -8.4017e+00, -9.5444e+00,  3.9084e+00,  4.3412e+00,
         -1.3169e-01, -9.7519e+00],
        [-2.2583e-01, -1.6545e-01,  1.7507e-03, -1.2931e-02, -1.1900e-01,
          1.1572e-03, -1.6503e-02, -2.2678e-03, -1.8733e-01, -6.9320e-02,
         -2.5297e-01, -1.2687e-02, -9.1093e-03,  1.2293e-02,  1.9856e-02,
         -1.7657e-02, -1.7958e-01, -1.2930e-02, -1.9677e-02, -4.9670e-02,
          1.2308e-02, -3.1399e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2931e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2732e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [ 6.5891e-01,  3.0868e-01,  8.3566e-03,  3.5747e-02,  2.1159e-01,
          5.3475e-03,  5.7464e-02,  2.6629e-01,  5.5272e-01,  2.6083e-01,
          7.4008e-01,  8.5701e-02,  7.1654e-02,  3.7717e-02,  5.6900e-02,
          8.1005e-02,  2.9146e-01,  3.6840e-02,  1.1119e-01,  2.1066e-01,
          3.7716e-02,  1.3910e-01],
        [-2.2585e-01, -1.6548e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2733e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1087e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2307e-02, -3.1398e-02],
        [-7.5648e+00,  9.6323e+00,  3.4567e-02,  4.2023e+00,  4.4635e+00,
         -1.3328e-01,  2.0401e+00,  5.3264e+00, -6.2784e+00, -3.7048e+00,
         -9.3470e+00, -2.0562e+00,  5.8618e+00, -3.3635e-02,  2.0363e-01,
          5.0433e+00,  7.2814e+00,  9.5323e+00, -2.4148e+00, -3.3678e+00,
         -3.5727e-02,  7.7623e+00],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2750e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2744e-03, -1.8737e-01, -6.9326e-02,
         -2.5298e-01, -1.2689e-02, -9.1087e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2931e-02, -1.1901e-01,
          1.1574e-03, -1.6502e-02, -2.2722e-03, -1.8735e-01, -6.9324e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9673e-02,
          1.2308e-02, -3.1398e-02],
        [ 6.6450e-01,  3.1201e-01,  8.4127e-03,  3.4696e-02,  2.1235e-01,
          5.3877e-03,  5.6376e-02,  2.6891e-01,  5.5678e-01,  2.6166e-01,
          7.4701e-01,  8.5769e-02,  7.1346e-02,  3.8211e-02,  5.7275e-02,
          8.0058e-02,  2.9347e-01,  3.5786e-02,  1.1132e-01,  2.1139e-01,
          3.8209e-02,  1.3913e-01],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2753e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-2.4313,  0.0078, -2.4313,  0.0873, -0.2625, -0.5234, -2.4313, -2.4314,
        -2.4313, -2.4313, -0.4369, -0.2571, -2.4314, -2.4313,  4.5769, -2.4313,
        -0.4006, -2.4313, -2.4313, -2.4313,  4.6668, -2.4313], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[  0.0334, -10.4940,   0.0334, -15.8008,  -9.7979,  -6.9452,   0.0334,
           0.0334,   0.0334,   0.0334,  -7.0927,  14.9535,   0.0334,   0.0334,
           4.2936,   0.0334,  -7.0565,   0.0334,   0.0334,   0.0334,   4.7631,
           0.0334]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 1.0813e+01,  2.9656e+00],
        [ 5.5664e-01,  1.1757e+01],
        [ 1.8618e+01,  2.3664e+00],
        [ 1.0637e+01,  1.5273e-02],
        [-1.4941e+01, -2.2181e+00],
        [-1.2849e+00,  1.3570e+00],
        [-1.2800e+00,  1.3116e+00],
        [-1.7122e+00,  6.5637e-01],
        [-2.0284e+00,  2.5259e-01],
        [ 9.3477e+00, -5.2188e-01],
        [-1.9314e+00,  2.3251e-01],
        [-1.8788e+00,  4.0167e-01],
        [-1.0523e+01, -1.6251e+00],
        [-8.3398e+00,  5.3496e+00],
        [-7.4426e+00,  1.0247e+01],
        [-1.2446e+01, -2.8588e+00],
        [-1.4240e+01, -3.1016e+00],
        [-1.0901e+01, -2.0063e+00],
        [-1.0106e+01, -2.4687e+00],
        [ 3.1771e+00,  1.1429e+01],
        [ 1.0907e+01,  2.2476e+00],
        [ 1.1102e+01,  1.0847e+01]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-5.5365,  7.0663,  2.9709, -9.6018, -1.5848, -4.5127, -4.5185, -4.9090,
        -4.9531, -9.4875, -4.9847, -4.9560,  5.4223,  3.0397,  6.7011, -3.5168,
        -2.9913,  3.2472,  0.4201,  7.7652, -4.3018,  6.4326], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 6.1957e-01, -3.4634e+00, -1.7479e+00,  1.1905e+00,  1.2460e-02,
          1.1948e-01,  1.3226e-01,  4.3984e-02, -1.1598e-02,  1.0215e+00,
         -6.1706e-03,  2.4414e-03, -2.5313e+00,  1.1746e+00, -7.8526e-01,
         -9.2734e-03,  2.7572e-03, -2.7562e+00, -1.8971e+00, -2.6434e+00,
         -4.2419e-01,  3.0293e-02],
        [-4.6968e-01, -1.5418e-01, -2.2179e+00, -4.7229e-01, -1.4815e-02,
         -2.6861e-02, -2.4100e-02,  6.5293e-03, -1.5585e-02, -3.8766e-01,
         -1.6068e-02, -1.1227e-02, -1.0214e+00, -1.1716e-01, -1.0616e-01,
         -5.8386e-03, -7.9498e-03, -5.2026e-01, -1.9652e-01, -4.4158e-01,
         -1.2068e+00, -1.2289e+00],
        [-9.0043e-01, -3.1328e-01, -2.4749e+00, -1.0214e+00, -5.5072e-03,
         -2.2407e-02, -1.9453e-02, -7.7448e-03,  4.4606e-03, -9.3610e-01,
          4.1020e-03,  2.5876e-03, -1.2488e+00, -4.6992e-02, -9.2699e-02,
         -2.2626e-03, -3.5666e-03, -6.7176e-01, -2.4800e-01, -8.7567e-01,
         -1.3802e+00, -7.7155e-01],
        [-4.7184e-01, -1.5540e-01, -2.2143e+00, -4.7815e-01, -1.4473e-02,
         -2.7281e-02, -2.4476e-02,  6.5809e-03, -1.5495e-02, -3.9563e-01,
         -1.5975e-02, -1.1107e-02, -1.0396e+00, -1.1822e-01, -1.0605e-01,
         -5.8775e-03, -7.9716e-03, -5.2621e-01, -1.9589e-01, -4.4421e-01,
         -1.2127e+00, -1.2341e+00],
        [-4.8450e-01, -1.6921e-01, -2.2399e+00, -4.9569e-01, -1.4212e-02,
         -2.5472e-02, -2.2971e-02,  5.3544e-03, -1.0943e-02, -4.2767e-01,
         -1.1482e-02, -7.9784e-03, -1.0434e+00, -1.0826e-01, -9.0719e-02,
         -6.2509e-03, -8.3116e-03, -5.2892e-01, -2.1129e-01, -4.5420e-01,
         -1.2241e+00, -1.0613e+00],
        [ 3.0119e-01,  9.1885e-01, -1.5837e+00, -8.5542e-01, -1.1953e-02,
         -1.9274e+00, -1.8752e+00, -1.4092e+00, -5.5076e-01,  1.0780e+00,
         -4.5548e-01, -9.9188e-01, -3.9286e+00,  1.1415e+00,  2.2999e+00,
         -1.2239e-02, -1.3323e-02, -2.7068e+00, -9.7625e-01,  4.2057e-01,
         -1.0808e+00, -1.2393e+00],
        [ 2.4582e-01, -1.1721e+01,  5.7285e-01, -6.6182e+00,  3.3458e+00,
          1.7362e-01,  1.7999e-01,  2.0080e-01,  2.8786e-01, -4.5146e+00,
          2.9196e-01,  1.9339e-01,  3.6973e+00, -2.2846e+00, -8.2839e+00,
          2.5629e+00,  2.7897e+00,  3.3397e+00,  3.6998e+00, -1.2216e+01,
          1.0269e-01, -7.8724e+00],
        [-2.7710e+00,  3.8384e+00, -3.8614e+00, -5.2497e+00,  1.4955e-01,
         -5.1488e-01, -5.0931e-01, -4.0831e-01, -1.3933e-01, -4.9036e+00,
         -1.0681e-01, -2.8754e-01,  2.6586e+00,  3.1018e+00,  6.0454e+00,
          5.3721e-01,  5.1709e-01,  2.4000e+00,  1.7467e+00,  2.8980e+00,
         -1.8615e+00,  1.3298e+00],
        [ 5.3996e+00,  1.7695e+01,  2.7980e+00,  6.7002e+00, -6.8933e+00,
          1.9716e-02,  1.5955e-02,  1.6031e-02, -1.9886e-01,  4.1219e+00,
         -1.8883e-01,  2.3240e-02, -8.0362e+00,  3.0849e+00,  1.4710e+01,
         -3.3033e+00, -3.8057e+00, -7.4740e+00, -6.2744e+00,  1.9113e+01,
          5.0855e+00,  2.1580e+01],
        [-4.6054e-01, -1.5864e-01, -2.1828e+00, -4.7962e-01, -1.3132e-02,
         -2.7434e-02, -2.4527e-02,  7.6509e-03, -1.3661e-02, -3.9854e-01,
         -1.4154e-02, -9.5939e-03, -1.0591e+00, -1.2246e-01, -9.9910e-02,
         -5.2767e-03, -7.3107e-03, -5.5050e-01, -2.1282e-01, -4.5037e-01,
         -1.2105e+00, -1.2384e+00],
        [-9.3210e-01, -5.0637e-01, -2.5650e+00, -1.2297e+00,  5.1007e-03,
         -1.3266e-02, -1.0812e-02, -6.5037e-03, -1.3910e-03, -1.1288e+00,
         -1.7836e-03, -1.9456e-03, -7.9371e-01, -5.5349e-02, -8.6527e-02,
          5.2059e-03,  5.8080e-03, -8.8163e-01, -4.5943e-01, -1.6628e+00,
         -1.1149e+00, -5.6400e-01],
        [-2.8460e+00, -1.8825e+01, -9.7046e+00, -3.0631e+00,  6.2381e+00,
          2.2284e-02,  2.2216e-02,  3.8058e-02,  1.2254e-02, -4.6393e+00,
          2.0356e-03,  4.3669e-02,  7.6060e+00, -3.1393e+00, -1.1899e+01,
          2.9927e+00,  3.5772e+00,  7.5127e+00,  7.0486e+00, -2.2653e+01,
         -1.0357e+01, -2.5603e+01],
        [-4.7448e-01, -1.5413e-01, -2.2021e+00, -4.7761e-01, -1.5017e-02,
         -2.6936e-02, -2.4189e-02,  6.2971e-03, -1.5709e-02, -3.9518e-01,
         -1.6194e-02, -1.1365e-02, -1.0353e+00, -1.1675e-01, -1.0676e-01,
         -6.0131e-03, -8.0879e-03, -5.2030e-01, -1.9318e-01, -4.4328e-01,
         -1.2192e+00, -1.2259e+00],
        [-6.9231e-01,  3.0014e+00,  2.7786e+00, -1.3175e+00,  3.0620e-04,
         -1.3308e-01, -1.3059e-01, -4.6677e-03, -1.5150e-02, -1.3574e+00,
         -1.8928e-02, -2.6791e-03,  2.1880e+00, -4.4040e-01,  8.1953e-01,
         -1.8323e-02, -1.1176e-02,  1.4720e+00,  4.3629e-01,  2.4554e+00,
          8.6002e-02, -2.4341e-01],
        [ 3.0175e+00, -1.5929e-01,  3.1082e+00,  1.6836e+00, -3.7655e+00,
          1.7569e-01,  1.8810e-01,  2.3150e-01, -5.4313e-01,  3.8072e+00,
         -5.3327e-01,  1.6719e-01,  6.0672e-02, -2.5586e+00, -3.6155e+00,
         -4.5190e+00, -4.8662e+00,  1.6404e-01, -1.7814e-01, -2.9936e-01,
          2.7050e+00, -1.8862e+00],
        [-6.1343e-01, -2.0997e-01, -2.3786e+00, -7.6186e-01, -1.9840e-02,
         -3.2273e-02, -3.0458e-02, -4.7454e-03,  5.8161e-03, -6.4208e-01,
          6.0534e-03,  3.5540e-03, -1.0330e+00, -6.3106e-02, -1.0050e-01,
         -7.6629e-03, -1.3412e-02, -4.8643e-01, -1.8407e-01, -5.2743e-01,
         -1.3866e+00, -9.2565e-01],
        [ 2.3232e-01,  3.1081e+00,  2.1861e+00,  1.7924e+00,  8.3474e-01,
         -4.2057e-01, -3.7750e-01, -8.6959e-02, -6.3586e-02,  1.4179e+00,
         -6.1088e-02, -4.4329e-02,  1.9436e-01, -4.4091e-01,  1.1123e+00,
          4.9760e-01,  7.0823e-01, -1.6870e-01, -3.9429e-01, -1.1351e+00,
          1.7979e-02, -1.2019e+00],
        [-9.3911e-03, -3.8280e+00, -3.1866e-01, -2.0025e+00, -3.0075e-02,
          4.3973e-02,  5.3990e-02,  1.0353e-01,  1.4874e-01, -1.8588e+00,
          1.5683e-01,  1.3914e-01, -1.0725e-01, -2.1520e-01, -2.7783e-01,
          5.4541e-02,  7.3731e-03, -1.3880e+00, -8.0744e-01, -5.4071e+00,
         -9.3933e-01,  6.6525e-02],
        [-2.0923e+00,  1.6783e+00,  2.1031e+00, -6.6800e+00,  1.9109e-04,
         -8.2756e-01, -7.5222e-01, -4.3503e-01, -1.2713e-01, -3.5556e+00,
         -7.5366e-02, -3.3382e-01,  9.4887e+00, -1.2212e+00,  5.7869e+00,
         -6.4339e-04, -3.5999e-03,  9.1765e+00,  6.6382e+00,  6.8362e-01,
          2.7993e-01, -2.2562e+00],
        [-5.5183e+00, -1.5095e+01, -2.8824e-01, -4.9346e+00,  5.3321e+00,
          1.5448e-01,  1.5735e-01,  1.6104e-01,  5.9928e-01, -2.7075e+00,
          5.5855e-01,  1.3923e-01,  3.0535e+00,  8.4196e-01, -6.5453e+00,
          4.6053e+00,  5.0922e+00,  3.6158e+00,  3.8865e+00, -1.4997e+01,
         -2.8857e+00, -4.2056e+00],
        [ 4.0156e-01, -1.0952e+00, -1.5738e+00, -4.3123e-01, -8.5229e-03,
         -6.6402e-01, -6.0136e-01, -2.4497e-01, -5.3144e-02, -2.8255e-01,
         -5.5575e-02, -9.1214e-02, -2.1121e+00,  1.5978e+00,  1.4435e+00,
         -1.0813e-03, -1.8711e-03, -2.1573e+00, -8.6345e-01, -1.7321e+00,
         -7.5512e-01,  5.2300e-01],
        [-1.9858e+00,  2.9033e+00, -2.5269e+00, -2.1485e+00,  2.2962e+00,
         -1.4441e+00, -1.3739e+00, -7.3427e-01,  6.2891e-02,  2.1944e-01,
          6.1358e-02, -2.6440e-01,  7.4516e-02,  1.7016e+00,  3.0581e+00,
          1.5196e+00,  1.8766e+00,  6.5632e-01,  1.1298e+00,  1.3664e+00,
         -2.7325e+00, -7.5516e-01]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-1.8466, -2.2256, -2.5068, -2.1943, -2.2514, -1.8834,  0.6255, -4.9456,
        -2.2024, -2.2158, -2.5964,  0.0491, -2.2135,  3.0825,  3.0734, -2.4047,
         2.5296, -1.0040,  2.4991, -0.5295, -2.0766, -2.4070], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-1.5234e-02,  7.2296e-05, -1.5502e-04,  5.9106e-05,  9.2680e-05,
         -2.2228e-02, -7.7352e-03, -1.5990e-01, -1.5103e+00,  6.1218e-05,
         -1.5306e-04, -1.3007e-05,  6.3929e-05, -1.5060e+00, -1.5008e+00,
         -2.1007e-04, -1.4999e+00, -5.4381e-03, -6.9054e-01, -3.7369e-03,
         -4.7102e-03, -3.5212e-02],
        [-8.7292e-03, -1.4222e-03,  7.6021e-04, -1.3898e-03, -1.5771e-03,
         -1.3307e-02, -5.1882e-03, -1.0878e-01, -8.2132e-01, -1.3260e-03,
          8.8522e-04, -2.6449e-04, -1.4244e-03, -8.2289e-01, -8.1366e-01,
          5.1250e-04, -8.1735e-01,  1.2221e-03, -3.1415e-01, -6.8756e-03,
          4.4122e-03, -3.5269e-02],
        [-2.1229e-02, -5.1093e-04, -3.4543e-04, -5.1941e-04, -5.4632e-04,
         -1.8385e-02, -9.4420e-03, -1.3731e-01, -1.4218e+00, -5.2075e-04,
         -3.2211e-04,  2.3184e-05, -5.1689e-04, -1.4173e+00, -1.4127e+00,
         -3.8173e-04, -1.4125e+00, -6.1909e-03, -6.2055e-01, -3.7929e-03,
         -7.1839e-03, -2.7972e-02],
        [-9.4172e-03, -2.1938e-04, -2.2482e-04, -2.0759e-04, -2.8288e-04,
         -1.6622e-02, -7.4112e-03, -1.3137e-01, -1.2415e+00, -2.0252e-04,
         -2.1593e-04, -7.4338e-05, -2.1553e-04, -1.2385e+00, -1.2343e+00,
         -1.4845e-04, -1.2328e+00, -5.0361e-03, -5.7108e-01, -3.7365e-03,
         -7.0540e-03, -2.5170e-02],
        [-1.0969e+00,  7.0714e-02,  2.8031e-01,  4.2693e-02,  2.8583e-01,
          5.4877e-01,  3.6379e+00, -1.3225e+00, -3.0535e+00,  2.8854e-01,
          9.2331e-01, -1.4907e+01,  2.7428e-02,  3.6135e+00,  3.4661e+00,
         -2.3553e-02,  3.3911e+00,  1.2464e+00,  2.0600e+00,  5.6362e+00,
         -4.8358e-01,  4.4222e-01],
        [-1.1325e-02, -1.4138e-04,  1.4500e-04, -1.5008e-04, -1.0196e-03,
         -8.7395e-03, -5.0212e-04, -1.4891e-01, -9.6424e-01, -1.5847e-04,
          8.4481e-05, -6.7668e-04, -1.4540e-04, -9.6261e-01, -9.4804e-01,
         -9.4017e-05, -9.5700e-01,  4.4294e-03, -4.5741e-01, -5.5136e-03,
          2.2288e-03, -3.6784e-02],
        [-2.4271e-02, -7.7962e-04, -2.2040e-04, -7.9007e-04, -5.4691e-04,
         -1.4880e-02, -9.2166e-03, -1.1032e-01, -1.2944e+00, -7.8678e-04,
         -1.4609e-04, -3.3668e-05, -7.9327e-04, -1.2897e+00, -1.2879e+00,
         -3.7474e-04, -1.2861e+00, -9.7262e-03, -5.3746e-01, -3.8536e-03,
         -1.0548e-02, -2.4508e-02],
        [ 3.9237e+00, -6.2937e-02,  8.2976e-01, -8.9553e-02,  1.8773e-01,
          2.5280e+00,  4.4063e+00, -5.1176e-01,  2.7121e+00,  1.5038e-01,
          2.1898e+00, -6.3975e+00, -1.0291e-01,  9.8757e-01,  1.1535e+00,
          5.7770e-02,  9.4780e-01,  2.9512e+00,  2.3504e+00,  1.6411e+00,
          3.1498e+00,  1.2727e-01],
        [-1.4494e-02, -1.9430e-04, -1.7724e-04, -2.0127e-04, -2.0117e-04,
         -1.5493e-02, -8.1680e-03, -1.3258e-01, -1.3345e+00, -2.0053e-04,
         -1.8098e-04, -1.8463e-05, -1.9899e-04, -1.3303e+00, -1.3262e+00,
         -2.7675e-04, -1.3255e+00, -6.2074e-03, -5.8710e-01, -4.1919e-03,
         -7.5895e-03, -2.9301e-02],
        [-2.1892e-02, -3.5780e-04, -4.8405e-04, -3.6317e-04, -3.6356e-04,
         -2.3657e-02, -1.6951e-02, -9.6588e-02, -1.1849e+00, -3.5150e-04,
         -4.0838e-04, -1.7243e-05, -3.6464e-04, -1.1843e+00, -1.1795e+00,
         -3.3804e-04, -1.1790e+00, -7.4055e-03, -5.7283e-01, -5.4422e-03,
         -1.0076e-02, -3.1398e-02],
        [-2.3028e+00, -2.1890e-02, -8.3502e-03, -5.3786e-02,  9.5685e-02,
         -8.9290e-01, -1.4767e+01,  7.5055e+00,  3.0752e+00,  1.1812e-01,
         -7.0438e-02,  2.1906e-03, -5.7019e-02, -7.6423e-01, -1.3833e+00,
         -7.3209e-03, -7.3795e-01, -2.2229e+00,  1.8670e+00, -1.4910e+01,
         -1.6032e+00,  1.4609e+00],
        [ 2.4319e+00,  1.1747e-01, -1.6596e-01,  8.9778e-02,  3.1240e-01,
         -1.2941e+00, -9.2455e-01, -5.3120e-01,  5.2163e+00,  3.3676e-01,
         -2.0670e-01,  2.2187e+01,  7.3275e-02,  3.7788e-01,  7.5700e-01,
         -1.2275e-01,  4.8364e-01, -2.5823e+00,  1.5965e+00, -2.2668e+00,
         -6.5383e-01, -2.8611e+00],
        [-2.1115e-02, -3.0744e-04, -1.4460e-04, -2.9289e-04, -3.5131e-04,
         -2.2539e-02, -1.0971e-02, -1.5511e-01, -1.5086e+00, -2.8377e-04,
         -1.2594e-04,  2.8039e-05, -3.0274e-04, -1.5044e+00, -1.4994e+00,
         -3.7557e-04, -1.4986e+00, -6.5951e-03, -6.8458e-01, -3.5928e-03,
         -7.8039e-03, -3.0722e-02],
        [-1.4210e-02,  2.7210e-04, -1.6876e-04,  2.6752e-04,  2.9104e-04,
         -2.2712e-02, -5.7647e-03, -1.5704e-01, -1.4740e+00,  2.7486e-04,
         -1.6774e-04, -4.4364e-05,  2.6776e-04, -1.4699e+00, -1.4648e+00,
         -1.4749e-04, -1.4640e+00, -5.0059e-03, -6.6920e-01, -3.9010e-03,
         -5.3125e-03, -3.3932e-02]], device='cuda:0'))])
loaded xi:  855.6613
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857
 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857
 0.07142857 0.07142857]
W_T_mean: 8576.841924009083
W_T_median: 5042.380921625826
W_T_pctile_5: 103.64169553244135
W_T_CVAR_5_pct: -371.9331258181762
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -4775.078871312654
Current xi:  [870.71606]
objective value function right now is: -4775.078871312654
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -4803.004760101989
Current xi:  [885.9259]
objective value function right now is: -4803.004760101989
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -4814.743612632941
Current xi:  [900.5991]
objective value function right now is: -4814.743612632941
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -4911.805079597414
Current xi:  [915.3165]
objective value function right now is: -4911.805079597414
10.0% of gradient descent iterations done. Method = Adam
Current xi:  [930.2515]
objective value function right now is: -4890.923170096079
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [944.79517]
objective value function right now is: -4787.1356505782605
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [958.96826]
objective value function right now is: -4908.5955644664045
16.0% of gradient descent iterations done. Method = Adam
new min fval:  -4986.512378031189
Current xi:  [972.9195]
objective value function right now is: -4986.512378031189
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -5001.176853174418
Current xi:  [986.75366]
objective value function right now is: -5001.176853174418
20.0% of gradient descent iterations done. Method = Adam
new min fval:  -5069.71876394355
Current xi:  [1000.88947]
objective value function right now is: -5069.71876394355
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [1015.0922]
objective value function right now is: -5026.98121535556
24.0% of gradient descent iterations done. Method = Adam
new min fval:  -5098.139410174785
Current xi:  [1028.8296]
objective value function right now is: -5098.139410174785
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [1042.748]
objective value function right now is: -5093.278764635925
28.000000000000004% of gradient descent iterations done. Method = Adam
new min fval:  -5170.337126191323
Current xi:  [1056.3602]
objective value function right now is: -5170.337126191323
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [1070.1791]
objective value function right now is: -5136.319914081376
32.0% of gradient descent iterations done. Method = Adam
new min fval:  -5195.774452363917
Current xi:  [1083.4421]
objective value function right now is: -5195.774452363917
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [1097.0084]
objective value function right now is: -5179.674259236376
36.0% of gradient descent iterations done. Method = Adam
new min fval:  -5249.651228811549
Current xi:  [1109.856]
objective value function right now is: -5249.651228811549
38.0% of gradient descent iterations done. Method = Adam
new min fval:  -5290.142019776023
Current xi:  [1122.1036]
objective value function right now is: -5290.142019776023
40.0% of gradient descent iterations done. Method = Adam
new min fval:  -5317.160880171709
Current xi:  [1135.009]
objective value function right now is: -5317.160880171709
42.0% of gradient descent iterations done. Method = Adam
new min fval:  -5322.159953470516
Current xi:  [1147.5571]
objective value function right now is: -5322.159953470516
44.0% of gradient descent iterations done. Method = Adam
new min fval:  -5328.73750954823
Current xi:  [1159.5221]
objective value function right now is: -5328.73750954823
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [1172.2035]
objective value function right now is: -5282.383761234294
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [1184.2262]
objective value function right now is: -5283.710261552797
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [1195.2032]
objective value function right now is: -5328.124936463297
52.0% of gradient descent iterations done. Method = Adam
new min fval:  -5377.164601022419
Current xi:  [1206.3362]
objective value function right now is: -5377.164601022419
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [1217.9736]
objective value function right now is: -5370.551589391688
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [1229.728]
objective value function right now is: -5373.989256153922
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [1240.8025]
objective value function right now is: -5369.931358269757
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [1251.857]
objective value function right now is: -5293.5020164036805
62.0% of gradient descent iterations done. Method = Adam
new min fval:  -5399.8834472527415
Current xi:  [1262.1781]
objective value function right now is: -5399.8834472527415
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [1271.9795]
objective value function right now is: -5381.534334457932
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [1281.9203]
objective value function right now is: -5381.4453982767845
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [1291.3307]
objective value function right now is: -5393.013137410491
70.0% of gradient descent iterations done. Method = Adam
new min fval:  -5457.050106432447
Current xi:  [1300.503]
objective value function right now is: -5457.050106432447
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -5510.330017721229
Current xi:  [1302.482]
objective value function right now is: -5510.330017721229
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -5516.011830107285
Current xi:  [1304.1849]
objective value function right now is: -5516.011830107285
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [1306.4371]
objective value function right now is: -5514.949998936368
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [1308.3988]
objective value function right now is: -5451.357266150528
80.0% of gradient descent iterations done. Method = Adam
new min fval:  -5520.017352509276
Current xi:  [1310.3873]
objective value function right now is: -5520.017352509276
82.0% of gradient descent iterations done. Method = Adam
new min fval:  -5529.304327201042
Current xi:  [1312.353]
objective value function right now is: -5529.304327201042
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [1314.4294]
objective value function right now is: -5527.493504930826
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [1316.392]
objective value function right now is: -5529.026373900568
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [1318.5447]
objective value function right now is: -5525.646963782532
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [1320.5188]
objective value function right now is: -5527.016521029059
new min fval from sgd:  -5529.4139215563355
new min fval from sgd:  -5531.917043616271
new min fval from sgd:  -5533.114420509925
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [1322.555]
objective value function right now is: -5525.80320882521
new min fval from sgd:  -5533.91365163704
new min fval from sgd:  -5536.032156090887
new min fval from sgd:  -5536.244240983213
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [1324.43]
objective value function right now is: -5534.7222393498005
new min fval from sgd:  -5536.404405633834
new min fval from sgd:  -5537.823248996701
new min fval from sgd:  -5538.154839505559
new min fval from sgd:  -5538.821042781713
new min fval from sgd:  -5539.2200211556365
new min fval from sgd:  -5539.3205188057555
new min fval from sgd:  -5539.704216575699
new min fval from sgd:  -5539.812223179788
new min fval from sgd:  -5539.853508325952
new min fval from sgd:  -5540.183906310522
new min fval from sgd:  -5540.635025199447
new min fval from sgd:  -5540.720702585993
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [1326.272]
objective value function right now is: -5537.989392978853
new min fval from sgd:  -5540.743868435815
new min fval from sgd:  -5540.908005617605
new min fval from sgd:  -5540.974757429969
new min fval from sgd:  -5540.983708236249
new min fval from sgd:  -5541.028446123443
new min fval from sgd:  -5541.3007176179035
new min fval from sgd:  -5541.433030213034
new min fval from sgd:  -5541.502659362592
new min fval from sgd:  -5541.51711022106
new min fval from sgd:  -5541.659970797779
new min fval from sgd:  -5541.804941856459
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [1327.7991]
objective value function right now is: -5540.338212899114
new min fval from sgd:  -5541.986118960231
new min fval from sgd:  -5542.173452296692
new min fval from sgd:  -5542.261813212858
new min fval from sgd:  -5542.34706619665
new min fval from sgd:  -5542.4032408462
new min fval from sgd:  -5542.488565873569
new min fval from sgd:  -5542.489276390612
new min fval from sgd:  -5542.550219976597
new min fval from sgd:  -5542.578104680184
new min fval from sgd:  -5543.076656641038
new min fval from sgd:  -5543.423017316759
new min fval from sgd:  -5543.59077650441
new min fval from sgd:  -5543.645132677719
new min fval from sgd:  -5543.867083195739
new min fval from sgd:  -5544.060157646832
new min fval from sgd:  -5544.158760175696
new min fval from sgd:  -5544.1929585624375
new min fval from sgd:  -5544.231256924956
new min fval from sgd:  -5544.260918981191
new min fval from sgd:  -5544.266861535926
new min fval from sgd:  -5544.290682477454
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [1328.2589]
objective value function right now is: -5543.373798427161
min fval:  -5544.290682477454
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-12.6317,   5.8554],
        [ -3.5786, -11.3216],
        [ -7.8066,   5.0919],
        [ 11.5119,   0.7418],
        [-12.7854,  -8.7782],
        [ -9.9207,   4.2239],
        [  8.3907,   1.9343],
        [ 13.5859,  -0.0339],
        [-12.5034,   5.4390],
        [-12.6558,   5.8691],
        [-12.4599,   6.1526],
        [-12.1985,   4.7413],
        [ 11.0363,   0.9149],
        [ -2.6273,   2.5037],
        [ -1.5900,   0.8752],
        [  6.6455,   2.1781],
        [-14.5587, -10.2725],
        [ 11.0002,   0.9650],
        [-12.4458,   4.9143],
        [-12.4493,   4.6956],
        [ -3.5629,   3.7996],
        [-14.2931,  -7.5607]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([  5.0213,  -6.9114,  -1.3164, -10.6075,  -4.6859,  -2.3146,  -9.5941,
        -11.1682,   4.5452,   0.8569,   5.1843,  -0.9469, -10.4102,  -5.0769,
         -4.9729, -10.0627,  -5.0973, -10.4441,  -0.8047,  -0.4454,  -6.2781,
         -5.9769], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ 3.7219e-02, -1.9553e-01,  5.4012e-01,  6.1196e-01,  1.9602e-02,
          4.6602e-01,  6.1598e-01,  5.6759e-01,  6.5920e-02,  5.5810e-01,
          3.5534e-02,  5.5287e-01,  6.1387e-01,  3.3933e-01,  3.4940e-02,
          5.6090e-01, -3.7944e-03,  6.1553e-01,  5.7070e-01,  5.6841e-01,
          4.9722e-01,  1.6389e-01],
        [-9.9267e+00,  1.6134e+01, -5.3058e+00,  1.0227e+01,  5.2606e+00,
         -4.9028e+00,  3.2780e+00,  1.3777e+01, -8.1140e+00, -2.4709e+00,
         -1.0641e+01, -3.5333e+00,  9.1541e+00,  2.8923e-02,  4.7243e-01,
          1.9301e+00,  1.0255e+01,  1.0705e+01, -3.2960e+00, -3.0814e+00,
         -6.2777e-01,  6.9509e+00],
        [ 3.6813e-02, -1.9558e-01,  5.3959e-01,  6.1129e-01,  1.9487e-02,
          4.6626e-01,  6.1533e-01,  5.6692e-01,  6.5509e-02,  5.5758e-01,
          3.5115e-02,  5.5282e-01,  6.1320e-01,  3.3935e-01,  3.5022e-02,
          5.6047e-01, -3.9288e-03,  6.1486e-01,  5.7052e-01,  5.6825e-01,
          4.9707e-01,  1.6376e-01],
        [-1.0512e+01,  1.7009e+01, -5.0281e+00,  1.2388e+01,  6.1810e+00,
         -5.0712e+00,  5.0298e+00,  1.4499e+01, -9.0985e+00, -2.6446e+00,
         -1.1715e+01, -3.6897e+00,  9.8049e+00, -6.9064e-02, -5.5083e-01,
          1.0035e+00,  1.0966e+01,  1.0597e+01, -3.4840e+00, -3.3291e+00,
         -1.4574e+00,  7.9069e+00],
        [-8.8663e+00,  1.3782e+01, -4.5933e+00,  7.3167e+00,  5.3975e+00,
         -3.0675e+00,  1.1882e+00,  1.3812e+01, -7.4687e+00, -3.5793e+00,
         -9.5593e+00, -3.9724e+00,  8.9005e+00, -7.2724e-01,  7.1600e-01,
          2.0762e+00,  9.3463e+00,  1.2391e+01, -3.9119e+00, -2.5607e+00,
          3.9036e-01,  6.6366e+00],
        [-7.1291e+00,  1.0378e+01, -1.7999e+00,  6.1168e+00,  4.5543e+00,
         -5.2848e-01,  1.5583e+00,  8.9151e+00, -5.3128e+00, -1.2008e+00,
         -8.4914e+00, -1.2471e+00,  7.0925e+00,  1.0697e+00, -2.3439e-01,
          1.1011e+00,  7.7120e+00,  8.8092e+00, -1.3045e+00, -8.4609e-01,
         -1.1808e-01,  4.5785e+00],
        [ 3.7221e-02, -1.9553e-01,  5.4012e-01,  6.1197e-01,  1.9602e-02,
          4.6602e-01,  6.1598e-01,  5.6759e-01,  6.5922e-02,  5.5810e-01,
          3.5537e-02,  5.5287e-01,  6.1388e-01,  3.3933e-01,  3.4939e-02,
          5.6090e-01, -3.7936e-03,  6.1554e-01,  5.7070e-01,  5.6841e-01,
          4.9722e-01,  1.6389e-01],
        [ 3.7385e-02, -1.9550e-01,  5.4034e-01,  6.1224e-01,  1.9647e-02,
          4.6593e-01,  6.1625e-01,  5.6787e-01,  6.6078e-02,  5.5831e-01,
          3.5718e-02,  5.5290e-01,  6.1415e-01,  3.3932e-01,  3.4916e-02,
          5.6109e-01, -3.7431e-03,  6.1581e-01,  5.7077e-01,  5.6848e-01,
          4.9728e-01,  1.6394e-01],
        [ 3.6808e-02, -1.9559e-01,  5.3958e-01,  6.1128e-01,  1.9485e-02,
          4.6626e-01,  6.1532e-01,  5.6691e-01,  6.5504e-02,  5.5758e-01,
          3.5110e-02,  5.5282e-01,  6.1320e-01,  3.3935e-01,  3.5024e-02,
          5.6047e-01, -3.9310e-03,  6.1485e-01,  5.7051e-01,  5.6825e-01,
          4.9706e-01,  1.6376e-01],
        [ 3.7180e-02, -1.9554e-01,  5.4007e-01,  6.1190e-01,  1.9591e-02,
          4.6604e-01,  6.1591e-01,  5.6753e-01,  6.5881e-02,  5.5805e-01,
          3.5494e-02,  5.5287e-01,  6.1381e-01,  3.3933e-01,  3.4946e-02,
          5.6086e-01, -3.8064e-03,  6.1547e-01,  5.7068e-01,  5.6840e-01,
          4.9720e-01,  1.6387e-01],
        [-6.8481e+00,  1.0029e+01, -2.2112e+00,  7.3057e+00,  4.5194e+00,
         -5.6928e-02,  9.0666e-01,  8.1191e+00, -5.3415e+00, -3.5051e-01,
         -8.6130e+00, -7.0275e-01,  7.2576e+00,  9.5952e-01, -5.6196e-01,
         -1.8208e-01,  7.7460e+00,  8.6506e+00, -8.0019e-01, -1.4921e-01,
         -6.8095e-02,  4.6872e+00],
        [ 9.2687e+00, -1.4355e+01,  5.0862e+00, -1.1071e+01, -5.9261e+00,
          2.6225e+00, -3.5297e+00, -1.2884e+01,  7.8503e+00,  4.7360e+00,
          1.0843e+01,  4.6106e+00, -8.0534e+00,  7.0360e-01, -3.3622e-01,
         -5.2360e-01, -9.8354e+00, -1.0986e+01,  4.7597e+00,  3.6242e+00,
          3.0185e-01, -7.5052e+00],
        [ 3.7186e-02, -1.9553e-01,  5.4010e-01,  6.1194e-01,  1.9592e-02,
          4.6604e-01,  6.1595e-01,  5.6756e-01,  6.5862e-02,  5.5808e-01,
          3.5530e-02,  5.5287e-01,  6.1385e-01,  3.3931e-01,  3.4941e-02,
          5.6089e-01, -3.8086e-03,  6.1550e-01,  5.7068e-01,  5.6842e-01,
          4.9719e-01,  1.6388e-01],
        [ 3.7087e-02, -1.9555e-01,  5.3994e-01,  6.1174e-01,  1.9565e-02,
          4.6609e-01,  6.1576e-01,  5.6737e-01,  6.5788e-02,  5.5793e-01,
          3.5396e-02,  5.5286e-01,  6.1365e-01,  3.3933e-01,  3.4961e-02,
          5.6075e-01, -3.8366e-03,  6.1531e-01,  5.7064e-01,  5.6836e-01,
          4.9717e-01,  1.6385e-01],
        [ 6.4470e-01,  3.2005e-01,  1.9341e-01, -3.4348e-02,  2.3557e-01,
          1.1608e-01,  6.0159e-02, -1.0447e-01,  5.8948e-01,  2.2093e-01,
          6.4962e-01,  1.6944e-01, -2.1832e-02,  1.2264e-01,  3.5286e-02,
          1.5539e-01,  2.6181e-01, -1.7241e-02,  1.8472e-01,  1.8506e-01,
          1.4898e-01,  4.9494e-02],
        [ 3.7005e-02, -1.9556e-01,  5.3983e-01,  6.1160e-01,  1.9541e-02,
          4.6614e-01,  6.1563e-01,  5.6723e-01,  6.5705e-02,  5.5782e-01,
          3.5311e-02,  5.5285e-01,  6.1351e-01,  3.3933e-01,  3.4977e-02,
          5.6066e-01, -3.8644e-03,  6.1517e-01,  5.7060e-01,  5.6833e-01,
          4.9714e-01,  1.6382e-01],
        [-7.6981e+00,  1.1985e+01, -2.5345e+00,  6.9633e+00,  4.8624e+00,
         -1.3422e+00,  1.5871e+00,  1.0583e+01, -6.2345e+00, -1.2743e+00,
         -9.3000e+00, -1.9186e+00,  8.0663e+00,  9.7871e-01, -6.8685e-01,
          1.4776e+00,  8.5925e+00,  1.0180e+01, -1.8143e+00, -8.5264e-01,
         -9.5716e-01,  5.6817e+00],
        [ 3.6811e-02, -1.9558e-01,  5.3958e-01,  6.1129e-01,  1.9486e-02,
          4.6626e-01,  6.1533e-01,  5.6692e-01,  6.5507e-02,  5.5758e-01,
          3.5114e-02,  5.5282e-01,  6.1320e-01,  3.3935e-01,  3.5023e-02,
          5.6047e-01, -3.9295e-03,  6.1485e-01,  5.7051e-01,  5.6825e-01,
          4.9706e-01,  1.6376e-01],
        [ 3.6829e-02, -1.9558e-01,  5.3960e-01,  6.1131e-01,  1.9491e-02,
          4.6625e-01,  6.1535e-01,  5.6694e-01,  6.5525e-02,  5.5760e-01,
          3.5131e-02,  5.5282e-01,  6.1323e-01,  3.3935e-01,  3.5017e-02,
          5.6048e-01, -3.9238e-03,  6.1488e-01,  5.7052e-01,  5.6826e-01,
          4.9707e-01,  1.6376e-01],
        [ 3.7245e-02, -1.9553e-01,  5.4016e-01,  6.1201e-01,  1.9609e-02,
          4.6600e-01,  6.1602e-01,  5.6763e-01,  6.5946e-02,  5.5813e-01,
          3.5563e-02,  5.5288e-01,  6.1392e-01,  3.3933e-01,  3.4936e-02,
          5.6093e-01, -3.7859e-03,  6.1558e-01,  5.7071e-01,  5.6842e-01,
          4.9723e-01,  1.6389e-01],
        [ 6.4849e-01,  3.2206e-01,  1.9344e-01, -3.5653e-02,  2.3637e-01,
          1.1617e-01,  5.9064e-02, -1.0546e-01,  5.9234e-01,  2.2109e-01,
          6.5400e-01,  1.6968e-01, -2.3142e-02,  1.2287e-01,  3.5877e-02,
          1.5520e-01,  2.6278e-01, -1.8560e-02,  1.8502e-01,  1.8534e-01,
          1.4924e-01,  4.9148e-02],
        [ 3.6801e-02, -1.9559e-01,  5.3957e-01,  6.1127e-01,  1.9484e-02,
          4.6627e-01,  6.1531e-01,  5.6690e-01,  6.5497e-02,  5.5757e-01,
          3.5103e-02,  5.5282e-01,  6.1319e-01,  3.3935e-01,  3.5026e-02,
          5.6046e-01, -3.9325e-03,  6.1484e-01,  5.7051e-01,  5.6824e-01,
          4.9706e-01,  1.6376e-01]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-2.6217,  0.5430, -2.6215,  0.7689,  0.1157, -1.4795, -2.6217, -2.6218,
        -2.6215, -2.6216, -1.4771, -0.8173, -2.6217, -2.6216,  5.0919, -2.6215,
        -0.8059, -2.6215, -2.6215, -2.6217,  5.1682, -2.6215], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[  0.2186, -15.1199,   0.2185, -21.9893, -11.9843,  -5.6561,   0.2186,
           0.2186,   0.2185,   0.2186,  -5.7596,  18.7210,   0.2186,   0.2186,
           5.2372,   0.2186,  -7.2344,   0.2185,   0.2185,   0.2186,   5.6948,
           0.2185]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  7.5309,   0.0557],
        [ -1.8075,  13.3950],
        [ 24.2516,   3.2838],
        [ 13.1836,   0.1379],
        [ -2.0001,   0.4971],
        [ -2.8781,   0.5768],
        [ -2.8356,   0.6033],
        [ -2.1823,   0.2778],
        [ -0.3532,   3.5498],
        [  6.7961,  -0.0490],
        [ -1.9635,   0.5064],
        [ -2.0015,   0.6714],
        [-13.4737,  -1.4017],
        [-10.5187,   7.6092],
        [ -8.7578,  12.4017],
        [ -0.2597,   3.2466],
        [ -0.3809,   3.6206],
        [-13.0056,  -3.0139],
        [-12.8859,  -5.0249],
        [  4.0824,  13.9747],
        [ 10.4651,   2.0129],
        [ 13.8139,  12.5366]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-12.2801,   8.3517,   2.2170, -11.2801,  -6.3985,  -6.6420,  -6.7757,
         -6.7821,  -6.0443, -12.3314,  -6.5210,  -6.7836,   6.4922,   2.7226,
          6.8082,  -5.9608,  -6.0446,   3.1777,  -2.0749,   8.8994,  -8.4988,
          6.9075], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 1.0423e-01,  1.4365e+00, -3.0807e+00, -4.8284e-01,  2.2656e-02,
          2.0639e-03,  1.9275e-03,  1.0066e-02, -3.5972e-01,  9.6127e-02,
          2.0479e-02,  1.5743e-02, -1.2040e+00, -1.0784e+00, -2.3337e+00,
         -3.1738e-01, -3.7204e-01, -1.1512e+00, -4.0117e-01,  4.1825e-01,
          2.5481e-01, -1.6471e+00],
        [ 7.8526e-03,  3.9540e-01, -3.4590e+00, -1.1753e+00, -4.2418e-03,
         -1.5090e-03, -1.1788e-03, -5.9151e-03, -1.3140e-01,  5.0604e-03,
         -3.5387e-03,  5.3222e-04, -8.1991e-01, -2.4965e-01, -9.5567e-01,
         -1.2523e-01, -1.3295e-01, -7.5694e-01, -3.0171e-01, -3.3266e-01,
         -3.3092e-01, -1.8279e+00],
        [ 3.5074e-02,  9.2640e-01, -3.3463e+00, -8.9377e-01, -1.3031e-03,
         -4.2934e-03, -3.5255e-03, -4.7414e-03, -2.0684e-01,  2.2818e-02,
         -7.4613e-04,  3.3923e-03, -9.6873e-01, -4.7029e-01, -1.5899e+00,
         -1.8921e-01, -2.1190e-01, -9.0612e-01, -3.3631e-01,  2.4871e-02,
         -1.3028e-01, -1.7956e+00],
        [ 3.8446e-03,  2.4790e-01, -3.5725e+00, -1.0975e+00, -6.2163e-03,
         -6.1510e-03, -5.3562e-03, -7.2816e-03, -1.2041e-01,  2.9784e-03,
         -5.2453e-03, -1.7191e-03, -7.1754e-01, -1.8966e-01, -7.9465e-01,
         -1.1707e-01, -1.2147e-01, -5.8940e-01, -2.3990e-01, -3.7280e-01,
         -3.7737e-01, -1.7044e+00],
        [ 1.2655e-02,  5.5476e-01, -3.4201e+00, -1.0932e+00, -3.7106e-03,
         -2.9653e-03, -2.3569e-03, -3.9572e-03, -1.4858e-01,  7.2778e-03,
         -1.8861e-03,  8.1014e-04, -8.6145e-01, -2.9664e-01, -1.1294e+00,
         -1.3963e-01, -1.5116e-01, -7.9776e-01, -3.0100e-01, -2.2893e-01,
         -2.8838e-01, -1.8216e+00],
        [ 2.7581e-01,  2.0845e+00, -4.4928e+00, -1.3384e+00,  1.3491e-01,
          1.1676e-01,  1.1527e-01, -5.5732e-04, -2.0058e+00,  3.6193e-01,
         -3.4172e-02,  7.9332e-03,  6.9842e-01,  1.1168e+00,  3.3730e+00,
         -2.6474e+00, -1.6005e+00,  1.4563e+00,  2.5936e+00,  4.9838e-01,
         -1.1599e+00, -1.1959e+00],
        [-9.0698e-01, -1.3375e+01, -5.5715e-01, -6.0904e+00,  8.4424e-02,
          1.3104e-01,  1.1347e-01,  6.4427e-02, -3.5742e-02, -9.0246e-01,
          9.3143e-02,  7.1203e-02,  4.9248e+00, -1.7232e+00, -8.2978e+00,
         -1.8809e-02, -3.0901e-02,  3.3837e+00,  3.3802e+00, -1.2569e+01,
          7.4174e-01, -3.5015e+00],
        [ 1.5309e+00,  2.5733e+00, -3.2757e+00,  3.6882e-01, -1.8256e-01,
          2.2168e-03,  3.5288e-02,  7.2912e-02, -9.6746e-02,  1.5542e+00,
         -5.5146e-02,  1.9697e-02,  1.1291e+00,  5.3569e+00,  1.6205e+01,
          2.4312e-01, -2.5221e-01,  1.3546e+00, -2.4901e+00,  5.4453e+00,
         -4.3054e-01,  3.2033e+00],
        [ 1.2293e+00,  2.1944e+01,  4.2870e+00,  1.3033e+01,  9.9560e-02,
          1.3851e-01,  1.2408e-01,  8.9150e-02,  6.9429e-02,  3.0241e-01,
          6.8458e-02,  7.8331e-02, -1.0559e+01,  1.7946e+00,  1.2896e+01,
          8.3171e-02,  6.6961e-02, -1.0214e+01, -6.1478e+00,  2.3963e+01,
          9.9381e+00,  1.8596e+01],
        [ 4.2291e-02,  9.9775e-01, -3.3095e+00, -8.5326e-01, -3.1393e-04,
         -3.8848e-03, -3.1443e-03, -4.1029e-03, -2.2140e-01,  2.9107e-02,
          8.1094e-05,  4.2646e-03, -1.0005e+00, -5.2385e-01, -1.6883e+00,
         -2.0123e-01, -2.2717e-01, -9.4379e-01, -3.4623e-01,  7.5539e-02,
         -7.8390e-02, -1.7893e+00],
        [ 2.0769e-02,  7.2632e-01, -3.3820e+00, -1.0107e+00, -2.8155e-03,
         -3.8196e-03, -3.0856e-03, -4.7832e-03, -1.7261e-01,  1.2135e-02,
         -1.7100e-03,  1.8691e-03, -9.1287e-01, -3.6664e-01, -1.3341e+00,
         -1.6003e-01, -1.7621e-01, -8.4989e-01, -3.1681e-01, -1.1677e-01,
         -2.2429e-01, -1.8183e+00],
        [ 2.4472e-01, -3.1301e+01, -9.4150e+00, -1.8851e+01, -1.2708e-01,
         -1.2553e-01, -1.1957e-01, -9.7051e-02, -7.3116e-02,  1.9528e-01,
         -8.9374e-02, -1.0901e-01,  7.9723e+00, -2.1616e+00, -1.1739e+01,
         -9.6306e-02, -6.9188e-02,  8.3862e+00,  6.2279e+00, -3.9100e+01,
         -5.2906e+00, -2.8648e+01],
        [ 3.9045e-03,  2.5437e-01, -3.5819e+00, -1.0541e+00, -6.3992e-03,
         -4.6038e-03, -3.8922e-03, -7.6595e-03, -1.2331e-01,  2.9523e-03,
         -5.5313e-03, -1.1062e-03, -7.0379e-01, -1.9360e-01, -8.0155e-01,
         -1.1990e-01, -1.2438e-01, -5.6664e-01, -2.3710e-01, -3.5677e-01,
         -3.8024e-01, -1.6899e+00],
        [ 9.0188e-03,  3.6352e-01,  4.2149e+00,  1.2259e+00,  7.6330e-03,
          5.9923e-03,  5.6845e-03,  6.9451e-03, -2.6355e-02,  5.3913e-03,
          6.8775e-03,  9.0355e-03,  6.9822e-01, -1.6145e-01,  9.2399e-02,
          1.5829e-03, -3.4943e-02,  2.4370e-01, -1.4718e-01,  5.6913e-01,
          2.6896e-01,  1.9903e+00],
        [ 1.0943e-01, -9.5903e-01,  5.1939e+00,  2.7049e+00,  2.9305e-02,
          6.5309e-02,  6.0661e-02, -6.8198e-02, -7.9851e-01,  6.9482e-02,
          1.5848e-01,  8.1688e-02, -8.3542e-01, -1.3801e+00, -2.6595e+00,
         -7.5198e-01, -8.1759e-01, -9.2274e-01, -2.7907e+00, -1.2870e+00,
          5.0151e+00,  1.7710e-03],
        [ 3.1054e-02,  7.0651e-01, -3.9605e+00,  2.9654e-01,  6.4353e-04,
         -6.4906e-04, -1.1151e-04, -2.3766e-03, -2.6903e-01,  2.2333e-02,
          1.0207e-03,  5.7016e-03, -8.8783e-01, -7.0591e-01, -1.3109e+00,
         -2.4318e-01, -2.7658e-01, -4.1359e-01, -1.9172e-01, -3.4612e-02,
          1.3642e-01, -2.0834e+00],
        [ 9.0226e-03,  4.1041e-01,  4.1883e+00,  1.1881e+00,  7.6691e-03,
          5.7773e-03,  5.4739e-03,  6.9311e-03, -3.4982e-02,  5.1355e-03,
          6.8833e-03,  9.0790e-03,  7.1742e-01, -1.7349e-01,  8.0260e-02,
         -4.6040e-03, -4.4463e-02,  2.5107e-01, -1.4192e-01,  6.1969e-01,
          2.3406e-01,  1.9380e+00],
        [-3.6717e+00, -6.3163e+00, -2.0644e-01, -6.0729e+00,  9.3887e-02,
          3.1186e-02,  2.4489e-02,  4.7503e-02, -4.4685e-02, -2.3477e+00,
          7.6722e-02,  2.7700e-02, -3.4362e+00, -2.8856e-02, -5.9446e-02,
         -6.3091e-02, -4.0876e-02, -2.2220e+00,  3.7495e+00, -1.2220e+01,
         -3.0201e+00,  5.4243e-01],
        [-5.0255e-01, -2.4028e+00,  3.0321e+00, -8.7444e+00, -8.4285e-02,
         -1.4086e+00, -1.4367e+00,  6.4598e-01,  2.6254e-01, -7.9572e-01,
         -3.3435e-01, -8.3261e-02,  1.4587e+01,  1.8503e+00,  5.9956e+00,
         -2.5796e-01,  4.2817e-01,  2.0805e+01,  1.2590e+01, -9.9943e-01,
         -2.0244e+00, -2.7890e+00],
        [-3.4685e+00, -1.7191e+01, -1.5215e+00, -5.6420e+00,  3.5533e-01,
          3.5944e-01,  3.2970e-01,  2.9445e-01,  1.1113e-01, -8.1340e-03,
          3.5379e-01,  2.6185e-01,  5.7701e+00,  2.0302e+00, -3.4127e+00,
          1.6090e-01,  1.0677e-01,  5.4636e+00,  8.1742e+00, -1.9866e+01,
         -7.3534e+00, -5.4581e+00],
        [ 1.0283e-01,  1.4284e+00, -3.0882e+00, -4.8987e-01,  2.1407e-02,
          1.7577e-03,  1.6762e-03,  9.2664e-03, -3.5558e-01,  9.4781e-02,
          1.9331e-02,  1.5135e-02, -1.1982e+00, -1.0600e+00, -2.3228e+00,
         -3.1389e-01, -3.6770e-01, -1.1455e+00, -3.9906e-01,  4.1297e-01,
          2.4660e-01, -1.6501e+00],
        [-1.1207e+00,  3.2856e+00, -4.0434e+00, -1.2731e+01,  1.2692e-01,
         -1.7894e-01, -4.4126e-01, -2.3136e-01,  2.4502e+00, -3.9479e-01,
          7.9057e-02, -3.4887e-01,  2.9097e+00,  5.4209e+00,  2.6356e+00,
          2.2789e+00,  2.3383e+00,  3.1880e+00,  3.3871e+00,  2.3139e+00,
         -4.8586e+00, -1.3700e+00]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-3.1498, -3.4835, -3.3890, -3.6079, -3.4804, -4.0904,  1.7609, -4.9048,
        -1.8837, -3.3648, -3.4481, -2.0388, -3.6472,  4.2845,  4.9267, -4.0908,
         4.2586, -0.8985,  3.4258, -0.1274, -3.1555, -4.0326], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-5.4963e-04, -1.1814e-04, -3.5708e-04, -8.1579e-05, -1.9124e-04,
         -1.5133e-03, -1.1957e-02, -9.9256e-01, -1.7876e+00, -3.0616e-04,
         -3.4547e-04, -2.9984e-05, -7.8691e-05, -1.7877e+00, -1.7876e+00,
         -7.5923e-05, -1.7877e+00, -4.5360e-03, -4.0395e-01, -6.2000e-04,
         -5.4988e-04, -1.4904e-02],
        [ 2.7428e-03, -4.1084e-04,  5.5886e-04, -6.5136e-04, -1.9116e-04,
          4.6492e-03, -1.6537e-02, -8.5598e-01, -9.4684e-01,  6.3006e-04,
          1.1756e-04, -1.0140e-03, -6.5926e-04, -9.4835e-01, -9.4811e-01,
         -3.7118e-04, -9.4835e-01,  1.4087e-02, -1.8288e-01,  1.9527e-03,
          2.5382e-03, -3.0353e-02],
        [-1.1481e-03, -2.5643e-04, -6.2278e-04, -2.0552e-04, -3.4555e-04,
         -1.2971e-03, -1.3841e-02, -8.9066e-01, -1.6737e+00, -7.1622e-04,
         -4.4834e-04, -1.3479e-04, -2.0390e-04, -1.6739e+00, -1.6738e+00,
         -2.1017e-04, -1.6739e+00, -4.7129e-03, -3.7196e-01, -4.6744e-04,
         -1.1081e-03, -1.7547e-02],
        [-2.3405e-03, -3.8719e-05,  3.9392e-06, -2.7957e-05, -5.3749e-05,
         -1.9180e-03, -1.7661e-02, -8.6323e-01, -1.4949e+00,  4.7635e-05,
         -7.1015e-05, -1.4671e-04, -2.7960e-05, -1.4952e+00, -1.4951e+00,
         -7.8141e-06, -1.4952e+00, -5.5404e-03, -3.2979e-01, -2.2147e-04,
         -2.2697e-03, -1.3114e-02],
        [ 3.6642e-01,  1.8725e-01,  1.2862e-01, -1.8997e-02,  1.1795e-01,
          3.8074e-03,  4.3000e+00, -1.0590e-01, -3.0482e+00,  1.8481e-01,
          1.2812e-01, -2.1045e+01, -1.2671e-02,  3.7985e+00,  3.5783e+00,
          1.0522e+00,  3.5652e+00,  2.5627e+00,  2.1283e+00,  6.2115e+00,
          3.5391e-01, -5.6217e-01],
        [-3.4373e-04,  1.6576e-04, -9.9592e-05,  1.1195e-04,  2.4083e-04,
          1.6764e-03, -2.6384e-03, -8.8165e-01, -1.2414e+00, -2.9436e-04,
          2.5673e-04,  1.4110e-04,  1.1703e-04, -1.2420e+00, -1.2418e+00,
          3.8801e-04, -1.2420e+00,  1.4935e-03, -2.3612e-01,  2.2774e-04,
         -2.5474e-04, -9.2990e-03],
        [-2.8390e-03, -2.2562e-04, -6.6394e-04, -1.7857e-04, -3.1622e-04,
         -8.5380e-04, -1.6729e-02, -7.7649e-01, -1.5397e+00, -5.4313e-04,
         -4.7928e-04,  1.0341e-05, -1.7587e-04, -1.5400e+00, -1.5399e+00,
         -1.5662e-04, -1.5400e+00, -3.4440e-03, -3.2025e-01,  7.5909e-05,
         -2.6622e-03, -9.4753e-03],
        [-1.1926e+00, -4.4063e-01, -8.1681e-01, -4.9015e-01, -5.7542e-01,
          1.2064e+00,  3.9866e+00,  3.7534e-01,  3.0887e+00, -8.2221e-01,
         -6.7274e-01, -1.4289e+01, -4.8880e-01,  1.1562e+00,  1.2685e+00,
         -8.1793e-01,  1.1092e+00,  5.7216e+00,  2.2143e+00,  3.8046e+00,
         -1.1901e+00, -6.1517e-02],
        [-8.5008e-04, -2.1213e-04, -3.4374e-04, -1.7765e-04, -2.6124e-04,
         -1.2034e-03, -1.5485e-02, -8.6147e-01, -1.5965e+00, -3.4397e-04,
         -2.9833e-04, -1.9992e-04, -1.7631e-04, -1.5967e+00, -1.5965e+00,
         -1.5702e-04, -1.5967e+00, -4.6293e-03, -3.4851e-01, -2.7860e-04,
         -7.5811e-04, -1.2650e-02],
        [-3.4712e-03, -4.4987e-04, -6.8314e-04, -4.8244e-04, -4.4063e-04,
         -3.3395e-04, -2.6312e-02, -6.6772e-01, -1.3678e+00, -8.0127e-04,
         -5.0258e-04, -2.7785e-04, -4.8169e-04, -1.3686e+00, -1.3685e+00,
         -5.4702e-04, -1.3686e+00, -7.5193e-03, -4.7091e-01, -2.2053e-03,
         -3.4668e-03, -1.7165e-02],
        [ 3.0353e-01,  3.4194e-01,  2.8650e-01,  2.5628e-01,  2.8497e-01,
          3.0741e+00, -2.7881e+01,  5.9446e+00,  3.2283e+00,  3.0460e-01,
          2.9218e-01,  7.1965e-09,  2.7227e-01, -7.8431e-01, -1.2361e+00,
          3.7332e-01, -7.5417e-01, -5.1805e+00,  3.1582e+00, -2.7710e+01,
          2.9652e-01,  3.1460e+00],
        [ 2.5375e-01,  1.6788e-01,  1.3934e-01, -1.2693e-02,  1.2675e-01,
         -5.8637e+00,  1.5233e+00, -2.0369e-01,  5.4231e+00,  1.9148e-01,
          1.4305e-01,  2.9616e+01, -2.2091e-03,  5.4281e-01,  9.6772e-01,
          4.7223e-01,  6.6030e-01, -6.3272e+00,  1.5274e+00, -1.1903e+01,
          2.4588e-01, -2.9951e-01],
        [-8.8682e-04, -2.4626e-05, -4.0932e-04, -7.1815e-06, -9.6251e-05,
         -1.2071e-03, -1.2012e-02, -9.7472e-01, -1.7668e+00, -5.3737e-04,
         -1.7841e-04, -7.0909e-05, -7.7905e-06, -1.7669e+00, -1.7668e+00,
         -2.4855e-05, -1.7669e+00, -4.6833e-03, -4.0361e-01, -5.7039e-04,
         -8.4077e-04, -1.7691e-02],
        [-8.3341e-04, -1.1992e-04, -1.8327e-04, -9.8251e-05, -1.7516e-04,
         -1.5653e-03, -1.3083e-02, -9.9240e-01, -1.7473e+00, -1.0150e-04,
         -2.7794e-04, -7.3825e-05, -9.8295e-05, -1.7474e+00, -1.7472e+00,
         -9.9054e-05, -1.7474e+00, -4.8684e-03, -3.8989e-01, -8.6174e-04,
         -8.0172e-04, -1.7253e-02]], device='cuda:0'))])
xi:  [1328.018]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 1735.347979596999
W_T_median: 1694.2586431848695
W_T_pctile_5: 1340.0933696829757
W_T_CVAR_5_pct: 816.8248057499499
Average q (qsum/M+1):  47.274508568548384
Optimal xi:  [1328.018]
Expected(across Rb) median(across samples) p_equity:  3.323167660163051e-07
obj fun:  tensor(-5544.2907, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/factor_decumulation/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:262: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/factor_decumulation/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/factor_decumulation/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: MC_everything
Objective function: mean_cvar_single_level
Tracing param: 5.0
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       22  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       22  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 22)      True          22  
0     (22, 22)      True          22  
0      (22, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       22  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       22  logistic_sigmoid   
0        obj.layers[3]         3  output_layer       14           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 22)      True          22  
0     (22, 22)      True          22  
0     (22, 14)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -8.5715,   6.4621],
        [ -8.3669,  -9.0182],
        [ -5.1223,   3.2445],
        [  8.0669,   4.1508],
        [-11.4280,  -6.0457],
        [ -6.4858,   4.0851],
        [  6.0779,   4.9126],
        [  9.1747,   0.7713],
        [ -8.3119,   6.0846],
        [ -8.3147,   6.0977],
        [ -8.4882,   6.6116],
        [ -8.6931,   5.7529],
        [  7.8819,   3.3034],
        [ -1.2974,   1.0853],
        [  5.4594,  -0.3288],
        [  5.2299,   5.2824],
        [-11.7613,  -7.4762],
        [  7.7973,   4.2640],
        [ -8.5799,   5.8746],
        [ -7.8535,   5.7472],
        [ -1.2944,   1.0845],
        [-21.4386,  -5.7294]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ 4.8764, -5.7404, -3.0406, -9.5323, -3.7687, -2.3429, -8.4043, -9.1228,
         4.2727,  3.0356,  5.1757,  1.5461, -8.9288, -3.8883, -8.9159, -8.5427,
        -4.0692, -9.2749,  1.8685,  2.4405, -3.8889, -4.6902], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1574e-03, -1.6502e-02, -2.2728e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1088e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [-9.2453e+00,  1.2482e+01, -7.2066e-01,  7.0332e+00,  4.6981e+00,
         -1.2007e+00,  4.5523e+00,  6.2080e+00, -7.5674e+00, -3.0869e+00,
         -1.0021e+01, -1.8126e+00,  5.8578e+00, -1.6237e-01,  6.8999e-01,
          5.4520e+00,  8.4865e+00,  8.0426e+00, -2.2762e+00, -3.8127e+00,
         -1.9618e-01,  8.7135e+00],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2751e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-9.6515e+00,  1.3280e+01, -9.1434e-01,  9.3871e+00,  5.7620e+00,
         -1.3190e+00,  6.4927e+00,  6.8045e+00, -8.3770e+00, -3.3906e+00,
         -1.0939e+01, -2.1716e+00,  6.5179e+00, -2.1870e-01,  2.0491e+00,
          4.1453e+00,  9.2888e+00,  7.8384e+00, -2.6898e+00, -4.4743e+00,
         -1.9003e-01,  9.7752e+00],
        [-7.9773e+00,  1.0315e+01,  2.5895e-01,  4.6608e+00,  4.9211e+00,
          1.7041e-02,  2.1882e+00,  6.8647e+00, -6.6734e+00, -4.8263e+00,
         -8.8073e+00, -2.8795e+00,  6.4311e+00,  1.6629e-01,  1.1111e+00,
          5.0411e+00,  7.6765e+00,  1.1081e+01, -3.5739e+00, -4.0927e+00,
          1.6082e-01,  8.5887e+00],
        [-7.6589e+00,  9.2592e+00,  7.9739e-02,  3.9257e+00,  4.5700e+00,
          1.0005e-01,  2.1053e+00,  4.6166e+00, -6.0015e+00, -3.8545e+00,
         -9.2106e+00, -1.7570e+00,  5.7099e+00, -1.2986e-02,  5.9836e-02,
          4.9159e+00,  7.0161e+00,  9.4703e+00, -2.3319e+00, -3.1763e+00,
         -1.3208e-02,  7.3285e+00],
        [-2.2581e-01, -1.6549e-01,  1.7511e-03, -1.2938e-02, -1.1903e-01,
          1.1578e-03, -1.6509e-02, -2.2839e-03, -1.8738e-01, -6.9338e-02,
         -2.5288e-01, -1.2692e-02, -9.1165e-03,  1.2292e-02,  1.9855e-02,
         -1.7662e-02, -1.7966e-01, -1.2937e-02, -1.9683e-02, -4.9682e-02,
          1.2307e-02, -3.1400e-02],
        [-2.2584e-01, -1.6546e-01,  1.7508e-03, -1.2931e-02, -1.1901e-01,
          1.1573e-03, -1.6502e-02, -2.2704e-03, -1.8735e-01, -6.9322e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9856e-02,
         -1.7657e-02, -1.7959e-01, -1.2929e-02, -1.9678e-02, -4.9672e-02,
          1.2308e-02, -3.1398e-02],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2752e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2730e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1088e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [-7.4230e+00,  9.2761e+00,  8.2691e-02,  4.6883e+00,  4.4150e+00,
          1.2211e-01,  2.9895e+00,  3.5408e+00, -6.2114e+00, -3.5923e+00,
         -9.4198e+00, -1.8627e+00,  4.7011e+00, -1.9985e-02, -6.0281e-02,
          5.2032e+00,  7.0797e+00,  8.3206e+00, -2.3235e+00, -3.3515e+00,
         -1.9947e-02,  7.4397e+00],
        [ 7.9326e+00, -1.0706e+01,  4.0837e-01, -9.2089e+00, -5.7725e+00,
          6.6403e-01, -4.8629e+00, -5.8385e+00,  6.6214e+00,  5.0109e+00,
          9.6232e+00,  3.3999e+00, -5.8456e+00, -1.3669e-01, -1.4453e+00,
         -3.3601e+00, -8.4017e+00, -9.5444e+00,  3.9084e+00,  4.3412e+00,
         -1.3169e-01, -9.7519e+00],
        [-2.2583e-01, -1.6545e-01,  1.7507e-03, -1.2931e-02, -1.1900e-01,
          1.1572e-03, -1.6503e-02, -2.2678e-03, -1.8733e-01, -6.9320e-02,
         -2.5297e-01, -1.2687e-02, -9.1093e-03,  1.2293e-02,  1.9856e-02,
         -1.7657e-02, -1.7958e-01, -1.2930e-02, -1.9677e-02, -4.9670e-02,
          1.2308e-02, -3.1399e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2931e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2732e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2308e-02, -3.1398e-02],
        [ 6.5891e-01,  3.0868e-01,  8.3566e-03,  3.5747e-02,  2.1159e-01,
          5.3475e-03,  5.7464e-02,  2.6629e-01,  5.5272e-01,  2.6083e-01,
          7.4008e-01,  8.5701e-02,  7.1654e-02,  3.7717e-02,  5.6900e-02,
          8.1005e-02,  2.9146e-01,  3.6840e-02,  1.1119e-01,  2.1066e-01,
          3.7716e-02,  1.3910e-01],
        [-2.2585e-01, -1.6548e-01,  1.7509e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2733e-03, -1.8736e-01, -6.9325e-02,
         -2.5298e-01, -1.2688e-02, -9.1087e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9678e-02, -4.9674e-02,
          1.2307e-02, -3.1398e-02],
        [-7.5648e+00,  9.6323e+00,  3.4567e-02,  4.2023e+00,  4.4635e+00,
         -1.3328e-01,  2.0401e+00,  5.3264e+00, -6.2784e+00, -3.7048e+00,
         -9.3470e+00, -2.0562e+00,  5.8618e+00, -3.3635e-02,  2.0363e-01,
          5.0433e+00,  7.2814e+00,  9.5323e+00, -2.4148e+00, -3.3678e+00,
         -3.5727e-02,  7.7623e+00],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2750e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2744e-03, -1.8737e-01, -6.9326e-02,
         -2.5298e-01, -1.2689e-02, -9.1087e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02],
        [-2.2585e-01, -1.6547e-01,  1.7509e-03, -1.2931e-02, -1.1901e-01,
          1.1574e-03, -1.6502e-02, -2.2722e-03, -1.8735e-01, -6.9324e-02,
         -2.5298e-01, -1.2688e-02, -9.1089e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7960e-01, -1.2929e-02, -1.9678e-02, -4.9673e-02,
          1.2308e-02, -3.1398e-02],
        [ 6.6450e-01,  3.1201e-01,  8.4127e-03,  3.4696e-02,  2.1235e-01,
          5.3877e-03,  5.6376e-02,  2.6891e-01,  5.5678e-01,  2.6166e-01,
          7.4701e-01,  8.5769e-02,  7.1346e-02,  3.8211e-02,  5.7275e-02,
          8.0058e-02,  2.9347e-01,  3.5786e-02,  1.1132e-01,  2.1139e-01,
          3.8209e-02,  1.3913e-01],
        [-2.2586e-01, -1.6548e-01,  1.7510e-03, -1.2930e-02, -1.1901e-01,
          1.1575e-03, -1.6502e-02, -2.2753e-03, -1.8737e-01, -6.9327e-02,
         -2.5298e-01, -1.2689e-02, -9.1085e-03,  1.2292e-02,  1.9855e-02,
         -1.7657e-02, -1.7961e-01, -1.2929e-02, -1.9679e-02, -4.9675e-02,
          1.2307e-02, -3.1398e-02]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-2.4313,  0.0078, -2.4313,  0.0873, -0.2625, -0.5234, -2.4313, -2.4314,
        -2.4313, -2.4313, -0.4369, -0.2571, -2.4314, -2.4313,  4.5769, -2.4313,
        -0.4006, -2.4313, -2.4313, -2.4313,  4.6668, -2.4313], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[  0.0334, -10.4940,   0.0334, -15.8008,  -9.7979,  -6.9452,   0.0334,
           0.0334,   0.0334,   0.0334,  -7.0927,  14.9535,   0.0334,   0.0334,
           4.2936,   0.0334,  -7.0565,   0.0334,   0.0334,   0.0334,   4.7631,
           0.0334]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 1.0813e+01,  2.9656e+00],
        [ 5.5664e-01,  1.1757e+01],
        [ 1.8618e+01,  2.3664e+00],
        [ 1.0637e+01,  1.5273e-02],
        [-1.4941e+01, -2.2181e+00],
        [-1.2849e+00,  1.3570e+00],
        [-1.2800e+00,  1.3116e+00],
        [-1.7122e+00,  6.5637e-01],
        [-2.0284e+00,  2.5259e-01],
        [ 9.3477e+00, -5.2188e-01],
        [-1.9314e+00,  2.3251e-01],
        [-1.8788e+00,  4.0167e-01],
        [-1.0523e+01, -1.6251e+00],
        [-8.3398e+00,  5.3496e+00],
        [-7.4426e+00,  1.0247e+01],
        [-1.2446e+01, -2.8588e+00],
        [-1.4240e+01, -3.1016e+00],
        [-1.0901e+01, -2.0063e+00],
        [-1.0106e+01, -2.4687e+00],
        [ 3.1771e+00,  1.1429e+01],
        [ 1.0907e+01,  2.2476e+00],
        [ 1.1102e+01,  1.0847e+01]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-5.5365,  7.0663,  2.9709, -9.6018, -1.5848, -4.5127, -4.5185, -4.9090,
        -4.9531, -9.4875, -4.9847, -4.9560,  5.4223,  3.0397,  6.7011, -3.5168,
        -2.9913,  3.2472,  0.4201,  7.7652, -4.3018,  6.4326], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 6.1957e-01, -3.4634e+00, -1.7479e+00,  1.1905e+00,  1.2460e-02,
          1.1948e-01,  1.3226e-01,  4.3984e-02, -1.1598e-02,  1.0215e+00,
         -6.1706e-03,  2.4414e-03, -2.5313e+00,  1.1746e+00, -7.8526e-01,
         -9.2734e-03,  2.7572e-03, -2.7562e+00, -1.8971e+00, -2.6434e+00,
         -4.2419e-01,  3.0293e-02],
        [-4.6968e-01, -1.5418e-01, -2.2179e+00, -4.7229e-01, -1.4815e-02,
         -2.6861e-02, -2.4100e-02,  6.5293e-03, -1.5585e-02, -3.8766e-01,
         -1.6068e-02, -1.1227e-02, -1.0214e+00, -1.1716e-01, -1.0616e-01,
         -5.8386e-03, -7.9498e-03, -5.2026e-01, -1.9652e-01, -4.4158e-01,
         -1.2068e+00, -1.2289e+00],
        [-9.0043e-01, -3.1328e-01, -2.4749e+00, -1.0214e+00, -5.5072e-03,
         -2.2407e-02, -1.9453e-02, -7.7448e-03,  4.4606e-03, -9.3610e-01,
          4.1020e-03,  2.5876e-03, -1.2488e+00, -4.6992e-02, -9.2699e-02,
         -2.2626e-03, -3.5666e-03, -6.7176e-01, -2.4800e-01, -8.7567e-01,
         -1.3802e+00, -7.7155e-01],
        [-4.7184e-01, -1.5540e-01, -2.2143e+00, -4.7815e-01, -1.4473e-02,
         -2.7281e-02, -2.4476e-02,  6.5809e-03, -1.5495e-02, -3.9563e-01,
         -1.5975e-02, -1.1107e-02, -1.0396e+00, -1.1822e-01, -1.0605e-01,
         -5.8775e-03, -7.9716e-03, -5.2621e-01, -1.9589e-01, -4.4421e-01,
         -1.2127e+00, -1.2341e+00],
        [-4.8450e-01, -1.6921e-01, -2.2399e+00, -4.9569e-01, -1.4212e-02,
         -2.5472e-02, -2.2971e-02,  5.3544e-03, -1.0943e-02, -4.2767e-01,
         -1.1482e-02, -7.9784e-03, -1.0434e+00, -1.0826e-01, -9.0719e-02,
         -6.2509e-03, -8.3116e-03, -5.2892e-01, -2.1129e-01, -4.5420e-01,
         -1.2241e+00, -1.0613e+00],
        [ 3.0119e-01,  9.1885e-01, -1.5837e+00, -8.5542e-01, -1.1953e-02,
         -1.9274e+00, -1.8752e+00, -1.4092e+00, -5.5076e-01,  1.0780e+00,
         -4.5548e-01, -9.9188e-01, -3.9286e+00,  1.1415e+00,  2.2999e+00,
         -1.2239e-02, -1.3323e-02, -2.7068e+00, -9.7625e-01,  4.2057e-01,
         -1.0808e+00, -1.2393e+00],
        [ 2.4582e-01, -1.1721e+01,  5.7285e-01, -6.6182e+00,  3.3458e+00,
          1.7362e-01,  1.7999e-01,  2.0080e-01,  2.8786e-01, -4.5146e+00,
          2.9196e-01,  1.9339e-01,  3.6973e+00, -2.2846e+00, -8.2839e+00,
          2.5629e+00,  2.7897e+00,  3.3397e+00,  3.6998e+00, -1.2216e+01,
          1.0269e-01, -7.8724e+00],
        [-2.7710e+00,  3.8384e+00, -3.8614e+00, -5.2497e+00,  1.4955e-01,
         -5.1488e-01, -5.0931e-01, -4.0831e-01, -1.3933e-01, -4.9036e+00,
         -1.0681e-01, -2.8754e-01,  2.6586e+00,  3.1018e+00,  6.0454e+00,
          5.3721e-01,  5.1709e-01,  2.4000e+00,  1.7467e+00,  2.8980e+00,
         -1.8615e+00,  1.3298e+00],
        [ 5.3996e+00,  1.7695e+01,  2.7980e+00,  6.7002e+00, -6.8933e+00,
          1.9716e-02,  1.5955e-02,  1.6031e-02, -1.9886e-01,  4.1219e+00,
         -1.8883e-01,  2.3240e-02, -8.0362e+00,  3.0849e+00,  1.4710e+01,
         -3.3033e+00, -3.8057e+00, -7.4740e+00, -6.2744e+00,  1.9113e+01,
          5.0855e+00,  2.1580e+01],
        [-4.6054e-01, -1.5864e-01, -2.1828e+00, -4.7962e-01, -1.3132e-02,
         -2.7434e-02, -2.4527e-02,  7.6509e-03, -1.3661e-02, -3.9854e-01,
         -1.4154e-02, -9.5939e-03, -1.0591e+00, -1.2246e-01, -9.9910e-02,
         -5.2767e-03, -7.3107e-03, -5.5050e-01, -2.1282e-01, -4.5037e-01,
         -1.2105e+00, -1.2384e+00],
        [-9.3210e-01, -5.0637e-01, -2.5650e+00, -1.2297e+00,  5.1007e-03,
         -1.3266e-02, -1.0812e-02, -6.5037e-03, -1.3910e-03, -1.1288e+00,
         -1.7836e-03, -1.9456e-03, -7.9371e-01, -5.5349e-02, -8.6527e-02,
          5.2059e-03,  5.8080e-03, -8.8163e-01, -4.5943e-01, -1.6628e+00,
         -1.1149e+00, -5.6400e-01],
        [-2.8460e+00, -1.8825e+01, -9.7046e+00, -3.0631e+00,  6.2381e+00,
          2.2284e-02,  2.2216e-02,  3.8058e-02,  1.2254e-02, -4.6393e+00,
          2.0356e-03,  4.3669e-02,  7.6060e+00, -3.1393e+00, -1.1899e+01,
          2.9927e+00,  3.5772e+00,  7.5127e+00,  7.0486e+00, -2.2653e+01,
         -1.0357e+01, -2.5603e+01],
        [-4.7448e-01, -1.5413e-01, -2.2021e+00, -4.7761e-01, -1.5017e-02,
         -2.6936e-02, -2.4189e-02,  6.2971e-03, -1.5709e-02, -3.9518e-01,
         -1.6194e-02, -1.1365e-02, -1.0353e+00, -1.1675e-01, -1.0676e-01,
         -6.0131e-03, -8.0879e-03, -5.2030e-01, -1.9318e-01, -4.4328e-01,
         -1.2192e+00, -1.2259e+00],
        [-6.9231e-01,  3.0014e+00,  2.7786e+00, -1.3175e+00,  3.0620e-04,
         -1.3308e-01, -1.3059e-01, -4.6677e-03, -1.5150e-02, -1.3574e+00,
         -1.8928e-02, -2.6791e-03,  2.1880e+00, -4.4040e-01,  8.1953e-01,
         -1.8323e-02, -1.1176e-02,  1.4720e+00,  4.3629e-01,  2.4554e+00,
          8.6002e-02, -2.4341e-01],
        [ 3.0175e+00, -1.5929e-01,  3.1082e+00,  1.6836e+00, -3.7655e+00,
          1.7569e-01,  1.8810e-01,  2.3150e-01, -5.4313e-01,  3.8072e+00,
         -5.3327e-01,  1.6719e-01,  6.0672e-02, -2.5586e+00, -3.6155e+00,
         -4.5190e+00, -4.8662e+00,  1.6404e-01, -1.7814e-01, -2.9936e-01,
          2.7050e+00, -1.8862e+00],
        [-6.1343e-01, -2.0997e-01, -2.3786e+00, -7.6186e-01, -1.9840e-02,
         -3.2273e-02, -3.0458e-02, -4.7454e-03,  5.8161e-03, -6.4208e-01,
          6.0534e-03,  3.5540e-03, -1.0330e+00, -6.3106e-02, -1.0050e-01,
         -7.6629e-03, -1.3412e-02, -4.8643e-01, -1.8407e-01, -5.2743e-01,
         -1.3866e+00, -9.2565e-01],
        [ 2.3232e-01,  3.1081e+00,  2.1861e+00,  1.7924e+00,  8.3474e-01,
         -4.2057e-01, -3.7750e-01, -8.6959e-02, -6.3586e-02,  1.4179e+00,
         -6.1088e-02, -4.4329e-02,  1.9436e-01, -4.4091e-01,  1.1123e+00,
          4.9760e-01,  7.0823e-01, -1.6870e-01, -3.9429e-01, -1.1351e+00,
          1.7979e-02, -1.2019e+00],
        [-9.3911e-03, -3.8280e+00, -3.1866e-01, -2.0025e+00, -3.0075e-02,
          4.3973e-02,  5.3990e-02,  1.0353e-01,  1.4874e-01, -1.8588e+00,
          1.5683e-01,  1.3914e-01, -1.0725e-01, -2.1520e-01, -2.7783e-01,
          5.4541e-02,  7.3731e-03, -1.3880e+00, -8.0744e-01, -5.4071e+00,
         -9.3933e-01,  6.6525e-02],
        [-2.0923e+00,  1.6783e+00,  2.1031e+00, -6.6800e+00,  1.9109e-04,
         -8.2756e-01, -7.5222e-01, -4.3503e-01, -1.2713e-01, -3.5556e+00,
         -7.5366e-02, -3.3382e-01,  9.4887e+00, -1.2212e+00,  5.7869e+00,
         -6.4339e-04, -3.5999e-03,  9.1765e+00,  6.6382e+00,  6.8362e-01,
          2.7993e-01, -2.2562e+00],
        [-5.5183e+00, -1.5095e+01, -2.8824e-01, -4.9346e+00,  5.3321e+00,
          1.5448e-01,  1.5735e-01,  1.6104e-01,  5.9928e-01, -2.7075e+00,
          5.5855e-01,  1.3923e-01,  3.0535e+00,  8.4196e-01, -6.5453e+00,
          4.6053e+00,  5.0922e+00,  3.6158e+00,  3.8865e+00, -1.4997e+01,
         -2.8857e+00, -4.2056e+00],
        [ 4.0156e-01, -1.0952e+00, -1.5738e+00, -4.3123e-01, -8.5229e-03,
         -6.6402e-01, -6.0136e-01, -2.4497e-01, -5.3144e-02, -2.8255e-01,
         -5.5575e-02, -9.1214e-02, -2.1121e+00,  1.5978e+00,  1.4435e+00,
         -1.0813e-03, -1.8711e-03, -2.1573e+00, -8.6345e-01, -1.7321e+00,
         -7.5512e-01,  5.2300e-01],
        [-1.9858e+00,  2.9033e+00, -2.5269e+00, -2.1485e+00,  2.2962e+00,
         -1.4441e+00, -1.3739e+00, -7.3427e-01,  6.2891e-02,  2.1944e-01,
          6.1358e-02, -2.6440e-01,  7.4516e-02,  1.7016e+00,  3.0581e+00,
          1.5196e+00,  1.8766e+00,  6.5632e-01,  1.1298e+00,  1.3664e+00,
         -2.7325e+00, -7.5516e-01]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-1.8466, -2.2256, -2.5068, -2.1943, -2.2514, -1.8834,  0.6255, -4.9456,
        -2.2024, -2.2158, -2.5964,  0.0491, -2.2135,  3.0825,  3.0734, -2.4047,
         2.5296, -1.0040,  2.4991, -0.5295, -2.0766, -2.4070], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-1.5234e-02,  7.2296e-05, -1.5502e-04,  5.9106e-05,  9.2680e-05,
         -2.2228e-02, -7.7352e-03, -1.5990e-01, -1.5103e+00,  6.1218e-05,
         -1.5306e-04, -1.3007e-05,  6.3929e-05, -1.5060e+00, -1.5008e+00,
         -2.1007e-04, -1.4999e+00, -5.4381e-03, -6.9054e-01, -3.7369e-03,
         -4.7102e-03, -3.5212e-02],
        [-8.7292e-03, -1.4222e-03,  7.6021e-04, -1.3898e-03, -1.5771e-03,
         -1.3307e-02, -5.1882e-03, -1.0878e-01, -8.2132e-01, -1.3260e-03,
          8.8522e-04, -2.6449e-04, -1.4244e-03, -8.2289e-01, -8.1366e-01,
          5.1250e-04, -8.1735e-01,  1.2221e-03, -3.1415e-01, -6.8756e-03,
          4.4122e-03, -3.5269e-02],
        [-2.1229e-02, -5.1093e-04, -3.4543e-04, -5.1941e-04, -5.4632e-04,
         -1.8385e-02, -9.4420e-03, -1.3731e-01, -1.4218e+00, -5.2075e-04,
         -3.2211e-04,  2.3184e-05, -5.1689e-04, -1.4173e+00, -1.4127e+00,
         -3.8173e-04, -1.4125e+00, -6.1909e-03, -6.2055e-01, -3.7929e-03,
         -7.1839e-03, -2.7972e-02],
        [-9.4172e-03, -2.1938e-04, -2.2482e-04, -2.0759e-04, -2.8288e-04,
         -1.6622e-02, -7.4112e-03, -1.3137e-01, -1.2415e+00, -2.0252e-04,
         -2.1593e-04, -7.4338e-05, -2.1553e-04, -1.2385e+00, -1.2343e+00,
         -1.4845e-04, -1.2328e+00, -5.0361e-03, -5.7108e-01, -3.7365e-03,
         -7.0540e-03, -2.5170e-02],
        [-1.0969e+00,  7.0714e-02,  2.8031e-01,  4.2693e-02,  2.8583e-01,
          5.4877e-01,  3.6379e+00, -1.3225e+00, -3.0535e+00,  2.8854e-01,
          9.2331e-01, -1.4907e+01,  2.7428e-02,  3.6135e+00,  3.4661e+00,
         -2.3553e-02,  3.3911e+00,  1.2464e+00,  2.0600e+00,  5.6362e+00,
         -4.8358e-01,  4.4222e-01],
        [-1.1325e-02, -1.4138e-04,  1.4500e-04, -1.5008e-04, -1.0196e-03,
         -8.7395e-03, -5.0212e-04, -1.4891e-01, -9.6424e-01, -1.5847e-04,
          8.4481e-05, -6.7668e-04, -1.4540e-04, -9.6261e-01, -9.4804e-01,
         -9.4017e-05, -9.5700e-01,  4.4294e-03, -4.5741e-01, -5.5136e-03,
          2.2288e-03, -3.6784e-02],
        [-2.4271e-02, -7.7962e-04, -2.2040e-04, -7.9007e-04, -5.4691e-04,
         -1.4880e-02, -9.2166e-03, -1.1032e-01, -1.2944e+00, -7.8678e-04,
         -1.4609e-04, -3.3668e-05, -7.9327e-04, -1.2897e+00, -1.2879e+00,
         -3.7474e-04, -1.2861e+00, -9.7262e-03, -5.3746e-01, -3.8536e-03,
         -1.0548e-02, -2.4508e-02],
        [ 3.9237e+00, -6.2937e-02,  8.2976e-01, -8.9553e-02,  1.8773e-01,
          2.5280e+00,  4.4063e+00, -5.1176e-01,  2.7121e+00,  1.5038e-01,
          2.1898e+00, -6.3975e+00, -1.0291e-01,  9.8757e-01,  1.1535e+00,
          5.7770e-02,  9.4780e-01,  2.9512e+00,  2.3504e+00,  1.6411e+00,
          3.1498e+00,  1.2727e-01],
        [-1.4494e-02, -1.9430e-04, -1.7724e-04, -2.0127e-04, -2.0117e-04,
         -1.5493e-02, -8.1680e-03, -1.3258e-01, -1.3345e+00, -2.0053e-04,
         -1.8098e-04, -1.8463e-05, -1.9899e-04, -1.3303e+00, -1.3262e+00,
         -2.7675e-04, -1.3255e+00, -6.2074e-03, -5.8710e-01, -4.1919e-03,
         -7.5895e-03, -2.9301e-02],
        [-2.1892e-02, -3.5780e-04, -4.8405e-04, -3.6317e-04, -3.6356e-04,
         -2.3657e-02, -1.6951e-02, -9.6588e-02, -1.1849e+00, -3.5150e-04,
         -4.0838e-04, -1.7243e-05, -3.6464e-04, -1.1843e+00, -1.1795e+00,
         -3.3804e-04, -1.1790e+00, -7.4055e-03, -5.7283e-01, -5.4422e-03,
         -1.0076e-02, -3.1398e-02],
        [-2.3028e+00, -2.1890e-02, -8.3502e-03, -5.3786e-02,  9.5685e-02,
         -8.9290e-01, -1.4767e+01,  7.5055e+00,  3.0752e+00,  1.1812e-01,
         -7.0438e-02,  2.1906e-03, -5.7019e-02, -7.6423e-01, -1.3833e+00,
         -7.3209e-03, -7.3795e-01, -2.2229e+00,  1.8670e+00, -1.4910e+01,
         -1.6032e+00,  1.4609e+00],
        [ 2.4319e+00,  1.1747e-01, -1.6596e-01,  8.9778e-02,  3.1240e-01,
         -1.2941e+00, -9.2455e-01, -5.3120e-01,  5.2163e+00,  3.3676e-01,
         -2.0670e-01,  2.2187e+01,  7.3275e-02,  3.7788e-01,  7.5700e-01,
         -1.2275e-01,  4.8364e-01, -2.5823e+00,  1.5965e+00, -2.2668e+00,
         -6.5383e-01, -2.8611e+00],
        [-2.1115e-02, -3.0744e-04, -1.4460e-04, -2.9289e-04, -3.5131e-04,
         -2.2539e-02, -1.0971e-02, -1.5511e-01, -1.5086e+00, -2.8377e-04,
         -1.2594e-04,  2.8039e-05, -3.0274e-04, -1.5044e+00, -1.4994e+00,
         -3.7557e-04, -1.4986e+00, -6.5951e-03, -6.8458e-01, -3.5928e-03,
         -7.8039e-03, -3.0722e-02],
        [-1.4210e-02,  2.7210e-04, -1.6876e-04,  2.6752e-04,  2.9104e-04,
         -2.2712e-02, -5.7647e-03, -1.5704e-01, -1.4740e+00,  2.7486e-04,
         -1.6774e-04, -4.4364e-05,  2.6776e-04, -1.4699e+00, -1.4648e+00,
         -1.4749e-04, -1.4640e+00, -5.0059e-03, -6.6920e-01, -3.9010e-03,
         -5.3125e-03, -3.3932e-02]], device='cuda:0'))])
loaded xi:  855.6613
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857
 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857 0.07142857
 0.07142857 0.07142857]
W_T_mean: 8576.841924009083
W_T_median: 5042.380921625826
W_T_pctile_5: 103.64169553244135
W_T_CVAR_5_pct: -371.9331258181762
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -34581.53721869686
Current xi:  [870.81116]
objective value function right now is: -34581.53721869686
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -35311.617854008706
Current xi:  [886.0057]
objective value function right now is: -35311.617854008706
6.0% of gradient descent iterations done. Method = Adam
Current xi:  [901.0519]
objective value function right now is: -35206.03650139716
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -35901.31835640725
Current xi:  [915.9907]
objective value function right now is: -35901.31835640725
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -36188.30431129189
Current xi:  [930.735]
objective value function right now is: -36188.30431129189
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [945.4621]
objective value function right now is: -35549.69055332228
14.000000000000002% of gradient descent iterations done. Method = Adam
new min fval:  -36356.784178282185
Current xi:  [959.7179]
objective value function right now is: -36356.784178282185
16.0% of gradient descent iterations done. Method = Adam
new min fval:  -36808.36291140318
Current xi:  [974.14294]
objective value function right now is: -36808.36291140318
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -36970.73460651988
Current xi:  [988.17645]
objective value function right now is: -36970.73460651988
20.0% of gradient descent iterations done. Method = Adam
new min fval:  -37189.20642831817
Current xi:  [1002.5729]
objective value function right now is: -37189.20642831817
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -37990.000493590785
Current xi:  [1016.53314]
objective value function right now is: -37990.000493590785
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [1030.0247]
objective value function right now is: -37970.403114842105
26.0% of gradient descent iterations done. Method = Adam
new min fval:  -38171.644755065114
Current xi:  [1043.8967]
objective value function right now is: -38171.644755065114
28.000000000000004% of gradient descent iterations done. Method = Adam
new min fval:  -38539.08906654312
Current xi:  [1057.9573]
objective value function right now is: -38539.08906654312
30.0% of gradient descent iterations done. Method = Adam
new min fval:  -39000.611703698
Current xi:  [1071.5817]
objective value function right now is: -39000.611703698
32.0% of gradient descent iterations done. Method = Adam
new min fval:  -39222.24356784865
Current xi:  [1084.6227]
objective value function right now is: -39222.24356784865
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [1098.1205]
objective value function right now is: -39174.96111523727
36.0% of gradient descent iterations done. Method = Adam
new min fval:  -39777.89647180321
Current xi:  [1111.1575]
objective value function right now is: -39777.89647180321
38.0% of gradient descent iterations done. Method = Adam
new min fval:  -39786.20480265433
Current xi:  [1124.576]
objective value function right now is: -39786.20480265433
40.0% of gradient descent iterations done. Method = Adam
new min fval:  -39989.66524378398
Current xi:  [1137.4562]
objective value function right now is: -39989.66524378398
42.0% of gradient descent iterations done. Method = Adam
new min fval:  -40408.63079448222
Current xi:  [1150.2579]
objective value function right now is: -40408.63079448222
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [1163.338]
objective value function right now is: -39697.71106954354
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [1175.8695]
objective value function right now is: -40341.304718327054
48.0% of gradient descent iterations done. Method = Adam
new min fval:  -40745.00134597526
Current xi:  [1187.9753]
objective value function right now is: -40745.00134597526
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [1200.6576]
objective value function right now is: -40560.90392254578
52.0% of gradient descent iterations done. Method = Adam
new min fval:  -40760.57910051559
Current xi:  [1212.755]
objective value function right now is: -40760.57910051559
54.0% of gradient descent iterations done. Method = Adam
new min fval:  -41177.068395051545
Current xi:  [1225.38]
objective value function right now is: -41177.068395051545
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [1237.2631]
objective value function right now is: -41038.27013256115
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [1248.6691]
objective value function right now is: -40894.75255707395
60.0% of gradient descent iterations done. Method = Adam
new min fval:  -41203.2911506267
Current xi:  [1259.1337]
objective value function right now is: -41203.2911506267
62.0% of gradient descent iterations done. Method = Adam
new min fval:  -41506.53856011969
Current xi:  [1270.2251]
objective value function right now is: -41506.53856011969
64.0% of gradient descent iterations done. Method = Adam
new min fval:  -41974.35130954908
Current xi:  [1280.757]
objective value function right now is: -41974.35130954908
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [1291.3593]
objective value function right now is: -41648.72692531424
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [1301.151]
objective value function right now is: -41959.89789646257
70.0% of gradient descent iterations done. Method = Adam
new min fval:  -42023.30719774338
Current xi:  [1310.734]
objective value function right now is: -42023.30719774338
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -42372.36211310177
Current xi:  [1312.943]
objective value function right now is: -42372.36211310177
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -42490.78759991279
Current xi:  [1315.1328]
objective value function right now is: -42490.78759991279
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [1317.4106]
objective value function right now is: -42288.507343128564
78.0% of gradient descent iterations done. Method = Adam
new min fval:  -42546.605566025966
Current xi:  [1319.5226]
objective value function right now is: -42546.605566025966
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [1321.8271]
objective value function right now is: -42444.74084884796
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [1324.1787]
objective value function right now is: -42525.28228620076
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [1326.4232]
objective value function right now is: -42536.953852710234
86.0% of gradient descent iterations done. Method = Adam
new min fval:  -42582.71653246385
Current xi:  [1328.4741]
objective value function right now is: -42582.71653246385
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [1330.7059]
objective value function right now is: -42530.6602441195
new min fval from sgd:  -42590.15424295957
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [1332.9695]
objective value function right now is: -42590.15424295957
new min fval from sgd:  -42637.60862562114
new min fval from sgd:  -42667.99693357866
new min fval from sgd:  -42687.05247106657
new min fval from sgd:  -42692.867663011355
new min fval from sgd:  -42695.155941690566
new min fval from sgd:  -42699.87306616413
new min fval from sgd:  -42706.29150213582
new min fval from sgd:  -42717.13498915581
new min fval from sgd:  -42718.911888579474
new min fval from sgd:  -42719.19950353493
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [1335.0756]
objective value function right now is: -42679.236884115264
new min fval from sgd:  -42723.10388804203
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [1337.0944]
objective value function right now is: -42472.85822771554
new min fval from sgd:  -42724.80207780859
new min fval from sgd:  -42732.76773097428
new min fval from sgd:  -42735.04430168961
new min fval from sgd:  -42739.88541407651
new min fval from sgd:  -42740.8840531291
new min fval from sgd:  -42741.28503046595
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [1339.3116]
objective value function right now is: -42657.29070306763
new min fval from sgd:  -42744.6726666709
new min fval from sgd:  -42748.18997601701
new min fval from sgd:  -42750.45528167583
new min fval from sgd:  -42750.534269720876
new min fval from sgd:  -42753.055066263216
new min fval from sgd:  -42755.83452124834
new min fval from sgd:  -42757.99151595005
new min fval from sgd:  -42759.5457414425
new min fval from sgd:  -42760.9822518244
new min fval from sgd:  -42762.05367671421
new min fval from sgd:  -42763.6515613627
new min fval from sgd:  -42766.88409655942
new min fval from sgd:  -42769.057453298155
new min fval from sgd:  -42770.214217347515
new min fval from sgd:  -42770.682780336276
new min fval from sgd:  -42770.73931700207
new min fval from sgd:  -42774.11692815318
new min fval from sgd:  -42776.89661346764
new min fval from sgd:  -42780.02815985563
new min fval from sgd:  -42782.57972574094
new min fval from sgd:  -42782.75387521967
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [1340.7684]
objective value function right now is: -42774.377256391264
new min fval from sgd:  -42782.78634025594
new min fval from sgd:  -42783.10858492929
new min fval from sgd:  -42783.56149990275
new min fval from sgd:  -42784.18941865716
new min fval from sgd:  -42784.95184972906
new min fval from sgd:  -42785.542078222425
new min fval from sgd:  -42786.04264675571
new min fval from sgd:  -42786.10186194309
new min fval from sgd:  -42786.671588686484
new min fval from sgd:  -42787.77416747676
new min fval from sgd:  -42787.85806763664
new min fval from sgd:  -42789.31759633
new min fval from sgd:  -42791.25092896774
new min fval from sgd:  -42792.993053174345
new min fval from sgd:  -42794.004184169295
new min fval from sgd:  -42795.042016860665
new min fval from sgd:  -42795.888541967965
new min fval from sgd:  -42796.18938501692
new min fval from sgd:  -42796.41479069007
new min fval from sgd:  -42796.67038803434
new min fval from sgd:  -42797.36169665628
new min fval from sgd:  -42798.15764270835
new min fval from sgd:  -42798.80364676728
new min fval from sgd:  -42799.361268977904
new min fval from sgd:  -42799.75513575791
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [1341.2201]
objective value function right now is: -42763.80618215025
min fval:  -42799.75513575791
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-1.0286e+01,  8.1641e+00],
        [-8.3740e+00, -1.1845e+01],
        [ 3.1967e-01,  8.5333e+00],
        [ 1.2197e+01,  2.5167e+00],
        [-3.8815e+00, -2.9019e+00],
        [-5.9141e+00,  6.6765e+00],
        [ 8.7605e+00, -4.8031e-01],
        [ 1.5104e+01, -9.0874e-01],
        [-9.3125e+00,  7.5854e+00],
        [-1.0112e+01,  6.3289e+00],
        [-8.6353e+00,  9.4168e+00],
        [-7.2896e+00,  7.0219e+00],
        [ 1.3875e+01, -6.2661e-02],
        [-5.0870e-01,  7.4903e+00],
        [ 1.2900e+01,  7.5287e-01],
        [ 6.4346e+00, -3.8345e-01],
        [-2.5679e+01, -8.0559e+00],
        [ 1.3771e+01,  2.2283e-02],
        [-7.6813e+00,  6.7980e+00],
        [-8.6624e+00,  5.8673e+00],
        [ 1.9098e+00,  5.2857e+00],
        [-3.3228e+00, -2.6852e+00]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ 5.2649, -7.2860, -2.6043, -8.7811, -8.3503, -2.5468, -9.2860, -9.2443,
         3.0238, -0.4875,  5.8825,  0.8112, -8.7571, -2.3743, -8.4598, -9.3032,
        -6.7553, -8.6918,  0.6481, -0.5086, -2.3256, -8.5872], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ 5.7236e+00,  7.2020e+00,  5.5534e-01,  2.5970e+00,  1.7275e-01,
          1.2228e-01,  9.6615e-02,  3.1056e+00,  6.2916e+00,  6.0705e-01,
          4.2497e+00,  2.2830e+00,  3.0027e+00,  4.1613e-01,  2.7653e+00,
          3.0396e-02,  1.1025e+00,  3.0392e+00,  2.0761e+00,  1.0646e+00,
          1.3259e+00,  1.4737e-01],
        [-9.0332e+00,  1.5382e+01,  6.6881e-02,  1.2247e+01,  6.7455e-01,
         -9.0629e+00,  3.1930e+00,  1.5556e+01, -4.4472e+00, -3.0815e+00,
         -1.0831e+01, -1.4654e+00,  1.1816e+01, -4.9624e+00,  6.8698e+00,
          1.5973e+00,  6.7870e+00,  1.3216e+01, -1.3289e+00, -3.6160e+00,
         -3.0879e+00,  9.4682e-01],
        [-2.4200e-01,  7.9496e-01, -6.9645e-02,  5.4176e-02, -1.8826e-03,
         -2.6809e-02, -3.1840e-03,  2.4656e-02, -6.7646e-02, -2.1030e-02,
         -7.5684e-01, -5.0494e-02,  1.1317e-02,  3.7717e-02, -1.6994e-03,
         -8.3206e-04,  4.8282e-02,  1.0174e-02, -6.3370e-02, -2.9681e-02,
         -2.7720e-02, -1.9621e-03],
        [-9.6216e+00,  1.6086e+01, -7.5716e-02,  1.1866e+01,  1.5298e+00,
         -6.1501e+00,  5.0757e+00,  1.4904e+01, -6.1694e+00, -1.5094e+00,
         -1.1682e+01, -2.1171e+00,  1.1141e+01, -3.4659e+00,  6.8194e+00,
          1.8393e+00,  7.4703e+00,  1.1870e+01, -1.3410e+00, -2.7808e+00,
         -1.8499e+00,  2.1034e+00],
        [-7.7418e+00,  1.3740e+01, -5.5980e-01,  9.4708e+00,  4.9101e-01,
         -8.7034e+00,  2.1206e+00,  1.5723e+01, -3.7621e+00, -3.7209e+00,
         -9.5867e+00, -1.7823e+00,  1.2061e+01, -4.9061e+00,  6.3226e+00,
          1.5921e+00,  6.0407e+00,  1.5820e+01, -2.2212e+00, -3.2302e+00,
         -2.8884e+00,  4.1914e-01],
        [-7.2525e+00,  1.3198e+01, -1.7616e+00,  8.9242e+00,  2.0660e-01,
         -8.6553e+00,  1.5583e+00,  1.3719e+01, -2.9676e+00, -3.5126e+00,
         -9.8416e+00, -1.2828e+00,  1.2008e+01, -4.0958e+00,  6.2270e+00,
          8.9799e-01,  5.7211e+00,  1.4601e+01, -1.3571e+00, -3.0084e+00,
         -2.6691e+00, -2.7031e-02],
        [ 6.0465e+00,  7.0244e+00,  2.6226e-01,  2.0158e+00,  2.0907e-01,
          1.2406e-01, -1.7593e-02,  5.0700e+00,  6.3111e+00,  6.2830e-01,
          4.8497e+00,  1.2905e+00,  4.6299e+00,  3.6441e-01,  3.3980e+00,
         -1.4075e-02,  1.0520e+00,  4.7097e+00,  1.1387e+00,  5.7830e-01,
          8.1980e-01,  1.7957e-01],
        [ 6.0565e+00,  7.2910e+00,  4.3923e-01,  2.5137e+00,  1.8789e-01,
          1.2657e-01,  7.0627e-02,  3.8865e+00,  6.5676e+00,  6.3426e-01,
          4.6547e+00,  2.0712e+00,  3.6893e+00,  4.2437e-01,  3.1503e+00,
          1.7519e-02,  1.0320e+00,  3.7469e+00,  1.8500e+00,  9.6936e-01,
          1.1429e+00,  1.6096e-01],
        [-3.8168e-01,  4.0663e-01, -1.3331e-01,  4.9395e-01, -1.9973e-03,
         -1.8237e-01, -3.1143e-03,  9.6622e-03, -8.7830e-02, -5.4852e-02,
         -8.9616e-01, -9.3152e-02, -2.2215e-02,  6.8424e-01, -8.3434e-02,
         -1.4367e-03, -2.6629e-02, -1.9471e-02, -1.8905e-01, -1.1002e-01,
         -2.0729e-01, -2.0393e-03],
        [ 5.8047e+00,  7.2610e+00,  5.4333e-01,  2.6156e+00,  1.7560e-01,
          1.2368e-01,  9.6213e-02,  3.1685e+00,  6.3655e+00,  6.1247e-01,
          4.3107e+00,  2.2674e+00,  3.0611e+00,  4.2064e-01,  2.8081e+00,
          2.9354e-02,  1.0771e+00,  3.1002e+00,  2.0562e+00,  1.0594e+00,
          1.3057e+00,  1.5002e-01],
        [-7.3002e+00,  1.3242e+01, -1.7190e+00,  9.7609e+00,  1.6076e-01,
         -6.9662e+00,  1.4540e+00,  1.2219e+01, -3.3211e+00, -3.3743e+00,
         -1.0351e+01, -1.1286e+00,  1.0693e+01, -3.6161e+00,  5.6131e+00,
          4.1615e-01,  5.8852e+00,  1.2991e+01, -1.4765e+00, -3.3048e+00,
         -2.0166e+00, -3.9977e-02],
        [ 7.9520e+00, -1.3626e+01, -2.6259e-01, -1.3102e+01, -1.0880e+00,
          7.7343e+00, -3.3957e+00, -1.4206e+01,  4.1915e+00,  4.9441e+00,
          1.0538e+01,  2.5346e+00, -1.0950e+01,  3.9740e+00, -6.2268e+00,
         -1.0653e+00, -6.4125e+00, -1.3890e+01,  2.9864e+00,  4.1658e+00,
          1.6285e+00, -1.3469e+00],
        [ 6.0745e+00,  7.1810e+00,  3.4054e-01,  2.2122e+00,  1.9478e-01,
          1.2482e-01,  3.1424e-02,  4.5562e+00,  6.3976e+00,  6.1829e-01,
          4.7972e+00,  1.6345e+00,  4.2257e+00,  4.1197e-01,  3.3034e+00,
          4.5300e-03,  1.0172e+00,  4.2984e+00,  1.4390e+00,  7.6545e-01,
          9.8558e-01,  1.6701e-01],
        [ 5.6956e+00,  7.1805e+00,  5.5877e-01,  2.5884e+00,  1.7179e-01,
          1.2178e-01,  9.6564e-02,  3.0897e+00,  6.2662e+00,  6.0528e-01,
          4.2313e+00,  2.2879e+00,  2.9878e+00,  4.1434e-01,  2.7534e+00,
          3.0681e-02,  1.1125e+00,  3.0236e+00,  2.0825e+00,  1.0661e+00,
          1.3321e+00,  1.4646e-01],
        [ 1.1635e+00,  7.6806e-01,  4.4868e-02,  4.0788e-02,  9.2612e-03,
          4.8356e-02,  6.1749e-03,  7.3700e-02,  2.6005e-01,  6.7730e-02,
          1.5204e+00,  1.1255e-01,  6.3619e-02,  3.6746e-02,  5.1559e-02,
          5.2666e-03,  8.2311e-02,  6.6240e-02,  1.2147e-01,  9.3942e-02,
          1.7819e-02,  7.4705e-03],
        [ 5.7070e+00,  7.1893e+00,  5.5741e-01,  2.5920e+00,  1.7218e-01,
          1.2199e-01,  9.6594e-02,  3.0959e+00,  6.2766e+00,  6.0600e-01,
          4.2387e+00,  2.2860e+00,  2.9936e+00,  4.1509e-01,  2.7581e+00,
          3.0568e-02,  1.1084e+00,  3.0297e+00,  2.0799e+00,  1.0655e+00,
          1.3296e+00,  1.4683e-01],
        [-7.5606e+00,  1.3488e+01, -1.3284e+00,  8.2320e+00,  2.4817e-01,
         -9.4040e+00,  1.5895e+00,  1.3508e+01, -3.5738e+00, -2.2605e+00,
         -1.0409e+01, -1.6392e+00,  1.1220e+01, -2.7216e+00,  5.8359e+00,
          9.3643e-01,  6.0266e+00,  1.3852e+01, -1.1595e+00, -2.5800e+00,
         -2.1504e+00,  6.8744e-02],
        [-1.0687e-01,  1.0297e+00, -5.9720e-02,  3.8385e-02, -1.6591e-03,
         -2.3605e-02, -4.2364e-03,  2.5867e-02, -2.0342e-02, -1.9439e-02,
         -6.8461e-01, -4.7770e-02,  1.2877e-02,  1.7067e-02,  3.0096e-04,
         -6.0613e-04,  2.1024e-01,  1.1711e-02, -5.6463e-02, -2.7280e-02,
         -2.2477e-02, -1.8743e-03],
        [-3.7942e-01,  9.1052e-02,  4.9971e-03, -4.1803e-04,  3.1528e-04,
         -5.4879e-03, -2.5437e-04, -2.6774e-03, -8.7961e-02, -4.1729e-03,
         -6.2670e-01, -1.4547e-02, -2.2400e-03,  2.7259e-03, -1.1920e-03,
         -3.6465e-04,  9.0009e-03, -2.4798e-03, -1.4130e-02, -6.3561e-03,
         -9.4271e-03,  3.6867e-04],
        [ 5.8519e+00,  7.2911e+00,  5.3435e-01,  2.6219e+00,  1.7734e-01,
          1.2446e-01,  9.5389e-02,  3.2215e+00,  6.4097e+00,  6.1603e-01,
          4.3527e+00,  2.2569e+00,  3.1098e+00,  4.2283e-01,  2.8409e+00,
          2.8516e-02,  1.0649e+00,  3.1506e+00,  2.0435e+00,  1.0557e+00,
          1.2914e+00,  1.5162e-01],
        [ 1.1806e+00,  7.8330e-01,  4.3905e-02,  4.0555e-02,  9.4564e-03,
          4.8273e-02,  6.8239e-03,  7.4767e-02,  2.6340e-01,  6.8429e-02,
          1.5425e+00,  1.1324e-01,  6.4194e-02,  3.5956e-02,  5.1771e-02,
          5.6131e-03,  8.1672e-02,  6.6799e-02,  1.2246e-01,  9.5146e-02,
          1.6805e-02,  7.6061e-03],
        [-2.9501e-01,  7.6989e-02, -1.9905e-01,  1.4911e+00, -8.9170e-04,
         -5.1095e-01, -2.9423e-03,  5.4408e-02,  4.6487e-02, -2.7956e-01,
         -9.2159e-01, -6.7565e-02,  1.8561e-02,  2.0602e+00, -1.3095e-01,
         -1.2820e-03, -1.3030e-02,  3.7334e-02, -3.6710e-01, -3.5065e-01,
         -9.3362e-01, -9.9093e-04]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-3.0618,  1.9188, -4.6717,  2.2958,  1.2052,  0.9209, -3.1334, -3.2111,
        -4.5253, -3.0893,  1.0356, -2.1244, -3.2081, -3.0534,  4.5908, -3.0568,
         1.0638, -4.7980, -3.8597, -3.1076,  4.6843, -4.1404], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 1.6837e+00, -1.7482e+01, -2.3487e-01, -2.5065e+01, -1.5007e+01,
         -1.1645e+01,  2.5103e+00,  2.0017e+00, -2.2444e-01,  1.7386e+00,
         -1.1815e+01,  1.8376e+01,  2.1612e+00,  1.6658e+00,  3.6864e+00,
          1.6730e+00, -1.2926e+01, -1.9614e-01,  1.0049e-02,  1.7736e+00,
          4.1539e+00, -2.6819e-02]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -2.3145,   0.2997],
        [  0.7452,  13.5561],
        [ 27.1518,   3.0956],
        [ 12.8383,  -0.1555],
        [ -8.8634,   1.5359],
        [ -2.5357,   0.3413],
        [ -2.5436,   0.3603],
        [ -1.9358,   3.0745],
        [ -2.0368,   1.3894],
        [  6.7726,  -0.1927],
        [ -2.3642,   0.2832],
        [ -2.3938,   0.3723],
        [-13.3116,  -1.3549],
        [ -7.9429,  10.3607],
        [ -5.6779,  12.9800],
        [ -2.5406,   0.3593],
        [ -2.5619,   0.2883],
        [-13.6331,  -3.3556],
        [-13.0015,  -5.0154],
        [  4.1915,  14.1956],
        [ 10.5637,   3.4615],
        [ 13.8558,  12.7190]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ -8.4339,   8.4778,   2.1191, -11.5836,  -7.2772,  -8.3871,  -8.3842,
         -9.5739,  -9.2714, -14.3010,  -8.7742,  -8.5221,   6.4568,   3.3999,
          7.7684,  -8.3824,  -8.7859,   2.8993,  -1.8362,   8.8022,  -6.5491,
          6.9225], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-1.3688e-01, -2.9330e+00, -4.0163e+00,  2.2826e+00,  1.4885e-01,
         -1.3237e-01, -1.2127e-01, -6.5995e-01, -6.9290e-01,  7.3538e-01,
         -9.4533e-02, -9.8484e-02, -1.0222e+01,  3.2662e+00,  2.5252e+00,
         -1.1583e-01, -1.5969e-01, -3.4556e+00, -1.7381e+00,  2.5896e-02,
          2.6333e-01,  8.6733e-01],
        [-1.0885e-03, -2.5937e-01, -4.6975e+00, -1.4401e+00,  4.6010e-05,
         -1.1942e-03, -1.1457e-03, -6.3823e-02, -8.4257e-04,  2.6230e-03,
         -1.8355e-03, -1.1893e-03, -1.0429e+00, -1.1650e-01, -4.6578e-01,
         -1.1521e-03, -1.9995e-03, -4.4916e-01, -1.5741e-01, -3.4585e-01,
         -5.2330e-01, -1.8430e+00],
        [ 3.4011e-01,  2.4507e+00, -5.0582e+00, -4.4948e+00,  5.9300e-01,
          3.7425e-01,  3.7977e-01, -1.1304e+00,  1.6408e-01, -2.1518e-03,
          3.0507e-01,  3.3922e-01, -2.7242e-02,  1.4088e+00,  2.8169e+00,
          3.7960e-01,  3.0903e-01,  1.2529e+00,  2.2890e+00,  1.3793e+00,
         -4.8291e+00, -1.6299e+00],
        [ 9.8690e-04,  2.1087e-01, -4.5592e+00, -2.5233e+00, -3.3508e-03,
         -7.1328e-05, -1.7061e-05,  7.2932e-02,  1.8962e-02,  6.5863e-03,
         -1.9502e-03,  4.1144e-05, -1.7871e+00,  1.3756e-01, -9.0306e-01,
         -8.8978e-06, -2.8529e-03, -4.9393e-01, -1.7032e-02,  4.4279e-01,
         -7.0446e-01, -1.3636e+00],
        [ 2.5831e-02, -4.7067e+00, -2.3782e+00,  1.6374e+00, -5.5983e-03,
          2.9486e-02,  2.9178e-02, -8.2417e-01, -1.6857e-02,  8.1907e-01,
          3.0330e-02,  2.7731e-02, -6.6493e+00,  8.5805e-01, -4.3682e+00,
          2.9009e-02,  2.9247e-02, -4.6125e+00, -4.9830e+00, -8.1093e-01,
          2.4875e+00, -1.3344e+00],
        [-1.1517e-01,  2.3220e-01, -2.6771e+00, -3.6873e+00, -2.8484e-01,
         -1.1758e-01, -1.3233e-01, -1.0656e+00, -2.7967e-01,  2.5804e-02,
         -6.8874e-04,  2.2084e-01, -3.1420e+00,  1.9115e+00,  2.5502e+00,
         -1.2502e-01, -1.7061e-02, -7.2299e-01,  3.0251e-01, -3.4087e-01,
         -1.0144e+00, -1.4847e+00],
        [ 8.5013e-02, -1.3290e+01, -9.8319e-01, -5.8701e+00, -4.4658e-01,
          1.5940e-01,  1.1434e-01, -1.0319e-02,  7.1246e-02, -3.1083e+00,
          1.4461e-01,  1.3797e-01,  5.3593e+00, -3.9068e+00, -9.4102e+00,
          1.2126e-01,  1.5152e-01,  4.1000e+00,  4.2904e+00, -1.2444e+01,
         -6.3877e-01, -3.9299e+00],
        [-1.4757e-02,  1.0014e+00, -3.1335e+00,  2.6647e+00, -1.6765e-01,
          4.6449e-02, -3.2184e-02,  1.4507e-01,  1.4881e-01,  2.9381e+00,
          1.7934e-01,  1.3019e-01,  1.2834e+00,  9.7134e+00,  1.3619e+01,
         -2.0337e-02,  1.8004e-01,  1.4339e+00, -2.8208e+00,  4.4129e+00,
         -8.4924e-01,  3.6485e+00],
        [-1.1400e-01,  2.1107e+01,  4.0889e+00,  1.8623e+01, -1.1094e+00,
         -1.2240e-01, -1.2683e-01,  7.0546e-02,  3.5017e-02,  1.3787e+00,
         -5.0939e-02, -7.1332e-02, -1.1012e+01,  8.9418e-01,  1.3773e+01,
         -1.1695e-01, -4.6763e-02, -9.2865e+00, -6.7124e+00,  2.4151e+01,
          8.2615e+00,  1.9771e+01],
        [-2.5913e-01,  2.0604e+00, -3.8231e+00,  1.4817e+00,  1.9642e-02,
         -3.0869e-01, -3.0078e-01, -5.9751e-01,  2.2625e-01,  1.8369e+00,
         -2.4514e-01, -2.9461e-01, -3.5352e+00, -5.3610e+00,  2.2465e+00,
         -3.0638e-01, -2.4312e-01, -4.8044e-02,  1.3894e+00,  1.2865e+00,
         -9.5717e-01, -6.3136e-01],
        [-1.0845e-02,  2.4585e-01, -4.6291e+00, -1.3341e+00, -4.5381e-03,
         -1.0709e-02, -1.0681e-02, -2.8047e-01, -2.7461e-03, -5.6723e-03,
         -1.0071e-02, -1.0683e-02, -2.5740e-01,  2.3588e-01,  3.6679e-01,
         -1.0703e-02, -9.9643e-03,  8.7412e-02, -1.6922e-01,  3.1514e-02,
         -1.5695e+00, -2.0197e+00],
        [ 1.4064e-01, -3.0913e+01, -9.3251e+00, -2.6190e+01,  4.9739e-01,
          1.5300e-01,  1.4859e-01,  3.7019e-03,  5.4031e-02,  4.2824e-02,
          1.9654e-01,  1.9084e-01,  7.6990e+00, -1.8746e+00, -1.4867e+01,
          1.5079e-01,  2.0525e-01,  7.3553e+00,  6.9011e+00, -3.8148e+01,
         -2.1048e+01, -3.3586e+01],
        [ 3.1930e-03, -2.6899e-01, -4.6328e+00, -7.8431e-01,  4.9480e-04,
          3.0351e-03,  2.9942e-03, -1.7842e-01, -3.2032e-03, -4.3751e-03,
          2.5312e-03,  2.8314e-03, -1.2796e+00, -3.7255e-01, -4.7965e-01,
          3.0044e-03,  2.1874e-03, -5.5180e-01, -6.2163e-02, -5.7170e-01,
         -5.8118e-01, -2.2419e+00],
        [-1.2503e-01,  9.9244e+00,  3.0451e+00, -4.2822e+00,  1.5004e-05,
         -1.2396e-01, -1.1761e-01,  5.3015e-01, -5.0628e-02, -3.9190e-01,
         -1.4112e-01, -1.4867e-01,  1.6888e+01, -5.8630e-01,  3.3350e+00,
         -1.2020e-01, -1.2810e-01,  1.7529e+01,  1.1425e+01, -1.1077e+00,
         -3.9300e-01, -1.6832e+00],
        [-3.7087e-02,  4.8478e-01,  5.7979e+00,  1.3305e+00, -4.0448e-02,
         -3.7340e-02, -3.7202e-02,  7.4748e-01,  7.4780e-03, -2.0903e-03,
         -3.1906e-02, -3.5230e-02, -2.1134e-02, -8.9917e-01, -2.7445e+00,
         -3.7255e-02, -3.1774e-02, -1.0388e+00, -2.1629e+00, -5.2871e-01,
          4.9009e+00, -7.6681e-01],
        [-4.4020e-03, -1.0420e-01, -4.4066e+00, -2.4039e+00, -4.1941e-03,
         -4.4973e-03, -4.4472e-03,  6.0588e-02,  1.0161e-02,  7.0878e-03,
         -4.4096e-03, -4.2471e-03, -1.2566e+00,  1.5209e-01, -5.0240e-01,
         -4.4590e-03, -4.4999e-03, -3.7958e-01, -7.7011e-03,  1.7077e-01,
         -6.4281e-01, -1.6510e+00],
        [-4.1188e-03,  6.8514e+00,  4.4049e+00, -2.3910e+00, -1.4262e-04,
         -2.8006e-03, -2.5663e-03,  2.1440e-01,  6.0584e-03, -5.5739e-02,
         -1.7700e-03, -2.5913e-03,  7.4515e+00, -5.1226e-02,  1.1009e-01,
         -2.6014e-03, -2.9639e-04,  2.9260e+00,  8.3029e-01, -9.9294e-01,
          4.9731e-01,  6.1149e-01],
        [-6.6110e-02, -1.5279e+01, -6.2413e-01, -6.7517e+00,  5.9432e-04,
         -6.7026e-02, -7.0054e-02,  1.2271e-02, -1.9049e-02, -3.2179e+00,
          8.9615e-03,  1.1579e-02, -2.3373e+00, -1.1592e-02, -4.0634e+00,
         -6.2499e-02, -8.1450e-03, -2.0246e+00, -1.6915e-01, -1.3290e+01,
         -1.4424e+00,  7.6040e-01],
        [-2.1165e-01, -3.0480e+00,  2.9575e+00, -9.6424e+00, -5.0342e-01,
         -2.4311e-01, -2.7319e-01, -2.6055e+00, -7.4439e-01, -2.1137e+00,
         -1.6281e-01, -3.5336e-01,  1.1701e+00,  4.2304e+00,  5.2937e+00,
         -2.7489e-01, -1.3520e-01,  8.2462e+00,  1.8282e+01, -2.4768e+00,
         -3.2613e-01, -3.2396e+00],
        [-1.0499e-02, -1.7855e+01, -2.0316e+00, -3.8908e+00,  7.9761e-01,
         -2.0288e-02, -2.7004e-02,  5.2157e-02,  8.6740e-03,  9.3109e-02,
         -1.7253e-02, -3.4473e-02,  6.3326e+00,  1.8483e+00, -4.9234e+00,
         -2.7023e-02, -1.7382e-02,  4.6467e+00,  6.8437e+00, -2.0109e+01,
         -6.0308e+00, -4.4852e+00],
        [-1.0752e-02,  2.3769e-01, -4.2385e+00, -2.9313e+00, -1.0403e-02,
         -1.0906e-02, -1.0785e-02,  3.8294e-01,  2.2655e-02,  6.2705e-03,
         -1.1051e-02, -1.0836e-02, -1.7767e+00,  2.6303e-01,  2.0419e-01,
         -1.1175e-02, -1.1199e-02, -9.6581e-02, -2.6987e-01,  1.3151e-01,
         -1.2303e+00, -2.2527e+00],
        [ 4.0615e-02,  4.6085e+00, -4.4170e+00, -3.5332e+00,  1.1750e+00,
          1.3487e-02,  6.9089e-02, -2.3461e+00, -9.6051e-01,  2.8717e-01,
         -4.4029e-01, -1.6001e-01,  1.1757e+00,  3.1733e+00,  2.4187e+00,
          5.8378e-02, -5.4372e-01,  3.7702e+00,  3.0739e+00,  2.5458e+00,
         -3.4243e+00, -1.2064e+00]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-4.1125, -4.5075, -3.5778, -4.3535, -3.4639, -3.1145,  1.2242, -5.1072,
        -2.9250, -3.9945, -5.0192, -1.3658, -4.3139,  3.3486,  6.2990, -4.5973,
         4.7397, -1.3530,  3.3532, -0.6306, -4.6727, -4.5780], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-9.2804e-03, -1.6330e-05, -5.4161e-04, -2.6409e-05, -6.1515e-03,
         -6.4664e-04, -1.2251e-02, -1.1281e+00, -2.4076e+00, -9.0316e-03,
         -1.4007e-05, -3.9662e-04, -1.4564e-05, -2.3262e+00, -2.4080e+00,
         -2.0830e-05, -2.4078e+00, -4.5023e-03, -4.7276e-01, -1.8620e-03,
         -1.2977e-05, -2.1394e-02],
        [ 8.3331e-02, -1.4437e-03, -2.7292e-03, -1.8049e-03,  9.4036e-02,
          1.8877e-05, -1.1646e-01, -2.6543e+00, -5.4833e-01, -7.2682e-02,
         -7.5214e-04, -7.2103e-03, -1.3372e-03, -1.0450e+00, -5.6345e-01,
         -9.5178e-04, -5.6675e-01, -2.7833e-02, -1.5555e+00, -9.3555e-03,
         -6.5958e-04, -1.2400e-01],
        [-6.8918e-03, -2.2157e-05, -1.4850e-03, -2.9048e-05, -2.5482e-03,
         -3.7288e-04, -1.2190e-02, -1.0032e+00, -2.2963e+00, -6.0092e-03,
         -1.4286e-05,  7.0177e-05, -1.7560e-05, -2.2115e+00, -2.2970e+00,
         -2.2660e-05, -2.2968e+00, -2.9842e-03, -4.3434e-01, -6.8312e-04,
         -1.5487e-05, -1.9946e-02],
        [-3.5134e-03, -2.0078e-05, -1.1162e-03, -1.8644e-05, -6.9831e-04,
         -8.0557e-04, -9.2836e-03, -1.0405e+00, -2.0887e+00, -9.4885e-03,
         -8.3001e-06,  2.8269e-04, -2.6190e-05, -2.0346e+00, -2.0896e+00,
         -1.6025e-05, -2.0895e+00, -2.2249e-03, -4.3628e-01, -4.0525e-04,
         -2.4572e-06, -2.0633e-02],
        [-1.6777e+00,  1.4893e-01,  2.6404e-02,  2.2525e-01, -4.0131e+00,
         -2.1586e-01,  4.5360e+00, -1.3440e-01, -2.9915e+00,  2.9945e+00,
         -3.9962e-02, -2.3957e+01,  2.4542e-01,  3.6253e+00,  3.5780e+00,
          9.1196e-02,  3.5846e+00,  2.9193e+00,  2.0629e+00,  6.4019e+00,
         -4.2155e-01, -6.4015e-01],
        [ 2.4426e-03, -1.2989e-05, -1.3149e-03,  2.1553e-05, -4.3655e-03,
         -6.4681e-04,  5.6848e-05, -1.0223e+00, -1.7629e+00, -2.4568e-03,
         -4.9818e-05,  1.0766e-04, -9.0418e-05, -1.7345e+00, -1.7643e+00,
         -1.8656e-06, -1.7643e+00,  8.0413e-03, -3.6457e-01, -2.5461e-03,
         -3.0227e-05, -4.2683e-02],
        [-4.5045e-03, -1.0322e-05, -1.0655e-03, -1.9450e-05, -1.6443e-03,
         -4.4381e-04, -1.0707e-02, -8.7703e-01, -2.1694e+00, -6.0149e-03,
         -5.0985e-06,  7.6619e-04, -8.9218e-06, -2.0794e+00, -2.1704e+00,
         -1.1122e-05, -2.1702e+00, -1.7143e-03, -3.9018e-01, -3.9062e-04,
         -4.7329e-06, -1.9585e-02],
        [ 6.0116e+00, -1.0419e-01, -1.7305e+00,  2.7475e-01,  1.7937e+00,
          4.3671e+00,  4.1495e+00,  3.8594e-01,  2.9909e+00, -5.4301e+00,
          7.6106e-01, -2.4926e+01, -5.1185e-01,  1.0598e+00,  1.3015e+00,
          3.0903e-01,  1.0695e+00,  4.1810e+00,  2.2950e+00,  4.1237e+00,
          2.4419e+00,  1.3477e-01],
        [-6.7839e-03, -1.5699e-05, -1.4677e-03, -1.8301e-05, -3.6145e-03,
         -5.4789e-04, -1.0627e-02, -9.8203e-01, -2.2186e+00, -7.8307e-03,
         -1.2109e-05,  1.4498e-04, -8.9750e-06, -2.1419e+00, -2.2193e+00,
         -1.7117e-05, -2.2192e+00, -3.4414e-03, -4.2806e-01, -1.3072e-03,
         -1.0465e-05, -2.1883e-02],
        [-9.7937e-03, -1.3523e-04, -6.0043e-05, -2.0454e-04, -4.0194e-03,
         -3.7657e-04, -3.4813e-02, -8.3743e-01, -1.9617e+00, -1.5688e-02,
         -5.5768e-05,  2.1694e-04, -1.5403e-04, -1.9119e+00, -1.9644e+00,
         -1.4866e-04, -1.9642e+00, -1.1956e-02, -5.3082e-01, -4.4061e-03,
         -4.2652e-05, -1.4739e-02],
        [-4.5939e+00,  5.0945e-01,  4.2190e+00,  1.2258e+00,  2.9113e-02,
          2.5505e+00, -3.0781e+01,  5.6771e+00,  3.3200e+00,  1.4951e+00,
          9.6765e-01,  1.2859e-08,  6.0774e-01, -6.1906e-01, -1.1210e+00,
          8.9252e-01, -6.1309e-01, -4.5070e+01,  2.9725e+00, -3.2175e+01,
          7.8085e-01,  3.1398e+00],
        [ 2.4980e+00,  4.7065e-03, -4.9930e+00, -9.2885e-01,  3.7942e+00,
         -3.5459e+00, -1.9063e-01, -2.3705e-02,  5.2647e+00, -3.4352e+00,
          3.2248e-01,  3.1723e+01,  4.6090e-01,  6.5701e-01,  8.0205e-01,
         -6.2659e-01,  5.1430e-01, -5.6061e+00,  1.5390e+00, -1.1299e+01,
         -1.6083e+00, -7.7080e-01],
        [-8.7755e-03, -2.2925e-05, -7.7304e-04, -3.4732e-05, -3.8354e-03,
         -5.3024e-04, -1.2219e-02, -1.0926e+00, -2.3935e+00, -6.7484e-03,
         -1.4113e-05,  6.0988e-05, -2.7098e-05, -2.3064e+00, -2.3940e+00,
         -2.2957e-05, -2.3939e+00, -4.1473e-03, -4.5221e-01, -1.2838e-03,
         -1.3905e-05, -1.8700e-02],
        [-8.0730e-03, -1.8926e-05, -7.2813e-04, -2.0954e-05, -4.7211e-03,
         -5.7503e-04, -1.1408e-02, -1.1235e+00, -2.3580e+00, -9.8685e-03,
         -1.6985e-05, -5.4657e-05, -1.9602e-05, -2.2808e+00, -2.3585e+00,
         -2.1363e-05, -2.3584e+00, -3.5257e-03, -4.6674e-01, -1.5230e-03,
         -1.5841e-05, -2.2143e-02]], device='cuda:0'))])
xi:  [1341.1593]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 1686.1071622924644
W_T_median: 1638.9560961665072
W_T_pctile_5: 1364.3057219718555
W_T_CVAR_5_pct: 831.0587205656043
Average q (qsum/M+1):  43.16323950982863
Optimal xi:  [1341.1593]
Expected(across Rb) median(across samples) p_equity:  1.20524013325074e-07
obj fun:  tensor(-42799.7551, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
/home/marcchen/Documents/factor_decumulation/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:262: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/factor_decumulation/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/factor_decumulation/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: MC_everything
Objective function: mean_cvar_single_level
Tracing param: 50.0
-----------------------------------------------
