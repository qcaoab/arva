/home/marcchen/Documents/constrain_factor/researchcode/exp_config_json_files/multi_portfolio_exp1.json
Starting at: 
17-07-23_14:41

 numpy seed:  2  


 pytorch seed:  2  

Key parameters-------
paths: 256000
iterations: 30000
batchsize: 1000
remove neg:  False
w constaint activation:  yy_fix_jan29


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor4
timeseries_basket['basket_desc'] = Factor4 portfolio for paper: Basic, size, value, vol, mom
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'B10_real_ret', 'VWD_real_ret', 'Size_Lo30_real_ret', 'Value_Hi30_real_ret', 'Vol_Lo20_real_ret', 'Mom_Hi30_real_ret']
############# End: defined asset  basket #################
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
192601                  0.0                NaN  ...     0.000561     0.023174
192602                  0.0                NaN  ...    -0.033046    -0.053510
192603                  0.0                NaN  ...    -0.064002    -0.096824
192604                  0.0                NaN  ...     0.037029     0.032975
192605                  0.0                NaN  ...     0.012095     0.001035

[5 rows x 16 columns]
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
202208                  NaN            -0.0020  ...    -0.036240    -0.011556
202209                  NaN            -0.0955  ...    -0.091324    -0.099903
202210                  NaN             0.0883  ...     0.077403     0.049863
202211                  NaN            -0.0076  ...     0.052365     0.028123
202212                  NaN            -0.0457  ...    -0.057116    -0.047241

[5 rows x 16 columns]


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor4
timeseries_basket['basket_desc'] = Factor4 portfolio for paper: Basic, size, value, vol, mom
timeseries_basket['basket_columns'] = 
['T30_nom_ret', 'B10_nom_ret', 'VWD_nom_ret', 'Size_Lo30_nom_ret', 'Value_Hi30_nom_ret', 'Vol_Lo20_nom_ret', 'Mom_Hi30_nom_ret']
############# End: defined asset  basket #################
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
192607                    0.0014              0.0154  ...     0.005383     0.031411
192608                    0.0319              0.0561  ...     0.005363     0.028647
192609                   -0.0173             -0.0071  ...     0.005343     0.005787
192610                   -0.0294             -0.0355  ...     0.005323    -0.028996
192611                   -0.0038              0.0294  ...     0.005303     0.028554

[5 rows x 8 columns]
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
202208                   -0.0020             -0.0164  ...    -0.043289    -0.036240
202209                   -0.0955             -0.0871  ...    -0.050056    -0.091324
202210                    0.0883              0.1486  ...    -0.014968     0.077403
202211                   -0.0076              0.0462  ...     0.040789     0.052365
202212                   -0.0457             -0.0499  ...    -0.018566    -0.057116

[5 rows x 8 columns]
Indices constructed with column names:
Index(['date_for_plt', 'Size_Lo30_nom_ret_ind', 'Value_Hi30_nom_ret_ind',
       'Mom_Hi30_nom_ret_ind', 'Vol_Lo20_nom_ret_ind', 'CPI_nom_ret_ind',
       'T30_nom_ret_ind', 'B10_nom_ret_ind', 'VWD_nom_ret_ind'],
      dtype='object')
############# Updated: defined asset basket #################
timeseries_basket['data_df_mean'] = 
T30_real_ret           0.000229
B10_real_ret           0.001637
VWD_real_ret           0.006759
Size_Lo30_real_ret     0.009939
Value_Hi30_real_ret    0.010052
Vol_Lo20_real_ret      0.003529
Mom_Hi30_real_ret      0.011386
dtype: float64


timeseries_basket['data_df_stdev'] = 
T30_real_ret           0.005227
B10_real_ret           0.019258
VWD_real_ret           0.053610
Size_Lo30_real_ret     0.082598
Value_Hi30_real_ret    0.072063
Vol_Lo20_real_ret      0.030737
Mom_Hi30_real_ret      0.061421
dtype: float64


timeseries_basket['data_df_corr'] = 
                     T30_real_ret  ...  Mom_Hi30_real_ret
T30_real_ret             1.000000  ...           0.055142
B10_real_ret             0.351722  ...           0.066570
VWD_real_ret             0.068448  ...           0.936115
Size_Lo30_real_ret       0.014412  ...           0.903222
Value_Hi30_real_ret      0.018239  ...           0.869469
Vol_Lo20_real_ret        0.081282  ...           0.482682
Mom_Hi30_real_ret        0.055142  ...           1.000000

[7 rows x 7 columns]


timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names', 'data_df', 'data_df_mean', 'data_df_stdev', 'data_df_corr'])
############# End: updated: defined asset basket #################
-----------------------------------------------
Dates to be REMOVED due to missing values (should be at *start* only due to trading signals):
Int64Index([], dtype='int64')
-----------------------------------------------
Dates from available data for bootstrapping:
Start: 192607
End: 202212
-----------------------------------------------
Bootstrap block size: 6
-----------------------------------------------
Dates USED bootstrapping:
Start: 196307
End: 202212
-----------------------------------------------
0.0% of bootstrap sample done.
5.0% of bootstrap sample done.
10.0% of bootstrap sample done.
15.0% of bootstrap sample done.
20.0% of bootstrap sample done.
25.0% of bootstrap sample done.
30.0% of bootstrap sample done.
35.0% of bootstrap sample done.
40.0% of bootstrap sample done.
45.0% of bootstrap sample done.
50.0% of bootstrap sample done.
55.00000000000001% of bootstrap sample done.
60.0% of bootstrap sample done.
65.0% of bootstrap sample done.
70.0% of bootstrap sample done.
75.0% of bootstrap sample done.
80.0% of bootstrap sample done.
85.0% of bootstrap sample done.
90.0% of bootstrap sample done.
95.0% of bootstrap sample done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      15  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      15  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 15)     True          15  
2     (15, 15)     True          15  
3      (15, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       8       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      15  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      15  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       8              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 15)     True          15  
2     (15, 15)     True          15  
3      (15, 8)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        8              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 8)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 1500, 'itbound_SGD_algorithms': 30000, 'nit_IterateAveragingStart': 27000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        8              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 8)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0, 0.5, 0.1, 0.1, 0.1, 0.1, 0.1]
W_T_mean: 1080.663625928201
W_T_median: 808.5408506516229
W_T_pctile_5: -163.24259466603715
W_T_CVAR_5_pct: -300.4117296963052
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1804.4737997379964
Current xi:  [120.51303]
objective value function right now is: -1804.4737997379964
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1820.3511653743133
Current xi:  [142.9896]
objective value function right now is: -1820.3511653743133
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1836.9280181017518
Current xi:  [165.7954]
objective value function right now is: -1836.9280181017518
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -1848.773041536529
Current xi:  [188.33128]
objective value function right now is: -1848.773041536529
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1857.8574382812665
Current xi:  [210.2789]
objective value function right now is: -1857.8574382812665
12.0% of gradient descent iterations done. Method = Adam
new min fval:  -1870.418706709656
Current xi:  [232.0271]
objective value function right now is: -1870.418706709656
14.000000000000002% of gradient descent iterations done. Method = Adam
new min fval:  -1879.7370134653893
Current xi:  [253.44075]
objective value function right now is: -1879.7370134653893
16.0% of gradient descent iterations done. Method = Adam
new min fval:  -1895.6083560401248
Current xi:  [276.85782]
objective value function right now is: -1895.6083560401248
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -1905.8555649929376
Current xi:  [299.3267]
objective value function right now is: -1905.8555649929376
20.0% of gradient descent iterations done. Method = Adam
new min fval:  -1916.4813543575272
Current xi:  [320.83206]
objective value function right now is: -1916.4813543575272
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -1923.8593816489938
Current xi:  [341.7357]
objective value function right now is: -1923.8593816489938
24.0% of gradient descent iterations done. Method = Adam
new min fval:  -1930.082788655091
Current xi:  [362.47086]
objective value function right now is: -1930.082788655091
26.0% of gradient descent iterations done. Method = Adam
new min fval:  -1940.3982291741488
Current xi:  [382.49026]
objective value function right now is: -1940.3982291741488
28.000000000000004% of gradient descent iterations done. Method = Adam
new min fval:  -1947.2596632975874
Current xi:  [402.07303]
objective value function right now is: -1947.2596632975874
30.0% of gradient descent iterations done. Method = Adam
new min fval:  -1952.0704527613884
Current xi:  [420.93582]
objective value function right now is: -1952.0704527613884
32.0% of gradient descent iterations done. Method = Adam
new min fval:  -1956.9991448571236
Current xi:  [439.55167]
objective value function right now is: -1956.9991448571236
34.0% of gradient descent iterations done. Method = Adam
new min fval:  -1960.8511013263162
Current xi:  [457.12476]
objective value function right now is: -1960.8511013263162
36.0% of gradient descent iterations done. Method = Adam
new min fval:  -1964.873279683837
Current xi:  [474.057]
objective value function right now is: -1964.873279683837
38.0% of gradient descent iterations done. Method = Adam
new min fval:  -1970.0199578827378
Current xi:  [491.6105]
objective value function right now is: -1970.0199578827378
40.0% of gradient descent iterations done. Method = Adam
new min fval:  -1974.9512576979855
Current xi:  [508.0436]
objective value function right now is: -1974.9512576979855
42.0% of gradient descent iterations done. Method = Adam
new min fval:  -1976.4259932280231
Current xi:  [523.20435]
objective value function right now is: -1976.4259932280231
44.0% of gradient descent iterations done. Method = Adam
new min fval:  -1977.6268987315489
Current xi:  [537.63574]
objective value function right now is: -1977.6268987315489
46.0% of gradient descent iterations done. Method = Adam
new min fval:  -1980.7172080877197
Current xi:  [550.34717]
objective value function right now is: -1980.7172080877197
48.0% of gradient descent iterations done. Method = Adam
new min fval:  -1981.5814314717004
Current xi:  [562.35614]
objective value function right now is: -1981.5814314717004
50.0% of gradient descent iterations done. Method = Adam
new min fval:  -1983.0316712681117
Current xi:  [572.95636]
objective value function right now is: -1983.0316712681117
52.0% of gradient descent iterations done. Method = Adam
new min fval:  -1984.3650847872773
Current xi:  [583.441]
objective value function right now is: -1984.3650847872773
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [592.6674]
objective value function right now is: -1984.3398134689296
56.00000000000001% of gradient descent iterations done. Method = Adam
new min fval:  -1985.2765407370518
Current xi:  [599.3223]
objective value function right now is: -1985.2765407370518
57.99999999999999% of gradient descent iterations done. Method = Adam
new min fval:  -1986.1873367293742
Current xi:  [606.1366]
objective value function right now is: -1986.1873367293742
60.0% of gradient descent iterations done. Method = Adam
new min fval:  -1986.244441135146
Current xi:  [612.05426]
objective value function right now is: -1986.244441135146
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [616.5356]
objective value function right now is: -1985.2361532342468
64.0% of gradient descent iterations done. Method = Adam
new min fval:  -1986.297842850231
Current xi:  [620.5423]
objective value function right now is: -1986.297842850231
66.0% of gradient descent iterations done. Method = Adam
new min fval:  -1987.7395660034
Current xi:  [623.8805]
objective value function right now is: -1987.7395660034
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [625.84]
objective value function right now is: -1987.2596784007478
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [628.01666]
objective value function right now is: -1986.5691895806397
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -1988.4792549379044
Current xi:  [628.2145]
objective value function right now is: -1988.4792549379044
74.0% of gradient descent iterations done. Method = Adam
Current xi:  [628.6293]
objective value function right now is: -1988.1837492884674
76.0% of gradient descent iterations done. Method = Adam
new min fval:  -1988.8129927729576
Current xi:  [629.4128]
objective value function right now is: -1988.8129927729576
78.0% of gradient descent iterations done. Method = Adam
new min fval:  -1988.8695262112644
Current xi:  [629.9874]
objective value function right now is: -1988.8695262112644
80.0% of gradient descent iterations done. Method = Adam
new min fval:  -1988.9263024032289
Current xi:  [630.3762]
objective value function right now is: -1988.9263024032289
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [630.8905]
objective value function right now is: -1988.7875084531809
84.0% of gradient descent iterations done. Method = Adam
new min fval:  -1989.0831518715145
Current xi:  [631.5381]
objective value function right now is: -1989.0831518715145
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [631.87067]
objective value function right now is: -1988.8920803364413
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [632.2984]
objective value function right now is: -1989.0308809943324
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [632.57556]
objective value function right now is: -1988.7146682808705
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [632.75885]
objective value function right now is: -1989.0386650686405
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [633.1805]
objective value function right now is: -1988.5907711797947
new min fval from sgd:  -1989.0934736501306
new min fval from sgd:  -1989.1186841430183
new min fval from sgd:  -1989.1199345801147
new min fval from sgd:  -1989.1505686605274
new min fval from sgd:  -1989.1964719517712
new min fval from sgd:  -1989.2268545552292
new min fval from sgd:  -1989.2286205588714
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [633.5958]
objective value function right now is: -1988.8011722044303
new min fval from sgd:  -1989.2536192606967
new min fval from sgd:  -1989.3165668931285
new min fval from sgd:  -1989.3270694568516
new min fval from sgd:  -1989.3432557897745
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [633.6789]
objective value function right now is: -1989.2965624912797
new min fval from sgd:  -1989.3455350284823
new min fval from sgd:  -1989.3515511653316
new min fval from sgd:  -1989.3556446526782
new min fval from sgd:  -1989.356563937728
new min fval from sgd:  -1989.3674327012843
new min fval from sgd:  -1989.376323085153
new min fval from sgd:  -1989.3802519759522
new min fval from sgd:  -1989.3872231322932
new min fval from sgd:  -1989.395385303694
new min fval from sgd:  -1989.3958655177091
new min fval from sgd:  -1989.3979537935318
new min fval from sgd:  -1989.398928876325
new min fval from sgd:  -1989.4013115463256
new min fval from sgd:  -1989.404337707657
new min fval from sgd:  -1989.4046560801523
new min fval from sgd:  -1989.4073720265094
new min fval from sgd:  -1989.4114810746942
new min fval from sgd:  -1989.4145609418997
new min fval from sgd:  -1989.4163248220448
new min fval from sgd:  -1989.4166881048368
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [633.76355]
objective value function right now is: -1989.3980961605184
min fval:  -1989.4166881048368
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -0.7244,   0.0610],
        [-33.8999,  -9.5973],
        [ -0.7139,   0.1019],
        [ 10.9183,  -0.9316],
        [  2.9600,  11.9972],
        [ -0.6962,   0.0982],
        [ -0.7246,   0.0608],
        [-13.2780,   5.0787],
        [  7.8715,  -8.3982],
        [ -9.2438,  -0.7686],
        [  3.8722,  -9.2612],
        [-15.1512, -14.4156],
        [ -0.7245,   0.0608],
        [  3.8302,  -8.9646],
        [ -0.7007,   0.0896]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-2.7675, -4.6999, -2.8212, -8.6880,  3.6575, -2.7869, -2.7675,  2.4546,
        -3.8091,  8.7166, -4.2782,  1.0708, -2.7675, -4.2723, -2.7794],
       device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ 6.8161e-02,  4.8536e+00, -9.1243e-02,  1.1079e+01, -5.3186e+00,
          7.1499e-02,  6.8283e-02, -4.0643e+00,  2.9232e+00, -5.2944e+00,
          2.2154e+00,  6.6747e+00,  6.8266e-02,  2.1571e+00,  7.3644e-02],
        [-1.1289e-02,  6.5745e-03, -1.0843e-02, -2.7751e-01, -6.8025e-01,
         -1.1390e-02, -1.1288e-02, -1.0317e-01, -2.1945e-01, -5.2900e-01,
         -1.3054e-01, -2.6569e-01, -1.1288e-02, -1.2490e-01, -1.1414e-02],
        [-1.1289e-02,  6.5745e-03, -1.0843e-02, -2.7751e-01, -6.8025e-01,
         -1.1390e-02, -1.1288e-02, -1.0317e-01, -2.1945e-01, -5.2900e-01,
         -1.3054e-01, -2.6569e-01, -1.1288e-02, -1.2490e-01, -1.1414e-02],
        [-1.1289e-02,  6.5745e-03, -1.0843e-02, -2.7751e-01, -6.8025e-01,
         -1.1390e-02, -1.1288e-02, -1.0317e-01, -2.1945e-01, -5.2900e-01,
         -1.3054e-01, -2.6569e-01, -1.1288e-02, -1.2490e-01, -1.1414e-02],
        [-2.2906e-02, -6.3875e+00,  6.8017e-02, -1.1093e+01,  4.5247e+00,
          2.6489e-02, -2.3135e-02,  3.7002e+00, -4.2967e+00,  5.6473e+00,
         -2.9158e+00, -7.9661e+00, -2.3119e-02, -2.9527e+00,  1.3367e-02],
        [-1.1289e-02,  6.5745e-03, -1.0843e-02, -2.7751e-01, -6.8025e-01,
         -1.1390e-02, -1.1288e-02, -1.0317e-01, -2.1945e-01, -5.2900e-01,
         -1.3054e-01, -2.6569e-01, -1.1288e-02, -1.2490e-01, -1.1414e-02],
        [-1.1289e-02,  6.5745e-03, -1.0843e-02, -2.7751e-01, -6.8025e-01,
         -1.1390e-02, -1.1288e-02, -1.0317e-01, -2.1945e-01, -5.2900e-01,
         -1.3054e-01, -2.6569e-01, -1.1288e-02, -1.2490e-01, -1.1414e-02],
        [ 1.2471e-02, -8.2073e+00,  1.9768e-02, -1.1760e+01,  5.2957e+00,
          4.9484e-02,  1.2166e-02,  5.5938e+00, -4.0571e+00,  6.1052e+00,
         -3.2359e+00, -8.4029e+00,  1.2221e-02, -2.8720e+00,  4.3590e-02],
        [-1.1289e-02,  6.5745e-03, -1.0843e-02, -2.7751e-01, -6.8025e-01,
         -1.1390e-02, -1.1288e-02, -1.0317e-01, -2.1945e-01, -5.2900e-01,
         -1.3054e-01, -2.6569e-01, -1.1288e-02, -1.2490e-01, -1.1414e-02],
        [-1.1289e-02,  6.5745e-03, -1.0843e-02, -2.7751e-01, -6.8025e-01,
         -1.1390e-02, -1.1288e-02, -1.0317e-01, -2.1945e-01, -5.2900e-01,
         -1.3054e-01, -2.6569e-01, -1.1288e-02, -1.2490e-01, -1.1414e-02],
        [-1.1174e-02,  5.7873e-03, -1.0652e-02, -2.6515e-01, -7.2760e-01,
         -1.1264e-02, -1.1173e-02, -1.1389e-01, -2.0717e-01, -5.6358e-01,
         -1.2791e-01, -2.6172e-01, -1.1173e-02, -1.2234e-01, -1.1290e-02],
        [-1.1288e-02,  6.5742e-03, -1.0842e-02, -2.7753e-01, -6.8033e-01,
         -1.1389e-02, -1.1287e-02, -1.0318e-01, -2.1944e-01, -5.2903e-01,
         -1.3053e-01, -2.6570e-01, -1.1287e-02, -1.2490e-01, -1.1413e-02],
        [-1.1289e-02,  6.5745e-03, -1.0843e-02, -2.7751e-01, -6.8025e-01,
         -1.1390e-02, -1.1288e-02, -1.0317e-01, -2.1945e-01, -5.2900e-01,
         -1.3054e-01, -2.6569e-01, -1.1288e-02, -1.2490e-01, -1.1414e-02],
        [-7.5940e-02,  7.5092e+00,  1.0114e-01,  1.2861e+01, -5.7531e+00,
         -3.0679e-03, -7.6395e-02, -4.8016e+00,  3.8160e+00, -6.4848e+00,
          2.8478e+00,  7.8913e+00, -7.6332e-02,  2.4258e+00, -2.1009e-02],
        [-2.1392e-02, -6.2414e+00,  7.3802e-02, -1.1166e+01,  4.3007e+00,
          2.8332e-02, -2.1509e-02,  3.5360e+00, -4.4214e+00,  5.7645e+00,
         -2.9974e+00, -8.1572e+00, -2.1496e-02, -2.8064e+00,  1.5338e-02]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.7599, -0.8923, -0.8923, -0.8923,  0.3376, -0.8923, -0.8923,  0.0701,
        -0.8923, -0.8923, -0.8779, -0.8925, -0.8923, -0.8297,  0.6414],
       device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-5.9693e+00, -2.6730e-04, -2.6728e-04, -2.6728e-04,  6.4492e+00,
         -2.6731e-04, -2.6730e-04,  8.0387e+00, -2.6731e-04, -2.6729e-04,
         -5.1540e-04, -2.6820e-04, -2.6730e-04, -1.0472e+01,  6.2797e+00]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -9.3548,   4.7259],
        [-14.4457,  -4.2355],
        [  8.8479,  -1.6930],
        [ -8.4289, -10.4543],
        [ -7.6256,  11.7389],
        [ -6.1919,   3.2899],
        [ -1.4292,   0.3512],
        [ -1.4242,   0.3549],
        [-12.8042,  -6.7697],
        [ -2.3714,  -0.4176],
        [  7.2653,   2.2838],
        [ -1.4080,   0.3470],
        [ -1.4320,   0.3491],
        [  9.8587,  -0.1954],
        [ -1.4239,   0.3551]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([  2.9776,  -2.3067, -11.8424,  -4.2103,   4.9326,  -8.7667,  -4.1150,
         -4.1169,  -1.1393,  -3.9327,  -6.9194,  -4.1258,  -4.1140,  -7.9358,
         -4.1170], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-4.1993e-01, -5.1934e-02,  2.8689e-01, -4.7975e-01, -9.6247e-01,
         -1.7093e-01, -3.1523e-03, -3.0282e-03, -4.3694e-02, -1.6503e-02,
         -3.0983e-01, -4.2498e-03, -3.2242e-03, -8.4122e-01, -3.0210e-03],
        [-4.1986e-01, -5.1962e-02,  2.8715e-01, -4.7941e-01, -9.6259e-01,
         -1.7093e-01, -3.1733e-03, -3.0492e-03, -4.3520e-02, -1.6537e-02,
         -3.0990e-01, -4.2715e-03, -3.2453e-03, -8.4106e-01, -3.0419e-03],
        [ 5.7233e+00, -1.1051e+00, -2.3697e+00,  1.5233e+00,  2.0650e+00,
         -3.9195e+00,  1.1525e-01,  1.1638e-01,  9.2992e-01,  1.9627e-01,
         -2.5438e+00,  9.3110e-02,  1.1445e-01, -3.4076e+00,  1.1644e-01],
        [-3.0629e+00,  6.1555e+00, -1.0305e+01,  5.8916e+00, -7.4539e+00,
         -1.0460e-02, -1.9635e-01, -1.9299e-01,  8.8027e+00,  3.6822e-01,
         -2.0248e+00, -2.7407e-01, -1.9848e-01, -9.5845e+00, -1.9280e-01],
        [ 5.1007e+00,  6.2667e+00, -6.3731e-02, -3.4606e+00,  5.0781e+00,
          8.3705e-02,  8.6045e-02,  7.4542e-02,  2.7254e+00,  2.2616e+00,
         -2.8072e+00,  9.4699e-02,  9.2934e-02, -6.1082e+00,  7.3886e-02],
        [-4.1994e-01, -5.1935e-02,  2.8690e-01, -4.7973e-01, -9.6248e-01,
         -1.7092e-01, -3.1534e-03, -3.0294e-03, -4.3692e-02, -1.6504e-02,
         -3.0983e-01, -4.2509e-03, -3.2253e-03, -8.4119e-01, -3.0221e-03],
        [-4.1994e-01, -5.1935e-02,  2.8690e-01, -4.7974e-01, -9.6248e-01,
         -1.7092e-01, -3.1533e-03, -3.0293e-03, -4.3692e-02, -1.6504e-02,
         -3.0983e-01, -4.2508e-03, -3.2252e-03, -8.4120e-01, -3.0220e-03],
        [ 6.3743e-01, -3.3784e-01, -1.1492e-01, -2.0203e+00, -8.0994e-01,
          4.3070e-02,  5.7811e-01,  5.7438e-01, -5.5242e+00,  6.4095e-02,
         -3.8839e+00,  6.7506e-01,  5.8057e-01, -7.1192e+00,  5.7418e-01],
        [-4.1994e-01, -5.1935e-02,  2.8690e-01, -4.7974e-01, -9.6248e-01,
         -1.7092e-01, -3.1534e-03, -3.0294e-03, -4.3692e-02, -1.6504e-02,
         -3.0983e-01, -4.2509e-03, -3.2253e-03, -8.4120e-01, -3.0221e-03],
        [-1.1975e+01,  1.2240e+00, -8.3431e+00,  1.2194e+00, -1.6071e+00,
         -2.3354e-03,  2.1381e-01,  2.1268e-01,  3.5306e+00,  2.5023e-01,
          4.3734e+00,  2.8993e-01,  2.1492e-01,  2.5315e-01,  2.1264e-01],
        [-4.1994e-01, -5.1935e-02,  2.8690e-01, -4.7974e-01, -9.6248e-01,
         -1.7092e-01, -3.1535e-03, -3.0294e-03, -4.3692e-02, -1.6505e-02,
         -3.0983e-01, -4.2510e-03, -3.2254e-03, -8.4120e-01, -3.0221e-03],
        [-1.1240e+00,  3.6027e+00, -3.2152e+00,  6.5341e+00, -1.1267e+01,
         -2.6663e-02, -2.1679e-01, -2.1955e-01,  7.2165e+00,  6.1055e-01,
         -1.6606e+00, -1.7865e-01, -2.1501e-01, -2.1740e+00, -2.1970e-01],
        [-4.1994e-01, -5.1935e-02,  2.8690e-01, -4.7973e-01, -9.6248e-01,
         -1.7092e-01, -3.1533e-03, -3.0293e-03, -4.3693e-02, -1.6504e-02,
         -3.0983e-01, -4.2508e-03, -3.2252e-03, -8.4119e-01, -3.0220e-03],
        [-4.1994e-01, -5.1935e-02,  2.8690e-01, -4.7974e-01, -9.6248e-01,
         -1.7092e-01, -3.1535e-03, -3.0294e-03, -4.3692e-02, -1.6504e-02,
         -3.0983e-01, -4.2510e-03, -3.2253e-03, -8.4120e-01, -3.0221e-03],
        [-5.9006e+00,  3.0845e+00, -1.2801e-01,  2.0393e+00, -3.2412e+00,
          5.0206e+00, -3.5434e-03, -5.8177e-03, -1.9924e+00,  6.1357e-02,
          3.3146e+00, -1.7259e-02, -2.3057e-03,  6.9190e+00, -5.9554e-03]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-5.0625, -5.0624, -1.6317, -7.9919, -7.6744, -5.0625, -5.0625, -2.7438,
        -5.0625, -4.0396, -5.0625, -5.5744, -5.0626, -5.0625, -0.0457],
       device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-2.1207e-01, -2.1203e-01,  2.3992e+00, -4.6028e+00,  3.6463e+00,
         -2.1209e-01, -2.1209e-01, -4.9371e+00, -2.1209e-01,  3.5745e+00,
         -2.1209e-01, -5.2696e+00, -2.1209e-01, -2.1209e-01,  2.9753e-01],
        [ 2.8967e-01,  2.8994e-01,  1.1013e+00,  4.6163e+00, -6.1664e-01,
          2.8966e-01,  2.8966e-01,  5.4001e+00,  2.8966e-01, -2.6892e+00,
          2.8966e-01,  5.6383e+00,  2.8966e-01,  2.8966e-01,  1.9102e+00],
        [-1.6818e-01, -1.6819e-01, -1.2103e+01, -1.7357e-02, -2.3170e-01,
         -1.6817e-01, -1.6817e-01, -1.0181e+00, -1.6817e-01, -2.8766e-01,
         -1.6817e-01, -1.3701e-01, -1.6817e-01, -1.6817e-01, -1.1988e+01],
        [-1.6868e-01, -1.6869e-01, -1.1901e+01, -2.3141e-02, -1.9574e-01,
         -1.6867e-01, -1.6867e-01, -1.0559e+00, -1.6867e-01, -3.0861e-01,
         -1.6867e-01, -2.0994e-01, -1.6867e-01, -1.6867e-01, -1.2513e+01],
        [ 1.3769e-01,  1.4081e-01,  1.4819e+00, -3.9259e+00,  2.1359e+00,
          1.3678e-01,  1.3695e-01, -2.8330e+00,  1.3689e-01, -3.8076e+00,
          1.3691e-01,  6.8039e-01,  1.3675e-01,  1.3694e-01,  6.2578e-01],
        [-1.3047e-01, -1.3048e-01, -8.5481e+00, -6.1180e-02, -1.2840e-01,
         -1.3047e-01, -1.3047e-01, -8.4313e-01, -1.3047e-01, -2.9442e-01,
         -1.3047e-01, -4.8352e-01, -1.3047e-01, -1.3047e-01, -1.1180e+01],
        [-1.3341e-02, -1.0375e-02,  2.2776e+00,  4.6586e+00,  6.2950e-01,
         -1.4264e-02, -1.4092e-02,  3.4772e+00, -1.4148e-02,  4.6281e+00,
         -1.4133e-02,  4.9668e-01, -1.4295e-02, -1.4100e-02,  1.5316e+00],
        [ 3.6044e-01,  3.6059e-01,  6.1813e-01,  1.6831e+00, -3.5500e+00,
          3.6045e-01,  3.6045e-01,  3.0436e+00,  3.6045e-01,  1.2837e+00,
          3.6045e-01,  1.3477e+01,  3.6045e-01,  3.6045e-01,  1.1812e+01]],
       device='cuda:0'))])
xi:  [633.7417]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 856.3306879611705
W_T_median: 833.092202538618
W_T_pctile_5: 633.7324225762246
W_T_CVAR_5_pct: 364.69503502361397
Average q (qsum/M+1):  52.41035313760081
Optimal xi:  [633.7417]
Expected(across Rb) median(across samples) p_equity:  0.19219668067526072
obj fun:  tensor(-1989.4167, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: Paper_FactorInv_Factor4
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
