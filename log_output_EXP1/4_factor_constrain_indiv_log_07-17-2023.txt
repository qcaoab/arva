/home/marcchen/Documents/constrain_factor/researchcode/exp_config_json_files/multi_portfolio_exp1.json
Starting at: 
17-07-23_14:41

 numpy seed:  2  


 pytorch seed:  2  

Key parameters-------
paths: 256000
iterations: 30000
batchsize: 1000
remove neg:  False
w constaint activation:  yy_fix_jan29


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor4
timeseries_basket['basket_desc'] = Factor4 portfolio for paper: Basic, size, value, vol, mom
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'B10_real_ret', 'VWD_real_ret', 'Size_Lo30_real_ret', 'Value_Hi30_real_ret', 'Vol_Lo20_real_ret', 'Mom_Hi30_real_ret']
############# End: defined asset  basket #################
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
192601                  0.0                NaN  ...     0.000561     0.023174
192602                  0.0                NaN  ...    -0.033046    -0.053510
192603                  0.0                NaN  ...    -0.064002    -0.096824
192604                  0.0                NaN  ...     0.037029     0.032975
192605                  0.0                NaN  ...     0.012095     0.001035

[5 rows x 16 columns]
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
202208                  NaN            -0.0020  ...    -0.036240    -0.011556
202209                  NaN            -0.0955  ...    -0.091324    -0.099903
202210                  NaN             0.0883  ...     0.077403     0.049863
202211                  NaN            -0.0076  ...     0.052365     0.028123
202212                  NaN            -0.0457  ...    -0.057116    -0.047241

[5 rows x 16 columns]


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor4
timeseries_basket['basket_desc'] = Factor4 portfolio for paper: Basic, size, value, vol, mom
timeseries_basket['basket_columns'] = 
['T30_nom_ret', 'B10_nom_ret', 'VWD_nom_ret', 'Size_Lo30_nom_ret', 'Value_Hi30_nom_ret', 'Vol_Lo20_nom_ret', 'Mom_Hi30_nom_ret']
############# End: defined asset  basket #################
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
192607                    0.0014              0.0154  ...     0.005383     0.031411
192608                    0.0319              0.0561  ...     0.005363     0.028647
192609                   -0.0173             -0.0071  ...     0.005343     0.005787
192610                   -0.0294             -0.0355  ...     0.005323    -0.028996
192611                   -0.0038              0.0294  ...     0.005303     0.028554

[5 rows x 8 columns]
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
202208                   -0.0020             -0.0164  ...    -0.043289    -0.036240
202209                   -0.0955             -0.0871  ...    -0.050056    -0.091324
202210                    0.0883              0.1486  ...    -0.014968     0.077403
202211                   -0.0076              0.0462  ...     0.040789     0.052365
202212                   -0.0457             -0.0499  ...    -0.018566    -0.057116

[5 rows x 8 columns]
Indices constructed with column names:
Index(['date_for_plt', 'Size_Lo30_nom_ret_ind', 'Value_Hi30_nom_ret_ind',
       'Mom_Hi30_nom_ret_ind', 'Vol_Lo20_nom_ret_ind', 'CPI_nom_ret_ind',
       'T30_nom_ret_ind', 'B10_nom_ret_ind', 'VWD_nom_ret_ind'],
      dtype='object')
############# Updated: defined asset basket #################
timeseries_basket['data_df_mean'] = 
T30_real_ret           0.000229
B10_real_ret           0.001637
VWD_real_ret           0.006759
Size_Lo30_real_ret     0.009939
Value_Hi30_real_ret    0.010052
Vol_Lo20_real_ret      0.003529
Mom_Hi30_real_ret      0.011386
dtype: float64


timeseries_basket['data_df_stdev'] = 
T30_real_ret           0.005227
B10_real_ret           0.019258
VWD_real_ret           0.053610
Size_Lo30_real_ret     0.082598
Value_Hi30_real_ret    0.072063
Vol_Lo20_real_ret      0.030737
Mom_Hi30_real_ret      0.061421
dtype: float64


timeseries_basket['data_df_corr'] = 
                     T30_real_ret  ...  Mom_Hi30_real_ret
T30_real_ret             1.000000  ...           0.055142
B10_real_ret             0.351722  ...           0.066570
VWD_real_ret             0.068448  ...           0.936115
Size_Lo30_real_ret       0.014412  ...           0.903222
Value_Hi30_real_ret      0.018239  ...           0.869469
Vol_Lo20_real_ret        0.081282  ...           0.482682
Mom_Hi30_real_ret        0.055142  ...           1.000000

[7 rows x 7 columns]


timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names', 'data_df', 'data_df_mean', 'data_df_stdev', 'data_df_corr'])
############# End: updated: defined asset basket #################
-----------------------------------------------
Dates to be REMOVED due to missing values (should be at *start* only due to trading signals):
Int64Index([], dtype='int64')
-----------------------------------------------
Dates from available data for bootstrapping:
Start: 192607
End: 202212
-----------------------------------------------
Bootstrap block size: 6
-----------------------------------------------
Dates USED bootstrapping:
Start: 196307
End: 202212
-----------------------------------------------
0.0% of bootstrap sample done.
5.0% of bootstrap sample done.
10.0% of bootstrap sample done.
15.0% of bootstrap sample done.
20.0% of bootstrap sample done.
25.0% of bootstrap sample done.
30.0% of bootstrap sample done.
35.0% of bootstrap sample done.
40.0% of bootstrap sample done.
45.0% of bootstrap sample done.
50.0% of bootstrap sample done.
55.00000000000001% of bootstrap sample done.
60.0% of bootstrap sample done.
65.0% of bootstrap sample done.
70.0% of bootstrap sample done.
75.0% of bootstrap sample done.
80.0% of bootstrap sample done.
85.0% of bootstrap sample done.
90.0% of bootstrap sample done.
95.0% of bootstrap sample done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      15  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      15  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 15)     True          15  
2     (15, 15)     True          15  
3      (15, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       7       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      15  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      15  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       7              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 15)     True          15  
2     (15, 15)     True          15  
3      (15, 7)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        7              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 7)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 1500, 'itbound_SGD_algorithms': 30000, 'nit_IterateAveragingStart': 27000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        7              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 7)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0, 0.5, 0.1, 0.1, 0.1, 0.1, 0.1]
W_T_mean: 1080.663625928201
W_T_median: 808.5408506516229
W_T_pctile_5: -163.24259466603715
W_T_CVAR_5_pct: -300.4117296963052
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1696.2002718957467
Current xi:  [109.952354]
objective value function right now is: -1696.2002718957467
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1701.5487133272882
Current xi:  [123.651436]
objective value function right now is: -1701.5487133272882
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1709.3888002474953
Current xi:  [137.63101]
objective value function right now is: -1709.3888002474953
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -1735.1370151086949
Current xi:  [157.7271]
objective value function right now is: -1735.1370151086949
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1741.1858103076272
Current xi:  [175.31729]
objective value function right now is: -1741.1858103076272
12.0% of gradient descent iterations done. Method = Adam
new min fval:  -1743.7979365573665
Current xi:  [190.00385]
objective value function right now is: -1743.7979365573665
14.000000000000002% of gradient descent iterations done. Method = Adam
new min fval:  -1748.0105269530768
Current xi:  [202.61539]
objective value function right now is: -1748.0105269530768
16.0% of gradient descent iterations done. Method = Adam
new min fval:  -1749.7295733786893
Current xi:  [214.39017]
objective value function right now is: -1749.7295733786893
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -1751.9834980944336
Current xi:  [225.31564]
objective value function right now is: -1751.9834980944336
20.0% of gradient descent iterations done. Method = Adam
new min fval:  -1752.6318061640338
Current xi:  [234.45119]
objective value function right now is: -1752.6318061640338
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -1756.503077272549
Current xi:  [242.51353]
objective value function right now is: -1756.503077272549
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [249.80565]
objective value function right now is: -1751.525430665344
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [255.6329]
objective value function right now is: -1754.7931872797383
28.000000000000004% of gradient descent iterations done. Method = Adam
new min fval:  -1757.3554062048743
Current xi:  [261.114]
objective value function right now is: -1757.3554062048743
30.0% of gradient descent iterations done. Method = Adam
new min fval:  -1759.7421730147103
Current xi:  [266.05334]
objective value function right now is: -1759.7421730147103
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [270.1505]
objective value function right now is: -1757.0969372124216
34.0% of gradient descent iterations done. Method = Adam
new min fval:  -1759.7456780985067
Current xi:  [273.6061]
objective value function right now is: -1759.7456780985067
36.0% of gradient descent iterations done. Method = Adam
new min fval:  -1760.1138959311527
Current xi:  [276.37384]
objective value function right now is: -1760.1138959311527
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [279.09708]
objective value function right now is: -1760.1108432309306
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [281.9012]
objective value function right now is: -1758.243934832377
42.0% of gradient descent iterations done. Method = Adam
new min fval:  -1760.2206350901522
Current xi:  [284.1521]
objective value function right now is: -1760.2206350901522
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [286.0541]
objective value function right now is: -1759.876136665088
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [287.38428]
objective value function right now is: -1759.6969099884168
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [288.3651]
objective value function right now is: -1758.9426428661807
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [289.54443]
objective value function right now is: -1759.1794684663344
52.0% of gradient descent iterations done. Method = Adam
new min fval:  -1760.7357526039145
Current xi:  [290.7177]
objective value function right now is: -1760.7357526039145
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [291.44098]
objective value function right now is: -1759.0907090784203
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [291.921]
objective value function right now is: -1759.8842637446137
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [292.85434]
objective value function right now is: -1758.912393516398
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [293.13354]
objective value function right now is: -1760.1273891496394
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [293.97507]
objective value function right now is: -1759.6213618099405
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [294.6625]
objective value function right now is: -1759.9894924764014
66.0% of gradient descent iterations done. Method = Adam
new min fval:  -1761.210743127931
Current xi:  [294.58276]
objective value function right now is: -1761.210743127931
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [294.8038]
objective value function right now is: -1759.7794052741888
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [295.2207]
objective value function right now is: -1760.7594789648228
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -1762.173125684869
Current xi:  [295.10983]
objective value function right now is: -1762.173125684869
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -1762.9522252991246
Current xi:  [295.24933]
objective value function right now is: -1762.9522252991246
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [295.43237]
objective value function right now is: -1762.8919432039238
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [295.444]
objective value function right now is: -1762.7283638603355
80.0% of gradient descent iterations done. Method = Adam
new min fval:  -1763.2370808017426
Current xi:  [295.60977]
objective value function right now is: -1763.2370808017426
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [295.66315]
objective value function right now is: -1762.9169967921473
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [295.7364]
objective value function right now is: -1763.1104217297425
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [295.78445]
objective value function right now is: -1763.1490191571027
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [295.76782]
objective value function right now is: -1763.1645386338728
90.0% of gradient descent iterations done. Method = Adam
new min fval:  -1763.3704184111523
Current xi:  [295.92404]
objective value function right now is: -1763.3704184111523
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [295.91492]
objective value function right now is: -1762.992529792939
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [296.0539]
objective value function right now is: -1762.8786582072898
new min fval from sgd:  -1763.3800742305875
new min fval from sgd:  -1763.3846683142149
new min fval from sgd:  -1763.3916530233635
new min fval from sgd:  -1763.3934522028865
new min fval from sgd:  -1763.3982301764233
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [296.2529]
objective value function right now is: -1763.3518233153202
new min fval from sgd:  -1763.4052571232826
new min fval from sgd:  -1763.4350836461845
new min fval from sgd:  -1763.459394001385
new min fval from sgd:  -1763.4769994315607
new min fval from sgd:  -1763.482884587846
new min fval from sgd:  -1763.4896059699315
new min fval from sgd:  -1763.4941879715236
new min fval from sgd:  -1763.4951225196621
new min fval from sgd:  -1763.4976479221164
new min fval from sgd:  -1763.4988674064484
new min fval from sgd:  -1763.503826096999
new min fval from sgd:  -1763.5070667853504
new min fval from sgd:  -1763.5106205749428
new min fval from sgd:  -1763.5134379593896
new min fval from sgd:  -1763.5204308310333
new min fval from sgd:  -1763.5205393598383
new min fval from sgd:  -1763.52074804197
new min fval from sgd:  -1763.5209964901096
new min fval from sgd:  -1763.5217148266183
new min fval from sgd:  -1763.5249694571355
new min fval from sgd:  -1763.5308718518259
new min fval from sgd:  -1763.5309177460854
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [296.27707]
objective value function right now is: -1763.3997535168967
new min fval from sgd:  -1763.5412491531376
new min fval from sgd:  -1763.5546650866954
new min fval from sgd:  -1763.555294087859
new min fval from sgd:  -1763.5635307163818
new min fval from sgd:  -1763.5664825641486
new min fval from sgd:  -1763.5707236302187
new min fval from sgd:  -1763.5770493848595
new min fval from sgd:  -1763.577774423964
new min fval from sgd:  -1763.5792446963746
new min fval from sgd:  -1763.5813528965139
new min fval from sgd:  -1763.5841937053767
new min fval from sgd:  -1763.591092877956
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [296.30124]
objective value function right now is: -1763.5561776737184
min fval:  -1763.591092877956
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[  8.9600,  -0.1596],
        [ -7.3910,   5.1466],
        [  9.6451,  -0.5657],
        [ -9.0099,   5.9478],
        [-49.1803,  -4.1407],
        [  4.0696,   7.3858],
        [ -6.0792,  -2.0752],
        [ -0.8881,   0.5437],
        [ -6.2676,  -9.3370],
        [  9.7481,  -0.6257],
        [ -4.4745,  -7.4061],
        [  7.2848,   1.7316],
        [ -0.8691,   0.5643],
        [ -7.0188,   6.4991],
        [  3.7190,  -8.6416]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-8.4211,  0.6059, -8.6637,  3.9116, -3.4350, -9.1100,  6.5305, -2.4389,
        -4.4670, -8.6912,  6.5811, -8.0882, -2.4981,  4.6614, -6.0052],
       device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-1.0780e-01, -1.1378e-02, -1.3202e-01, -1.4898e-01, -4.5065e-03,
         -6.7813e-02, -6.0134e-01, -1.3712e-02, -1.7588e-01, -1.3704e-01,
         -5.7455e-01, -7.8990e-02, -1.3083e-02, -3.0517e-01, -2.3891e-01],
        [ 4.4445e+00, -2.3246e+00,  5.4044e+00, -6.8644e+00,  7.6960e+00,
          4.3644e+00, -1.7495e+00, -3.1139e-01,  1.2924e+01,  5.9067e+00,
         -3.7181e+00,  3.1833e+00, -2.2180e-01, -7.9271e+00,  4.4054e+00],
        [ 5.7028e-01,  1.3099e-01,  6.2104e-01,  4.5665e-01, -4.2231e-02,
          3.1184e-01,  1.5039e+00,  7.5594e-02,  2.6592e-01,  6.3286e-01,
          1.3763e+00,  5.2805e-01,  7.2197e-02,  1.0939e+00,  5.0255e-01],
        [ 4.4317e+00, -1.8823e+00,  5.6264e+00, -6.3217e+00,  7.8464e+00,
          4.3319e+00, -9.7073e-01,  6.9587e-02,  1.3531e+01,  5.8503e+00,
         -3.2363e+00,  3.1039e+00,  8.7992e-02, -7.3958e+00,  4.6906e+00],
        [ 5.7302e-01,  1.3132e-01,  6.2408e-01,  4.5821e-01, -4.2215e-02,
          3.1334e-01,  1.5097e+00,  7.5912e-02,  2.6631e-01,  6.3597e-01,
          1.3816e+00,  5.3044e-01,  7.2503e-02,  1.0985e+00,  5.0468e-01],
        [-1.1255e-01, -1.0968e-02, -1.3537e-01, -1.7846e-01, -1.5596e-02,
         -7.3279e-02, -6.7404e-01, -1.2340e-02, -6.4725e-02, -1.4005e-01,
         -6.5898e-01, -8.5836e-02, -1.1762e-02, -3.6541e-01, -2.1885e-01],
        [ 4.4121e+00, -1.8868e+00,  5.5391e+00, -6.3902e+00,  8.1540e+00,
          4.5191e+00, -1.1693e+00,  7.6302e-02,  1.3657e+01,  6.0255e+00,
         -3.1646e+00,  3.0563e+00,  1.4114e-01, -7.7084e+00,  4.6947e+00],
        [-1.0779e-01, -1.1378e-02, -1.3202e-01, -1.4898e-01, -4.5065e-03,
         -6.7814e-02, -6.0134e-01, -1.3712e-02, -1.7588e-01, -1.3704e-01,
         -5.7455e-01, -7.8990e-02, -1.3083e-02, -3.0517e-01, -2.3891e-01],
        [ 3.5822e+00, -1.6023e+00,  5.0941e+00, -5.8127e+00,  8.0732e+00,
          3.2331e+00, -2.6943e+00,  1.3826e-01,  1.1764e+01,  5.5895e+00,
         -3.3889e+00,  1.9746e+00,  3.7966e-02, -7.2237e+00,  5.4718e+00],
        [-1.0779e-01, -1.1378e-02, -1.3202e-01, -1.4898e-01, -4.5065e-03,
         -6.7814e-02, -6.0134e-01, -1.3712e-02, -1.7588e-01, -1.3704e-01,
         -5.7455e-01, -7.8990e-02, -1.3083e-02, -3.0517e-01, -2.3891e-01],
        [-1.0779e-01, -1.1378e-02, -1.3202e-01, -1.4898e-01, -4.5065e-03,
         -6.7814e-02, -6.0134e-01, -1.3712e-02, -1.7588e-01, -1.3704e-01,
         -5.7455e-01, -7.8990e-02, -1.3083e-02, -3.0517e-01, -2.3891e-01],
        [-1.0779e-01, -1.1378e-02, -1.3202e-01, -1.4898e-01, -4.5065e-03,
         -6.7814e-02, -6.0134e-01, -1.3712e-02, -1.7588e-01, -1.3704e-01,
         -5.7455e-01, -7.8990e-02, -1.3083e-02, -3.0517e-01, -2.3891e-01],
        [ 4.8682e+00, -2.4480e+00,  6.1796e+00, -6.7910e+00,  8.1176e+00,
          4.6486e+00, -2.2361e+00,  4.0570e-02,  1.2750e+01,  6.6828e+00,
         -3.7158e+00,  3.0492e+00, -4.0078e-02, -7.9972e+00,  5.2850e+00],
        [-1.0780e-01, -1.1378e-02, -1.3202e-01, -1.4898e-01, -4.5065e-03,
         -6.7814e-02, -6.0134e-01, -1.3712e-02, -1.7588e-01, -1.3704e-01,
         -5.7455e-01, -7.8990e-02, -1.3083e-02, -3.0517e-01, -2.3891e-01],
        [-1.0780e-01, -1.1378e-02, -1.3202e-01, -1.4898e-01, -4.5065e-03,
         -6.7813e-02, -6.0134e-01, -1.3712e-02, -1.7588e-01, -1.3704e-01,
         -5.7455e-01, -7.8990e-02, -1.3083e-02, -3.0517e-01, -2.3891e-01]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.7774, -1.6053,  2.3110, -1.4428,  2.3206, -0.7912, -1.3068, -0.7774,
        -1.9872, -0.7774, -0.7774, -0.7774, -1.9214, -0.7774, -0.7774],
       device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 1.9944e-03, -5.8175e+00,  7.3156e+00, -6.1774e+00,  7.5150e+00,
          1.7270e-03, -6.3742e+00,  1.9943e-03, -6.5581e+00,  1.9943e-03,
          1.9943e-03,  1.9943e-03, -7.5924e+00,  1.9943e-03,  1.9943e-03]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -6.5501,  10.3632],
        [-11.0976,  -4.2248],
        [ 12.2904,   0.4430],
        [  9.4050,   0.6178],
        [ -1.6123,   0.1107],
        [ -9.7595,  -5.6638],
        [  0.6634,  11.7324],
        [-11.8709,   5.2726],
        [-10.1408,   7.6564],
        [ 10.7984,   4.2663],
        [ -9.6185,  -5.5749],
        [ -1.6139,   0.1110],
        [ -5.0361,  -9.8457],
        [-14.8907,  -6.7007],
        [ 11.1194,   5.5216]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([  7.2085,   0.3211, -10.1038,  -8.6694,  -3.6661,  -4.4958,   7.2681,
          4.2895,   5.5954,   0.3489,  -5.0775,  -3.6663,  -7.0661,  -4.8552,
          2.0608], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ -0.3224,  -1.0821,  -1.4386,  -0.9689,  -0.1369,   1.6459,  -1.0515,
          -1.6754,  -0.3751,  -0.9910,   2.0759,  -0.1375,  -0.3350,   2.1008,
          -1.5675],
        [ -7.6489,   0.1129,  -3.2284,  -1.8496,  -0.2443,   5.3090, -15.2291,
           0.3444,  -2.1023,  -2.5440,   4.9793,  -0.2467,   8.5851,   6.2644,
          -6.8704],
        [ -0.0659,  -1.0596,  -1.5590,  -1.0560,  -0.1343,   1.5559,  -1.1722,
          -1.0877,   0.1393,  -0.8554,   1.9853,  -0.1352,  -0.3198,   1.9810,
          -1.4286],
        [-11.4803,   4.3348,  -2.5443,  -1.0000,   0.1077,   5.8016, -11.9370,
          -1.5624,  -4.8691,  -3.0045,   5.3791,   0.1119,   5.5180,   6.6104,
          -5.6743],
        [ -3.7655,  -0.9377,  11.2966,   7.9663,  -0.0407,  -0.5339,  -2.7414,
          -4.4814,  -1.6249,   1.2768,  -0.3770,  -0.0394,   3.4110,  -1.3620,
           1.6674],
        [ -1.3488,  -3.8921,   6.3748,   1.7061,  -0.0905,  -1.0386,  -3.7739,
           0.7393,  -1.6058,  -1.7432,  -0.7823,  -0.0902,  -1.7331,  -0.0815,
          -0.8776],
        [  4.5996,  -6.7079, -13.0884,  -6.0754,   0.0304,   0.2860,   5.4023,
           5.7525,   6.5655,  -0.5256,   1.0128,   0.0306,  -8.5007,   5.7901,
          -1.6238],
        [  6.2089,  -5.8635, -11.8124,  -6.0637,   0.0434,  -7.3569,   9.3289,
           6.8852,  11.7424,   0.7473,  -5.5118,   0.0388, -15.4813,  -2.8519,
          -0.2810],
        [ -0.3615,  -1.0843,  -1.4428,  -0.9737,  -0.1363,   1.6493,  -1.0550,
          -1.7311,  -0.4274,  -0.9902,   2.0796,  -0.1369,  -0.3315,   2.1072,
          -1.5669],
        [ -0.5119,  -1.0917,  -1.4587,  -0.9917,  -0.1329,   1.6626,  -1.0655,
          -1.9565,  -0.6344,  -0.9864,   2.0942,  -0.1335,  -0.3177,   2.1332,
          -1.5636],
        [ -0.3160,  -1.0817,  -1.4378,  -0.9681,  -0.1370,   1.6454,  -1.0508,
          -1.6663,  -0.3665,  -0.9911,   2.0753,  -0.1376,  -0.3356,   2.0997,
          -1.5677],
        [  2.0132,   2.4300, -10.7786,  -3.5309,   0.0664,  -0.4586,  -1.6352,
           6.1582,   4.4373,  -1.1181,  -0.6848,   0.0680,  -0.6675,   0.8784,
          -1.5626],
        [ -0.7399,  -1.1001,  -1.4830,  -1.0172,  -0.1253,   1.6842,  -1.0730,
          -2.3334,  -0.9670,  -0.9787,   2.1171,  -0.1258,  -0.2957,   2.1771,
          -1.5565],
        [  1.1424,  -0.7483,  -1.2706,  -1.0148,   0.0697,   1.6428,  -0.6288,
          -0.1401,   1.3800,  -0.9707,   1.9958,   0.0685,  -0.3623,   2.0935,
          -1.5198],
        [ -2.2940,  -1.3849,  -2.1246,  -1.5199,  -0.0584,   1.4446,  -1.3434,
          -5.0065,  -3.3082,  -0.4546,   1.9155,  -0.0592,   0.2935,   2.1235,
          -1.4631]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-2.5006, -0.6101, -2.4393,  1.2271,  2.1983, -3.1691, -2.4218, -1.5598,
        -2.5017, -2.5047, -2.5004,  0.7117, -2.5065, -2.2613, -1.8337],
       device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ 2.2494e+00, -6.4377e+00,  2.1093e+00, -8.2037e-01,  4.2983e-01,
          4.6948e-01,  1.6821e+00, -1.5547e-01,  2.2548e+00,  2.2781e+00,
          2.2486e+00,  1.3134e+00,  2.3209e+00,  2.2598e+00,  1.9737e+00],
        [-2.2069e+00,  6.5332e+00, -2.0631e+00,  8.6846e-01,  8.7355e-01,
          2.1556e-01, -4.8588e-01,  4.8258e-01, -2.2126e+00, -2.2371e+00,
         -2.2060e+00, -1.6520e-01, -2.2817e+00, -2.1987e+00, -1.9377e+00],
        [-7.2088e-02, -1.3355e-01, -1.2721e-01, -7.2968e-01, -9.2028e+00,
         -4.1838e-01, -1.7560e+00, -2.3959e+00, -6.8678e-02, -5.7443e-02,
         -7.2671e-02, -5.3009e+00, -4.5212e-02, -7.0679e-01, -6.6250e-02],
        [ 1.6794e+00,  9.3494e+00,  1.9773e+00,  7.3409e+00, -4.0794e-01,
         -7.2945e+00, -5.1939e+00,  1.4200e+00,  1.6899e+00,  1.7303e+00,
          1.6777e+00, -6.5851e+00,  1.7938e+00,  1.1548e+00,  3.6053e+00],
        [ 3.4524e-01,  2.7958e+00,  4.7994e-01,  5.9312e+00,  1.0038e+01,
          6.2892e-01, -4.4419e+00,  3.2598e+00,  3.3131e-01,  2.7837e-01,
          3.4754e-01, -2.9080e-02,  2.0215e-01,  8.6384e-01,  1.1762e-01],
        [ 2.7071e-01,  3.9673e+00,  4.6914e-01,  1.2991e+01,  7.3666e+00,
          8.5964e-01, -1.0975e+01,  6.4142e+00,  2.5350e-01,  1.9201e-01,
          2.7360e-01, -5.9709e+00,  1.1552e-01,  1.1563e+00,  2.8621e-01],
        [-4.8401e-01,  3.1653e+00, -7.6975e-01,  8.2729e+00,  1.4646e+01,
          5.9629e-03, -4.5484e+00,  3.2263e+00, -4.5639e-01, -3.5155e-01,
         -4.8858e-01,  5.5321e-02, -2.0387e-01, -1.5007e+00,  1.7273e-02]],
       device='cuda:0'))])
xi:  [296.2922]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 426.8087763131675
W_T_median: 393.08421556128883
W_T_pctile_5: 296.28616491461565
W_T_CVAR_5_pct: 154.72881342339656
Average q (qsum/M+1):  51.898776146673384
Optimal xi:  [296.2922]
Expected(across Rb) median(across samples) p_equity:  0.1908900818787515
obj fun:  tensor(-1763.5911, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: Paper_FactorInv_Factor4
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
