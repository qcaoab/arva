/home/marcchen/Documents/constrain_factor/researchcode/exp_config_json_files/multi_portfolio_exp1.json
Starting at: 
18-07-23_16:18

 numpy seed:  2  


 pytorch seed:  2  

Key parameters-------
paths: 256000
iterations: 10000
batchsize: 1000
remove neg:  False
w constaint activation:  yy_fix_jan29


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor2
timeseries_basket['basket_desc'] = Factor2 portfolio for paper: Basic, size and value
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'B10_real_ret', 'VWD_real_ret', 'Size_Lo30_real_ret', 'Value_Hi30_real_ret']
############# End: defined asset  basket #################
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
192601                  0.0                NaN  ...     0.000561     0.023174
192602                  0.0                NaN  ...    -0.033046    -0.053510
192603                  0.0                NaN  ...    -0.064002    -0.096824
192604                  0.0                NaN  ...     0.037029     0.032975
192605                  0.0                NaN  ...     0.012095     0.001035

[5 rows x 16 columns]
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
202208                  NaN            -0.0020  ...    -0.036240    -0.011556
202209                  NaN            -0.0955  ...    -0.091324    -0.099903
202210                  NaN             0.0883  ...     0.077403     0.049863
202211                  NaN            -0.0076  ...     0.052365     0.028123
202212                  NaN            -0.0457  ...    -0.057116    -0.047241

[5 rows x 16 columns]


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor2
timeseries_basket['basket_desc'] = Factor2 portfolio for paper: Basic, size and value
timeseries_basket['basket_columns'] = 
['T30_nom_ret', 'B10_nom_ret', 'VWD_nom_ret', 'Size_Lo30_nom_ret', 'Value_Hi30_nom_ret']
############# End: defined asset  basket #################
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
192607                    0.0014              0.0154  ...     0.005383     0.031411
192608                    0.0319              0.0561  ...     0.005363     0.028647
192609                   -0.0173             -0.0071  ...     0.005343     0.005787
192610                   -0.0294             -0.0355  ...     0.005323    -0.028996
192611                   -0.0038              0.0294  ...     0.005303     0.028554

[5 rows x 6 columns]
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
202208                   -0.0020             -0.0164  ...    -0.043289    -0.036240
202209                   -0.0955             -0.0871  ...    -0.050056    -0.091324
202210                    0.0883              0.1486  ...    -0.014968     0.077403
202211                   -0.0076              0.0462  ...     0.040789     0.052365
202212                   -0.0457             -0.0499  ...    -0.018566    -0.057116

[5 rows x 6 columns]
Indices constructed with column names:
Index(['date_for_plt', 'Size_Lo30_nom_ret_ind', 'Value_Hi30_nom_ret_ind',
       'CPI_nom_ret_ind', 'T30_nom_ret_ind', 'B10_nom_ret_ind',
       'VWD_nom_ret_ind'],
      dtype='object')
############# Updated: defined asset basket #################
timeseries_basket['data_df_mean'] = 
T30_real_ret           0.000229
B10_real_ret           0.001637
VWD_real_ret           0.006759
Size_Lo30_real_ret     0.009939
Value_Hi30_real_ret    0.010052
dtype: float64


timeseries_basket['data_df_stdev'] = 
T30_real_ret           0.005227
B10_real_ret           0.019258
VWD_real_ret           0.053610
Size_Lo30_real_ret     0.082598
Value_Hi30_real_ret    0.072063
dtype: float64


timeseries_basket['data_df_corr'] = 
                     T30_real_ret  ...  Value_Hi30_real_ret
T30_real_ret             1.000000  ...             0.018239
B10_real_ret             0.351722  ...             0.031301
VWD_real_ret             0.068448  ...             0.909335
Size_Lo30_real_ret       0.014412  ...             0.908542
Value_Hi30_real_ret      0.018239  ...             1.000000

[5 rows x 5 columns]


timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names', 'data_df', 'data_df_mean', 'data_df_stdev', 'data_df_corr'])
############# End: updated: defined asset basket #################
-----------------------------------------------
Dates to be REMOVED due to missing values (should be at *start* only due to trading signals):
Int64Index([], dtype='int64')
-----------------------------------------------
Dates from available data for bootstrapping:
Start: 192607
End: 202212
-----------------------------------------------
Bootstrap block size: 6
-----------------------------------------------
Dates USED bootstrapping:
Start: 196307
End: 202212
-----------------------------------------------
0.0% of bootstrap sample done.
5.0% of bootstrap sample done.
10.0% of bootstrap sample done.
15.0% of bootstrap sample done.
20.0% of bootstrap sample done.
25.0% of bootstrap sample done.
30.0% of bootstrap sample done.
35.0% of bootstrap sample done.
40.0% of bootstrap sample done.
45.0% of bootstrap sample done.
50.0% of bootstrap sample done.
55.00000000000001% of bootstrap sample done.
60.0% of bootstrap sample done.
65.0% of bootstrap sample done.
70.0% of bootstrap sample done.
75.0% of bootstrap sample done.
80.0% of bootstrap sample done.
85.0% of bootstrap sample done.
90.0% of bootstrap sample done.
95.0% of bootstrap sample done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      13  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      13  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 13)     True          13  
2     (13, 13)     True          13  
3      (13, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       6       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      13  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      13  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       6              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 13)     True          13  
2     (13, 13)     True          13  
3      (13, 6)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       13  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       13  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 13)      True          13  
0     (13, 13)      True          13  
0      (13, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       13  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       13  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        6              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 13)      True          13  
0     (13, 13)      True          13  
0      (13, 6)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 500, 'itbound_SGD_algorithms': 10000, 'nit_IterateAveragingStart': 9000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       13  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       13  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 13)      True          13  
0     (13, 13)      True          13  
0      (13, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       13  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       13  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        6              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 13)      True          13  
0     (13, 13)      True          13  
0      (13, 6)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-10.6829,  -0.9899],
        [  3.7461,  -8.6940],
        [ -1.1031,   1.4265],
        [ -4.2631, -11.0761],
        [  4.9691,  -8.8128],
        [ -1.0401,   1.3068],
        [ -7.0617,  -4.1018],
        [ -9.6502,   8.9263],
        [  9.5645,   1.0432],
        [ -8.9480,  -2.4834],
        [  3.0281,  -8.8872],
        [ -8.6267,   8.3395],
        [-49.8229,  -5.4397]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ 9.1355, -5.7429, -2.6909, -5.3538, -5.7410, -2.7192,  5.7084,  4.3039,
        -8.6489,  7.5354, -5.6595,  3.8232, -3.9535], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ 9.5440e+00,  9.0182e-01,  5.6541e-01, -1.4066e-03,  1.8922e+00,
          4.4803e-01,  4.5141e+00,  3.7661e+00, -4.3648e+00,  6.6846e+00,
          4.9106e-01,  7.3906e-01, -1.7109e-20],
        [-4.9072e-01, -1.4671e-01, -6.0405e-03, -2.4150e-01, -2.2039e-01,
         -6.8496e-03, -4.7508e-01, -8.2894e-02, -2.7851e-01, -4.8606e-01,
         -1.4535e-01, -8.1520e-02, -1.0049e-01],
        [-5.3446e+00,  3.5061e+00, -1.6298e-01,  1.1620e+01,  4.2876e+00,
         -1.8941e-02, -1.7479e+00, -7.7567e+00,  7.0560e+00, -4.1144e+00,
          3.6316e+00, -7.6515e+00,  1.0625e+01],
        [-6.2571e+00,  3.3289e+00,  2.4885e-01,  1.0370e+01,  3.7883e+00,
          2.2542e-01, -1.4455e+00, -4.6006e+00,  5.5843e+00, -4.0139e+00,
          3.7249e+00, -4.4364e+00,  7.5383e+00],
        [-4.9072e-01, -1.4671e-01, -6.0405e-03, -2.4150e-01, -2.2039e-01,
         -6.8496e-03, -4.7508e-01, -8.2894e-02, -2.7851e-01, -4.8606e-01,
         -1.4535e-01, -8.1520e-02, -1.0049e-01],
        [-5.3704e+00,  3.0000e+00,  5.7847e-03,  1.3655e+01,  4.2820e+00,
         -7.0646e-02, -1.3299e+00, -7.1488e+00,  5.8048e+00, -3.2771e+00,
          3.6867e+00, -7.0517e+00,  1.2433e+01],
        [-6.0730e+00,  3.4108e+00,  2.0064e-01,  1.1342e+01,  4.0053e+00,
          1.2312e-01, -1.6032e+00, -6.1736e+00,  6.8324e+00, -3.8984e+00,
          3.8052e+00, -6.0558e+00,  8.6698e+00],
        [-4.9072e-01, -1.4671e-01, -6.0405e-03, -2.4150e-01, -2.2039e-01,
         -6.8496e-03, -4.7508e-01, -8.2894e-02, -2.7851e-01, -4.8606e-01,
         -1.4535e-01, -8.1520e-02, -1.0049e-01],
        [-2.3990e+00,  2.6319e-02, -1.2302e-01,  4.0824e-01,  2.6876e-01,
         -1.0829e-01, -7.5869e-01, -3.5946e-01,  1.0200e+00, -1.5215e+00,
          2.8801e-03, -3.9632e-01,  1.7991e-02],
        [-4.9072e-01, -1.4671e-01, -6.0405e-03, -2.4150e-01, -2.2039e-01,
         -6.8496e-03, -4.7508e-01, -8.2894e-02, -2.7851e-01, -4.8606e-01,
         -1.4535e-01, -8.1520e-02, -1.0049e-01],
        [-4.9072e-01, -1.4671e-01, -6.0405e-03, -2.4150e-01, -2.2039e-01,
         -6.8496e-03, -4.7508e-01, -8.2894e-02, -2.7851e-01, -4.8606e-01,
         -1.4535e-01, -8.1520e-02, -1.0049e-01],
        [-4.9072e-01, -1.4671e-01, -6.0405e-03, -2.4150e-01, -2.2039e-01,
         -6.8496e-03, -4.7508e-01, -8.2894e-02, -2.7851e-01, -4.8606e-01,
         -1.4535e-01, -8.1520e-02, -1.0049e-01],
        [-4.9072e-01, -1.4671e-01, -6.0405e-03, -2.4150e-01, -2.2039e-01,
         -6.8496e-03, -4.7508e-01, -8.2894e-02, -2.7851e-01, -4.8606e-01,
         -1.4535e-01, -8.1520e-02, -1.0049e-01]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.2318, -0.9535, -2.9434, -1.9927, -0.9535, -2.4056, -2.5673, -0.9535,
        -2.2314, -0.9535, -0.9535, -0.9535, -0.9535], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 12.2102,   0.0346,  -9.6845,  -5.9831,   0.0346, -10.8043,  -7.7913,
           0.0346,  -0.9826,   0.0346,   0.0346,   0.0346,   0.0346]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  0.2287,  14.1091],
        [-10.4143,  -5.1617],
        [-12.2121,   1.1868],
        [ 10.7429,   3.4456],
        [  0.1234,   1.7005],
        [ -1.6260,   0.3049],
        [ 10.6687,   4.5197],
        [  5.6502,  11.5341],
        [ -4.1337,  15.6659],
        [  8.9638,   4.1441],
        [ -8.7096,   3.7339],
        [-12.2784,  -6.3820],
        [ -2.2217, -12.9624]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ 7.7598, -3.0003, 10.9901, -2.4904, -4.4079, -3.9656,  0.7053,  8.1873,
         9.9863, -6.1396, -5.5146, -3.6450, -8.1119], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-1.5333e+00, -4.2342e-01, -1.0041e+00, -5.6805e-01,  1.0828e+00,
         -4.6744e-02, -1.0540e+00, -1.3107e+00, -2.6493e-01, -1.0013e+00,
          1.6374e+00, -4.6729e-01, -3.2120e-01],
        [-1.7515e+00, -8.0355e-01, -8.2736e-01, -2.7583e-01,  1.2337e+00,
          3.6873e-02, -7.1245e-01, -1.2469e+00,  4.1618e-02, -8.9002e-01,
          2.2531e+00, -9.0955e-01,  3.3894e-01],
        [-1.6848e+00, -6.4885e-01, -9.1447e-01, -2.2897e-01,  1.3951e+00,
          1.5354e-01, -7.2018e-01, -1.1007e+00,  3.0895e-01, -7.0130e-01,
          2.5065e+00, -7.5342e-01,  6.0066e-01],
        [-3.4486e+00,  2.2437e+00,  2.0310e+00, -3.2213e+00,  1.3708e-01,
          3.4800e-01, -3.1026e+00,  3.6217e+00, -9.5557e+00, -2.7793e+00,
          1.8361e-02,  5.3748e+00, -1.1628e+00],
        [-7.9508e-01,  2.8940e-01, -1.0705e+00, -1.5024e+00,  5.7296e-01,
         -5.3861e-02, -1.1965e+00,  1.2360e-01,  3.4560e-01, -2.1826e+00,
          8.4987e-01,  1.5328e-01, -1.3741e-01],
        [ 4.0948e-01, -5.3405e+00,  8.1251e-01,  1.0401e+00, -3.2544e-01,
         -1.3434e-01,  9.8637e-01, -2.9695e+00,  9.2264e+00, -1.2205e+00,
         -1.3802e-01, -4.9892e+00, -4.5928e-02],
        [ 5.1160e-01,  7.3621e+00,  7.2395e-01, -1.6604e+00, -2.0150e-01,
         -1.5868e-01, -1.0022e+01, -1.8805e+01,  3.9191e+00, -6.6153e-02,
          1.3633e-02,  1.0573e+01,  1.3172e+00],
        [-5.9643e-01, -3.0192e-01, -6.3058e-01, -1.2554e+00, -3.9998e-02,
          5.8343e-03, -1.9398e+00, -1.0892e+00, -9.7249e-01,  7.9070e-02,
         -2.5725e-02, -2.5176e-01, -1.0102e+00],
        [-9.7987e-01, -2.2740e-01, -1.2263e+00, -1.1681e+00,  4.7040e-02,
          5.1876e-03, -1.5942e+00, -8.2568e-01, -5.1736e-01, -7.6176e-01,
          6.5533e-02, -2.3047e-01, -6.4792e-01],
        [-8.0943e+00,  2.2381e+00,  1.6128e+00, -8.6471e-01,  1.3069e-01,
          1.8910e-01, -5.1711e+00, -1.2011e+01, -8.3444e+00, -7.4624e-01,
         -2.1222e-02,  9.0231e+00,  4.6157e+00],
        [-1.2814e+01,  4.1954e+00,  5.4845e+00, -3.6667e+00,  2.8457e-01,
          2.8567e-01, -5.9698e+00, -7.5266e+00, -1.9086e+01, -5.1107e+00,
          6.8492e-03,  1.1190e+01,  4.4451e+00],
        [-3.9215e+00,  4.3097e+00,  4.4074e+00, -1.7321e+00, -3.1981e-02,
          5.9617e-03, -4.8828e+00, -1.5814e+01, -3.7288e+00, -8.7054e-01,
         -5.1611e-04,  7.5909e+00,  2.5780e+00],
        [ 1.1560e+00,  3.1357e+00,  9.6439e+00, -3.4833e+00,  3.6166e-01,
          1.7087e-01, -5.0535e+00,  1.3162e-01,  4.3846e+00,  1.0848e+00,
         -5.6145e+00,  2.9158e+00, -2.2844e+01]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-1.7903, -1.4367, -1.3635, -1.6905, -1.5785,  0.9205, -1.2820, -2.7250,
        -2.0401,  2.2004,  1.3671, -1.5116, -5.8435], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-6.9570e-02, -2.7371e-01, -4.2894e-01, -2.8659e+00, -2.3648e-01,
         -5.9186e+00, -1.5547e-02, -1.6484e-02, -3.2538e-02, -1.0816e+00,
         -3.0326e+00, -7.1478e-02, -9.4163e-03],
        [-2.3553e-01, -3.3267e-01, -3.8674e-01, -3.9700e-01, -6.5018e-01,
         -5.8115e+00,  4.0932e-01,  1.5855e-02, -1.2032e-01,  5.4800e+00,
          2.8795e-01,  1.2112e+01, -1.1741e-01],
        [ 2.8016e-01,  3.8973e-01,  4.5286e-01,  1.3116e+00,  7.5580e-01,
          1.1790e+01, -3.8304e-01,  9.3621e-03,  1.5550e-01, -4.5382e+00,
          7.5127e-01, -1.2045e+01,  1.2215e-01],
        [-1.5595e+00, -2.1892e+00, -2.2187e+00,  2.0326e+00, -1.4831e+00,
         -2.9289e-01,  8.4674e+00, -2.5809e-01, -6.0090e-01, -5.2713e+00,
         -6.3804e+00,  7.1884e+00,  2.0110e+00],
        [ 1.5594e+00,  2.1891e+00,  2.2187e+00, -2.0316e+00,  1.4904e+00,
          2.7217e-01, -8.4721e+00,  2.5786e-01,  6.0086e-01,  5.2117e+00,
          6.3260e+00, -7.1920e+00, -2.0296e+00],
        [-9.8024e-02, -1.9390e-01, -3.6144e-01, -1.9889e+00,  2.5553e-01,
          1.0469e+00, -1.8969e+01, -5.3609e-01,  2.8045e-02, -2.0479e-01,
          1.1950e+01, -1.7808e+00, -2.3489e+00]], device='cuda:0'))])
loaded xi:  53.657986
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.0, 0.5, 0.2, 0.15, 0.15]
W_T_mean: 946.602944399095
W_T_median: 688.975868829786
W_T_pctile_5: -224.8070334170533
W_T_CVAR_5_pct: -354.8956793322215
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1720.1594626081708
Current xi:  [59.711002]
objective value function right now is: -1720.1594626081708
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1723.0682042563215
Current xi:  [65.92856]
objective value function right now is: -1723.0682042563215
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1725.442092555304
Current xi:  [72.18032]
objective value function right now is: -1725.442092555304
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -1728.1414315652441
Current xi:  [78.343094]
objective value function right now is: -1728.1414315652441
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1730.1142828673735
Current xi:  [84.39512]
objective value function right now is: -1730.1142828673735
12.0% of gradient descent iterations done. Method = Adam
new min fval:  -1734.0993757928368
Current xi:  [91.123955]
objective value function right now is: -1734.0993757928368
14.000000000000002% of gradient descent iterations done. Method = Adam
new min fval:  -1737.2082299154586
Current xi:  [98.007454]
objective value function right now is: -1737.2082299154586
16.0% of gradient descent iterations done. Method = Adam
new min fval:  -1741.2243363434268
Current xi:  [104.691925]
objective value function right now is: -1741.2243363434268
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [110.55702]
objective value function right now is: -1733.3566095233784
20.0% of gradient descent iterations done. Method = Adam
new min fval:  -1745.487810068123
Current xi:  [116.42591]
objective value function right now is: -1745.487810068123
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -1748.1946562676694
Current xi:  [122.77176]
objective value function right now is: -1748.1946562676694
24.0% of gradient descent iterations done. Method = Adam
new min fval:  -1750.486864668254
Current xi:  [129.08844]
objective value function right now is: -1750.486864668254
26.0% of gradient descent iterations done. Method = Adam
new min fval:  -1751.8432254904362
Current xi:  [134.96954]
objective value function right now is: -1751.8432254904362
28.000000000000004% of gradient descent iterations done. Method = Adam
new min fval:  -1753.0164556904776
Current xi:  [141.13478]
objective value function right now is: -1753.0164556904776
30.0% of gradient descent iterations done. Method = Adam
new min fval:  -1756.3379093825008
Current xi:  [146.94415]
objective value function right now is: -1756.3379093825008
32.0% of gradient descent iterations done. Method = Adam
new min fval:  -1756.6356421949076
Current xi:  [152.53714]
objective value function right now is: -1756.6356421949076
34.0% of gradient descent iterations done. Method = Adam
new min fval:  -1759.7860829893878
Current xi:  [158.02841]
objective value function right now is: -1759.7860829893878
36.0% of gradient descent iterations done. Method = Adam
new min fval:  -1761.4177997923227
Current xi:  [163.75119]
objective value function right now is: -1761.4177997923227
38.0% of gradient descent iterations done. Method = Adam
new min fval:  -1763.2985956335372
Current xi:  [169.10681]
objective value function right now is: -1763.2985956335372
40.0% of gradient descent iterations done. Method = Adam
new min fval:  -1764.2752097626812
Current xi:  [174.45425]
objective value function right now is: -1764.2752097626812
42.0% of gradient descent iterations done. Method = Adam
new min fval:  -1765.7204666488958
Current xi:  [179.89609]
objective value function right now is: -1765.7204666488958
44.0% of gradient descent iterations done. Method = Adam
new min fval:  -1767.797632550593
Current xi:  [185.14053]
objective value function right now is: -1767.797632550593
46.0% of gradient descent iterations done. Method = Adam
new min fval:  -1768.8987984407963
Current xi:  [190.30354]
objective value function right now is: -1768.8987984407963
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [195.4028]
objective value function right now is: -1767.2575613515953
50.0% of gradient descent iterations done. Method = Adam
new min fval:  -1770.4633798001535
Current xi:  [200.53923]
objective value function right now is: -1770.4633798001535
52.0% of gradient descent iterations done. Method = Adam
new min fval:  -1771.9741409260494
Current xi:  [205.59843]
objective value function right now is: -1771.9741409260494
54.0% of gradient descent iterations done. Method = Adam
new min fval:  -1773.1396105768524
Current xi:  [210.6288]
objective value function right now is: -1773.1396105768524
56.00000000000001% of gradient descent iterations done. Method = Adam
new min fval:  -1773.513104944288
Current xi:  [215.4556]
objective value function right now is: -1773.513104944288
57.99999999999999% of gradient descent iterations done. Method = Adam
new min fval:  -1776.1476110371525
Current xi:  [220.2474]
objective value function right now is: -1776.1476110371525
60.0% of gradient descent iterations done. Method = Adam
new min fval:  -1777.2967596793249
Current xi:  [224.36304]
objective value function right now is: -1777.2967596793249
62.0% of gradient descent iterations done. Method = Adam
new min fval:  -1778.2336374443692
Current xi:  [228.82628]
objective value function right now is: -1778.2336374443692
64.0% of gradient descent iterations done. Method = Adam
new min fval:  -1779.2405635340265
Current xi:  [233.35179]
objective value function right now is: -1779.2405635340265
66.0% of gradient descent iterations done. Method = Adam
new min fval:  -1779.6772886124077
Current xi:  [237.31654]
objective value function right now is: -1779.6772886124077
68.0% of gradient descent iterations done. Method = Adam
new min fval:  -1780.6397944417718
Current xi:  [241.5654]
objective value function right now is: -1780.6397944417718
70.0% of gradient descent iterations done. Method = Adam
new min fval:  -1781.0481742343857
Current xi:  [245.46397]
objective value function right now is: -1781.0481742343857
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -1782.3575975417898
Current xi:  [246.36232]
objective value function right now is: -1782.3575975417898
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -1782.4016113171726
Current xi:  [247.18152]
objective value function right now is: -1782.4016113171726
76.0% of gradient descent iterations done. Method = Adam
new min fval:  -1782.7146826387095
Current xi:  [248.13704]
objective value function right now is: -1782.7146826387095
78.0% of gradient descent iterations done. Method = Adam
new min fval:  -1782.9704519669883
Current xi:  [249.05937]
objective value function right now is: -1782.9704519669883
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [249.92262]
objective value function right now is: -1782.8516144415944
82.0% of gradient descent iterations done. Method = Adam
new min fval:  -1783.3129119488337
Current xi:  [250.86273]
objective value function right now is: -1783.3129119488337
84.0% of gradient descent iterations done. Method = Adam
new min fval:  -1783.3514960347559
Current xi:  [251.7818]
objective value function right now is: -1783.3514960347559
86.0% of gradient descent iterations done. Method = Adam
new min fval:  -1783.3581148716944
Current xi:  [252.79454]
objective value function right now is: -1783.3581148716944
88.0% of gradient descent iterations done. Method = Adam
new min fval:  -1783.7910444706106
Current xi:  [253.78357]
objective value function right now is: -1783.7910444706106
90.0% of gradient descent iterations done. Method = Adam
new min fval:  -1783.945457014035
Current xi:  [254.74368]
objective value function right now is: -1783.945457014035
92.0% of gradient descent iterations done. Method = Adam
new min fval:  -1784.1728041513118
Current xi:  [255.73982]
objective value function right now is: -1784.1728041513118
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [256.66983]
objective value function right now is: -1783.9285877745594
new min fval from sgd:  -1784.1781031127964
new min fval from sgd:  -1784.1931269186223
new min fval from sgd:  -1784.215465476322
new min fval from sgd:  -1784.243239108558
new min fval from sgd:  -1784.273205362955
new min fval from sgd:  -1784.2932246019907
new min fval from sgd:  -1784.2965181830436
new min fval from sgd:  -1784.297129149646
new min fval from sgd:  -1784.3081722127242
new min fval from sgd:  -1784.3097956800086
new min fval from sgd:  -1784.3154615564404
new min fval from sgd:  -1784.328471545753
new min fval from sgd:  -1784.3353091093995
new min fval from sgd:  -1784.354253055055
new min fval from sgd:  -1784.3893882723646
new min fval from sgd:  -1784.440111382041
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [257.62308]
objective value function right now is: -1784.1473888263479
new min fval from sgd:  -1784.4557022403628
new min fval from sgd:  -1784.476522804913
new min fval from sgd:  -1784.4976433764423
new min fval from sgd:  -1784.5038351489995
new min fval from sgd:  -1784.5139661217997
new min fval from sgd:  -1784.5141134917355
new min fval from sgd:  -1784.5485133293391
new min fval from sgd:  -1784.5664368768746
new min fval from sgd:  -1784.6061747541419
new min fval from sgd:  -1784.6133410564428
new min fval from sgd:  -1784.6172350560391
new min fval from sgd:  -1784.6232261587204
new min fval from sgd:  -1784.6233421174652
new min fval from sgd:  -1784.6273528187276
new min fval from sgd:  -1784.631401368047
new min fval from sgd:  -1784.6368994393893
new min fval from sgd:  -1784.6418471706374
new min fval from sgd:  -1784.6423253188827
new min fval from sgd:  -1784.6428657940003
new min fval from sgd:  -1784.6449646257556
new min fval from sgd:  -1784.6472672214597
new min fval from sgd:  -1784.6500080846586
new min fval from sgd:  -1784.655321340608
new min fval from sgd:  -1784.6610322982845
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [258.19495]
objective value function right now is: -1784.6420862653126
new min fval from sgd:  -1784.6651814569339
new min fval from sgd:  -1784.6683314254576
new min fval from sgd:  -1784.6696215828574
new min fval from sgd:  -1784.6732177205208
new min fval from sgd:  -1784.6747186731448
new min fval from sgd:  -1784.6769210758887
new min fval from sgd:  -1784.6769658434275
new min fval from sgd:  -1784.6794504352488
new min fval from sgd:  -1784.6820506871
new min fval from sgd:  -1784.685457268469
new min fval from sgd:  -1784.688576802039
new min fval from sgd:  -1784.691491433785
new min fval from sgd:  -1784.6940747896322
new min fval from sgd:  -1784.6961922678822
new min fval from sgd:  -1784.6974819322882
new min fval from sgd:  -1784.6986391190608
new min fval from sgd:  -1784.7010440053302
new min fval from sgd:  -1784.7035357054494
new min fval from sgd:  -1784.7036251276043
new min fval from sgd:  -1784.704538872492
new min fval from sgd:  -1784.709799542673
new min fval from sgd:  -1784.7123645308222
new min fval from sgd:  -1784.7155073419572
new min fval from sgd:  -1784.7221061080284
new min fval from sgd:  -1784.7250596143092
new min fval from sgd:  -1784.7257127296768
new min fval from sgd:  -1784.7257245305739
new min fval from sgd:  -1784.7265900856187
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [258.39487]
objective value function right now is: -1784.7089235526616
min fval:  -1784.7265900856187
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-11.8010,   0.6565],
        [  3.4871,  -9.4865],
        [ -1.2205,   0.5050],
        [ -6.1849, -12.0946],
        [  5.7624,  -9.2381],
        [ -1.2204,   0.5049],
        [ -6.9194,  -4.1916],
        [-11.9672,   8.2973],
        [ 10.7139,  -0.1370],
        [ -9.4685,  -1.5425],
        [  3.1718,  -9.7053],
        [-11.2808,   8.0004],
        [-49.7957,  -5.9868]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ 9.9337, -5.9535, -2.5391, -5.3921, -5.9069, -2.5378,  6.2200,  5.1102,
        -9.3013,  8.1430, -5.9037,  4.3296, -4.0447], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ 2.1627,  0.1821,  0.0746,  0.1278,  0.3124,  0.0744,  1.0889, -0.1787,
          0.7183,  1.5428,  0.1817, -0.1584, -0.0338],
        [-0.4751, -0.2551, -0.0241, -0.1177, -0.3372, -0.0241, -0.4902, -0.0588,
         -0.5846, -0.4797, -0.2535, -0.0365, -0.0183],
        [-6.0188,  3.5266, -0.0419, 12.1551,  3.9906, -0.0372, -1.6356, -7.5908,
          8.0524, -4.2015,  3.8514, -7.0174, 11.3978],
        [-6.4207,  3.0693,  0.1005,  8.6084,  2.8837,  0.1001, -1.4844, -3.2328,
          5.1999, -3.9596,  3.5201, -2.4917,  5.7309],
        [-0.4751, -0.2551, -0.0241, -0.1177, -0.3372, -0.0241, -0.4902, -0.0588,
         -0.5846, -0.4797, -0.2535, -0.0365, -0.0183],
        [-6.0621,  3.3917,  0.0437, 13.9726,  4.4223,  0.0427, -1.0737, -7.7022,
          7.6670, -3.2808,  4.2236, -7.2507, 13.2875],
        [-6.7110,  3.5116, -0.0432, 11.2712,  3.5569, -0.0477, -1.5641, -5.8561,
          7.3634, -4.0100,  4.0686, -5.1959,  9.1778],
        [-0.4751, -0.2551, -0.0241, -0.1177, -0.3372, -0.0241, -0.4902, -0.0588,
         -0.5846, -0.4797, -0.2535, -0.0365, -0.0183],
        [-0.4748, -0.2550, -0.0241, -0.1178, -0.3370, -0.0241, -0.4901, -0.0588,
         -0.5843, -0.4795, -0.2534, -0.0365, -0.0185],
        [-0.4751, -0.2551, -0.0241, -0.1177, -0.3372, -0.0241, -0.4902, -0.0588,
         -0.5846, -0.4797, -0.2535, -0.0365, -0.0183],
        [-0.4751, -0.2551, -0.0241, -0.1177, -0.3372, -0.0241, -0.4902, -0.0588,
         -0.5846, -0.4797, -0.2535, -0.0365, -0.0183],
        [-0.4751, -0.2551, -0.0241, -0.1177, -0.3372, -0.0241, -0.4902, -0.0588,
         -0.5846, -0.4797, -0.2535, -0.0365, -0.0183],
        [-0.4751, -0.2551, -0.0241, -0.1177, -0.3372, -0.0241, -0.4902, -0.0588,
         -0.5846, -0.4797, -0.2535, -0.0365, -0.0183]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([ 3.1717, -1.1786, -2.8036, -2.0211, -1.1786, -2.2399, -2.4539, -1.1786,
        -1.1804, -1.1786, -1.1786, -1.1786, -1.1786], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 12.1103,   0.0286, -10.0163,  -4.2435,   0.0286, -11.6379,  -7.3784,
           0.0286,   0.0287,   0.0286,   0.0286,   0.0286,   0.0286]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -8.8878,  11.2188],
        [-11.4725,  -3.6942],
        [-13.8481,   0.7943],
        [  9.9353,   1.9385],
        [ -1.1456,   0.8706],
        [  0.2025,  -1.9106],
        [ 11.6023,   3.7619],
        [  4.6363,  10.5662],
        [ -4.4401,  16.9520],
        [  3.7081,   8.5288],
        [ -6.9094,   3.4824],
        [-11.0673,  -6.9106],
        [ -3.4530, -13.3668]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ 6.4679, -3.5374, 10.5484, -2.7066, -3.4393, -5.3812,  0.6561,  9.0259,
        10.1556, -7.4146, -5.7136, -5.5304, -9.1046], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-5.2704e-01,  7.9843e-03, -1.0719e+01,  1.4585e+00,  2.9704e-01,
          9.2579e-02,  1.9854e-01,  5.1664e-01,  1.4558e+00, -1.7129e+00,
          7.7087e+00,  1.8936e-02, -7.9630e+00],
        [-4.5613e-01, -1.6461e-01, -6.3208e-01, -8.8593e-01,  1.3746e-02,
         -8.5311e-03, -9.4619e-01, -1.3122e+00, -8.5095e-01,  2.0914e-02,
          4.3306e-02, -2.3805e-01, -9.0424e-01],
        [-4.5426e-01, -1.6510e-01, -6.3201e-01, -8.8004e-01,  1.3899e-02,
         -8.7323e-03, -9.4673e-01, -1.3154e+00, -8.4990e-01,  2.1466e-02,
          4.2942e-02, -2.3781e-01, -9.0463e-01],
        [-4.4397e+00,  3.4033e+00,  1.5178e+00, -2.2494e+00,  6.3238e-02,
          5.8896e-01, -2.7011e+00,  2.4347e+00, -1.3085e+01, -3.2802e-03,
         -1.9177e-02,  6.9169e+00,  7.1532e+00],
        [-2.1910e+00, -1.2596e+00, -5.4274e+00,  1.7762e+00,  1.6410e-01,
          9.8562e-01,  2.3548e+00,  2.6764e+00, -4.7328e+00, -8.8515e-01,
          6.5147e+00, -7.6384e-01,  1.4664e+00],
        [ 1.4909e-01, -1.6873e-01,  1.4070e+00, -9.5147e-02,  4.1571e-02,
          1.6771e-01,  1.5632e+00,  6.8916e-01,  2.5827e-01,  2.4451e-01,
          1.8557e-02, -2.7902e-01, -1.6265e-01],
        [ 4.3212e-01,  6.1238e+00,  1.0762e+00, -3.5232e+00,  3.0738e-02,
         -2.1363e+00, -8.0958e+00, -1.0485e+01,  1.9615e-01, -1.1727e-05,
          3.8679e-04,  1.0965e+01, -1.5421e+00],
        [-2.0311e-01, -6.4322e-02, -1.5829e+00, -3.9300e-01, -2.2410e-02,
         -3.4792e-02, -1.0459e+00, -1.7622e+00, -2.6588e-01, -1.4262e-01,
         -2.3011e-02, -7.1028e-02, -5.1553e-01],
        [-7.4986e-01,  1.6526e-01, -3.9481e+00, -3.2397e-01, -4.2012e-02,
          8.1653e-01, -1.3954e+00, -1.2109e+00,  1.5223e-01,  5.7907e-01,
         -1.4010e-02,  1.4866e+00, -1.9426e+00],
        [ 6.7150e-02,  1.6231e+00, -2.6852e+00,  1.2081e-02,  1.4094e-02,
          2.0255e-01, -2.6396e+00, -6.7418e+00, -9.6373e-02, -6.4902e-02,
         -2.9877e-04,  3.3206e+00,  4.7744e+00],
        [-7.1590e+00,  3.3308e+00,  5.4549e+00, -4.4629e+00,  2.1594e-01,
          2.9911e-01, -5.6267e+00, -8.7577e+00, -1.6735e+01,  1.4208e-03,
         -2.3765e-02,  8.6321e+00,  7.4473e+00],
        [ 3.9957e+00,  1.9173e+00,  3.5757e+00, -3.5102e+00,  2.5746e-01,
         -4.0855e-01, -3.3183e+00, -5.1422e+00,  5.0371e+00, -7.8188e-01,
         -2.2091e-01,  3.3762e+00, -8.4776e-01],
        [ 2.6268e+00,  1.1778e-03,  7.5208e+00, -2.5101e+00,  2.5869e-01,
         -3.8846e-01, -4.9600e+00, -2.7959e-01,  5.4365e+00,  1.0378e+00,
         -3.6765e+00, -6.9610e-01, -1.3332e+01]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([ 0.0480, -1.5407, -1.5454, -0.5467,  0.6181,  2.0597, -3.8523, -1.5912,
        -1.2136,  0.8106,  2.5800, -2.4428, -6.2647], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-4.7752e-01, -1.8907e-02, -1.8810e-02, -6.4196e-01, -1.1202e+00,
         -3.3382e+00, -1.1063e-03, -1.1224e-02, -8.1461e-03, -1.4235e-01,
         -3.7668e-01, -7.0773e-02, -3.7488e-01],
        [-4.6609e-01, -1.3125e-02, -1.2885e-02, -4.2090e-01, -1.0405e+00,
         -3.1803e+00, -1.7153e-04, -9.7790e-03, -7.7623e-03, -5.1967e-02,
         -1.2276e-01, -5.2444e-02, -3.9664e-01],
        [ 1.0305e+00,  3.2471e-02,  3.2309e-02,  1.0756e+00,  2.3206e+00,
          6.8190e+00,  1.1836e-03,  2.1509e-02,  1.5024e-02,  3.1101e-01,
          6.2746e-01,  1.2285e-01,  7.5870e-01],
        [-1.6096e+00,  3.0655e-01,  3.0405e-01,  5.1363e-01, -1.3234e+00,
          6.0471e-02,  6.7735e+00, -1.4851e-01, -4.6925e-01, -2.3034e+00,
         -4.4517e+00,  3.7758e+00,  9.9542e-01],
        [ 1.6102e+00, -3.0641e-01, -3.0391e-01, -5.1140e-01,  1.3311e+00,
         -8.0210e-02, -6.7776e+00,  1.4884e-01,  4.6945e-01,  2.2803e+00,
          4.4311e+00, -3.7779e+00, -1.0126e+00],
        [ 6.7485e+00,  2.6826e-01,  2.6808e-01, -2.0013e+00,  3.9213e+00,
          1.0882e+00, -1.8313e+01,  2.0697e-01,  1.7493e+00,  2.5572e-01,
          1.3044e+01, -3.7418e+00, -2.1230e+00]], device='cuda:0'))])
xi:  [258.30768]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 406.99757731503956
W_T_median: 358.61883327403433
W_T_pctile_5: 258.3837169542242
W_T_CVAR_5_pct: 121.07878421747442
Average q (qsum/M+1):  53.666204637096776
Optimal xi:  [258.30768]
Expected(across Rb) median(across samples) p_equity:  0.21331767035493007
obj fun:  tensor(-1784.7266, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: Paper_FactorInv_Factor2
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
