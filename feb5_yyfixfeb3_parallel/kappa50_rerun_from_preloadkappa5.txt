Starting at: 
07-02-23_10:51

 Random seed:  2  

Key parameters-------
paths: 256000
iterations: 10000
batchsize: 1000
remove neg:  False


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
3.3333333333333335% of MC simulations done.
6.666666666666667% of MC simulations done.
10.0% of MC simulations done.
13.333333333333334% of MC simulations done.
16.666666666666664% of MC simulations done.
20.0% of MC simulations done.
23.333333333333332% of MC simulations done.
26.666666666666668% of MC simulations done.
30.0% of MC simulations done.
33.33333333333333% of MC simulations done.
36.666666666666664% of MC simulations done.
40.0% of MC simulations done.
43.333333333333336% of MC simulations done.
46.666666666666664% of MC simulations done.
50.0% of MC simulations done.
53.333333333333336% of MC simulations done.
56.666666666666664% of MC simulations done.
60.0% of MC simulations done.
63.33333333333333% of MC simulations done.
66.66666666666666% of MC simulations done.
70.0% of MC simulations done.
73.33333333333333% of MC simulations done.
76.66666666666667% of MC simulations done.
80.0% of MC simulations done.
83.33333333333334% of MC simulations done.
86.66666666666667% of MC simulations done.
90.0% of MC simulations done.
93.33333333333333% of MC simulations done.
96.66666666666667% of MC simulations done.
100.0% of MC simulations done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 1000, 'itbound_SGD_algorithms': 10000, 'nit_IterateAveragingStart': 9000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -1.1570,   0.4903],
        [-35.5395, -10.8950],
        [ 13.8606,  -0.0639],
        [ -2.0691,   3.8144],
        [ -2.9186,   2.5055],
        [ 12.2876,  -1.6684],
        [ 13.2848,  -4.6688],
        [  3.9986, -13.4180],
        [ 11.6718,  -7.1991],
        [  1.3208,  -0.5523]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ -3.3743,  -9.8970, -12.1618,  -4.9512,  -6.1980,  -9.1276,  -8.6709,
        -10.1044,  -9.6439,  -5.7255], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ 6.9929e-02,  8.9457e+00,  9.8304e+00,  5.2534e-01, -4.7516e-01,
          4.5926e+00,  4.2903e+00,  1.6135e+01,  3.1956e+00, -1.0825e-01],
        [ 5.8804e-03, -1.2842e-02, -1.2272e-01,  1.5499e-03,  1.8897e-02,
         -3.2232e-01, -4.7678e-01, -4.1125e-01, -1.3515e-01,  5.2762e-03],
        [ 1.7304e-01, -1.1938e+00,  9.5005e-03,  5.1615e-02, -4.2080e-03,
         -1.1227e-01, -3.9819e-01,  9.3986e+00, -1.4167e-01,  1.1094e-01],
        [-6.0483e-03,  1.0450e+01,  1.1218e+01,  5.5840e-01, -8.8916e-01,
          5.2727e+00,  5.4568e+00,  1.6213e+01,  5.6168e+00, -2.9330e-01],
        [ 5.8804e-03, -1.2842e-02, -1.2272e-01,  1.5500e-03,  1.8897e-02,
         -3.2232e-01, -4.7678e-01, -4.1125e-01, -1.3515e-01,  5.2762e-03],
        [ 5.8805e-03, -1.2842e-02, -1.2272e-01,  1.5501e-03,  1.8897e-02,
         -3.2232e-01, -4.7678e-01, -4.1125e-01, -1.3515e-01,  5.2763e-03],
        [ 5.8805e-03, -1.2842e-02, -1.2272e-01,  1.5502e-03,  1.8897e-02,
         -3.2232e-01, -4.7678e-01, -4.1125e-01, -1.3515e-01,  5.2763e-03],
        [ 4.0016e-02,  7.7392e+00,  1.3927e+01,  7.3208e-01, -2.0902e+00,
          5.3614e+00,  7.2375e+00,  1.7545e+01,  1.2011e+01,  3.2595e-01],
        [ 5.8804e-03, -1.2842e-02, -1.2272e-01,  1.5499e-03,  1.8897e-02,
         -3.2232e-01, -4.7678e-01, -4.1125e-01, -1.3515e-01,  5.2762e-03],
        [ 5.8804e-03, -1.2842e-02, -1.2272e-01,  1.5499e-03,  1.8897e-02,
         -3.2232e-01, -4.7678e-01, -4.1125e-01, -1.3515e-01,  5.2762e-03]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-11.1006,  -2.1158,  -7.6770, -11.4345,  -2.1158,  -2.1158,  -2.1158,
        -11.5893,  -2.1158,  -2.1158], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ -9.5691,   0.0189,  -3.1520, -10.5756,   0.0189,   0.0189,   0.0189,
         -12.2805,   0.0189,   0.0189]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -1.7283,   2.9731],
        [ -0.6459,   9.4208],
        [ 12.3579,   5.0153],
        [ -1.7283,   2.9731],
        [ -3.8461,  10.7883],
        [ 13.0074,  -0.8851],
        [ -1.9323,   3.2183],
        [-10.5748,  -6.6210],
        [-13.9002,  -9.1451],
        [  1.4726,  12.1123]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ -4.6604,   2.0696,   3.7739,  -4.6604,   7.5919, -12.5533,  -4.3385,
         -2.8498,  -6.0696,   9.3289], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 1.6370e-01,  1.3845e+00,  1.0770e+00,  1.6371e-01,  1.3740e+01,
          1.5619e+00,  1.8567e-01, -1.1359e+01,  1.3545e+00,  1.3711e+01],
        [ 1.4530e-01, -6.1675e-03, -3.4732e+00,  1.4529e-01, -2.1435e-01,
         -4.8941e-01,  1.2023e-01, -3.7148e-01, -4.8658e-02, -9.6010e-01],
        [ 4.7880e-02, -3.5183e-02, -3.7819e+00,  4.7880e-02, -2.9446e-01,
         -4.0072e-01,  4.8466e-02, -3.3752e-01, -5.5341e-02, -9.4198e-01],
        [ 2.3039e-01, -1.5476e-01, -3.2961e+00,  2.3039e-01, -2.8705e-01,
         -3.8505e-01,  2.1323e-01, -1.0501e+00, -2.8021e-01, -1.4193e+00],
        [-7.2794e-01, -2.3029e+00, -3.3308e+00, -7.2794e-01, -5.2230e+00,
         -2.5368e+01, -6.6463e-01,  2.7859e+00, -7.7593e-01,  4.9823e+00],
        [ 3.4334e+00, -1.8889e+00, -1.1577e+00,  3.4334e+00, -9.8787e+00,
         -1.6489e+00,  3.7981e+00, -1.2050e+01,  5.3749e+00, -3.6154e-01],
        [-5.9557e-01, -8.6827e-01, -1.3283e+01, -5.9559e-01, -4.0897e+00,
         -2.5291e+01, -6.2271e-01,  7.1083e+00,  1.0360e+01, -4.2582e+01],
        [-1.1157e-01, -2.2612e+00, -6.9193e+00, -1.1159e-01, -8.2132e+00,
         -1.4195e+01, -1.1921e-01,  6.3442e+00,  7.0728e+00, -2.0490e+01],
        [-1.3247e+00,  4.9226e+00, -8.9723e+00, -1.3247e+00,  1.2927e+00,
          1.3427e+00, -5.8272e-01,  2.8053e+00,  2.0838e+00, -5.0788e-01],
        [ 2.6932e+00,  1.3195e+00,  3.3087e-01,  2.6933e+00, -9.9668e+00,
         -7.8849e+00,  2.2818e+00, -1.7906e+00,  5.0914e+00, -3.7446e-01]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-0.7271, -4.3374, -3.8793, -5.2128, -2.8286, -2.9330, -4.6101,  1.5972,
        -1.4842, -3.9782], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ 4.9991e-01,  2.3916e-02,  3.0650e-02, -2.7768e-01,  2.3297e+00,
         -6.1817e+00,  1.9032e+01, -9.6529e+00,  3.0818e+00, -5.2202e+00],
        [-4.4815e-01, -4.7343e-03, -2.5640e-02,  2.9726e-01, -2.3916e+00,
          5.8370e+00, -1.9229e+01,  9.4217e+00, -3.0864e+00,  5.2689e+00]],
       device='cuda:0'))])
loaded xi:  188.92459
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1576.8182150775267
W_T_median: 1136.7449346433505
W_T_pctile_5: -127.64084552288806
W_T_CVAR_5_pct: -295.72244238283764
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -2700.972505266155
Current xi:  [193.41653]
objective value function right now is: -2700.972505266155
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -2795.315462531412
Current xi:  [197.2246]
objective value function right now is: -2795.315462531412
6.0% of gradient descent iterations done. Method = Adam
Current xi:  [199.73088]
objective value function right now is: -2706.0962357113667
8.0% of gradient descent iterations done. Method = Adam
Current xi:  [201.88513]
objective value function right now is: -2705.60169487361
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -2820.731944774772
Current xi:  [204.2347]
objective value function right now is: -2820.731944774772
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [204.17987]
objective value function right now is: -2794.247305498029
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [205.31296]
objective value function right now is: -2791.480278525058
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [206.92128]
objective value function right now is: -2765.404607760973
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [207.42001]
objective value function right now is: -2774.633941001817
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [207.70798]
objective value function right now is: -2783.246974234833
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [208.66733]
objective value function right now is: -2735.567805724582
24.0% of gradient descent iterations done. Method = Adam
new min fval:  -2821.9034312491885
Current xi:  [209.6217]
objective value function right now is: -2821.9034312491885
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [210.0085]
objective value function right now is: -2734.585932395099
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [210.22104]
objective value function right now is: -2581.9977613277283
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [210.17892]
objective value function right now is: -2437.993822459136
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [210.87582]
objective value function right now is: -2736.410184507663
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [210.40472]
objective value function right now is: -2791.0933179877243
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [211.44543]
objective value function right now is: -2698.2463224429507
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [211.38571]
objective value function right now is: -2712.9700299686447
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [210.05586]
objective value function right now is: -2737.5869070680355
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [208.93896]
objective value function right now is: -2693.3969296605205
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [209.53497]
objective value function right now is: -2667.761549008313
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [208.628]
objective value function right now is: -2748.9634512640873
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [209.10117]
objective value function right now is: -2726.1012724306415
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [209.21321]
objective value function right now is: -2784.9400742913967
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [210.17448]
objective value function right now is: -2801.2068324063935
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [209.40715]
objective value function right now is: -2661.6143954604977
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [209.68388]
objective value function right now is: -2739.5137742336933
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [208.5546]
objective value function right now is: -2753.55628616272
60.0% of gradient descent iterations done. Method = Adam
new min fval:  -2826.2096765580286
Current xi:  [209.21426]
objective value function right now is: -2826.2096765580286
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [209.05226]
objective value function right now is: -2807.565568312904
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [209.00256]
objective value function right now is: -2766.850649315616
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [210.46828]
objective value function right now is: -2779.0428641281733
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [210.4928]
objective value function right now is: -2761.0954301425922
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [210.82883]
objective value function right now is: -2710.9944140012626
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -2877.2339252052525
Current xi:  [210.9729]
objective value function right now is: -2877.2339252052525
74.0% of gradient descent iterations done. Method = Adam
Current xi:  [210.75604]
objective value function right now is: -2852.0650413567873
76.0% of gradient descent iterations done. Method = Adam
new min fval:  -2880.127815643899
Current xi:  [210.52702]
objective value function right now is: -2880.127815643899
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [210.70764]
objective value function right now is: -2868.3342727812887
80.0% of gradient descent iterations done. Method = Adam
new min fval:  -2884.012473273866
Current xi:  [210.8577]
objective value function right now is: -2884.012473273866
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [211.08134]
objective value function right now is: -2857.1118015902625
84.0% of gradient descent iterations done. Method = Adam
new min fval:  -2884.1886388006087
Current xi:  [211.18599]
objective value function right now is: -2884.1886388006087
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [211.25134]
objective value function right now is: -2873.6717126848957
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [211.71799]
objective value function right now is: -2863.642236931422
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [211.775]
objective value function right now is: -2840.689813485073
new min fval from sgd:  -2885.1707332901947
new min fval from sgd:  -2885.9284829037056
new min fval from sgd:  -2886.242835107216
new min fval from sgd:  -2887.445496930075
new min fval from sgd:  -2888.183632064257
new min fval from sgd:  -2888.734960746533
new min fval from sgd:  -2889.1315240174067
new min fval from sgd:  -2889.235897242591
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [211.85971]
objective value function right now is: -2881.048854584624
new min fval from sgd:  -2889.834319024736
new min fval from sgd:  -2890.446480906676
new min fval from sgd:  -2891.3007079754757
new min fval from sgd:  -2892.2605899856017
new min fval from sgd:  -2892.3680851036916
new min fval from sgd:  -2892.444442418225
new min fval from sgd:  -2893.6502656365637
new min fval from sgd:  -2894.0116914839195
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [212.1825]
objective value function right now is: -2891.1857821428043
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [212.32834]
objective value function right now is: -2857.5914958206017
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [212.62036]
objective value function right now is: -2887.5266041514624
new min fval from sgd:  -2894.026413520776
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [212.672]
objective value function right now is: -2879.563209375445
min fval:  -2894.026413520776
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -1.4150,   0.5741],
        [-29.5602, -11.3704],
        [ 15.7829,  -0.6919],
        [ -2.0822,   0.8033],
        [ -2.7483,   3.4726],
        [ 14.0232,  -1.6567],
        [ 14.9405,  -5.2523],
        [  5.4073, -14.3235],
        [ 14.5013,  -7.9508],
        [ -1.2143,   0.4700]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ -4.5971, -10.3022, -12.3923,  -4.3914,  -4.9935,  -9.6690,  -8.9188,
        -10.2622,  -8.9948,  -4.6607], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-3.1255e-02,  6.5421e+00,  1.0140e+01,  3.0395e-01,  1.0682e+00,
          4.7094e+00,  7.1195e+00,  1.5184e+01,  7.4073e+00,  1.7196e-01],
        [-2.2120e-03,  5.2983e-02,  5.2608e-01,  2.0121e-03,  6.5259e-02,
          9.1089e-01,  1.0806e+00,  1.2564e+00,  9.9197e-01, -5.2505e-03],
        [-8.0515e-03, -9.6139e-02, -2.0594e-01, -6.1832e-03, -1.3868e-01,
         -2.4642e-01, -3.9810e-01, -5.6193e-01, -4.3390e-01, -8.9494e-03],
        [ 6.1157e-02,  9.1347e+00,  1.3265e+01, -1.8055e-01,  7.1812e-01,
          6.2838e+00,  7.8830e+00,  1.6766e+01,  1.0019e+01, -8.4394e-02],
        [-2.2117e-03,  5.2983e-02,  5.2608e-01,  2.0123e-03,  6.5260e-02,
          9.1089e-01,  1.0806e+00,  1.2564e+00,  9.9197e-01, -5.2502e-03],
        [-2.2117e-03,  5.2983e-02,  5.2608e-01,  2.0122e-03,  6.5259e-02,
          9.1089e-01,  1.0806e+00,  1.2564e+00,  9.9197e-01, -5.2502e-03],
        [-2.2118e-03,  5.2983e-02,  5.2609e-01,  2.0123e-03,  6.5257e-02,
          9.1090e-01,  1.0806e+00,  1.2564e+00,  9.9197e-01, -5.2502e-03],
        [-1.5801e-02,  7.5320e+00,  1.6262e+01,  1.1903e-01, -3.6129e-01,
          6.1448e+00,  7.5406e+00,  1.8369e+01,  1.3002e+01,  6.3427e-02],
        [-2.2112e-03,  5.2983e-02,  5.2609e-01,  2.0128e-03,  6.5256e-02,
          9.1090e-01,  1.0806e+00,  1.2564e+00,  9.9197e-01, -5.2497e-03],
        [-2.2114e-03,  5.2984e-02,  5.2609e-01,  2.0126e-03,  6.5258e-02,
          9.1089e-01,  1.0806e+00,  1.2564e+00,  9.9196e-01, -5.2499e-03]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-11.3051,   4.4872,  -3.1332, -10.5010,   4.4872,   4.4872,   4.4872,
        -11.4592,   4.4872,   4.4872], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-8.2239e+00,  2.3625e+00, -1.8614e-03, -1.2370e+01,  2.3625e+00,
          2.3625e+00,  2.3625e+00, -1.6265e+01,  2.3625e+00,  2.3625e+00]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -4.1626,   2.4801],
        [ -7.3968,   4.3643],
        [ 12.4223,   5.4346],
        [ -4.1621,   2.4810],
        [ -4.7881,  12.0515],
        [ 12.7702,  -1.7457],
        [ -4.0181,   0.8348],
        [-11.2557,  -6.7814],
        [-14.0876,  -9.7740],
        [  3.0480,  12.7277]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ -6.6342,  -3.6369,   2.6148,  -6.6337,   9.2243, -14.1611,  -6.8626,
         -3.0540,  -6.8063,   9.5740], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 3.7068e-01,  4.7009e+00,  7.2238e-01,  3.7084e-01,  1.8479e+01,
          2.9207e+00,  4.5123e-01, -1.2620e+01,  6.8259e-01,  9.4821e+00],
        [-3.4442e-02, -5.2459e-02, -4.5138e+00, -3.4567e-02, -1.9504e-01,
         -7.2611e-01,  8.5113e-04, -1.0136e+00, -2.8928e-01, -1.1693e+00],
        [-3.5125e-02, -5.3396e-02, -4.5133e+00, -3.5253e-02, -1.9456e-01,
         -7.2638e-01,  8.4622e-04, -1.0139e+00, -2.8747e-01, -1.1687e+00],
        [-4.1154e-02, -6.1524e-02, -4.4755e+00, -4.1299e-02, -1.8740e-01,
         -7.2695e-01,  8.9960e-04, -1.0055e+00, -2.6325e-01, -1.1598e+00],
        [-3.6780e+00, -2.9545e+00, -4.1462e+00, -3.6814e+00,  1.6196e-01,
         -2.4922e+01,  4.6356e-02,  2.5672e+00, -3.4190e+00,  5.3447e+00],
        [ 5.2720e-01, -2.1613e+00, -1.7026e+00,  5.2731e-01, -1.6221e+01,
          3.3704e-02,  6.9629e-01, -1.0910e+01,  8.1509e+00,  3.4536e-01],
        [ 2.4792e-01,  1.8877e+00, -1.4943e+01,  2.4766e-01,  4.7868e+00,
         -3.3859e+01,  9.3403e-01,  5.2908e+00,  1.0104e+01, -4.5961e+01],
        [-3.7581e-01, -4.8547e+00, -6.5565e+00, -3.7652e-01, -6.9736e+00,
         -1.5844e+01, -5.0894e-02,  5.5719e+00,  6.5312e+00, -2.2466e+01],
        [-2.8920e+00,  4.2006e+00, -9.6616e+00, -2.8952e+00,  1.1385e+00,
         -1.4947e+00, -1.0419e-01,  8.9299e-01, -1.6601e-01, -5.7488e-01],
        [ 1.0430e+00, -2.8495e-01,  4.8091e-02,  1.0432e+00, -1.7984e+01,
         -7.1989e+00,  8.8203e-01, -3.5665e-01,  4.7198e+00,  1.0100e+00]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-0.9708, -5.7913, -5.7929, -5.8429, -4.0608, -3.4563, -7.2243,  1.9226,
        -2.5853, -4.2117], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[  0.5111,   0.0786,   0.0773,   0.0798,   2.7635,  -6.4443,  21.2812,
         -10.4634,   2.7552,  -5.6824],
        [ -0.4593,  -0.0746,  -0.0762,  -0.0758,  -2.8253,   6.1007, -21.4725,
          10.2326,  -2.7595,   5.7311]], device='cuda:0'))])
xi:  [212.62447]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 689.3548449840847
W_T_median: 480.65583705403424
W_T_pctile_5: 212.85060679199987
W_T_CVAR_5_pct: 29.545394968721574
Average q (qsum/M+1):  45.70239651587702
Optimal xi:  [212.62447]
Observed VAR:  269.7530290226099
Expected(across Rb) median(across samples) p_equity:  0.2064779272923867
obj fun:  tensor(-2894.0264, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
[0.0, 100.0, 200.0, 300.0, 400.0, 500.0, 600.0, 700.0, 800.0, 900.0, 1000.0, 1100.0, 1200.0, 1300.0, 1400.0, 1500.0, 1600.0, 1700.0, 1800.0, 1900.0, 2000.0]
/home/marcchen/Documents/testing_pyt_decum/researchcode/fun_Plot_NN_control_FunctionHeatmaps.py:196: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  
[0.0, 100.0, 200.0, 300.0, 400.0, 500.0, 600.0, 700.0, 800.0, 900.0, 1000.0, 1100.0, 1200.0, 1300.0, 1400.0, 1500.0, 1600.0, 1700.0, 1800.0, 1900.0, 2000.0]
[0.0, 100.0, 200.0, 300.0, 400.0, 500.0, 600.0, 700.0, 800.0, 900.0, 1000.0, 1100.0, 1200.0, 1300.0, 1400.0, 1500.0, 1600.0, 1700.0, 1800.0, 1900.0, 2000.0]
/home/marcchen/Documents/testing_pyt_decum/researchcode/fun_Plot_NN_control_DataHeatmaps.py:158: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 50.0
-----------------------------------------------
