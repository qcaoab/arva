Starting at: 
05-02-23_19:30

 Random seed:  2  

Key parameters-------
paths: 256000
iterations: 50000
batchsize: 1000
remove neg:  False


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
3.3333333333333335% of MC simulations done.
6.666666666666667% of MC simulations done.
10.0% of MC simulations done.
13.333333333333334% of MC simulations done.
16.666666666666664% of MC simulations done.
20.0% of MC simulations done.
23.333333333333332% of MC simulations done.
26.666666666666668% of MC simulations done.
30.0% of MC simulations done.
33.33333333333333% of MC simulations done.
36.666666666666664% of MC simulations done.
40.0% of MC simulations done.
43.333333333333336% of MC simulations done.
46.666666666666664% of MC simulations done.
50.0% of MC simulations done.
53.333333333333336% of MC simulations done.
56.666666666666664% of MC simulations done.
60.0% of MC simulations done.
63.33333333333333% of MC simulations done.
66.66666666666666% of MC simulations done.
70.0% of MC simulations done.
73.33333333333333% of MC simulations done.
76.66666666666667% of MC simulations done.
80.0% of MC simulations done.
83.33333333333334% of MC simulations done.
86.66666666666667% of MC simulations done.
90.0% of MC simulations done.
93.33333333333333% of MC simulations done.
96.66666666666667% of MC simulations done.
100.0% of MC simulations done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 5000, 'itbound_SGD_algorithms': 50000, 'nit_IterateAveragingStart': 45000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1576.8182150775267
W_T_median: 1136.7449346433505
W_T_pctile_5: -127.64084552288806
W_T_CVAR_5_pct: -295.72244238283764
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1521.5329899954904
Current xi:  [91.55379]
objective value function right now is: -1521.5329899954904
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1536.1355475939317
Current xi:  [79.12958]
objective value function right now is: -1536.1355475939317
6.0% of gradient descent iterations done. Method = Adam
Current xi:  [69.220215]
objective value function right now is: -1525.5387467922508
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -1555.252123248963
Current xi:  [64.810875]
objective value function right now is: -1555.252123248963
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1560.8809124276954
Current xi:  [62.75894]
objective value function right now is: -1560.8809124276954
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [60.59326]
objective value function right now is: -1557.0025486858674
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [59.50283]
objective value function right now is: -1555.0211490113622
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [58.550133]
objective value function right now is: -1555.8232659684393
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [58.667225]
objective value function right now is: -1558.5676995923568
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [57.805763]
objective value function right now is: -1548.1449108715165
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [57.563164]
objective value function right now is: -1558.7285675603073
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [57.510952]
objective value function right now is: -1559.5575901448747
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [57.338795]
objective value function right now is: -1555.370466156513
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [57.32026]
objective value function right now is: -1559.5769929808218
30.0% of gradient descent iterations done. Method = Adam
new min fval:  -1562.2839561750181
Current xi:  [57.173786]
objective value function right now is: -1562.2839561750181
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [57.358524]
objective value function right now is: -1559.990152095982
34.0% of gradient descent iterations done. Method = Adam
new min fval:  -1562.6241068920908
Current xi:  [57.732185]
objective value function right now is: -1562.6241068920908
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [57.385418]
objective value function right now is: -1560.1760808028032
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [57.50592]
objective value function right now is: -1557.5926106023194
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [57.96759]
objective value function right now is: -1560.15412741108
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [54.399433]
objective value function right now is: -1562.2862450605714
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [54.612835]
objective value function right now is: -1558.4262895949776
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [54.735577]
objective value function right now is: -1559.5408236558276
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [54.889313]
objective value function right now is: -1561.4835270920591
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [54.517292]
objective value function right now is: -1562.1408453494641
52.0% of gradient descent iterations done. Method = Adam
new min fval:  -1562.8774525827034
Current xi:  [54.164467]
objective value function right now is: -1562.8774525827034
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [54.270557]
objective value function right now is: -1558.546019697419
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [54.627224]
objective value function right now is: -1558.1072293840125
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [54.847023]
objective value function right now is: -1556.904613631162
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [54.357197]
objective value function right now is: -1561.9851491294644
62.0% of gradient descent iterations done. Method = Adam
new min fval:  -1563.010066089742
Current xi:  [54.522526]
objective value function right now is: -1563.010066089742
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [54.68783]
objective value function right now is: -1558.4372353717072
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [54.620922]
objective value function right now is: -1556.642929066165
68.0% of gradient descent iterations done. Method = Adam
new min fval:  -1563.9475410749624
Current xi:  [54.542866]
objective value function right now is: -1563.9475410749624
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [54.890648]
objective value function right now is: -1557.58686648521
72.0% of gradient descent iterations done. Method = Adam
Current xi:  [55.136272]
objective value function right now is: -1562.690759654175
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -1564.8814072824441
Current xi:  [55.172436]
objective value function right now is: -1564.8814072824441
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [55.431057]
objective value function right now is: -1564.1656343626541
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [55.67131]
objective value function right now is: -1564.1585412329628
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [55.65816]
objective value function right now is: -1564.229998448326
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [55.834213]
objective value function right now is: -1564.2374019866788
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [56.074795]
objective value function right now is: -1564.7618721752958
86.0% of gradient descent iterations done. Method = Adam
new min fval:  -1565.1103186595794
Current xi:  [56.199707]
objective value function right now is: -1565.1103186595794
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [56.324986]
objective value function right now is: -1564.9799368752763
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [56.68481]
objective value function right now is: -1563.7763851580075
new min fval from sgd:  -1565.1652539816719
new min fval from sgd:  -1565.183841806378
new min fval from sgd:  -1565.275112898088
new min fval from sgd:  -1565.289057203168
new min fval from sgd:  -1565.4151174672616
new min fval from sgd:  -1565.4265908566183
new min fval from sgd:  -1565.4780188446514
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [57.04856]
objective value function right now is: -1565.11329817552
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [57.31869]
objective value function right now is: -1563.1972979452014
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [57.237976]
objective value function right now is: -1564.771607808224
new min fval from sgd:  -1565.479894825466
new min fval from sgd:  -1565.4918680602714
new min fval from sgd:  -1565.507452014342
new min fval from sgd:  -1565.5240656957985
new min fval from sgd:  -1565.5334822538455
new min fval from sgd:  -1565.541976885216
new min fval from sgd:  -1565.5464768830748
new min fval from sgd:  -1565.5515956573347
new min fval from sgd:  -1565.5619258147237
new min fval from sgd:  -1565.5679556289788
new min fval from sgd:  -1565.57013525827
new min fval from sgd:  -1565.5819401656008
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [57.45721]
objective value function right now is: -1565.4639154418974
new min fval from sgd:  -1565.5824789580456
new min fval from sgd:  -1565.5941062899317
new min fval from sgd:  -1565.5987285753504
new min fval from sgd:  -1565.6008577194805
new min fval from sgd:  -1565.6040019488412
new min fval from sgd:  -1565.6145674791649
new min fval from sgd:  -1565.6176308403465
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [57.509438]
objective value function right now is: -1564.9407804685407
min fval:  -1565.6176308403465
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-47.4447,  -6.7963],
        [ 11.6553,  -1.7711],
        [  8.9327,  -1.6659],
        [ -0.9933,   0.8400],
        [ -1.8762, -10.0830],
        [  5.0902,  -8.4751],
        [  7.7209,  -7.1926],
        [ -1.1324, -10.0826],
        [ -9.4942,  -2.5061],
        [ 11.0163,  -4.2163]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ -6.9813, -10.1216, -10.2292,  -2.6924,  -8.5428,  -8.1999,  -8.6702,
         -8.5622,   9.3779,  -9.2598], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ 7.5691e+00,  8.5968e+00,  2.8998e+00,  7.1396e-02,  1.0057e+01,
          5.2091e+00,  4.0237e+00,  9.5684e+00, -8.6867e+00,  4.6573e+00],
        [ 7.4742e-02, -5.7876e-01, -1.4559e-01, -3.9827e-02,  6.4857e-04,
          7.3016e-02, -3.1890e-01,  1.9771e-02, -8.5023e-01, -6.7774e-01],
        [ 7.4741e-02, -5.7876e-01, -1.4559e-01, -3.9827e-02,  6.4488e-04,
          7.3015e-02, -3.1890e-01,  1.9767e-02, -8.5024e-01, -6.7774e-01],
        [ 6.7288e+00,  6.1037e+00,  1.3927e+00,  1.2748e-01,  9.4582e+00,
          4.9365e+00,  3.7975e+00,  9.4048e+00, -8.7992e+00,  5.0027e+00],
        [ 1.0813e-01, -4.7319e-01, -1.3699e-01, -5.4732e-02,  4.6252e-01,
          2.4174e-01, -1.1166e-01,  4.8968e-01, -2.1131e+00, -4.9058e-01],
        [ 5.9371e+00,  3.8835e+00,  3.0861e-01,  1.9890e-01,  8.6867e+00,
          4.9703e+00,  3.1970e+00,  8.9229e+00, -8.3584e+00,  4.1482e+00],
        [ 7.4741e-02, -5.7876e-01, -1.4559e-01, -3.9827e-02,  6.4454e-04,
          7.3015e-02, -3.1890e-01,  1.9767e-02, -8.5024e-01, -6.7774e-01],
        [ 7.4741e-02, -5.7876e-01, -1.4559e-01, -3.9827e-02,  6.4462e-04,
          7.3015e-02, -3.1890e-01,  1.9767e-02, -8.5024e-01, -6.7774e-01],
        [ 6.1822e+00,  8.8489e+00,  3.1534e+00, -2.2236e-01,  9.2952e+00,
          6.3331e+00,  7.0903e+00,  9.1719e+00, -8.2221e+00,  6.2364e+00],
        [ 7.4741e-02, -5.7876e-01, -1.4559e-01, -3.9827e-02,  6.4486e-04,
          7.3015e-02, -3.1890e-01,  1.9767e-02, -8.5024e-01, -6.7774e-01]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-4.9590, -1.4664, -1.4663, -4.3101, -1.7048, -4.0649, -1.4663, -1.4663,
        -4.5289, -1.4663], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-8.5536, -0.5224, -0.5224, -6.8498, -0.7642, -5.5552, -0.5224, -0.5224,
         -6.8587, -0.5224]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[-13.8634,  -0.2485],
        [ -1.0433,  -1.6330],
        [-14.9775,  -3.9798],
        [ -2.3907,   6.3082],
        [-13.4084,  -2.7944],
        [ 10.1129,   9.6926],
        [-15.5578,  -2.7075],
        [  3.6499,  14.4777],
        [-12.8611,  -2.6269],
        [  1.5653,  -0.3960]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([10.5284,  0.2568, -1.1682, -1.3597,  1.6790,  7.9389,  6.2235, 12.4083,
         0.1208,  4.5592], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-1.2566e+00, -1.6254e+00, -7.8173e-02, -8.7933e-01, -7.7975e-01,
         -6.7236e-01, -9.9678e-01, -4.9786e-01, -2.7278e-01, -2.0229e+00],
        [-9.5399e-01, -1.4489e+00, -1.2565e-01, -1.0355e+00, -1.1986e+00,
         -5.5476e-01, -1.0285e+00, -7.5128e-01, -4.1832e-01, -1.9478e+00],
        [-1.2763e+01, -6.7505e-01, -4.5810e+00,  3.4882e-02, -8.0486e+00,
          1.4607e+01, -4.9759e+00,  3.9651e+01, -5.3413e+00,  5.1579e+00],
        [ 5.4094e+00,  1.9956e+00, -2.2605e+00,  2.9221e+00, -1.4382e+00,
          3.2138e+00, -4.0209e+00,  7.7628e-01, -1.8604e+00,  1.1853e+00],
        [-1.0154e+00, -1.5750e+00, -8.8259e-02, -9.1483e-01, -8.7841e-01,
         -6.8500e-01, -9.4937e-01, -8.2382e-01, -2.9997e-01, -2.0002e+00],
        [-7.3318e-01, -9.5652e-01, -4.4144e-01, -1.2058e+00, -2.7457e+00,
         -1.8170e-01, -9.0348e-01, -6.2075e-01, -1.2782e+00, -1.7054e+00],
        [-8.3128e-01, -8.1217e-01, -7.0824e-01, -1.5269e+00, -3.5134e+00,
          5.4337e-02, -1.0885e+00,  7.3759e-02, -1.9402e+00, -1.4114e+00],
        [ 6.5681e-01, -1.7645e+00,  1.1210e+00, -2.2607e-01,  6.1650e-01,
         -1.3274e+00,  1.1019e+00, -5.0177e-02,  5.6959e-01, -2.5620e+00],
        [-6.0012e+00, -1.0357e+00,  3.5556e+00,  7.7124e-02, -8.0555e+00,
          3.1355e+00, -2.7788e+00,  2.7189e+01, -1.4620e+00,  2.8558e+00],
        [ 4.0418e+00, -4.7167e-01,  7.6117e+00,  2.7229e-02,  4.6804e+00,
         -2.7426e+01,  8.8206e+00, -1.2104e+01,  4.4773e+00, -1.1062e+01]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-2.0464, -1.9715,  4.1026,  1.0366, -2.0237, -1.7232, -1.4674, -2.5644,
        -0.2195, -4.5256], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ -0.7915,  -0.9184,   3.3674,  -3.4047,  -0.7812,  -1.4304,  -1.5083,
           0.7507,   0.5503,  10.4632],
        [  0.7915,   0.9184,  -2.9648,   3.3398,   0.7812,   1.4305,   1.5084,
          -0.7506,  -0.5846, -10.4593]], device='cuda:0'))])
xi:  [57.48758]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 628.2036465778914
W_T_median: 269.7530290226099
W_T_pctile_5: 57.50407874999391
W_T_CVAR_5_pct: -44.04503549730439
Average q (qsum/M+1):  51.92463142641129
Optimal xi:  [57.48758]
Observed VAR:  269.7530290226099
Expected(across Rb) median(across samples) p_equity:  0.3350428303082784
obj fun:  tensor(-1565.6176, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
[0.0, 100.0, 200.0, 300.0, 400.0, 500.0, 600.0, 700.0, 800.0, 900.0, 1000.0, 1100.0, 1200.0, 1300.0, 1400.0, 1500.0, 1600.0, 1700.0, 1800.0, 1900.0, 2000.0]
[0.0, 100.0, 200.0, 300.0, 400.0, 500.0, 600.0, 700.0, 800.0, 900.0, 1000.0, 1100.0, 1200.0, 1300.0, 1400.0, 1500.0, 1600.0, 1700.0, 1800.0, 1900.0, 2000.0]
[0.0, 100.0, 200.0, 300.0, 400.0, 500.0, 600.0, 700.0, 800.0, 900.0, 1000.0, 1100.0, 1200.0, 1300.0, 1400.0, 1500.0, 1600.0, 1700.0, 1800.0, 1900.0, 2000.0]
/home/marcchen/Documents/testing_pyt_decum/researchcode/fun_Plot_NN_control_DataHeatmaps.py:158: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
