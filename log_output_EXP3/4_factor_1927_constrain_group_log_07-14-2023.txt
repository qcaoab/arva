/home/marcchen/Documents/constrain_factor/researchcode/exp_config_json_files/multi_portfolio_exp3_split_1927.json
Starting at: 
14-07-23_09:48

 numpy seed:  2  


 pytorch seed:  2  

Key parameters-------
paths: 256000
iterations: 30000
batchsize: 1000
remove neg:  False
w constaint activation:  yy_fix_jan29


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = 4_factor_1927
timeseries_basket['basket_desc'] = 4 factors with data since 1927: Basic, size, value, div, mom
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'B10_real_ret', 'VWD_real_ret', 'Size_Lo30_real_ret', 'Value_Hi30_real_ret', 'Div_Hi30_real_ret', 'Mom_Hi30_real_ret']
############# End: defined asset  basket #################
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
192601                  0.0                NaN  ...     0.000561     0.023174
192602                  0.0                NaN  ...    -0.033046    -0.053510
192603                  0.0                NaN  ...    -0.064002    -0.096824
192604                  0.0                NaN  ...     0.037029     0.032975
192605                  0.0                NaN  ...     0.012095     0.001035

[5 rows x 16 columns]
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
202208                  NaN            -0.0020  ...    -0.036240    -0.011556
202209                  NaN            -0.0955  ...    -0.091324    -0.099903
202210                  NaN             0.0883  ...     0.077403     0.049863
202211                  NaN            -0.0076  ...     0.052365     0.028123
202212                  NaN            -0.0457  ...    -0.057116    -0.047241

[5 rows x 16 columns]


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = 4_factor_1927
timeseries_basket['basket_desc'] = 4 factors with data since 1927: Basic, size, value, div, mom
timeseries_basket['basket_columns'] = 
['T30_nom_ret', 'B10_nom_ret', 'VWD_nom_ret', 'Size_Lo30_nom_ret', 'Value_Hi30_nom_ret', 'Div_Hi30_nom_ret', 'Mom_Hi30_nom_ret']
############# End: defined asset  basket #################
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
192607                    0.0014              0.0154  ...     0.005383     0.031411
192608                    0.0319              0.0561  ...     0.005363     0.028647
192609                   -0.0173             -0.0071  ...     0.005343     0.005787
192610                   -0.0294             -0.0355  ...     0.005323    -0.028996
192611                   -0.0038              0.0294  ...     0.005303     0.028554

[5 rows x 8 columns]
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
202208                   -0.0020             -0.0164  ...    -0.043289    -0.036240
202209                   -0.0955             -0.0871  ...    -0.050056    -0.091324
202210                    0.0883              0.1486  ...    -0.014968     0.077403
202211                   -0.0076              0.0462  ...     0.040789     0.052365
202212                   -0.0457             -0.0499  ...    -0.018566    -0.057116

[5 rows x 8 columns]
Indices constructed with column names:
Index(['date_for_plt', 'Size_Lo30_nom_ret_ind', 'Value_Hi30_nom_ret_ind',
       'Mom_Hi30_nom_ret_ind', 'Div_Hi30_nom_ret_ind', 'CPI_nom_ret_ind',
       'T30_nom_ret_ind', 'B10_nom_ret_ind', 'VWD_nom_ret_ind'],
      dtype='object')
############# Updated: defined asset basket #################
timeseries_basket['data_df_mean'] = 
T30_real_ret           0.000229
B10_real_ret           0.001637
VWD_real_ret           0.006759
Size_Lo30_real_ret     0.009939
Value_Hi30_real_ret    0.010052
Div_Hi30_real_ret      0.007888
Mom_Hi30_real_ret      0.011386
dtype: float64


timeseries_basket['data_df_stdev'] = 
T30_real_ret           0.005227
B10_real_ret           0.019258
VWD_real_ret           0.053610
Size_Lo30_real_ret     0.082598
Value_Hi30_real_ret    0.072063
Div_Hi30_real_ret      0.056728
Mom_Hi30_real_ret      0.061421
dtype: float64


timeseries_basket['data_df_corr'] = 
                     T30_real_ret  ...  Mom_Hi30_real_ret
T30_real_ret             1.000000  ...           0.055142
B10_real_ret             0.351722  ...           0.066570
VWD_real_ret             0.068448  ...           0.936115
Size_Lo30_real_ret       0.014412  ...           0.903222
Value_Hi30_real_ret      0.018239  ...           0.869469
Div_Hi30_real_ret        0.059813  ...           0.804028
Mom_Hi30_real_ret        0.055142  ...           1.000000

[7 rows x 7 columns]


timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names', 'data_df', 'data_df_mean', 'data_df_stdev', 'data_df_corr'])
############# End: updated: defined asset basket #################
-----------------------------------------------
Dates to be REMOVED due to missing values (should be at *start* only due to trading signals):
Int64Index([], dtype='int64')
-----------------------------------------------
Dates from available data for bootstrapping:
Start: 192607
End: 202212
-----------------------------------------------
Bootstrap block size: 6
-----------------------------------------------
Dates USED bootstrapping:
Start: 192707
End: 199112
-----------------------------------------------
0.0% of bootstrap sample done.
5.0% of bootstrap sample done.
10.0% of bootstrap sample done.
15.0% of bootstrap sample done.
20.0% of bootstrap sample done.
25.0% of bootstrap sample done.
30.0% of bootstrap sample done.
35.0% of bootstrap sample done.
40.0% of bootstrap sample done.
45.0% of bootstrap sample done.
50.0% of bootstrap sample done.
55.00000000000001% of bootstrap sample done.
60.0% of bootstrap sample done.
65.0% of bootstrap sample done.
70.0% of bootstrap sample done.
75.0% of bootstrap sample done.
80.0% of bootstrap sample done.
85.0% of bootstrap sample done.
90.0% of bootstrap sample done.
95.0% of bootstrap sample done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      15  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      15  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 15)     True          15  
2     (15, 15)     True          15  
3      (15, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       8       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      15  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      15  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       8              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 15)     True          15  
2     (15, 15)     True          15  
3      (15, 8)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        8              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 8)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 1500, 'itbound_SGD_algorithms': 30000, 'nit_IterateAveragingStart': 27000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        8              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 8)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0, 0.5, 0.1, 0.1, 0.1, 0.1, 0.1]
W_T_mean: 1035.0895544199634
W_T_median: 669.2147774295086
W_T_pctile_5: -315.4100835464404
W_T_CVAR_5_pct: -448.30591220261425
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1736.8364863364252
Current xi:  [119.354164]
objective value function right now is: -1736.8364863364252
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1750.2769066336766
Current xi:  [140.50868]
objective value function right now is: -1750.2769066336766
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1761.937457155244
Current xi:  [162.10742]
objective value function right now is: -1761.937457155244
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -1773.346073719163
Current xi:  [183.6565]
objective value function right now is: -1773.346073719163
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1793.1301398299954
Current xi:  [206.04013]
objective value function right now is: -1793.1301398299954
12.0% of gradient descent iterations done. Method = Adam
new min fval:  -1802.3113524213593
Current xi:  [227.41139]
objective value function right now is: -1802.3113524213593
14.000000000000002% of gradient descent iterations done. Method = Adam
new min fval:  -1806.6703022281583
Current xi:  [249.43651]
objective value function right now is: -1806.6703022281583
16.0% of gradient descent iterations done. Method = Adam
new min fval:  -1817.6892502702945
Current xi:  [270.3617]
objective value function right now is: -1817.6892502702945
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -1823.4533430740387
Current xi:  [290.67526]
objective value function right now is: -1823.4533430740387
20.0% of gradient descent iterations done. Method = Adam
new min fval:  -1829.6739011039035
Current xi:  [310.00912]
objective value function right now is: -1829.6739011039035
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -1834.7705827756572
Current xi:  [329.23248]
objective value function right now is: -1834.7705827756572
24.0% of gradient descent iterations done. Method = Adam
new min fval:  -1840.239830959308
Current xi:  [348.03467]
objective value function right now is: -1840.239830959308
26.0% of gradient descent iterations done. Method = Adam
new min fval:  -1844.0149631828513
Current xi:  [366.2669]
objective value function right now is: -1844.0149631828513
28.000000000000004% of gradient descent iterations done. Method = Adam
new min fval:  -1845.868115493712
Current xi:  [383.87268]
objective value function right now is: -1845.868115493712
30.0% of gradient descent iterations done. Method = Adam
new min fval:  -1851.0629614306588
Current xi:  [401.26447]
objective value function right now is: -1851.0629614306588
32.0% of gradient descent iterations done. Method = Adam
new min fval:  -1854.2848351564878
Current xi:  [416.9485]
objective value function right now is: -1854.2848351564878
34.0% of gradient descent iterations done. Method = Adam
new min fval:  -1857.111821907226
Current xi:  [431.84366]
objective value function right now is: -1857.111821907226
36.0% of gradient descent iterations done. Method = Adam
new min fval:  -1859.9110732302452
Current xi:  [446.23923]
objective value function right now is: -1859.9110732302452
38.0% of gradient descent iterations done. Method = Adam
new min fval:  -1860.1575168249742
Current xi:  [459.52783]
objective value function right now is: -1860.1575168249742
40.0% of gradient descent iterations done. Method = Adam
new min fval:  -1862.524154635459
Current xi:  [472.83603]
objective value function right now is: -1862.524154635459
42.0% of gradient descent iterations done. Method = Adam
new min fval:  -1863.1482892188992
Current xi:  [483.2327]
objective value function right now is: -1863.1482892188992
44.0% of gradient descent iterations done. Method = Adam
new min fval:  -1863.7912510226772
Current xi:  [492.80414]
objective value function right now is: -1863.7912510226772
46.0% of gradient descent iterations done. Method = Adam
new min fval:  -1864.6900083013984
Current xi:  [502.3456]
objective value function right now is: -1864.6900083013984
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [509.88773]
objective value function right now is: -1864.1553445606678
50.0% of gradient descent iterations done. Method = Adam
new min fval:  -1865.6866712408912
Current xi:  [517.5811]
objective value function right now is: -1865.6866712408912
52.0% of gradient descent iterations done. Method = Adam
new min fval:  -1866.837395780307
Current xi:  [522.43286]
objective value function right now is: -1866.837395780307
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [527.6182]
objective value function right now is: -1863.8836979075968
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [530.2912]
objective value function right now is: -1865.3482552485434
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [534.0414]
objective value function right now is: -1865.1064872218908
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [536.9853]
objective value function right now is: -1864.5232648243648
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [540.82965]
objective value function right now is: -1865.2796049556089
64.0% of gradient descent iterations done. Method = Adam
new min fval:  -1867.2512408811856
Current xi:  [541.95917]
objective value function right now is: -1867.2512408811856
66.0% of gradient descent iterations done. Method = Adam
new min fval:  -1867.3574006579881
Current xi:  [542.9072]
objective value function right now is: -1867.3574006579881
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [544.2566]
objective value function right now is: -1865.9737709904728
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [544.5009]
objective value function right now is: -1863.8228481185624
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -1868.1496435347624
Current xi:  [544.55457]
objective value function right now is: -1868.1496435347624
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -1868.2167071801546
Current xi:  [544.79834]
objective value function right now is: -1868.2167071801546
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [544.99994]
objective value function right now is: -1867.5169617247018
78.0% of gradient descent iterations done. Method = Adam
new min fval:  -1868.5910741155376
Current xi:  [545.1793]
objective value function right now is: -1868.5910741155376
80.0% of gradient descent iterations done. Method = Adam
new min fval:  -1868.689472223711
Current xi:  [545.31915]
objective value function right now is: -1868.689472223711
82.0% of gradient descent iterations done. Method = Adam
new min fval:  -1868.6953681274401
Current xi:  [545.4487]
objective value function right now is: -1868.6953681274401
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [545.3612]
objective value function right now is: -1868.4637928247482
86.0% of gradient descent iterations done. Method = Adam
new min fval:  -1868.7254097742825
Current xi:  [545.37976]
objective value function right now is: -1868.7254097742825
88.0% of gradient descent iterations done. Method = Adam
new min fval:  -1868.84471068108
Current xi:  [545.3865]
objective value function right now is: -1868.84471068108
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [545.4827]
objective value function right now is: -1868.4381960941344
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [545.32196]
objective value function right now is: -1868.163822638704
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [544.99756]
objective value function right now is: -1868.6354607670862
new min fval from sgd:  -1868.8519043513081
new min fval from sgd:  -1868.8772359098057
new min fval from sgd:  -1868.880712045569
new min fval from sgd:  -1868.8819893306015
new min fval from sgd:  -1868.8904726017067
new min fval from sgd:  -1868.8935389436929
new min fval from sgd:  -1868.900772240299
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [545.10406]
objective value function right now is: -1868.4711943282382
new min fval from sgd:  -1868.9036934237263
new min fval from sgd:  -1868.9201068722816
new min fval from sgd:  -1868.936503992255
new min fval from sgd:  -1868.954664840813
new min fval from sgd:  -1868.9613655642722
new min fval from sgd:  -1868.9616417475627
new min fval from sgd:  -1868.9642960135047
new min fval from sgd:  -1868.9702423995495
new min fval from sgd:  -1868.9783615367962
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [545.06726]
objective value function right now is: -1868.857303539344
new min fval from sgd:  -1868.9783767698743
new min fval from sgd:  -1868.9832301044185
new min fval from sgd:  -1868.9904790676562
new min fval from sgd:  -1868.9964806374555
new min fval from sgd:  -1869.001236749861
new min fval from sgd:  -1869.0034076766474
new min fval from sgd:  -1869.0050256717266
new min fval from sgd:  -1869.0062078102867
new min fval from sgd:  -1869.0063137723487
new min fval from sgd:  -1869.0075409672886
new min fval from sgd:  -1869.0089292504467
new min fval from sgd:  -1869.0101373042255
new min fval from sgd:  -1869.010785015479
new min fval from sgd:  -1869.01223555114
new min fval from sgd:  -1869.0133585466388
new min fval from sgd:  -1869.0154400180452
new min fval from sgd:  -1869.0232758430172
new min fval from sgd:  -1869.0336827428841
new min fval from sgd:  -1869.0419500912772
new min fval from sgd:  -1869.048304514595
new min fval from sgd:  -1869.0544573838263
new min fval from sgd:  -1869.059459564223
new min fval from sgd:  -1869.0608386760764
new min fval from sgd:  -1869.0652940757057
new min fval from sgd:  -1869.0688103266673
new min fval from sgd:  -1869.0718054473668
new min fval from sgd:  -1869.0737970902642
new min fval from sgd:  -1869.0748395753392
new min fval from sgd:  -1869.0756292012652
new min fval from sgd:  -1869.0761824155052
new min fval from sgd:  -1869.0811772863308
new min fval from sgd:  -1869.0824265598803
new min fval from sgd:  -1869.0834933460803
new min fval from sgd:  -1869.0877428991723
new min fval from sgd:  -1869.0991500971265
new min fval from sgd:  -1869.105803688183
new min fval from sgd:  -1869.1102963068429
new min fval from sgd:  -1869.1114820077876
new min fval from sgd:  -1869.1140867694608
new min fval from sgd:  -1869.1154799019778
new min fval from sgd:  -1869.1171968908002
new min fval from sgd:  -1869.118723531793
new min fval from sgd:  -1869.1192137590847
new min fval from sgd:  -1869.1212401916869
new min fval from sgd:  -1869.1226956008657
new min fval from sgd:  -1869.1244890561322
new min fval from sgd:  -1869.124944926158
new min fval from sgd:  -1869.1250439592839
new min fval from sgd:  -1869.1277959454642
new min fval from sgd:  -1869.1304295263706
new min fval from sgd:  -1869.1329303328846
new min fval from sgd:  -1869.1353473221832
new min fval from sgd:  -1869.1365055980102
new min fval from sgd:  -1869.138525889503
new min fval from sgd:  -1869.1402183062098
new min fval from sgd:  -1869.1413209579314
new min fval from sgd:  -1869.1416395231035
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [545.03455]
objective value function right now is: -1869.075648843504
min fval:  -1869.1416395231035
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ 11.8174,  -6.7098],
        [ -5.1129, -13.0814],
        [  7.2633,  -7.1923],
        [  9.8594,  -0.3701],
        [-14.1404,   8.4222],
        [ -1.1802,   0.1684],
        [ -0.9324,  -0.5613],
        [-10.2137,   0.5495],
        [  7.7243,  -8.5189],
        [ -1.1779,   0.1689],
        [  6.6147,  -4.4684],
        [ -5.2374, -13.7104],
        [-17.5086, -14.4581],
        [ -1.1956,   0.1706],
        [ -1.1791,   0.1687]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-2.6974, -4.1500, -7.2173, -8.8212,  3.3628, -2.6369, -3.6992,  8.6423,
        -6.9677, -2.6368, -8.1718, -4.2913,  4.1858, -2.6426, -2.6369],
       device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-9.1467e-01, -5.8553e-02, -1.7644e-01, -2.6885e-01, -7.3666e-02,
         -1.7447e-02, -7.1751e-03, -5.8981e-01, -2.6719e-01, -1.7445e-02,
         -1.7881e-02, -6.0097e-02, -2.0231e-01, -1.7298e-02, -1.7445e-02],
        [-9.1467e-01, -5.8553e-02, -1.7644e-01, -2.6885e-01, -7.3666e-02,
         -1.7447e-02, -7.1751e-03, -5.8981e-01, -2.6719e-01, -1.7445e-02,
         -1.7881e-02, -6.0097e-02, -2.0231e-01, -1.7298e-02, -1.7445e-02],
        [-9.1467e-01, -5.8553e-02, -1.7644e-01, -2.6885e-01, -7.3666e-02,
         -1.7447e-02, -7.1751e-03, -5.8981e-01, -2.6719e-01, -1.7445e-02,
         -1.7881e-02, -6.0097e-02, -2.0231e-01, -1.7298e-02, -1.7445e-02],
        [-9.1467e-01, -5.8553e-02, -1.7644e-01, -2.6885e-01, -7.3666e-02,
         -1.7447e-02, -7.1751e-03, -5.8981e-01, -2.6719e-01, -1.7445e-02,
         -1.7881e-02, -6.0097e-02, -2.0231e-01, -1.7298e-02, -1.7445e-02],
        [-2.3982e+00, -7.8345e+00, -3.8377e+00, -7.6970e+00,  5.6752e+00,
          7.5303e-03, -2.0700e-01,  9.0210e+00, -4.1275e+00,  1.3322e-02,
         -2.7298e+00, -9.0642e+00, -8.2646e+00, -4.4270e-02,  9.9956e-03],
        [-9.1467e-01, -5.8553e-02, -1.7644e-01, -2.6885e-01, -7.3666e-02,
         -1.7447e-02, -7.1751e-03, -5.8981e-01, -2.6719e-01, -1.7445e-02,
         -1.7881e-02, -6.0097e-02, -2.0231e-01, -1.7298e-02, -1.7445e-02],
        [-9.1467e-01, -5.8553e-02, -1.7644e-01, -2.6885e-01, -7.3666e-02,
         -1.7447e-02, -7.1751e-03, -5.8981e-01, -2.6719e-01, -1.7445e-02,
         -1.7881e-02, -6.0097e-02, -2.0231e-01, -1.7298e-02, -1.7445e-02],
        [-9.1467e-01, -5.8553e-02, -1.7644e-01, -2.6885e-01, -7.3666e-02,
         -1.7447e-02, -7.1751e-03, -5.8981e-01, -2.6719e-01, -1.7445e-02,
         -1.7881e-02, -6.0097e-02, -2.0231e-01, -1.7298e-02, -1.7445e-02],
        [ 3.3701e+00,  8.3599e+00,  2.3219e+00,  8.3344e+00, -8.5543e+00,
         -8.0359e-02,  3.5811e-01, -9.6736e+00,  3.1702e+00, -7.2751e-02,
          2.4387e+00,  9.3991e+00,  8.5093e+00, -9.0998e-02, -7.6293e-02],
        [-9.1467e-01, -5.8553e-02, -1.7644e-01, -2.6885e-01, -7.3666e-02,
         -1.7447e-02, -7.1751e-03, -5.8981e-01, -2.6719e-01, -1.7445e-02,
         -1.7881e-02, -6.0097e-02, -2.0231e-01, -1.7298e-02, -1.7445e-02],
        [-9.1467e-01, -5.8553e-02, -1.7644e-01, -2.6885e-01, -7.3666e-02,
         -1.7447e-02, -7.1751e-03, -5.8981e-01, -2.6719e-01, -1.7445e-02,
         -1.7881e-02, -6.0097e-02, -2.0231e-01, -1.7298e-02, -1.7445e-02],
        [-9.1467e-01, -5.8553e-02, -1.7644e-01, -2.6885e-01, -7.3666e-02,
         -1.7447e-02, -7.1751e-03, -5.8981e-01, -2.6719e-01, -1.7445e-02,
         -1.7881e-02, -6.0097e-02, -2.0231e-01, -1.7298e-02, -1.7445e-02],
        [-9.1467e-01, -5.8553e-02, -1.7644e-01, -2.6885e-01, -7.3666e-02,
         -1.7447e-02, -7.1751e-03, -5.8981e-01, -2.6719e-01, -1.7445e-02,
         -1.7881e-02, -6.0097e-02, -2.0231e-01, -1.7298e-02, -1.7445e-02],
        [ 2.1272e+00,  6.3477e+00,  2.7104e+00,  7.3223e+00, -4.8889e+00,
          1.4226e-01, -8.9003e-02, -8.9004e+00,  3.2195e+00,  1.4273e-01,
          2.1319e+00,  7.2920e+00,  6.6146e+00,  9.5442e-02,  1.4257e-01],
        [-2.6974e+00, -7.5128e+00, -4.1576e+00, -7.1100e+00,  4.9813e+00,
          2.8347e-02,  3.1429e-02,  8.4620e+00, -4.5812e+00,  3.1093e-02,
         -2.6716e+00, -9.0368e+00, -7.9530e+00,  4.6105e-02,  3.0725e-02]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-1.0226, -1.0226, -1.0226, -1.0226,  3.2841, -1.0226, -1.0226, -1.0226,
        -4.6810, -1.0226, -1.0226, -1.0226, -1.0226, -3.6604,  3.4485],
       device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-7.4220e-03, -7.4219e-03, -7.4219e-03, -7.4219e-03,  1.0198e+01,
         -7.4219e-03, -7.4219e-03, -7.4220e-03, -1.1075e+01, -7.4220e-03,
         -7.4219e-03, -7.4220e-03, -7.4219e-03, -6.4431e+00,  8.6870e+00]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  7.2209,   6.7757],
        [ -1.3506,   0.8640],
        [  9.6211,   0.1927],
        [ -1.2673,   1.0900],
        [  8.5709,   9.4073],
        [ -1.2565,   1.1134],
        [-18.6496,   1.2698],
        [ -0.7892,  12.2507],
        [ -6.8618,  -5.9493],
        [-10.4159,  -7.8642],
        [ -1.0700,  12.5843],
        [-10.9584,   7.5084],
        [ -9.3930,  12.1080],
        [ -0.2058,  12.8674],
        [ -1.2627,   1.1000]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-1.4913, -4.0087, -8.5252, -3.8684,  2.2349, -3.8544, -0.1146,  4.3208,
        -4.8516, -1.4906,  3.3435,  1.4936,  3.1396,  2.2331, -3.8630],
       device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 1.1403e+00,  1.1660e-02,  1.8653e+00,  9.8067e-02,  9.5384e-01,
          1.1769e-01, -2.5271e-01,  5.8540e-01, -4.9023e-02,  2.3735e-01,
          3.3074e-01,  2.9555e-02, -3.6315e-01,  3.8830e-01,  1.0617e-01],
        [-2.0367e+00,  1.1652e-01, -2.1097e+00,  1.1782e-01, -2.2069e-01,
          1.1912e-01,  4.6301e-02, -6.3469e-01,  7.3965e-02, -1.2537e+00,
         -5.3428e-01,  1.1238e-01,  2.8245e-02, -4.5835e-01,  1.1828e-01],
        [-2.7971e+00, -3.3816e-01,  5.0943e+00, -5.1959e-01, -3.0613e+00,
         -5.5674e-01, -2.8620e-01,  1.0570e+00,  3.5888e-01,  5.1291e-01,
          1.8082e+00, -4.7799e+00,  1.4621e-01,  3.2897e+00, -5.3478e-01],
        [-3.2885e+00,  1.7889e-01, -8.2786e+00,  1.9309e-02, -4.7863e+00,
          9.6312e-03,  3.5803e+00, -9.8662e+00,  2.5624e+00,  6.6809e+00,
         -7.4873e+00, -6.8623e-01, -4.4530e+00, -5.3719e+00,  1.6976e-02],
        [-1.9305e+00,  9.2076e-02, -2.1602e+00,  9.5662e-02, -3.9319e-01,
          9.7322e-02,  6.3281e-02, -6.6029e-01,  8.4761e-02, -1.2107e+00,
         -5.0833e-01,  1.1663e-01,  3.9251e-02, -4.1620e-01,  9.6264e-02],
        [-6.0315e-01, -1.4720e-01, -1.3237e+01, -3.8052e-01, -1.5692e+00,
         -4.2588e-01,  2.8572e+00,  2.8116e+00,  8.8432e-01,  4.6042e+00,
          2.4637e+00,  3.8757e+00,  1.7924e+00,  1.2095e+00, -3.9913e-01],
        [-2.0362e+00,  1.1615e-01, -2.1079e+00,  1.1747e-01, -2.2255e-01,
          1.1878e-01,  4.6702e-02, -6.3434e-01,  7.4036e-02, -1.2536e+00,
         -5.3389e-01,  1.1266e-01,  2.8381e-02, -4.5808e-01,  1.1794e-01],
        [-2.0171e+00,  1.1738e-01, -2.1717e+00,  1.1865e-01, -2.2879e-01,
          1.1983e-01,  4.3140e-02, -6.5224e-01,  7.7444e-02, -1.2413e+00,
         -5.3591e-01,  1.0677e-01,  2.8147e-02, -4.5136e-01,  1.1907e-01],
        [ 3.8288e-01,  1.2094e-01, -1.0838e+01,  2.5111e-01,  1.7167e+00,
          2.8226e-01, -1.4137e-02,  3.8105e+00,  5.1035e-01,  3.3344e+00,
          3.6677e+00,  1.5059e+00,  1.6599e+00, -5.4995e-01,  2.6246e-01],
        [-2.9861e+00, -4.5402e-03, -1.4815e-01,  1.9304e-03, -8.3766e+00,
          8.0183e-03,  4.3035e+00, -6.8983e+00,  2.9022e+00,  4.3753e+00,
         -4.3959e+00,  2.7245e-01, -6.8668e-01, -1.2135e+00,  4.5672e-03],
        [-2.1098e+00,  2.4594e-01, -2.6953e+00,  2.6347e-01,  5.0802e-02,
          2.6425e-01, -1.8186e-01, -7.0887e-01,  1.3809e-02, -1.3625e+00,
         -6.4297e-01, -2.4242e-02, -6.5134e-02, -4.8626e-01,  2.6378e-01],
        [-8.4557e-01, -3.9568e-02, -3.8943e+00, -1.6544e-02, -6.4251e+00,
         -1.5470e-02,  2.6138e+00, -5.7863e+00,  8.3569e-01,  4.5002e+00,
         -3.7630e+00, -3.4227e-01, -1.5387e+00, -1.2874e+00, -1.6494e-02],
        [-7.0375e-01, -1.1042e-01, -2.6844e+00, -7.6941e-02, -2.5402e+00,
         -7.0552e-02,  3.6635e+00,  2.5652e+00, -5.8439e-02, -4.1755e+00,
          2.0103e+00,  2.6100e+00,  1.4801e+01, -9.0631e-02, -7.4802e-02],
        [-1.8252e+00,  1.1201e-01, -9.7903e+00,  6.7519e-03, -1.5660e+00,
          3.5454e-04,  6.4035e+00,  1.6511e+00,  1.0649e+00,  1.4331e+00,
          1.6874e+00,  3.4158e+00,  1.3059e+00,  1.4042e+00,  5.3484e-03],
        [-2.0044e+00,  1.2250e-01, -2.2555e+00,  1.2383e-01, -2.4391e-01,
          1.2490e-01,  3.4174e-02, -6.6748e-01,  7.7915e-02, -1.2563e+00,
         -5.4171e-01,  9.8558e-02,  2.5547e-02, -4.4684e-01,  1.2422e-01]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([ 3.9004, -3.4088, -4.5781,  0.7203, -3.4867, -1.2423, -3.4103, -3.3999,
         2.5599, -0.9240, -2.8124, -1.3732, -4.1813, -4.1130, -3.3504],
       device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ 1.0199e+00, -1.7517e+00,  2.0105e+00, -8.7933e-01, -1.5960e+00,
          1.7341e+00, -1.7498e+00, -1.7489e+00,  8.0235e-01, -5.3440e+00,
         -2.3263e+00, -1.7563e+00,  9.6742e-01,  2.0232e+00, -1.7766e+00],
        [ 1.2480e+00,  1.7700e+00, -7.5638e-01,  1.5671e+00,  1.6133e+00,
         -4.5041e-01,  1.7681e+00,  1.7670e+00,  8.6769e-01,  5.5794e+00,
          2.3507e+00,  1.9515e+00,  4.4708e-01, -4.5379e-01,  1.7949e+00],
        [-9.1868e+00, -4.0645e-02, -1.2426e-01, -9.9864e-02, -3.3155e-02,
         -1.5473e-01, -4.0564e-02, -3.9906e-02, -2.7883e+00, -9.3525e-02,
         -6.8416e-02, -2.8978e-02, -1.3615e-01, -9.5245e-03, -4.0170e-02],
        [-3.2567e+00, -1.3888e-02, -8.0360e-02, -1.5961e-01, -1.2021e-02,
         -7.8507e-02, -1.3867e-02, -1.3734e-02, -9.7985e-01, -1.8490e-01,
         -2.1890e-02, -7.2183e-02, -5.1818e-02, -3.8890e-03, -1.3853e-02],
        [-2.3294e+00, -9.4459e-03, -3.7549e-02, -1.6125e-01, -7.1936e-03,
         -8.4385e-02, -9.4204e-03, -9.2046e-03, -7.9558e-01, -1.2873e-01,
         -1.8717e-02, -7.9583e-02, -4.8206e-02, -3.6933e-03, -9.3306e-03],
        [-2.6261e+00, -1.5506e-02, -5.7395e-02, -1.7471e-01, -1.2438e-02,
         -1.0062e-01, -1.5473e-02, -1.5142e-02, -8.2389e-01, -1.5940e-01,
         -2.7060e-02, -8.6510e-02, -3.9997e-02, -4.3379e-03, -1.5235e-02],
        [ 8.6667e+00,  5.1551e-02,  1.5935e-01,  6.5565e-01,  4.3933e-02,
          1.9174e-01,  5.1462e-02,  5.0979e-02,  3.2396e+00,  4.1108e-01,
          8.4729e-02,  1.6948e-01,  4.6251e-01, -8.8132e-03,  5.1617e-02],
        [ 1.4926e+00, -1.2603e+00,  1.0758e+00,  8.9706e+00, -1.1158e+00,
         -2.2161e+00, -1.2582e+00, -1.2655e+00,  1.0074e+00,  1.5120e+00,
         -1.7578e+00,  5.0813e+00, -2.7226e-01, -3.4970e+00, -1.2874e+00]],
       device='cuda:0'))])
xi:  [545.035]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 945.3823372694283
W_T_median: 905.3665048412731
W_T_pctile_5: 545.2405016820608
W_T_CVAR_5_pct: 234.36305224140196
Average q (qsum/M+1):  52.734839654737904
Optimal xi:  [545.035]
Expected(across Rb) median(across samples) p_equity:  0.11634859497038026
obj fun:  tensor(-1869.1416, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: 4_factor_1927
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
