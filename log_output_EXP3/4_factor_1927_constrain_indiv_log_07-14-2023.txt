/home/marcchen/Documents/constrain_factor/researchcode/exp_config_json_files/multi_portfolio_exp3_split_1927.json
Starting at: 
14-07-23_15:30

 numpy seed:  2  


 pytorch seed:  2  

Key parameters-------
paths: 256000
iterations: 30000
batchsize: 1000
remove neg:  False
w constaint activation:  yy_fix_jan29


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = 4_factor_1927
timeseries_basket['basket_desc'] = 4 factors with data since 1927: Basic, size, value, div, mom
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'B10_real_ret', 'VWD_real_ret', 'Size_Lo30_real_ret', 'Value_Hi30_real_ret', 'Div_Hi30_real_ret', 'Mom_Hi30_real_ret']
############# End: defined asset  basket #################
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
192601                  0.0                NaN  ...     0.000561     0.023174
192602                  0.0                NaN  ...    -0.033046    -0.053510
192603                  0.0                NaN  ...    -0.064002    -0.096824
192604                  0.0                NaN  ...     0.037029     0.032975
192605                  0.0                NaN  ...     0.012095     0.001035

[5 rows x 16 columns]
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
202208                  NaN            -0.0020  ...    -0.036240    -0.011556
202209                  NaN            -0.0955  ...    -0.091324    -0.099903
202210                  NaN             0.0883  ...     0.077403     0.049863
202211                  NaN            -0.0076  ...     0.052365     0.028123
202212                  NaN            -0.0457  ...    -0.057116    -0.047241

[5 rows x 16 columns]


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = 4_factor_1927
timeseries_basket['basket_desc'] = 4 factors with data since 1927: Basic, size, value, div, mom
timeseries_basket['basket_columns'] = 
['T30_nom_ret', 'B10_nom_ret', 'VWD_nom_ret', 'Size_Lo30_nom_ret', 'Value_Hi30_nom_ret', 'Div_Hi30_nom_ret', 'Mom_Hi30_nom_ret']
############# End: defined asset  basket #################
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
192607                    0.0014              0.0154  ...     0.005383     0.031411
192608                    0.0319              0.0561  ...     0.005363     0.028647
192609                   -0.0173             -0.0071  ...     0.005343     0.005787
192610                   -0.0294             -0.0355  ...     0.005323    -0.028996
192611                   -0.0038              0.0294  ...     0.005303     0.028554

[5 rows x 8 columns]
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
202208                   -0.0020             -0.0164  ...    -0.043289    -0.036240
202209                   -0.0955             -0.0871  ...    -0.050056    -0.091324
202210                    0.0883              0.1486  ...    -0.014968     0.077403
202211                   -0.0076              0.0462  ...     0.040789     0.052365
202212                   -0.0457             -0.0499  ...    -0.018566    -0.057116

[5 rows x 8 columns]
Indices constructed with column names:
Index(['date_for_plt', 'Size_Lo30_nom_ret_ind', 'Value_Hi30_nom_ret_ind',
       'Mom_Hi30_nom_ret_ind', 'Div_Hi30_nom_ret_ind', 'CPI_nom_ret_ind',
       'T30_nom_ret_ind', 'B10_nom_ret_ind', 'VWD_nom_ret_ind'],
      dtype='object')
############# Updated: defined asset basket #################
timeseries_basket['data_df_mean'] = 
T30_real_ret           0.000229
B10_real_ret           0.001637
VWD_real_ret           0.006759
Size_Lo30_real_ret     0.009939
Value_Hi30_real_ret    0.010052
Div_Hi30_real_ret      0.007888
Mom_Hi30_real_ret      0.011386
dtype: float64


timeseries_basket['data_df_stdev'] = 
T30_real_ret           0.005227
B10_real_ret           0.019258
VWD_real_ret           0.053610
Size_Lo30_real_ret     0.082598
Value_Hi30_real_ret    0.072063
Div_Hi30_real_ret      0.056728
Mom_Hi30_real_ret      0.061421
dtype: float64


timeseries_basket['data_df_corr'] = 
                     T30_real_ret  ...  Mom_Hi30_real_ret
T30_real_ret             1.000000  ...           0.055142
B10_real_ret             0.351722  ...           0.066570
VWD_real_ret             0.068448  ...           0.936115
Size_Lo30_real_ret       0.014412  ...           0.903222
Value_Hi30_real_ret      0.018239  ...           0.869469
Div_Hi30_real_ret        0.059813  ...           0.804028
Mom_Hi30_real_ret        0.055142  ...           1.000000

[7 rows x 7 columns]


timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names', 'data_df', 'data_df_mean', 'data_df_stdev', 'data_df_corr'])
############# End: updated: defined asset basket #################
-----------------------------------------------
Dates to be REMOVED due to missing values (should be at *start* only due to trading signals):
Int64Index([], dtype='int64')
-----------------------------------------------
Dates from available data for bootstrapping:
Start: 192607
End: 202212
-----------------------------------------------
Bootstrap block size: 6
-----------------------------------------------
Dates USED bootstrapping:
Start: 192707
End: 199112
-----------------------------------------------
0.0% of bootstrap sample done.
5.0% of bootstrap sample done.
10.0% of bootstrap sample done.
15.0% of bootstrap sample done.
20.0% of bootstrap sample done.
25.0% of bootstrap sample done.
30.0% of bootstrap sample done.
35.0% of bootstrap sample done.
40.0% of bootstrap sample done.
45.0% of bootstrap sample done.
50.0% of bootstrap sample done.
55.00000000000001% of bootstrap sample done.
60.0% of bootstrap sample done.
65.0% of bootstrap sample done.
70.0% of bootstrap sample done.
75.0% of bootstrap sample done.
80.0% of bootstrap sample done.
85.0% of bootstrap sample done.
90.0% of bootstrap sample done.
95.0% of bootstrap sample done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      15  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      15  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 15)     True          15  
2     (15, 15)     True          15  
3      (15, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       7       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      15  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      15  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       7              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 15)     True          15  
2     (15, 15)     True          15  
3      (15, 7)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        7              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 7)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 1500, 'itbound_SGD_algorithms': 30000, 'nit_IterateAveragingStart': 27000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        7              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 7)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0, 0.5, 0.1, 0.1, 0.1, 0.1, 0.1]
W_T_mean: 1035.0895544199634
W_T_median: 669.2147774295086
W_T_pctile_5: -315.4100835464404
W_T_CVAR_5_pct: -448.30591220261425
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1109.3415310998316
Current xi:  [116.356186]
objective value function right now is: -1109.3415310998316
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1517.6123835444787
Current xi:  [123.277374]
objective value function right now is: -1517.6123835444787
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1574.9222641658957
Current xi:  [104.42489]
objective value function right now is: -1574.9222641658957
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -1595.2431829091938
Current xi:  [103.3325]
objective value function right now is: -1595.2431829091938
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1602.2960829275066
Current xi:  [107.764946]
objective value function right now is: -1602.2960829275066
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [111.33306]
objective value function right now is: -1600.8653212140478
14.000000000000002% of gradient descent iterations done. Method = Adam
new min fval:  -1609.506378337608
Current xi:  [114.347176]
objective value function right now is: -1609.506378337608
16.0% of gradient descent iterations done. Method = Adam
new min fval:  -1615.29398367081
Current xi:  [117.53573]
objective value function right now is: -1615.29398367081
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [120.210815]
objective value function right now is: -1614.4985625627678
20.0% of gradient descent iterations done. Method = Adam
new min fval:  -1615.6305262518886
Current xi:  [122.88258]
objective value function right now is: -1615.6305262518886
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -1615.6962400240634
Current xi:  [124.91225]
objective value function right now is: -1615.6962400240634
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [127.30436]
objective value function right now is: -1613.4261438660506
26.0% of gradient descent iterations done. Method = Adam
new min fval:  -1615.7755126903457
Current xi:  [129.1022]
objective value function right now is: -1615.7755126903457
28.000000000000004% of gradient descent iterations done. Method = Adam
new min fval:  -1616.6907064439865
Current xi:  [130.32956]
objective value function right now is: -1616.6907064439865
30.0% of gradient descent iterations done. Method = Adam
new min fval:  -1617.5668729148583
Current xi:  [131.6815]
objective value function right now is: -1617.5668729148583
32.0% of gradient descent iterations done. Method = Adam
new min fval:  -1617.9246112234375
Current xi:  [132.65164]
objective value function right now is: -1617.9246112234375
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [133.16913]
objective value function right now is: -1614.0043457821034
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [133.83768]
objective value function right now is: -1617.3032153326235
38.0% of gradient descent iterations done. Method = Adam
new min fval:  -1620.061325563347
Current xi:  [134.41652]
objective value function right now is: -1620.061325563347
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [135.07886]
objective value function right now is: -1618.0446464281958
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [135.4949]
objective value function right now is: -1612.2150258429913
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [134.86244]
objective value function right now is: -1615.3458803028814
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [135.3141]
objective value function right now is: -1615.5985430970006
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [135.4318]
objective value function right now is: -1619.3637870866028
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [135.84163]
objective value function right now is: -1614.46699777684
52.0% of gradient descent iterations done. Method = Adam
new min fval:  -1620.1430890260847
Current xi:  [136.5597]
objective value function right now is: -1620.1430890260847
54.0% of gradient descent iterations done. Method = Adam
new min fval:  -1620.2856384496722
Current xi:  [136.74924]
objective value function right now is: -1620.2856384496722
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [136.7983]
objective value function right now is: -1618.233142631084
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [137.16475]
objective value function right now is: -1617.9547372498494
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [137.83147]
objective value function right now is: -1613.6306615824926
62.0% of gradient descent iterations done. Method = Adam
new min fval:  -1620.6749682065101
Current xi:  [138.4013]
objective value function right now is: -1620.6749682065101
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [138.07219]
objective value function right now is: -1616.498790267637
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [138.23486]
objective value function right now is: -1615.7864756135546
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [138.72815]
objective value function right now is: -1618.9453880351257
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [138.48232]
objective value function right now is: -1609.3934103442832
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -1621.3799646373586
Current xi:  [138.5302]
objective value function right now is: -1621.3799646373586
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -1621.67345206327
Current xi:  [138.53833]
objective value function right now is: -1621.67345206327
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [138.46907]
objective value function right now is: -1621.310503371744
78.0% of gradient descent iterations done. Method = Adam
new min fval:  -1621.9246578267082
Current xi:  [138.49966]
objective value function right now is: -1621.9246578267082
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [138.65013]
objective value function right now is: -1620.6720799409004
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [138.72583]
objective value function right now is: -1621.7515369018022
84.0% of gradient descent iterations done. Method = Adam
new min fval:  -1622.143637321589
Current xi:  [138.75836]
objective value function right now is: -1622.143637321589
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [138.93921]
objective value function right now is: -1622.1333011271768
88.0% of gradient descent iterations done. Method = Adam
new min fval:  -1622.4595728683776
Current xi:  [138.83379]
objective value function right now is: -1622.4595728683776
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [138.74002]
objective value function right now is: -1622.0089838121319
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [138.85185]
objective value function right now is: -1621.4733394507446
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [138.8999]
objective value function right now is: -1621.8397032533376
new min fval from sgd:  -1622.4643473063659
new min fval from sgd:  -1622.4896083461954
new min fval from sgd:  -1622.5527381186764
new min fval from sgd:  -1622.6686756178738
new min fval from sgd:  -1622.7581102252343
new min fval from sgd:  -1622.7973906323966
new min fval from sgd:  -1622.8198870639733
new min fval from sgd:  -1622.8698294391586
new min fval from sgd:  -1622.8735831100596
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [139.09904]
objective value function right now is: -1622.3119886172572
new min fval from sgd:  -1622.8741666857927
new min fval from sgd:  -1622.883897857049
new min fval from sgd:  -1622.9050415736351
new min fval from sgd:  -1622.915808796253
new min fval from sgd:  -1622.923451395309
new min fval from sgd:  -1622.9296758383848
new min fval from sgd:  -1622.936242027946
new min fval from sgd:  -1622.9437030798072
new min fval from sgd:  -1622.9476522635655
new min fval from sgd:  -1622.9538540084457
new min fval from sgd:  -1622.95892982754
new min fval from sgd:  -1622.9688577605796
new min fval from sgd:  -1622.980959813413
new min fval from sgd:  -1622.9876616910892
new min fval from sgd:  -1622.997196484042
new min fval from sgd:  -1623.0004479912204
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [139.04262]
objective value function right now is: -1622.905641565676
new min fval from sgd:  -1623.0056976957303
new min fval from sgd:  -1623.012638440203
new min fval from sgd:  -1623.0228481488452
new min fval from sgd:  -1623.0248938568213
new min fval from sgd:  -1623.0303349683395
new min fval from sgd:  -1623.0309627429824
new min fval from sgd:  -1623.0310265144576
new min fval from sgd:  -1623.0331141461704
new min fval from sgd:  -1623.0343193989388
new min fval from sgd:  -1623.0345140190148
new min fval from sgd:  -1623.0351142059299
new min fval from sgd:  -1623.0393241147954
new min fval from sgd:  -1623.0409202070232
new min fval from sgd:  -1623.0424969126252
new min fval from sgd:  -1623.04292980382
new min fval from sgd:  -1623.050731971349
new min fval from sgd:  -1623.0538315601862
new min fval from sgd:  -1623.057981876201
new min fval from sgd:  -1623.0607007320086
new min fval from sgd:  -1623.0612845994367
new min fval from sgd:  -1623.0646007034136
new min fval from sgd:  -1623.06627247484
new min fval from sgd:  -1623.069701819311
new min fval from sgd:  -1623.0753729964538
new min fval from sgd:  -1623.0779264460082
new min fval from sgd:  -1623.0893610482801
new min fval from sgd:  -1623.1005727477686
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [139.0884]
objective value function right now is: -1622.958803350958
min fval:  -1623.1005727477686
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -1.0760,   0.7872],
        [ -1.0713,   0.7772],
        [  9.1648,  -7.7539],
        [ -6.4051,   5.8014],
        [ -1.0706,   0.7769],
        [ 10.3328,   1.1622],
        [ -1.0703,   0.7765],
        [ 47.5521,   8.2222],
        [ -5.9981, -12.1948],
        [  3.7702,  -7.7626],
        [ -5.5438,   5.2867],
        [  3.4019,  -7.6995],
        [ -1.0701,   0.7759],
        [-10.4885,  -0.6874],
        [  3.6609,  -7.9965]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-2.8400, -2.8456, -5.4860, -0.0404, -2.8465, -9.0740, -2.8468,  6.4364,
        -5.5230, -5.6059, -0.8112, -5.5489, -2.8470,  8.9988, -5.7524],
       device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-5.9522e-03, -5.9633e-03, -5.7524e-01, -5.8122e-03, -5.9702e-03,
         -3.8245e-01, -5.9712e-03, -8.7359e-01, -3.6725e-01, -1.6295e-01,
         -4.2992e-03, -1.4547e-01, -5.9705e-03, -6.1764e-01, -1.4828e-01],
        [-1.1908e-02,  1.1889e-03,  5.0449e+00, -1.6652e+00,  3.9649e-03,
          1.2291e+01,  4.6927e-03, -1.0304e+01,  1.4689e+01,  5.1105e+00,
         -5.9557e-01,  3.9652e+00,  5.0351e-03, -7.8852e+00,  4.5171e+00],
        [-5.9522e-03, -5.9633e-03, -5.7524e-01, -5.8122e-03, -5.9702e-03,
         -3.8245e-01, -5.9711e-03, -8.7359e-01, -3.6725e-01, -1.6295e-01,
         -4.2992e-03, -1.4547e-01, -5.9705e-03, -6.1764e-01, -1.4828e-01],
        [-4.1073e-03, -1.9795e-02,  5.2311e+00, -1.7701e+00, -2.1686e-02,
          1.2816e+01, -2.2422e-02, -1.0083e+01,  1.3534e+01,  4.7954e+00,
         -9.8566e-01,  3.8988e+00, -2.3099e-02, -8.2211e+00,  4.3911e+00],
        [-5.9522e-03, -5.9633e-03, -5.7524e-01, -5.8122e-03, -5.9702e-03,
         -3.8245e-01, -5.9712e-03, -8.7359e-01, -3.6725e-01, -1.6295e-01,
         -4.2992e-03, -1.4547e-01, -5.9705e-03, -6.1764e-01, -1.4828e-01],
        [-5.9522e-03, -5.9633e-03, -5.7524e-01, -5.8122e-03, -5.9702e-03,
         -3.8245e-01, -5.9712e-03, -8.7359e-01, -3.6725e-01, -1.6295e-01,
         -4.2992e-03, -1.4547e-01, -5.9705e-03, -6.1764e-01, -1.4828e-01],
        [ 5.3516e-02,  5.5921e-02,  4.6638e+00, -7.3034e-01,  5.4095e-02,
          1.1830e+01,  5.4001e-02, -1.0827e+01,  1.2143e+01,  4.3655e+00,
         -7.9650e-01,  3.2621e+00,  5.4486e-02, -6.6207e+00,  4.1914e+00],
        [-5.9522e-03, -5.9633e-03, -5.7524e-01, -5.8122e-03, -5.9702e-03,
         -3.8245e-01, -5.9711e-03, -8.7359e-01, -3.6725e-01, -1.6295e-01,
         -4.2992e-03, -1.4547e-01, -5.9705e-03, -6.1764e-01, -1.4828e-01],
        [-5.9522e-03, -5.9633e-03, -5.7524e-01, -5.8122e-03, -5.9702e-03,
         -3.8245e-01, -5.9712e-03, -8.7359e-01, -3.6725e-01, -1.6295e-01,
         -4.2992e-03, -1.4547e-01, -5.9705e-03, -6.1764e-01, -1.4828e-01],
        [-5.9522e-03, -5.9633e-03, -5.7524e-01, -5.8122e-03, -5.9702e-03,
         -3.8245e-01, -5.9712e-03, -8.7359e-01, -3.6725e-01, -1.6295e-01,
         -4.2992e-03, -1.4547e-01, -5.9705e-03, -6.1764e-01, -1.4828e-01],
        [ 1.0065e-01,  9.8861e-02,  1.2922e+00,  2.6787e-01,  9.8652e-02,
          2.9186e-01,  9.8569e-02,  1.9702e+00,  7.2114e-01,  3.6592e-01,
          2.5606e-01,  3.2349e-01,  9.8490e-02,  1.5105e+00,  3.2906e-01],
        [-5.9522e-03, -5.9633e-03, -5.7524e-01, -5.8122e-03, -5.9702e-03,
         -3.8245e-01, -5.9712e-03, -8.7359e-01, -3.6725e-01, -1.6295e-01,
         -4.2992e-03, -1.4547e-01, -5.9705e-03, -6.1764e-01, -1.4828e-01],
        [-5.9522e-03, -5.9633e-03, -5.7524e-01, -5.8122e-03, -5.9702e-03,
         -3.8245e-01, -5.9712e-03, -8.7359e-01, -3.6725e-01, -1.6295e-01,
         -4.2992e-03, -1.4547e-01, -5.9705e-03, -6.1764e-01, -1.4828e-01],
        [-5.9522e-03, -5.9633e-03, -5.7524e-01, -5.8122e-03, -5.9702e-03,
         -3.8245e-01, -5.9712e-03, -8.7359e-01, -3.6725e-01, -1.6295e-01,
         -4.2992e-03, -1.4547e-01, -5.9705e-03, -6.1764e-01, -1.4828e-01],
        [-5.9522e-03, -5.9633e-03, -5.7524e-01, -5.8122e-03, -5.9702e-03,
         -3.8245e-01, -5.9712e-03, -8.7359e-01, -3.6725e-01, -1.6295e-01,
         -4.2992e-03, -1.4547e-01, -5.9705e-03, -6.1764e-01, -1.4828e-01]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.9441, -0.8345, -0.9441, -1.7262, -0.9441, -0.9441, -1.0056, -0.9441,
        -0.9441, -0.9441,  2.0649, -0.9441, -0.9441, -0.9441, -0.9441],
       device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ -0.0265, -11.2913,  -0.0265, -11.3932,  -0.0265,  -0.0265,  -8.0835,
          -0.0265,  -0.0265,  -0.0265,  12.5303,  -0.0265,  -0.0265,  -0.0265,
          -0.0265]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  1.3046,  10.1252],
        [ -9.6470,  -4.2302],
        [  0.7614,   7.1914],
        [ -5.3503,   9.7124],
        [ -1.8524,   0.4293],
        [-10.5977,  -3.8984],
        [  4.2879,   9.4264],
        [-11.3952,   5.9098],
        [ -1.8311,   0.4493],
        [  0.3360,  10.1870],
        [-10.3706,  -4.6775],
        [ -9.4985,  -4.0869],
        [ -3.5638,   2.4310],
        [ -8.6838,  -0.2024],
        [ 12.0614,   5.3747]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ 6.0905, -2.3328, -4.5997,  7.1679, -3.6853,  0.4094,  6.7974,  5.5687,
        -3.6784,  6.1023, -2.3153, -2.1921, -5.4045,  6.4835,  2.7004],
       device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-1.9433e+00, -4.1334e-01,  1.9980e-01, -5.6816e-01, -1.1649e-02,
         -1.9398e+00, -3.8733e-01,  1.5323e-01, -1.1151e-02, -2.2739e+00,
         -4.2901e-01, -4.4735e-01,  3.3722e-01, -3.0171e+00, -9.4707e-01],
        [-1.3336e+01,  6.8017e+00, -1.0072e-02, -9.4118e+00,  4.5708e-02,
          7.8994e+00, -6.3988e+00, -6.6632e+00,  4.2594e-02, -1.3040e+01,
          8.4044e+00,  6.5590e+00, -2.4010e-02,  4.7083e+00, -4.4353e+00],
        [-1.9426e+00, -4.1251e-01,  1.9890e-01, -5.6807e-01, -1.1589e-02,
         -1.9349e+00, -3.8802e-01,  1.5292e-01, -1.1084e-02, -2.2728e+00,
         -4.2814e-01, -4.4640e-01,  3.3664e-01, -3.0181e+00, -9.4838e-01],
        [-9.4751e+00,  3.9983e+00, -3.8864e-04, -4.0110e+00,  1.4514e-01,
          8.4318e+00, -1.2036e+01, -5.5454e-01,  1.2850e-01, -8.2266e+00,
          4.9906e+00,  3.6477e+00,  1.6062e-02,  5.2601e+00, -6.5705e+00],
        [-1.9438e+00, -4.1398e-01,  2.0049e-01, -5.6823e-01, -1.1696e-02,
         -1.9435e+00, -3.8680e-01,  1.5346e-01, -1.1203e-02, -2.2747e+00,
         -4.2967e-01, -4.4808e-01,  3.3766e-01, -3.0164e+00, -9.4605e-01],
        [ 9.9675e-01,  2.2495e+00, -1.1962e+00, -5.9515e+00,  1.8851e-01,
         -6.7309e-01, -5.8205e-01, -8.8918e-01,  1.7727e-01, -2.9152e-01,
          3.2076e+00,  1.8622e+00,  1.4174e-01, -1.3956e+01,  1.8388e+00],
        [ 1.4623e+00,  1.2446e-03,  5.0092e+00,  8.5940e+00,  1.0908e-01,
          1.5895e-02, -5.6948e-01, -4.8137e+00,  1.0202e-01,  2.3227e+00,
          7.5107e-04,  1.9586e-03,  4.6176e+00, -1.8966e+01, -5.0498e+00],
        [-7.0953e+00,  3.3504e+00, -6.8533e-03, -1.2135e+00, -1.4734e-01,
          3.7615e+00, -2.6886e+01,  5.5703e+00, -1.5015e-01, -5.7133e+00,
          4.4569e+00,  3.1538e+00,  6.5917e-03,  2.4983e+00, -7.3992e+00],
        [ 1.1558e+01, -5.8572e+00, -7.5365e-03,  6.0211e+00, -1.3772e-01,
         -6.3683e+00,  1.2295e+01,  3.0531e+00, -1.2258e-01,  1.0570e+01,
         -6.8801e+00, -5.8831e+00, -4.0275e-02, -4.9899e+00,  7.1264e+00],
        [ 6.2207e+00, -4.8668e+00,  1.4108e-02,  1.1957e+01,  9.3618e-02,
         -1.1648e+01,  4.7264e-01,  1.1095e+01,  9.0471e-02,  8.8174e+00,
         -5.4856e+00, -5.1247e+00,  2.1049e-02, -7.3169e-01, -4.9247e-01],
        [-1.9435e+00, -4.1370e-01,  2.0018e-01, -5.6820e-01, -1.1676e-02,
         -1.9419e+00, -3.8703e-01,  1.5336e-01, -1.1181e-02, -2.2743e+00,
         -4.2938e-01, -4.4776e-01,  3.3747e-01, -3.0167e+00, -9.4650e-01],
        [ 2.8022e+00, -5.1318e-01,  7.4858e-02,  3.5645e+00,  4.8093e-02,
         -1.2935e+01,  7.9364e-01,  1.3261e+01,  4.6615e-02,  2.9404e+00,
         -1.4020e-02, -1.4553e+00, -2.8975e-02,  7.4355e+00, -6.6493e+00],
        [-1.9435e+00, -4.1371e-01,  2.0019e-01, -5.6820e-01, -1.1676e-02,
         -1.9419e+00, -3.8703e-01,  1.5336e-01, -1.1181e-02, -2.2743e+00,
         -4.2939e-01, -4.4776e-01,  3.3747e-01, -3.0167e+00, -9.4649e-01],
        [-1.9433e+00, -4.1341e-01,  1.9987e-01, -5.6817e-01, -1.1654e-02,
         -1.9402e+00, -3.8727e-01,  1.5325e-01, -1.1157e-02, -2.2739e+00,
         -4.2908e-01, -4.4742e-01,  3.3727e-01, -3.0170e+00, -9.4696e-01],
        [ 4.5313e-01,  3.7303e+00, -1.7745e+00,  2.9746e-01,  2.2167e-01,
          3.3326e+00, -7.4126e-01,  1.0206e+00,  1.5680e-01,  6.8295e-01,
          3.7780e+00,  3.7197e+00, -1.1529e+00,  1.7826e+00, -3.5314e+00]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-1.2348,  2.8856, -1.2358,  0.4424, -1.2341,  0.3393, -5.7264, -1.2097,
        -1.1362, -4.7618, -1.2344, -6.1034, -1.2344, -1.2348, -0.2414],
       device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-2.5136e+00, -8.7672e+00, -2.5101e+00, -1.7084e-01, -2.5163e+00,
          1.7596e+00, -3.2479e-01, -2.1348e-02,  1.4596e+00,  6.2391e-01,
         -2.5151e+00,  1.4044e+00, -2.5151e+00, -2.5139e+00,  1.8886e+00],
        [ 1.4749e+00, -2.0455e+00,  1.4736e+00, -4.2807e-01,  1.4759e+00,
          1.1796e+00,  1.6572e+00,  1.0575e+01,  1.3794e+00,  1.1288e+00,
          1.4754e+00, -7.5505e-01,  1.4754e+00,  1.4750e+00,  1.0133e+00],
        [ 7.2719e-01,  5.1276e+00,  7.2450e-01,  3.2693e+00,  7.2920e-01,
         -1.1936e+01, -2.5396e-02, -1.0822e+01, -5.8236e+00, -4.0158e+00,
          7.2831e-01, -7.5239e-01,  7.2832e-01,  7.2740e-01,  2.3698e-01],
        [ 6.6335e-01,  1.4354e+01,  6.6136e-01,  8.7995e-01,  6.6486e-01,
         -6.9094e+00,  3.8757e+00, -1.0733e-01, -1.8916e+00,  1.9973e+00,
          6.6419e-01, -4.2608e+00,  6.6420e-01,  6.6351e-01, -1.8385e+00],
        [ 1.3126e-01,  4.1014e+00,  1.3099e-01,  2.7963e+00,  1.3147e-01,
          7.4445e-01,  2.1497e-01, -1.5255e+01,  9.5571e+00,  1.8908e+00,
          1.3138e-01,  3.5132e-01,  1.3138e-01,  1.3128e-01,  2.3149e-01],
        [ 6.6324e-01,  1.3227e+01,  6.6149e-01,  9.8580e+00,  6.6461e-01,
          2.9270e+00,  1.4825e+01, -1.7939e-04,  6.1918e+00,  4.1555e+00,
          6.6401e-01, -1.3450e+01,  6.6402e-01,  6.6339e-01, -5.7068e+00],
        [ 1.2412e-01,  3.8799e+00,  1.2384e-01,  2.6790e+00,  1.2435e-01,
          6.7759e-01,  1.9903e-01, -1.5919e+01,  1.0444e+01,  1.9772e+00,
          1.2425e-01,  4.2062e-01,  1.2425e-01,  1.2415e-01,  9.1484e-01]],
       device='cuda:0'))])
xi:  [139.06898]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 570.9585629481253
W_T_median: 355.6595524652272
W_T_pctile_5: 139.13121592487047
W_T_CVAR_5_pct: 12.041718145372833
Average q (qsum/M+1):  51.969785628780244
Optimal xi:  [139.06898]
Expected(across Rb) median(across samples) p_equity:  0.20468040332198142
obj fun:  tensor(-1623.1006, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: 4_factor_1927
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
