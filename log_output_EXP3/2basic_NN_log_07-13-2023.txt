/home/marcchen/Documents/constrain_factor/researchcode/exp_config_json_files/multi_portfolio_exp3_split_1927.json
Starting at: 
13-07-23_18:17

 numpy seed:  2  


 pytorch seed:  2  

Key parameters-------
paths: 256000
iterations: 30000
batchsize: 1000
remove neg:  False
w constaint activation:  yy_fix_jan29


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
192601                  0.0                NaN  ...     0.000561     0.023174
192602                  0.0                NaN  ...    -0.033046    -0.053510
192603                  0.0                NaN  ...    -0.064002    -0.096824
192604                  0.0                NaN  ...     0.037029     0.032975
192605                  0.0                NaN  ...     0.012095     0.001035

[5 rows x 16 columns]
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
202208                  NaN            -0.0020  ...    -0.036240    -0.011556
202209                  NaN            -0.0955  ...    -0.091324    -0.099903
202210                  NaN             0.0883  ...     0.077403     0.049863
202211                  NaN            -0.0076  ...     0.052365     0.028123
202212                  NaN            -0.0457  ...    -0.057116    -0.047241

[5 rows x 16 columns]


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_nom_ret', 'VWD_nom_ret']
############# End: defined asset  basket #################
               CPI_nom_ret  B10_nom_ret  VWD_nom_ret
My identifier                                       
192607           -0.011299     0.005383     0.031411
192608           -0.005714     0.005363     0.028647
192609            0.005747     0.005343     0.005787
192610            0.005714     0.005323    -0.028996
192611            0.005682     0.005303     0.028554
               CPI_nom_ret  B10_nom_ret  VWD_nom_ret
My identifier                                       
202208           -0.000354    -0.043289    -0.036240
202209            0.002151    -0.050056    -0.091324
202210            0.004056    -0.014968     0.077403
202211           -0.001010     0.040789     0.052365
202212           -0.003070    -0.018566    -0.057116
Indices constructed with column names:
Index(['date_for_plt', 'CPI_nom_ret_ind', 'B10_nom_ret_ind',
       'VWD_nom_ret_ind'],
      dtype='object')
############# Updated: defined asset basket #################
timeseries_basket['data_df_mean'] = 
B10_real_ret    0.001637
VWD_real_ret    0.006759
dtype: float64


timeseries_basket['data_df_stdev'] = 
B10_real_ret    0.019258
VWD_real_ret    0.053610
dtype: float64


timeseries_basket['data_df_corr'] = 
              B10_real_ret  VWD_real_ret
B10_real_ret      1.000000      0.090987
VWD_real_ret      0.090987      1.000000


timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names', 'data_df', 'data_df_mean', 'data_df_stdev', 'data_df_corr'])
############# End: updated: defined asset basket #################
-----------------------------------------------
Dates to be REMOVED due to missing values (should be at *start* only due to trading signals):
Int64Index([], dtype='int64')
-----------------------------------------------
Dates from available data for bootstrapping:
Start: 192607
End: 202212
-----------------------------------------------
Bootstrap block size: 6
-----------------------------------------------
Dates USED bootstrapping:
Start: 192707
End: 199112
-----------------------------------------------
0.0% of bootstrap sample done.
5.0% of bootstrap sample done.
10.0% of bootstrap sample done.
15.0% of bootstrap sample done.
20.0% of bootstrap sample done.
25.0% of bootstrap sample done.
30.0% of bootstrap sample done.
35.0% of bootstrap sample done.
40.0% of bootstrap sample done.
45.0% of bootstrap sample done.
50.0% of bootstrap sample done.
55.00000000000001% of bootstrap sample done.
60.0% of bootstrap sample done.
65.0% of bootstrap sample done.
70.0% of bootstrap sample done.
75.0% of bootstrap sample done.
80.0% of bootstrap sample done.
85.0% of bootstrap sample done.
90.0% of bootstrap sample done.
95.0% of bootstrap sample done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 3000, 'itbound_SGD_algorithms': 30000, 'nit_IterateAveragingStart': 27000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.7, 0.3]
W_T_mean: 810.5634553956887
W_T_median: 552.8300112001896
W_T_pctile_5: -288.41106811417075
W_T_CVAR_5_pct: -406.39571256436057
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -853.6337165653637
Current xi:  [83.52045]
objective value function right now is: -853.6337165653637
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -909.9842730202992
Current xi:  [68.954796]
objective value function right now is: -909.9842730202992
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1340.1280309275612
Current xi:  [43.456062]
objective value function right now is: -1340.1280309275612
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -1351.2104764959686
Current xi:  [21.247046]
objective value function right now is: -1351.2104764959686
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1371.4173177459054
Current xi:  [1.7825161]
objective value function right now is: -1371.4173177459054
12.0% of gradient descent iterations done. Method = Adam
new min fval:  -1373.4573551547958
Current xi:  [-9.974557]
objective value function right now is: -1373.4573551547958
14.000000000000002% of gradient descent iterations done. Method = Adam
new min fval:  -1383.6840681116507
Current xi:  [-23.57677]
objective value function right now is: -1383.6840681116507
16.0% of gradient descent iterations done. Method = Adam
new min fval:  -1388.5387042057378
Current xi:  [-36.47922]
objective value function right now is: -1388.5387042057378
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -1390.6510703902675
Current xi:  [-45.9009]
objective value function right now is: -1390.6510703902675
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [-57.02982]
objective value function right now is: -1386.0131155790245
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -1393.5235720912779
Current xi:  [-67.63754]
objective value function right now is: -1393.5235720912779
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [-76.37019]
objective value function right now is: -1392.7869174607265
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [-78.95693]
objective value function right now is: -1392.3785251490642
28.000000000000004% of gradient descent iterations done. Method = Adam
new min fval:  -1396.0567999972595
Current xi:  [-79.6134]
objective value function right now is: -1396.0567999972595
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [-78.62242]
objective value function right now is: -1390.8801833694633
32.0% of gradient descent iterations done. Method = Adam
new min fval:  -1396.103721563322
Current xi:  [-79.69408]
objective value function right now is: -1396.103721563322
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [-81.5903]
objective value function right now is: -1395.0143403305613
36.0% of gradient descent iterations done. Method = Adam
new min fval:  -1396.6203186831942
Current xi:  [-80.875565]
objective value function right now is: -1396.6203186831942
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [-80.54934]
objective value function right now is: -1396.2970336927056
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [-80.035484]
objective value function right now is: -1393.5026565505161
42.0% of gradient descent iterations done. Method = Adam
new min fval:  -1396.727176523956
Current xi:  [-80.62419]
objective value function right now is: -1396.727176523956
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [-79.82741]
objective value function right now is: -1395.6153036644953
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [-80.08614]
objective value function right now is: -1395.366540862672
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [-82.64873]
objective value function right now is: -1394.0304406590406
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [-81.11467]
objective value function right now is: -1395.3653009473087
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [-80.663155]
objective value function right now is: -1395.078657064138
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [-79.00017]
objective value function right now is: -1394.4158541206966
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [-80.21155]
objective value function right now is: -1396.1170956320316
57.99999999999999% of gradient descent iterations done. Method = Adam
new min fval:  -1396.736364546095
Current xi:  [-79.870125]
objective value function right now is: -1396.736364546095
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [-80.26876]
objective value function right now is: -1395.632441888654
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [-79.44379]
objective value function right now is: -1394.1477229851412
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [-80.45142]
objective value function right now is: -1396.6986683447813
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [-82.136826]
objective value function right now is: -1396.1319100565065
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [-84.360176]
objective value function right now is: -1394.628284847641
70.0% of gradient descent iterations done. Method = Adam
new min fval:  -1398.6914643188818
Current xi:  [-87.5129]
objective value function right now is: -1398.6914643188818
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -1399.1767811950992
Current xi:  [-88.692825]
objective value function right now is: -1399.1767811950992
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -1399.3294188676107
Current xi:  [-90.07644]
objective value function right now is: -1399.3294188676107
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [-91.48359]
objective value function right now is: -1397.7400026431592
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [-92.84973]
objective value function right now is: -1399.2255347026703
80.0% of gradient descent iterations done. Method = Adam
new min fval:  -1399.8047367589297
Current xi:  [-93.90868]
objective value function right now is: -1399.8047367589297
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [-94.93034]
objective value function right now is: -1399.6024683263545
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [-96.0566]
objective value function right now is: -1399.3423385706694
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [-97.09805]
objective value function right now is: -1399.4335845976377
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [-98.38507]
objective value function right now is: -1399.7562730584373
new min fval from sgd:  -1400.2100756305902
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [-99.32325]
objective value function right now is: -1400.2100756305902
new min fval from sgd:  -1400.2145336230146
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [-100.08723]
objective value function right now is: -1400.1904945729902
new min fval from sgd:  -1400.264732174367
new min fval from sgd:  -1400.3007595065517
new min fval from sgd:  -1400.3181500688008
new min fval from sgd:  -1400.324824181357
new min fval from sgd:  -1400.3363249477964
new min fval from sgd:  -1400.3387224402427
new min fval from sgd:  -1400.3406979575418
new min fval from sgd:  -1400.348716981534
new min fval from sgd:  -1400.3491958938298
new min fval from sgd:  -1400.4011399417636
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [-101.040245]
objective value function right now is: -1398.9740289551848
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [-101.555725]
objective value function right now is: -1400.160928009207
new min fval from sgd:  -1400.4035720282143
new min fval from sgd:  -1400.4132855851576
new min fval from sgd:  -1400.4205418741085
new min fval from sgd:  -1400.4287154203257
new min fval from sgd:  -1400.4365630532582
new min fval from sgd:  -1400.4432667914612
new min fval from sgd:  -1400.4473968876223
new min fval from sgd:  -1400.4504806491702
new min fval from sgd:  -1400.4539045977347
new min fval from sgd:  -1400.4541892680115
new min fval from sgd:  -1400.4557197989184
new min fval from sgd:  -1400.460353781817
new min fval from sgd:  -1400.463229582351
new min fval from sgd:  -1400.4644411373763
new min fval from sgd:  -1400.4689576319317
new min fval from sgd:  -1400.48361367708
new min fval from sgd:  -1400.4939870168985
new min fval from sgd:  -1400.500326994427
new min fval from sgd:  -1400.503517655665
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [-101.94233]
objective value function right now is: -1400.4775800382874
new min fval from sgd:  -1400.5051253420847
new min fval from sgd:  -1400.509198535252
new min fval from sgd:  -1400.5127378291284
new min fval from sgd:  -1400.5155164496232
new min fval from sgd:  -1400.5157165903538
new min fval from sgd:  -1400.5285386453763
new min fval from sgd:  -1400.5389099595627
new min fval from sgd:  -1400.5472096115361
new min fval from sgd:  -1400.5534107465687
new min fval from sgd:  -1400.557451511718
new min fval from sgd:  -1400.560500515005
new min fval from sgd:  -1400.5608591703203
new min fval from sgd:  -1400.5609042738704
new min fval from sgd:  -1400.5638199715177
new min fval from sgd:  -1400.5665869736308
new min fval from sgd:  -1400.5687766649928
new min fval from sgd:  -1400.572026558713
new min fval from sgd:  -1400.5737279361117
new min fval from sgd:  -1400.5763942012904
new min fval from sgd:  -1400.5772701688036
new min fval from sgd:  -1400.578374587586
new min fval from sgd:  -1400.5795137892842
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [-102.01021]
objective value function right now is: -1400.5460122937861
min fval:  -1400.5795137892842
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-1.3095,  0.4733],
        [-9.0042,  2.0171],
        [ 2.1519, -7.6174],
        [ 5.5755, -5.9108],
        [ 9.3800,  1.3523],
        [-2.8661, -9.7362],
        [ 2.7819, -8.2793],
        [-1.3288,  0.4614],
        [-1.2867,  0.4824],
        [ 6.9346, -4.7450]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-2.2248,  6.9615, -6.7122, -6.0432, -8.6793, -8.0949, -7.4094, -2.2188,
        -2.2336, -6.2738], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-0.0175, -0.5744, -0.1897, -0.3052, -0.3178, -0.1130, -0.1915, -0.0174,
         -0.0175, -0.3014],
        [-0.0175, -0.5744, -0.1897, -0.3052, -0.3178, -0.1130, -0.1915, -0.0174,
         -0.0175, -0.3014],
        [-0.0175, -0.5744, -0.1897, -0.3052, -0.3178, -0.1130, -0.1915, -0.0174,
         -0.0175, -0.3014],
        [-0.0175, -0.5744, -0.1897, -0.3052, -0.3178, -0.1130, -0.1915, -0.0174,
         -0.0175, -0.3014],
        [-0.2799, -9.7935,  4.0634,  2.1389,  8.6863,  8.0240,  5.9157, -0.3135,
         -0.2475,  3.6587],
        [-0.0343, -3.6302,  0.6927,  0.1728,  2.0141,  1.2921,  0.9056, -0.0349,
         -0.0336,  0.3318],
        [-0.0175, -0.5744, -0.1897, -0.3052, -0.3178, -0.1130, -0.1915, -0.0174,
         -0.0175, -0.3014],
        [-0.2471, -9.4385,  3.9842,  1.9279,  7.9508,  7.6145,  5.5752, -0.2674,
         -0.2271,  3.2226],
        [-0.0175, -0.5744, -0.1897, -0.3052, -0.3178, -0.1130, -0.1915, -0.0174,
         -0.0175, -0.3014],
        [-0.2502,  8.3302, -4.8110, -3.7313, -9.4711, -7.9025, -7.0599, -0.2739,
         -0.2273, -5.2128]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-1.1442, -1.1442, -1.1442, -1.1442, -3.6398, -2.9454, -1.1442, -3.3194,
        -1.1442,  3.8635], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-9.1932e-03, -9.1932e-03, -9.1932e-03, -9.1932e-03, -7.9559e+00,
         -1.2734e+00, -9.1932e-03, -6.9204e+00, -9.1932e-03,  1.4901e+01]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 11.4082,   2.8673],
        [  0.1357,  12.5171],
        [-10.2015,  -1.6088],
        [-10.1571,  -1.9787],
        [-13.0945,  -3.3771],
        [  5.0315,   8.0682],
        [ -8.5262,  -2.7522],
        [ -9.8350,   0.2176],
        [-10.8809,  -1.5602],
        [ 10.4723,   3.9952]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ 0.1167, 11.2818,  2.7161, -0.5716, -1.0332,  7.9898, -3.3754,  8.3120,
         1.5865, -0.4610], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-1.4529e+00, -1.4112e+00, -4.1914e-01,  1.6390e-01,  5.2170e-01,
          2.5905e+00,  2.6542e-01, -7.4296e+00, -4.9033e-02, -2.1281e+00],
        [ 2.3432e+00,  3.3995e+01, -4.9720e+00, -2.9124e+00, -7.1326e-01,
          5.5990e+00, -4.3994e-01, -9.0930e+00, -5.2737e+00,  8.5039e-01],
        [-4.0598e+00, -2.3604e+01,  3.9556e+00,  2.9284e+00,  3.6398e+00,
         -8.5316e+00,  1.4573e-01,  6.4753e+00,  6.0007e+00, -2.2091e+00],
        [-2.2712e+00, -5.7948e+00,  2.1759e+00,  2.2675e+00,  2.2104e+00,
          1.0786e+00,  1.1980e+00, -1.9385e+00,  2.5526e+00, -3.4838e+00],
        [-2.4708e+00, -3.0127e+00,  1.0702e+00, -7.7317e-01, -5.7177e-01,
          2.6275e+00,  8.1531e-02,  1.2971e+00, -1.0365e+00, -3.4953e+00],
        [-1.1656e+01, -7.3151e+00,  3.9636e+00,  6.0221e+00,  1.3232e+01,
         -2.2686e+01,  4.5195e+00,  4.1477e+00,  5.4231e+00, -9.8892e+00],
        [-1.3984e+00, -2.4766e+00, -1.3319e+00, -4.7862e-01, -4.9491e-01,
          2.9794e-02, -1.3834e-01, -6.4088e-01, -7.9670e-01, -6.9648e-01],
        [-3.1097e+00,  3.6617e+00,  6.0442e-01,  1.0523e+00,  2.3489e+00,
          4.1595e-01,  1.3193e+00, -1.1307e+00,  4.5510e-01, -5.3201e+00],
        [-1.6114e+00, -2.1949e+00, -1.2145e+00, -4.0197e-01, -4.0828e-01,
          6.1759e-02, -1.1480e-01, -7.8176e-01, -7.0394e-01, -7.8316e-01],
        [-2.3411e+00,  6.7475e+00,  3.6965e+00, -1.5004e+00, -3.9090e+00,
          7.2819e-01, -1.9642e+00, -8.0382e-01,  8.9712e-01, -2.4873e+00]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-1.3730,  0.7613, -1.7440, -1.7640, -3.0407, -3.1457, -1.7198, -3.0448,
        -1.9286, -3.1744], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[  2.3413,   0.3045,  -5.9227,   3.6548,   2.1660,  11.1470,  -0.8401,
          -4.3007,  -0.7427,  -0.3876],
        [ -2.4081,  -0.3449,   5.9703,  -3.5412,  -2.2374, -11.1286,   0.8395,
           4.2970,   0.7405,   0.3893]], device='cuda:0'))])
xi:  [-102.01905]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 559.8302230583721
W_T_median: 164.77999189987884
W_T_pctile_5: -102.16492530281656
W_T_CVAR_5_pct: -203.29022579960153
Average q (qsum/M+1):  51.737737840221776
Optimal xi:  [-102.01905]
Expected(across Rb) median(across samples) p_equity:  0.44649756252765654
obj fun:  tensor(-1400.5795, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
