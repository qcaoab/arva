/home/marcchen/Documents/constrain_factor/researchcode/exp_config_json_files/multi_portfolio_TEST1.json
Starting at: 
18-07-23_10:39

 numpy seed:  2  


 pytorch seed:  2  

Key parameters-------
paths: 256000
iterations: 10
batchsize: 10
remove neg:  False
w constaint activation:  yy_fix_jan29


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor4
timeseries_basket['basket_desc'] = Factor4 portfolio for paper: Basic, size, value, vol, mom
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'B10_real_ret', 'VWD_real_ret', 'Size_Lo30_real_ret', 'Value_Hi30_real_ret', 'Vol_Lo20_real_ret', 'Mom_Hi30_real_ret']
############# End: defined asset  basket #################
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
192601                  0.0                NaN  ...     0.000561     0.023174
192602                  0.0                NaN  ...    -0.033046    -0.053510
192603                  0.0                NaN  ...    -0.064002    -0.096824
192604                  0.0                NaN  ...     0.037029     0.032975
192605                  0.0                NaN  ...     0.012095     0.001035

[5 rows x 16 columns]
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
202208                  NaN            -0.0020  ...    -0.036240    -0.011556
202209                  NaN            -0.0955  ...    -0.091324    -0.099903
202210                  NaN             0.0883  ...     0.077403     0.049863
202211                  NaN            -0.0076  ...     0.052365     0.028123
202212                  NaN            -0.0457  ...    -0.057116    -0.047241

[5 rows x 16 columns]


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor4
timeseries_basket['basket_desc'] = Factor4 portfolio for paper: Basic, size, value, vol, mom
timeseries_basket['basket_columns'] = 
['T30_nom_ret', 'B10_nom_ret', 'VWD_nom_ret', 'Size_Lo30_nom_ret', 'Value_Hi30_nom_ret', 'Vol_Lo20_nom_ret', 'Mom_Hi30_nom_ret']
############# End: defined asset  basket #################
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
192607                    0.0014              0.0154  ...     0.005383     0.031411
192608                    0.0319              0.0561  ...     0.005363     0.028647
192609                   -0.0173             -0.0071  ...     0.005343     0.005787
192610                   -0.0294             -0.0355  ...     0.005323    -0.028996
192611                   -0.0038              0.0294  ...     0.005303     0.028554

[5 rows x 8 columns]
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
202208                   -0.0020             -0.0164  ...    -0.043289    -0.036240
202209                   -0.0955             -0.0871  ...    -0.050056    -0.091324
202210                    0.0883              0.1486  ...    -0.014968     0.077403
202211                   -0.0076              0.0462  ...     0.040789     0.052365
202212                   -0.0457             -0.0499  ...    -0.018566    -0.057116

[5 rows x 8 columns]
Indices constructed with column names:
Index(['date_for_plt', 'Size_Lo30_nom_ret_ind', 'Value_Hi30_nom_ret_ind',
       'Mom_Hi30_nom_ret_ind', 'Vol_Lo20_nom_ret_ind', 'CPI_nom_ret_ind',
       'T30_nom_ret_ind', 'B10_nom_ret_ind', 'VWD_nom_ret_ind'],
      dtype='object')
############# Updated: defined asset basket #################
timeseries_basket['data_df_mean'] = 
T30_real_ret           0.000229
B10_real_ret           0.001637
VWD_real_ret           0.006759
Size_Lo30_real_ret     0.009939
Value_Hi30_real_ret    0.010052
Vol_Lo20_real_ret      0.003529
Mom_Hi30_real_ret      0.011386
dtype: float64


timeseries_basket['data_df_stdev'] = 
T30_real_ret           0.005227
B10_real_ret           0.019258
VWD_real_ret           0.053610
Size_Lo30_real_ret     0.082598
Value_Hi30_real_ret    0.072063
Vol_Lo20_real_ret      0.030737
Mom_Hi30_real_ret      0.061421
dtype: float64


timeseries_basket['data_df_corr'] = 
                     T30_real_ret  ...  Mom_Hi30_real_ret
T30_real_ret             1.000000  ...           0.055142
B10_real_ret             0.351722  ...           0.066570
VWD_real_ret             0.068448  ...           0.936115
Size_Lo30_real_ret       0.014412  ...           0.903222
Value_Hi30_real_ret      0.018239  ...           0.869469
Vol_Lo20_real_ret        0.081282  ...           0.482682
Mom_Hi30_real_ret        0.055142  ...           1.000000

[7 rows x 7 columns]


timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names', 'data_df', 'data_df_mean', 'data_df_stdev', 'data_df_corr'])
############# End: updated: defined asset basket #################
-----------------------------------------------
Dates to be REMOVED due to missing values (should be at *start* only due to trading signals):
Int64Index([], dtype='int64')
-----------------------------------------------
Dates from available data for bootstrapping:
Start: 192607
End: 202212
-----------------------------------------------
Bootstrap block size: 18
-----------------------------------------------
Dates USED bootstrapping:
Start: 196307
End: 202212
-----------------------------------------------
0.0% of bootstrap sample done.
5.0% of bootstrap sample done.
10.0% of bootstrap sample done.
15.0% of bootstrap sample done.
20.0% of bootstrap sample done.
25.0% of bootstrap sample done.
30.0% of bootstrap sample done.
35.0% of bootstrap sample done.
40.0% of bootstrap sample done.
45.0% of bootstrap sample done.
50.0% of bootstrap sample done.
55.00000000000001% of bootstrap sample done.
60.0% of bootstrap sample done.
65.0% of bootstrap sample done.
70.0% of bootstrap sample done.
75.0% of bootstrap sample done.
80.0% of bootstrap sample done.
85.0% of bootstrap sample done.
90.0% of bootstrap sample done.
95.0% of bootstrap sample done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      15  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      15  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 15)     True          15  
2     (15, 15)     True          15  
3      (15, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       8       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      15  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      15  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       8              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 15)     True          15  
2     (15, 15)     True          15  
3      (15, 8)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        8              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 8)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 0, 'itbound_SGD_algorithms': 10, 'nit_IterateAveragingStart': 9, 'batchsize': 10, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.0, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        8              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 8)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -0.7244,   0.0610],
        [-33.8999,  -9.5973],
        [ -0.7139,   0.1019],
        [ 10.9183,  -0.9316],
        [  2.9600,  11.9972],
        [ -0.6962,   0.0982],
        [ -0.7246,   0.0608],
        [-13.2780,   5.0787],
        [  7.8715,  -8.3982],
        [ -9.2438,  -0.7686],
        [  3.8722,  -9.2612],
        [-15.1512, -14.4156],
        [ -0.7245,   0.0608],
        [  3.8302,  -8.9646],
        [ -0.7007,   0.0896]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-2.7675, -4.6999, -2.8212, -8.6880,  3.6575, -2.7869, -2.7675,  2.4546,
        -3.8091,  8.7166, -4.2782,  1.0708, -2.7675, -4.2723, -2.7794],
       device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ 6.8161e-02,  4.8536e+00, -9.1243e-02,  1.1079e+01, -5.3186e+00,
          7.1499e-02,  6.8283e-02, -4.0643e+00,  2.9232e+00, -5.2944e+00,
          2.2154e+00,  6.6747e+00,  6.8266e-02,  2.1571e+00,  7.3644e-02],
        [-1.1289e-02,  6.5745e-03, -1.0843e-02, -2.7751e-01, -6.8025e-01,
         -1.1390e-02, -1.1288e-02, -1.0317e-01, -2.1945e-01, -5.2900e-01,
         -1.3054e-01, -2.6569e-01, -1.1288e-02, -1.2490e-01, -1.1414e-02],
        [-1.1289e-02,  6.5745e-03, -1.0843e-02, -2.7751e-01, -6.8025e-01,
         -1.1390e-02, -1.1288e-02, -1.0317e-01, -2.1945e-01, -5.2900e-01,
         -1.3054e-01, -2.6569e-01, -1.1288e-02, -1.2490e-01, -1.1414e-02],
        [-1.1289e-02,  6.5745e-03, -1.0843e-02, -2.7751e-01, -6.8025e-01,
         -1.1390e-02, -1.1288e-02, -1.0317e-01, -2.1945e-01, -5.2900e-01,
         -1.3054e-01, -2.6569e-01, -1.1288e-02, -1.2490e-01, -1.1414e-02],
        [-2.2906e-02, -6.3875e+00,  6.8017e-02, -1.1093e+01,  4.5247e+00,
          2.6489e-02, -2.3135e-02,  3.7002e+00, -4.2967e+00,  5.6473e+00,
         -2.9158e+00, -7.9661e+00, -2.3119e-02, -2.9527e+00,  1.3367e-02],
        [-1.1289e-02,  6.5745e-03, -1.0843e-02, -2.7751e-01, -6.8025e-01,
         -1.1390e-02, -1.1288e-02, -1.0317e-01, -2.1945e-01, -5.2900e-01,
         -1.3054e-01, -2.6569e-01, -1.1288e-02, -1.2490e-01, -1.1414e-02],
        [-1.1289e-02,  6.5745e-03, -1.0843e-02, -2.7751e-01, -6.8025e-01,
         -1.1390e-02, -1.1288e-02, -1.0317e-01, -2.1945e-01, -5.2900e-01,
         -1.3054e-01, -2.6569e-01, -1.1288e-02, -1.2490e-01, -1.1414e-02],
        [ 1.2471e-02, -8.2073e+00,  1.9768e-02, -1.1760e+01,  5.2957e+00,
          4.9484e-02,  1.2166e-02,  5.5938e+00, -4.0571e+00,  6.1052e+00,
         -3.2359e+00, -8.4029e+00,  1.2221e-02, -2.8720e+00,  4.3590e-02],
        [-1.1289e-02,  6.5745e-03, -1.0843e-02, -2.7751e-01, -6.8025e-01,
         -1.1390e-02, -1.1288e-02, -1.0317e-01, -2.1945e-01, -5.2900e-01,
         -1.3054e-01, -2.6569e-01, -1.1288e-02, -1.2490e-01, -1.1414e-02],
        [-1.1289e-02,  6.5745e-03, -1.0843e-02, -2.7751e-01, -6.8025e-01,
         -1.1390e-02, -1.1288e-02, -1.0317e-01, -2.1945e-01, -5.2900e-01,
         -1.3054e-01, -2.6569e-01, -1.1288e-02, -1.2490e-01, -1.1414e-02],
        [-1.1174e-02,  5.7873e-03, -1.0652e-02, -2.6515e-01, -7.2760e-01,
         -1.1264e-02, -1.1173e-02, -1.1389e-01, -2.0717e-01, -5.6358e-01,
         -1.2791e-01, -2.6172e-01, -1.1173e-02, -1.2234e-01, -1.1290e-02],
        [-1.1288e-02,  6.5742e-03, -1.0842e-02, -2.7753e-01, -6.8033e-01,
         -1.1389e-02, -1.1287e-02, -1.0318e-01, -2.1944e-01, -5.2903e-01,
         -1.3053e-01, -2.6570e-01, -1.1287e-02, -1.2490e-01, -1.1413e-02],
        [-1.1289e-02,  6.5745e-03, -1.0843e-02, -2.7751e-01, -6.8025e-01,
         -1.1390e-02, -1.1288e-02, -1.0317e-01, -2.1945e-01, -5.2900e-01,
         -1.3054e-01, -2.6569e-01, -1.1288e-02, -1.2490e-01, -1.1414e-02],
        [-7.5940e-02,  7.5092e+00,  1.0114e-01,  1.2861e+01, -5.7531e+00,
         -3.0679e-03, -7.6395e-02, -4.8016e+00,  3.8160e+00, -6.4848e+00,
          2.8478e+00,  7.8913e+00, -7.6332e-02,  2.4258e+00, -2.1009e-02],
        [-2.1392e-02, -6.2414e+00,  7.3802e-02, -1.1166e+01,  4.3007e+00,
          2.8332e-02, -2.1509e-02,  3.5360e+00, -4.4214e+00,  5.7645e+00,
         -2.9974e+00, -8.1572e+00, -2.1496e-02, -2.8064e+00,  1.5338e-02]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.7599, -0.8923, -0.8923, -0.8923,  0.3376, -0.8923, -0.8923,  0.0701,
        -0.8923, -0.8923, -0.8779, -0.8925, -0.8923, -0.8297,  0.6414],
       device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-5.9693e+00, -2.6730e-04, -2.6728e-04, -2.6728e-04,  6.4492e+00,
         -2.6731e-04, -2.6730e-04,  8.0387e+00, -2.6731e-04, -2.6729e-04,
         -5.1540e-04, -2.6820e-04, -2.6730e-04, -1.0472e+01,  6.2797e+00]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -9.3548,   4.7259],
        [-14.4457,  -4.2355],
        [  8.8479,  -1.6930],
        [ -8.4289, -10.4543],
        [ -7.6256,  11.7389],
        [ -6.1919,   3.2899],
        [ -1.4292,   0.3512],
        [ -1.4242,   0.3549],
        [-12.8042,  -6.7697],
        [ -2.3714,  -0.4176],
        [  7.2653,   2.2838],
        [ -1.4080,   0.3470],
        [ -1.4320,   0.3491],
        [  9.8587,  -0.1954],
        [ -1.4239,   0.3551]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([  2.9776,  -2.3067, -11.8424,  -4.2103,   4.9326,  -8.7667,  -4.1150,
         -4.1169,  -1.1393,  -3.9327,  -6.9194,  -4.1258,  -4.1140,  -7.9358,
         -4.1170], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-4.1993e-01, -5.1934e-02,  2.8689e-01, -4.7975e-01, -9.6247e-01,
         -1.7093e-01, -3.1523e-03, -3.0282e-03, -4.3694e-02, -1.6503e-02,
         -3.0983e-01, -4.2498e-03, -3.2242e-03, -8.4122e-01, -3.0210e-03],
        [-4.1986e-01, -5.1962e-02,  2.8715e-01, -4.7941e-01, -9.6259e-01,
         -1.7093e-01, -3.1733e-03, -3.0492e-03, -4.3520e-02, -1.6537e-02,
         -3.0990e-01, -4.2715e-03, -3.2453e-03, -8.4106e-01, -3.0419e-03],
        [ 5.7233e+00, -1.1051e+00, -2.3697e+00,  1.5233e+00,  2.0650e+00,
         -3.9195e+00,  1.1525e-01,  1.1638e-01,  9.2992e-01,  1.9627e-01,
         -2.5438e+00,  9.3110e-02,  1.1445e-01, -3.4076e+00,  1.1644e-01],
        [-3.0629e+00,  6.1555e+00, -1.0305e+01,  5.8916e+00, -7.4539e+00,
         -1.0460e-02, -1.9635e-01, -1.9299e-01,  8.8027e+00,  3.6822e-01,
         -2.0248e+00, -2.7407e-01, -1.9848e-01, -9.5845e+00, -1.9280e-01],
        [ 5.1007e+00,  6.2667e+00, -6.3731e-02, -3.4606e+00,  5.0781e+00,
          8.3705e-02,  8.6045e-02,  7.4542e-02,  2.7254e+00,  2.2616e+00,
         -2.8072e+00,  9.4699e-02,  9.2934e-02, -6.1082e+00,  7.3886e-02],
        [-4.1994e-01, -5.1935e-02,  2.8690e-01, -4.7973e-01, -9.6248e-01,
         -1.7092e-01, -3.1534e-03, -3.0294e-03, -4.3692e-02, -1.6504e-02,
         -3.0983e-01, -4.2509e-03, -3.2253e-03, -8.4119e-01, -3.0221e-03],
        [-4.1994e-01, -5.1935e-02,  2.8690e-01, -4.7974e-01, -9.6248e-01,
         -1.7092e-01, -3.1533e-03, -3.0293e-03, -4.3692e-02, -1.6504e-02,
         -3.0983e-01, -4.2508e-03, -3.2252e-03, -8.4120e-01, -3.0220e-03],
        [ 6.3743e-01, -3.3784e-01, -1.1492e-01, -2.0203e+00, -8.0994e-01,
          4.3070e-02,  5.7811e-01,  5.7438e-01, -5.5242e+00,  6.4095e-02,
         -3.8839e+00,  6.7506e-01,  5.8057e-01, -7.1192e+00,  5.7418e-01],
        [-4.1994e-01, -5.1935e-02,  2.8690e-01, -4.7974e-01, -9.6248e-01,
         -1.7092e-01, -3.1534e-03, -3.0294e-03, -4.3692e-02, -1.6504e-02,
         -3.0983e-01, -4.2509e-03, -3.2253e-03, -8.4120e-01, -3.0221e-03],
        [-1.1975e+01,  1.2240e+00, -8.3431e+00,  1.2194e+00, -1.6071e+00,
         -2.3354e-03,  2.1381e-01,  2.1268e-01,  3.5306e+00,  2.5023e-01,
          4.3734e+00,  2.8993e-01,  2.1492e-01,  2.5315e-01,  2.1264e-01],
        [-4.1994e-01, -5.1935e-02,  2.8690e-01, -4.7974e-01, -9.6248e-01,
         -1.7092e-01, -3.1535e-03, -3.0294e-03, -4.3692e-02, -1.6505e-02,
         -3.0983e-01, -4.2510e-03, -3.2254e-03, -8.4120e-01, -3.0221e-03],
        [-1.1240e+00,  3.6027e+00, -3.2152e+00,  6.5341e+00, -1.1267e+01,
         -2.6663e-02, -2.1679e-01, -2.1955e-01,  7.2165e+00,  6.1055e-01,
         -1.6606e+00, -1.7865e-01, -2.1501e-01, -2.1740e+00, -2.1970e-01],
        [-4.1994e-01, -5.1935e-02,  2.8690e-01, -4.7973e-01, -9.6248e-01,
         -1.7092e-01, -3.1533e-03, -3.0293e-03, -4.3693e-02, -1.6504e-02,
         -3.0983e-01, -4.2508e-03, -3.2252e-03, -8.4119e-01, -3.0220e-03],
        [-4.1994e-01, -5.1935e-02,  2.8690e-01, -4.7974e-01, -9.6248e-01,
         -1.7092e-01, -3.1535e-03, -3.0294e-03, -4.3692e-02, -1.6504e-02,
         -3.0983e-01, -4.2510e-03, -3.2253e-03, -8.4120e-01, -3.0221e-03],
        [-5.9006e+00,  3.0845e+00, -1.2801e-01,  2.0393e+00, -3.2412e+00,
          5.0206e+00, -3.5434e-03, -5.8177e-03, -1.9924e+00,  6.1357e-02,
          3.3146e+00, -1.7259e-02, -2.3057e-03,  6.9190e+00, -5.9554e-03]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-5.0625, -5.0624, -1.6317, -7.9919, -7.6744, -5.0625, -5.0625, -2.7438,
        -5.0625, -4.0396, -5.0625, -5.5744, -5.0626, -5.0625, -0.0457],
       device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[-2.1207e-01, -2.1203e-01,  2.3992e+00, -4.6028e+00,  3.6463e+00,
         -2.1209e-01, -2.1209e-01, -4.9371e+00, -2.1209e-01,  3.5745e+00,
         -2.1209e-01, -5.2696e+00, -2.1209e-01, -2.1209e-01,  2.9753e-01],
        [ 2.8967e-01,  2.8994e-01,  1.1013e+00,  4.6163e+00, -6.1664e-01,
          2.8966e-01,  2.8966e-01,  5.4001e+00,  2.8966e-01, -2.6892e+00,
          2.8966e-01,  5.6383e+00,  2.8966e-01,  2.8966e-01,  1.9102e+00],
        [-1.6818e-01, -1.6819e-01, -1.2103e+01, -1.7357e-02, -2.3170e-01,
         -1.6817e-01, -1.6817e-01, -1.0181e+00, -1.6817e-01, -2.8766e-01,
         -1.6817e-01, -1.3701e-01, -1.6817e-01, -1.6817e-01, -1.1988e+01],
        [-1.6868e-01, -1.6869e-01, -1.1901e+01, -2.3141e-02, -1.9574e-01,
         -1.6867e-01, -1.6867e-01, -1.0559e+00, -1.6867e-01, -3.0861e-01,
         -1.6867e-01, -2.0994e-01, -1.6867e-01, -1.6867e-01, -1.2513e+01],
        [ 1.3769e-01,  1.4081e-01,  1.4819e+00, -3.9259e+00,  2.1359e+00,
          1.3678e-01,  1.3695e-01, -2.8330e+00,  1.3689e-01, -3.8076e+00,
          1.3691e-01,  6.8039e-01,  1.3675e-01,  1.3694e-01,  6.2578e-01],
        [-1.3047e-01, -1.3048e-01, -8.5481e+00, -6.1180e-02, -1.2840e-01,
         -1.3047e-01, -1.3047e-01, -8.4313e-01, -1.3047e-01, -2.9442e-01,
         -1.3047e-01, -4.8352e-01, -1.3047e-01, -1.3047e-01, -1.1180e+01],
        [-1.3341e-02, -1.0375e-02,  2.2776e+00,  4.6586e+00,  6.2950e-01,
         -1.4264e-02, -1.4092e-02,  3.4772e+00, -1.4148e-02,  4.6281e+00,
         -1.4133e-02,  4.9668e-01, -1.4295e-02, -1.4100e-02,  1.5316e+00],
        [ 3.6044e-01,  3.6059e-01,  6.1813e-01,  1.6831e+00, -3.5500e+00,
          3.6045e-01,  3.6045e-01,  3.0436e+00,  3.6045e-01,  1.2837e+00,
          3.6045e-01,  1.3477e+01,  3.6045e-01,  3.6045e-01,  1.1812e+01]],
       device='cuda:0'))])
loaded xi:  633.7417
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0, 0.5, 0.1, 0.1, 0.1, 0.1, 0.1]
W_T_mean: 1145.5145662869302
W_T_median: 859.9386077279269
W_T_pctile_5: -136.26604266856006
W_T_CVAR_5_pct: -277.4390415040601
-----------------------------------------------
new min fval from sgd:  -2052.3318109909355
min fval:  -2052.3318109909355
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 902.3891811694482
W_T_median: 866.5125400654515
W_T_pctile_5: 683.4480230044464
W_T_CVAR_5_pct: 437.2322421512056
Average q (qsum/M+1):  52.43302671370968
Optimal xi:  [633.7417]
Expected(across Rb) median(across samples) p_equity:  0.19695512072648852
obj fun:  tensor(-2052.3318, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Fi14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [707.87775]
objective value function right now is: -2065.455736944875
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [712.6895]
objective value function right now is: -2070.3211052227675
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -2072.18806474607
Current xi:  [716.4234]
objective value function right now is: -2072.18806474607
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [719.7546]
objective value function right now is: -2070.8235955023533
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -2072.2654762604793
Current xi:  [722.67017]
objective value function right now is: -2072.2654762604793
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [726.37134]
objective value function right now is: -2072.0514927016534
26.0% of gradient descent iterations done. Method = Adam
new min fval:  -2072.770596632822
Current xi:  [726.95026]
objective value function right now is: -2072.770596632822
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [729.56616]
objective value function right now is: -2070.7041764155883
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [731.3721]
objective value function right now is: -2071.4629641087267
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [731.2896]
objective value function right now is: -2071.2427932748506
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [733.5526]
objective value function right now is: -2071.0812705719172
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [731.6683]
objective value function right now is: -2069.447480165691
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [731.28705]
objective value function right now is: -2071.9803812023238
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [732.3007]
objective value function right now is: -2069.036542769314
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [732.2497]
objective value function right now is: -2071.6710833417783
44.0% of gradient descent iterations done. Method = Adam
new min fval:  -2072.8010812170846
Current xi:  [733.8397]
objective value function right now is: -2072.8010812170846
46.0% of gradient descent iterations done. Method = Adam
new min fval:  -2073.10326111156
Current xi:  [734.2757]
objective value function right now is: -2073.10326111156
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [734.8572]
objective value function right now is: -2071.2616928828347
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [735.3767]
objective value function right now is: -2072.6860096201544
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [735.60394]
objective value function right now is: -2070.121458460553
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [735.12695]
objective value function right now is: -2072.9254312602675
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [734.692]
objective value function right now is: -2072.0142908893613
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [735.0511]
objective value function right now is: -2071.134811286341
60.0% of gradient descent iterations done. Method = Adam
new min fval:  -2073.5559394093584
Current xi:  [735.2691]
objective value function right now is: -2073.5559394093584
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [735.4671]
objective value function right now is: -2072.355671321441
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [734.0727]
objective value function right now is: -2072.056437233745
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [735.1446]
objective value function right now is: -2072.137154346654
68.0% of gradient descent iterations done. Method = Adam
new min fval:  -2073.9253716593125
Current xi:  [735.5811]
objective value function right now is: -2073.9253716593125
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [737.04877]
objective value function right now is: -2072.238191016926
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -2074.453542288632
Current xi:  [737.3906]
objective value function right now is: -2074.453542288632
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -2075.0400399529644
Current xi:  [737.59015]
objective value function right now is: -2075.0400399529644
76.0% of gradient descent iterations done. Method = Adam
new min fval:  -2075.1086477532117
Current xi:  [737.5233]
objective value function right now is: -2075.1086477532117
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [737.60675]
objective value function right now is: -2075.0562778510603
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [737.5868]
objective value function right now is: -2074.953855369625
82.0% of gradient descent iterations done. Method = Adam
new min fval:  -2075.1243008367805
Current xi:  [737.4687]
objective value function right now is: -2075.1243008367805
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [737.5976]
objective value function right now is: -2074.8604638054017
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [737.3868]
objective value function right now is: -2074.7328830087777
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [737.20905]
objective value function right now is: -2075.014645458526
90.0% of gradient descent iterations done. Method = Adam
new min fval:  -2075.151879411983
Current xi:  [737.0303]
objective value function right now is: -2075.151879411983
92.0% of gradient descent iterations done. Method = Adam
new min fval:  -2075.4298598642363
Current xi:  [737.0696]
objective value function right now is: -2075.4298598642363
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [737.0295]
objective value function right now is: -2073.94249593955
new min fval from sgd:  -2075.443689515227
new min fval from sgd:  -2075.4761748707856
new min fval from sgd:  -2075.50033968932
new min fval from sgd:  -2075.5271181050252
new min fval from sgd:  -2075.539866256395
new min fval from sgd:  -2075.542187781491
new min fval from sgd:  -2075.5448736046587
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [736.8877]
objective value function right now is: -2075.049071608865
new min fval from sgd:  -2075.5495131587136
new min fval from sgd:  -2075.562219352814
new min fval from sgd:  -2075.582922757021
new min fval from sgd:  -2075.6093379875524
new min fval from sgd:  -2075.625679047192
new min fval from sgd:  -2075.6292056070492
new min fval from sgd:  -2075.63350012352
new min fval from sgd:  -2075.6378804602978
new min fval from sgd:  -2075.6402028032794
new min fval from sgd:  -2075.6438043043618
new min fval from sgd:  -2075.6486690958855
new min fval from sgd:  -2075.653935135858
new min fval from sgd:  -2075.65858530534
new min fval from sgd:  -2075.6616427201498
new min fval from sgd:  -2075.664818246243
new min fval from sgd:  -2075.668862984997
new min fval from sgd:  -2075.6722223853617
new min fval from sgd:  -2075.6757564587288
new min fval from sgd:  -2075.6794169990776
new min fval from sgd:  -2075.684112562859
new min fval from sgd:  -2075.6888223591995
new min fval from sgd:  -2075.6920645544997
new min fval from sgd:  -2075.695234919817
new min fval from sgd:  -2075.6959792008724
new min fval from sgd:  -2075.6970372856676
new min fval from sgd:  -2075.698257541081
new min fval from sgd:  -2075.700190779186
new min fval from sgd:  -2075.7052765721187
new min fval from sgd:  -2075.71127060284
new min fval from sgd:  -2075.7167629295936
new min fval from sgd:  -2075.720728871664
new min fval from sgd:  -2075.7239881131786
new min fval from sgd:  -2075.725775320003
new min fval from sgd:  -2075.727152777956
new min fval from sgd:  -2075.727812245285
new min fval from sgd:  -2075.72980334006
new min fval from sgd:  -2075.731086144327
new min fval from sgd:  -2075.7321250275177
new min fval from sgd:  -2075.7342613470273
new min fval from sgd:  -2075.7351823965832
new min fval from sgd:  -2075.737508988366
new min fval from sgd:  -2075.740756410036
new min fval from sgd:  -2075.744736315586
new min fval from sgd:  -2075.748318387464
new min fval from sgd:  -2075.7497902049167
new min fval from sgd:  -2075.7517210893357
new min fval from sgd:  -2075.755109345274
new min fval from sgd:  -2075.7585889510633
new min fval from sgd:  -2075.761877916636
new min fval from sgd:  -2075.7623908904434
new min fval from sgd:  -2075.7635422328144
new min fval from sgd:  -2075.769343017668
new min fval from sgd:  -2075.774035053421
new min fval from sgd:  -2075.7764972482764
new min fval from sgd:  -2075.7784135847864
new min fval from sgd:  -2075.7789540609247
new min fval from sgd:  -2075.78036364401
new min fval from sgd:  -2075.780989014956
new min fval from sgd:  -2075.7831019268688
new min fval from sgd:  -2075.78464170472
new min fval from sgd:  -2075.7859016924976
new min fval from sgd:  -2075.7883225177397
new min fval from sgd:  -2075.789110996789
new min fval from sgd:  -2075.789637630912
new min fval from sgd:  -2075.789806616189
new min fval from sgd:  -2075.7907367896337
new min fval from sgd:  -2075.7933013355314
new min fval from sgd:  -2075.7937520114806
new min fval from sgd:  -2075.7973053552755
new min fval from sgd:  -2075.799924894704
new min fval from sgd:  -2075.8029329939613
new min fval from sgd:  -2075.806183132007
new min fval from sgd:  -2075.8093960881465
new min fval from sgd:  -2075.80987390641
new min fval from sgd:  -2075.809886961073
new min fval from sgd:  -2075.8157684910275
new min fval from sgd:  -2075.8224860501778
new min fval from sgd:  -2075.829376575614
new min fval from sgd:  -2075.8336030817154
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [737.0117]
objective value function right now is: -2075.787035798355
new min fval from sgd:  -2075.8337485524526
new min fval from sgd:  -2075.834220532988
new min fval from sgd:  -2075.838804466586
new min fval from sgd:  -2075.8463224998764
new min fval from sgd:  -2075.853519213931
new min fval from sgd:  -2075.8618817000706
new min fval from sgd:  -2075.8629178273886
new min fval from sgd:  -2075.8637591116735
new min fval from sgd:  -2075.864419454402
new min fval from sgd:  -2075.866113286661
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [737.04144]
objective value function right now is: -2075.7311729953462
min fval:  -2075.866113286661
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -0.9921,  -0.1850],
        [ -4.0404, -12.5878],
        [ -0.9921,  -0.1850],
        [ 14.4707,  -1.2902],
        [  2.9976,  16.1055],
        [ -0.9921,  -0.1850],
        [ -0.9921,  -0.1850],
        [-18.9526,   6.0137],
        [  8.6284, -12.4208],
        [-13.2521,   0.8986],
        [  4.5778, -14.8251],
        [-15.6451, -16.7698],
        [ -0.9921,  -0.1850],
        [  4.4257, -14.2985],
        [ -0.9921,  -0.1850]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ -2.5401,  -5.1232,  -2.5401, -11.4199,   5.1610,  -2.5401,  -2.5401,
          3.5005,  -3.2993,  10.3137,  -4.1404,   0.4884,  -2.5401,  -4.0215,
         -2.5401], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-1.4852e-02, -1.8391e-02, -1.4852e-02, -4.9451e-01, -8.9393e-01,
         -1.4852e-02, -1.4852e-02, -2.8292e-01, -2.7688e-01, -3.9997e-01,
         -5.8113e-02, -2.2541e-01, -1.4852e-02, -5.7861e-02, -1.4852e-02],
        [-1.4852e-02, -1.8391e-02, -1.4852e-02, -4.9451e-01, -8.9393e-01,
         -1.4852e-02, -1.4852e-02, -2.8292e-01, -2.7688e-01, -3.9997e-01,
         -5.8113e-02, -2.2541e-01, -1.4852e-02, -5.7861e-02, -1.4852e-02],
        [-1.4852e-02, -1.8391e-02, -1.4852e-02, -4.9451e-01, -8.9393e-01,
         -1.4852e-02, -1.4852e-02, -2.8292e-01, -2.7688e-01, -3.9997e-01,
         -5.8113e-02, -2.2541e-01, -1.4852e-02, -5.7861e-02, -1.4852e-02],
        [-1.4852e-02, -1.8391e-02, -1.4852e-02, -4.9451e-01, -8.9393e-01,
         -1.4852e-02, -1.4852e-02, -2.8292e-01, -2.7688e-01, -3.9997e-01,
         -5.8113e-02, -2.2541e-01, -1.4852e-02, -5.7861e-02, -1.4852e-02],
        [-1.4862e-02, -1.8908e-02, -1.4862e-02, -5.0475e-01, -8.7087e-01,
         -1.4862e-02, -1.4862e-02, -2.7839e-01, -2.7943e-01, -3.9680e-01,
         -6.1442e-02, -2.2321e-01, -1.4862e-02, -6.1082e-02, -1.4862e-02],
        [-1.4852e-02, -1.8391e-02, -1.4852e-02, -4.9451e-01, -8.9393e-01,
         -1.4852e-02, -1.4852e-02, -2.8292e-01, -2.7688e-01, -3.9997e-01,
         -5.8113e-02, -2.2541e-01, -1.4852e-02, -5.7861e-02, -1.4852e-02],
        [-1.4852e-02, -1.8391e-02, -1.4852e-02, -4.9451e-01, -8.9393e-01,
         -1.4852e-02, -1.4852e-02, -2.8292e-01, -2.7688e-01, -3.9997e-01,
         -5.8113e-02, -2.2541e-01, -1.4852e-02, -5.7861e-02, -1.4852e-02],
        [-5.5472e-02, -4.0084e+00, -5.5472e-02, -1.4846e+01,  7.2142e+00,
         -5.5472e-02, -5.5472e-02,  5.6508e+00, -3.8439e+00,  8.1672e+00,
         -5.3405e+00, -1.0339e+01, -5.5472e-02, -4.7422e+00, -5.5472e-02],
        [-1.4852e-02, -1.8391e-02, -1.4852e-02, -4.9451e-01, -8.9393e-01,
         -1.4852e-02, -1.4852e-02, -2.8292e-01, -2.7688e-01, -3.9997e-01,
         -5.8113e-02, -2.2541e-01, -1.4852e-02, -5.7861e-02, -1.4852e-02],
        [-1.4852e-02, -1.8391e-02, -1.4852e-02, -4.9451e-01, -8.9393e-01,
         -1.4852e-02, -1.4852e-02, -2.8292e-01, -2.7688e-01, -3.9997e-01,
         -5.8113e-02, -2.2541e-01, -1.4852e-02, -5.7861e-02, -1.4852e-02],
        [-1.4852e-02, -1.8391e-02, -1.4852e-02, -4.9451e-01, -8.9393e-01,
         -1.4852e-02, -1.4852e-02, -2.8292e-01, -2.7688e-01, -3.9997e-01,
         -5.8113e-02, -2.2541e-01, -1.4852e-02, -5.7861e-02, -1.4852e-02],
        [-1.4852e-02, -1.8391e-02, -1.4852e-02, -4.9451e-01, -8.9393e-01,
         -1.4852e-02, -1.4852e-02, -2.8292e-01, -2.7688e-01, -3.9997e-01,
         -5.8113e-02, -2.2541e-01, -1.4852e-02, -5.7861e-02, -1.4852e-02],
        [-1.4852e-02, -1.8391e-02, -1.4852e-02, -4.9451e-01, -8.9393e-01,
         -1.4852e-02, -1.4852e-02, -2.8292e-01, -2.7688e-01, -3.9997e-01,
         -5.8113e-02, -2.2541e-01, -1.4852e-02, -5.7861e-02, -1.4852e-02],
        [-8.3628e-03,  5.8594e+00, -8.3628e-03,  1.5759e+01, -8.0990e+00,
         -8.3628e-03, -8.3629e-03, -5.4860e+00,  4.1492e+00, -9.2044e+00,
          5.6562e+00,  8.4701e+00, -8.3629e-03,  5.0425e+00, -8.3628e-03],
        [-5.8175e-02, -2.2198e-01, -5.8175e-02, -2.3468e+00,  9.3080e-02,
         -5.8175e-02, -5.8175e-02,  4.4380e-01, -1.4223e+00,  6.8663e-01,
         -9.5632e-01, -1.4351e+00, -5.8175e-02, -9.2678e-01, -5.8175e-02]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-1.0172, -1.0172, -1.0172, -1.0172, -1.0461, -1.0172, -1.0172,  0.4443,
        -1.0172, -1.0172, -1.0172, -1.0172, -1.0172, -1.8809, -1.4694],
       device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ -0.0422,  -0.0422,  -0.0422,  -0.0422,  -0.0428,  -0.0422,  -0.0422,
          12.8233,  -0.0422,  -0.0422,  -0.0422,  -0.0422,  -0.0422, -14.3375,
           1.2116]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[-10.8401,   5.5175],
        [-21.7535,  -4.5818],
        [ 13.8547,  -2.0067],
        [-11.1279, -12.5769],
        [-10.7667,  11.0678],
        [ -9.2745,   4.6610],
        [ -1.6904,   2.8242],
        [ -1.9781,   0.1916],
        [-14.7937,  -8.6468],
        [ -1.9790,   0.1915],
        [ 13.0176,   4.0790],
        [ -1.9785,   0.1915],
        [ -1.6192,   0.3297],
        [ 11.4176,   0.5176],
        [ -1.9782,   0.1916]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([  3.2017,  -1.3683, -16.1449,  -4.9202,   5.5812, -12.2546,  -5.4292,
         -4.1858,  -2.0533,  -4.1844,  -9.9029,  -4.1853,  -4.5239, -11.2348,
         -4.1856], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 2.0160e-01,  9.4661e-02, -4.4688e-01, -6.8854e-01, -9.7434e-02,
         -2.1049e-01, -2.3030e-01,  4.2814e-02,  3.2020e-01,  4.2864e-02,
         -8.4536e-01,  4.2830e-02,  3.6941e-02, -7.8527e-01,  4.2819e-02],
        [ 1.3450e-01,  7.8335e-02, -4.3479e-01, -6.9646e-01, -1.6378e-01,
         -2.1767e-01, -2.3788e-01,  3.5373e-02,  2.3801e-01,  3.5413e-02,
         -8.0374e-01,  3.5386e-02,  3.2156e-02, -7.3070e-01,  3.5377e-02],
        [ 1.0497e+00,  8.5823e+00,  1.2515e+01, -2.4085e+00,  4.0529e+00,
         -8.9870e+00,  9.6632e-01,  4.2824e-01, -4.4166e+00,  4.2996e-01,
         -2.3514e+00,  4.2872e-01,  6.2660e-02,  2.3164e+00,  4.2838e-01],
        [ 1.3440e+00,  6.5132e+00, -1.5660e+01,  4.7343e+00, -2.9150e+00,
          1.0654e-03,  2.0760e-01,  5.9502e-01,  5.5014e+00,  5.9664e-01,
          1.8836e+00,  5.9531e-01,  6.7204e-01, -1.4783e+01,  5.9510e-01],
        [ 6.3579e+00,  5.5517e+00, -5.4159e-01, -3.7701e+00,  2.0648e+00,
         -7.0550e+00,  1.3623e+00, -2.5790e-01,  1.3343e+00, -2.5625e-01,
         -1.7485e+00, -2.5758e-01,  4.4875e-01,  7.2355e-01, -2.5780e-01],
        [ 2.0152e-01,  9.4640e-02, -4.4686e-01, -6.8855e-01, -9.7511e-02,
         -2.1050e-01, -2.3031e-01,  4.2805e-02,  3.2011e-01,  4.2855e-02,
         -8.4531e-01,  4.2821e-02,  3.6935e-02, -7.8521e-01,  4.2810e-02],
        [ 2.0140e-01,  9.4606e-02, -4.4684e-01, -6.8856e-01, -9.7639e-02,
         -2.1051e-01, -2.3032e-01,  4.2789e-02,  3.1995e-01,  4.2839e-02,
         -8.4523e-01,  4.2806e-02,  3.6925e-02, -7.8511e-01,  4.2794e-02],
        [ 2.3096e+00, -1.8212e-01,  8.1163e+00, -2.2977e+01,  3.3874e-01,
         -2.1408e+00, -1.1806e+00,  4.2149e-01,  2.6247e+00,  4.2374e-01,
         -1.4663e+00,  4.2199e-01,  1.1718e-01, -1.5962e+00,  4.2163e-01],
        [ 2.0154e-01,  9.4645e-02, -4.4687e-01, -6.8855e-01, -9.7493e-02,
         -2.1050e-01, -2.3031e-01,  4.2807e-02,  3.2013e-01,  4.2857e-02,
         -8.4532e-01,  4.2823e-02,  3.6936e-02, -7.8522e-01,  4.2812e-02],
        [-1.8478e+01,  5.5811e-01, -1.5245e+00, -8.5474e-01, -3.2709e+00,
          1.2436e-04, -8.9771e-01,  2.7180e-01,  2.1442e+00,  2.7165e-01,
          5.7515e+00,  2.7203e-01,  1.6570e-01, -1.4110e-01,  2.7188e-01],
        [ 2.0157e-01,  9.4653e-02, -4.4687e-01, -6.8854e-01, -9.7461e-02,
         -2.1049e-01, -2.3030e-01,  4.2810e-02,  3.2017e-01,  4.2861e-02,
         -8.4534e-01,  4.2827e-02,  3.6939e-02, -7.8525e-01,  4.2816e-02],
        [-3.6047e+00,  1.0238e+01, -1.1861e+00,  2.7741e+00, -6.0994e+00,
         -4.6962e-01, -2.9138e-01, -1.7939e-01,  3.1048e+00, -1.7878e-01,
          1.5830e+00, -1.7936e-01, -1.9019e-01,  1.9122e+00, -1.7938e-01],
        [ 2.0183e-01,  9.4722e-02, -4.4692e-01, -6.8850e-01, -9.7200e-02,
         -2.1046e-01, -2.3027e-01,  4.2841e-02,  3.2048e-01,  4.2892e-02,
         -8.4550e-01,  4.2858e-02,  3.6958e-02, -7.8545e-01,  4.2847e-02],
        [ 2.0135e-01,  9.4592e-02, -4.4683e-01, -6.8857e-01, -9.7690e-02,
         -2.1052e-01, -2.3033e-01,  4.2783e-02,  3.1989e-01,  4.2834e-02,
         -8.4520e-01,  4.2800e-02,  3.6921e-02, -7.8507e-01,  4.2789e-02],
        [-2.5868e+00, -8.1691e-01, -2.5801e+00,  9.0524e+00, -2.3628e+00,
          2.3335e+00, -2.7390e-01,  1.3424e-01, -2.3135e+00,  1.3615e-01,
          1.8806e+00,  1.3466e-01,  2.3626e-01,  6.3025e+00,  1.3437e-01]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-4.9835, -5.0191, -4.6407, -6.4241, -7.9439, -4.9835, -4.9836, -3.0401,
        -4.9835, -4.4292, -4.9835, -2.8063, -4.9834, -4.9836,  0.1998],
       device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ 3.8645e-01,  3.5653e-01,  5.1879e+00, -2.2462e+00,  4.4072e+00,
          3.8642e-01,  3.8637e-01,  1.5234e-01,  3.8643e-01,  1.3978e+00,
          3.8644e-01, -6.8345e+00,  3.8656e-01,  3.8634e-01,  1.0464e+00],
        [-1.2391e-01, -1.0841e-01, -4.1801e-01,  3.4001e+00, -1.5963e+00,
         -1.2390e-01, -1.2387e-01,  1.9480e+00, -1.2390e-01, -5.5189e-01,
         -1.2391e-01,  8.0202e+00, -1.2396e-01, -1.2386e-01,  1.4967e+00],
        [-1.1168e+00, -9.9911e-01, -1.8333e+01, -1.6647e+00, -6.8199e+00,
         -1.1167e+00, -1.1164e+00, -9.4486e+00, -1.1167e+00, -8.1957e-03,
         -1.1167e+00, -3.9430e-01, -1.1172e+00, -1.1163e+00, -2.2839e+01],
        [-1.1188e+00, -1.0020e+00, -1.7194e+01, -1.5776e+00, -6.1904e+00,
         -1.1187e+00, -1.1184e+00, -8.9708e+00, -1.1187e+00, -9.8404e-03,
         -1.1187e+00, -4.2193e-01, -1.1192e+00, -1.1183e+00, -2.3477e+01],
        [ 2.5342e-01,  2.5617e-01,  5.6010e+00, -5.7467e+00,  2.8363e+00,
          2.5342e-01,  2.5342e-01, -4.9325e+00,  2.5342e-01, -4.8404e+00,
          2.5342e-01,  1.1462e+00,  2.5341e-01,  2.5342e-01,  7.8641e-01],
        [-6.8234e-01, -6.1431e-01, -1.1793e+01, -1.3644e+00, -3.4404e+00,
         -6.8225e-01, -6.8211e-01, -6.7279e+00, -6.8227e-01, -2.1555e-02,
         -6.8230e-01, -3.9129e-01, -6.8258e-01, -6.8206e-01, -1.7640e+01],
        [ 1.0589e-01,  8.3550e-02, -7.3030e-01,  8.1613e+00,  3.8799e-01,
          1.0586e-01,  1.0582e-01,  8.0843e+00,  1.0587e-01,  5.6976e+00,
          1.0588e-01,  2.0065e-01,  1.0597e-01,  1.0580e-01,  1.7904e+00],
        [-3.7426e-01, -3.6000e-01, -1.3052e+00,  1.2786e-02, -3.1120e+00,
         -3.7425e-01, -3.7423e-01,  3.3471e-01, -3.7425e-01,  1.3369e+00,
         -3.7426e-01,  1.3253e+01, -3.7430e-01, -3.7422e-01,  1.4191e+01]],
       device='cuda:0'))])
xi:  [737.0203]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 1045.193701148072
W_T_median: 991.3626448931394
W_T_pctile_5: 736.9797686822932
W_T_CVAR_5_pct: 458.1729413748058
Average q (qsum/M+1):  52.18363312752016
Optimal xi:  [737.0203]
Expected(across Rb) median(across samples) p_equity:  0.16992379032890312
obj fun:  tensor(-2075.8661, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: Paper_FactorInv_Factor4
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
