/home/marcchen/Documents/constrain_factor/researchcode/exp_config_json_files/multi_portfolio_TEST1.json
Starting at: 
18-07-23_10:39

 numpy seed:  2  


 pytorch seed:  2  

Key parameters-------
paths: 256000
iterations: 10
batchsize: 10
remove neg:  False
w constaint activation:  yy_fix_jan29


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor4
timeseries_basket['basket_desc'] = Factor4 portfolio for paper: Basic, size, value, vol, mom
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'B10_real_ret', 'VWD_real_ret', 'Size_Lo30_real_ret', 'Value_Hi30_real_ret', 'Vol_Lo20_real_ret', 'Mom_Hi30_real_ret']
############# End: defined asset  basket #################
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
192601                  0.0                NaN  ...     0.000561     0.023174
192602                  0.0                NaN  ...    -0.033046    -0.053510
192603                  0.0                NaN  ...    -0.064002    -0.096824
192604                  0.0                NaN  ...     0.037029     0.032975
192605                  0.0                NaN  ...     0.012095     0.001035

[5 rows x 16 columns]
               Cash_nom_ret  Size_Lo30_nom_ret  ...  VWD_nom_ret  EWD_nom_ret
My identifier                                   ...                          
202208                  NaN            -0.0020  ...    -0.036240    -0.011556
202209                  NaN            -0.0955  ...    -0.091324    -0.099903
202210                  NaN             0.0883  ...     0.077403     0.049863
202211                  NaN            -0.0076  ...     0.052365     0.028123
202212                  NaN            -0.0457  ...    -0.057116    -0.047241

[5 rows x 16 columns]


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = Paper_FactorInv_Factor4
timeseries_basket['basket_desc'] = Factor4 portfolio for paper: Basic, size, value, vol, mom
timeseries_basket['basket_columns'] = 
['T30_nom_ret', 'B10_nom_ret', 'VWD_nom_ret', 'Size_Lo30_nom_ret', 'Value_Hi30_nom_ret', 'Vol_Lo20_nom_ret', 'Mom_Hi30_nom_ret']
############# End: defined asset  basket #################
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
192607                    0.0014              0.0154  ...     0.005383     0.031411
192608                    0.0319              0.0561  ...     0.005363     0.028647
192609                   -0.0173             -0.0071  ...     0.005343     0.005787
192610                   -0.0294             -0.0355  ...     0.005323    -0.028996
192611                   -0.0038              0.0294  ...     0.005303     0.028554

[5 rows x 8 columns]
               Size_Lo30_nom_ret  Value_Hi30_nom_ret  ...  B10_nom_ret  VWD_nom_ret
My identifier                                         ...                          
202208                   -0.0020             -0.0164  ...    -0.043289    -0.036240
202209                   -0.0955             -0.0871  ...    -0.050056    -0.091324
202210                    0.0883              0.1486  ...    -0.014968     0.077403
202211                   -0.0076              0.0462  ...     0.040789     0.052365
202212                   -0.0457             -0.0499  ...    -0.018566    -0.057116

[5 rows x 8 columns]
Indices constructed with column names:
Index(['date_for_plt', 'Size_Lo30_nom_ret_ind', 'Value_Hi30_nom_ret_ind',
       'Mom_Hi30_nom_ret_ind', 'Vol_Lo20_nom_ret_ind', 'CPI_nom_ret_ind',
       'T30_nom_ret_ind', 'B10_nom_ret_ind', 'VWD_nom_ret_ind'],
      dtype='object')
############# Updated: defined asset basket #################
timeseries_basket['data_df_mean'] = 
T30_real_ret           0.000229
B10_real_ret           0.001637
VWD_real_ret           0.006759
Size_Lo30_real_ret     0.009939
Value_Hi30_real_ret    0.010052
Vol_Lo20_real_ret      0.003529
Mom_Hi30_real_ret      0.011386
dtype: float64


timeseries_basket['data_df_stdev'] = 
T30_real_ret           0.005227
B10_real_ret           0.019258
VWD_real_ret           0.053610
Size_Lo30_real_ret     0.082598
Value_Hi30_real_ret    0.072063
Vol_Lo20_real_ret      0.030737
Mom_Hi30_real_ret      0.061421
dtype: float64


timeseries_basket['data_df_corr'] = 
                     T30_real_ret  ...  Mom_Hi30_real_ret
T30_real_ret             1.000000  ...           0.055142
B10_real_ret             0.351722  ...           0.066570
VWD_real_ret             0.068448  ...           0.936115
Size_Lo30_real_ret       0.014412  ...           0.903222
Value_Hi30_real_ret      0.018239  ...           0.869469
Vol_Lo20_real_ret        0.081282  ...           0.482682
Mom_Hi30_real_ret        0.055142  ...           1.000000

[7 rows x 7 columns]


timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names', 'data_df', 'data_df_mean', 'data_df_stdev', 'data_df_corr'])
############# End: updated: defined asset basket #################
-----------------------------------------------
Dates to be REMOVED due to missing values (should be at *start* only due to trading signals):
Int64Index([], dtype='int64')
-----------------------------------------------
Dates from available data for bootstrapping:
Start: 192607
End: 202212
-----------------------------------------------
Bootstrap block size: 18
-----------------------------------------------
Dates USED bootstrapping:
Start: 196307
End: 202212
-----------------------------------------------
0.0% of bootstrap sample done.
5.0% of bootstrap sample done.
10.0% of bootstrap sample done.
15.0% of bootstrap sample done.
20.0% of bootstrap sample done.
25.0% of bootstrap sample done.
30.0% of bootstrap sample done.
35.0% of bootstrap sample done.
40.0% of bootstrap sample done.
45.0% of bootstrap sample done.
50.0% of bootstrap sample done.
55.00000000000001% of bootstrap sample done.
60.0% of bootstrap sample done.
65.0% of bootstrap sample done.
70.0% of bootstrap sample done.
75.0% of bootstrap sample done.
80.0% of bootstrap sample done.
85.0% of bootstrap sample done.
90.0% of bootstrap sample done.
95.0% of bootstrap sample done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      15  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      15  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 15)     True          15  
2     (15, 15)     True          15  
3      (15, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       7       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/constrain_factor/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      15  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      15  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       7              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 15)     True          15  
2     (15, 15)     True          15  
3      (15, 7)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        7              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 7)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 0, 'itbound_SGD_algorithms': 10, 'nit_IterateAveragingStart': 9, 'batchsize': 10, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.0, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       15  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       15  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        7              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 15)      True          15  
0     (15, 15)      True          15  
0      (15, 7)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[  8.9600,  -0.1596],
        [ -7.3910,   5.1466],
        [  9.6451,  -0.5657],
        [ -9.0099,   5.9478],
        [-49.1803,  -4.1407],
        [  4.0696,   7.3858],
        [ -6.0792,  -2.0752],
        [ -0.8881,   0.5437],
        [ -6.2676,  -9.3370],
        [  9.7481,  -0.6257],
        [ -4.4745,  -7.4061],
        [  7.2848,   1.7316],
        [ -0.8691,   0.5643],
        [ -7.0188,   6.4991],
        [  3.7190,  -8.6416]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-8.4211,  0.6059, -8.6637,  3.9116, -3.4350, -9.1100,  6.5305, -2.4389,
        -4.4670, -8.6912,  6.5811, -8.0882, -2.4981,  4.6614, -6.0052],
       device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-1.0780e-01, -1.1378e-02, -1.3202e-01, -1.4898e-01, -4.5065e-03,
         -6.7813e-02, -6.0134e-01, -1.3712e-02, -1.7588e-01, -1.3704e-01,
         -5.7455e-01, -7.8990e-02, -1.3083e-02, -3.0517e-01, -2.3891e-01],
        [ 4.4445e+00, -2.3246e+00,  5.4044e+00, -6.8644e+00,  7.6960e+00,
          4.3644e+00, -1.7495e+00, -3.1139e-01,  1.2924e+01,  5.9067e+00,
         -3.7181e+00,  3.1833e+00, -2.2180e-01, -7.9271e+00,  4.4054e+00],
        [ 5.7028e-01,  1.3099e-01,  6.2104e-01,  4.5665e-01, -4.2231e-02,
          3.1184e-01,  1.5039e+00,  7.5594e-02,  2.6592e-01,  6.3286e-01,
          1.3763e+00,  5.2805e-01,  7.2197e-02,  1.0939e+00,  5.0255e-01],
        [ 4.4317e+00, -1.8823e+00,  5.6264e+00, -6.3217e+00,  7.8464e+00,
          4.3319e+00, -9.7073e-01,  6.9587e-02,  1.3531e+01,  5.8503e+00,
         -3.2363e+00,  3.1039e+00,  8.7992e-02, -7.3958e+00,  4.6906e+00],
        [ 5.7302e-01,  1.3132e-01,  6.2408e-01,  4.5821e-01, -4.2215e-02,
          3.1334e-01,  1.5097e+00,  7.5912e-02,  2.6631e-01,  6.3597e-01,
          1.3816e+00,  5.3044e-01,  7.2503e-02,  1.0985e+00,  5.0468e-01],
        [-1.1255e-01, -1.0968e-02, -1.3537e-01, -1.7846e-01, -1.5596e-02,
         -7.3279e-02, -6.7404e-01, -1.2340e-02, -6.4725e-02, -1.4005e-01,
         -6.5898e-01, -8.5836e-02, -1.1762e-02, -3.6541e-01, -2.1885e-01],
        [ 4.4121e+00, -1.8868e+00,  5.5391e+00, -6.3902e+00,  8.1540e+00,
          4.5191e+00, -1.1693e+00,  7.6302e-02,  1.3657e+01,  6.0255e+00,
         -3.1646e+00,  3.0563e+00,  1.4114e-01, -7.7084e+00,  4.6947e+00],
        [-1.0779e-01, -1.1378e-02, -1.3202e-01, -1.4898e-01, -4.5065e-03,
         -6.7814e-02, -6.0134e-01, -1.3712e-02, -1.7588e-01, -1.3704e-01,
         -5.7455e-01, -7.8990e-02, -1.3083e-02, -3.0517e-01, -2.3891e-01],
        [ 3.5822e+00, -1.6023e+00,  5.0941e+00, -5.8127e+00,  8.0732e+00,
          3.2331e+00, -2.6943e+00,  1.3826e-01,  1.1764e+01,  5.5895e+00,
         -3.3889e+00,  1.9746e+00,  3.7966e-02, -7.2237e+00,  5.4718e+00],
        [-1.0779e-01, -1.1378e-02, -1.3202e-01, -1.4898e-01, -4.5065e-03,
         -6.7814e-02, -6.0134e-01, -1.3712e-02, -1.7588e-01, -1.3704e-01,
         -5.7455e-01, -7.8990e-02, -1.3083e-02, -3.0517e-01, -2.3891e-01],
        [-1.0779e-01, -1.1378e-02, -1.3202e-01, -1.4898e-01, -4.5065e-03,
         -6.7814e-02, -6.0134e-01, -1.3712e-02, -1.7588e-01, -1.3704e-01,
         -5.7455e-01, -7.8990e-02, -1.3083e-02, -3.0517e-01, -2.3891e-01],
        [-1.0779e-01, -1.1378e-02, -1.3202e-01, -1.4898e-01, -4.5065e-03,
         -6.7814e-02, -6.0134e-01, -1.3712e-02, -1.7588e-01, -1.3704e-01,
         -5.7455e-01, -7.8990e-02, -1.3083e-02, -3.0517e-01, -2.3891e-01],
        [ 4.8682e+00, -2.4480e+00,  6.1796e+00, -6.7910e+00,  8.1176e+00,
          4.6486e+00, -2.2361e+00,  4.0570e-02,  1.2750e+01,  6.6828e+00,
         -3.7158e+00,  3.0492e+00, -4.0078e-02, -7.9972e+00,  5.2850e+00],
        [-1.0780e-01, -1.1378e-02, -1.3202e-01, -1.4898e-01, -4.5065e-03,
         -6.7814e-02, -6.0134e-01, -1.3712e-02, -1.7588e-01, -1.3704e-01,
         -5.7455e-01, -7.8990e-02, -1.3083e-02, -3.0517e-01, -2.3891e-01],
        [-1.0780e-01, -1.1378e-02, -1.3202e-01, -1.4898e-01, -4.5065e-03,
         -6.7813e-02, -6.0134e-01, -1.3712e-02, -1.7588e-01, -1.3704e-01,
         -5.7455e-01, -7.8990e-02, -1.3083e-02, -3.0517e-01, -2.3891e-01]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.7774, -1.6053,  2.3110, -1.4428,  2.3206, -0.7912, -1.3068, -0.7774,
        -1.9872, -0.7774, -0.7774, -0.7774, -1.9214, -0.7774, -0.7774],
       device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 1.9944e-03, -5.8175e+00,  7.3156e+00, -6.1774e+00,  7.5150e+00,
          1.7270e-03, -6.3742e+00,  1.9943e-03, -6.5581e+00,  1.9943e-03,
          1.9943e-03,  1.9943e-03, -7.5924e+00,  1.9943e-03,  1.9943e-03]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -6.5501,  10.3632],
        [-11.0976,  -4.2248],
        [ 12.2904,   0.4430],
        [  9.4050,   0.6178],
        [ -1.6123,   0.1107],
        [ -9.7595,  -5.6638],
        [  0.6634,  11.7324],
        [-11.8709,   5.2726],
        [-10.1408,   7.6564],
        [ 10.7984,   4.2663],
        [ -9.6185,  -5.5749],
        [ -1.6139,   0.1110],
        [ -5.0361,  -9.8457],
        [-14.8907,  -6.7007],
        [ 11.1194,   5.5216]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([  7.2085,   0.3211, -10.1038,  -8.6694,  -3.6661,  -4.4958,   7.2681,
          4.2895,   5.5954,   0.3489,  -5.0775,  -3.6663,  -7.0661,  -4.8552,
          2.0608], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ -0.3224,  -1.0821,  -1.4386,  -0.9689,  -0.1369,   1.6459,  -1.0515,
          -1.6754,  -0.3751,  -0.9910,   2.0759,  -0.1375,  -0.3350,   2.1008,
          -1.5675],
        [ -7.6489,   0.1129,  -3.2284,  -1.8496,  -0.2443,   5.3090, -15.2291,
           0.3444,  -2.1023,  -2.5440,   4.9793,  -0.2467,   8.5851,   6.2644,
          -6.8704],
        [ -0.0659,  -1.0596,  -1.5590,  -1.0560,  -0.1343,   1.5559,  -1.1722,
          -1.0877,   0.1393,  -0.8554,   1.9853,  -0.1352,  -0.3198,   1.9810,
          -1.4286],
        [-11.4803,   4.3348,  -2.5443,  -1.0000,   0.1077,   5.8016, -11.9370,
          -1.5624,  -4.8691,  -3.0045,   5.3791,   0.1119,   5.5180,   6.6104,
          -5.6743],
        [ -3.7655,  -0.9377,  11.2966,   7.9663,  -0.0407,  -0.5339,  -2.7414,
          -4.4814,  -1.6249,   1.2768,  -0.3770,  -0.0394,   3.4110,  -1.3620,
           1.6674],
        [ -1.3488,  -3.8921,   6.3748,   1.7061,  -0.0905,  -1.0386,  -3.7739,
           0.7393,  -1.6058,  -1.7432,  -0.7823,  -0.0902,  -1.7331,  -0.0815,
          -0.8776],
        [  4.5996,  -6.7079, -13.0884,  -6.0754,   0.0304,   0.2860,   5.4023,
           5.7525,   6.5655,  -0.5256,   1.0128,   0.0306,  -8.5007,   5.7901,
          -1.6238],
        [  6.2089,  -5.8635, -11.8124,  -6.0637,   0.0434,  -7.3569,   9.3289,
           6.8852,  11.7424,   0.7473,  -5.5118,   0.0388, -15.4813,  -2.8519,
          -0.2810],
        [ -0.3615,  -1.0843,  -1.4428,  -0.9737,  -0.1363,   1.6493,  -1.0550,
          -1.7311,  -0.4274,  -0.9902,   2.0796,  -0.1369,  -0.3315,   2.1072,
          -1.5669],
        [ -0.5119,  -1.0917,  -1.4587,  -0.9917,  -0.1329,   1.6626,  -1.0655,
          -1.9565,  -0.6344,  -0.9864,   2.0942,  -0.1335,  -0.3177,   2.1332,
          -1.5636],
        [ -0.3160,  -1.0817,  -1.4378,  -0.9681,  -0.1370,   1.6454,  -1.0508,
          -1.6663,  -0.3665,  -0.9911,   2.0753,  -0.1376,  -0.3356,   2.0997,
          -1.5677],
        [  2.0132,   2.4300, -10.7786,  -3.5309,   0.0664,  -0.4586,  -1.6352,
           6.1582,   4.4373,  -1.1181,  -0.6848,   0.0680,  -0.6675,   0.8784,
          -1.5626],
        [ -0.7399,  -1.1001,  -1.4830,  -1.0172,  -0.1253,   1.6842,  -1.0730,
          -2.3334,  -0.9670,  -0.9787,   2.1171,  -0.1258,  -0.2957,   2.1771,
          -1.5565],
        [  1.1424,  -0.7483,  -1.2706,  -1.0148,   0.0697,   1.6428,  -0.6288,
          -0.1401,   1.3800,  -0.9707,   1.9958,   0.0685,  -0.3623,   2.0935,
          -1.5198],
        [ -2.2940,  -1.3849,  -2.1246,  -1.5199,  -0.0584,   1.4446,  -1.3434,
          -5.0065,  -3.3082,  -0.4546,   1.9155,  -0.0592,   0.2935,   2.1235,
          -1.4631]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-2.5006, -0.6101, -2.4393,  1.2271,  2.1983, -3.1691, -2.4218, -1.5598,
        -2.5017, -2.5047, -2.5004,  0.7117, -2.5065, -2.2613, -1.8337],
       device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ 2.2494e+00, -6.4377e+00,  2.1093e+00, -8.2037e-01,  4.2983e-01,
          4.6948e-01,  1.6821e+00, -1.5547e-01,  2.2548e+00,  2.2781e+00,
          2.2486e+00,  1.3134e+00,  2.3209e+00,  2.2598e+00,  1.9737e+00],
        [-2.2069e+00,  6.5332e+00, -2.0631e+00,  8.6846e-01,  8.7355e-01,
          2.1556e-01, -4.8588e-01,  4.8258e-01, -2.2126e+00, -2.2371e+00,
         -2.2060e+00, -1.6520e-01, -2.2817e+00, -2.1987e+00, -1.9377e+00],
        [-7.2088e-02, -1.3355e-01, -1.2721e-01, -7.2968e-01, -9.2028e+00,
         -4.1838e-01, -1.7560e+00, -2.3959e+00, -6.8678e-02, -5.7443e-02,
         -7.2671e-02, -5.3009e+00, -4.5212e-02, -7.0679e-01, -6.6250e-02],
        [ 1.6794e+00,  9.3494e+00,  1.9773e+00,  7.3409e+00, -4.0794e-01,
         -7.2945e+00, -5.1939e+00,  1.4200e+00,  1.6899e+00,  1.7303e+00,
          1.6777e+00, -6.5851e+00,  1.7938e+00,  1.1548e+00,  3.6053e+00],
        [ 3.4524e-01,  2.7958e+00,  4.7994e-01,  5.9312e+00,  1.0038e+01,
          6.2892e-01, -4.4419e+00,  3.2598e+00,  3.3131e-01,  2.7837e-01,
          3.4754e-01, -2.9080e-02,  2.0215e-01,  8.6384e-01,  1.1762e-01],
        [ 2.7071e-01,  3.9673e+00,  4.6914e-01,  1.2991e+01,  7.3666e+00,
          8.5964e-01, -1.0975e+01,  6.4142e+00,  2.5350e-01,  1.9201e-01,
          2.7360e-01, -5.9709e+00,  1.1552e-01,  1.1563e+00,  2.8621e-01],
        [-4.8401e-01,  3.1653e+00, -7.6975e-01,  8.2729e+00,  1.4646e+01,
          5.9629e-03, -4.5484e+00,  3.2263e+00, -4.5639e-01, -3.5155e-01,
         -4.8858e-01,  5.5321e-02, -2.0387e-01, -1.5007e+00,  1.7273e-02]],
       device='cuda:0'))])
loaded xi:  296.2922
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0, 0.5, 0.1, 0.1, 0.1, 0.1, 0.1]
W_T_mean: 1145.5145662869302
W_T_median: 859.9386077279269
W_T_pctile_5: -136.26604266856006
W_T_CVAR_5_pct: -277.4390415040601
-----------------------------------------------
new min fval from sgd:  -1774.8258317981736
min fval:  -1774.8258317981736
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 467.6628058264129
W_T_median: 425.140030583736
W_T_pctile_5: 331.66660041805346
W_T_CVAR_5_pct: 185.23364293182934
Average q (qsum/M+1):  51.56367345010081
Optimal xi:  [296.2922]
Expected(across Rb) median(across samples) p_equity:  0.20042059291154146
obj fun:  tensor(-1774.8258, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so resul14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [320.46918]
objective value function right now is: -1787.4135615537502
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [321.9965]
objective value function right now is: -1788.9479224562117
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [323.6556]
objective value function right now is: -1788.6884926904067
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [325.3422]
objective value function right now is: -1787.997414858549
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -1790.9698232324329
Current xi:  [326.6117]
objective value function right now is: -1790.9698232324329
24.0% of gradient descent iterations done. Method = Adam
new min fval:  -1791.0522113021473
Current xi:  [327.878]
objective value function right now is: -1791.0522113021473
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [328.54538]
objective value function right now is: -1789.806065758607
28.000000000000004% of gradient descent iterations done. Method = Adam
new min fval:  -1791.1382740927518
Current xi:  [329.7988]
objective value function right now is: -1791.1382740927518
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [330.6596]
objective value function right now is: -1787.563074236869
32.0% of gradient descent iterations done. Method = Adam
new min fval:  -1791.4822534945617
Current xi:  [330.9084]
objective value function right now is: -1791.4822534945617
34.0% of gradient descent iterations done. Method = Adam
new min fval:  -1791.9313717004518
Current xi:  [332.0014]
objective value function right now is: -1791.9313717004518
36.0% of gradient descent iterations done. Method = Adam
new min fval:  -1792.6455814071937
Current xi:  [331.61325]
objective value function right now is: -1792.6455814071937
38.0% of gradient descent iterations done. Method = Adam
new min fval:  -1793.899720419228
Current xi:  [332.4353]
objective value function right now is: -1793.899720419228
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [333.06796]
objective value function right now is: -1793.3569990924389
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [333.6388]
objective value function right now is: -1791.4904229959152
44.0% of gradient descent iterations done. Method = Adam
new min fval:  -1794.7015112611375
Current xi:  [334.54544]
objective value function right now is: -1794.7015112611375
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [335.00848]
objective value function right now is: -1789.1637365507968
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [335.3609]
objective value function right now is: -1793.6307521376846
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [335.40594]
objective value function right now is: -1794.53261929191
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [335.74646]
objective value function right now is: -1793.744964154426
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [336.52094]
objective value function right now is: -1793.4637669324802
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [336.1759]
objective value function right now is: -1794.0926211940791
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [336.22745]
objective value function right now is: -1792.746797560736
60.0% of gradient descent iterations done. Method = Adam
new min fval:  -1795.313991701142
Current xi:  [336.50858]
objective value function right now is: -1795.313991701142
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [336.37323]
objective value function right now is: -1795.1586692477752
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [336.15814]
objective value function right now is: -1794.9155785367332
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [336.84488]
objective value function right now is: -1795.1561267242769
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [336.37234]
objective value function right now is: -1793.4125749391396
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [337.111]
objective value function right now is: -1794.0616682576022
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -1797.1198622768184
Current xi:  [337.192]
objective value function right now is: -1797.1198622768184
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -1797.2565894616266
Current xi:  [337.38757]
objective value function right now is: -1797.2565894616266
76.0% of gradient descent iterations done. Method = Adam
new min fval:  -1797.4819106956754
Current xi:  [337.47272]
objective value function right now is: -1797.4819106956754
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [337.5826]
objective value function right now is: -1797.3511812128536
80.0% of gradient descent iterations done. Method = Adam
new min fval:  -1797.6775650579925
Current xi:  [337.709]
objective value function right now is: -1797.6775650579925
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [337.7095]
objective value function right now is: -1797.1276066764287
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [338.07977]
objective value function right now is: -1797.0825195851987
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [338.16928]
objective value function right now is: -1797.613726631226
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [338.30493]
objective value function right now is: -1797.0912846670178
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [338.34583]
objective value function right now is: -1797.4308284318574
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [338.37805]
objective value function right now is: -1797.671906141394
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [338.2427]
objective value function right now is: -1797.5127934061095
new min fval from sgd:  -1797.7301949147884
new min fval from sgd:  -1797.7376772779319
new min fval from sgd:  -1797.7444561115253
new min fval from sgd:  -1797.776234275227
new min fval from sgd:  -1797.8038334227922
new min fval from sgd:  -1797.8112286023768
new min fval from sgd:  -1797.82852557075
new min fval from sgd:  -1797.8515030340884
new min fval from sgd:  -1797.8921037577713
new min fval from sgd:  -1797.9022511448804
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [338.338]
objective value function right now is: -1797.5568620944462
new min fval from sgd:  -1797.9023835229045
new min fval from sgd:  -1797.910534865133
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [338.51437]
objective value function right now is: -1797.910534865133
new min fval from sgd:  -1797.9145064276174
new min fval from sgd:  -1797.9165710926438
new min fval from sgd:  -1797.9216395062786
new min fval from sgd:  -1797.9309055382043
new min fval from sgd:  -1797.9347004688977
new min fval from sgd:  -1797.9391176090737
new min fval from sgd:  -1797.9393174702316
new min fval from sgd:  -1797.939873156129
new min fval from sgd:  -1797.943608746452
new min fval from sgd:  -1797.956682150908
new min fval from sgd:  -1797.9627906761473
new min fval from sgd:  -1797.97235051882
new min fval from sgd:  -1797.9779243756732
new min fval from sgd:  -1797.9886262501714
new min fval from sgd:  -1797.9892490899213
new min fval from sgd:  -1797.993181430608
new min fval from sgd:  -1797.99328320116
new min fval from sgd:  -1797.9981843172975
new min fval from sgd:  -1798.0070306240832
new min fval from sgd:  -1798.0086589786401
new min fval from sgd:  -1798.009169559639
new min fval from sgd:  -1798.013372513258
new min fval from sgd:  -1798.0134315354035
new min fval from sgd:  -1798.0140224143893
new min fval from sgd:  -1798.0192917224927
new min fval from sgd:  -1798.0248703894329
new min fval from sgd:  -1798.0277485273439
new min fval from sgd:  -1798.0298640687527
new min fval from sgd:  -1798.0317676138845
new min fval from sgd:  -1798.032124448191
new min fval from sgd:  -1798.0323727308485
new min fval from sgd:  -1798.0374894481267
new min fval from sgd:  -1798.0394923937504
new min fval from sgd:  -1798.0408742099005
new min fval from sgd:  -1798.0439748646031
new min fval from sgd:  -1798.045377392574
new min fval from sgd:  -1798.0503987531515
new min fval from sgd:  -1798.0569725459418
new min fval from sgd:  -1798.0606405438953
new min fval from sgd:  -1798.0609851463682
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [338.54352]
objective value function right now is: -1798.0067242611613
min fval:  -1798.0609851463682
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ 11.3975,  -0.2476],
        [ -0.8405,   0.5629],
        [ 13.2434,  -1.5212],
        [-14.0431,   7.0443],
        [-47.1775,  -5.5815],
        [ -0.8405,   0.5629],
        [ -6.3991,  -4.9735],
        [ -0.8406,   0.5629],
        [ -6.2106, -11.4362],
        [ 13.4244,  -1.6400],
        [ -4.5311,  -7.4992],
        [ -0.8405,   0.5629],
        [ -0.8406,   0.5629],
        [ -8.8977,   7.8083],
        [  3.8859, -10.5475]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-10.9768,  -2.3123, -11.3391,   4.7398,  -4.3523,  -2.3124,   8.8511,
         -2.3124,  -6.0064, -11.4258,   9.4142,  -2.3124,  -2.3124,   5.0868,
         -7.1520], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-4.7529e-02, -8.6091e-03, -1.2554e-01, -9.3570e-02, -3.8354e-02,
         -8.6089e-03, -6.1134e-01, -8.6080e-03, -1.7545e-01, -1.3084e-01,
         -6.4566e-01, -8.6086e-03, -8.6080e-03, -2.0334e-01, -1.9186e-01],
        [ 1.2460e-02, -3.6799e-03,  1.0664e-01, -2.6855e+00, -6.6053e-01,
         -3.6830e-03, -1.8289e+00, -3.6688e-03,  5.7562e+00,  1.1285e-01,
         -3.0060e+00, -3.6752e-03, -3.6688e-03, -2.5547e+00,  2.9274e+00],
        [ 3.6994e-01,  8.0685e-02,  5.2222e-01,  3.3087e-01,  5.0505e-02,
          8.0685e-02,  1.5210e+00,  8.0679e-02,  3.6616e-01,  5.2572e-01,
          1.5808e+00,  8.0683e-02,  8.0679e-02,  9.5834e-01,  4.9440e-01],
        [ 4.1404e+00,  1.2599e-04,  8.0339e+00, -6.4071e+00,  9.8404e+00,
         -6.3458e-04, -1.5366e+00, -2.0407e-04,  1.3906e+01,  8.5078e+00,
         -3.9038e+00, -2.1685e-04, -2.0873e-04, -6.1833e+00,  6.3253e+00],
        [ 3.7205e-01,  8.0967e-02,  5.2489e-01,  3.3169e-01,  5.0703e-02,
          8.0967e-02,  1.5258e+00,  8.0961e-02,  3.6666e-01,  5.2840e-01,
          1.5855e+00,  8.0965e-02,  8.0961e-02,  9.6355e-01,  4.9636e-01],
        [-4.7529e-02, -8.6091e-03, -1.2554e-01, -9.3570e-02, -3.8354e-02,
         -8.6089e-03, -6.1134e-01, -8.6080e-03, -1.7545e-01, -1.3084e-01,
         -6.4566e-01, -8.6086e-03, -8.6080e-03, -2.0334e-01, -1.9186e-01],
        [ 4.2569e+00,  1.7485e-02,  8.0525e+00, -6.5503e+00,  1.0168e+01,
          1.8214e-02, -1.7410e+00,  1.7902e-02,  1.4134e+01,  8.6774e+00,
         -3.8759e+00,  1.7858e-02,  1.7906e-02, -6.4399e+00,  6.3306e+00],
        [-4.7529e-02, -8.6091e-03, -1.2554e-01, -9.3570e-02, -3.8354e-02,
         -8.6089e-03, -6.1134e-01, -8.6080e-03, -1.7545e-01, -1.3084e-01,
         -6.4566e-01, -8.6086e-03, -8.6080e-03, -2.0334e-01, -1.9186e-01],
        [ 3.3467e+00, -2.3699e-03,  7.3497e+00, -4.9153e+00,  9.3089e+00,
         -2.3616e-03, -3.2623e+00, -2.4142e-03,  1.1128e+01,  7.9312e+00,
         -3.9604e+00, -2.3938e-03, -2.4143e-03, -6.1377e+00,  7.2449e+00],
        [-4.7529e-02, -8.6091e-03, -1.2554e-01, -9.3570e-02, -3.8354e-02,
         -8.6089e-03, -6.1134e-01, -8.6080e-03, -1.7545e-01, -1.3084e-01,
         -6.4566e-01, -8.6086e-03, -8.6080e-03, -2.0334e-01, -1.9186e-01],
        [-4.7529e-02, -8.6091e-03, -1.2554e-01, -9.3570e-02, -3.8354e-02,
         -8.6089e-03, -6.1134e-01, -8.6080e-03, -1.7545e-01, -1.3084e-01,
         -6.4566e-01, -8.6086e-03, -8.6080e-03, -2.0334e-01, -1.9186e-01],
        [-4.7529e-02, -8.6091e-03, -1.2554e-01, -9.3570e-02, -3.8354e-02,
         -8.6089e-03, -6.1134e-01, -8.6080e-03, -1.7545e-01, -1.3084e-01,
         -6.4566e-01, -8.6086e-03, -8.6080e-03, -2.0334e-01, -1.9186e-01],
        [ 4.7598e+00, -1.6025e-02,  8.9512e+00, -6.5068e+00,  9.9960e+00,
         -1.6028e-02, -3.2124e+00, -1.6080e-02,  1.2974e+01,  9.6734e+00,
         -4.8139e+00, -1.6047e-02, -1.6080e-02, -6.3922e+00,  8.1145e+00],
        [-4.7529e-02, -8.6091e-03, -1.2554e-01, -9.3570e-02, -3.8354e-02,
         -8.6089e-03, -6.1134e-01, -8.6080e-03, -1.7545e-01, -1.3084e-01,
         -6.4566e-01, -8.6086e-03, -8.6080e-03, -2.0334e-01, -1.9186e-01],
        [-4.7529e-02, -8.6091e-03, -1.2554e-01, -9.3570e-02, -3.8354e-02,
         -8.6089e-03, -6.1134e-01, -8.6080e-03, -1.7545e-01, -1.3084e-01,
         -6.4566e-01, -8.6086e-03, -8.6080e-03, -2.0334e-01, -1.9186e-01]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-0.7210, -1.8337,  2.2925, -2.2384,  2.3025, -0.7210, -2.1133, -0.7210,
        -3.0351, -0.7210, -0.7210, -0.7210, -3.2857, -0.7210, -0.7210],
       device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[  0.0135,  -1.7191,   7.1949,  -6.8385,   7.3779,   0.0135,  -7.1756,
           0.0135,  -7.7002,   0.0135,   0.0135,   0.0135, -10.6042,   0.0135,
           0.0135]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -8.7556,  13.4453],
        [-11.7656,  -6.6055],
        [ 14.1418,   0.1797],
        [ 14.2467,   0.3136],
        [ -4.3123,   2.4916],
        [-10.6930,  -8.8827],
        [ -1.2976,  12.7361],
        [-14.6790,   5.8549],
        [-10.4598,   9.7173],
        [ 11.0878,  -0.4860],
        [ -9.2574,  -9.4434],
        [ -4.3092,   2.4896],
        [ -7.6812, -12.8376],
        [-17.1939,  -6.5762],
        [ 13.2617,   9.3488]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([  8.7511,  -0.7244, -10.7523, -13.2555,  -5.1311,  -7.2696,   8.5061,
          4.5928,   5.2892,  -6.5452,  -9.4073,  -5.1268,  -8.6140,  -4.6322,
          4.2192], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[ 1.9714e+00, -1.1248e+00, -1.7151e+00, -1.4540e+00, -9.8626e-01,
          1.6167e+00,  2.7688e-02,  1.0638e+00,  1.4432e+00, -3.1736e+00,
          3.8728e+00, -9.8623e-01, -1.5954e+00,  3.6830e+00, -1.5402e+00],
        [-3.6460e+00,  1.8140e+00, -2.9988e+00, -3.4469e-01, -4.0338e-02,
          7.5194e+00, -1.3199e+01,  1.1399e+00,  4.0289e-01, -3.1700e+00,
          4.7562e+00, -4.0515e-02,  9.7065e+00,  4.6323e+00, -1.0507e+01],
        [-1.6638e-01, -8.4580e-01, -6.2739e-01, -1.4241e-01, -1.7057e-02,
         -2.6473e-02, -3.0597e-01, -5.8488e-02, -5.6000e-02, -9.8867e-01,
         -4.3353e-02, -1.7055e-02, -4.4820e-01,  5.4403e-02, -2.0779e+00],
        [-6.4777e+00,  6.6874e-01,  4.1051e+00, -1.2931e+01,  8.3683e-04,
          6.1240e+00, -9.4968e+00,  1.3051e+00, -4.1308e+00,  1.6441e-03,
          1.9720e+00,  7.7989e-04,  6.9724e+00,  3.6991e+00, -7.0034e+00],
        [-4.5437e+00, -2.1509e+00,  1.0411e+01,  3.1816e+00,  1.2084e+00,
          1.3422e+00, -3.6683e+00, -7.2045e+00, -3.5884e+00,  2.3050e+00,
          1.0539e+00,  1.2087e+00,  7.5346e+00, -3.0631e+00,  2.4655e+00],
        [-2.1093e+00, -4.2717e+00,  1.0906e+01,  1.1303e+01, -1.4168e+00,
         -3.9856e+00, -5.7839e+00, -1.4195e+00, -1.3245e+00, -4.6585e+00,
         -2.6222e+00, -1.4168e+00,  2.5342e+00, -7.3178e-03, -2.5675e+00],
        [ 9.0659e+00, -8.4962e+00, -1.3573e+01, -1.2881e+01,  1.7726e+00,
          2.1912e+00,  6.9654e+00,  7.2070e+00,  7.0595e+00,  1.7148e+00,
         -2.1022e-01,  1.7739e+00, -4.7772e+00,  6.3082e+00, -1.7764e+00],
        [ 1.3671e+01, -2.4025e+00, -1.4029e+01,  1.0701e+01, -2.4109e-02,
         -6.0272e+00,  5.8785e+00,  5.3461e+00,  4.9756e+00, -2.5109e-01,
         -1.0160e+00, -2.4147e-02, -1.7037e+01, -3.8121e+00,  1.9052e+00],
        [-1.0503e+00, -2.2832e+00, -1.3978e+00, -1.7764e-01, -2.4196e-02,
          1.9854e+00, -5.8848e-01, -2.3402e+00, -5.0137e-01, -3.3056e+00,
          5.0291e+00, -2.4222e-02, -1.8172e+00,  4.8842e+00, -5.0782e-01],
        [-2.1921e+00, -2.9776e+00, -2.1902e+00,  4.7001e-02, -3.9776e-02,
          1.9213e+00,  5.9191e-01, -4.3890e+00, -2.0599e+00, -3.2936e+00,
          5.8134e+00, -3.9953e-02, -2.9022e+00,  5.9984e+00,  1.0802e+00],
        [ 2.4593e+00, -8.1923e-01, -2.0013e+00, -1.8048e+00, -1.2878e+00,
          1.5157e+00,  3.6132e-01,  1.7401e+00,  2.0306e+00, -3.4218e+00,
          3.2624e+00, -1.2877e+00, -1.4619e+00,  3.8399e+00, -1.6597e+00],
        [ 4.0433e+00,  3.4781e-01, -1.1907e+01, -7.5018e+00, -3.4183e+00,
         -1.5805e+00,  1.9514e+00,  6.5562e+00,  9.1344e+00, -4.4484e-01,
         -1.2802e+00, -3.4089e+00,  8.0846e-01, -3.3752e+00, -2.3290e+00],
        [-1.0727e-01, -2.1712e+00,  3.6366e-01, -5.5510e+00, -1.3394e-02,
          3.3124e+00, -8.4345e+00, -2.5690e+00, -1.7191e-01, -3.4284e-01,
          7.0755e+00, -1.3452e-02, -7.0346e+00,  7.9328e+00,  1.2509e+00],
        [ 2.6304e+00, -2.5196e+00, -6.1984e-01, -8.1875e-01, -6.7923e+00,
         -3.2420e-01, -2.3551e-01, -4.9267e+00,  1.4850e+01,  6.7298e-01,
         -4.8773e-01, -6.7906e+00, -1.3349e+00,  6.0992e-02, -1.4015e+00],
        [-3.8643e-01, -1.7611e+00, -1.0918e+00, -3.0258e-01, -4.3695e-02,
          1.9345e+00, -9.9477e-01, -1.7611e+00, -2.9798e-01, -2.9282e+00,
          4.5133e+00, -4.3715e-02, -1.3415e+00,  4.0768e+00, -1.1891e+00]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-2.8070, -4.7769, -2.5243,  0.7929,  3.8230, -6.5401, -3.2089, -1.2530,
        -3.2130, -2.6533, -2.6172,  0.2571, -2.5708, -2.7257, -3.1873],
       device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[  1.0635,  -5.5920,   0.0733,  -0.8111,   0.4521,   0.3530,   1.5220,
          -0.4866,   1.9396,   4.2759,   1.2859,   2.0525,   3.4450,   0.9369,
           0.8798],
        [ -0.9605,   5.5976,  -0.0407,   0.9319,   0.9629,   0.2867,  -0.2991,
           0.8529,  -1.9219,  -4.2598,  -1.1637,  -0.4867,  -3.4038,  -0.8470,
          -0.8546],
        [ -0.3972,  -0.0285,  -0.0904,  -0.9861,  -8.9487,  -0.7791,  -1.3612,
          -2.2214,  -0.0185,  -0.0474,  -1.0359,  -4.3716,  -0.2013,  -0.1086,
          -0.0225],
        [ -4.6094,   7.2359,   0.1194,  10.0576,   0.3820,   1.0592,  -4.0585,
           4.1392,  -4.1025,  -3.4858,  -4.9724,  -7.3527,  -9.2409,   0.2361,
          -4.0505],
        [ -2.9471,   3.7142,  -0.0405,  -0.5535,  11.3716,   0.6228,  -2.9384,
           3.0117,  -4.8533,  -5.7442,  -2.7695,   1.7722,  -6.2335,  -0.2954,
          -4.2462],
        [ -4.3527,   2.9031,   0.2046,   6.1032,   7.6791, -15.0343,  -1.4839,
           2.9796,  -5.3791,  -5.6909,  -4.2971,  -6.6340,  -3.5892,   4.3087,
          -5.2148],
        [ -1.0144,   2.0637,  -0.3585,   9.4855,  10.3823,   0.7508,  -4.7871,
           5.4285,  -0.0253,   0.1572,  -1.2787,  -2.8974,   0.2061,   1.2356,
          -0.0643]], device='cuda:0'))])
xi:  [338.5381]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 492.0370127342881
W_T_median: 463.8210037170804
W_T_pctile_5: 338.51918900455667
W_T_CVAR_5_pct: 183.94863496038795
Average q (qsum/M+1):  52.068142798639116
Optimal xi:  [338.5381]
Expected(across Rb) median(across samples) p_equity:  0.1480005139717832
obj fun:  tensor(-1798.0610, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/constrain_factor/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/constrain_factor/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: Paper_FactorInv_Factor4
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
