Starting at: 
02-06-23_11:36

 numpy seed:  3  


 pytorch seed:  3  

Key parameters-------
paths: 256000
iterations: 10000
batchsize: 1000
remove neg:  False
w constaint activation:  yy_fix_jan29


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
               CPI  CPI_nom_ret  ...  VWD_real_ret  EWD_real_ret
date                             ...                            
192512  100.000000          NaN  ...           NaN           NaN
192601  100.000000     0.000000  ...      0.000561      0.023174
192602  100.000000     0.000000  ...     -0.033046     -0.053510
192603   99.441303    -0.005587  ...     -0.058743     -0.091750
192604  100.000000     0.005618  ...      0.031235      0.027204

[5 rows x 12 columns]
                CPI  CPI_nom_ret  ...  VWD_real_ret  EWD_real_ret
date                              ...                            
202008  1452.055956     0.003153  ...      0.065084      0.035618
202009  1454.078149     0.001393  ...     -0.036399     -0.028709
202010  1454.681696     0.000415  ...     -0.020584      0.000169
202011  1453.793232    -0.000611  ...      0.124393      0.175130
202012  1455.162018     0.000942  ...      0.044065      0.071843

[5 rows x 12 columns]


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_nom_ret', 'VWD_nom_ret']
############# End: defined asset  basket #################
        CPI_nom_ret  B10_nom_ret  VWD_nom_ret
date                                         
192601     0.000000     0.004350     0.000561
192602     0.000000     0.004338    -0.033046
192603    -0.005587     0.004327    -0.064002
192604     0.005618     0.004316     0.037029
192605    -0.005587     0.004304     0.012095
        CPI_nom_ret  B10_nom_ret  VWD_nom_ret
date                                         
202008     0.003153    -0.014709     0.068443
202009     0.001393     0.002560    -0.035057
202010     0.000415    -0.017311    -0.020178
202011    -0.000611     0.004016     0.123706
202012     0.000942    -0.004965     0.045048
Indices constructed with column names:
Index(['date_for_plt', 'CPI_nom_ret_ind', 'B10_nom_ret_ind',
       'VWD_nom_ret_ind'],
      dtype='object')
############# Updated: defined asset basket #################
timeseries_basket['data_df_mean'] = 
B10_real_ret    0.001986
VWD_real_ret    0.006974
dtype: float64


timeseries_basket['data_df_stdev'] = 
B10_real_ret    0.018939
VWD_real_ret    0.053569
dtype: float64


timeseries_basket['data_df_corr'] = 
              B10_real_ret  VWD_real_ret
B10_real_ret      1.000000      0.075353
VWD_real_ret      0.075353      1.000000


timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names', 'data_df', 'data_df_mean', 'data_df_stdev', 'data_df_corr'])
############# End: updated: defined asset basket #################
-----------------------------------------------
Dates to be REMOVED due to missing values (should be at *start* only due to trading signals):
Int64Index([], dtype='int64')
-----------------------------------------------
Dates from available data for bootstrapping:
Start: 192601
End: 202012
-----------------------------------------------
Bootstrap block size: 12
-----------------------------------------------
Dates USED bootstrapping:
Start: 192601
End: 201912
-----------------------------------------------
0.0% of bootstrap sample done.
5.0% of bootstrap sample done.
10.0% of bootstrap sample done.
15.0% of bootstrap sample done.
20.0% of bootstrap sample done.
25.0% of bootstrap sample done.
30.0% of bootstrap sample done.
35.0% of bootstrap sample done.
40.0% of bootstrap sample done.
45.0% of bootstrap sample done.
50.0% of bootstrap sample done.
55.00000000000001% of bootstrap sample done.
60.0% of bootstrap sample done.
65.0% of bootstrap sample done.
70.0% of bootstrap sample done.
75.0% of bootstrap sample done.
80.0% of bootstrap sample done.
85.0% of bootstrap sample done.
90.0% of bootstrap sample done.
95.0% of bootstrap sample done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 1000, 'itbound_SGD_algorithms': 10000, 'nit_IterateAveragingStart': 9000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ 0.1286, -0.1987],
        [ 0.1286, -0.1987],
        [ 0.1286, -0.1987],
        [ 0.1286, -0.1987],
        [ 0.1286, -0.1987],
        [ 0.1286, -0.1987],
        [ 0.1286, -0.1987],
        [ 0.1286, -0.1987],
        [ 0.1286, -0.1987],
        [ 0.1286, -0.1987]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([0.2330, 0.2330, 0.2330, 0.2330, 0.2330, 0.2330, 0.2330, 0.2330, 0.2330,
        0.2330], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470,
         0.2470],
        [0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470,
         0.2470],
        [0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470,
         0.2470],
        [0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470,
         0.2470],
        [0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470,
         0.2470],
        [0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470,
         0.2470],
        [0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470,
         0.2470],
        [0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470,
         0.2470],
        [0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470,
         0.2470],
        [0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470, 0.2470,
         0.2470]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([0.4005, 0.4005, 0.4005, 0.4005, 0.4005, 0.4005, 0.4005, 0.4005, 0.4005,
        0.4005], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-1.7688, -1.7688, -1.7688, -1.7688, -1.7688, -1.7688, -1.7688, -1.7688,
         -1.7688, -1.7688]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 14.3071,   8.9954],
        [-27.3132,  -3.1232],
        [ 12.0633,  -2.6311],
        [ -1.7024,   0.4812],
        [-11.4305,   3.2591],
        [-22.9057,   2.3158],
        [ -3.0329,  16.1110],
        [ -2.1153,   3.9878],
        [ -1.7022,   0.4661],
        [ 14.3706,  23.1320]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([  4.1046,  16.1419, -12.4736,  -3.7949,   1.7351,  23.9689,  12.8677,
         -5.0090,  -3.8115,  16.4730], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-2.7733e+00,  1.5692e+00, -1.4278e+00, -9.5870e-02, -1.6441e+00,
         -2.1698e+00,  1.9237e+00, -4.2273e-01, -8.6045e-02,  1.0862e+00],
        [ 1.0069e+01, -9.8813e-01,  6.7221e-01,  3.8218e-02,  4.1513e+00,
         -1.6795e+00,  1.7912e+01,  2.3897e-02,  3.8220e-02,  1.7208e+00],
        [-3.2569e+00,  1.9828e+00,  1.4897e+00,  1.4046e-02, -1.1228e+00,
         -2.1014e+00,  4.9266e+00, -8.2885e-01,  3.1819e-02, -2.7258e-02],
        [-1.7446e+01,  1.0915e+01, -7.1271e+00, -4.5272e-02, -1.1678e+00,
          4.4786e+00, -1.0501e+01, -5.0717e-03, -4.9866e-02, -2.0494e+01],
        [-3.1059e+00, -4.5329e-01, -1.1084e+01,  8.0550e-02, -5.1100e+00,
         -2.0669e+00,  2.2020e+00,  1.9195e+00,  4.8091e-02,  4.9407e+00],
        [-2.7151e+00,  1.2689e+00, -5.9608e-01, -1.8189e-01, -5.0935e+00,
         -2.0358e+00,  2.9646e+00,  3.2088e+00, -1.3078e-01,  2.8209e+00],
        [-1.3108e-01, -3.1295e-01,  1.0464e+00,  1.6180e-01,  6.3027e-01,
         -2.4032e+00,  9.5382e-01,  5.6659e-01,  1.5917e-01, -3.2053e+00],
        [-2.0771e+00,  7.0294e-01, -3.3688e-01, -5.2928e-02,  6.9871e-01,
         -8.8556e-01,  1.6547e+00,  2.8458e-01, -3.4137e-02, -1.5123e+00],
        [-8.0526e+00,  2.8233e+00, -4.9481e-01,  4.0104e-01, -1.7294e+00,
          7.8355e+00, -8.5186e+00,  9.8750e-02,  3.7656e-01, -6.7861e+00],
        [-3.8605e+01,  3.0973e+00, -1.2227e+01, -5.1517e-01,  3.0994e+00,
          1.9489e+00, -1.0392e+01, -1.2594e-02, -4.7543e-01, -1.1490e+01]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-5.0432, -9.1847, -4.9500, -5.8588, -5.5584, -6.3836, -4.1148, -4.1329,
        -3.2904, -3.2890], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[  2.1611,   0.4604,   3.5708,  -8.5474,   4.9514,   3.1938,   1.8529,
           0.8438,  -0.5662,  20.3362],
        [ -2.1611,  -0.5005,  -3.5709,   8.5432,  -4.9514,  -3.1938,  -1.8530,
          -0.8438,   0.4854, -20.3335]], device='cuda:0'))])
loaded xi:  217.09328
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1454.3079541656982
W_T_median: 1099.4362368042316
W_T_pctile_5: -130.52069429807673
W_T_CVAR_5_pct: -291.87227415269723
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -13.483659682879905
Current xi:  [216.94237]
objective value function right now is: -13.483659682879905
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -16.10941662678962
Current xi:  [216.96608]
objective value function right now is: -16.10941662678962
6.0% of gradient descent iterations done. Method = Adam
Current xi:  [215.97476]
objective value function right now is: -14.835810602794707
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -16.258976649113283
Current xi:  [215.83818]
objective value function right now is: -16.258976649113283
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -16.446330067035063
Current xi:  [215.09006]
objective value function right now is: -16.446330067035063
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [214.82614]
objective value function right now is: -14.45440361623002
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [215.05368]
objective value function right now is: -15.769480757099123
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [215.05951]
objective value function right now is: -14.877635877995013
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [214.85701]
objective value function right now is: -16.07871504346638
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [215.16628]
objective value function right now is: -16.269686255937614
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.50182]
objective value function right now is: -16.33792601949853
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.02841]
objective value function right now is: -14.907377362401833
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [214.16676]
objective value function right now is: -14.493283230255562
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [214.40952]
objective value function right now is: -8.409840501592768
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.58028]
objective value function right now is: -14.256284737566599
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [214.20921]
objective value function right now is: -16.19153192693114
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [214.0586]
objective value function right now is: -13.600945782629372
36.0% of gradient descent iterations done. Method = Adam
new min fval:  -16.582017363365782
Current xi:  [213.03946]
objective value function right now is: -16.582017363365782
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.15001]
objective value function right now is: -14.405430816656779
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.06482]
objective value function right now is: -15.11544630371036
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.36467]
objective value function right now is: -15.763155117933051
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.50371]
objective value function right now is: -12.843637476527395
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.07687]
objective value function right now is: -11.772435654148358
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.50626]
objective value function right now is: -13.29953239862548
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [212.74254]
objective value function right now is: -16.048993252040958
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [212.90099]
objective value function right now is: -15.64262471808786
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.91501]
objective value function right now is: -16.14497573187847
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [214.30605]
objective value function right now is: -15.016778033493019
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [213.44499]
objective value function right now is: -14.544446885891718
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.98694]
objective value function right now is: -13.3491527172875
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [214.28325]
objective value function right now is: -16.57744085993166
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [214.13942]
objective value function right now is: -13.079852268828576
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [212.80695]
objective value function right now is: -15.147711164783017
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [212.41447]
objective value function right now is: -14.003121050809918
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.02922]
objective value function right now is: -16.048510661834495
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -17.642793796993203
Current xi:  [213.01595]
objective value function right now is: -17.642793796993203
74.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.02826]
objective value function right now is: -17.11806330660308
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.14302]
objective value function right now is: -17.401680523404263
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.29012]
objective value function right now is: -17.159423924339894
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.43765]
objective value function right now is: -17.58782774885344
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.53268]
objective value function right now is: -17.41469194254012
84.0% of gradient descent iterations done. Method = Adam
new min fval:  -17.73913425936641
Current xi:  [213.43422]
objective value function right now is: -17.73913425936641
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.45235]
objective value function right now is: -16.81719780296374
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.5655]
objective value function right now is: -17.340042118502975
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.616]
objective value function right now is: -16.626200061938476
new min fval from sgd:  -17.7471184296418
new min fval from sgd:  -17.78987144329063
new min fval from sgd:  -17.827202195282737
new min fval from sgd:  -17.83834091520976
new min fval from sgd:  -17.860386993416608
new min fval from sgd:  -17.88016351961206
new min fval from sgd:  -17.895118285079196
new min fval from sgd:  -17.913612665214597
new min fval from sgd:  -17.932592335878287
new min fval from sgd:  -17.94956375259112
new min fval from sgd:  -17.959946654397655
new min fval from sgd:  -17.96091097267143
new min fval from sgd:  -17.96129689853877
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.57207]
objective value function right now is: -17.832780939837715
new min fval from sgd:  -17.962368685830636
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.64088]
objective value function right now is: -17.69778592449954
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.66093]
objective value function right now is: -17.473802388047602
new min fval from sgd:  -17.982871975151
new min fval from sgd:  -17.989981353700955
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.85512]
objective value function right now is: -17.89467546545216
new min fval from sgd:  -17.9915983604893
new min fval from sgd:  -17.99276874449522
new min fval from sgd:  -17.993977442167886
new min fval from sgd:  -17.995608538044436
new min fval from sgd:  -17.998332680484488
new min fval from sgd:  -17.99834919737822
new min fval from sgd:  -18.000160793586584
new min fval from sgd:  -18.002346612944514
new min fval from sgd:  -18.00622511068137
new min fval from sgd:  -18.00994798145633
new min fval from sgd:  -18.015897535634053
new min fval from sgd:  -18.020159478336375
new min fval from sgd:  -18.02298025511499
new min fval from sgd:  -18.025277871546635
new min fval from sgd:  -18.026759708279016
new min fval from sgd:  -18.028298013686562
new min fval from sgd:  -18.0297423186574
new min fval from sgd:  -18.033750556239855
new min fval from sgd:  -18.036856560282068
new min fval from sgd:  -18.03995961173439
new min fval from sgd:  -18.04181380658123
new min fval from sgd:  -18.04396751457553
new min fval from sgd:  -18.04507895640483
new min fval from sgd:  -18.046375005480066
new min fval from sgd:  -18.048946239548062
new min fval from sgd:  -18.05003580725607
new min fval from sgd:  -18.051004194473652
new min fval from sgd:  -18.051575914539683
new min fval from sgd:  -18.052627696030054
new min fval from sgd:  -18.05389591692502
new min fval from sgd:  -18.05508719751675
new min fval from sgd:  -18.05543304563338
new min fval from sgd:  -18.056436776946235
new min fval from sgd:  -18.058943111130436
new min fval from sgd:  -18.06189087402421
new min fval from sgd:  -18.064835049501152
new min fval from sgd:  -18.067332232934092
new min fval from sgd:  -18.071637026754573
new min fval from sgd:  -18.07534952777526
new min fval from sgd:  -18.0783731142439
new min fval from sgd:  -18.080093210572784
new min fval from sgd:  -18.08149992974013
new min fval from sgd:  -18.082499141568093
new min fval from sgd:  -18.08294172224049
new min fval from sgd:  -18.083490936265996
new min fval from sgd:  -18.083702443424688
new min fval from sgd:  -18.0837132445435
new min fval from sgd:  -18.08465047123083
new min fval from sgd:  -18.084654962253662
new min fval from sgd:  -18.08497987179299
new min fval from sgd:  -18.08692438457631
new min fval from sgd:  -18.08733757537376
new min fval from sgd:  -18.087882917853346
new min fval from sgd:  -18.089504026162537
new min fval from sgd:  -18.09021063318269
new min fval from sgd:  -18.091424082300488
new min fval from sgd:  -18.092664918201766
new min fval from sgd:  -18.09474053161815
new min fval from sgd:  -18.096104438110856
new min fval from sgd:  -18.096714880762846
new min fval from sgd:  -18.097825526645696
new min fval from sgd:  -18.099215415193292
new min fval from sgd:  -18.100397591957485
new min fval from sgd:  -18.101014248934465
new min fval from sgd:  -18.101876701452944
new min fval from sgd:  -18.102575507000424
new min fval from sgd:  -18.104137732464523
new min fval from sgd:  -18.105701954467186
new min fval from sgd:  -18.108815111335016
new min fval from sgd:  -18.10979952484915
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [213.85606]
objective value function right now is: -18.10229308161882
min fval:  -18.10979952484915
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ 0.1283, -0.2133],
        [ 0.1283, -0.2133],
        [ 0.1283, -0.2133],
        [ 0.1283, -0.2133],
        [ 0.1283, -0.2133],
        [ 0.1283, -0.2133],
        [ 0.1283, -0.2133],
        [ 0.1283, -0.2133],
        [ 0.1283, -0.2133],
        [ 0.1283, -0.2133]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([0.2286, 0.2286, 0.2286, 0.2286, 0.2286, 0.2286, 0.2286, 0.2286, 0.2286,
        0.2286], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463,
         0.2463],
        [0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463,
         0.2463],
        [0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463,
         0.2463],
        [0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463,
         0.2463],
        [0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463,
         0.2463],
        [0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463,
         0.2463],
        [0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463,
         0.2463],
        [0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463,
         0.2463],
        [0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463,
         0.2463],
        [0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463, 0.2463,
         0.2463]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([0.3959, 0.3959, 0.3959, 0.3959, 0.3959, 0.3959, 0.3959, 0.3959, 0.3959,
        0.3959], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-1.7694, -1.7694, -1.7694, -1.7694, -1.7694, -1.7694, -1.7694, -1.7694,
         -1.7694, -1.7694]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 14.0371,   8.2507],
        [-28.2078,  -4.0123],
        [ 12.1110,  -1.7123],
        [ -1.6621,   1.4132],
        [ -6.9634,   5.1855],
        [-23.7778,   1.3387],
        [ -4.9703,  15.5230],
        [  1.7264,   6.3933],
        [ -1.6622,   1.4130],
        [ 12.6220,  22.0068]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([  4.8193,  15.2312, -11.3138,  -3.6880,  -2.0633,  23.9967,  14.1845,
         -4.5971,  -3.6883,  17.5477], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-2.7645e+00, -6.2700e-01, -4.3619e-01, -1.9171e-01, -2.1620e-01,
         -2.2485e+00,  1.7961e+00, -1.4316e+00, -1.9180e-01,  2.9441e-01],
        [ 9.8821e+00, -7.4543e-01,  9.4982e-01,  1.0171e-01, -1.7068e-02,
         -3.2439e+00,  1.7036e+01, -2.1977e-02,  1.0166e-01,  3.6920e+00],
        [-3.3954e+00,  1.2326e+00, -4.8393e-01,  5.2098e-01, -2.6948e-01,
         -2.0151e+00,  5.8490e+00, -4.8347e+00,  5.2092e-01,  1.2771e+00],
        [-1.7356e+01,  1.1054e+01, -4.6534e+00, -1.8929e-01,  1.1736e-01,
          4.8691e+00, -9.7716e+00, -5.8948e-03, -1.8918e-01, -2.3150e+01],
        [-4.1855e+00, -1.4169e-01, -1.2403e+01,  3.9405e-02, -5.7236e+00,
         -1.9651e+00,  4.1014e+00,  9.8227e-01,  3.9105e-02,  4.5297e+00],
        [-2.7858e+00, -2.8084e-01, -6.9298e-01, -8.9520e-03,  4.8624e-03,
         -2.5038e+00,  1.5449e+00, -4.7462e-01, -9.0273e-03,  9.1388e-01],
        [-2.1301e+00, -4.8977e-01, -1.3853e+00,  4.6070e-03, -1.7389e-01,
         -1.8939e+00, -4.0177e-01, -2.1654e-01,  4.6027e-03, -7.1049e-01],
        [-2.1947e+00, -4.8750e-01, -1.3404e+00,  2.5058e-02, -1.7592e-01,
         -1.9726e+00, -4.3733e-01, -2.1650e-01,  2.5061e-02, -7.2293e-01],
        [-8.9176e+00,  4.6081e+00, -1.6903e-01,  1.3376e-01,  5.8964e-03,
          7.6718e+00, -1.0934e+01, -1.1120e-02,  1.3356e-01, -7.6865e+00],
        [-3.8499e+01,  3.2852e+00, -1.6947e+01, -4.2928e-01,  1.5696e-01,
          2.1657e+00, -1.0321e+01,  7.6751e-04, -4.2921e-01, -4.3666e+00]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-3.9627, -9.4715, -6.0044, -4.9008, -5.6303, -5.3817, -3.2668, -3.1708,
        -3.2229, -2.9241], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[  0.9818,   0.3565,   3.2000,  -8.4059,   4.6120,   0.7019,   0.1283,
           0.1499,  -0.5355,  18.9227],
        [ -0.9818,  -0.3966,  -3.2000,   8.3987,  -4.6120,  -0.7019,  -0.1283,
          -0.1499,   0.4550, -18.9198]], device='cuda:0'))])
xi:  [213.86139]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 1294.4005863759808
W_T_median: 993.631077433507
W_T_pctile_5: 214.8999903493055
W_T_CVAR_5_pct: 18.113977942577204
Average q (qsum/M+1):  35.0
Optimal xi:  [213.86139]
Expected(across Rb) median(across samples) p_equity:  0.2498524044950803
obj fun:  tensor(-18.1098, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/testing_pyt_decum/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/testing_pyt_decum/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 999.0
-----------------------------------------------
