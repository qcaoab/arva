tracing parameter entered from terminal:  0.6


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1596.8227901478413
gradient value of function right now is: [ 7.15459886e-01  2.34405420e+00  4.31840014e-01  2.14296799e-01
 -7.15459886e-01 -2.34405420e+00 -4.31840014e-01 -2.14296799e-01
  8.02348951e-01  4.74594202e-01  6.86566291e-01  3.09773057e-01
 -2.24598181e-01 -4.17285384e-01 -7.65026456e-01 -3.08352999e-01
 -1.13307642e-01 -3.02810767e-01 -7.61664808e-01 -2.46652314e-01
 -4.92919415e-02 -1.42762066e-01 -4.59793421e-01 -1.37285073e-01
  8.00787435e-02  5.11236417e-01  4.11344236e-01  2.83601784e-03
 -4.80122976e-01  1.15982196e+00 -8.93976151e-01  1.01494342e-01
  1.39505737e-01  1.23546980e+00 -7.16191843e-02  3.76960692e-02
  4.05637268e-02  3.20081591e-01 -1.20512683e-02  7.12540930e-03
 -8.17009774e-02 -4.09089824e-01 -1.44322308e-01 -1.01850891e-01
 -6.10134960e-01 -1.14674221e+00 -1.15881225e+00 -6.57173437e-01
  8.32051747e-01  1.28055547e+00 -1.00759096e-01  1.00224319e+00
  2.19063604e-02 -2.44516146e-01  4.50805664e-01 -5.21022573e-03
  1.52118332e+00  1.01193038e+00  1.26009820e+00 -2.48338592e+00
 -8.39470805e-01  3.53180844e-02  1.10187541e+00  3.46053272e-02
 -1.49972758e+01]
supnorm grad right now is: 14.997275825881061
Weights right now are: 
[-2.20388646  0.79758338  3.44965114  3.46545583  2.45845517 -0.90627507
 -3.05071387 -4.18148421 -2.01878141  9.72335898  3.7648692   1.35123343
  4.97799046  4.69309718 -1.4569681  -0.93987471  5.07784229  5.92057397
  3.91245532  2.09556401  6.09672164  6.26681161  5.56429151  4.12873015
  6.10382612  6.01579763 -1.90758385 11.84647494 -2.25676682  3.2919028
  2.46406934 -6.554788    3.61736916  0.12623887  3.40600601 19.60968113
  4.23345184  2.41649514  4.48618766 17.48504275  8.18505151  0.11256116
  0.93702705  6.99808753  4.97812125  0.33557468 -4.62871985  2.89252412
 -4.42662189  3.94593791  5.5477529  -1.65022802 12.48959638 10.16908267
 -4.29296688 12.65017478  3.39787961 -1.66834441 -1.01228762 -1.95886369
  5.08685342  1.00816059  2.59562034 -1.89688178 30.3936737 ]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.5765706008349
gradient value of function right now is: [ 2.47590536e-01  2.07297154e+00  4.82726721e-01  3.86007877e-01
 -2.47590536e-01 -2.07297154e+00 -4.82726721e-01 -3.86007877e-01
 -1.55042982e-01  3.16248176e-01  4.73001743e-01  8.98027257e-02
 -1.23499005e-01 -1.28682982e+00 -1.44868170e+00 -1.89485911e-01
 -7.41725566e-03 -5.17158787e-01 -4.96110773e-01 -2.24412236e-02
 -5.69354731e-03 -4.77229998e-01 -4.43362470e-01 -1.81143669e-02
  1.48549623e-02  1.49177995e-01 -1.12585181e-01  6.07093836e-05
  8.89055466e-01  3.33453842e+00  6.03280331e-01  1.39578803e-01
  3.33032435e-01  1.69862104e+00  1.20875625e-01  1.70070756e-02
  1.26145571e-02  3.53428303e-02 -7.65334685e-02  1.33228785e-04
 -5.65044625e-02 -5.85581031e-01 -1.13644003e-01 -8.61743679e-02
 -4.95480685e-01 -4.50249173e+00 -7.29053389e-01 -8.20722761e-01
 -4.54765992e-01 -1.24069657e+00 -2.28714611e-01 -5.48499902e-01
 -6.14464077e-03 -2.82930910e-02  1.32825696e-01 -1.60705894e-02
  1.25400902e+00 -1.20424836e+00  1.27928664e+00 -9.25621440e-01
 -3.07278699e-01  6.00263657e-01  1.77110852e+00 -7.39914811e-01
 -1.17597435e+01]
supnorm grad right now is: 11.759743510045858
Weights right now are: 
[-2.3586283   1.62950402  2.91427556  2.7357448   2.61319701 -1.73819571
 -2.51533829 -3.45177319 -3.36902396 10.40193497  5.27772958 -6.43808906
  4.64824772  5.44180023  0.64057748 -3.20892807  8.40670607  7.11530329
  5.63724932  5.03000846 10.13477467  7.37983966  6.44771422  7.05320389
 11.47541196 11.60452873 -1.20765977 29.28251187 -2.11576268  3.38374572
  2.77110809 -7.14538425  7.90017136  0.31855932  9.53917297 26.25403275
  7.60103216  8.60287705  6.48449219 34.28407433 12.38000601  1.07537587
  0.76839945 12.14415674  6.27740705  0.15171217 -4.81194694  3.54436121
 -4.63972496  5.19172867  9.06956886 -1.95494575 15.10843417 11.69323588
 -4.03940644 17.0191533   4.26783531 -1.81605818 -1.79679215 -2.15657892
  5.6641309   0.8789939   2.78323228 -2.43617257 30.47087605]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1596.1319512346504
gradient value of function right now is: [ 5.60437883e-01  2.42605015e+00  5.27363032e-01  4.13013574e-01
 -5.60437883e-01 -2.42605015e+00 -5.27363032e-01 -4.13013574e-01
  5.57333142e-01  7.71609397e-01  7.86957253e-01  3.69416869e-01
 -8.22911014e-02 -2.43198124e+00 -4.18476523e+00 -8.38625996e-02
 -2.37349699e-03 -3.53276435e-01 -4.25601596e-01 -2.29630220e-03
 -1.07753317e-03 -2.76681255e-01 -2.93135686e-01 -1.11989385e-03
  1.28476798e-03  6.67216157e-02  1.05190779e-01  6.58615348e-07
  1.02724190e+00  4.24933159e+00  4.27618535e-02 -7.87073283e-02
  2.57532121e-01  2.49339300e+00  5.99268133e-03  2.60589455e-02
 -7.34193895e-04 -3.41959020e-03  1.05871664e-01  1.11052951e-07
 -6.69388312e-02 -4.70410462e-01 -1.96052216e-01 -9.59619093e-02
 -6.95724171e-01 -5.18348939e+00 -1.13032936e+00 -1.27019250e+00
  2.16865131e-01 -2.39916061e-01 -1.66522597e-01  2.54466270e-01
 -1.40222989e-01 -5.89460855e-02 -8.13293110e-01 -7.27047318e-02
  1.58478078e+00 -2.73796103e+00  1.26636829e+00 -2.64364326e+00
 -7.83858240e-01  2.01714513e+00  2.35146976e+00 -2.65711053e+00
 -2.22593775e+01]
supnorm grad right now is: 22.259377509853714
Weights right now are: 
[-3.07615884  3.1659163   2.42127583  1.88121101  3.33072755 -3.27460799
 -2.02233856 -2.59723939 -3.87603447 11.848399    5.94126564 -9.63162274
  7.44979392  5.41855675  1.54220657 -2.26643703  8.0089791   7.89280375
  6.46573248 -0.43090957  8.76481023  8.30999597  7.53061583  1.50193939
 25.83025093 19.51999068 -0.56608177 35.30612128 -2.70201719  3.74326511
  3.66338035 -7.29988279 11.82102761 -0.288395   13.19430671 30.25539372
 -1.59057102 19.15988606 10.03503288 38.86037326 14.59438835  1.59969364
  0.83118343 16.08213159  6.51168843  0.52583983 -5.34371088  3.92723271
 -6.25732631  7.08119926 11.88170135 -1.18717759 15.15968304 14.27192079
 -4.24985864 21.18476212  4.87287444 -1.74081881 -2.1440542  -2.38327946
  6.47946936  0.92037536  2.33133717 -2.68890477 30.33731473]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.7641579566289
gradient value of function right now is: [ 2.08276405e-01  4.63765000e-02  1.68604435e-01  1.39915445e-01
 -2.08276405e-01 -4.63765000e-02 -1.68604435e-01 -1.39915445e-01
  2.84236998e-01  3.52085877e-01  1.96445406e-01  2.31327614e-01
  1.62062456e-02  3.13710500e-02  1.29808648e+00  4.65391031e-02
  7.33268166e-05 -1.15143852e-01  6.84974999e-03  5.75017463e-04
  4.04632744e-06 -1.05209037e-01 -5.70285240e-03  1.95887873e-04
 -1.69388303e-04 -1.93825927e-02  1.66123022e-02 -2.26213691e-08
  6.97627630e-01  1.73739361e+00  1.06285949e-01  6.88218754e-01
 -5.79881590e-02 -3.30969661e-01 -3.49801035e-02  1.54792807e-02
  2.07319769e-03  2.66618034e-02  4.78994531e-02 -8.75352938e-06
  6.08001126e-02  5.48231956e-01  4.34644641e-01  6.78772787e-02
 -2.16978322e-02  1.83186424e+00 -7.00384076e-01  2.40113070e-01
  9.47067128e-02  2.03607445e-01 -4.57288877e-02  1.57731499e-01
  1.49294519e-01  4.01722480e-01  1.14500554e+00  8.76999392e-02
 -6.71411969e-01  2.67669647e+00 -2.15819249e+00  5.80662140e+00
  3.52076013e-01 -1.61419602e+00 -1.77201493e+00  2.73027497e+00
  6.20220802e+00]
supnorm grad right now is: 6.2022080217793665
Weights right now are: 
[ -3.00198847   4.41248292   2.12785837   1.63067829   3.25655719
  -4.52117461  -1.7289211   -2.34670668  -3.73679076  12.88070258
   6.75483171 -10.45999259  10.35335346   5.74774042   2.15693501
  -3.54896666  12.63039415   9.93585935   8.24111565  -6.37547326
  14.2587148   10.8834281   12.65785385  -4.71154343  40.8357026
  25.47836538  -0.96773785  35.41008456  -3.62060068   3.90610899
   3.99607264  -7.3969788   15.44503285  -0.68838132  17.85037628
  30.71171157 -11.65862801  18.72896084  11.02273386  39.43250608
  14.32865481   2.35133014   0.46348187  17.0506931    6.62068092
   0.4657881   -4.93429092   4.38724498  -8.06319653   8.41363581
  13.35505135  -1.03030909  13.88442012  15.28982311  -4.70107532
  24.17060157   4.91264067  -1.83630181  -1.90841577  -2.40283984
   6.96081137   0.94458665   2.62124003  -2.77035301  30.60712474]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.8225623975854
gradient value of function right now is: [ 1.64311984e-01  3.70227228e-01  1.30000131e-01  1.33496951e-01
 -1.64311984e-01 -3.70227228e-01 -1.30000131e-01 -1.33496951e-01
  4.18699879e-02  9.97783989e-02 -6.65210912e-02 -4.42688433e-02
  6.45106295e-03 -6.80720699e-01  4.33688079e-01  1.69295201e-02
 -2.42976022e-06 -6.11214145e-02  3.14216089e-03  4.44378112e-05
 -2.30783189e-06 -1.10425223e-01  2.86913372e-03  4.94634103e-05
 -1.32377010e-05 -7.43754904e-03  4.27114541e-02  1.21164953e-09
  1.21074582e+00  3.44474945e+00  1.37171137e-01  1.27878510e+00
 -1.00463214e-01 -1.09362483e-01 -1.27795570e-02  1.15900329e-02
  5.63379917e-04  2.33901825e-03  3.06063660e-02 -1.93886776e-05
  1.29781877e-01  9.91346181e-01  1.03233811e+00  7.95695673e-02
 -1.88006573e-01  2.30041362e+00 -1.43871064e+00  1.01083935e-01
  1.13690051e-01  1.06853791e-01 -9.24139498e-02  1.22615809e-01
  2.98847243e-01  6.08462612e-01  2.35901859e+00  1.29069239e-01
 -1.25806994e+00  4.82363613e+00 -3.45710215e+00  1.10315109e+01
  4.95916996e-01 -2.93488418e+00 -1.78676968e+00  4.54394356e+00
  5.52057974e+00]
supnorm grad right now is: 11.031510895932227
Weights right now are: 
[-3.17318335e+00  4.87058168e+00  1.60080400e+00  2.03600866e+00
  3.42775206e+00 -4.97927337e+00 -1.20186673e+00 -2.75203704e+00
 -3.45621496e+00  1.34025357e+01  6.29629404e+00 -1.16846284e+01
  1.26154296e+01  5.94816072e+00  2.27825420e+00 -3.56708167e+00
  1.74946297e+01  1.44495801e+01  1.60279918e+01 -8.35322193e+00
  1.86056825e+01  1.44949285e+01  2.14545805e+01 -7.12462907e+00
  5.48959655e+01  2.85294994e+01 -5.36784864e-02  3.54357805e+01
 -4.29144083e+00  4.29374850e+00  4.70889108e+00 -7.04018595e+00
  1.80442100e+01 -6.40667189e-01  2.25487988e+01  3.11616926e+01
 -1.53953221e+01  2.02056171e+01  1.24745650e+01  4.48435720e+01
  1.40270237e+01  3.20751799e+00  1.56371076e-01  1.81204995e+01
  6.40272269e+00  3.20316323e-01 -4.93095105e+00  4.14492667e+00
 -8.91102639e+00  9.58163136e+00  1.39413038e+01 -8.46295020e-01
  1.34866650e+01  1.67653530e+01 -4.37063980e+00  2.70089128e+01
  4.49244493e+00 -1.92038301e+00 -2.24201572e+00 -2.52065743e+00
  6.95477168e+00  9.23180386e-01  2.91607178e+00 -2.93975472e+00
  3.06132117e+01]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.4499964988456
gradient value of function right now is: [ 3.14531530e-01  1.05306270e+00  3.38765819e-02  3.41975971e-02
 -3.14531530e-01 -1.05306270e+00 -3.38765819e-02 -3.41975971e-02
  3.22442726e-01  4.51836312e-01  5.06879909e-01  3.14868713e-01
 -2.88673114e-03 -1.22292779e+00 -2.69942904e+00 -8.17320567e-03
  8.34975484e-08 -8.64796591e-03 -5.54336164e-03 -1.72710849e-06
  1.12727240e-07 -1.55299037e-02 -8.46298143e-03 -3.39977855e-06
  5.77944952e-06  6.21095126e-03 -6.85150763e-04  7.21564128e-10
  2.65633355e-01  2.11713316e+00  3.13746163e-02 -9.85950819e-03
  9.65848002e-02  1.64386553e+00 -4.06527387e-03  1.64830787e-02
 -7.81712708e-05  4.08838787e-03  2.53910799e-02 -2.06482487e-06
 -6.73026460e-02 -4.27189898e-01 -2.35603899e-01 -6.23068880e-02
 -2.72598445e-01 -2.56747765e+00 -4.54958750e-01 -4.87349275e-01
 -1.72746804e-02 -1.03660009e-01 -4.74163286e-02  2.41609743e-02
 -5.00865525e-02 -4.90013862e-02 -2.57377745e-01 -2.29262528e-02
  8.31803305e-01 -1.04617080e+00  8.71367995e-01 -1.77844011e+00
 -2.91353698e-01  9.93423467e-01  1.27718501e+00 -1.48042406e+00
 -9.21373748e+00]
supnorm grad right now is: 9.213737480660772
Weights right now are: 
[-2.93739578e+00  5.00901233e+00  1.80959922e+00  2.29372032e+00
  3.19196449e+00 -5.11770402e+00 -1.41066195e+00 -3.00974870e+00
 -3.59359967e+00  1.41705726e+01  6.55931196e+00 -1.22633706e+01
  1.53700123e+01  6.05048835e+00  2.62435881e+00 -3.09861793e+00
  1.81474659e+01  1.85595295e+01  2.21250052e+01 -9.54025862e+00
  1.92541252e+01  1.71937371e+01  2.42382305e+01 -8.58194372e+00
  6.52942622e+01  3.10214902e+01 -7.51978923e-01  3.54400552e+01
 -4.96982558e+00  4.44977647e+00  5.78749560e+00 -7.03544628e+00
  2.16256006e+01 -4.74484688e-01  2.57581716e+01  3.07158940e+01
 -1.60794822e+01  2.26461941e+01  1.41233994e+01  4.85302457e+01
  1.38984850e+01  3.61185284e+00 -7.65647074e-03  2.02352150e+01
  6.00664216e+00  2.09450987e-01 -4.44737500e+00  4.66683404e+00
 -1.09792051e+01  1.05358272e+01  1.54711407e+01 -1.29855537e+00
  1.21538994e+01  1.82979949e+01 -4.33508872e+00  2.95561161e+01
  5.20302902e+00 -1.65148591e+00 -2.26302957e+00 -2.59131259e+00
  6.93872587e+00  9.87403876e-01  2.70943182e+00 -3.04171963e+00
  3.05556704e+01]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.9036797151255
gradient value of function right now is: [-5.38265680e-01 -1.83565449e+00 -5.20935706e-02 -7.08234997e-02
  5.38265680e-01  1.83565449e+00  5.20935706e-02  7.08234997e-02
 -2.60052112e-01 -3.28993181e-01 -5.61872453e-01 -7.75881167e-02
  5.46796622e-03  1.41208963e+00  5.64997208e+00  2.00615517e-02
  1.02746048e-07  7.82236941e-03  5.58398916e-03  2.42804557e-08
  2.05448352e-07  2.11277479e-02  1.97509676e-02 -7.91462557e-07
 -2.86858358e-06 -8.98181705e-03 -5.09792417e-02 -3.83717929e-10
  1.29656863e-02 -2.36576046e+00  1.51029787e-01  2.97304374e-01
 -1.18640264e-01 -3.60974236e+00  1.26351394e-03 -5.69763820e-02
 -2.95616552e-05  1.03385580e-02 -7.35990712e-02 -3.70649170e-06
  2.01038446e-01  5.96064025e-01  8.43256567e-01  1.35633577e-01
  6.14571707e-01  2.69320240e+00  9.72020690e-01  6.39210021e-01
 -2.71655335e-01 -2.51793639e-01  6.82754374e-02 -3.42240337e-01
  2.84634846e-01  2.29621568e-01  1.67726416e+00  1.33360222e-01
 -1.67313724e+00  4.33410398e+00 -1.25865776e+00  5.40049449e+00
  7.71322523e-01 -2.76832322e+00 -1.94709484e+00  6.40839169e+00
  2.16452306e+01]
supnorm grad right now is: 21.64523061971261
Weights right now are: 
[ -3.25643339   4.95668029   1.40149753   2.4746545    3.5110021
  -5.06537198  -1.00256026  -3.19068288  -3.49441941  14.64774686
   6.3754914  -12.75048469  16.92328055   6.35446151   2.74499897
  -3.86745551  18.44606077  21.22452491  28.93331727  -9.39845966
  19.55774091  18.25428529  25.92511267  -8.12321103  68.63593014
  33.70621888  -1.49878447  35.44052157  -5.21149061   4.29678203
   6.90824426  -7.29875974  23.40395845  -0.49243961  29.28465502
  27.3085946  -18.12110382  22.24652126  15.52501253  50.0622927
  13.79604962   3.74276336   0.3781239   21.37840628   5.82437706
   0.08588514  -4.17347258   4.57204138 -11.80142064  11.24214811
  15.86017796  -1.20559914  10.8473703   20.55247339  -4.24309335
  32.15114062   4.40602454  -1.86339117  -2.12473749  -2.8028704
   6.48648513   0.99001122   3.15662127  -2.85203936  30.7110457 ]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.1911021621247
gradient value of function right now is: [ 1.84140398e-01 -4.33921050e-01 -6.05425924e-03 -4.00061781e-02
 -1.84140398e-01  4.33921050e-01  6.05425924e-03  4.00061781e-02
  5.80780888e-01  4.75354161e-01  3.36633958e-01  4.48776710e-01
 -6.01552376e-03  6.94736160e-01  4.77714699e-01 -1.44644472e-02
  3.41728557e-07 -2.22889493e-03  3.49946474e-04 -3.94104033e-09
 -7.38305270e-07  4.50640831e-02 -2.94494715e-03  1.25060625e-07
  5.68018049e-08  7.90482213e-03  3.78720910e-02 -2.20772952e-12
 -8.30028480e-01 -2.20441335e+00 -2.87845230e-01 -4.49776933e-01
  3.15137389e-03 -3.60705416e-01 -1.85232492e-02  2.02055336e-04
  5.23610705e-05  4.92700442e-03  7.44741280e-02  8.94156505e-06
 -5.39635658e-02 -3.55821835e-01 -6.02589648e-01 -2.69557759e-02
 -5.78914681e-02 -1.34431525e-01  5.50063212e-01 -1.67428109e-01
  1.76776947e-01  3.02684320e-01  9.42164038e-02  2.03168937e-01
 -7.50307549e-02 -2.09375801e-01 -6.97698777e-01 -3.77457235e-02
  5.60103697e-01 -9.23300402e-01  1.79525083e+00 -5.33410578e+00
 -3.23586168e-01  3.51166732e-01  6.68041673e-01 -1.83368253e+00
 -4.84738773e+00]
supnorm grad right now is: 5.3341057775514304
Weights right now are: 
[-2.65877541e+00  4.65739156e+00 -8.03276627e-01  3.08604863e+00
  2.91334412e+00 -4.76608325e+00  1.20221390e+00 -3.80207702e+00
 -3.27075179e+00  1.49668789e+01  6.27079051e+00 -1.34383507e+01
  1.64580996e+01  6.45564043e+00  2.88956758e+00 -5.20013443e+00
  1.85875808e+01  3.03173304e+01  3.77544430e+01 -9.66086037e+00
  1.99295212e+01  1.76360015e+01  2.61934356e+01 -8.94355445e+00
  7.00269832e+01  3.60912144e+01 -6.07253814e-01  3.54406403e+01
 -5.95358217e+00  4.59843715e+00  6.80687622e+00 -7.10269921e+00
  2.40498588e+01 -4.00753880e-01  3.36332913e+01  3.02710956e+01
 -2.07909786e+01  2.21664633e+01  1.66472452e+01  5.36808272e+01
  1.34022752e+01  4.45804474e+00  7.01127086e-02  2.29515768e+01
  5.05223490e+00  1.72959841e-02 -4.49062629e+00  4.81208359e+00
 -1.21570931e+01  1.23261045e+01  1.62458827e+01 -7.68477204e-01
  1.05277057e+01  2.20660845e+01 -3.77237581e+00  3.47336377e+01
  4.13776696e+00 -2.03053003e+00 -2.29071670e+00 -2.81657281e+00
  6.08533483e+00  8.15963531e-01  2.77237595e+00 -2.96989162e+00
  3.04920614e+01]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.639012400095
gradient value of function right now is: [-6.85759968e-01 -6.35665447e-01 -4.19468877e-03 -5.59511645e-02
  6.85759968e-01  6.35665447e-01  4.19468877e-03  5.59511645e-02
 -1.01470909e+00 -9.67939039e-01 -6.61826017e-01 -7.25720506e-01
  3.02910738e-04  7.66873840e-01  4.29182989e-01  1.22595131e-03
 -5.85753971e-08 -4.50303984e-03 -1.12689685e-03 -1.43951043e-07
  2.01226276e-07  6.74644129e-02  7.09731509e-03  8.47842056e-06
  2.57430952e-08 -3.50989347e-03 -7.93457701e-02 -1.49199732e-11
 -8.31566099e-01 -2.23583706e+00  1.03084674e-01 -4.40819068e-01
 -8.96756181e-03 -3.68066912e-01  3.09752344e-02 -5.40721862e-03
  5.78389542e-05 -9.88774612e-03 -1.53350369e-01  4.60662424e-06
 -3.63703120e-02 -4.94957609e-01 -5.18798913e-01 -1.85476545e-02
  4.04639815e-01 -1.41418100e-01  1.03292290e+00  3.34823381e-01
 -4.33265551e-01 -4.79601729e-01  1.26438740e-02 -5.61851176e-01
 -8.30525660e-02 -1.75723303e-01 -8.05027830e-01 -3.24987377e-02
 -3.23414343e-01 -2.61351090e+00  1.65193945e+00 -4.13698979e+00
  6.07349580e-02  1.36330721e+00  6.80270493e-01 -1.60829890e+00
  1.06101079e+01]
supnorm grad right now is: 10.610107891284875
Weights right now are: 
[-2.73217996e+00  4.57197767e+00 -4.49427481e+00  4.42736179e+00
  2.98674867e+00 -4.68066936e+00  4.89321208e+00 -5.14339018e+00
 -3.68479175e+00  1.43876181e+01  6.64532261e+00 -1.41043548e+01
  1.97838300e+01  6.34943867e+00  2.73014269e+00 -3.15858241e+00
  1.80029702e+01  4.13037391e+01  3.11322065e+01 -9.68637157e+00
  2.04434796e+01  1.94321219e+01  2.79916143e+01 -7.42449878e+00
  7.04256471e+01  3.61787055e+01 -1.68461063e+00  3.54406723e+01
 -6.01554071e+00  4.66285398e+00  6.83479070e+00 -7.10629010e+00
  2.47805486e+01 -3.44777027e-01  3.94534613e+01  3.22880458e+01
 -2.17216976e+01  2.38514133e+01  1.59105062e+01  5.50615507e+01
  1.33326217e+01  4.23732559e+00 -9.66036840e-02  2.52630469e+01
  5.55558541e+00  5.37858506e-02 -3.97556422e+00  4.69158274e+00
 -1.29150667e+01  1.27168692e+01  1.68209560e+01 -1.31208339e+00
  8.50001360e+00  2.33377817e+01 -3.81376430e+00  3.62056469e+01
  4.52058184e+00 -1.99945622e+00 -1.95590946e+00 -2.76391280e+00
  6.49230597e+00  1.09302890e+00  2.81120958e+00 -3.17561540e+00
  3.07138918e+01]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1596.8070416568512
gradient value of function right now is: [ 1.00859189e-01  2.72357890e-01 -1.07871923e-02  4.43298568e-02
 -1.00859189e-01 -2.72357890e-01  1.07871923e-02 -4.43298568e-02
  1.02833421e-03  1.45844778e-01  1.64778659e-01  1.13012037e-01
  6.93249092e-03 -3.59316046e-01  8.73436211e-01  2.82786429e-02
 -3.55172297e-08  3.08172854e-03 -2.84582716e-03 -1.66534430e-06
  5.26318926e-07 -7.91465809e-02  6.52976572e-03  4.11974776e-05
 -1.10457792e-06 -1.34134103e-02 -2.73790676e-02  1.92452104e-12
  1.09305516e+00  3.05156713e+00  1.32906464e-01  1.07983432e+00
 -3.34292501e-02 -1.86132210e-01  1.38790546e-03  1.93178057e-03
  1.02123717e-04  1.02674475e-02 -4.73844050e-02 -5.87796371e-06
  1.85091745e-01  5.27257003e-01  1.98633117e+00  7.45976501e-02
 -1.89201460e-01  2.79612516e+00 -1.87908408e+00  2.81653436e-01
 -1.26816407e-01 -1.20224450e-01 -4.01327481e-02 -1.42196814e-01
  2.69649091e-01  3.93097837e-01  2.60520533e+00  9.35328819e-02
 -1.00808244e+00  3.51126966e+00 -2.67586080e+00  1.25901130e+01
  3.89089227e-01 -1.07935334e+00 -2.42195958e+00  5.76534246e+00
  6.00809425e-01]
supnorm grad right now is: 12.590113003476286
Weights right now are: 
[ -2.03129483   4.35245515  -7.67101232   4.55299132   2.28586354
  -4.46114684   8.06994958  -5.2690197   -3.35664303  14.56108371
   6.99771314 -14.09978616  22.05883716   6.45616838   2.64185636
  -3.28923747  16.52281784  44.17396566  30.81315665  -9.75515091
  20.54471869  21.58870638  27.16634614  -6.27216667  70.90036172
  37.38390365  -1.16325355  35.44069315  -5.94417438   5.01054583
   8.10925091  -7.01946416  24.86130997  -0.10572996  42.31496047
  33.68587901 -21.96332575  23.45153975  15.77082139  57.17738019
  13.35684238   4.32195578  -0.12011499  26.90611171   5.05689197
   0.26234143  -3.99094145   5.41087616 -13.61361615  13.00561648
  18.29268285  -1.59449898   7.81443707  25.16721391  -3.18478313
  38.66511236   4.60270222  -1.92988942  -2.4211359   -2.57558152
   6.24623598   0.81517597   2.45974494  -3.11760709  30.30591807]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.1415504929826
gradient value of function right now is: [ 1.23980967e-02  1.10366207e+00  1.16870594e-02  1.40873438e-02
 -1.23980967e-02 -1.10366207e+00 -1.16870594e-02 -1.40873438e-02
 -2.42890310e-01 -9.17148147e-02  2.88551939e-01 -9.90031865e-02
 -6.28050318e-03 -6.54740120e-01 -4.13437914e+00 -2.62806220e-02
 -1.45715712e-05  6.99655310e-03  3.22433605e-03 -2.05283746e-06
  8.92782400e-08  1.83708975e-02 -1.13412409e-02 -7.90909632e-06
  4.68732901e-07  1.63757163e-02 -3.24637294e-02  1.34429712e-12
 -5.48785621e-01 -3.18175745e-01  8.68866341e-02 -7.96534167e-01
  7.97475153e-02  2.16583815e+00  2.06791300e-02  2.98727728e-03
 -6.85890394e-06  5.96054018e-03 -7.37282153e-02 -3.09831726e-07
 -1.89702080e-01 -6.67723881e-01 -1.52203010e+00 -1.01677739e-01
 -3.40595824e-01 -4.28965227e+00  5.03385583e-01 -8.80696627e-01
 -3.39662787e-01 -5.32720864e-01 -6.62695880e-02 -4.45735896e-01
 -2.30596519e-01 -2.44758766e-01 -2.08627785e+00 -8.38548044e-02
  9.04578925e-01 -4.61921567e+00  2.38735318e+00 -8.01797833e+00
 -4.95864978e-01  2.82614012e+00  2.73721105e+00 -5.34626445e+00
 -1.34124661e+01]
supnorm grad right now is: 13.412466107636893
Weights right now are: 
[ -2.84863939   4.50860547  -8.04505751   5.50805709   3.1032081
  -4.61729716   8.44399478  -6.22408548  -3.80101815  14.38133666
   7.32490919 -14.65153224  23.46456643   6.30203514   2.87052253
  -2.8239434    5.65595944  46.81912071  31.54106782  -9.7148769
  20.73035225  22.6712872   29.268135    -6.26751     71.09510654
  38.27383301  -1.98050995  35.44070088  -5.90962623   5.25848172
   8.92352574  -7.19279873  25.10499368  -0.35285451  45.37476551
  37.87299019 -18.98446853  24.41339855  16.46156111  59.93533351
  13.1029825    4.43789605  -0.42008117  28.14628247   4.3105891
   0.2772199   -3.78018797   4.43598229 -14.53722582  13.60721707
  17.44367592  -1.72075671   6.42772476  26.24158927  -3.31251701
  39.71737574   4.78291365  -1.99435185  -2.42376629  -2.9817278
   6.39534577   1.078281     2.96762689  -3.24001396  30.45872457]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.7747036949777
gradient value of function right now is: [-5.39653808e-01 -7.05384725e-01 -8.34678689e-05 -6.08816240e-02
  5.39653808e-01  7.05384725e-01  8.34678689e-05  6.08816240e-02
 -3.58391280e-01 -2.93800515e-01 -1.23312670e-02 -1.09400551e-01
 -3.21145621e-04  5.72924117e-01  6.62456895e-01  1.08397833e-03
 -8.82681579e-03 -5.67750610e-03  1.54137794e-03 -9.03407353e-05
  3.10595993e-08  9.13152246e-02 -5.70755871e-04  2.50559112e-05
 -2.65989432e-08  1.15557742e-03 -5.63201020e-02 -1.57676205e-12
 -3.74690474e-01 -2.24649014e+00  2.49744532e-01 -3.18135145e-01
 -1.18858985e-02 -4.03473002e-01  1.71147724e-02  7.24515816e-04
  2.95800543e-05  6.38555272e-03 -1.04499193e-01 -5.84224289e-06
 -1.08415677e-01 -2.19682885e-01 -9.38273636e-01 -4.89017361e-02
  3.06306558e-01  5.61811152e-01  1.47140419e+00  1.65582384e-01
 -4.70697088e-01 -6.21548252e-01 -6.25918823e-02 -5.75987723e-01
 -1.35352481e-01 -1.35014508e-01 -1.14979908e+00 -6.04075557e-02
 -4.11029562e-01 -3.11710939e+00  5.18633023e-01 -3.98878094e+00
  4.67291510e-01  6.46208831e-01  3.55391334e-01 -3.27630617e+00
  7.21724649e+00]
supnorm grad right now is: 7.217246489078305
Weights right now are: 
[-2.02309727e+00  4.11709990e+00 -8.25445531e+00  5.38486614e+00
  2.27766598e+00 -4.22579159e+00  8.65339258e+00 -6.10089453e+00
 -4.05209177e+00  1.46320046e+01  7.54671895e+00 -1.43485919e+01
  2.30771967e+01  6.39749840e+00  3.04090286e+00 -4.76799940e+00
 -5.74454857e-01  4.96333699e+01  3.29762438e+01 -6.31442443e+00
  2.08071906e+01  2.43052617e+01  3.10012382e+01 -9.43840122e+00
  7.13282838e+01  4.14930717e+01 -3.80884881e+00  3.54407100e+01
 -5.97855093e+00  5.40128742e+00  8.34768878e+00 -7.82984848e+00
  2.66181286e+01  6.49839258e-02  4.34022642e+01  3.94056987e+01
 -1.89357332e+01  2.33151563e+01  1.69533623e+01  6.57771070e+01
  1.28892799e+01  4.06880634e+00 -4.41475438e-01  2.90984121e+01
  4.05123767e+00  1.84226448e-01 -3.01946390e+00  5.07905690e+00
 -1.56862326e+01  1.46870456e+01  1.66470232e+01 -1.90731216e+00
  5.29148647e+00  2.66389083e+01 -3.24278721e+00  4.08775564e+01
  4.33541932e+00 -2.22852083e+00 -2.75859387e+00 -2.86808546e+00
  6.84743788e+00  7.54824596e-01  3.01632056e+00 -3.20429059e+00
  3.06349434e+01]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.164180264847
gradient value of function right now is: [-6.53030161e-01 -9.32972984e-01 -1.42089639e-03 -4.18730489e-02
  6.53030161e-01  9.32972984e-01  1.42089639e-03  4.18730489e-02
 -3.70061092e-01 -4.36889764e-01 -3.80640596e-01 -3.19332079e-01
  1.13515742e-03  6.22814379e-01  1.04978112e+00  8.89749670e-03
  2.50700300e-04 -4.00953313e-03 -1.55991833e-03 -1.68597401e-05
  1.83251910e-09  5.62634701e-02  6.65387250e-03  5.72669597e-05
 -3.71562063e-08 -4.63559570e-03 -1.26228126e-02 -1.07978376e-12
 -5.08581179e-01 -1.66587889e+00 -2.82252846e-03 -4.66630552e-02
 -3.06010414e-02 -6.88545089e-01  6.37545412e-03 -1.69745351e-03
  2.90390329e-04 -5.94389968e-04 -3.04144602e-02  4.50458444e-06
 -5.57160584e-03 -2.22374174e-01 -1.51202614e-01  5.29191716e-04
  3.92880871e-01  1.05078457e+00  7.90118795e-01  3.98009431e-01
 -2.13374479e-01 -2.18419264e-01  2.22369429e-02 -2.68879257e-01
  1.25032461e-02 -4.55905018e-02  6.80244395e-02  1.62118698e-03
 -3.90893729e-01 -9.09855501e-01  4.84432698e-01 -1.16782168e+00
  3.41419206e-01 -2.22195627e-01 -8.90810024e-02  1.33569880e-01
  9.95656530e+00]
supnorm grad right now is: 9.95656529559843
Weights right now are: 
[ -1.8406327    3.8690859   -6.65829322   5.50085081   2.09520142
  -3.97777759   7.05723049  -6.2168792   -4.8086563   14.31773447
   7.34138435 -14.76617388  27.21048171   6.58970095   2.96930263
  -3.5613831    0.88461623  50.90530176  33.59182101  -1.20566567
  20.81039246  25.53000828  32.8374126   -8.58595605  71.55685163
  41.47668642  -6.10593073  35.44071425  -6.47474362   5.6734167
   8.90685892  -8.37564414  26.85936283   0.19688576  45.02212155
  38.00208401 -22.37183012  23.45046577  15.86051321  70.58546134
  12.83171262   4.18645616  -0.43879928  29.5676396    4.14965278
   0.1661926   -3.24442393   4.9368871  -15.8388375   16.3747385
  17.61543667  -1.56061668   5.10921818  27.29554399  -3.25060667
  42.4993235    4.42371862  -2.06027631  -2.65554807  -3.08859033
   6.43797349   0.6105634    2.92965476  -3.2410734   30.70131693]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -1600.1873649290326
gradient value of function right now is: [ 2.18794994e-01  1.21024028e-01  4.70379575e-03  1.81810075e-02
 -2.18794994e-01 -1.21024028e-01 -4.70379575e-03 -1.81810075e-02
  1.62571236e-01  1.80698099e-01  1.55896229e-01  1.58508828e-01
  1.41474547e-03 -5.68179231e-02 -4.60108409e-03  8.77120424e-03
 -1.07534219e-03  2.38811548e-03  1.22669883e-04 -2.60901987e-05
 -7.16661388e-10 -1.38409509e-02 -1.12369981e-04  2.04544992e-05
 -1.17945509e-08 -2.92090805e-03  1.35820872e-03 -4.20902060e-14
 -1.03633245e-01  3.80833791e-01 -5.00932367e-02  1.63278790e-01
  9.40174667e-03  1.64286269e-02 -1.81482043e-03  2.80982413e-04
  2.33479545e-04  5.70840101e-03  3.81774455e-03  4.81268806e-06
  4.18125516e-02 -2.02601837e-01  2.41436988e-01  1.25594498e-02
 -1.29270937e-02 -4.05855697e-01 -3.01120069e-01  2.40217509e-02
  4.51551314e-02  7.81729855e-02  2.60318005e-02  4.91836591e-02
  1.04163611e-01  3.38530284e-02  6.78589226e-01  3.35162280e-02
 -4.47671200e-02  6.89652552e-01  3.14000636e-01  9.33250501e-01
 -6.69794199e-02 -5.31319079e-01 -4.26354562e-02  1.79530138e+00
  2.06317067e-01]
supnorm grad right now is: 1.7953013781940685
Weights right now are: 
[-1.31694939e+00  3.77801105e+00 -6.77057142e+00  4.94597632e+00
  1.57151810e+00 -3.88670274e+00  7.16950869e+00 -5.66200470e+00
 -4.81165387e+00  1.43070433e+01  7.52828816e+00 -1.50425035e+01
  2.85095090e+01  6.62395704e+00  2.85472976e+00 -3.51860169e+00
 -3.82092118e+00  5.20576998e+01  3.44947505e+01  2.86149687e-01
  2.08106250e+01  2.68212645e+01  3.60191437e+01 -9.58229644e+00
  7.17394331e+01  4.21752932e+01 -4.96525446e+00  3.54407214e+01
 -6.63748779e+00  6.10440532e+00  9.71495468e+00 -8.35649506e+00
  2.62698261e+01  2.19338248e-01  4.72735847e+01  3.97117718e+01
 -2.21503350e+01  2.37682631e+01  1.61600865e+01  7.41550051e+01
  1.33230593e+01  4.15075543e+00  6.98493227e-02  3.09985603e+01
  4.02736793e+00  3.65699799e-01 -2.95090549e+00  4.85338780e+00
 -1.60684558e+01  1.71516269e+01  2.01133395e+01 -1.38873082e+00
  3.90794912e+00  2.85271950e+01 -3.33058578e+00  4.36236492e+01
  4.24418112e+00 -1.92308717e+00 -2.59701067e+00 -3.13775715e+00
  5.85575896e+00  7.25400210e-01  2.93161499e+00 -3.12799989e+00
  3.05725137e+01]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1596.7610556077748
gradient value of function right now is: [-2.21859519e+00 -2.50844035e+00 -5.43402382e-02 -1.12829578e-01
  2.21859519e+00  2.50844035e+00  5.43402382e-02  1.12829578e-01
 -1.07496433e+00 -1.18868217e+00 -1.30683567e+00 -1.01626817e+00
  2.95238534e-03  1.16440427e+00  3.98482143e+00  3.14395158e-02
 -1.07738240e-02 -2.01980936e-02 -1.47231423e-02 -1.28408140e-04
  4.84960388e-09  3.48588688e-02  2.66366464e-02  1.14975306e-04
 -6.53873621e-07 -1.76503147e-02 -2.83501510e-02 -3.04785030e-12
 -2.66737706e-01 -1.45124670e+00  1.26295787e-02  2.60334588e-01
 -1.06397595e-01 -2.40642819e+00  7.62387669e-03 -1.29509529e-02
  1.04717031e-03 -1.21486371e-02 -4.44821227e-02  1.85756092e-05
  1.63212472e-01  3.85762231e-01  8.54793430e-01  1.03352964e-01
  8.43860235e-01  5.11729469e+00  3.17920087e-01  1.31910591e+00
 -2.93912157e-01 -3.10029373e-01  6.09537929e-03 -3.63148424e-01
  1.96960346e-01  1.13170004e-01  1.39501696e+00  8.38663674e-02
 -1.64839141e+00  6.36102237e-01 -1.14569970e+00  4.63636115e+00
  6.53640464e-01 -9.52295284e-01 -2.76476598e+00  5.90629508e+00
  2.29798452e+01]
supnorm grad right now is: 22.97984517276121
Weights right now are: 
[-1.33985936e+00  3.55912642e+00 -5.77036815e+00  4.62128417e+00
  1.59442807e+00 -3.66781811e+00  6.16930542e+00 -5.33731256e+00
 -5.37500898e+00  1.42364417e+01  7.14803148e+00 -1.54456578e+01
  2.74844391e+01  6.52763271e+00  2.95633016e+00 -4.14032674e+00
 -4.32153766e+00  5.45107905e+01  3.60574968e+01 -6.47353097e-02
  2.08115817e+01  2.81122396e+01  3.79964431e+01 -1.67959269e+01
  7.19243105e+01  4.43242611e+01 -4.88613411e+00  3.54407244e+01
 -6.88378699e+00  6.43788729e+00  8.07680356e+00 -9.08978633e+00
  2.65913549e+01  3.75424845e-01  4.80320062e+01  3.86386568e+01
 -2.39170127e+01  2.33578591e+01  1.85163643e+01  8.32406013e+01
  1.36703056e+01  4.29002175e+00 -1.75491228e-01  3.17113032e+01
  3.90734951e+00  5.62478505e-01 -2.83682604e+00  4.90717652e+00
 -1.75032978e+01  1.74305246e+01  1.97426691e+01 -2.24913396e+00
  3.71919301e+00  2.90553783e+01 -3.21323026e+00  4.55770732e+01
  4.46114762e+00 -2.03529537e+00 -2.69115169e+00 -3.12338331e+00
  6.44039434e+00  8.43742587e-01  2.91365375e+00 -3.05486565e+00
  3.05960567e+01]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1595.4269071906
gradient value of function right now is: [-9.28404947e-01 -3.51702052e+00 -5.54045257e-02 -1.58329299e-01
  9.28404947e-01  3.51702052e+00  5.54045257e-02  1.58329299e-01
  2.48143418e-02 -1.08844776e-01 -2.78221689e-01  2.99815065e-02
  5.55230614e-03  1.93032931e+00  6.18968611e+00  6.14123073e-02
 -2.76113192e-03 -2.51365472e-02 -1.17316457e-02 -3.05766866e-05
  7.33224212e-10  5.88777366e-02  2.45663022e-02  1.53689734e-04
 -3.77604515e-07 -1.52408030e-02 -4.08217009e-03 -1.14276370e-12
 -5.39772705e-01 -3.24440015e+00 -5.80147576e-02  9.00771150e-02
 -1.41663724e-01 -3.86041794e+00 -2.05598137e-03 -1.25753038e-02
  3.85013752e-03  4.12340125e-02 -5.62095316e-03  8.41155826e-05
  1.56084518e-01  5.72919732e-01  6.01597243e-01  1.11375904e-01
  6.13904993e-01  7.69080798e+00  9.27385641e-01  1.26477328e+00
 -2.20966025e-02  5.21039543e-02  3.65664889e-02 -1.95070800e-02
  1.48265651e-01  6.43804110e-02  7.85525177e-01  5.18536410e-02
 -9.16785407e-01  2.24207547e+00 -1.01130342e+00  2.85988466e+00
  6.56297389e-01 -1.51448288e+00 -3.84593064e+00  4.76891447e+00
  2.94617802e+01]
supnorm grad right now is: 29.46178017070481
Weights right now are: 
[ -1.32470144   3.57142544  -6.3402577    4.27183304   1.57927015
  -3.68011713   6.73919497  -4.98786142  -5.49709681  14.48420346
   7.97872812 -15.18157289  29.57103041   6.73157645   3.10438352
  -5.25863092  -4.51973436  56.78965531  39.75249864  -0.93291314
  20.81267168  28.70699544  38.25269739 -21.81854878  72.13173053
  45.97088575  -6.4887546   35.44072597  -7.49912911   6.51108568
   7.28931372  -9.23992147  26.52220258   0.28964643  50.45114604
  40.47056719 -24.28517113  22.62536991  17.82356476  92.24266497
  13.50630627   4.15388524  -0.41574216  31.87427631   3.66121712
   0.46773546  -2.64390516   5.01664452 -17.98427937  18.53643247
  19.48038089  -2.18608144   3.35976286  29.44359292  -3.36069803
  46.4583236    5.53992785  -1.82036879  -2.89209895  -3.19333188
   6.94278029   0.88993574   2.80254908  -3.32752515  30.7808865 ]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.7957433291122
gradient value of function right now is: [ 9.43226046e-02  3.35426415e-01 -3.15945700e-03  6.59383976e-02
 -9.43226046e-02 -3.35426415e-01  3.15945700e-03 -6.59383976e-02
 -5.91498441e-02 -7.17757827e-04 -8.66309165e-02 -5.68350618e-02
  2.10670927e-03 -3.55674360e-01  7.02144341e-01  5.86381698e-03
 -1.39470322e-02  1.76058780e-03 -2.56720282e-03 -6.80846314e-05
  1.03592055e-09 -6.72590342e-02  2.82498340e-03 -8.10959844e-04
 -9.46887532e-08 -5.83072255e-03 -7.97694245e-03  4.06000695e-13
  7.96354939e-01  1.83806409e+00  4.66018557e-02  3.40532980e-01
 -1.87083608e-02 -3.42498326e-01  1.31673791e-03  1.21376253e-04
 -1.21744322e-02 -1.76127096e-02 -4.10323740e-03 -3.22661415e-04
  1.19696673e-01  6.44875053e-01  9.82420121e-01  6.69857053e-02
 -7.19286003e-02  7.77014400e-01 -1.47487167e+00  9.01529206e-02
 -1.86994472e-01 -2.29468363e-01 -2.47756795e-02 -2.07930559e-01
  1.28231291e-01  1.56627180e-01  1.14836633e+00  5.80952177e-02
 -7.58505752e-01  7.32988450e-01 -1.83961962e+00  5.83824033e+00
 -3.01249574e-03  2.34285343e-01 -1.43924994e+00  4.24106102e+00
  6.19838073e+00]
supnorm grad right now is: 6.198380729789006
Weights right now are: 
[ -0.82228832   3.4397168   -5.65652098   4.37192709   1.07685704
  -3.54840849   6.05545825  -5.08795547  -5.4319821   14.36779801
   7.99668307 -15.44651839  32.47122124   6.46951422   2.72173276
  -5.06635068  -6.23622484  58.88056564  38.5253192   -0.92228999
  20.81223611  29.58416636  42.64440726 -21.94659539  72.26164571
  46.51393717  -3.87116671  35.4407273   -6.73119264   7.00231754
   7.39885198  -9.15578005  24.56788746   0.39296087  52.2346813
  40.05920923 -26.34358345  22.09668105  19.83772037  95.01500759
  13.79301289   4.19057745  -0.36054841  33.13687198   3.34219131
   0.52689277  -2.447279     5.50637788 -18.74062841  19.09081967
  20.33041681  -2.55535145   3.65825068  30.23832143  -3.15156104
  47.51640273   3.97971928  -2.19054618  -2.99622218  -3.23557225
   5.89489157   0.82069089   3.08277359  -3.09472032  30.56461995]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.9574328706958
gradient value of function right now is: [-2.46801679e-01 -8.26680464e-01 -2.10739266e-02 -1.08230322e-01
  2.46801679e-01  8.26680464e-01  2.10739266e-02  1.08230322e-01
  3.51025783e-01  2.86371017e-01  4.47538377e-01  3.95660542e-01
 -1.17011439e-03  8.53146826e-01 -2.18600488e-01 -3.76425988e-03
 -5.71024192e-03 -9.57901204e-03 -2.60525870e-03 -1.00878702e-04
  2.29802521e-09  6.97642434e-02  3.25076375e-03  2.61506849e-04
  4.14603720e-08  7.58898935e-03 -7.83095583e-03 -3.47131175e-14
 -1.28865253e+00 -2.91667779e+00 -9.95484158e-02 -8.20539409e-01
  1.99838828e-02  8.35375036e-03  4.92335624e-04 -1.95828555e-03
  4.91037767e-03  1.74630314e-02 -1.04446204e-02  1.43670167e-04
 -1.38352808e-01 -7.62281375e-01 -1.56766789e+00 -9.64764373e-02
  4.00131917e-02 -8.83125505e-01  2.26238585e+00 -2.30068138e-01
 -9.24922850e-02 -2.30318629e-02  3.52836375e-02 -8.87045877e-02
 -1.98577112e-01 -2.76388109e-01 -2.16734353e+00 -1.11233742e-01
  5.70678924e-01 -1.70920707e+00  2.58957616e+00 -9.36533652e+00
 -3.55473092e-01  2.08355403e+00  1.95242267e+00 -7.92437094e+00
 -5.59983363e+00]
supnorm grad right now is: 9.365336515049448
Weights right now are: 
[ -1.39987998   3.52547132  -5.0668522    4.23810325   1.65444869
  -3.63416301   5.46578947  -4.95413164  -5.66464399  14.47774302
   9.53219881 -14.83609375  32.49199645   6.94833607   3.16657242
  -4.84009736  -3.68868555  61.48112334  40.43978777   1.77351966
  20.81225806  30.49889255  41.19438976 -19.0407413   72.56877086
  47.64839197  -5.4921251   35.44072841  -7.16241213   7.1599585
   7.71748205  -8.81937064  26.44761093   0.24298697  59.42046068
  39.47129587 -25.06634342  22.80091315  14.81126244 100.52958488
  13.45098665   4.1394886   -0.47165379  34.59049962   3.298215
   0.59640187  -2.47087543   4.6319493  -18.97920079  20.12923846
  19.26137889  -2.62543973   2.878563    30.41030529  -3.46823338
  47.99889882   4.89998803  -2.26039236  -2.80192187  -3.24461272
   6.80550228   0.89233276   3.05305868  -3.08174913  30.54108571]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.4876027714263
gradient value of function right now is: [ 1.02643797e+00  2.59009314e+00  5.01213431e-02  1.18118251e-01
 -1.02643797e+00 -2.59009314e+00 -5.01213431e-02 -1.18118251e-01
  2.05192348e-01  2.64772839e-01  3.35133191e-01  2.06970234e-01
 -3.48643185e-03 -1.00044046e+00 -4.21091475e+00 -4.78536696e-02
  1.51953684e-03  1.06970524e-02  7.76436542e-03  1.44038836e-05
 -1.72932555e-10 -3.31174961e-02 -1.63989148e-02 -1.57085487e-04
  2.43192107e-07  1.36314382e-02  6.11400287e-03  2.51543273e-13
  1.09981045e-01  1.61259256e+00 -5.75335941e-03 -1.18900091e-01
  1.00231125e-01  2.28569809e+00  1.87877712e-04  5.36340696e-03
 -7.95444013e-04 -1.96030770e-02  3.84736457e-03 -1.07338225e-05
 -8.11261676e-02 -5.77141626e-01 -4.43638669e-01 -6.29321216e-02
 -7.45785931e-01 -5.81906886e+00 -5.81436223e-01 -9.66089558e-01
 -7.83771351e-03 -1.70350312e-02 -7.29667720e-03 -3.65905720e-03
 -3.84263313e-02 -3.73349436e-02 -4.10046225e-01 -1.98211932e-02
  1.03432457e+00 -1.03710381e+00  1.27558574e+00 -2.44286370e+00
 -3.86082136e-01  8.03270260e-01  2.34284580e+00 -2.50642878e+00
 -2.07141540e+01]
supnorm grad right now is: 20.71415395012973
Weights right now are: 
[ -0.67969256   3.16794454  -4.95980477   4.2962275    0.93426127
  -3.27663623   5.35874204  -5.01225589  -6.32590817  13.93918807
   8.67498248 -15.19007901  32.54344093   6.62680784   2.78072681
  -4.44735586   0.41988498  65.95097127  40.22757896   5.29660227
  20.81384169  31.18454474  40.66443752 -18.90534314  72.89065171
  47.92531044  -3.6837793   35.44072962  -6.55647261   7.51217216
   7.14117409  -7.92584589  25.36470892   0.41583416  59.53710776
  33.4933749  -23.17254378  22.67454267  21.39738346 109.69484958
  13.7656513    4.25841352  -0.35121114  35.67901897   3.14507135
   0.66380675  -2.21363555   4.60496459 -19.24819832  20.26011564
  20.21932129  -3.10533968   3.79058975  32.0377236   -3.16495288
  49.155927     4.18758135  -2.37750118  -2.75330335  -3.08743892
   6.96554993   0.91036586   3.26024235  -3.15450434  30.41832978]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.8356671796098
gradient value of function right now is: [-4.93995623e-01 -1.37327107e+00  7.99424479e-03 -4.38395234e-02
  4.93995623e-01  1.37327107e+00 -7.99424479e-03  4.38395234e-02
  6.81310714e-02 -2.14328080e-02  9.89091432e-02  1.17880225e-01
 -7.59787950e-04  1.06361311e+00  9.71225809e-01  1.49161049e-03
 -5.18394044e-03 -7.11648154e-04  7.34972464e-04 -5.85499021e-06
  6.66357074e-10  5.59749365e-02  1.40353419e-03  1.71590914e-04
 -3.18856413e-09  4.90284156e-03 -9.53831955e-03 -2.66509740e-16
 -1.26900066e+00 -3.74752852e+00 -2.06730413e-02 -8.83290840e-01
 -2.92816839e-02 -6.75534050e-01  3.25318906e-03  3.13519189e-04
  2.35499174e-03  1.51965601e-02 -1.20219929e-02  4.30571219e-05
 -2.67660793e-01 -2.53710932e-01 -2.22278605e+00 -6.65499280e-02
  3.32458550e-01  1.51669622e+00  2.76977560e+00 -2.91136763e-02
 -1.18860375e-01 -1.15421823e-01  3.24303734e-03 -1.40650877e-01
 -3.65181017e-01 -2.68802000e-01 -2.78344816e+00 -9.54741150e-02
  3.58622514e-01 -3.99889626e+00  1.52604159e+00 -9.65124946e+00
 -1.50287153e-01  2.35130963e+00  5.40775406e-01 -6.71872195e+00
  3.86445157e+00]
supnorm grad right now is: 9.651249459233139
Weights right now are: 
[ -1.33316986   3.5069232   -6.0805401    4.75820839   1.58773857
  -3.61561489   6.47947737  -5.47423677  -6.78352544  14.27667036
   8.88390236 -15.06281645  31.52135222   7.31388931   3.22860638
  -5.12765961  -1.12271943  69.22091107  40.77605635   4.41164073
  20.81040821  32.44718677  38.53752682 -16.49486555  73.01820102
  51.55261487  -5.30749737  35.44073105  -6.86209242   6.96673738
   8.11723057  -8.03946057  25.13156356   0.43578263  58.52481228
  32.42156087 -26.22142578  23.86009102  23.28007313 110.53780324
  12.90250255   4.36509402  -1.08468801  35.5375589    2.94145791
   0.46550537  -2.49956789   4.66482496 -19.60339799  20.5755454
  22.05151112  -3.09379412   3.5976757   32.92958302  -3.2276521
  50.58623416   4.99027748  -1.86559773  -3.11195638  -3.21702787
   6.82007697   1.09803837   3.00674463  -3.45049879  30.66306146]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.708180119487
gradient value of function right now is: [-1.02095966e-01 -3.82466301e-01 -1.64702508e-02 -3.34793864e-02
  1.02095966e-01  3.82466301e-01  1.64702508e-02  3.34793864e-02
 -3.83358098e-02  1.06207733e-02 -1.29036327e-01 -4.03286550e-02
  2.17694659e-04 -2.30865005e-01  1.26138477e+00 -5.93247764e-03
  2.95321079e-03 -6.82800235e-03 -5.21346882e-03  1.37434118e-05
 -5.07765958e-11 -1.08340364e-02  8.96854314e-03 -6.61431903e-04
  3.93808324e-11 -1.16351384e-03  2.99448002e-04  1.67106354e-14
  6.79882199e-01  5.67296237e-01  6.24479221e-02 -9.57189107e-02
 -3.53735958e-02 -8.63309181e-01 -4.50108974e-04 -4.58628509e-03
 -7.88762629e-03 -1.42689669e-02 -6.10772183e-04 -1.42766504e-04
  5.59542806e-02  7.55369518e-01  1.83350222e-01  3.93098141e-02
  1.28789214e-01  6.67365495e-01  3.03238087e-01  1.40410048e-01
  3.75030092e-02 -3.38623514e-05 -1.50795101e-02  4.32668377e-02
 -9.27156027e-02  3.46899090e-02 -5.02437020e-01 -1.75138062e-02
 -4.35151161e-01  6.95984475e-01 -1.49592393e+00  2.07383331e+00
  1.51182897e-01 -8.64391428e-02 -9.82373602e-01  2.28562654e-01
  5.84981024e+00]
supnorm grad right now is: 5.849810239725421
Weights right now are: 
[ -1.27654978   3.62917079  -6.71264744   4.42528069   1.53111849
  -3.73786248   7.11158471  -5.14130907  -7.12790932  14.37069492
   9.17815101 -14.90270933  32.8013138    6.72021385   3.01614242
  -5.40078038  -1.99929148  68.768824    40.6996117    5.65473952
  20.81011053  31.71769886  39.61589851 -19.27405676  73.17946045
  50.93495469  -6.7092817   35.44073165  -7.20902026   7.47761708
   7.62668939  -8.40411007  24.99473181   0.47095147  61.286236
  28.81302371 -24.51577617  22.2981604   22.18405605 121.30904462
  13.68378978   4.41698191  -0.9798811   38.30758103   3.73395406
   0.40478612  -2.43035896   4.83286928 -19.49293654  21.7479907
  23.02159722  -2.86149056   2.68972663  33.15749009  -3.57371268
  50.84095408   4.9193267   -1.74175859  -3.2876416   -3.36408221
   7.09923854   0.75115188   2.98708323  -3.42854345  30.62196188]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.1588891321703
gradient value of function right now is: [ 3.17117467e-02  1.79407100e+00  7.43030962e-03 -9.26823707e-03
 -3.17117467e-02 -1.79407100e+00 -7.43030962e-03  9.26823707e-03
 -1.01635136e-01 -1.00498918e-01  6.57742637e-02 -1.00016680e-01
 -1.86165343e-03 -6.37795508e-01 -4.37305223e+00 -2.87937019e-02
  1.09406414e-04  1.13554595e-03  2.24736725e-03  7.93376032e-07
  4.98836267e-12  2.07789977e-02 -7.45790195e-03  6.66867619e-07
  1.70689586e-08  5.11862907e-03  1.89932562e-05  1.47816791e-13
 -4.56119643e-01  4.61955352e-01 -2.65132687e-02 -2.94688304e-01
  6.78750916e-02  2.53236739e+00  3.93230239e-04  3.49240845e-03
  2.97721282e-04 -1.72647476e-02 -3.87594770e-04  8.95212402e-06
 -1.51852579e-01 -6.93607033e-01 -8.90726376e-01 -7.91923923e-02
 -2.05193468e-01 -6.00385868e+00  5.27893936e-01 -7.12481685e-01
  1.66979875e-03  5.83987301e-03  7.61388097e-03 -3.55328700e-04
 -1.18802858e-01 -1.03072460e-01 -7.71274979e-01 -3.79447363e-02
  9.03147290e-01 -1.72138047e+00  1.65882530e+00 -4.62637538e+00
 -4.28952242e-01  9.19803074e-01  3.20717643e+00 -4.24540352e+00
 -1.28247782e+01]
supnorm grad right now is: 12.824778230623158
Weights right now are: 
[ -1.09039915   3.5770607   -5.2822762    4.22602931   1.34496787
  -3.68575239   5.68121347  -4.9420577   -7.47874755  14.24588192
   8.85165254 -15.10612592  34.07854949   6.48034649   2.94574215
  -4.69681811  -2.5739507   72.03496242  42.03955358   5.52480885
  20.81020753  32.78255415  38.01328088 -17.87290935  73.27706321
  51.09994818  -7.2903173   35.4407325   -7.21752354   7.27198502
   8.6552063   -7.8718811   24.01143441   0.82330225  61.88689367
  31.95477695 -23.34412852  23.26470885  24.43204416 122.73691115
  12.55982056   4.37412408  -0.93561206  38.68398223   3.6373386
   0.32703909  -2.30529506   4.9153948  -20.43179602  21.93864257
  23.82808108  -3.23156896   1.75824836  34.53710128  -3.12414254
  51.93350459   5.03077203  -1.90113953  -2.78111779  -3.2750776
   6.37716666   0.68267704   3.00305587  -3.3470644   30.60360691]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.5887046667142
gradient value of function right now is: [-1.64357696e-01  3.13968110e-01 -9.16179632e-02 -6.53463085e-02
  1.64357696e-01 -3.13968110e-01  9.16179632e-02  6.53463085e-02
 -1.01952333e-01 -1.21291733e-02 -7.94646787e-02 -8.00681550e-02
 -3.24422106e-04 -4.22698548e-01  2.67391266e-01 -1.18043472e-03
 -6.53253736e-03 -8.99039144e-03 -8.32285402e-03 -3.55343103e-06
  5.48887998e-10 -3.95443865e-02  7.05857856e-03 -1.04224997e-04
 -6.11147543e-10  1.79119993e-03 -5.22391590e-03  2.93853058e-15
  8.24214235e-01  2.16888635e+00  5.66560340e-02  5.34887955e-01
 -5.89749237e-03 -1.16069110e-01  2.33695438e-03  2.88109680e-03
 -7.15649901e-04  2.45847052e-03 -6.31121524e-03 -2.15724216e-05
  1.36861500e-01  4.79814877e-01  1.18632903e+00  6.86565698e-02
 -3.45451004e-01  1.99598382e-01 -2.04859680e+00 -1.79844520e-01
 -1.37040009e-01 -1.91835501e-01 -2.80841601e-02 -1.60716342e-01
  1.58626372e-01  1.31300969e-01  1.37019597e+00  6.04365953e-02
 -3.84006932e-01  4.33694394e-01 -1.33165855e+00  5.29628420e+00
  1.41354789e-01 -1.36384316e-01 -1.20649816e+00  5.28242970e+00
  4.92554066e-01]
supnorm grad right now is: 5.296284200908355
Weights right now are: 
[ -1.11882746   3.4220458   -6.04383712   4.11809478   1.37339617
  -3.53073749   6.44277439  -4.83412317  -7.84591209  14.12740155
   9.31361809 -15.2569997   37.87945132   7.05783944   3.26637045
  -4.535055    -2.4824394   74.07908648  39.75894375   7.59188507
  20.81017724  33.17781261  39.52463988 -17.86032297  73.32415613
  51.76953519  -6.18233101  35.44073285  -7.042521     7.48243063
   9.76504073  -7.570662    24.17889339   0.65646255  66.84820285
  31.79722101 -24.11949328  23.18994305  24.65924953 129.12010973
  12.66886332   4.32620451  -0.84573524  39.57933384   3.34516281
   0.39746792  -2.59188273   4.65309224 -20.87798244  22.36917458
  24.27849642  -3.47100281   1.15310815  34.76267939  -3.10464538
  52.25392154   4.76312084  -2.02884235  -3.17976874  -3.4061996
   7.0216619    1.04362954   2.7579348   -3.2135547   30.49525486]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.8382145698492
gradient value of function right now is: [ 1.03874512e+00  4.22808063e-01  4.04654014e-03  5.87564369e-02
 -1.03874512e+00 -4.22808063e-01 -4.04654014e-03 -5.87564369e-02
  3.88903669e-01  4.44044572e-01  3.70728172e-01  3.77306342e-01
 -8.56991415e-04 -3.66780392e-01  4.91776473e-02 -1.13979201e-02
  2.78968760e-03  3.71916443e-03 -1.05774464e-03  4.21897319e-06
 -3.80998314e-09 -3.09718913e-02 -1.01388036e-03 -2.13358076e-05
  9.79805111e-10  7.72624896e-03  1.13825676e-02  2.91236295e-15
  4.18073125e-01  1.19854079e+00 -2.69036367e-02  3.62140803e-01
  4.64442191e-03 -1.06167162e-01 -2.97685494e-03  7.24839110e-05
  6.56682973e-05  6.58292678e-03  9.10276113e-03 -6.15901997e-06
  1.02467093e-01  2.39693724e-01  7.49317492e-01  3.48422374e-02
 -4.93375530e-01 -4.51174329e-01 -1.29798212e+00 -5.39042138e-01
  1.38818552e-01  1.55901386e-01  3.28987505e-03  1.60395947e-01
  1.38710446e-01  7.60134240e-02  9.83895726e-01  3.84029004e-02
  1.34577010e-01  1.84843795e+00 -6.54327587e-01  3.06911362e+00
 -6.39221883e-02 -7.86130808e-01 -3.64624412e-01  3.35249846e+00
 -6.55248029e+00]
supnorm grad right now is: 6.552480292203996
Weights right now are: 
[ -0.81725913   3.23674442  -4.90491801   3.91652592   1.07182784
  -3.34543611   5.30385528  -4.63255431  -7.53455846  14.19414208
   9.52011218 -15.12412993  36.59157802   6.52417239   3.206338
  -4.23190791  -2.74031879  76.26550941  37.91555591   8.75354051
  20.81043229  34.48981468  41.76715754 -18.76560909  73.36832197
  51.94131629  -3.61322368  35.44073295  -6.93652927   7.60513099
   8.8620234   -7.42242186  24.46838561   0.67833563  66.51005225
  31.31106526 -22.74653495  22.27201882  28.33013636 138.37404078
  13.06135546   4.26290658  -1.10460986  40.45704864   3.25348518
   0.43810501  -2.59115993   4.5951152  -21.08647147  23.34883472
  25.48848063  -3.35353946   1.37585887  35.69399349  -3.13663071
  52.58205763   4.8498638   -1.78327006  -3.10787178  -3.3569749
   6.69942251   1.01836428   3.14934988  -3.16274193  30.45393533]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1595.782148242963
gradient value of function right now is: [ 8.75203974e-01  2.38244180e+00  1.79047033e-02  5.06170890e-02
 -8.75203974e-01 -2.38244180e+00 -1.79047033e-02 -5.06170890e-02
  3.03375315e-01  4.10982032e-01  4.96635068e-01  3.36082690e-01
 -2.33715777e-03 -1.02242087e+00 -4.21357975e+00 -5.36208337e-02
  2.04593073e-03  3.86913623e-03  4.75545394e-03  2.02878856e-05
 -2.92626620e-10 -1.31827115e-02 -1.29608259e-02 -4.47325932e-04
  7.03284011e-09  1.61680589e-02  1.90949348e-03  2.37558765e-14
  2.69290401e-01  1.75787599e+00  2.52895792e-02  4.04238772e-02
  7.75212380e-02  2.60064963e+00 -6.09214938e-04  2.56208196e-03
 -2.77070254e-03 -1.40202957e-02  1.76766259e-03 -2.56763635e-05
 -7.95091896e-02 -3.48270101e-01 -2.36194712e-01 -4.92780926e-02
 -8.73262633e-01 -6.34532673e+00 -8.70745745e-01 -1.58991396e+00
  4.42672269e-02  3.87100323e-02 -8.28362887e-03  6.15601085e-02
 -6.07766957e-03  1.61390445e-03 -2.28612638e-05 -3.63940647e-03
  9.81269029e-01 -9.28820168e-02  6.14423192e-01 -8.18047527e-01
 -2.92439910e-01  2.16818767e-01  2.21382066e+00 -1.30210915e+00
 -2.23159047e+01]
supnorm grad right now is: 22.315904666503226
Weights right now are: 
[ -1.1713132    3.42486012  -5.09063984   3.75638787   1.42588192
  -3.53355181   5.48957711  -4.47241625  -8.07149139  13.98165829
   9.96314624 -15.13109597  39.01092232   6.85640359   3.262953
  -3.92686754  -1.95892864  77.68798579  40.54830174  10.8057687
  20.81001851  34.10778233  38.89532846 -23.43652828  73.41800653
  52.094273    -5.04257598  35.44073314  -6.70615651   7.87057844
   8.4766817   -7.9861433   24.64384426   0.70395158  72.23634842
  29.09931865 -22.78053104  21.44383118  25.82527744 143.55152862
  12.27219019   4.65200319  -1.35438876  40.22028916   3.22748035
   0.49560756  -2.1243239    4.01007276 -21.8747957   23.15419098
  25.37721187  -3.94194774   1.83713691  37.23939323  -2.76328284
  53.57583447   5.56357612  -1.58039632  -3.14016215  -3.20338772
   7.20232146   0.86798967   3.21655923  -3.35599451  30.45754632]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.9090054110181
gradient value of function right now is: [ 2.98271557e-01  7.31921569e-01  2.60855155e-02  9.01521584e-02
 -2.98271557e-01 -7.31921569e-01 -2.60855155e-02 -9.01521584e-02
 -8.08773099e-02 -6.10137840e-02 -5.91301062e-02 -9.67852632e-02
  1.99689662e-04 -1.71358546e-01 -5.37809730e-01  1.38718152e-02
  1.29810420e-03  6.67687093e-03  4.55868909e-03 -6.81416114e-07
 -1.22190375e-09 -2.62383045e-02 -8.37142558e-03  5.07499094e-04
 -1.84683204e-08 -1.94210254e-03  4.74659172e-03  1.46484696e-14
  2.40374725e-01  8.27730911e-01 -2.84574132e-02  2.13241431e-01
  2.10907262e-02  5.72254882e-01 -5.80765445e-04  3.06844474e-03
  4.25738627e-03  1.05293063e-02  2.73607056e-03  3.94562641e-06
  4.37724865e-02 -4.34947138e-02  5.43189996e-01  5.84275467e-03
 -2.37576781e-01  4.09180723e-01 -1.44295464e+00 -1.57673970e-02
  5.27819782e-02  6.44344265e-02  4.99007616e-03  5.71673641e-02
  8.12566054e-02  6.14828223e-02  6.58758994e-01  2.46677508e-02
  2.67446548e-02  2.28675705e-01 -3.44843670e-01  2.38540778e+00
 -1.72587633e-01  1.12805270e-01 -2.90679232e-01  1.39969586e+00
 -3.12854671e+00]
supnorm grad right now is: 3.128546710540447
Weights right now are: 
[ -1.1420914    3.45980327  -5.32607551   4.22085276   1.39666011
  -3.56849496   5.72501278  -4.93688114  -8.37502454  13.82213656
  10.12098603 -15.32032032  40.61657923   7.26701659   3.29094644
  -4.00813504  -4.77148202  80.40396942  40.98034071  12.29462854
  20.80918441  34.68597466  38.51030261 -24.06695784  73.47032032
  52.56388815  -3.73765876  35.44073329  -6.86142406   7.56078904
   8.11974631  -8.13028834  23.67648302   1.04002146  74.03539468
  32.11677729 -21.31937586  20.80967485  25.50635961 146.21474627
  12.16056861   3.89415597  -1.18416999  41.10400501   3.15403402
   0.68883985  -2.18393352   4.94811472 -21.84658117  24.80721302
  28.66185644  -3.41087175   1.18973297  37.40282015  -3.17753989
  53.53144624   4.94998862  -1.87600605  -3.18353935  -3.24946024
   6.13952107   0.88254243   3.02435505  -3.22931757  30.54590203]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.9712039143467
gradient value of function right now is: [-2.81716611e-01  4.75006851e-01  1.03937376e-02  2.33971436e-02
  2.81716611e-01 -4.75006851e-01 -1.03937376e-02 -2.33971436e-02
 -1.83737203e-01 -1.65959831e-01 -1.49588547e-01 -1.77428750e-01
 -2.90124729e-03 -3.00541150e-01 -7.80423706e-01 -6.16125303e-02
 -1.70585013e-03  1.70093983e-03  2.50727244e-03 -1.87700262e-05
  1.95843635e-10 -3.75676617e-03 -2.53315099e-03  3.52741470e-04
  1.81233526e-08  8.29453250e-03 -3.26834682e-03  1.94437970e-14
  1.42963993e-01  3.81575142e-01  8.63651401e-04  1.24651594e-02
 -4.04115095e-03  4.28583451e-01  1.51236415e-03  1.63330997e-03
  4.69520263e-05 -3.38424253e-02 -3.55608230e-03 -5.78474562e-05
 -5.19989058e-03  1.33322471e-01  7.27467285e-02 -3.38726331e-03
 -1.73744332e-01 -2.75187381e-02 -6.70763344e-01 -2.17699493e-01
 -9.07869032e-02 -1.13472741e-01 -9.57613195e-03 -1.08511827e-01
  4.92858727e-03  1.53757732e-02  3.57583773e-02  1.81104620e-03
  3.63897978e-02 -8.24882798e-01 -4.03767311e-01  7.27918225e-01
 -1.00282922e-01  7.52660003e-01  2.31913589e-01 -7.76155461e-02
 -9.47352859e-01]
supnorm grad right now is: 0.947352859297798
Weights right now are: 
[ -1.09247075   3.43072697  -5.12013535   4.03371421   1.34703946
  -3.53941866   5.51907261  -4.7497426   -8.27839077  13.5827472
  10.39478108 -15.26006873  40.34548606   6.79700792   2.93772398
  -5.93798505  -7.58859433  80.76485423  39.26868472  12.56725694
  20.8095693   35.54069041  37.20264054 -19.6702039   73.5436961
  53.278496    -6.23342918  35.44073359  -6.76346609   7.6600399
   9.87593205  -8.12442239  22.12871718   0.87567749  74.78441945
  35.09738057 -18.25218483  18.90870642  25.47339757 150.88987288
  11.99232806   4.09472249  -1.31705809  42.26159925   3.25234393
   0.75617222  -2.09688062   4.78708263 -23.20299438  24.4899356
  30.19585578  -4.11438266   0.97650357  38.41775123  -3.09697717
  53.55166953   5.20882359  -1.97350043  -3.04697061  -3.38624389
   6.74352764   1.22120067   3.23665442  -3.19035361  30.56130045]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.3388436862774
gradient value of function right now is: [ 1.63693139e-01  2.79263829e+00  2.75753382e-02  7.03445261e-02
 -1.63693139e-01 -2.79263829e+00 -2.75753382e-02 -7.03445261e-02
 -1.37289076e-01 -1.66901940e-01  8.10450539e-02 -1.36120421e-01
 -1.65835857e-03 -5.22697099e-01 -5.64724099e+00 -5.61756421e-02
  3.92387024e-04  6.01824634e-03  6.00002296e-03  2.80192480e-05
 -5.09989355e-10  3.21735198e-03 -2.56218000e-02  1.22810760e-04
  6.41409528e-08  6.30875772e-03  1.15622468e-03  1.34200448e-13
 -8.03009189e-01  9.33144337e-02 -3.69197697e-02 -9.82182539e-01
  1.61957278e-01  3.67035853e+00 -1.27798828e-04  8.19756325e-03
  5.48666795e-04 -2.91251307e-02  6.02134204e-04  2.27371920e-05
 -3.58625226e-01 -1.54645929e+00 -1.80843600e+00 -1.50903615e-01
  4.40616934e-02 -1.06840205e+01  1.91724240e+00 -1.00347363e+00
  1.76178909e-02  3.69821144e-02  7.25452519e-03  2.30007491e-02
 -5.80056215e-01 -2.16952369e-01 -2.90649569e+00 -1.34930400e-01
  1.30524941e+00 -2.67657484e+00  2.99059779e+00 -9.91775199e+00
 -1.06477247e+00  3.68999367e+00  5.76604918e+00 -1.15059711e+01
 -2.23929889e+01]
supnorm grad right now is: 22.392988868938048
Weights right now are: 
[ -1.01707345   3.39116864  -4.32057801   4.09742326   1.27164216
  -3.49986033   4.71951528  -4.81345165  -8.9784338   13.10028135
  10.2468049  -15.85645584  41.92718869   7.20209975   3.15017807
  -2.89303003 -10.34801801  81.78267306  36.49705404  10.6910458
  20.80949331  34.97902535  34.24759933 -23.52195636  73.5635182
  51.91660226  -3.89780392  35.44073582  -6.97895547   7.84159656
   8.56076058  -8.28246913  23.62684458   1.04636256  79.42870609
  30.81489261 -20.42419566  19.98514179  23.93842387 152.10893134
  11.77152925   3.42869327  -1.16816907  42.55817021   3.17730694
   0.4961552   -2.15744105   4.80555644 -23.79506585  25.22825568
  31.28230557  -4.38865522   0.62640831  38.82703785  -3.42380669
  53.88480828   5.61874601  -1.48524954  -3.42763356  -3.64787096
   6.36057629   0.87682631   3.23654902  -3.25715649  30.62036803]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.4878128175571
gradient value of function right now is: [-5.45431292e-01 -7.97844104e-01 -1.72378883e-02 -7.51740628e-02
  5.45431292e-01  7.97844104e-01  1.72378883e-02  7.51740628e-02
 -2.34466039e-01 -2.69646908e-01 -2.69140504e-01 -2.38091933e-01
  4.68388389e-04  2.89137940e-01  1.09942291e+00  1.12154156e-02
 -2.46628881e-04 -5.13670118e-03 -2.14912834e-03 -7.53183658e-06
  1.88035238e-09  2.29028214e-02  5.72966667e-03 -1.60023367e-05
  2.11015748e-09 -3.52933541e-03 -1.60416271e-03 -4.59182752e-13
 -3.05917300e-01 -7.86392175e-01 -2.14301933e-02 -1.32102834e-01
 -1.46882342e-02 -8.89039078e-01  1.01031968e-03 -3.78001308e-03
  1.90080928e-04  4.10516222e-03 -2.26459665e-03  1.54003215e-05
  8.23105411e-03 -9.90522746e-02 -1.63217942e-01  8.73237071e-03
  4.81640543e-01 -4.52353688e-02  1.21302141e+00  3.79124413e-01
 -7.50348942e-02 -8.90211018e-02  9.23784984e-04 -9.01002427e-02
 -2.85906371e-03 -2.80057989e-02 -1.21741755e-01 -2.09490931e-03
 -2.48122294e-01 -7.99095815e-02  5.19782983e-01 -1.32847363e+00
  1.36342103e-01 -1.97371150e-01  1.94666318e-01  3.43101093e-01
  5.22934718e+00]
supnorm grad right now is: 5.229347175111418
Weights right now are: 
[ -1.45826514   3.43555326  -5.65315039   4.12071606   1.71283385
  -3.54424495   6.05208766  -4.83674444  -8.67503387  13.80307115
  11.40664467 -15.17338174  43.72732141   7.05450624   3.3891073
  -4.3631206   -6.9907439   83.60273972  37.84362272  11.27631952
  20.81678609  34.2098486   31.07953646 -22.67007903  73.6534991
  51.74440576  -4.41613323  35.44073628  -7.293658     8.02401051
   8.21558711  -8.18960714  22.66128789   0.69742772  88.24162888
  32.04056824 -18.71771446  19.66826427  15.27889122 151.98135179
  11.79820061   4.34206573  -1.37875583  43.61108627   3.5710207
   0.53905845  -2.01359505   5.18494119 -23.26069801  26.23980209
  30.05079882  -3.78096077   1.09823399  39.2239096   -3.13414974
  54.23991741   4.80120874  -2.02125014  -3.18450704  -3.60791921
   7.35471075   1.00093395   3.22607267  -3.06910754  30.5459648 ]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.4138994201835
gradient value of function right now is: [ 3.13339600e-01 -2.13154113e+00 -1.21314770e-02 -6.44260872e-02
 -3.13339600e-01  2.13154113e+00  1.21314770e-02  6.44260872e-02
  1.77343986e-01  1.95100466e-01  1.03845325e-01  1.77640312e-01
  2.99835932e-03  6.51314810e-01  4.08212467e+00  7.49597964e-02
  2.13094660e-03 -3.85930990e-03 -3.32701302e-03  2.27116053e-05
 -1.33150320e-09  8.76250580e-03  1.17513371e-02 -4.84893862e-04
 -1.20368863e-07 -5.82972431e-03  3.55328861e-03 -2.33982373e-13
  3.11514879e-01 -1.02850368e+00  9.70094489e-03  2.47409779e-02
 -8.71295859e-02 -2.34977228e+00 -1.08728547e-03 -8.51089290e-03
 -8.44503614e-03  6.49910320e-02  1.78593976e-03 -7.48395037e-05
  8.91976108e-02  7.09966318e-01  3.03172088e-01  6.33262675e-02
  5.05367686e-01  5.26570314e+00  9.01606324e-01  6.12837095e-01
  9.18034598e-02  9.12776463e-02  1.33914921e-02  9.79553170e-02
  2.01651359e-02  2.99933299e-02  1.00765250e-01  9.34389796e-03
 -7.47802006e-01  1.43767479e+00 -1.38188058e+00  2.05021870e+00
  3.11681298e-01 -1.63330027e+00 -2.52183084e+00  2.73423269e+00
  1.88969337e+01]
supnorm grad right now is: 18.896933701605523
Weights right now are: 
[ -0.6603601    3.10756971  -4.69255806   3.60304518   0.91492881
  -3.2162614    5.09149533  -4.31907357  -8.78635394  13.7447539
  11.45178586 -15.33286676  35.45540042   6.87280884   2.98092504
  -5.97220924  -7.68152898  86.07824451  35.11766373   8.86529385
  20.81548207  35.568782    33.18480585 -21.86018019  73.82630341
  55.40616222  -3.7053288   35.4407365   -7.08574294   8.28407159
   6.16804937  -8.11229596  21.03138532   0.92034559  95.06212746
  30.84239405 -18.51343079  20.07388067  14.32365914 152.80067684
  11.96703343   3.87746168  -1.0024704   43.82402634   2.87136075
   0.76684483  -1.66484763   4.77015839 -23.92210197  26.39630118
  27.16891276  -4.40162617   0.96393109  39.83934973  -3.36899044
  54.14177519   4.42728953  -2.13230901  -3.2644772   -3.70208425
   6.62325036   0.48367888   3.19460596  -3.254517    30.74441096]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1596.1610321873368
gradient value of function right now is: [ 1.00396628e+00  1.92716693e+00  3.42672601e-02  1.86536068e-01
 -1.00396628e+00 -1.92716693e+00 -3.42672601e-02 -1.86536068e-01
  2.74136896e-01  3.88175563e-01  3.31671426e-01  2.93786524e-01
  5.32473020e-04 -8.32986348e-01 -1.34076941e+00 -1.41266638e-02
 -8.74553151e-03  5.69251647e-03  6.87755910e-03 -1.98024840e-04
  1.87697921e-08 -6.83542965e-02 -1.44621098e-02 -1.42962514e-03
  1.33645072e-08  3.21025835e-03 -5.52003849e-03  3.88854791e-14
  1.36321392e+00  2.96168014e+00  1.02638599e-01  5.71358828e-01
  4.39712942e-02  1.00036891e+00 -1.35704953e-04  2.71448290e-03
 -1.17213744e-02 -2.32863589e-02 -4.68603560e-04 -1.28581617e-04
  6.77102642e-02  3.74491716e-01  1.45254806e+00  6.23392490e-02
 -4.88520662e-01 -1.94600758e+00 -2.79279278e+00 -6.32439867e-01
 -1.01938436e-01 -1.40280208e-01 -1.99161969e-02 -1.06619931e-01
  7.25720505e-02  1.16422200e-01  1.28805053e+00  5.99831603e-02
  1.93094604e-02  1.60401598e-01 -1.17631686e+00  5.58646430e+00
  1.40044287e-01 -7.58816379e-01 -4.56070708e-01  5.98631652e+00
 -1.06569243e+01]
supnorm grad right now is: 10.656924306813037
Weights right now are: 
[ -0.74718179   3.29736102  -4.12603207   3.51033036   1.0017505
  -3.40605271   4.52496934  -4.22635875  -8.77880027  13.81388194
  12.2287462  -15.13608943  40.35110909   7.38527364   3.15210006
  -4.41312722  -6.77688812  87.413589    33.91090964   5.66594598
  20.81510645  35.38460815  34.21100349 -24.53539212  74.11864808
  52.38073879  -3.22114783  35.4407368   -7.25542338   8.57859332
   7.41702226  -7.36389976  21.61794701   1.01518101 104.68170022
  30.88075345 -19.42901746  19.66149282  11.74532244 156.22047022
  10.98528051   4.44482746  -1.20957007  44.30584231   2.55503688
   0.58098081  -1.87258587   5.60499246 -24.58474902  26.21015666
  29.39445894  -5.0414736    0.83209749  40.81128091  -2.95189305
  54.76644092   5.20820495  -2.51602998  -3.43450673  -3.38620378
   7.95064965   0.90139073   2.86677471  -2.94521989  30.30879361]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.6863283537043
gradient value of function right now is: [ 5.30160390e-02 -8.03596683e-01  1.13396559e-02 -3.80923399e-02
 -5.30160390e-02  8.03596683e-01 -1.13396559e-02  3.80923399e-02
  3.20986204e-01  2.73564476e-01  3.33923020e-01  3.33335461e-01
 -6.74168008e-04  4.66568712e-01  6.98453814e-01  1.02499782e-02
  1.66705815e-03  4.07993580e-04  2.52258215e-03  1.19922340e-04
  2.87580295e-09  3.15300575e-02 -2.27347080e-03  7.32926037e-04
 -1.20591021e-08  5.02836711e-03  1.15994557e-03  1.70533017e-15
 -6.14967058e-01 -1.48448028e+00 -4.47292213e-02 -1.17993805e-01
 -1.66452193e-02 -4.46865336e-01 -5.20905390e-04  1.59638145e-03
  8.71720205e-03  3.35026282e-02  5.08223730e-04  8.90340890e-05
 -6.32413407e-02 -1.51913825e-01 -5.12503678e-01 -3.50541900e-02
  3.20615361e-02  1.43973314e+00  6.86974593e-01 -2.96885040e-02
  6.14722923e-02  8.78511410e-02  9.26156266e-03  7.42565006e-02
 -2.45818436e-02 -4.15160880e-02 -2.06928146e-01 -1.25899306e-02
  1.92410266e-01  1.67608954e-02  4.68711985e-01 -2.16451786e+00
 -2.63461668e-03 -5.79171756e-02  1.72489325e-01 -1.76736975e+00
 -2.94569122e+00]
supnorm grad right now is: 2.9456912243773745
Weights right now are: 
[-1.13430216e+00  3.35662884e+00 -3.82636231e+00  3.57066291e+00
  1.38887087e+00 -3.46532053e+00  4.22529958e+00 -4.28669130e+00
 -9.01333824e+00  1.34806028e+01  1.23738551e+01 -1.54347543e+01
  3.47578408e+01  7.21093083e+00  3.54371522e+00 -5.81150399e+00
 -7.22324271e+00  9.00634264e+01  3.38999357e+01  5.17026407e+00
  2.08368629e+01  3.60099092e+01  3.25657939e+01 -2.53529887e+01
  7.42557299e+01  5.50143498e+01 -3.84884662e+00  3.54407379e+01
 -7.71144751e+00  8.18705834e+00  6.96384934e+00 -7.56429206e+00
  2.18111094e+01  1.01176641e+00  1.10413552e+02  3.14889581e+01
 -1.93016949e+01  1.96794510e+01  8.28111396e+00  1.62753269e+02
  9.65551841e+00  4.42767973e+00 -1.51716043e+00  4.47689594e+01
  2.04016839e+00  7.02009905e-01 -2.00110421e+00  5.98489288e+00
 -2.45160838e+01  2.74378497e+01  3.02046242e+01 -4.51113597e+00
  9.96745164e-02  4.13501805e+01 -3.13393602e+00  5.45300917e+01
  5.69983350e+00 -1.87300903e+00 -3.39591794e+00 -3.46955844e+00
  7.47206102e+00  8.92715853e-01  3.05829333e+00 -3.09138184e+00
  3.04499828e+01]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1596.97700922328
gradient value of function right now is: [-9.75439016e-01 -2.40218257e+00  1.26469308e-03  9.14335955e-02
  9.75439016e-01  2.40218257e+00 -1.26469308e-03 -9.14335955e-02
 -3.06096375e-01 -2.95826060e-01 -4.38551795e-01 -3.28863283e-01
  3.02120070e-03  8.80218432e-01  5.50684429e+00  1.26701232e-01
 -8.72187276e-03  1.36433244e-03 -4.59219357e-03 -5.38017580e-04
  1.90001357e-08 -3.92207989e-02  1.26984586e-02  6.91781349e-04
 -1.19637246e-06 -1.55633706e-02 -4.53087765e-03 -5.27710512e-16
  9.81984632e-01 -6.30842117e-02  2.70551670e-02  5.32267741e-01
 -1.84333846e-01 -3.35318978e+00  4.07882360e-04 -7.79570883e-04
  1.31890769e-03  1.11487262e-01 -8.20693423e-04 -1.39071300e-04
  1.77672177e-01  1.51245364e+00  2.10641085e+00  1.66431770e-01
  2.08199499e-01  1.03780968e+01 -1.87306533e+00  1.06621658e+00
 -1.83398230e-01 -2.18670234e-01 -2.00547433e-02 -2.09351800e-01
  1.17057404e-01  1.54946618e-01  1.47185858e+00  7.02866078e-02
 -7.61477628e-01  4.57531761e-01 -3.90185968e+00  9.36923992e+00
  6.67332852e-01 -1.21968632e+00 -5.83238182e+00  9.41248964e+00
  2.73840643e+01]
supnorm grad right now is: 27.384064264804422
Weights right now are: 
[ -0.75574017   3.0546573   -3.85270595   3.62605633   1.01030888
  -3.16334899   4.25164322  -4.34208471  -9.87921067  13.10350165
  11.84803938 -16.05246482  38.42123709   6.84379833   3.47456301
  -5.35806608 -10.39824886  91.67218409  33.45952286   1.30021879
  20.87781899  35.87890595  36.16399717 -26.20413335  74.3511592
  54.19965821  -6.17915538  35.44073816  -7.46720337   8.4176908
   7.66884111  -7.73410895  20.08768484   0.85634049 114.75898002
  29.24951618 -20.13108139  20.49349863  10.85534181 164.0869775
  10.05952741   3.78338361  -1.17542438  45.99529829   1.35884845
   0.94807561  -2.05819915   5.54123924 -25.51716151  27.22625452
  30.2768494   -5.32014185   0.44440001  42.16665729  -3.46886878
  53.72122591   5.59656123  -2.32334536  -3.4597963   -3.47320799
   6.87819719   0.99946654   3.06055868  -3.13680613  30.62860601]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1596.920374728777
gradient value of function right now is: [ 2.07184205e+00 -1.36933296e+00  1.35649774e-02  1.23820444e-01
 -2.07184205e+00  1.36933296e+00 -1.35649774e-02 -1.23820444e-01
  3.56983987e-01  3.86070316e-01  3.42919560e-01  3.68926194e-01
  1.78836756e-03  3.97464295e-01  2.99098179e+00  6.68425135e-02
  1.02100946e-02  5.83028191e-03 -2.89201223e-03  4.60652929e-04
 -2.62139921e-08 -3.77411121e-02  4.15950427e-03  6.54061203e-04
 -1.24628732e-07 -1.19306384e-03  5.89514248e-03 -2.86547640e-14
  2.45658039e-01  2.27124111e-01 -7.45139603e-02  6.00824821e-01
 -6.09310914e-02 -1.95611967e+00 -9.42917864e-04 -3.09569685e-03
  1.34589081e-02  7.13657869e-02  1.79584078e-03  8.26633097e-05
  2.25272048e-01  3.43964971e-01  1.75670856e+00  1.18875858e-01
 -1.23487535e-01  4.16733064e+00 -1.94454252e+00  2.07638121e-01
  2.63384101e-01  3.13043992e-01  1.57326321e-02  2.97142931e-01
  2.22032533e-01  8.47503320e-02  1.83322701e+00  9.13406006e-02
 -1.90130682e-01  3.53299809e+00 -1.00165584e+00  4.69103149e+00
  2.16122989e-01 -2.21825693e+00 -2.88757315e+00  1.00036950e+01
  2.40656204e+00]
supnorm grad right now is: 10.003695027949105
Weights right now are: 
[ -0.32178811   2.88765563  -3.7595834    3.45841959   0.57635682
  -2.99634732   4.15852067  -4.17444797  -9.57738332  13.50323758
  12.46188954 -15.71301668  38.75073845   7.32201265   3.17754187
  -4.69479823 -10.57191172  92.44890262  34.16310302   0.70249449
  20.87677814  35.83887789  37.1579513  -26.62874942  74.65918617
  53.37010363  -6.03049362  35.44073853  -7.61682038   8.64260613
   7.58404586  -7.13853864  20.1253325    0.9689131  118.00451542
  30.9282876  -18.99407212  20.24206918  12.4460673  169.20768342
   9.9135956    3.6800881   -1.12626515  46.14312872   2.27597762
   0.7184425   -1.72917498   5.60471028 -25.0736168   28.33160356
  32.02260547  -5.02917689   1.5874365   43.90289585  -3.11659824
  53.73310193   5.45953935  -1.79950636  -3.46580175  -3.64558052
   7.13767117   1.03633018   3.12636572  -2.87292788  30.42111283]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.7427512166523
gradient value of function right now is: [-7.38236382e-01 -2.29442103e+00 -3.15384301e-02 -1.38323369e-01
  7.38236382e-01  2.29442103e+00  3.15384301e-02  1.38323369e-01
 -2.73616783e-01 -2.65314105e-01 -4.07073437e-01 -2.82751911e-01
  1.10524340e-03  3.88933262e-01  4.06529921e+00  1.75474530e-02
 -9.12814547e-06 -6.54794443e-03 -5.93949805e-03 -2.64897815e-05
  1.54459288e-08  1.67247947e-02  1.89369730e-02 -2.01802986e-03
 -9.13637004e-09 -7.63509465e-03 -2.13930881e-04 -1.65840602e-13
  2.90136263e-01 -1.01382556e+00  2.16036073e-02 -2.49803416e-01
 -1.04722913e-01 -2.95063230e+00  1.60314615e-04 -8.04074455e-03
 -1.81172214e-02  1.48663858e-03 -7.43938384e-04 -1.43197314e-04
  1.94084583e-02  8.53052067e-01 -1.36972315e-01  5.49490071e-02
  8.92313176e-01  4.28187529e+00  2.23928364e+00  9.08946641e-01
 -2.31321359e-02 -3.85458171e-02 -7.68813355e-03 -2.66907904e-02
 -1.21136228e-01 -8.80061151e-03 -7.40890324e-01 -2.52065976e-02
 -5.64798669e-01  6.08843661e-01 -1.37533707e+00  8.49703331e-01
  3.63701537e-01 -3.38228280e-01 -2.24205236e+00  5.75708738e-01
  2.08259984e+01]
supnorm grad right now is: 20.825998356538193
Weights right now are: 
[ -1.23141415   3.25588181  -3.8771056    3.37111391   1.48598286
  -3.3645735    4.27604287  -4.08714229  -9.87332852  13.39105725
  12.75629575 -15.95732575  38.00605231   7.01015606   3.43490502
  -5.15926061 -10.24295353  93.95372815  36.24419919   1.14991866
  20.88563746  36.14869144  34.03625289 -28.01757559  74.79218356
  54.79587789  -5.89345058  35.44073908  -7.79115881   8.72334582
   7.46848698  -6.88111478  21.00593279   0.83010921 128.12249121
  28.60799867 -20.29064072  19.63540199   8.60654913 176.05834151
   9.81685208   4.23053681  -1.5052505   45.47042984   2.85154623
   0.54471245  -1.60774046   4.96011065 -25.28015701  28.63182371
  33.5199842   -5.34757004   1.40568515  45.33110041  -3.28681395
  53.47370096   5.52099429  -1.56977169  -3.59558817  -3.71789302
   7.74693351   1.28725398   3.07647325  -3.29131008  30.77921469]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.7415551235297
gradient value of function right now is: [ 3.24110244e-01 -4.38476129e-01 -6.35316991e-04 -3.86208959e-02
 -3.24110244e-01  4.38476129e-01  6.35316991e-04  3.86208959e-02
  9.92184268e-02  7.28898689e-02  8.44708180e-02  9.27397223e-02
  2.46486631e-03  2.63308148e-01  4.21954483e-01  4.75434445e-02
  4.52830944e-03 -2.95167235e-04 -8.01021349e-04  6.25968167e-04
 -3.21779741e-08  1.58431985e-02  2.06185670e-03  4.85916465e-04
 -1.06947096e-08 -7.36006634e-03  2.46003312e-03 -1.63713699e-12
 -4.03422989e-01 -6.22970556e-01 -6.77838299e-02 -5.03810145e-03
  9.90971783e-03 -2.34747406e-01 -5.80699119e-04 -1.84144512e-03
  1.34807510e-02  3.59994490e-02  1.03864671e-03  1.13389435e-04
  6.95690011e-03 -3.10482348e-01  2.29070445e-02 -8.33979520e-03
  3.44715970e-01 -1.25376529e-01  6.22642380e-01  3.27778205e-01
  1.35627640e-01  1.66448615e-01  1.63463064e-02  1.51088767e-01
  3.83870678e-02 -1.35580121e-02  1.96224596e-01  8.46561979e-03
  8.73741461e-02  1.02983514e+00  6.82459274e-01 -7.92174697e-01
 -3.51923896e-02 -8.89285622e-01  2.67747266e-01  2.94909171e-01
  3.82452935e+00]
supnorm grad right now is: 3.8245293491758
Weights right now are: 
[ -0.78264688   3.04199624  -4.50845802   3.27175914   1.03721559
  -3.15068793   4.90739529  -3.98778752 -10.00382895  13.51822375
  12.81618536 -16.05934466  38.83997162   6.91855011   3.1610476
  -5.42359473 -10.43626965  95.97939282  34.76380739   1.28460109
  20.83809497  35.08208325  33.41753021 -24.4491658   74.92311607
  55.08882362  -6.06061615  35.44073987  -8.30092251   8.97996052
   7.09073456  -7.63411424  19.31363998   1.49989552 135.99720401
  33.82948959 -18.61826443  20.09165482   7.09150587 175.06679722
  10.4038045    3.30345786  -1.43889373  46.49493062   3.53594597
   0.77524911  -1.6180492    5.08987874 -25.54106932  29.25454787
  33.53139106  -5.29563544   0.78413771  45.77840697  -3.08255046
  53.51359641   5.11224284  -1.70834145  -3.25709042  -3.88472739
   7.25407306   0.7125145    2.98386039  -3.22079054  30.69153316]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.2560233573602
gradient value of function right now is: [-1.59371544e+00 -1.92436976e+00 -4.35874680e-02 -1.38577799e-01
  1.59371544e+00  1.92436976e+00  4.35874680e-02  1.38577799e-01
 -1.52942635e-01 -2.36981416e-01 -1.90125977e-01 -1.64695105e-01
  2.10160718e-03  8.50912738e-01  1.21445335e+00  6.29771368e-02
 -1.03069262e-02 -2.35247422e-03 -2.06386134e-03 -4.10140796e-04
  7.42264037e-09  4.72554209e-02  1.01065708e-02  9.82677220e-04
 -4.40008953e-08 -8.59463600e-03 -5.19409002e-03 -9.89476797e-13
 -1.18616061e+00 -2.61928480e+00 -9.17442910e-03 -3.60092708e-01
 -6.27904449e-02 -8.79675663e-01  9.72059188e-05 -8.89572203e-03
  2.38855146e-02  5.33896734e-02 -3.82258978e-05  9.29855215e-05
 -1.70779276e-01 -5.38575228e-01 -1.22081398e+00 -5.50888138e-02
  1.00966927e+00  1.09074523e+00  3.33647560e+00  6.08547638e-01
 -1.85422772e-01 -2.04282313e-01  6.66283025e-03 -2.03774251e-01
 -1.13078361e-01 -7.54131666e-02 -9.27803783e-01 -4.35717442e-02
 -1.63528874e-01 -2.25838808e+00  8.55836896e-01 -3.96095267e+00
 -1.94099080e-02  8.00388091e-01  4.16318327e-01 -4.16195549e+00
  8.00269695e+00]
supnorm grad right now is: 8.002696948420782
Weights right now are: 
[ -0.50443944   3.02450745  -0.77343478   2.70618891   0.75900815
  -3.13319914   1.17237205  -3.42221729  -9.843255    13.47059453
  12.19431399 -16.22716602  37.97612996   7.41439828   3.09557624
  -4.78909754 -12.15500502  95.90655093  22.87138143  -1.52060962
  19.45836302  35.85704411  38.53866347 -23.50415997  75.82619633
  54.33072654  -6.47947103  35.44074188  -8.76977935   9.37972074
   7.30829103  -8.76009364  19.9631251    1.0423334  133.56375702
  23.86850665 -18.78003297  20.82674043  11.57907042 176.6560121
  11.28506239   3.05592951  -1.31314777  47.29540868   2.23882293
   0.87501345  -1.27898471   6.18886281 -26.16277331  28.89126807
  33.84951933  -6.22083306   2.51185964  50.02347936  -2.74003642
  55.02595989   2.9286998   -2.33625851  -4.0637236   -3.86744957
   7.52580382   0.74925276   3.69064419  -3.13545155  30.58547769]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.0908867886533
gradient value of function right now is: [ 4.76122748e-02  4.64683271e-02  3.27489443e-02  5.69243049e-02
 -4.76122748e-02 -4.64683271e-02 -3.27489443e-02 -5.69243049e-02
  6.38320165e-02  4.12152005e-02  7.72486266e-02  6.21427080e-02
  1.75342594e-04  3.10915157e-01 -7.89049329e-02 -1.58127912e-02
 -2.96334918e-03  2.74573966e-03  4.75067349e-03 -1.62655059e-04
  4.67317775e-09  5.27139691e-03 -1.27980011e-02 -2.81471356e-04
 -1.13364011e-07 -3.67055008e-05 -1.59597214e-03  1.59249702e-14
 -6.50708501e-01 -1.18325832e+00 -5.71961338e-03 -4.43544480e-01
  3.99233991e-02  2.19189184e-01 -1.09779933e-04  2.66201064e-03
 -1.05409747e-02 -1.68461505e-02 -1.63169571e-04 -7.33868716e-05
 -2.34185220e-01 -1.03881162e-01 -2.31433815e+00 -9.07503783e-02
  2.45271374e-01  4.38254979e-01  2.33824591e+00  1.28197517e-01
 -4.80691429e-02 -4.31668321e-02  2.58827057e-03 -4.73507885e-02
 -1.57916961e-01 -8.91863267e-02 -1.63509649e+00 -5.74382166e-02
  2.64120307e-01 -2.16360419e+00  7.26558839e-01 -5.16350652e+00
 -3.90413292e-01  2.17999248e+00  7.37955471e-01 -7.02959885e+00
 -1.66871948e+00]
supnorm grad right now is: 7.029598847073077
Weights right now are: 
[ -0.86241727   3.08317397  -3.26381903   3.36327871   1.11698598
  -3.19186566   3.6627563   -4.07930709  -9.63189097  13.63669605
  12.95323747 -15.97995579  37.90503589   6.84607453   3.14833469
  -6.27517473 -11.97129234 100.11996081  34.29219339  -1.77384723
  19.45370442  36.29011209  33.58796804 -23.83660078  76.11826911
  55.87997334  -6.05842761  35.44074291  -8.1674057    9.43430271
   8.01189116  -8.00143891  19.79162511   1.06124241 139.110024
  28.96958065 -18.55314223  20.11913137  11.54964011 179.37683706
  10.75044154   3.76324078  -1.79018237  47.27538002   3.05890489
   1.07292402  -1.55479646   5.67377526 -25.67650902  29.85794372
  34.49080674  -5.54423965   1.83087413  50.67485079  -2.64019585
  54.28145061   4.41557587  -2.09219507  -3.64039917  -3.62109014
   6.82966427   1.32413894   3.04106255  -3.2368628   30.55708526]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.3972445257823
gradient value of function right now is: [-7.84581879e-01  4.25105615e-01  3.59313341e-03 -6.92423932e-02
  7.84581879e-01 -4.25105615e-01 -3.59313341e-03  6.92423932e-02
 -2.81366346e-01 -4.23140669e-01 -2.35730342e-01 -2.93395552e-01
 -1.91098076e-03  3.46293028e-01 -2.56635215e+00 -4.28991999e-02
  3.50667244e-04 -3.88129065e-05  7.57164910e-04  1.74060660e-05
  2.72551047e-10  3.87054792e-02 -7.50343660e-03  2.56665168e-04
  1.63572654e-08  1.64915082e-03  1.52690690e-04 -7.47378826e-14
 -1.42706381e+00 -1.80732844e+00 -3.84861665e-02 -7.20933031e-01
  6.61707502e-02  1.54678440e+00  1.85519126e-05 -2.71794381e-04
  8.27696732e-03 -3.44367732e-02  2.17960126e-04  9.39420926e-05
 -4.26311754e-01 -9.01342336e-01 -3.02429437e+00 -1.58564349e-01
  7.96566280e-01 -4.77424744e+00  4.24901092e+00 -7.04661181e-02
  3.50851024e-03  1.83909900e-02  5.28413012e-03  6.23323334e-03
 -3.41744081e-01 -1.40026929e-01 -2.18182495e+00 -9.02467635e-02
  6.20582444e-01 -2.18504057e+00  2.63879689e+00 -8.80466525e+00
 -6.75013599e-01  2.83776422e+00  4.10501644e+00 -1.06374636e+01
 -7.37157493e+00]
supnorm grad right now is: 10.637463644516881
Weights right now are: 
[-1.18087615e+00  3.27359246e+00 -3.45522673e+00  3.11656501e+00
  1.43544486e+00 -3.38228415e+00  3.85416400e+00 -3.83259339e+00
 -1.01764323e+01  1.32475576e+01  1.29496078e+01 -1.64001641e+01
  3.66696340e+01  7.33624277e+00  3.38144788e+00 -5.46685726e+00
 -1.45828110e+01  1.02299936e+02  3.16316965e+01 -4.22373688e+00
  1.94547940e+01  3.66859054e+01  3.28053687e+01 -2.75234346e+01
  7.65754266e+01  5.65978777e+01 -8.12171610e+00  3.54407435e+01
 -8.48802145e+00  8.92969508e+00  7.90977455e+00 -7.37009173e+00
  2.08357910e+01  1.14859291e+00  1.40752946e+02  2.79345701e+01
 -1.92943442e+01  2.04167641e+01  1.51455594e+01  1.86919042e+02
  9.93084688e+00  4.06669546e+00 -1.92771621e+00  4.73559101e+01
  2.97494401e+00  5.85756246e-01 -1.55959653e+00  5.39952691e+00
 -2.65921138e+01  3.00836142e+01  3.57791321e+01 -5.99361828e+00
  1.63159282e-01  5.01767487e+01 -2.96497195e+00  5.25784971e+01
  6.43283480e+00 -1.42380031e+00 -3.28924806e+00 -3.74901358e+00
  7.47693293e+00  1.41538962e+00  3.05218444e+00 -3.20320421e+00
  3.06979087e+01]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1595.5627966002314
gradient value of function right now is: [-8.35190456e-02  1.55290491e+00  1.90224877e-02  3.98272447e-01
  8.35190456e-02 -1.55290491e+00 -1.90224877e-02 -3.98272447e-01
 -5.55092920e-01 -4.19925023e-01 -6.21051510e-01 -5.76320696e-01
 -1.72235149e-03 -8.56150478e-01  2.73612829e-01 -6.30781504e-02
 -4.37614187e-03  8.19096356e-03  1.77659759e-03 -1.95420803e-04
  1.80442246e-08 -1.33009451e-01 -1.42939588e-03 -7.11060805e-03
 -1.89005762e-09 -4.36733960e-03 -2.74429377e-03  1.53587384e-16
  2.37070390e+00  3.91808939e+00  2.80893656e-02  8.46452133e-01
 -1.86342443e-02 -7.06019474e-02  8.45513625e-04  8.11879783e-04
 -7.50882745e-02 -1.46963153e-01 -2.75145456e-03 -5.29488386e-04
  2.41826178e-01  9.05342690e-01  3.69342217e+00  1.63310568e-01
 -2.32271085e-01  1.74993247e+00 -4.67542245e+00  1.19147500e-01
 -1.79009093e-01 -2.26607995e-01 -1.65542508e-02 -2.07596050e-01
  1.55742276e-01  1.49783184e-01  2.38494942e+00  8.90937299e-02
 -7.62035845e-01  2.18880237e-01 -2.91559554e+00  9.96874679e+00
  1.57250188e-01 -8.44488655e-01 -3.11949242e+00  1.10316960e+01
  8.74387258e+00]
supnorm grad right now is: 11.031696048317464
Weights right now are: 
[-1.05347482e+00  3.01040293e+00 -3.03293709e+00  3.39555636e+00
  1.30804353e+00 -3.11909462e+00  3.43187436e+00 -4.11158474e+00
 -1.04764780e+01  1.33006137e+01  1.30681148e+01 -1.65090347e+01
  3.79915931e+01  6.87991922e+00  3.16655188e+00 -6.84398021e+00
 -1.61907036e+01  1.03760381e+02  3.52884253e+01 -6.20157441e+00
  1.94553418e+01  3.74149541e+01  3.26129832e+01 -2.79313855e+01
  7.66398460e+01  5.69545602e+01 -9.12077005e+00  3.54407436e+01
 -7.49200940e+00  9.27070877e+00  8.13224101e+00 -7.11738103e+00
  1.84971732e+01  1.37039809e+00  1.45961606e+02  2.73786223e+01
 -2.14269616e+01  2.06164287e+01  1.42872626e+01  1.85894324e+02
  9.76801005e+00  3.93560239e+00 -1.85868113e+00  4.74136517e+01
  2.48086829e+00  5.85268593e-01 -2.20054686e+00  5.65539174e+00
 -2.70090686e+01  3.05872710e+01  3.54499136e+01 -6.23006013e+00
  7.21755494e-03  5.07199292e+01 -2.49230456e+00  5.28870392e+01
  4.62727559e+00 -2.27616366e+00 -3.33760124e+00 -3.65450479e+00
  7.16240099e+00  1.34570390e+00  2.98388429e+00 -3.00232559e+00
  3.06087382e+01]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.8072901105747
gradient value of function right now is: [ 8.35230547e-01  1.24272637e+00  1.69409266e-02  1.02894706e-01
 -8.35230547e-01 -1.24272637e+00 -1.69409266e-02 -1.02894706e-01
  3.87715075e-01  4.16500382e-01  4.57841628e-01  4.07158347e-01
 -6.75990346e-04 -2.54382186e-01 -1.61897776e+00 -1.15065880e-02
  2.42239102e-04  3.54479179e-03  4.07455604e-03  2.19179972e-05
 -1.25478313e-10 -1.69925433e-02 -1.73089048e-02  9.67151938e-04
  3.90952202e-08  8.80822511e-03  4.70940264e-04  6.54018936e-15
 -1.23171697e-01  7.08303314e-01 -4.51083713e-02  2.20324052e-01
  8.17982166e-02  1.16867726e+00 -3.64407325e-04  1.68535252e-03
  1.37515702e-02  1.10577320e-02  8.75972204e-04  8.06516139e-05
  4.86592071e-02 -4.79277965e-01  5.77018899e-01 -2.95641032e-03
 -5.71909774e-01 -3.04245340e+00 -1.46296401e+00 -7.33239667e-01
  5.25490801e-02  7.30892113e-02  9.12742591e-03  6.25358230e-02
  8.79248529e-02  1.11055811e-02  7.64446992e-01  3.57655067e-02
  3.90313927e-01  6.62079294e-01  9.42825464e-01 -1.18356149e-01
 -2.57729209e-01 -4.12603585e-01  1.50040943e+00  2.24690234e+00
 -1.36735445e+01]
supnorm grad right now is: 13.673544515486912
Weights right now are: 
[ -0.87894101   2.96914337  -3.93954486   3.63671834   1.13350972
  -3.07783506   4.33848213  -4.35274673 -10.25581247  13.86997371
  14.00665091 -16.05130942  41.88347723   7.3692475    3.41178205
  -5.23883629 -15.91116426 104.80056603  35.23198927  -4.55570044
  19.45096119  37.332117    32.18417869 -24.66142817  76.81319407
  55.67603064  -8.92192329  35.44074372  -7.83790381   9.33169581
   7.09625089  -7.13414795  19.03123004   1.24533342 153.4533573
  28.19017618 -20.33276803  21.53824309  17.8074885  186.98217127
  10.71029466   3.6665375   -1.83699253  47.00139028   2.0993724
   0.77088883  -1.74965071   5.44863198 -26.99933946  31.13707229
  34.44229079  -6.28010328  -0.27620418  50.98653417  -2.74995209
  52.27907544   5.03688272  -1.94452159  -3.38403871  -3.79280948
   7.00854595   0.88616518   3.30349109  -2.92522965  30.42276037]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1594.5968281788473
gradient value of function right now is: [-3.49443889e+00 -1.83041531e+00 -2.15707551e+00 -1.96448594e-01
  3.49443889e+00  1.83041531e+00  2.15707551e+00  1.96448594e-01
 -8.40278777e-03 -1.98685665e-02 -2.52924340e-02 -7.11856699e-03
  1.67347451e-03  1.71075664e-01  5.47407467e-01 -5.21615019e-02
 -1.61200663e-02 -3.60064715e-03 -1.24680441e-03 -5.70120346e-04
  3.52675618e-08  2.55274882e-02  1.75228137e-02 -1.43206051e-03
  3.09093683e-07 -1.50212788e-03 -6.41276993e-03 -3.08157941e-13
 -6.18430092e-01 -1.41127507e+00  5.85860687e-02 -5.16117833e-01
 -1.36643381e-01 -9.09879776e-01  2.85862435e-04 -2.19771225e-02
 -2.54602115e-02 -8.59970627e-02 -2.09354488e-03 -1.30203246e-04
 -1.12495098e-02  1.34771082e-01 -2.10955862e+00 -5.38166749e-02
  1.13170447e-01 -8.49234832e-01  5.26803721e+00  2.93174869e-01
 -2.95436586e-01 -4.06357564e-01 -1.99853885e-02 -2.77015017e-01
 -2.07252871e-02 -6.64862723e-02 -1.64227635e+00 -7.65489440e-02
 -1.20917297e+00 -1.68371909e+00  5.97497890e-01 -3.36611324e+00
  4.65464719e-02  1.22183331e+00  3.52312942e-02 -6.42999146e+00
  1.08956785e+01]
supnorm grad right now is: 10.895678494559629
Weights right now are: 
[-1.74799339e-01  2.59117095e+00 -2.41818500e-01  2.04363256e+00
  4.29368050e-01 -2.69986264e+00  6.40755770e-01 -2.75966094e+00
 -1.06179868e+01  1.33901559e+01  1.35125518e+01 -1.65729739e+01
  4.41175148e+01  6.66518776e+00  2.16009308e+00 -6.39995024e+00
 -1.79414080e+01  1.03885744e+02  2.99418038e+01 -6.18775304e+00
  1.94492116e+01  3.73380453e+01  3.49892355e+01 -2.55496961e+01
  7.75774035e+01  5.24991344e+01 -1.11005312e+01  3.54407438e+01
 -8.31420773e+00  9.71201148e+00  8.64582148e+00 -7.50150022e+00
  1.68846051e+01  5.48629070e-01  1.58886719e+02  2.00425248e+01
 -1.94620148e+01  1.99997933e+01  1.73724499e+01  1.89002796e+02
  1.24472363e+01  4.10885219e+00 -1.38962143e+00  4.82173821e+01
  2.68204329e+00  8.38517816e-01 -8.86234024e-01  5.85213574e+00
 -2.95495281e+01  2.89198249e+01  3.35691483e+01 -9.17721979e+00
  1.21669964e+00  5.22349116e+01 -2.71156276e+00  5.24365298e+01
  3.80568396e+00 -4.10856289e+00 -2.72482415e+00 -3.74541531e+00
  7.97766625e+00  1.64442593e+00  2.66389546e+00 -2.95188212e+00
  3.06669091e+01]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1598.6663590129026
gradient value of function right now is: [-6.74785064e-01  1.16745726e+00 -3.92409050e-01  4.86008188e-02
  6.74785064e-01 -1.16745726e+00  3.92409050e-01 -4.86008188e-02
 -3.68058368e-02 -2.52092235e-02 -1.87814470e-02 -3.58160597e-02
 -3.41550057e-03 -4.48803173e-01 -1.47384188e+00 -7.02827038e-02
 -6.88296844e-03 -7.96375112e-04  1.10755475e-04 -8.06204170e-05
  4.81581401e-09 -7.73237307e-03 -5.21562820e-03 -8.13123522e-05
  4.88181857e-08  8.38439532e-03 -2.52966414e-03  8.42848252e-16
  4.78693778e-02  8.16032153e-01  8.15113842e-03  1.35138161e-01
  7.21427560e-02  7.63258210e-01  2.69832543e-04 -4.75549957e-05
  1.27240656e-04 -6.12457133e-02 -4.22955071e-04  1.51465384e-05
  9.13615031e-03 -3.44151921e-01  3.39459859e-01  6.32499571e-03
 -1.16858828e-01 -2.85432884e+00 -5.73274205e-01 -2.53616433e-01
 -1.51052405e-01 -1.85488902e-01 -2.14054383e-02 -1.52760601e-01
  1.78822083e-02  8.31021911e-03  5.02422560e-01  2.96111161e-02
 -1.16036380e-01 -5.94784885e-01  7.98170791e-01 -1.06203136e-01
  1.07206334e-02  4.23603490e-02  1.40818543e+00  1.80405261e+00
 -1.23905894e+00]
supnorm grad right now is: 2.854328844112608
Weights right now are: 
[ -0.3679591    2.92137231  -0.46172018   2.08332229   0.62252781
  -3.030064     0.86065745  -2.79935068 -10.93293347  13.06890768
  13.73599739 -17.0583394   34.78825149   6.86085807   3.21174343
  -7.95420402 -17.04728784 105.21907077  29.57036107  -7.28201141
  19.45414485  37.59903894  41.8608992  -22.38561921  77.98260432
  58.34085682 -10.52149094  35.44074409  -8.30119819   9.57581644
   7.82055706  -7.82958963  18.6305261    0.99115974 162.43946845
  16.75132761 -17.8965645   21.30995566  19.94087925 190.12182555
  13.31706716   3.92286049  -1.1399602   48.58010781   2.04422122
   0.65420408  -1.85926887   7.00124623 -29.04627688  29.84556404
  32.3489884   -9.03944472   1.47534864  52.85862579  -3.31653241
  51.28343106   4.87364793  -3.44573829  -3.25434453  -3.92140864
   6.32789592   0.52603481   3.64204493  -2.99323999  30.62115832]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1597.867119200168
gradient value of function right now is: [-1.44608696e+00 -1.28284957e+00 -9.61179954e-02 -2.26531539e-01
  1.44608696e+00  1.28284957e+00  9.61179954e-02  2.26531539e-01
 -5.42712707e-01 -5.95161425e-01 -6.23485915e-01 -5.65593997e-01
 -1.05726773e-03  2.66137380e-01  1.03362436e+00 -9.47793246e-03
 -1.20775497e-03 -4.31178247e-03 -5.33030707e-03 -8.08943010e-06
  3.31511105e-10  1.43582580e-02  1.34835093e-02 -8.03721607e-05
  2.09544402e-10 -5.37665054e-03 -9.45649291e-04 -7.44609513e-18
 -2.96408264e-01 -8.90855432e-01 -9.15571282e-03 -5.11766277e-01
 -4.73952394e-02 -1.09595331e+00  4.23045816e-04 -5.91336278e-03
 -6.32468275e-04 -1.33158800e-02 -6.53439884e-04 -6.35920454e-06
 -6.22990720e-02  1.97625387e-01 -9.22118213e-01 -6.64841610e-03
  5.02469650e-01  1.14469644e+00  1.72202607e+00  6.23071593e-01
 -7.64901045e-02 -9.29384060e-02 -4.17248556e-03 -9.08005175e-02
 -1.06468805e-01 -4.68292032e-02 -1.20294332e+00 -4.86393708e-02
 -1.65844899e-01 -1.24084338e+00  3.37637324e-02 -2.32630331e+00
 -7.69980245e-02  1.54833613e+00 -3.87612557e-01 -3.29288276e+00
  1.27107539e+01]
supnorm grad right now is: 12.710753901441047
Weights right now are: 
[-1.20114302e+00  3.14316053e+00 -1.71169751e+00  2.39918354e+00
  1.45571173e+00 -3.25185222e+00  2.11063478e+00 -3.11521192e+00
 -1.10663190e+01  1.29680047e+01  1.44316147e+01 -1.70579343e+01
  3.62230274e+01  6.93328440e+00  3.81253786e+00 -5.60212547e+00
 -1.39627470e+01  1.08905482e+02  3.96624603e+01 -4.70569151e+00
  1.94556254e+01  3.83253105e+01  3.86080940e+01 -2.54999577e+01
  7.80359162e+01  5.85790756e+01 -7.84311351e+00  3.54407441e+01
 -8.08397962e+00  9.37365160e+00  6.95388675e+00 -7.02968268e+00
  1.92568872e+01  1.24960362e+00  1.68310228e+02  2.30628591e+01
 -1.92880606e+01  2.19107606e+01  2.00115612e+01  1.93372115e+02
  1.16165636e+01  4.30699585e+00 -2.02533190e+00  4.83466002e+01
  1.56109064e+00  5.54177269e-01 -1.92534617e+00  6.00103907e+00
 -2.70720100e+01  3.24739802e+01  3.24610521e+01 -7.16318449e+00
 -1.44617898e-01  5.31230349e+01 -3.77261409e+00  4.91577676e+01
  5.97098955e+00 -2.00965595e+00 -3.17258630e+00 -3.84155722e+00
  7.42704224e+00  1.44725528e+00  3.26832336e+00 -3.05231702e+00
  3.07469229e+01]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1599.068307835034
gradient value of function right now is: [ 8.42631677e-01  3.52054017e-01  1.40255720e-02  6.44100064e-02
 -8.42631677e-01 -3.52054017e-01 -1.40255720e-02 -6.44100064e-02
  1.50457610e-01  1.76179998e-01  1.73262152e-01  1.61096228e-01
 -3.52693919e-03 -7.37505292e-02 -1.16059672e-01 -3.61743852e-02
  1.26674891e-03  1.62913059e-03  2.55027493e-03  4.83510584e-06
 -6.79231845e-10 -1.09386762e-02 -5.08562733e-03  2.01953425e-04
 -6.24517817e-08  1.07506488e-02  9.35049291e-04  1.97717314e-15
  4.13672388e-02  3.20478051e-01 -5.10413808e-02  3.16478600e-01
 -2.37634293e-03  2.33817468e-01 -2.12606607e-04  3.38973538e-03
  5.32138887e-03  4.31835342e-03  5.78179270e-04  2.42806816e-05
  6.99532052e-02  8.43946848e-02  6.36573103e-01  3.18646775e-02
 -5.24151879e-01  1.26389561e+00 -1.65636919e+00 -4.82531478e-01
  5.47325083e-02  6.54627740e-02  7.82564000e-03  5.87026912e-02
  8.92617951e-02  1.95770738e-02  7.45134069e-01  4.33950535e-02
  3.83512510e-02  7.08868855e-01 -2.06498181e-01  1.15798085e+00
 -8.87490933e-02 -1.02016255e+00 -3.06232761e-01  3.28140251e+00
 -5.41276846e+00]
supnorm grad right now is: 5.412768457261519
Weights right now are: 
[ -0.69335694   3.03755827  -3.47126026   2.96972481   0.94792565
  -3.14624996   3.87019753  -3.6857532  -10.98484284  12.72641084
  14.93412581 -17.07132248  33.52922001   6.90616631   3.26034442
  -6.60593218 -12.55154654 112.89566534  41.15415032  -3.81991496
  19.4550918   38.93232465  36.80386598 -23.7893587   78.09614679
  58.73597806  -6.54782554  35.44074413  -8.03367438   9.20870535
   5.24418803  -6.82967777  18.22107005   1.36348638 181.41253603
  24.51318293 -17.21987999  20.9265819   16.09591487 195.07629075
  10.8237981    4.23187937  -1.97387634  47.17151458   1.12430017
   0.9593083   -1.9254744    6.13842096 -27.02719162  32.44518228
  33.95487445  -7.46743657  -0.41334395  54.0060841   -3.45810659
  47.83483173   5.47409526  -2.02779578  -3.63828882  -3.98974864
   6.55093502   0.57587517   3.16380174  -2.88473807  30.48590719]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1600.2959857942835
gradient value of function right now is: [-2.18441939e-01  2.22050981e-01  1.42390566e-02  5.51409835e-03
  2.18441939e-01 -2.22050981e-01 -1.42390566e-02 -5.51409835e-03
 -3.28683154e-02 -3.98794461e-02 -2.02846792e-02 -3.17132268e-02
 -4.76016620e-04 -4.57908684e-02 -5.15701488e-01 -1.08680719e-02
 -3.92580858e-04  6.80835548e-04  1.51372792e-03 -2.30300633e-06
  7.21994853e-10  7.60305533e-03 -2.87699589e-03  2.59679842e-04
  9.22995338e-09  1.55025168e-03 -2.93775248e-04  3.57445764e-15
 -1.91185582e-01 -1.85673515e-01 -2.03705278e-02 -6.66813591e-02
  1.22691891e-02  3.31826168e-01  1.58397236e-04  2.19218480e-03
  3.64302305e-03 -3.64379681e-03 -1.59698374e-04  2.20244650e-05
 -2.23536806e-02 -1.05125785e-01 -2.18909715e-01 -2.07054688e-02
  3.22650055e-03 -8.28803336e-01  1.89679020e-01 -6.75746986e-02
 -3.06793349e-02 -3.90389891e-02 -1.31443764e-04 -3.91357224e-02
 -1.08248216e-02 -1.25058643e-02 -1.12625811e-01 -8.25779373e-03
 -2.99669230e-02 -6.00505796e-01  3.30702965e-01 -9.41846952e-01
 -5.05093645e-02  2.65463414e-01  6.41578257e-01 -1.21497507e+00
 -2.12252657e+00]
supnorm grad right now is: 2.1225265651346263
Weights right now are: 
[ -0.55774572   2.9587462   -3.73525728   2.70524166   0.81231443
  -3.06743789   4.13419455  -3.42127004 -10.96905955  12.90170678
  15.21548952 -16.92241049  37.85012445   6.95217209   3.11359675
  -5.78005265 -13.61662212 113.71592785  38.31969009  -4.67093334
  19.45452811  39.74083652  37.166914   -23.77629221  78.18539415
  57.06102058  -8.01740125  35.4407442   -7.99144308   9.42804436
   5.51743191  -7.12023714  17.57976989   1.4215348  186.11787673
  21.39294633 -19.69271431  20.93723088  16.06955533 189.30337714
  10.74560727   3.56428927  -1.95285162  46.71276758   1.53310358
   0.8588414   -1.65847135   6.63032735 -27.85882888  32.14439159
  32.59259453  -8.29276376  -0.84062993  55.2240015   -3.38103019
  47.52015461   5.58193927  -2.63091558  -3.39996422  -3.74546652
   7.194556     0.48429402   2.99333119  -2.97842542  30.58853587]
(65,)
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1600.1508493268973
gradient value of function right now is: [-2.82207904e-01  3.25902713e-01  1.53992444e-02  4.51847631e-04
  2.82207904e-01 -3.25902713e-01 -1.53992444e-02 -4.51847631e-04
 -1.27830674e-02 -1.81336739e-02  2.91755648e-03 -1.05956358e-02
 -7.23624461e-04 -8.53681250e-02 -7.02130715e-01 -2.00504316e-02
 -5.35536531e-03 -1.16348423e-04  1.43465968e-03 -1.99880242e-05
  6.48309532e-10  9.32652399e-03 -3.34845080e-03  4.23082222e-04
  4.64611400e-08  2.76475056e-03 -1.72284700e-03  8.98700549e-15
 -2.10721899e-01 -1.87197081e-01  7.53508935e-03 -1.07231240e-01
  1.89796134e-02  4.30928125e-01  1.58649328e-04  2.97964106e-03
  5.10301983e-03 -8.34232130e-03 -1.56807199e-04  2.39226259e-05
 -3.11472817e-02 -1.39095621e-01 -3.45087701e-01 -3.09818066e-02
 -8.44349367e-03 -1.15426090e+00  3.00523404e-01 -1.11752721e-01
 -1.10610665e-01 -1.26824052e-01 -7.77420040e-03 -1.23028776e-01
 -1.83949910e-02 -1.61109690e-02 -2.23986537e-01 -1.47010012e-02
 -2.60520349e-02 -8.71185448e-01  3.99875669e-01 -1.21955215e+00
 -4.18054221e-02  7.38026161e-01  9.08483409e-01 -1.91790915e+00
 -3.10447723e+00]
supnorm grad right now is: 3.1044772268295104
Weights right now are: 
[-1.13435853e+00  3.04410369e+00 -1.16209284e+00  3.50772684e+00
  1.38892724e+00 -3.15279539e+00  1.56103011e+00 -4.22375522e+00
 -1.16347322e+01  1.25363335e+01  1.51545399e+01 -1.73870491e+01
  3.67029302e+01  7.38882077e+00  3.26472959e+00 -6.13967301e+00
 -1.15592895e+01  1.16711491e+02  4.00393855e+01 -1.66153554e+00
  1.94560137e+01  3.80852119e+01  3.64645818e+01 -2.21526539e+01
  7.92320953e+01  5.66464904e+01 -5.86745606e+00  3.54407442e+01
 -8.39272505e+00  9.66941578e+00  3.96750390e+00 -7.87375872e+00
  1.70885785e+01  1.41401849e+00  1.91739422e+02  2.20252099e+01
 -1.90687549e+01  2.14810647e+01  1.57562433e+01  1.87850941e+02
  1.12846659e+01  3.27651502e+00 -2.08931738e+00  4.76504792e+01
  1.17996948e+00  7.33836422e-01 -2.15646413e+00  6.21019698e+00
 -2.65716174e+01  3.37316947e+01  3.25329528e+01 -7.20226486e+00
 -1.60649112e+00  5.54197813e+01 -3.98682203e+00  4.62525619e+01
  5.12942162e+00 -2.15417287e+00 -3.70179436e+00 -4.06982730e+00
  6.53422041e+00  1.47101508e-01  3.52025847e+00 -2.91027279e+00
  3.06137991e+01]
(65,)
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1600.2927513401837
gradient value of function right now is: [-2.27662228e-01  2.90005975e-01  1.50995587e-02  2.84261218e-03
  2.27662228e-01 -2.90005975e-01 -1.50995587e-02 -2.84261218e-03
 -3.51041839e-02 -3.86213233e-02 -2.01581467e-02 -3.34200362e-02
 -5.18445579e-04 -7.38316945e-02 -5.84685916e-01 -1.33374089e-02
 -2.37281240e-03  2.38291726e-04  1.44305440e-03 -1.12485378e-05
  6.14914217e-10  7.89744799e-03 -3.29254681e-03  3.95111389e-04
  2.98860390e-08  2.14139735e-03 -8.99796777e-04  9.30798064e-15
 -1.65938932e-01 -1.35295129e-01 -3.95209188e-03 -7.77076586e-02
  1.65957002e-02  3.75536057e-01  1.49041365e-04  2.69848627e-03
  4.73797804e-03 -4.60080968e-03 -1.48500851e-04  1.54471374e-05
 -2.54283938e-02 -1.22770591e-01 -2.58081581e-01 -2.41926746e-02
 -2.48596137e-03 -9.48895048e-01  2.00712628e-01 -9.06439950e-02
 -6.44658484e-02 -7.53986937e-02 -5.11001873e-03 -7.30116713e-02
 -1.39752380e-02 -1.20184798e-02 -1.55465603e-01 -1.05468468e-02
  1.01518039e-02 -6.09503656e-01  3.25522844e-01 -9.62017810e-01
 -4.30012359e-02  5.37308387e-01  7.51078169e-01 -1.45394824e+00
 -2.62327170e+00]
supnorm grad right now is: 2.623271703403661
Weights right now are: 
[ -0.56344874   2.80684814  -4.34222959   3.37811815   0.81801745
  -2.91553983   4.74116686  -4.09414653 -11.31314902  13.02902764
  15.59280785 -17.0252046   39.41602999   6.98732186   3.58829042
  -6.70362359 -14.14432836 119.33658883  36.69734675  -5.02378245
  19.45504739  37.29899902  35.25265486 -24.56028968  79.39390101
  54.3230951   -8.91658767  35.44074817  -8.11442328   9.40959749
   7.61528616  -6.77870843  15.49747041   1.18151726 195.63272018
  24.02112036 -18.13499983  21.46987462  17.1141428  193.2622696
   9.83974547   3.55230693  -2.35796332  46.59994288   2.04115984
   0.56171597  -1.925354     7.18714976 -28.70713566  31.89803668
  32.15784482  -9.30443974  -1.62685222  56.62240253  -2.76483389
  46.40272141   5.32535308  -2.82589898  -3.57309988  -3.86053044
   6.98120755   1.13738701   3.12068982  -2.90888355  30.49237447]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1600.205244333196
gradient value of function right now is: [-2.57316974e-01  3.02727502e-01  1.73957737e-02  2.26250815e-03
  2.57316974e-01 -3.02727502e-01 -1.73957737e-02 -2.26250815e-03
 -1.49041629e-02 -1.88244406e-02  5.01344601e-04 -1.29430823e-02
 -6.65072648e-04 -7.50907919e-02 -6.13764442e-01 -1.73860726e-02
 -2.66354364e-03  1.53859577e-04  1.49422527e-03 -1.23754947e-05
  8.82125830e-10  8.18006953e-03 -3.56019437e-03  3.96303605e-04
  5.67608999e-08  2.69778757e-03 -9.93308282e-04  1.20737794e-14
 -1.86894928e-01 -1.62429370e-01 -3.85157872e-03 -9.32424441e-02
  1.84486647e-02  3.90885915e-01  1.71048111e-04  2.88144817e-03
  5.04646651e-03 -7.07069625e-03 -1.83090243e-04  1.49037966e-05
 -2.87487010e-02 -1.28648607e-01 -3.09273605e-01 -2.75799681e-02
 -5.68170925e-03 -9.93497651e-01  2.45856643e-01 -9.44260549e-02
 -7.33072354e-02 -8.62486631e-02 -6.45129595e-03 -8.30294432e-02
 -1.59023112e-02 -1.38893073e-02 -1.89770555e-01 -1.24427793e-02
 -1.39147304e-02 -7.14032006e-01  3.49348332e-01 -1.08632315e+00
 -5.31546143e-02  6.49192043e-01  8.20412185e-01 -1.66510300e+00
 -2.91755951e+00]
supnorm grad right now is: 2.917559514214496
Weights right now are: 
[ -1.05582837   2.97895297  -1.58419379   2.67161646   1.31039708
  -3.08764466   1.98313105  -3.38764485 -10.88825322  12.92320994
  15.94319281 -16.92315009  33.71422731   7.17820191   3.40119554
  -6.86183415 -13.73892586 120.62835053  34.84751808  -6.02391504
  19.45625345  37.32635435  34.61197742 -26.74695619  80.96769798
  54.77297798  -8.97667631  35.44075117  -8.08811275   9.63251587
   4.77743641  -6.96112824  17.81797652   1.42970931 200.37822606
  19.4251186  -19.15397406  20.73540483  18.77535753 197.01763373
  10.57481706   4.07296577  -2.29683504  46.5288299    1.88521633
   0.59239862  -2.020179     7.12622282 -27.93687914  33.21600602
  30.14005983  -8.47423089  -1.25478469  58.2221823   -2.98165162
  45.21413619   5.10055284  -2.01354995  -3.32394805  -4.17541547
   7.18780571   1.15418718   3.5209543   -2.97463036  30.64023091]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1600.2735747006125
gradient value of function right now is: [-1.98959325e-01  3.07401035e-01  1.76861104e-02  3.28973535e-03
  1.98959325e-01 -3.07401035e-01 -1.76861104e-02 -3.28973535e-03
 -1.35413818e-02 -1.71793722e-02  1.27830365e-03 -1.18630884e-02
 -5.37700038e-04 -7.33494785e-02 -6.01763139e-01 -1.42942091e-02
 -1.98427293e-03  2.55568600e-04  1.52238687e-03 -6.50600108e-06
  8.61117904e-10  7.68280343e-03 -3.61972980e-03  3.69537735e-04
  3.75572431e-08  2.23889373e-03 -7.01147236e-04  9.84803099e-15
 -1.72414475e-01 -1.38338182e-01 -7.01012747e-03 -8.06671109e-02
  1.78370439e-02  3.94964849e-01  1.36557305e-04  2.70282385e-03
  4.71576551e-03 -5.46830451e-03 -1.41216266e-04  1.45878344e-05
 -2.88316325e-02 -1.18302691e-01 -2.81776657e-01 -2.52305892e-02
 -8.87833460e-03 -9.50498597e-01  2.02604583e-01 -9.25180428e-02
 -5.72766917e-02 -6.60114178e-02 -5.56027061e-03 -6.43215783e-02
 -1.45566809e-02 -1.21702003e-02 -1.60341199e-01 -1.04309740e-02
  2.08374689e-03 -6.27152910e-01  3.20350739e-01 -9.81665352e-01
 -6.29424225e-02  6.07362245e-01  7.60430271e-01 -1.47413474e+00
 -2.87391643e+00]
supnorm grad right now is: 2.8739164312693055
Weights right now are: 
[ -1.36611869   3.20475863  -3.37781832   3.0695656    1.6206874
  -3.31345032   3.77675559  -3.78559398 -10.81486164  13.53750317
  16.30996217 -16.71996919  31.96036105   6.94652304   3.82479772
  -6.63498795 -14.40941409 123.58505377  38.04206382  -6.14999938
  19.45286364  37.31769173  34.52542148 -29.80803194  81.03145911
  56.61752743  -9.46947089  35.44075121  -7.98783077   9.47589889
   7.64540718  -6.70547534  16.60650931   1.09652252 205.42792773
  22.42380267 -20.81810271  21.15277984  19.07732836 201.20867826
  10.27016658   4.57110024  -2.75735655  46.75312273   2.53098234
   0.56796522  -2.2546349    6.00072443 -27.36527872  34.56330347
  33.00468987  -7.63369957  -1.2738156   58.66500543  -3.20601421
  44.8815601    5.41621042  -1.52238958  -3.4281931   -3.83090217
   6.63034975   0.73205607   3.23574363  -3.10183267  30.62002456]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1179.4772901115896
W_T_median: 1078.9989055310598
W_T_pctile_5: 933.2576248660081
W_T_CVAR_5_pct: 892.6107934592484
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.6
F value: -1600.2735747006125
-----------------------------------------------
