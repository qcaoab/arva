tracing parameter entered from terminal:  0.4


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.488305226189
gradient value of function right now is: [-6.44979289e-01 -1.05658207e+00 -1.33235190e+00 -1.28755581e+00
  6.44979289e-01  1.05658207e+00  1.33235190e+00  1.28755581e+00
 -5.00451893e-02 -1.11885081e-01 -2.14480284e-04 -1.61442916e-02
  5.85135128e-02  2.62119056e-02  8.32731205e-02  2.31828341e-01
 -6.62965841e-01  2.42969765e-01 -4.02937910e-02 -1.01879846e-01
 -2.68410221e-01  3.41893739e-01 -4.39487415e-03  6.27171245e-02
  7.27679824e-01  3.40933545e-01  2.16992902e+00 -3.19377434e-03
  9.13423574e-01  8.46236440e-01  1.20667655e+00  5.43229545e-01
  4.37323029e-01  3.48022468e-02  1.49336636e-01  4.10180057e-01
 -1.09298697e-01 -3.50931858e-01 -3.37959895e-01 -8.19321379e-02
 -4.26126025e-01 -4.26650325e-01 -4.92419933e-01 -4.11334226e-01
 -2.38458309e-01 -2.39399265e-01 -2.62545333e-01 -2.17438663e-01
 -1.07887316e-01 -1.06229181e-01 -1.63986973e+00 -1.00270850e-01
  7.34377442e-02  7.28257431e-02  6.99155740e-01  6.59732713e-02
 -3.64758863e-01  1.13457474e+00 -2.98428690e-01  9.38981350e-01
  6.48308625e-01 -2.11808918e+00 -1.95252973e-01  9.71106138e-01
 -6.00470196e+00]
supnorm grad right now is: 6.0047019608261
Weights right now are: 
[-1.2334232  -1.60761759  2.59424982  1.12883205  1.48799191  1.4989259
 -2.19531255 -1.84486043 10.1665506   9.43092181  8.37366628  7.56951022
  6.86051538  1.81938525 -7.55447586  0.5261236   4.21812218 -1.10599287
  2.65194797  3.68507776  4.95957137  0.27331533  2.39971434  4.47089536
  3.91446009  2.52032686 -1.29532102  2.65836616 -1.85465006  2.68827541
  4.76295095 -4.31631919  1.80246875  3.00788696 12.02168759 -4.96596674
 -1.3878166  -3.90692425 12.13019403 -5.22435164  1.98123703  0.90457188
 -2.39524245  1.77220342  0.454148    1.30523382  3.75442018  1.38793378
 -6.98682505 -5.17037332  2.07577326 -5.97207938 10.16839788 10.14382615
 -2.95561761  9.92927314  2.83610065 -2.51860853  2.81922571 -2.54099872
  4.29738386  1.15196032  3.06855414 -2.53042638 30.89130438]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.5147306177291
gradient value of function right now is: [ 3.12946117e-04  4.99934961e-02 -1.76490108e-01  2.55668051e-02
 -3.12946117e-04 -4.99934961e-02  1.76490108e-01 -2.55668051e-02
 -2.60073276e-05 -8.50491578e-06 -3.39566122e-09 -9.90364838e-07
  1.77950546e-02  9.92029574e-02  4.59252710e-02  1.00969731e-01
 -5.93511232e-02  7.71195604e-01 -1.07615552e-02  3.35780869e-01
 -6.99093586e-03  7.11808663e-04  1.32366949e-06  3.63257544e-04
 -2.08296180e-01 -1.00421751e-01 -7.00345577e-02 -2.28032116e-01
  1.45302568e-01  7.94902946e-02  1.17650731e-01  1.19736766e-01
  2.77165831e-01  1.41035715e-02  8.10247455e-02  2.31148123e-01
 -4.06691976e-01 -4.15732170e-01 -4.37067718e-01 -4.41593831e-01
  1.98054304e-02  2.15041150e-02  4.91601692e-02  1.70005014e-02
 -9.24047072e-03 -1.29872578e-02 -1.48447229e-01 -5.63348905e-03
 -5.65699966e-02 -3.69968562e-02 -1.01981065e+00 -6.37002234e-02
  3.26117982e-02  2.32288098e-02  5.36163514e-01  3.54293581e-02
  2.92684507e-01  1.08774865e+00  4.29032134e-01  7.82461459e-01
 -2.61954642e-01 -1.13546911e+00  1.55187042e-01  1.04042608e+00
  3.58340951e+00]
supnorm grad right now is: 3.583409509348154
Weights right now are: 
[ 3.03591749e-01 -2.71222996e+00  3.06831408e+00  2.24749625e-01
 -4.90230381e-02  2.60353827e+00 -2.66937681e+00 -9.40778008e-01
  2.31019496e+01  2.26073018e+01  1.06473393e+01  1.47334130e+01
  1.24219062e+01  4.66798213e+00 -1.12137861e+01  1.55389262e+00
  4.02539512e+00 -8.48448924e-01  4.46896233e+00  3.87961965e+00
  9.34197473e+00  5.32871668e+00  2.90010732e+00  4.38170124e+00
  4.28935332e+00  1.36346921e+00 -1.84966986e+00  4.15089999e-01
 -2.79319283e+00  2.57747797e+00  4.66184625e+00 -5.54763737e+00
  1.37147156e+00  1.20743265e+00  1.48805529e+01 -6.55052255e+00
 -1.17616597e+00 -4.48148960e+00  1.24908572e+01 -6.12003030e+00
  1.94505728e+00 -9.75759787e-03 -2.50302740e+00  3.20236140e+00
  4.93904624e-01 -5.05196964e-01  4.05839690e+00  4.66059841e+00
 -9.88655130e+00 -7.86023411e+00  2.63567344e+00 -9.07740504e+00
  1.35588689e+01  1.38633606e+01 -2.79612841e+00  1.28293418e+01
  3.48563720e+00 -2.69091461e+00  2.78042239e+00 -2.74525029e+00
  4.50271660e+00  1.16061262e+00  4.19006846e+00 -2.73154228e+00
  3.10408827e+01]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.3319098354305
gradient value of function right now is: [ 3.22214387e-05  1.06325714e-01  2.12454721e+00  9.25386895e-03
 -3.22214387e-05 -1.06325714e-01 -2.12454721e+00 -9.25386895e-03
 -3.61748157e-05 -4.10833328e-04 -9.98564758e-08 -1.07008900e-06
  5.75905791e-02  2.10332653e-01  4.35206274e-02  1.04912506e-01
 -1.09460294e+00 -3.31128712e+00 -7.70639198e-02 -1.22894241e+00
 -3.18719355e-03 -4.87181155e-03 -3.50344745e-06 -2.33356886e-04
  1.58748397e+00  4.35270882e-01  2.15925134e+00  3.57421225e-01
 -7.91502573e-01 -2.89545537e-01 -7.19986763e-01 -3.78955573e-01
  6.00002239e-01  1.39341805e-01  2.67473783e-01  4.81900588e-01
  1.11878152e+00  5.49026718e-01  8.04489818e-01  8.84165843e-01
 -2.72105322e-01 -3.89718055e-01 -9.79412530e-01 -2.40099985e-01
 -5.50675688e-03 -6.33151532e-03  3.17354581e-01 -4.99096190e-03
 -4.46223807e-03 -2.46662125e-02 -1.59335217e+00 -8.43470134e-04
  5.61911605e-03  1.05518564e-02  7.70744982e-01  4.49896012e-03
  1.06670650e-04  4.47063811e-01 -5.34849541e-01  9.47312232e-01
  4.77910454e-01 -2.00487008e+00  1.78991163e-01  1.88332057e-01
  1.54269876e+00]
supnorm grad right now is: 3.311287123011277
Weights right now are: 
[  3.24760333  -2.91035947   3.1727937    0.87469419  -2.99303461
   2.80166778  -2.77385643  -1.59072257  31.66174782  23.67057178
  10.58172501   9.88145811  16.04464824   6.71293996 -12.68166683
   1.46916279   4.23194146  -0.6707659    7.53506163   2.61198766
  22.85585754  11.87173545   3.55406405   9.07532275   4.76311865
   1.23671286  -2.12055692   1.59552551  -2.90024234   2.52345638
   5.59253013  -5.4042074    1.7950293   -2.47237918  16.92599143
  -7.2298537   -1.00672991  -4.33660397  12.8222469   -6.35553688
   2.2305261   -1.59777295  -2.85691496   4.53666441   2.94017509
  -1.25941288   4.49533839   9.07881832 -12.04522216  -8.94105151
   2.724794   -11.31021419  15.64211741  17.03036035  -2.24282056
  14.12391201   3.94853423  -3.17150333   2.25283003  -3.36829672
   4.70361117   0.98542523   4.48839491  -3.16967731  31.0498631 ]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.1418139430164
gradient value of function right now is: [ 1.22206736e-02  2.14969132e-01  3.02441522e+00  5.37663234e-02
 -1.22206736e-02 -2.14969132e-01 -3.02441522e+00 -5.37663234e-02
 -8.94387181e-03 -5.96423495e-03 -5.68704648e-06 -4.63130303e-04
  1.82642343e-01 -5.71242289e-02 -1.21257720e-01 -1.88197658e-01
 -1.77886731e+00 -1.29061712e+00  3.55926019e-02 -9.05354462e-02
 -3.26908588e-02 -2.60129260e-02 -2.43587631e-05 -1.82161653e-03
  2.33060927e+00  4.03270068e-01  3.81174754e+00  1.70592665e-01
 -9.78125607e-01 -3.33809125e-01 -1.05553891e+00 -3.14438837e-01
 -8.37911627e-01 -1.64473469e-02 -2.27103096e-01 -6.41416299e-01
  2.02150763e-01  2.09566437e-01  2.70199674e-01  1.52297041e-01
 -4.75207535e-01 -1.03327281e+00 -1.04446400e+00 -4.27630371e-01
 -1.47128702e-02 -3.33153590e-02 -5.46994944e-02 -1.25984784e-02
  1.23473251e-01  2.06085680e-01  2.85402314e+00  1.25360504e-01
 -6.23562777e-02 -1.07951138e-01 -1.64127412e+00 -6.36639659e-02
  9.23792534e-01 -2.52334844e+00  8.03227948e-03 -2.71122243e+00
 -1.22686909e+00  5.53233887e+00  1.16799966e+00 -2.63233488e+00
 -1.78374579e+01]
supnorm grad right now is: 17.837457915799693
Weights right now are: 
[  3.44870292  -3.07081344   2.95267028   2.39425284  -3.19413421
   2.96212175  -2.55373301  -3.11028122  35.82325092  19.36556453
  12.01904172  11.33855305  17.70098412   7.96648555 -14.08845055
   1.56435356   4.54487265  -0.94443077   9.87106597   2.21463594
  27.82452634  11.54626587   9.54852948  15.79860154   4.86006333
   1.87554486  -1.9181341    2.2859668   -3.11145661   2.57062656
   5.55484671  -5.09951366   1.61863917  -4.9027217   17.41437537
  -8.20116138  -1.16947056  -5.54719259  12.81037937  -7.29562019
   2.78958309  -2.03779037  -2.54498549   5.20112167  10.08954542
   0.88317906   4.10762386  17.32368198 -14.2238421   -8.93883607
   2.82065391 -13.56549658  17.14677558  20.34330599  -2.44445851
  15.19161111   4.00190905  -3.34801215   1.88647857  -3.13851874
   4.70771003   1.00314261   4.36776904  -3.25860355  30.94654184]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.1303827213922
gradient value of function right now is: [ 1.60133464e-02  2.52553528e-01  1.46091143e+00  5.90319235e-02
 -1.60133464e-02 -2.52553528e-01 -1.46091143e+00 -5.90319235e-02
 -8.94155652e-03 -9.99142549e-03 -5.66636459e-06 -9.80663415e-04
  1.16369090e-01  2.39502393e-01  7.15481492e-02  1.21063212e-01
 -8.98717798e-01  1.42317711e+00  5.37962412e-02  1.13785779e+00
 -3.31370668e-02 -4.02972444e-02 -2.27523165e-05 -3.79362526e-03
  1.28451615e+00  4.72812206e-01  1.87358486e+00  9.04953652e-02
 -4.26767631e-01 -2.34331543e-01 -5.38473851e-01 -9.60642710e-02
 -1.49797284e-01 -4.28562976e-02 -1.26345073e-01 -5.31337860e-02
 -6.55138485e-01 -6.44177466e-02 -2.83252946e-01 -4.12807863e-01
 -6.59437413e-02 -3.01009259e-01 -4.16479404e-01 -6.90590850e-02
 -2.27692662e-02 -7.55921335e-02 -2.74925185e-01 -2.37722440e-02
  1.12344937e-01  2.28263981e-01  1.97723717e+00  1.21698664e-01
 -5.90144928e-02 -1.24698910e-01 -1.06529112e+00 -6.40276073e-02
  8.25412738e-01 -2.57378625e+00  1.29533342e+00 -3.07005391e+00
 -1.06854031e+00  3.83419458e+00  9.70702709e-01 -2.81890380e+00
 -1.13887099e+01]
supnorm grad right now is: 11.388709931037294
Weights right now are: 
[  3.51270972  -3.06563286   2.91436201   3.04700971  -3.25814101
   2.95694117  -2.51542474  -3.7630381   39.21518054  19.11873695
  12.29088505  14.78122745  20.3113674    9.43392859 -14.83383731
   2.40291368   4.41605038  -0.6028041   11.07098569   2.12391393
  31.2707468   11.74652019  10.95262039  19.83199822   4.58242294
   2.33472889  -1.92720037   4.2990273   -3.27473555   2.379711
   5.8520467   -5.41352056   2.06290282  -5.00015626  18.60382277
  -8.38933037  -1.30851896  -5.92227248  13.54678577  -8.14186154
   2.38817727  -1.56438512  -2.6863897    4.69525555  13.99024469
   0.8137322    3.05369326  21.7402835  -16.17424287  -7.65450124
   2.83736984 -15.59008844  18.78360521  23.77388621  -2.48257069
  16.50313608   4.31333474  -3.50278048   1.80793543  -3.42624981
   4.71094115   0.68886088   4.35388878  -3.39218153  30.9572496 ]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.7132464626409
gradient value of function right now is: [ 3.46401827e-03  1.57156565e-02  9.80753520e-02  1.11428209e-02
 -3.46401827e-03 -1.57156565e-02 -9.80753520e-02 -1.11428209e-02
 -1.92346360e-03 -1.74765990e-03 -6.52561048e-07 -6.04360955e-04
  2.50044854e-02 -1.48847256e-01 -1.30862845e-01 -1.70195972e-01
  1.22763375e-01  6.91489546e-01  3.69503534e-02  2.39355639e-01
 -8.78927896e-03 -7.69003425e-03 -3.22117182e-06 -2.90287004e-03
 -2.06363558e-01  1.82205510e-01 -4.31027377e-01  7.11306087e-03
 -2.14713871e-01 -2.38440380e-01 -2.61044792e-01 -6.06187566e-02
 -8.47005628e-01 -1.78529079e-01 -2.81621541e-01 -6.20066321e-01
 -1.62051616e-02  2.00463447e-01  1.55380781e-01 -1.23066011e-02
  1.68089621e-01  1.47745185e-01  5.53085426e-01  1.69377461e-01
 -8.29598263e-03 -1.25446231e-02 -4.77044773e-01 -9.29779473e-03
  4.30147676e-02  1.45448207e-01  2.64178343e+00  4.98730999e-02
 -2.48053627e-02 -9.58736288e-02 -1.54029568e+00 -2.85580791e-02
  2.12833394e-01 -1.29623016e+00  5.33204577e-01 -3.26400037e+00
 -9.58259753e-01  4.35105582e+00  2.00321201e-01 -1.41574547e+00
  8.09017225e+00]
supnorm grad right now is: 8.09017224842485
Weights right now are: 
[  3.42591973  -3.19418796   2.72994047   4.34837558  -3.17135102
   3.08549627  -2.3310032   -5.06440396  42.333578    17.86181562
  12.28872591  16.40918554  22.18827873  10.03853163 -16.29670684
   2.26808831   4.48539171  -0.907512    12.83539344   1.93177508
  33.0431814   11.24509432  11.24928401  20.77302625   4.37014669
   2.36628351  -1.78255115   8.26619753  -3.3900144    1.12344862
   5.91779808  -6.71652023   2.14157592  -5.7571028   18.90977005
  -9.08508953  -1.73772065  -8.31386534  13.02728775  -8.69030136
   2.67143369  -1.29795058  -2.45617574   4.79793158  17.93408334
   0.20935502   2.49189618  25.6924592  -18.37708416  -5.54973424
   2.70686511 -17.69310908  19.43804567  27.2191597   -2.51442664
  16.95650955   4.49216169  -3.62243221   1.09144536  -2.93435806
   4.44166728   1.19113666   4.6519156   -3.44374067  31.16698689]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.0101476116977
gradient value of function right now is: [ 1.63701978e-03  1.15285842e-02 -9.17127406e-01 -7.37697769e-05
 -1.63701978e-03 -1.15285842e-02  9.17127406e-01  7.37697769e-05
 -1.81065391e-04 -1.81942242e-03 -1.53660576e-06 -1.53021583e-03
 -1.30533145e-02  1.11052082e-02  4.26623193e-03  1.79508369e-02
  4.08361621e-01  1.91791777e-01  1.41002989e-02 -2.88986381e-01
  3.68846835e-03  2.44586379e-03 -3.18490513e-06 -3.35269913e-03
 -1.04175185e+00 -5.08556199e-03 -1.21261806e+00 -6.95850373e-03
  1.16772670e-01 -1.03546368e-01  9.74069039e-02 -1.73641482e-02
 -9.42568930e-02 -2.08297775e-02 -3.72436897e-02 -5.04674990e-02
  4.42195527e-01  2.43016342e-01  3.59027072e-01  1.07204080e-01
  8.12811461e-02  3.28908574e-01  5.43818687e-01  8.40475439e-02
  1.37881372e-02  1.58733287e-01  2.27828875e-01  1.44165898e-02
 -3.78422006e-02 -2.34854432e-01 -4.90837756e-01 -4.10812308e-02
  1.59451523e-02  5.11147790e-02  2.32390996e-01  1.78631173e-02
 -3.87207331e-01  9.16392412e-01 -6.91357121e-01  1.49107375e+00
  3.26617111e-01 -6.53334097e-01 -4.91021964e-01  1.06661088e+00
  1.58353901e+01]
supnorm grad right now is: 15.835390131065578
Weights right now are: 
[  5.07795304  -2.66550689   2.5633071    4.89221266  -4.82338433
   2.5568152   -2.16436983  -5.60824104  44.93197278  15.71860872
  12.03187013   9.45043529  24.37914743  11.32222433 -16.11299901
   2.41968454   4.20239432  -0.92190176  12.86471198   2.29028506
  35.53693997  12.46562068  10.23302087  13.31450128   4.22324093
   3.5610556   -1.82906713  17.36264352  -3.21315083  -0.23639901
   6.06256914  -9.77204485   2.14510785  -5.83983045  18.58172014
  -9.95574077  -1.37058727 -10.75809278  13.49035981  -9.65489201
   1.93454076  -1.21853032  -2.75621923   4.09728178  21.15099412
   1.83297573   2.54693263  28.94743396 -20.45994793  -3.5678899
   2.61025655 -19.69925867  20.72404482  29.76820565  -2.61858516
  17.90859745   4.9434987   -3.68588832   0.49595188  -2.96413971
   4.6885388    1.18011275   5.01559071  -3.52694499  31.1310786 ]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.1336512518615
gradient value of function right now is: [ 7.73395246e-03  4.66637655e-02  1.35304841e+00  1.38110064e-02
 -7.73395246e-03 -4.66637655e-02 -1.35304841e+00 -1.38110064e-02
 -4.43024906e-03 -1.50638029e-02 -3.52516317e-06 -2.99558152e-03
  4.04016648e-02 -1.44244915e-02 -5.02814830e-02 -5.29766534e-02
 -1.02883508e+00  9.11580496e-01  3.93338291e-02  9.58199187e-01
 -8.29363795e-03 -1.93188017e-02 -3.50669772e-06 -2.98371303e-03
  1.81472245e+00  1.13682763e-01  2.69846752e+00  5.24133137e-03
 -2.97085097e-01 -9.90043889e-02 -3.04921580e-01 -2.78248087e-03
 -5.40428704e-01 -1.47675384e-01 -2.14201212e-01 -2.78489781e-01
 -1.85748079e-01  2.17015493e-02 -3.74231304e-03 -1.05184862e-01
 -3.48897012e-01 -1.16933278e+00 -4.87109484e-01 -3.39007102e-01
 -9.98008001e-03 -6.16621952e-02 -4.88827598e-01 -1.08694457e-02
  3.91275259e-02  2.20316165e-01  1.73417273e+00  4.29669862e-02
 -2.08942016e-02 -1.14767977e-01 -1.15927581e+00 -2.34229134e-02
  5.29140286e-01 -1.29937913e+00  9.24182510e-01 -3.68660991e+00
 -1.09290289e+00  3.18987722e+00  7.28877878e-01 -1.46229288e+00
 -1.00559639e+01]
supnorm grad right now is: 10.055963888991691
Weights right now are: 
[  5.47484363  -3.59695388   2.57649986   4.15056347  -5.22027492
   3.48826219  -2.1775626   -4.86659186  47.04688304  14.83905157
  11.60129293   2.2965301   24.13735915  12.41246838 -16.97714436
   2.31837814   4.55684329  -0.97751464  14.3641776    2.41776154
  38.55813826  13.61774554   9.56074567   6.86280473   4.37055503
   3.98604553  -1.83589661  28.13835108  -3.03916437  -1.06286624
   6.38562967 -13.01347833   2.50311315  -6.16552957  18.45643292
 -11.05075754  -0.70561618 -12.84290833  13.78288331 -11.15456005
   1.91411066  -1.45727169  -3.53808019   4.16930254  23.58179171
   3.21744528   2.09207081  31.4948619  -21.72356681  -2.11392165
   2.58711246 -20.91996671  22.29349312  32.63496671  -2.3398982
  18.98391696   4.87237407  -3.68890435   0.32089117  -3.06861432
   4.9126206    1.21007481   5.0082656   -3.53033124  30.98349634]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.0031731407344
gradient value of function right now is: [ 2.39256821e-03  3.04221147e-02  3.10098464e+00  5.30878512e-03
 -2.39256821e-03 -3.04221147e-02 -3.10098464e+00 -5.30878512e-03
 -2.92108218e-03 -6.75711531e-03 -2.46805139e-07 -3.69835937e-04
  3.68033350e-02  7.88906525e-03 -2.35335216e-02 -3.19960119e-02
 -9.53485437e-01 -1.88801849e+00  3.12135459e-03 -3.26072240e-01
 -5.96145598e-03 -1.09099336e-02 -3.30644335e-07 -3.29046937e-04
  2.18258355e+00  1.46864229e-01  2.41724860e+00  3.49179838e-03
 -1.14474590e+00 -1.91811782e-01 -9.67961006e-01 -1.17388273e-02
 -1.59240882e-01 -3.13259993e-02 -3.50682504e-02 -8.04143081e-02
  3.65053412e-01  1.70281963e-01  2.67648886e-01  2.29195582e-02
 -1.37865891e-01 -1.30968274e+00 -5.47767178e-01 -1.43925805e-01
 -6.46383073e-03 -5.96899681e-02 -3.89263255e-02 -6.88378056e-03
  5.28995847e-02  6.07476705e-01  6.44277650e-01  5.68905782e-02
 -3.91676600e-03 -3.01414907e-02 -2.94479356e-01 -4.41089209e-03
  6.06255644e-01 -6.89132560e-01 -2.00864663e-01 -4.61936815e-01
 -9.02943666e-01  1.68172524e+00  7.55100146e-01 -8.15988964e-01
 -6.47273481e+00]
supnorm grad right now is: 6.472734808075246
Weights right now are: 
[  6.80977228  -4.02638022   2.43758378   5.19304813  -6.55520357
   3.91768853  -2.03864651  -5.90907651  46.78222623  14.48649018
  11.26977861  -1.37702681  24.21507817  12.68543451 -18.5233087
   1.29810428   4.64926836  -1.2595525   14.74331507   2.5144516
  39.56263563  13.82418295   9.1006369    2.24665328   4.31924494
   4.79210569  -1.95530437  32.00138675  -3.34337625  -2.73765884
   6.20937645 -17.85028683   3.00900296  -6.08161395  18.68302335
 -12.12389016  -0.23090203 -15.04173541  13.39544114 -12.64499334
   2.96052502  -1.35586409  -4.43974578   5.34680592  25.97089297
   4.75606188   1.64407111  33.97476635 -21.4444914   -0.65454226
   2.62630852 -20.76908268  24.58186919  36.49875376  -2.34078597
  20.64347456   5.3721572   -3.6769382   -0.37989995  -3.01258409
   4.82497857   1.08767016   5.33205428  -3.53563468  31.01616007]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.3412040437956
gradient value of function right now is: [-6.76959066e-03 -8.14400053e-02 -8.00199511e-02 -1.50570836e-02
  6.76959066e-03  8.14400053e-02  8.00199511e-02  1.50570836e-02
  1.04382410e-02 -8.69796738e-03 -1.62790571e-04 -1.82754032e-02
 -6.54194552e-02 -2.69535750e-02  2.59913264e-02  3.79636169e-02
  2.48957629e-01 -3.86954360e+00 -5.23895788e-02 -3.18418561e+00
  1.62314391e-02  1.73965429e-02  1.25637181e-06  3.10978912e-04
 -6.62040043e-01 -1.42718936e-01 -7.65402823e-02  1.66064295e-03
  5.59621527e-01  1.81512595e-02  5.20614171e-01 -2.41590898e-02
  8.19389015e-01  1.74816603e-01  2.42539250e-01  2.54880933e-01
  1.75727543e+00  3.96784369e-01  6.54955833e-01  2.64711772e-01
 -1.31525371e-01  5.02923372e-01 -3.10818581e-01 -1.25064325e-01
  3.88042640e-02  7.18752573e-01  2.02459737e+00  3.62477726e-02
 -7.86773176e-02 -1.58885349e+00 -3.63871727e+00 -7.24372853e-02
  3.91366153e-02  2.27539468e-01  2.44558443e+00  4.39161489e-02
 -1.16073033e+00  3.08614732e+00 -3.33619146e+00  1.08004967e+01
  1.28351660e+00 -4.51211006e+00 -8.89848939e-01  3.18824577e+00
  1.91529925e+01]
supnorm grad right now is: 19.15299251268109
Weights right now are: 
[  5.85220635  -3.79395876   2.48936777   5.12923283  -5.59763764
   3.68526707  -2.0904305   -5.84526122  47.87153923  14.41836649
  12.41661146  -6.87546483  26.38350952  13.7254097  -18.09313769
   1.55705217   4.57589552  -1.34311998  15.24759638   2.36884082
  40.49248603  17.17637087   9.00012729   1.74432946   4.08981877
   5.7523587   -2.06429946  37.84025707  -2.07199001  -3.72513144
   6.8932824  -24.03103189   3.74862307  -7.55417792  17.76546554
 -12.95127072   0.45603338 -16.54122877  13.05042405 -13.95697014
   1.99970269  -1.88428979  -4.91959159   5.2644837   29.98074137
   5.18436401   1.87127014  38.18387436 -20.73607663  -0.47637885
   2.75788456 -19.71551019  26.29613266  40.49640953  -2.08081537
  21.41203496   4.78552244  -3.97703945  -0.41745711  -3.08979368
   4.63286841   1.13566436   5.5465132   -3.75450215  31.05224226]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1369.2193293295686
gradient value of function right now is: [ 3.04300154e-02  1.54273687e-01  3.18260038e+00  4.36035099e-02
 -3.04300154e-02 -1.54273687e-01 -3.18260038e+00 -4.36035099e-02
 -2.02988856e-02 -2.42802627e-02  1.24822669e-04  8.72531201e-03
  1.28085003e-01  2.15027524e-02 -6.92712225e-02 -9.13327145e-02
 -1.38328020e+00  2.18109651e+00  2.41359308e-02  2.44262402e+00
 -4.64398338e-02 -5.33851355e-02 -8.19343711e-07 -1.96631787e-03
  3.71925100e+00  1.84768925e-01  3.71146091e+00  8.24937655e-04
 -9.38173397e-01 -1.03204873e-01 -6.96245522e-01  2.30499566e-03
 -6.77515803e-01 -1.61830466e-01 -1.54975969e-01 -2.79696229e-01
 -1.29368745e+00 -2.76839166e-01 -3.78742362e-01 -2.01858778e-01
 -2.81903984e-01 -1.49964097e+00 -3.59075807e-01 -2.25659518e-01
 -4.66783945e-02 -6.11541888e-01 -1.88944410e+00 -4.34989578e-02
  1.16564679e-01  1.19768380e+00  3.12934514e+00  1.07310093e-01
 -4.52386116e-02 -1.97731048e-01 -2.34573263e+00 -4.86184794e-02
  1.37869242e+00 -3.84565572e+00  2.15156187e+00 -9.16851546e+00
 -1.86214878e+00  5.76403505e+00  1.37064308e+00 -3.91426172e+00
 -1.87851189e+01]
supnorm grad right now is: 18.78511894515763
Weights right now are: 
[  4.61981401  -4.3390668    2.57496429   6.15088677  -4.3652453
   4.23037511  -2.17602702  -6.86691515  49.29077581  14.79022666
  13.13975871  -7.22014683  28.44899778  13.92846675 -18.91784795
   0.94204932   4.69443316  -1.1537803   15.3224211    2.91814636
  41.84160492  16.62643051   8.98019588   2.60161829   4.17023165
   6.23062222  -2.12903425  43.85517932  -2.0803401   -5.10020725
   7.0705943  -33.36565279   4.66657923  -7.40635456  18.57336682
 -13.56495573   1.04990516 -17.74049807  12.58624152 -14.73184502
   1.75221499  -2.10918048  -6.45504486   6.07349153  32.84953528
   4.21805064   1.37434298  42.00801759 -20.9783927   -0.66950334
   3.13654494 -19.84871986  28.20339351  44.22594307  -2.30655416
  21.99538499   5.03223403  -3.87084638  -0.62754051  -3.26908496
   5.11471067   1.04487585   5.93924346  -3.66534263  31.05764208]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.0407556289929
gradient value of function right now is: [-4.05102179e-03  3.45176397e-02 -3.01047481e+00 -4.54522394e-03
  4.05102179e-03 -3.45176397e-02  3.01047481e+00  4.54522394e-03
  2.00854957e-03  7.86824284e-03  6.45681975e-05  4.56850609e-03
 -1.80928548e-02  1.31154271e-01  1.29217947e-01  1.41461110e-01
  9.80995841e-01  2.45766264e+00  1.36030335e-02  1.37358866e+00
  5.90261838e-03  4.55006825e-03  4.55432050e-08  1.43056301e-05
 -3.20823836e+00 -7.48448949e-02 -2.85694476e+00 -6.74954523e-04
  3.25851914e-01  2.28967309e-02  1.95241763e-01  2.69611694e-03
 -2.71031897e-04 -2.84800182e-03 -1.69956739e-02  4.89571331e-02
 -7.13174916e-01 -7.49355552e-02 -1.55768696e-01 -1.09708358e-01
  8.42121193e-02  7.97948528e-01  2.66397610e-01  6.35195185e-02
 -2.93750089e-03  1.54133941e-01 -5.19321012e-01 -7.22292885e-03
 -4.65345742e-02 -6.38759932e-01  4.82680706e-01 -3.47983305e-02
 -1.85018011e-02 -7.68958504e-02 -7.50367431e-01 -2.14557701e-02
 -4.53573770e-01 -7.01693105e-01  7.51148966e-01 -3.44482276e+00
  3.52857620e-01  5.74006791e-01 -3.78766134e-01 -8.19838432e-01
  3.28296480e+00]
supnorm grad right now is: 3.4448227574119237
Weights right now are: 
[  3.53882141  -2.68989934   2.34077103   5.63277272  -3.2842527
   2.58120765  -1.94183376  -6.3488011   51.28077948  14.20690001
  17.1474679   -7.45675156  29.98480246  15.15738336 -17.70682463
   1.52166497   4.79314964  -1.31937138  14.11693753   2.50667179
  43.43874805  18.8381539    8.93446128   3.20253053   3.73295989
   6.44071595  -2.56626004  51.11061391  -1.69255536  -6.77694239
   7.62273106 -36.5554288    5.89979896  -8.68079902  17.46114555
 -14.20855546   1.45505416 -17.78541682  12.87144408 -18.10332918
   1.11025879  -2.25531315  -6.33004322   6.17511955  35.49188159
   4.09282722   1.55994175  45.58591795 -20.17899783  -0.55276176
   3.21846258 -18.79102492  29.75203108  47.11785321  -2.09552576
  22.22451374   4.91550478  -3.87924686  -0.75067759  -3.34014114
   5.08930063   1.28428244   5.68646908  -3.58690007  30.97402424]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1366.9219328206914
gradient value of function right now is: [-5.35154936e-02 -1.12105880e-01 -7.65024277e+00 -1.76954055e-02
  5.35154936e-02  1.12105880e-01  7.65024277e+00  1.76954055e-02
  1.05643611e-02  8.04723398e-02  5.07069093e-05  6.79005623e-02
 -8.48436490e-02 -1.31811135e-01 -2.38768091e-02 -3.83711989e-02
  2.65273765e+00  3.51807911e+00 -6.61848528e-03  1.09480917e+00
  1.19842929e-02  1.48177513e-02  1.91703660e-06  1.15406056e-03
 -7.44318433e+00 -2.84611154e-01 -6.66849275e+00 -4.98667238e-03
  2.57556151e+00  2.84527096e-01  1.05862791e+00  1.72058327e-02
  8.30960678e-02 -2.28928618e-02 -2.24624899e-02  3.34800941e-03
 -1.34421951e+00 -4.26398457e-01 -6.32713217e-01  1.79949319e-02
  4.30028247e-01  1.87962386e+00  1.05200818e+00  3.12617457e-01
  1.10835528e-02 -1.32417398e-01 -3.46054181e-01  9.89675077e-03
 -2.14202825e-01 -1.11655484e+00 -1.71254303e+00 -1.70182491e-01
  2.79177493e-02  8.21192775e-02  1.05029769e+00  2.86226061e-02
 -1.44109513e+00  2.69923642e+00  9.11186791e-01  2.03328839e+00
  2.10334855e+00 -3.87994359e+00 -1.37647580e+00  2.50479502e+00
  3.13135813e+01]
supnorm grad right now is: 31.31358133514878
Weights right now are: 
[  2.54637654  -4.59028637   2.35180882   3.62628912  -2.29180783
   4.48159468  -1.95287155  -4.3423175   53.79857228  14.17458709
  25.32345859  -7.16786797  32.04863567  14.76692067 -18.66345473
   0.61213683   5.21030714  -1.15368694  16.55104956   2.78143037
  46.0031589   19.82807966   8.98991384   5.18362343   3.58269555
   6.46673023  -2.4859574   56.20189838  -1.06499266  -6.49677467
   8.04220294 -38.13596098   6.00325456  -9.44974647  16.14686377
 -15.09876506   1.884051   -18.70543623  11.86666485 -18.17933519
   1.46072225  -2.24706776  -6.03643704   7.96869742  37.43207401
   3.76881229   1.59224719  48.67065611 -20.53717979   0.11186089
   3.69386356 -18.75065063  33.00847243  50.31379984  -1.84717736
  23.98949326   4.67478311  -4.05292624  -0.87949652  -3.36931999
   4.59942551   1.25661034   5.94724701  -3.91019294  31.15138614]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.1645970794712
gradient value of function right now is: [ 5.46008214e-04 -1.16389252e-02  9.72112005e-01 -1.08360205e-03
 -5.46008214e-04  1.16389252e-02 -9.72112005e-01  1.08360205e-03
 -2.53651875e-05 -4.79255522e-03 -2.76142092e-06 -4.09586332e-03
  3.61050256e-03 -7.50440858e-02 -5.64327084e-02 -7.36601177e-02
 -4.89186340e-01 -1.01735647e+00  7.85058639e-04 -8.53004254e-01
  1.08367081e-04  1.23619986e-03 -4.40109041e-07 -3.01144022e-04
  1.24313465e+00  3.40872251e-02  1.38632863e+00 -7.57899330e-05
 -3.12810111e-02 -5.86171104e-02 -7.20988189e-02 -7.32511080e-04
 -2.42606551e-01 -8.49585689e-02 -5.13949563e-02 -1.37491966e-01
  5.42375165e-01  1.99167190e-01  2.29732974e-01  5.39355253e-02
 -1.11037970e-01 -5.03978585e-01 -1.31592355e-01 -7.20171362e-02
  7.51408750e-03  7.26505400e-02  2.30625309e-01  6.79074398e-03
  9.51887837e-03  8.63111656e-02 -1.44867802e-01  1.51720601e-03
  6.41484386e-03  1.79069089e-02 -7.43786630e-02  7.68928707e-03
  4.09161923e-02  5.70380088e-01 -5.56512100e-01  8.98437945e-01
 -2.55156199e-01  2.86605912e-01  1.17405280e-01  5.37813937e-01
  4.52511053e+00]
supnorm grad right now is: 4.525110532935522
Weights right now are: 
[  3.33223019  -4.36716539   2.35717379   5.58328235  -3.07766148
   4.2584737   -1.95823652  -6.29931074  53.07558614  13.33849934
  29.53335498  -6.35639898  34.62400889  15.47606135 -19.4242236
   0.33123622   4.82028063  -1.38366559  21.51142078   2.28141132
  46.76513868  16.96243889   8.86556756   4.89979513   3.7257838
   6.94792566  -2.10967364  62.30325504  -0.85054976  -7.9365625
   7.7126244  -40.61565965   6.04105802  -8.75575901  16.36204472
 -15.88328795   2.97480408 -18.49814154  12.61492152 -17.69949779
   0.30000769  -2.082126    -7.24195177   8.99410424  39.01470523
   3.98786933   1.30725907  51.86291957 -20.47271122   0.44501731
   4.00313603 -18.36473308  36.15747704  52.68630025  -1.96412424
  24.79878355   5.05310182  -4.08499266  -0.54257726  -3.50402914
   5.240577     0.89730888   6.70487638  -3.7668483   31.06709097]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.8410554192499
gradient value of function right now is: [-7.44025176e-03  3.37272998e-03 -2.30205446e+00 -5.64299842e-03
  7.44025176e-03 -3.37272998e-03  2.30205446e+00  5.64299842e-03
  2.58943321e-03  4.40768664e-03 -1.63927028e-04 -4.11176366e-03
 -1.41476597e-02  9.99959395e-02  8.83610624e-02  1.12094661e-01
  1.22975943e+00 -1.15670100e+00 -2.87138860e-02 -1.59186717e+00
  5.45110039e-03  6.67846530e-03  7.59406088e-08  1.51303348e-04
 -3.91833086e+00 -1.09143253e-01 -3.34447757e+00 -1.02877352e-03
  6.98786292e-01  1.45593445e-01  3.54045256e-01  3.82663842e-03
  8.69058894e-01  1.92589043e-01  1.15641007e-01  3.85195024e-01
  2.08502195e-01 -1.21852745e-01 -1.62691633e-01  8.97397440e-02
  1.68925963e-01  9.72942973e-01  1.94857022e-01  1.06277867e-01
  2.61544609e-02  1.02286208e-01  1.09925234e+00  2.51872117e-02
 -1.02393489e-01 -6.72835927e-01 -1.64448652e+00 -8.54949405e-02
  3.13748181e-02  1.28875151e-01  2.63191820e+00  4.16099375e-02
 -1.05414211e+00  2.73624228e+00 -6.69367381e-01  6.98085885e+00
  1.56013418e+00 -4.73819186e+00 -1.16672608e+00  2.92990097e+00
  1.46467914e+01]
supnorm grad right now is: 14.646791425336353
Weights right now are: 
[  2.8970854   -3.47171775   2.31188072   5.05706779  -2.64251668
   3.36302606  -1.91294345  -5.77309618  55.46330345  13.01239401
  34.83518482  -6.92940393  36.0406097   16.28710892 -19.1194775
   0.54131868   5.06175515  -1.45621261  20.04843652   2.35697406
  48.56285466  17.03322298   8.86178145   7.62141326   3.182214
   8.02309502  -2.02061985  69.01635436  -0.69899223  -8.7251881
   7.79231926 -45.82361965   7.80412676  -7.67298583  18.0317761
 -15.11777797   3.17254329 -18.83314419  12.08936049 -19.78223346
  -1.01154519  -1.81697516  -7.64910713   9.31745039  40.13168081
   3.83046196   1.67419507  55.29987095 -21.8394253    0.90766148
   4.27773848 -19.77407838  37.78961184  55.82523666  -2.00585439
  23.72392642   4.95745997  -4.04187835  -0.58337897  -3.41016921
   5.85115329   1.2028238    6.26971856  -3.62236422  30.99209634]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.702514450128
gradient value of function right now is: [-3.24893884e-02 -1.34400756e-01 -3.08315240e+00 -3.20519775e-02
  3.24893884e-02  1.34400756e-01  3.08315240e+00  3.20519775e-02
  1.12706116e-02  1.95526293e-02 -7.54222835e-06 -2.27780129e-03
 -9.32640765e-02 -1.06978366e-01 -6.10397357e-03 -8.43401605e-03
  6.69944157e-01 -1.13935914e+00 -5.09218352e-03 -1.38151730e+00
  2.13762056e-02  2.88895274e-02  4.92937316e-06  1.46887256e-03
 -1.66354009e+00 -1.71746325e-01 -8.40223573e-01 -2.25928672e-04
  1.63865939e+00  1.58387006e-01  6.59253649e-01 -2.20917271e-03
  1.08165434e-01  4.57277300e-02  3.15365986e-02  1.99786304e-02
  1.30579058e+00  3.80589295e-01  2.72310552e-01  1.27125326e-01
  5.71337210e-02  4.33714246e-01 -1.56456690e-02  4.58483129e-02
  3.65481180e-02  1.03096820e+00  1.72444708e+00  3.04206117e-02
 -6.28132842e-02 -1.60130737e+00 -1.45208887e+00 -5.27702801e-02
  1.77127170e-02  1.12307982e-01  1.06876097e+00  2.20157148e-02
 -1.13068500e+00  2.42416010e+00 -2.28983803e+00  7.06143670e+00
  1.29043725e+00 -2.74637796e+00 -9.48321877e-01  2.43810594e+00
  2.14305353e+01]
supnorm grad right now is: 21.43053534342562
Weights right now are: 
[  2.82025439  -4.69314601   2.26793505   4.3065403   -2.56568568
   4.58445432  -1.86899778  -5.02256868  59.09830335  13.37241403
  41.16192889  -6.36363549  34.06786063  16.40520277 -19.32575988
   0.18350921   5.59441901  -1.42286496  22.77151745   2.99506145
  52.13782284  16.95590294   8.8882438   11.00364032   3.21013241
   7.60552426  -1.7717237   76.57782988  -0.15539012  -9.50285373
   9.19592866 -52.46986728   7.81771463  -7.76538613  16.14106407
 -16.42142797   4.10045381 -18.73559895  12.04345025 -19.65142091
  -0.79606887  -1.85480155  -6.87046216  10.94686782  40.79856314
   4.41284774   1.58259146  57.51588452 -22.07652541   1.33678526
   5.08104265 -20.55670893  39.88498992  57.96104804  -2.29975068
  23.45414724   5.22466981  -4.31835242  -1.02605237  -3.49975522
   5.27741515   1.12886043   6.68672388  -3.87025755  31.15369028]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.0024799818063
gradient value of function right now is: [ 1.04422588e-02  4.43983279e-02  1.04545795e+00  4.50186852e-03
 -1.04422588e-02 -4.43983279e-02 -1.04545795e+00 -4.50186852e-03
 -5.19968212e-03 -1.61675934e-02 -1.26097846e-04  1.99986193e-03
  7.28701625e-03  1.50319626e-01  1.16197926e-01  1.38285341e-01
 -5.11847688e-03  3.36770271e-03 -3.23206965e-03  4.22772946e-01
 -3.30307635e-03 -8.35682450e-03 -1.49393643e-06 -9.46942733e-04
  4.15868790e-01  1.70061965e-01 -6.76088060e-01  4.64276346e-04
 -3.98105199e-01 -4.49578802e-02 -1.35904699e-01 -8.30136327e-04
  3.93735441e-01  1.23635273e-01  3.14481484e-02  2.21202577e-01
 -1.45194678e-01 -1.49507095e-02  5.29793474e-02 -4.15628270e-02
  8.84131500e-02 -2.44344433e-01  3.85342323e-02  6.67423182e-02
 -1.39578748e-02 -4.79477674e-01 -1.81389979e-01 -1.10454352e-02
 -5.45501797e-04  4.10639197e-01  2.71919019e-02 -1.51148039e-03
 -4.62596466e-03 -1.98297834e-02  3.87029932e-01 -4.83319971e-03
  3.62081469e-01 -5.05592742e-01  4.40110066e-01 -9.17169573e-01
  1.27236043e-01 -6.02264936e-01  4.90012172e-02 -6.19494039e-01
  4.68099178e+00]
supnorm grad right now is: 4.680991775914036
Weights right now are: 
[  5.31282722  -3.46504412   2.59772775   5.53118726  -5.05825851
   3.35635243  -2.19879048  -6.24721564  59.27765464  12.82570639
  46.34761556  -7.68713629  36.0377911   17.49909334 -19.4542151
   0.61865837   5.91010457  -1.30927495  25.56191856   3.0306617
  52.67564581  16.96284514   8.78665163   7.95122712   2.71445396
  10.04010893  -1.60117123  80.58767453   0.52138216 -11.15787753
   9.04481666 -58.79060024   9.28959971  -7.14053982  15.58261316
 -16.06317922   4.5170869  -18.87240666  11.55597752 -22.34754991
  -2.44888963  -1.34212747  -8.39314819  10.31698889  40.44831484
   4.34521255   1.27755769  59.14443178 -23.74620883   2.24041359
   5.62012504 -21.89847307  42.94044959  59.71624175  -1.95645447
  24.04778128   5.31936864  -4.48690407  -1.15686162  -3.44186064
   6.3600639    0.79301559   6.42719853  -4.24819647  31.04805248]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.2144806753251
gradient value of function right now is: [-1.77599421e-03  1.29961346e-03 -1.38004282e+00  2.94188984e-04
  1.77599421e-03 -1.29961346e-03  1.38004282e+00 -2.94188984e-04
 -1.19985141e-04  1.23700909e-02  4.13834157e-05  1.10610830e-02
  4.66560115e-03 -1.02211729e-02 -1.03640180e-02 -1.03625511e-02
 -1.74537361e-01  3.02506256e+00  3.42515270e-03  1.57290590e+00
 -4.01647923e-04 -9.06962146e-05  3.74226788e-08 -2.32562651e-06
  3.91336528e-01 -2.82274050e-02  8.59093283e-01 -6.85488641e-04
  3.60325760e-01  6.07403547e-02  5.05498313e-02  3.15351588e-03
 -6.42804917e-02 -6.35917349e-02 -4.29407579e-02 -1.98242874e-02
 -1.07727303e+00 -3.89347533e-01 -2.08772364e-01 -3.72314018e-02
 -7.72770956e-02  2.16393549e-02  1.04003330e-01 -4.95067099e-02
 -8.69490662e-03 -1.69487436e-01 -9.24457879e-01 -4.99277658e-03
  1.30216121e-02  4.43181176e-02  3.30518682e-01  8.66754790e-03
  4.39922215e-03 -3.05324114e-02  1.32408160e-01  7.10488081e-03
  2.01523408e-01 -3.20406982e-01  1.61086671e+00 -2.73403421e+00
 -2.71117329e-01  2.73670595e-01  3.25027768e-01 -1.66911394e-01
 -5.66773032e+00]
supnorm grad right now is: 5.667730317048513
Weights right now are: 
[  3.27453944  -4.52345452   2.31519251   5.75452692  -3.01997073
   4.41476283  -1.91625524  -6.4705553   62.09958635  14.11397551
  55.19140186  -8.0387711   33.69060641  16.60199134 -20.75312737
  -0.79043202   6.21732476  -1.1714626   23.10263712   3.06005784
  54.44225803  19.72633032   8.60535938  12.03403171   2.57700721
   9.67700219  -1.03652401  89.54005867   0.65621757 -12.19495638
   9.35419356 -64.62801506   9.78739343  -7.70468501  14.46156133
 -16.92605827   5.35956675 -18.76892427  11.03925202 -23.39518928
  -2.57200868  -0.79741826  -8.24498196  11.39461297  39.36497422
   4.6284171    1.22191595  60.75508069 -25.81271353   2.99827919
   7.82509804 -23.8135231   46.05602398  60.99269652  -1.95632915
  25.01563564   4.80041299  -4.1290109   -1.0196668   -3.44563713
   5.15232003   1.12286676   6.80638976  -3.82283675  30.95253484]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1365.8923943927314
gradient value of function right now is: [ 1.28185423e-02  1.11735806e-01  5.23794716e+00  1.14908417e-02
 -1.28185423e-02 -1.11735806e-01 -5.23794716e+00 -1.14908417e-02
 -5.93889069e-03 -1.78667223e-02 -2.88515132e-05 -4.11592357e-03
  8.35521566e-02  7.81125632e-02  1.30125706e-02  1.99868370e-02
 -9.28189867e-01 -3.73699655e+00 -7.58478874e-03 -1.40729960e+00
 -1.21444205e-02 -1.39030564e-02 -3.76590583e-06 -3.62488580e-04
  3.30178906e+00  9.66195162e-02  1.45248312e+00  4.37425050e-04
 -1.99787972e+00 -1.72547962e-01 -2.75008780e-01 -2.32449736e-03
  2.57244779e-01  6.13310810e-02  9.63709126e-03  7.71791108e-02
  1.07063523e+00  2.91191078e-01  1.14275445e-01  6.99562129e-02
 -1.19195931e-01 -8.51127850e-01 -2.54150305e-01 -7.61753345e-02
 -1.44944769e-02 -3.52589587e-01  8.33110972e-01 -5.89123499e-03
  7.02788843e-02  8.34107406e-01  2.80506593e-01  4.72577913e-02
  6.59918669e-03  6.75820221e-02  1.15810694e+00  9.12075151e-03
  8.57734333e-01 -1.99244507e-01 -1.53724149e+00  5.11888681e+00
 -1.05792424e+00  8.37813974e-01  7.45637225e-01 -8.78726210e-02
 -2.34232839e+01]
supnorm grad right now is: 23.423283857573967
Weights right now are: 
[  3.93935695  -4.31760624   2.38716793   6.47801713  -3.68478824
   4.20891455  -1.98823066  -7.19404551  62.85767556  15.1043107
  61.67163965  -8.72862185  30.44001917  17.69266147 -20.56648833
  -0.58042479   6.73235873  -1.47308984  25.36843899   2.48793181
  55.6432299   19.6963677    8.21477137   5.389293     2.72555035
  10.74990129  -0.95785009 105.84123863   1.30041764 -11.83855876
  10.03119456 -74.89664756  10.06088964  -7.7128144   14.45773615
 -17.41584425   5.991625   -18.12403963  10.41779542 -23.92272181
  -2.12196171  -1.28487552  -8.7921345   12.66042856  38.96363899
   4.31466359   1.39643042  62.15669026 -26.87684729   3.80500861
   8.81611775 -25.00005026  47.98976554  61.72952627  -1.91020241
  25.23965648   4.83709877  -4.39690679  -1.51840515  -3.38446555
   5.31088112   1.3359307    6.51455795  -3.91664342  30.79110273]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.5035889239487
gradient value of function right now is: [-9.83849210e-03 -4.67348388e-02 -1.48430026e+00 -3.25416765e-03
  9.83849210e-03  4.67348388e-02  1.48430026e+00  3.25416765e-03
  1.12543303e-03  1.68490267e-02  2.78478383e-05  1.37319729e-02
 -1.30977918e-02 -1.06433647e-01 -7.27830787e-02 -9.53815300e-02
  3.11936717e-01  8.19452570e-01  5.75082957e-03  3.88259912e-01
  3.61467712e-03  5.26846661e-03  3.31582741e-06  5.47503166e-04
 -1.23982846e+00 -4.49970722e-02 -1.32393985e+00 -2.80492589e-04
  4.59567199e-01  1.46453111e-01  1.16048846e-01  5.12320725e-04
 -3.97073036e-01 -1.58527436e-01 -6.32276832e-02 -1.84282059e-01
 -4.66228588e-01 -1.86347465e-01 -1.43830917e-01 -2.87178336e-03
  1.18105591e-01  2.99207037e-01  2.30142987e-01  7.66785384e-02
  2.07198305e-03 -1.64911448e-01 -2.57458154e-01  1.56239932e-03
 -1.96600649e-02  4.38507920e-02 -4.85899325e-02 -1.26852762e-02
 -3.88873526e-03 -2.39317924e-02 -6.67395711e-01 -2.98657904e-03
 -2.16634077e-02 -5.59150858e-02  8.08893084e-01 -2.48848400e+00
  4.52368924e-01 -6.48128808e-02 -3.28573266e-01  1.12673717e-02
 -3.51391809e+00]
supnorm grad right now is: 3.5139180933447665
Weights right now are: 
[  2.72756622  -3.49097735   2.18797658   8.01603529  -2.47299751
   3.38228566  -1.78903931  -8.73206367  65.95355378  17.233972
  67.30066417  -8.2224198   30.59733568  17.76707899 -20.70734391
  -0.99813658   6.92104387  -1.67965887  27.03358327   2.33840222
  54.84707291  20.92782647   8.08283685   7.00065867   2.5885233
  10.28458551  -1.39595189 118.49618293   1.73470134 -12.10878829
  10.9860483  -74.74162228  10.05797315  -8.5549588   12.30099132
 -18.39854207   6.0748249  -18.34254745   9.09917071 -25.17450237
  -2.20054994  -1.56555762  -8.12647491  13.03054245  37.42410444
   4.28354186   1.54656752  62.53834816 -29.92942394   3.68762658
  10.89732518 -28.81062574  50.78492566  62.87304307  -1.98150693
  25.70355959   4.45727094  -4.30662133  -1.08561103  -3.62722705
   5.31901915   1.03049353   6.30309498  -4.29491228  30.91244581]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.6192697993222
gradient value of function right now is: [ 4.91094257e-03  4.56314569e-02  2.96742673e+00  5.42025827e-03
 -4.91094257e-03 -4.56314569e-02 -2.96742673e+00 -5.42025827e-03
 -1.07085367e-03 -3.92904195e-03 -3.88327819e-07 -8.75279441e-04
  4.56117260e-02 -6.12293577e-02 -6.71399710e-02 -8.14124287e-02
 -6.29758713e-01 -1.78151724e+00  9.95929690e-03 -5.41374486e-01
 -7.54243589e-03 -7.75735755e-03 -1.89348459e-06 -2.68052206e-04
  2.26369581e+00  4.86676905e-02  1.88338559e+00  4.09696175e-04
 -9.78797398e-01 -1.91481626e-01 -1.66870433e-01 -3.63283872e-03
 -4.87428237e-01 -1.18086238e-01 -1.16052734e-03 -2.09253526e-01
  5.97573531e-01  3.18104959e-01  2.04512774e-01 -2.71357538e-02
 -1.84814667e-01 -5.52416377e-01 -1.95227682e-01 -9.52738369e-02
 -1.08589532e-02  6.93449243e-02 -4.48107304e-01 -1.30348872e-02
  2.92859607e-02  1.38332793e-01  8.59434229e-02  1.74326752e-02
 -2.03154231e-02 -7.18702563e-02 -1.72339438e+00 -2.61220846e-02
  2.60669077e-01 -1.55528780e+00 -3.87053534e-01 -3.83360258e+00
 -8.53110248e-01  2.28525025e+00  5.92784572e-01 -1.41768740e+00
 -1.15617110e+01]
supnorm grad right now is: 11.561710954228737
Weights right now are: 
[  2.19836302  -3.72715418   2.42129182   8.57454384  -1.94379431
   3.61846249  -2.02235455  -9.29057223  66.52244955  17.3074907
  74.55303695  -9.83327266  29.73356895  18.73660625 -20.45253407
  -0.9955701    6.71679726  -1.56183969  25.88056886   2.43176655
  55.52276058  21.38531216   7.49011486   6.43250069   2.67497219
  10.17263304  -0.93684947 144.35299191   1.76275342 -12.77731632
  10.12207351 -80.3858971   10.39485027  -7.67394379  14.1182716
 -18.62687012   6.52333183 -18.04796809   9.28811565 -24.57141415
  -2.98973756  -1.88256952  -8.99484883  13.7935398   37.65345594
   5.22137208   1.03675201  63.18352631 -31.47196446   4.36005511
  11.72954449 -32.42563986  52.5109553   62.96151683  -2.3065495
  26.41880266   4.11987806  -4.58510052  -1.2026279   -3.65799507
   5.24904688   0.80742457   6.57492494  -4.1094009   30.94373349]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1370.341638085742
gradient value of function right now is: [ 1.39995157e-03  4.24989411e-02  1.84401507e+00  3.52868836e-03
 -1.39995157e-03 -4.24989411e-02 -1.84401507e+00 -3.52868836e-03
 -1.54287621e-04 -1.70917028e-04 -1.38844693e-07  5.53022025e-05
  3.89123822e-02 -2.86789060e-03 -1.61040363e-02 -1.89684221e-02
 -6.22674412e-01 -6.04727186e-01 -4.54137612e-03 -6.24490094e-02
 -6.77551066e-03 -5.82144909e-03 -2.12015937e-06 -2.19324503e-04
  2.13429457e+00  3.86798476e-02  1.67926532e+00 -1.32561986e-04
 -3.84073529e-01  2.41284050e-02 -3.67492265e-02  8.03954577e-04
  8.01789837e-02 -6.89662961e-03 -2.11088988e-02  1.26255727e-03
  5.88166489e-02 -1.32700308e-01 -1.22805384e-01  6.22362891e-02
 -1.41232359e-01 -4.18469889e-01 -8.28044009e-02 -7.89729030e-02
 -5.48775046e-03 -4.32033130e-01  4.34819617e-01  4.63875811e-03
  2.61644818e-02  3.28364465e-01  1.66137636e-01  1.68754682e-02
  1.29944190e-02  6.47195815e-02  9.57706846e-01  1.85913268e-02
  3.71170818e-01  4.79485946e-01  5.54679448e-02  3.38595149e+00
 -4.77541999e-01 -1.42062804e-01  5.36523259e-01  8.52579016e-01
 -1.41496944e+01]
supnorm grad right now is: 14.149694381389418
Weights right now are: 
[  0.8107887   -3.86477888   2.3639911   10.1962518   -0.55621999
   3.75608719  -1.96505383 -10.91228018  68.01625528  18.61811535
  78.54238815  -9.15940285  29.93715568  19.00700969 -21.05655837
  -1.54466681   6.61617383  -1.35757438  26.86983689   2.63156518
  54.43491429  20.69758839   6.90840078   5.2072095    2.53490365
  10.94767627  -0.68009149 159.36332155   1.52544837 -12.96542911
  10.10552724 -83.04256956  10.48499033  -7.98033474  12.65760823
 -19.69552736   6.58520812 -18.39360207   8.07993669 -24.26369859
  -2.23470841  -1.54978658  -9.36356507  14.52653172  36.19705298
   4.27009186   1.02994155  64.23208526 -33.76705141   3.88908634
  13.07084705 -36.06367467  55.24507863  64.04295608  -2.45631567
  27.78607182   4.51770903  -4.32034656  -1.19459435  -3.32922795
   4.94014648   0.84771154   6.55631949  -3.76321524  30.83833296]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.0598949081552
gradient value of function right now is: [-2.21383887e-03 -8.84192023e-02  1.10259214e+00 -9.90799856e-03
  2.21383887e-03  8.84192023e-02 -1.10259214e+00  9.90799856e-03
  1.30384690e-04  3.23315833e-05  2.27693870e-08 -1.45080730e-05
 -4.00841950e-02 -1.11474316e-01 -6.49190918e-02 -9.53882298e-02
 -1.07313855e-02 -2.43813492e+00 -4.94407653e-03 -1.87107427e+00
  1.35357104e-02  6.51467577e-03  3.28242328e-06  8.88925161e-04
  2.87142521e-01 -2.21162591e-02  5.01935588e-01  1.98200096e-04
 -1.99003810e-01 -8.07626010e-02  1.59818053e-02 -3.91965398e-03
 -3.29430129e-01 -7.43010163e-02  2.37195696e-02 -1.94887530e-01
  3.52952491e-01  2.02992246e-01  1.28699148e-01  8.39240842e-03
 -4.17352541e-02 -1.34884755e-01 -6.16173999e-02 -2.91926220e-02
  3.98494848e-03  2.86027100e-01 -1.97861214e-01 -1.24945732e-03
 -6.65672830e-03 -3.44466909e-01 -2.93328523e-02 -4.68881405e-05
 -1.36916581e-02 -2.54818236e-02 -1.00247485e+00 -1.26878555e-02
 -4.03747204e-01 -7.09941312e-01 -4.44202923e-01 -1.37162671e+00
  5.94802844e-02  1.03244386e+00 -9.79640571e-02 -5.72311202e-01
  5.64136083e-01]
supnorm grad right now is: 2.4381349175539584
Weights right now are: 
[  0.54215968  -4.02371362   2.30888553   9.45972899  -0.28759097
   3.91502193  -1.90994826 -10.17575738  76.73233248  25.55921085
  78.6540019   -6.63741758  30.12608606  18.85116899 -22.10348282
  -2.35369537   6.82739687  -1.57944468  25.54373571   2.15527014
  55.79740932  22.26140882   6.30459649   8.37550412   2.9280523
  11.75555369  -1.0945592  181.37268739   1.90078827 -12.69664935
  10.81002029 -83.00129489  10.67168158  -7.57366237  16.66681968
 -19.50044151   6.67152344 -17.70316868   7.8728661  -27.36196407
  -2.76001173  -1.68143528  -8.3528303   13.68743243  36.93641023
   4.64043087   1.15085586  64.99046007 -32.96621449   3.42503018
  14.97413818 -37.16506738  56.86218909  64.23692347  -2.35642235
  27.80806428   4.54209214  -4.37261626  -1.15430096  -3.92646531
   5.54508091   0.46907244   5.98419771  -4.31114471  31.01802866]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.0099439959126
gradient value of function right now is: [ 7.72195745e-04  7.16248684e-02  2.43175980e+00  8.41680408e-03
 -7.72195745e-04 -7.16248684e-02 -2.43175980e+00 -8.41680408e-03
 -9.14106935e-05 -1.56679840e-04 -3.12094396e-08 -6.11799386e-06
  5.98222239e-02 -6.54624910e-02 -8.78763797e-02 -1.09238021e-01
 -5.94955894e-01  1.39236153e+00  2.28508653e-02  1.95032718e+00
 -1.23005228e-02 -1.42380251e-02 -2.64405317e-06 -3.91521441e-04
  2.23970996e+00  5.64984325e-02  1.27780891e+00  1.58480987e-04
 -1.42628771e+00 -1.93109389e-01 -2.44738454e-01 -1.72715259e-03
 -8.86740775e-01 -2.75948067e-01 -2.85157819e-02 -3.11256437e-01
 -6.79084685e-01 -1.00672966e-02  1.59829461e-01 -1.79043030e-01
 -1.04034739e-01 -5.78203893e-01  1.18211644e-01 -5.70092761e-02
 -3.95570088e-02 -4.09657044e-01 -1.65528648e+00 -3.38695531e-02
  3.47801048e-02  5.83935877e-01  1.99531685e-01  1.88077567e-02
 -5.11682527e-02 -2.04184148e-01 -3.08408585e+00 -5.26323358e-02
  1.04379460e+00 -4.12779781e+00  1.60573755e+00 -1.24900569e+01
 -1.15535704e+00  3.18223565e+00  9.87640957e-01 -3.33135710e+00
 -1.16664926e+01]
supnorm grad right now is: 12.49005692360082
Weights right now are: 
[  1.04904666  -3.82323293   2.33748393   9.60454503  -0.79447795
   3.71454124  -1.93854666 -10.32057342  84.43418441  29.63362975
  78.68460878  -6.84051687  29.64616755  20.13088102 -21.41567506
  -1.86250262   7.08076267  -1.30694703  26.26073064   2.74289334
  55.78820467  24.45141473   6.19646684  10.49945582   2.89541855
  13.28574902  -0.99011245 204.23042594   1.54079694 -12.50500925
  10.02096605 -88.69553693  10.95960364  -7.60820099  15.85584071
 -19.88002678   6.79094182 -17.36720271   8.77094421 -27.09568428
  -2.40951645  -2.0926923   -8.90560373  14.20940231  36.26927335
   4.88704748   1.44883343  64.9752894  -34.10743968   3.79424661
  15.43649403 -40.13425091  58.18143924  65.04190506  -2.38672731
  28.13953538   4.66126281  -4.66645277  -1.64860435  -4.00259238
   5.10831156   0.26141536   6.49373233  -4.44766589  31.10088297]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.5377057700905
gradient value of function right now is: [-6.07650005e-05  4.48492178e-03  3.34509029e-02 -7.26584944e-04
  6.07650005e-05 -4.48492178e-03 -3.34509029e-02  7.26584944e-04
  1.83934182e-06  6.42496894e-06  1.00450147e-09  1.04048073e-07
  6.98138150e-03  3.11551151e-03  6.03274993e-03  9.41537624e-03
 -1.28503198e-02  6.06112834e-01  6.66750880e-03  5.95070611e-01
 -1.12834409e-05  2.94496293e-03  5.15040686e-07  8.80581354e-05
 -1.80247289e-01 -5.25218746e-03 -2.09985003e-01  7.33494379e-05
 -2.67507744e-01 -9.39420274e-02 -5.10100080e-02 -1.79862743e-03
 -1.13755328e-01 -2.53330944e-02  1.50070606e-04 -1.85245074e-02
 -1.90947598e-01  9.58750547e-02  1.28485266e-01 -9.00197230e-02
 -1.25022127e-02 -7.69996109e-02 -6.80339848e-03 -6.38092623e-03
 -1.35067195e-02  2.24209169e-01 -7.68072150e-01 -1.73456754e-02
  4.54303956e-03 -1.10965162e-01  1.21586874e-02  3.31477062e-03
 -1.86985807e-02 -8.03758609e-02 -1.20520003e+00 -2.32599832e-02
  1.40741386e-01 -1.53162882e+00 -1.08824115e-01 -4.44216123e+00
 -2.14079368e-01  9.08557639e-01  2.32334845e-01 -1.62376789e+00
 -5.96395224e+00]
supnorm grad right now is: 5.9639522419351865
Weights right now are: 
[  0.52499708  -3.93975733   2.23246823  10.11223289  -0.27042837
   3.83106564  -1.83353096 -10.82826127  89.70326802  37.05940716
  78.70907294  -0.8762897   29.46284255  20.76909166 -20.77377033
  -1.68840707   6.87466751  -1.40456853  25.71112239   2.61645836
  55.43491808  26.39304048   6.16185326  16.30752268   2.47438415
  14.5346566   -1.27845315 234.52156962   1.6926822  -12.09234354
  10.86624043 -84.60664637  11.45467553  -7.40176041  15.21289353
 -20.3759052    6.92111371 -17.23271975   8.58807413 -26.87813842
  -2.53685341  -3.08068942  -9.31456278  13.58649461  36.50305063
   5.21657926   1.04957652  65.12348721 -34.62547011   3.92131157
  15.68629411 -42.08119995  59.21336508  65.58656647  -2.07613823
  28.63218135   4.66827676  -4.78585496  -1.74034047  -3.80642906
   5.12611979   0.40271031   6.06952983  -4.42967757  30.99004417]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.1440091801728
gradient value of function right now is: [-8.29989285e-05 -7.11669321e-02 -2.67817801e+00 -5.57119174e-03
  8.29989285e-05  7.11669321e-02  2.67817801e+00  5.57119174e-03
  1.62891428e-05  2.15616171e-05  4.46115138e-09 -3.10586670e-06
 -3.59216985e-02 -9.84725090e-02 -4.68409005e-02 -6.30073847e-02
  4.79477972e-01  9.97092626e-01  1.10442821e-03  1.77916897e-01
  9.70488604e-03  1.48442057e-02  4.19103932e-06  4.50864334e-04
 -2.08171196e+00 -5.47001162e-02 -6.55984090e-01 -2.06041234e-04
  1.09046799e+00  1.46509037e-01  1.37224884e-01  1.42605059e-03
 -2.08212083e-01 -8.63203252e-02 -2.44249967e-02 -1.09716604e-01
 -2.14733182e-01 -9.80367005e-02 -8.57792180e-02  8.04951379e-03
  7.82608663e-02  6.31541524e-01  9.47127995e-02  5.14607410e-02
  1.43571582e-02  3.89958118e-01  1.06039551e-01  1.11851130e-02
 -1.40073485e-02 -4.59869144e-01 -4.85229335e-02 -8.24273668e-03
  1.90044841e-03  6.77000061e-03 -2.37138521e-01  1.89273747e-03
 -4.82803455e-01  3.80502659e-01  7.72993897e-02 -1.86530725e-01
  6.08870830e-01  9.61899607e-02 -7.08058445e-01  3.62619288e-01
  9.17461851e+00]
supnorm grad right now is: 9.174618509011392
Weights right now are: 
[  1.39337192  -3.74689054   2.22395802  12.37625777  -1.13880321
   3.63819885  -1.82502075 -13.09228615  91.73433507  40.05055824
  78.71575672   1.44686954  29.82658881  20.49424069 -21.86646011
  -2.75723244   7.3936557   -1.34352196  24.76179941   2.77282758
  54.05012826  25.13226113   5.90303615  21.32872919   2.42014851
  16.25868419  -0.78560836 261.35793837   1.96768314 -10.72946834
  11.36286845 -79.01122877  11.24920567  -7.62410967  17.67195182
 -20.938917     6.99487587 -17.57406254   8.01519066 -25.70012682
  -1.46960634  -1.72357624  -9.34451787  14.16485002  37.28147039
   4.99043841   0.70546224  66.78080745 -33.77384997   3.78600826
  17.48360165 -41.42440434  61.74563876  66.69105981  -2.5643655
  30.61461145   4.81595627  -4.59227113  -1.51398043  -3.83133181
   4.86880756   0.4168221    5.81303801  -4.29960831  31.10481711]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.2130865774266
gradient value of function right now is: [ 6.75303045e-04  9.59514453e-02  1.46663250e+00  1.41221364e-02
 -6.75303045e-04 -9.59514453e-02 -1.46663250e+00 -1.41221364e-02
 -1.78927558e-04 -4.50131470e-04 -4.74132190e-08 -1.97917028e-05
  4.10634418e-02  1.01864263e-01  5.39580092e-02  6.54237565e-02
 -2.62693703e-01 -6.29584488e-01 -1.18910500e-03 -2.52601708e-01
 -1.95840502e-02 -3.43634256e-02 -3.23949751e-06 -1.10754935e-03
  1.49633232e+00  4.05784521e-02  5.29830511e-01  8.72804405e-05
 -3.43863615e-01 -1.68612116e-02 -3.05151148e-02 -1.76576762e-03
  1.85249917e-01  8.54868264e-02  1.19389886e-02  9.63481100e-02
  2.21944562e-01  1.20161604e-01  7.67034149e-02  1.65492317e-03
 -1.25224809e-02 -2.45855177e-01 -9.43787742e-02 -8.07508695e-03
 -8.38584226e-03 -7.49141652e-02  5.13980788e-02 -7.51794738e-03
  1.49028788e-02  1.64460325e-01  7.58530329e-03  1.06234157e-02
 -9.89807542e-04  7.75027955e-03  2.16963634e-01 -1.18753127e-03
  3.07476331e-01 -2.35435055e-01 -4.28921169e-01  1.00171744e+00
 -1.06567530e-01 -2.02267978e-01  3.35316258e-01 -4.13788051e-01
 -7.78387827e+00]
supnorm grad right now is: 7.783878267550077
Weights right now are: 
[ 3.48512336e+00 -3.65015813e+00  2.31807151e+00  1.34028276e+01
 -3.23055465e+00  3.54146644e+00 -1.91913424e+00 -1.41188560e+01
  9.22841290e+01  3.97563103e+01  7.87121479e+01  1.58271049e+00
  2.88596443e+01  2.18652329e+01 -2.14566387e+01 -1.98575059e+00
  7.64965649e+00 -1.42545711e+00  2.73590892e+01  2.91724699e+00
  5.43286175e+01  2.45423260e+01  5.51836158e+00  2.12653149e+01
  2.67718924e+00  1.65540414e+01 -1.00342265e+00  2.89463029e+02
  1.86456426e+00 -1.16048207e+01  1.12303405e+01 -8.18538950e+01
  1.18940239e+01 -6.53521320e+00  1.62636196e+01 -2.10442843e+01
  7.35766411e+00 -1.75509616e+01  8.56041550e+00 -2.41947253e+01
 -1.04986144e+00 -2.65135426e+00 -1.04860001e+01  1.47250348e+01
  3.98515627e+01  4.81058517e+00  6.98900318e-01  6.88248739e+01
 -3.32542334e+01  4.12096940e+00  1.66424150e+01 -4.22342494e+01
  6.21630102e+01  6.66678783e+01 -2.51968093e+00  3.03392020e+01
  4.88779188e+00 -4.86690824e+00 -1.90874576e+00 -3.74769262e+00
  5.72118769e+00  1.18649837e-01  6.13622901e+00 -4.27944764e+00
  3.09045449e+01]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -1370.0157997022736
gradient value of function right now is: [ 4.47197933e-04  1.57851537e-01  3.43703143e+00  1.83462774e-02
 -4.47197933e-04 -1.57851537e-01 -3.43703143e+00 -1.83462774e-02
 -1.16132022e-04 -1.57596643e-04 -1.15597596e-08 -4.58374665e-06
  8.20212758e-02  9.06257914e-02  2.66079691e-02  3.71527450e-02
 -6.96595045e-01 -1.44237480e+00 -2.36367968e-03 -3.77390855e-01
 -3.15390997e-02 -3.71082072e-02 -2.79001860e-06 -9.46107298e-04
  3.05083195e+00  5.43480699e-02  1.64035654e+00  9.08735499e-05
 -8.60860359e-01 -5.33612021e-02 -1.11247408e-01 -1.00166108e-03
  1.88478046e-01  7.40683635e-02  1.07844635e-02  8.71102432e-02
  4.43651924e-01  1.31063834e-01  6.16511311e-02  3.62108370e-02
 -1.32451055e-01 -7.32341736e-01 -2.25961975e-01 -1.03890789e-01
 -9.01997223e-03 -3.71534368e-01  2.51112429e-01 -4.74213483e-03
  2.87877035e-02  4.68728870e-01  7.09208210e-02  2.38244221e-02
  3.87479731e-03  3.48431672e-02  5.05806740e-01  7.13980141e-03
  4.63102304e-01 -6.48009075e-03 -5.81183543e-01  2.80463789e+00
 -5.35981230e-01  1.45683519e-01  8.37186698e-01 -6.18144172e-02
 -1.46361083e+01]
supnorm grad right now is: 14.636108322381228
Weights right now are: 
[ 2.40312709e+00 -3.50245345e+00  2.40442208e+00  1.30486256e+01
 -2.14855838e+00  3.39376176e+00 -2.00548481e+00 -1.37646540e+01
  9.57572835e+01  4.28538663e+01  7.87176757e+01  2.48024940e+00
  2.94949689e+01  2.15850410e+01 -2.25523882e+01 -2.75697129e+00
  7.07753956e+00 -1.23982873e+00  2.59668684e+01  2.95007850e+00
  5.48235375e+01  2.56046358e+01  5.48068038e+00  2.34385789e+01
  2.85348553e+00  1.74092155e+01 -8.08674053e-01  3.12401294e+02
  1.65911821e+00 -1.21331180e+01  1.05121501e+01 -8.18856928e+01
  1.19968385e+01 -6.94897646e+00  1.80480419e+01 -2.13468979e+01
  7.34632166e+00 -1.70875703e+01  8.14833766e+00 -2.58207438e+01
 -2.34034505e+00 -2.12201502e+00 -1.02163242e+01  1.43906525e+01
  4.11679607e+01  4.64985693e+00  1.38472469e+00  7.02041926e+01
 -3.29668864e+01  4.24445649e+00  1.66953363e+01 -4.27961447e+01
  6.37243905e+01  6.76596863e+01 -2.61998051e+00  3.03184009e+01
  4.80832923e+00 -4.85645029e+00 -1.78221462e+00 -3.62635309e+00
  5.89868393e+00 -6.67384672e-02  5.90613798e+00 -4.20834306e+00
  3.08983795e+01]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.6317968090757
gradient value of function right now is: [ 1.13746248e-05  1.06126235e-02  1.06074133e+00  1.69463752e-03
 -1.13746248e-05 -1.06126235e-02 -1.06074133e+00 -1.69463752e-03
 -5.29365922e-07 -3.22287854e-06 -9.24291546e-10 -2.48047451e-07
  1.02433348e-02 -2.73383192e-02 -3.68900522e-02 -4.63510144e-02
 -1.62943214e-01 -4.47923378e-02  5.56850080e-03  3.29921755e-01
 -2.21089462e-03 -6.99053534e-03 -1.93753965e-06 -4.51799144e-04
  7.67065866e-01  2.44479485e-02 -6.92389913e-02 -2.16411672e-05
 -5.80725927e-01 -6.75866997e-02 -9.09383953e-02 -4.80552106e-04
 -2.91831567e-01 -1.10674268e-01 -2.22766481e-02 -1.09240952e-01
  1.18512961e-01  3.41024074e-02  4.00895131e-02 -1.05570391e-02
  2.22526183e-02 -2.28470213e-01  1.00180491e-01  2.68857182e-02
 -4.38358069e-03 -2.74223116e-01 -1.91440115e-01 -4.09461069e-03
  7.63920503e-03  3.82649387e-01  3.20015512e-02  2.65947691e-03
 -3.47298638e-03 -3.14741390e-02 -4.72182319e-01 -6.21446319e-03
  3.75769004e-01 -3.07586722e-01  4.33683001e-01 -2.41777535e+00
 -4.03446896e-01  6.15480939e-01  3.55509857e-01 -3.32382906e-01
 -6.92534707e+00]
supnorm grad right now is: 6.925347073307753
Weights right now are: 
[ 9.49623818e-01 -3.65188063e+00  2.28477149e+00  1.32827031e+01
 -6.95055107e-01  3.54318894e+00 -1.88583423e+00 -1.39987315e+01
  9.82790040e+01  4.91582206e+01  7.87199269e+01  5.17187805e+00
  2.88376042e+01  2.15710363e+01 -2.28854008e+01 -3.27600477e+00
  7.36521898e+00 -1.37588112e+00  2.66467570e+01  3.02300119e+00
  5.50497546e+01  2.65982483e+01  5.28129174e+00  2.92993182e+01
  2.53020754e+00  1.86783010e+01 -8.86812519e-01  3.35378572e+02
  1.71834533e+00 -1.20431298e+01  1.14676878e+01 -8.22385352e+01
  1.13733984e+01 -8.18240509e+00  1.68759815e+01 -2.25502237e+01
  6.87857676e+00 -1.74455591e+01  8.12118707e+00 -2.66409874e+01
 -1.40977285e+00 -2.29312425e+00 -9.08139823e+00  1.42101980e+01
  4.10054520e+01  5.18676283e+00  1.35462145e+00  7.07698166e+01
 -3.53714829e+01  4.36967603e+00  1.74230847e+01 -4.72997876e+01
  6.44900179e+01  6.82116299e+01 -2.32372689e+00  3.06706407e+01
  4.97726399e+00 -4.65906045e+00 -1.75333387e+00 -3.87754464e+00
  5.00676467e+00  1.74604113e-01  5.86592794e+00 -3.98661684e+00
  3.09675060e+01]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.628999064041
gradient value of function right now is: [ 6.70924025e-06  7.80990100e-03  1.24026422e+00  9.47541885e-04
 -6.70924025e-06 -7.80990100e-03 -1.24026422e+00 -9.47541885e-04
  1.05507060e-06  1.09462478e-06  3.26573820e-11  8.18667055e-08
  1.16542124e-02 -3.35548012e-02 -3.06062604e-02 -3.37180212e-02
 -5.02686456e-02 -1.56532133e+00  1.10267049e-03 -8.23846552e-01
 -2.13667794e-03 -1.02874248e-03  1.30766626e-07 -8.14005644e-05
  4.80301668e-02 -3.78912737e-03  3.63612963e-01  1.10722127e-05
 -3.26140742e-01 -1.51688581e-01 -1.02010126e-01 -1.97586810e-03
 -1.21729066e-01 -6.72763003e-03  1.38447619e-02 -5.60558372e-02
  6.89271883e-01  3.26178715e-01  1.74358022e-01 -6.20651442e-03
 -9.69956532e-03 -4.54552819e-02 -1.05943003e-01 -7.25449033e-03
  4.26249800e-04  3.24826492e-01  5.48707900e-02 -2.00998174e-03
  1.01076416e-02 -5.45849016e-02  1.96431447e-03  8.56749926e-03
 -6.54516660e-03 -1.28837824e-02 -6.13797435e-01 -1.12535668e-02
  9.35461254e-04 -5.00445212e-01 -1.03648587e+00 -3.45619348e-02
 -3.48282721e-01  1.24294543e+00  8.35752978e-02 -6.10418217e-01
  2.50481542e+00]
supnorm grad right now is: 2.504815419282189
Weights right now are: 
[ -0.96744166  -3.4189928    2.34521647  12.69743186   1.22201037
   3.31030111  -1.9462792  -13.41346024 101.2404656   52.3598571
  78.72195226   5.60353019  29.19774573  22.51920703 -22.38071085
  -2.62335003   7.16364456  -1.40384606  27.01432332   2.68632819
  54.9301953   28.46789983   5.36749369  33.27362568   2.52151628
  18.585586    -0.94121668 353.48270842   2.00004855 -13.19389357
  10.9236022  -82.6780853   11.93656789  -6.41482827  20.37719191
 -22.22531679   6.79440721 -17.69584922   8.50520781 -24.86711816
  -1.57876284  -2.24309696 -10.79090771  14.58648576  43.58959388
   5.45065968   1.03593827  72.87462658 -33.6435524    4.40221144
  18.2104963  -46.50922943  65.75644302  68.69338184  -2.91896258
  30.76353331   4.93478728  -4.88049007  -1.48062422  -3.83158802
   5.31492649   0.3607724    6.31540506  -4.26705753  31.01135375]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.4303164710598
gradient value of function right now is: [-8.57111487e-05 -1.06175208e-01  2.52363852e-01 -1.08940612e-02
  8.57111487e-05  1.06175208e-01 -2.52363852e-01  1.08940612e-02
  6.39079433e-06  8.40551432e-06  9.48703665e-10  3.89945361e-07
 -6.17767006e-02 -9.66093836e-03  2.38949751e-02  3.24953597e-02
  5.17354841e-01 -4.31716844e+00 -1.53683392e-02 -3.12114651e+00
  2.09215112e-02  2.11316537e-02  2.51184399e-06  8.43537942e-04
 -1.99588572e+00 -4.24066095e-02 -8.24036202e-01 -1.50486646e-05
  4.63245206e-01 -1.18443429e-01 -1.54375147e-02 -2.54037706e-03
  5.08798567e-01  1.94803530e-01  4.51215979e-02  1.58290541e-01
  1.73160814e+00  6.66993419e-01  3.11985837e-01  1.53946125e-01
  8.45235452e-02  3.40699348e-01 -2.27690904e-01  5.30819326e-02
  3.18837555e-02  7.84242785e-01  1.33130360e+00  3.98077176e-02
 -2.44142675e-02 -5.90923231e-01 -2.18313687e-01 -1.87576849e-02
  2.00494371e-02  1.40481319e-01  1.54199424e+00  3.52479218e-02
 -1.01175497e+00  2.61015142e+00 -2.60272402e+00  1.10634370e+01
  8.74363315e-01 -1.97836638e+00 -1.46916268e+00  3.67650030e+00
  2.23722872e+01]
supnorm grad right now is: 22.37228716303503
Weights right now are: 
[ 8.57964764e-01 -3.49620786e+00  2.32233794e+00  1.38261809e+01
 -6.03396053e-01  3.38751617e+00 -1.92340067e+00 -1.45422093e+01
  1.02685590e+02  5.64099769e+01  7.87244809e+01  8.30145635e+00
  2.94615808e+01  2.24254101e+01 -2.33123055e+01 -3.11654983e+00
  6.89046858e+00 -1.60136803e+00  2.89311101e+01  2.63250091e+00
  5.42425842e+01  2.92326501e+01  5.29453388e+00  3.33999704e+01
  2.74038054e+00  1.88324368e+01 -9.26662167e-01  3.72302057e+02
  1.79837115e+00 -1.32573821e+01  1.09076443e+01 -8.41676249e+01
  1.17168181e+01 -7.46475917e+00  1.81458847e+01 -2.27621240e+01
  6.95228201e+00 -1.72426166e+01  8.32956544e+00 -2.46850980e+01
 -1.47436323e+00 -2.15184962e+00 -9.57597695e+00  1.47835505e+01
  4.44414597e+01  4.96916282e+00  1.11664444e+00  7.34026005e+01
 -3.49437758e+01  4.12868181e+00  1.77260336e+01 -4.93401686e+01
  6.64010208e+01  6.90404430e+01 -2.48601727e+00  3.07162035e+01
  4.72856845e+00 -4.87475847e+00 -1.58529985e+00 -3.88723562e+00
  5.37699936e+00  2.60806587e-02  5.86419570e+00 -4.16922286e+00
  3.10540353e+01]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1369.996111699953
gradient value of function right now is: [ 6.25821173e-05  6.17602234e-02 -1.79322131e+00  4.22123770e-03
 -6.25821173e-05 -6.17602234e-02  1.79322131e+00 -4.22123770e-03
  1.03952669e-05  4.75002602e-05  1.45253916e-09  2.45390227e-06
  3.23238363e-02  1.18613330e-01  7.99630701e-02  1.00724525e-01
 -4.14685080e-01  6.13809661e+00  3.68645267e-03  3.66860692e+00
 -4.78684592e-03 -1.17178310e-02 -4.79942600e-07 -5.88634757e-04
  1.26653514e+00  1.22045224e-02  1.26488222e+00  3.40721632e-06
  1.87793178e-01  1.57680026e-01  9.62682939e-02  2.83957877e-03
  2.03392322e-01  1.16555688e-01  2.78519640e-02  1.54249203e-01
 -2.63044272e+00 -1.04651401e+00 -4.94327041e-01 -1.72544338e-01
 -1.44974649e-01 -2.43690302e-01  1.68896045e-01 -8.60574796e-02
 -2.82149933e-02 -7.26568414e-01 -1.36775703e+00 -3.95806434e-02
  6.20575229e-03  2.66927294e-01  1.04872983e-01  4.98913515e-03
 -1.42422218e-02 -1.23412323e-01 -5.84835853e-01 -2.41919003e-02
  4.64577067e-01 -2.06544178e+00  2.62909489e+00 -9.75222507e+00
  1.16472742e-01 -1.11470249e+00  1.01599247e+00 -3.20386283e+00
 -3.68235802e+00]
supnorm grad right now is: 9.752225074594548
Weights right now are: 
[-3.69933399e+00 -3.83501650e+00  2.27371972e+00  1.31625996e+01
  3.95390270e+00  3.72632481e+00 -1.87478245e+00 -1.38786280e+01
  1.02323020e+02  5.78266807e+01  7.87250529e+01  8.55324389e+00
  2.90763474e+01  2.34372455e+01 -2.28976633e+01 -2.86261475e+00
  6.61769336e+00 -1.08168563e+00  2.75837879e+01  3.06555604e+00
  5.49513061e+01  2.87978076e+01  5.11399553e+00  3.38447207e+01
  2.86059832e+00  1.98289690e+01 -7.72301943e-01  3.90389417e+02
  1.72562327e+00 -1.32049445e+01  1.11767054e+01 -8.35247201e+01
  1.23346453e+01 -6.44137155e+00  2.19508668e+01 -2.23648203e+01
  6.96923198e+00 -1.72950739e+01  7.73494966e+00 -2.54073641e+01
 -1.88876228e+00 -1.98932163e+00 -1.05555483e+01  1.48776779e+01
  4.46993154e+01  4.96102260e+00  9.91596970e-01  7.39703975e+01
 -3.50991958e+01  3.90423453e+00  1.78041507e+01 -5.04330554e+01
  6.77090671e+01  6.94562326e+01 -2.66798498e+00  3.10401707e+01
  4.69064628e+00 -5.27089462e+00 -1.72889012e+00 -3.89605031e+00
  5.60665034e+00 -3.56944761e-01  6.37624064e+00 -4.45895532e+00
  3.11104877e+01]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.4058997714494
gradient value of function right now is: [-1.82301644e-06 -5.05971418e-02 -2.50994688e+00 -2.10688372e-03
  1.82301644e-06  5.05971418e-02  2.50994688e+00  2.10688372e-03
 -1.84871678e-06  1.18358706e-06  6.10674792e-10  6.16190097e-07
 -2.70252374e-02 -8.50019082e-02 -5.96121929e-02 -7.49221486e-02
  2.31356626e-01  2.65092680e+00  7.54559868e-03  1.57482575e+00
  5.72799495e-03  4.03531285e-03  3.81162622e-07 -1.42843852e-04
 -8.46152830e-01 -1.41534836e-02 -5.21906270e-01 -4.91734675e-05
  6.00805101e-01  1.42681126e-01  1.04038450e-01  1.73366375e-03
 -3.90984928e-01 -1.85095293e-01 -7.26744023e-02 -1.68045523e-01
 -1.01016249e+00 -3.51842593e-01 -1.52376939e-01 -7.00678725e-02
  8.30269606e-02  4.21524798e-01  2.00414765e-01  4.54884687e-02
 -1.15429732e-03 -7.66655718e-02 -6.21378413e-01 -5.23237103e-03
 -9.27508646e-03 -1.80078902e-01  2.18093731e-02 -4.85911167e-03
 -6.47998091e-03 -6.44711203e-02 -9.56016379e-01 -1.20026093e-02
 -1.17201908e-01 -5.48276973e-01  1.78626150e+00 -5.76859408e+00
  5.07289372e-01  5.74349388e-02 -3.46640990e-01 -9.65156099e-01
 -4.76195232e-01]
supnorm grad right now is: 5.768594080535095
Weights right now are: 
[-1.77934949e+00 -3.72336990e+00  2.11549689e+00  1.46844293e+01
  2.03391820e+00  3.61467821e+00 -1.71655962e+00 -1.54004577e+01
  1.03335466e+02  6.10727909e+01  7.87269415e+01  9.97100993e+00
  2.80004936e+01  2.34363767e+01 -2.38192429e+01 -3.64331614e+00
  7.47915240e+00 -1.45736540e+00  2.97493142e+01  2.96355610e+00
  5.53101283e+01  2.74237929e+01  4.90522804e+00  3.22726960e+01
  2.63572217e+00  2.05640330e+01 -8.79345591e-01  4.12321379e+02
  1.96135403e+00 -1.18905523e+01  1.22144511e+01 -8.43201170e+01
  1.22280177e+01 -8.10656391e+00  1.75188211e+01 -2.36287482e+01
  6.74983068e+00 -1.72429729e+01  7.52962886e+00 -2.58452499e+01
 -2.07407600e+00 -1.62386995e+00 -9.98519790e+00  1.50102010e+01
  4.58203330e+01  5.52425642e+00  1.66856888e+00  7.53169941e+01
 -3.53642118e+01  4.16706843e+00  1.93745135e+01 -5.17251467e+01
  6.94541856e+01  7.03267999e+01 -1.87800893e+00  3.16691615e+01
  4.42869798e+00 -5.19846645e+00 -1.53435880e+00 -3.93428967e+00
  4.76273096e+00  1.93487152e-01  5.59447661e+00 -4.44287578e+00
  3.10224172e+01]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1370.7285517135283
gradient value of function right now is: [ 2.97756199e-05  4.24447985e-02  1.53286761e+00  8.50151525e-04
 -2.97756199e-05 -4.24447985e-02 -1.53286761e+00 -8.50151525e-04
  2.17096675e-05 -4.44433034e-06 -1.30087086e-09 -4.69680788e-07
  3.12253222e-02  9.88317585e-03  2.04284345e-02  2.51629656e-02
 -2.16438908e-01 -2.87224380e+00 -8.96903007e-03 -1.88079308e+00
 -5.92468271e-03  8.36529176e-03  1.60894167e-06  5.75684476e-04
  4.57168913e-01 -2.40676805e-02  1.08890633e+00  1.17588269e-05
  2.20192642e-01 -3.61750745e-02  1.20700475e-02 -1.49147844e-03
  3.22155981e-01  1.08187868e-01  1.10416703e-02  1.00952357e-01
  1.25987763e+00  4.15575104e-01  9.41040036e-02  1.25065784e-01
 -7.99017153e-02 -1.76395565e-01 -2.97071472e-01 -7.49954056e-02
  1.21165216e-02  5.83273307e-01  1.11115875e+00  2.10917534e-02
  6.81364457e-03 -2.95001021e-01 -1.12622056e-02  8.87249454e-03
  1.23349354e-02  9.96960954e-02  1.47031157e+00  2.64623146e-02
 -3.46526138e-01  1.31559471e+00 -2.10930050e+00  8.25845007e+00
 -2.22754181e-01  3.85134870e-02 -2.42363632e-01  2.13041614e+00
 -1.60817544e-01]
supnorm grad right now is: 8.258450074900905
Weights right now are: 
[-3.61649096e+00 -3.13015021e+00  2.25533601e+00  1.33913074e+01
  3.87105967e+00  3.02145852e+00 -1.85639874e+00 -1.41073358e+01
  1.04242244e+02  6.21868010e+01  7.87264784e+01  1.06044809e+01
  2.90572537e+01  2.38889147e+01 -2.35303049e+01 -3.16893041e+00
  6.59118267e+00 -1.61163373e+00  2.86897396e+01  2.75341091e+00
  5.66184104e+01  2.91042475e+01  5.05194847e+00  3.37374075e+01
  2.75873074e+00  2.00791973e+01 -7.01528452e-01  4.35107117e+02
  1.98338872e+00 -1.30255943e+01  1.26132043e+01 -8.96095985e+01
  1.25921022e+01 -7.88310573e+00  1.81187569e+01 -2.39356687e+01
  7.03421569e+00 -1.64392594e+01  7.66931083e+00 -2.54593386e+01
 -1.83449510e+00 -2.06462337e+00 -9.96734817e+00  1.55024121e+01
  4.74654278e+01  5.20949361e+00  1.12765689e+00  7.66306453e+01
 -3.46993525e+01  4.27801727e+00  1.93535215e+01 -5.28243075e+01
  7.02982441e+01  7.05706906e+01 -1.79609717e+00  3.17924252e+01
  4.96101550e+00 -4.89981200e+00 -1.80374858e+00 -3.87063451e+00
  4.86332617e+00  1.88337624e-01  5.57921049e+00 -4.09098949e+00
  3.09123123e+01]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1368.3523382725955
gradient value of function right now is: [-7.11611946e-05 -2.26056569e-01 -2.98837637e+00 -1.12517320e-02
  7.11611946e-05  2.26056569e-01  2.98837637e+00  1.12517320e-02
 -6.89059435e-05 -3.40389787e-05 -3.41527322e-09 -8.68489145e-07
 -1.48735815e-01 -2.12017763e-01 -1.26567385e-01 -1.59735616e-01
  5.53639695e-01  1.06403678e+00  1.77840971e-02  4.76653376e-01
  2.34664230e-02  1.43458358e-02  1.34609481e-06  2.46977707e-04
 -1.23149688e+00 -1.90957818e-02 -1.99412234e-01 -1.02642075e-04
  8.59558750e-01 -1.44159663e-01 -1.24213914e-02 -7.20958739e-04
 -9.87167005e-01 -3.57716049e-01 -6.28344824e-02 -3.51783566e-01
 -4.51527995e-02  2.82596968e-01  3.12003940e-01 -1.36712354e-01
 -2.31746311e-02 -8.14680422e-02  2.79018663e-01 -2.21989965e-03
  2.40043185e-03  3.36870536e-01 -7.56923489e-01 -1.35208832e-02
 -4.55621435e-02 -6.27929226e-01 -1.20591313e-01 -3.09206447e-02
 -2.61373716e-02 -1.48055662e-01 -2.12462265e+00 -5.35572670e-02
 -7.58272103e-01 -1.71616921e+00  8.70000183e-01 -1.01060527e+01
  3.06619637e-01  1.50882765e+00 -3.92327198e-01 -2.30148108e+00
  9.19748391e+00]
supnorm grad right now is: 10.10605265093327
Weights right now are: 
[-5.83883585e+00 -4.09153812e+00  2.07933357e+00  1.24930425e+01
  6.09340456e+00  3.98284643e+00 -1.68039630e+00 -1.32090709e+01
  1.01426300e+02  6.44033385e+01  7.87294631e+01  1.17271511e+01
  2.78014085e+01  2.42691006e+01 -2.40697064e+01 -3.71571467e+00
  7.59002879e+00 -1.53410979e+00  3.06411806e+01  3.21089070e+00
  5.75179357e+01  3.01456607e+01  4.88529421e+00  3.48672241e+01
  2.66443065e+00  2.10317232e+01 -9.36809857e-01  4.49946254e+02
  1.93199325e+00 -1.43417213e+01  1.18907989e+01 -8.49740218e+01
  1.21912409e+01 -8.91794459e+00  1.87786217e+01 -2.46742828e+01
  7.51796708e+00 -1.58648586e+01  7.11787681e+00 -2.59480145e+01
 -3.32477786e+00 -1.85633892e+00 -9.79528865e+00  1.50270803e+01
  4.97237779e+01  4.61152422e+00  1.21606056e+00  7.86936389e+01
 -3.41542349e+01  3.83812386e+00  2.07384340e+01 -5.28383148e+01
  7.14113732e+01  7.12876168e+01 -2.84074932e+00  3.15159532e+01
  4.33919454e+00 -5.24985208e+00 -2.22509433e+00 -4.16617400e+00
  5.15266277e+00 -4.29547693e-01  6.21423666e+00 -4.34292423e+00
  3.11101598e+01]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.7499380160193
gradient value of function right now is: [ 1.96859021e-06  3.63089437e-03 -7.30537965e-01  5.12627099e-04
 -1.96859021e-06 -3.63089437e-03  7.30537965e-01 -5.12627099e-04
 -1.04022415e-06  8.16863361e-06  8.88248002e-10  1.05183280e-06
 -2.74927116e-03 -4.89514463e-03 -1.01471276e-02 -9.77015921e-03
  5.23917518e-01  9.79145562e-01  1.40103826e-03  6.51719426e-01
  1.04576732e-04 -2.46481655e-03 -3.12795741e-07 -3.35298085e-04
 -1.70146018e+00  8.04852003e-03 -2.55021533e+00 -3.32779629e-05
 -6.56290636e-02  3.19262398e-02  5.06629484e-03  1.02643422e-04
 -4.54017034e-02 -2.19805874e-02 -6.03234238e-03 -1.62652729e-02
 -3.33172512e-01 -1.00186320e-01 -3.61771462e-02 -4.15684899e-02
  1.53611762e-01  3.60873542e-01  2.47243497e-01  1.39349782e-01
 -9.74009619e-04 -2.47216204e-01 -1.76348574e-01 -2.15165342e-03
 -2.22651455e-02  9.67094946e-02 -8.33122912e-02 -2.50272749e-02
 -4.61782475e-03 -2.32992825e-02 -3.54355523e-01 -9.38943078e-03
  1.87093446e-02 -1.75611304e-01  5.51744265e-01 -2.08540734e+00
  6.49180118e-01 -6.14152983e-01 -6.81693925e-01 -7.42527924e-03
  3.06429792e+00]
supnorm grad right now is: 3.064297916024441
Weights right now are: 
[-1.09305151e+01 -3.16972178e+00  2.29294082e+00  1.22764277e+01
  1.11850838e+01  3.06103009e+00 -1.89400355e+00 -1.29924561e+01
  9.65960986e+01  6.50229642e+01  7.87296629e+01  1.18919670e+01
  2.93119283e+01  2.51913476e+01 -2.39654645e+01 -3.38971768e+00
  6.79841620e+00 -1.22288705e+00  2.94136009e+01  2.81174017e+00
  5.76306633e+01  2.92203966e+01  4.70031444e+00  3.48137330e+01
  2.37752006e+00  2.32418398e+01 -1.40849366e+00  4.71180027e+02
  1.91743144e+00 -1.31174796e+01  1.32407565e+01 -8.77754050e+01
  1.35418435e+01 -8.42304364e+00  1.70868687e+01 -2.47659893e+01
  6.59825380e+00 -1.63103419e+01  7.25514434e+00 -2.63416012e+01
 -2.52575833e+00 -2.02655239e+00 -9.90702448e+00  1.59918102e+01
  5.05405257e+01  5.02785479e+00  1.02702087e+00  7.92919004e+01
 -3.58889906e+01  4.64359278e+00  2.03091596e+01 -5.73904074e+01
  7.18975824e+01  7.15893392e+01 -2.28116011e+00  3.11634698e+01
  5.03080045e+00 -4.89476925e+00 -2.10768248e+00 -4.08402316e+00
  5.58150452e+00  1.92888762e-01  5.52822150e+00 -4.10732012e+00
  3.10190302e+01]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.9076182350539
gradient value of function right now is: [-4.09596358e-06 -1.39019655e-03 -1.87984385e+00 -7.41210942e-04
  4.09596358e-06  1.39019655e-03  1.87984385e+00  7.41210942e-04
 -9.02438332e-06 -8.11844275e-07 -2.59701461e-11 -5.17968299e-08
 -1.45006392e-02  5.12263232e-02  3.85424187e-02  5.18123420e-02
  3.58527077e-01  8.71910659e-01 -6.36044344e-03  1.25626821e-01
  2.19803147e-03  6.72205300e-04  1.56739481e-08  5.67233440e-05
 -1.31928377e+00 -1.88226649e-03 -1.66533637e+00 -2.87921069e-05
  6.42970670e-01  2.65492734e-01  1.65662379e-01  1.07378854e-03
  3.61696624e-01  1.79433633e-01  3.83106408e-02  1.40496280e-01
 -7.69201341e-01 -4.06585916e-01 -2.66184783e-01  3.80448278e-02
  1.51638810e-01  7.50190797e-01  1.19019647e-01  1.29825638e-01
  3.77359457e-03 -3.34465516e-01  2.60787733e-01  6.19939114e-03
 -1.28232903e-02 -8.17368377e-02 -8.04585138e-02 -1.24453311e-02
  8.75958514e-03  5.80374481e-02  6.78318389e-01  1.25828461e-02
  2.18244296e-03  1.00088770e+00  2.92626706e-01  3.14702973e+00
  1.19199077e+00 -2.16459826e+00 -6.96564083e-01  1.04496390e+00
  7.17615970e-01]
supnorm grad right now is: 3.1470297250001287
Weights right now are: 
[-9.70945471e+00 -2.89818707e+00  2.14212655e+00  1.40908545e+01
  9.96402342e+00  2.78949538e+00 -1.74318928e+00 -1.48068829e+01
  9.78304197e+01  6.77152520e+01  7.87344176e+01  1.44339315e+01
  2.85483046e+01  2.49082551e+01 -2.57824047e+01 -4.17532707e+00
  7.52950077e+00 -1.63805015e+00  3.08225786e+01  3.00987913e+00
  5.60902135e+01  2.86111805e+01  4.61622301e+00  3.49523214e+01
  2.69707420e+00  2.48677452e+01 -1.06104882e+00  4.90740957e+02
  1.84134742e+00 -1.37698873e+01  1.33881771e+01 -8.87469827e+01
  1.31623245e+01 -8.57346456e+00  1.84646684e+01 -2.48681201e+01
  6.71285853e+00 -1.66818590e+01  6.31504812e+00 -2.48600612e+01
 -2.71357429e+00 -1.73850975e+00 -9.37479560e+00  1.51362798e+01
  5.26435428e+01  4.10566886e+00  6.80467643e-01  8.09759377e+01
 -3.46543302e+01  3.90262450e+00  2.35217969e+01 -5.78731538e+01
  7.28797008e+01  7.17663207e+01 -2.27196446e+00  3.15912751e+01
  5.05222307e+00 -4.77308305e+00 -2.76612732e+00 -3.85163923e+00
  5.33845968e+00 -3.93250646e-01  5.50475807e+00 -4.38809198e+00
  3.09258448e+01]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.7685945437122
gradient value of function right now is: [ 3.21938115e-05  7.05552577e-02  2.69558699e-01  3.17870329e-03
 -3.21938115e-05 -7.05552577e-02 -2.69558699e-01 -3.17870329e-03
  9.80259946e-05  2.18588081e-05  1.39629876e-10  6.91984329e-07
  3.05563535e-02  7.92948494e-02  5.87556933e-02  7.11197734e-02
 -3.61635521e-01  1.12599666e+00 -2.51946652e-03  4.88573547e-01
 -7.64202591e-03 -2.52345743e-03 -1.55685133e-08 -6.60526643e-05
  1.42430080e+00  3.24987880e-04  8.30730745e-01 -9.38702167e-06
 -1.74395076e-01  4.06262925e-02 -9.95970423e-03  8.90398647e-04
  2.93018778e-01  1.15811740e-01  8.29590030e-03  1.42443593e-01
 -5.27273206e-01 -2.61370056e-01 -8.09171044e-02  3.23908429e-03
 -5.12101530e-02 -1.58687459e-01 -5.75588116e-02 -4.81361333e-02
 -4.30333276e-03 -1.22272886e-01 -1.75401655e-02 -4.80976163e-03
  1.78384746e-02  1.87140674e-01  7.59816978e-02  1.81814388e-02
  2.86572795e-03  1.83656929e-02  6.36009236e-01  5.63250829e-03
  2.33313572e-01 -2.03859581e-02  1.57200988e-01  8.86943995e-01
 -2.26020561e-01 -4.27455587e-01  6.20710562e-01 -2.87453565e-01
 -6.42499624e+00]
supnorm grad right now is: 6.42499624068437
Weights right now are: 
[-1.59891469e+01 -3.02973132e+00  2.16784553e+00  1.21009373e+01
  1.62437156e+01  2.92103963e+00 -1.76890826e+00 -1.28169657e+01
  9.51702460e+01  6.31615066e+01  7.87323793e+01  9.33376858e+00
  2.99404957e+01  2.58354341e+01 -2.51951795e+01 -3.53800329e+00
  6.90562251e+00 -1.35679553e+00  3.06780584e+01  3.17612865e+00
  5.53597496e+01  3.16837729e+01  4.66293727e+00  4.20538464e+01
  2.67299049e+00  2.76092748e+01 -9.00468029e-01  5.14395984e+02
  1.81189210e+00 -1.44369273e+01  1.27138864e+01 -8.79777947e+01
  1.41796653e+01 -8.14846973e+00  1.91988742e+01 -2.46198666e+01
  6.68439676e+00 -1.60127996e+01  6.34367878e+00 -2.58998691e+01
 -2.80628175e+00 -2.09732822e+00 -1.02585101e+01  1.48324498e+01
  5.44055274e+01  4.49796774e+00  1.29982570e+00  8.26380884e+01
 -3.28117431e+01  4.00279358e+00  2.51160336e+01 -5.74554485e+01
  7.28435311e+01  7.19461658e+01 -1.79783598e+00  3.12974267e+01
  5.45583727e+00 -5.08566289e+00 -2.49023168e+00 -3.89499377e+00
  5.12399292e+00 -7.85071279e-02  5.90429597e+00 -4.43858698e+00
  3.09460325e+01]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1370.5807833919941
gradient value of function right now is: [-2.90970409e-05 -5.01154163e-02 -5.31629875e+00 -7.91088758e-03
  2.90970409e-05  5.01154163e-02  5.31629875e+00  7.91088758e-03
 -2.73065437e-05 -1.00217264e-04 -2.50707878e-09 -2.39155352e-06
 -2.35607246e-02  1.55105213e-03  4.42294101e-02  5.52616551e-02
  4.41315969e-01  3.18700668e+00 -1.86502232e-03  7.21520450e-01
  6.69823286e-03  2.53754100e-02  6.74216159e-07  6.96455839e-04
 -1.92747543e+00 -3.07394761e-02 -6.60452153e-01 -2.58332785e-04
  1.87630895e+00  1.81962723e-01  8.22790579e-02  6.70252106e-03
  3.03790473e-01  8.31373775e-02 -1.03145928e-02  1.38460301e-01
 -5.80659230e-01 -3.57839042e-01 -1.64454072e-01  7.15309164e-02
  9.06174297e-02  6.78605249e-01  9.61235862e-02  6.40699715e-02
  1.84529260e-02  2.87209410e-01  6.71665803e-01  2.22224841e-02
 -2.93544334e-03 -3.46513847e-01  7.02884735e-03 -2.07458300e-04
  2.00644089e-02  9.35386982e-02  1.68948374e+00  2.96585199e-02
 -4.15926924e-01  1.99961187e+00 -2.06329537e-03  5.49752963e+00
  9.40106439e-01 -1.32816425e+00 -8.11181405e-01  1.95748217e+00
  2.02154032e+01]
supnorm grad right now is: 20.215403168040616
Weights right now are: 
[-1.41030589e+01 -3.95054862e+00  2.15926296e+00  1.18781386e+01
  1.43576276e+01  3.84185693e+00 -1.76032569e+00 -1.25941670e+01
  9.44454720e+01  6.65262446e+01  7.87372261e+01  1.37348785e+01
  2.83679226e+01  2.61939393e+01 -2.54584158e+01 -3.76211176e+00
  6.92550660e+00 -1.09257845e+00  3.09272797e+01  3.07373198e+00
  5.71984985e+01  3.14356827e+01  4.64882434e+00  4.12522613e+01
  2.73460577e+00  2.82871620e+01 -1.14714282e+00  5.42163979e+02
  2.30856279e+00 -1.46231230e+01  1.31331289e+01 -8.83050691e+01
  1.40786028e+01 -8.80051322e+00  2.05767078e+01 -2.52639224e+01
  6.68726010e+00 -1.58409697e+01  5.93794162e+00 -2.51499848e+01
 -3.18789428e+00 -1.52208697e+00 -9.70919629e+00  1.48131221e+01
  5.62777247e+01  5.16616253e+00  1.68859651e+00  8.40105050e+01
 -3.17189557e+01  3.90884816e+00  2.51472550e+01 -5.91036348e+01
  7.28366509e+01  7.27573329e+01 -1.94021452e+00  3.04259451e+01
  5.36354768e+00 -4.89946764e+00 -1.71293243e+00 -3.96438520e+00
  4.53626037e+00  1.07089662e-01  6.13912254e+00 -4.39312525e+00
  3.11245639e+01]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1370.2583086856323
gradient value of function right now is: [-3.40734272e-05 -5.47897499e-02  1.43231160e+00 -6.92444225e-03
  3.40734272e-05  5.47897499e-02 -1.43231160e+00  6.92444225e-03
 -3.72637616e-05 -9.38457465e-05 -5.44310041e-09 -6.09787732e-06
 -2.31402022e-02 -4.07365105e-03  2.22442865e-02  2.81899961e-02
  5.24370497e-01 -5.49027855e+00 -1.64496628e-02 -3.86867350e+00
  8.05359904e-03  1.77636455e-02  1.05511889e-06  1.12346916e-03
 -2.01561480e+00 -2.72937306e-02 -1.25182048e+00  3.47763780e-05
  2.52902102e-01 -1.82753047e-01 -6.96205135e-02 -2.94232181e-03
  5.62205338e-01  2.34063156e-01  5.54944758e-02  1.57923684e-01
  1.85250027e+00  7.76597126e-01  3.48603795e-01  1.49410252e-01
  1.10275867e-01  6.30772730e-01 -3.32503890e-01  9.69803414e-02
  1.74032554e-02  8.58338232e-01  1.07071462e+00  2.61604484e-02
 -7.71372427e-03 -6.46226654e-01 -1.34989939e-01 -8.13651975e-03
  1.53682214e-02  1.33792878e-01  1.23065318e+00  2.50686218e-02
 -5.18895622e-01  2.11873705e+00 -3.06878764e+00  1.19730400e+01
  5.14959917e-01 -2.62173083e-02 -1.61125833e+00  2.55099406e+00
  1.55312282e+01]
supnorm grad right now is: 15.53122824216038
Weights right now are: 
[-1.30963391e+01 -3.12295636e+00  2.27045987e+00  1.23251378e+01
  1.33509078e+01  3.01426467e+00 -1.87152260e+00 -1.30411662e+01
  9.48363195e+01  6.91296798e+01  7.87445780e+01  1.82501835e+01
  2.94164878e+01  2.60742946e+01 -2.61624338e+01 -4.25344969e+00
  6.71618704e+00 -1.72994678e+00  3.40976475e+01  2.50554655e+00
  5.62976597e+01  3.20074816e+01  4.55870162e+00  3.87460250e+01
  2.88047192e+00  2.86340122e+01 -1.18467821e+00  5.60144792e+02
  1.90291558e+00 -1.51340150e+01  1.22527277e+01 -9.00701151e+01
  1.34955137e+01 -9.45738761e+00  2.00038843e+01 -2.61616341e+01
  6.61820842e+00 -1.55640675e+01  7.08573846e+00 -2.48511255e+01
 -2.73176962e+00 -1.96100617e+00 -9.11715086e+00  1.51485217e+01
  5.67850620e+01  5.63595930e+00  1.35072858e+00  8.41697767e+01
 -3.51337681e+01  3.94010497e+00  2.15376130e+01 -6.56521177e+01
  7.27215432e+01  7.29011178e+01 -1.98606483e+00  2.95801141e+01
  5.14155308e+00 -4.97171072e+00 -2.38415467e+00 -4.03433537e+00
  4.88828825e+00 -4.99669073e-01  5.20770554e+00 -4.48183219e+00
  3.09972510e+01]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.404317478893
gradient value of function right now is: [ 3.20678854e-07  2.26768284e-02  1.89417575e+00  8.37259219e-04
 -3.20678854e-07 -2.26768284e-02 -1.89417575e+00 -8.37259219e-04
  4.18943007e-07  2.31359472e-06  3.14021995e-11  8.32212853e-08
  1.25705346e-02  3.07627382e-02  1.79032084e-02  2.41438896e-02
 -2.63699201e-01 -1.84036218e+00 -6.36900922e-03 -1.05562481e+00
 -1.57399630e-03 -2.14724403e-03 -5.27366861e-08 -1.07728281e-04
  9.01288869e-01  3.96806260e-03  8.91897940e-01 -8.19540727e-06
 -3.31769637e-01  7.32074923e-03 -5.22688725e-03  1.13779865e-04
  3.21003507e-01  1.02212047e-01 -3.03133018e-03  9.67792115e-02
  5.40553143e-01  4.32427142e-02 -5.18419213e-02  8.77724349e-02
 -9.03723138e-02 -1.69296344e-01 -1.80609828e-01 -7.87294866e-02
  3.89158866e-03 -1.02482429e-01  6.90651752e-01  1.02292710e-02
  7.93112481e-03  1.21708034e-01  5.08828033e-02  8.62518430e-03
  1.22070810e-02  7.15330090e-02  1.30445563e+00  2.34026001e-02
 -4.28123671e-02  1.13525413e+00 -6.43805668e-01  5.20963143e+00
 -4.01705628e-01  2.89170148e-01  2.53696003e-01  1.59753125e+00
  4.44768149e+00]
supnorm grad right now is: 5.209631431246214
Weights right now are: 
[-9.37150278e+00 -3.50687536e+00  2.15246924e+00  1.30333075e+01
  9.62607149e+00  3.39818367e+00 -1.75353198e+00 -1.37493359e+01
  9.51598193e+01  7.64817646e+01  7.87500292e+01  2.45296198e+01
  2.96190354e+01  2.65073999e+01 -2.62524217e+01 -3.98944242e+00
  6.58612780e+00 -1.67726702e+00  3.57437128e+01  2.89683817e+00
  5.70624062e+01  3.31811251e+01  4.52669191e+00  3.83024093e+01
  2.62384792e+00  3.20074352e+01 -8.18851028e-01  5.72274708e+02
  1.71956898e+00 -1.44328006e+01  1.41850705e+01 -9.74933758e+01
  1.40913734e+01 -1.01284162e+01  1.79690780e+01 -2.66980239e+01
  6.25472008e+00 -1.60154237e+01  5.95561720e+00 -2.53731643e+01
 -3.63543102e+00 -1.92729065e+00 -9.95960933e+00  1.40463945e+01
  5.79918226e+01  4.64918377e+00  1.08463340e+00  8.56046572e+01
 -3.43736229e+01  4.20238399e+00  2.25902462e+01 -6.62765440e+01
  7.50600589e+01  7.39728020e+01 -1.43787728e+00  3.15172877e+01
  5.17478662e+00 -4.90947190e+00 -2.04348458e+00 -4.06390791e+00
  4.73165990e+00 -3.43573862e-02  5.91325495e+00 -4.18623639e+00
  3.10209238e+01]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.9333313775326
gradient value of function right now is: [ 7.29841211e-06 -7.67855347e-03  5.92743425e-01 -2.99045278e-03
 -7.29841211e-06  7.67855347e-03 -5.92743425e-01  2.99045278e-03
  2.77455117e-05 -1.12038993e-05 -2.53526293e-10 -4.71840434e-07
  4.11731487e-03 -6.04548271e-03  9.15668666e-03  1.30557726e-02
 -1.43604127e-01 -2.29772141e+00 -3.62462102e-03 -1.55545925e+00
  1.78356813e-03  1.21944233e-02  1.88339321e-07  4.77396509e-04
  2.73533951e-01 -1.24864789e-02  1.02756870e+00 -3.67393029e-06
  1.91402709e-01 -9.23791829e-02 -5.30057859e-02 -1.99401849e-04
  1.74191851e-01  7.29377245e-02  1.12548304e-02  5.78789242e-02
  1.33628977e+00  5.05734563e-01  1.99202867e-01  8.50415096e-02
 -1.10066200e-01 -2.23679476e-01 -2.68365540e-01 -8.15589416e-02
  9.54103274e-03  6.33151444e-01  7.73942627e-01  1.67420073e-02
  4.05989267e-03 -2.95404916e-01 -8.66911663e-03  6.62349899e-03
  7.83103376e-03  7.58180964e-02  7.97423680e-01  1.85519919e-02
 -3.78264420e-01  9.50952017e-01 -1.99594788e+00  7.14703170e+00
 -2.40804616e-01  1.89577405e-02 -9.36257753e-02  1.85957927e+00
  7.73863961e+00]
supnorm grad right now is: 7.738639610253095
Weights right now are: 
[-1.27736198e+01 -3.48412751e+00  2.23929762e+00  1.36896902e+01
  1.30281885e+01  3.37543582e+00 -1.84036035e+00 -1.44057186e+01
  9.14455338e+01  7.74144297e+01  7.87514697e+01  2.46936981e+01
  3.03492356e+01  2.64104693e+01 -2.75096757e+01 -4.92911507e+00
  6.53931577e+00 -1.36325058e+00  3.45911576e+01  3.03015808e+00
  5.68883360e+01  3.19906826e+01  4.41427523e+00  3.77982605e+01
  2.66998049e+00  3.40982872e+01 -1.08701727e+00  5.91015311e+02
  1.86709731e+00 -1.50150958e+01  1.30178004e+01 -1.02446506e+02
  1.44114298e+01 -9.37393589e+00  1.96057944e+01 -2.68449575e+01
  6.47775000e+00 -1.56448682e+01  7.06384094e+00 -2.51716283e+01
 -3.44129344e+00 -2.47980357e+00 -9.79299591e+00  1.46610971e+01
  5.98143822e+01  5.24976963e+00  9.39636664e-01  8.75789418e+01
 -3.44709480e+01  3.76192464e+00  2.27584984e+01 -6.77757858e+01
  7.62465846e+01  7.43727752e+01 -2.32445810e+00  3.17905498e+01
  4.83131157e+00 -5.22492626e+00 -2.33638131e+00 -3.90143089e+00
  4.89203158e+00 -2.29815795e-01  6.22958813e+00 -4.20460811e+00
  3.10546702e+01]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.5201816875021
gradient value of function right now is: [ 6.80530834e-05  1.00488996e-01  3.07238415e+00  7.52511108e-03
 -6.80530834e-05 -1.00488996e-01 -3.07238415e+00 -7.52511108e-03
  2.17027673e-04  7.78930212e-05  1.67363372e-09  5.14513357e-06
  5.70788435e-02  5.48741190e-02  1.09500316e-02  1.60485426e-02
 -6.35721615e-01  8.71685060e-01  3.11450051e-03  1.38451941e+00
 -1.04189687e-02 -1.61986242e-02 -4.67928340e-07 -1.00856523e-03
  2.34567451e+00  2.31706632e-02  1.06550754e+00  4.38183537e-05
 -1.41602590e+00 -1.35379668e-02 -8.47751406e-02 -4.56274065e-04
 -5.11821423e-02 -2.30541236e-02 -1.84644906e-03  4.90801548e-03
 -6.96806710e-01 -3.86675930e-01 -1.48235498e-01 -5.68287157e-02
 -6.78734248e-02 -4.10462472e-01  5.72754654e-02 -4.70902016e-02
 -1.56234288e-02 -7.82423145e-01 -5.05555343e-01 -1.83631925e-02
  2.47264363e-02  7.39071454e-01  1.55595529e-01  2.08116891e-02
 -5.06067848e-03 -5.13039714e-02 -2.70415390e-01 -8.64082005e-03
  7.68059908e-01 -1.14058366e+00  1.29239732e+00 -4.57122230e+00
 -8.47712965e-01  4.19028163e-01  1.33404718e+00 -1.79507889e+00
 -1.52068874e+01]
supnorm grad right now is: 15.206887391025846
Weights right now are: 
[-1.74671122e+01 -3.64827732e+00  2.35542801e+00  1.15884034e+01
  1.77216809e+01  3.53958563e+00 -1.95649074e+00 -1.23044318e+01
  8.74233312e+01  7.70220599e+01  7.87519208e+01  2.43420768e+01
  2.94421501e+01  2.82272069e+01 -2.62253490e+01 -3.65089947e+00
  6.81018550e+00 -1.62103905e+00  4.00703479e+01  3.59259659e+00
  5.84275869e+01  3.29102725e+01  4.36529684e+00  3.70976968e+01
  2.74762207e+00  3.37381930e+01 -8.14598581e-01  6.05345066e+02
  1.95797515e+00 -1.48714842e+01  1.33960262e+01 -9.77003836e+01
  1.42792808e+01 -9.44579950e+00  1.97144665e+01 -2.66929125e+01
  6.46255385e+00 -1.52813423e+01  5.37344043e+00 -2.54397503e+01
 -1.87133771e+00 -2.13734732e+00 -9.23652065e+00  1.56669889e+01
  6.17813186e+01  5.03096789e+00  1.74374937e+00  8.96629155e+01
 -3.46676736e+01  4.30091428e+00  2.31304405e+01 -6.87846817e+01
  7.73898078e+01  7.49935601e+01 -2.03339289e+00  3.21012936e+01
  5.16546945e+00 -5.21154463e+00 -2.23909774e+00 -4.07598975e+00
  4.81594821e+00 -5.09654970e-01  6.11297666e+00 -4.44973590e+00
  3.09723256e+01]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1372.2362635042828
gradient value of function right now is: [-1.89235765e-05  2.24212879e-02  2.28999209e+00  2.56783606e-03
  1.89235765e-05 -2.24212879e-02 -2.28999209e+00 -2.56783606e-03
 -5.92315960e-05  3.23573845e-05  8.74469485e-10  1.79944625e-06
  2.15005445e-02 -3.40228940e-02 -4.66576917e-02 -5.31204129e-02
 -3.85464217e-01 -2.31421367e-03  2.06578254e-03  6.18941463e-01
 -3.26066463e-03 -7.53563807e-03 -3.12778401e-07 -6.15222764e-04
  1.61192450e+00  1.47770941e-02  4.23470490e-01  2.61191243e-05
 -1.03989457e+00 -1.06758478e-02 -5.97484909e-02 -6.03944433e-04
 -2.37000264e-01 -9.58234846e-02 -1.58914444e-02 -9.69607432e-02
 -1.76678037e-01 -1.22991615e-01 -4.64280268e-02 -2.36709304e-02
 -6.56929394e-03 -4.25921154e-01  2.63097304e-02 -9.47216127e-03
 -8.71080535e-03 -5.32868377e-01 -3.91326880e-01 -1.18734872e-02
  1.27417496e-02  6.09769040e-01  8.94200291e-02  1.54989432e-02
 -7.06491297e-03 -3.61306864e-02 -6.82474702e-01 -1.01457336e-02
  4.55603499e-01 -9.99168403e-01  7.42374267e-01 -3.28572814e+00
 -6.43184662e-01  1.23614583e+00  9.64044645e-01 -1.44226913e+00
 -1.25100314e+01]
supnorm grad right now is: 12.510031363040484
Weights right now are: 
[-1.83404186e+01 -3.99572620e+00  2.21927925e+00  1.22446040e+01
  1.85949873e+01  3.88703451e+00 -1.82034198e+00 -1.29606324e+01
  8.71002317e+01  7.81767824e+01  7.87552885e+01  2.63908045e+01
  3.04957445e+01  2.83368187e+01 -2.73027613e+01 -4.33773058e+00
  6.90465153e+00 -1.63296176e+00  4.09895862e+01  3.08231056e+00
  5.81418328e+01  3.26717691e+01  4.27571109e+00  3.52205530e+01
  2.87490903e+00  3.68312345e+01 -7.74249071e-01  6.26890298e+02
  1.59334697e+00 -1.54880176e+01  1.40975240e+01 -1.03974149e+02
  1.41195595e+01 -9.83017073e+00  1.90563341e+01 -2.76164098e+01
  6.17316808e+00 -1.58479774e+01  5.26437686e+00 -2.44847893e+01
 -2.36906134e+00 -1.58388705e+00 -9.59631237e+00  1.56925393e+01
  6.41806187e+01  4.97676338e+00  6.76996230e-01  9.09648152e+01
 -3.38506809e+01  4.02177152e+00  2.24870912e+01 -6.98869691e+01
  7.83332449e+01  7.50556783e+01 -2.15533839e+00  3.24897064e+01
  5.57728267e+00 -4.63500798e+00 -2.29125539e+00 -4.15535978e+00
  5.26058050e+00  3.41350015e-01  5.37180800e+00 -4.28278457e+00
  3.09578894e+01]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1371.530425857511
gradient value of function right now is: [-8.47874221e-05 -2.36532367e-02 -1.38990899e+00 -2.99508671e-03
  8.47874221e-05  2.36532367e-02  1.38990899e+00  2.99508671e-03
 -2.13867794e-04 -6.66398675e-05 -3.02815454e-09 -9.78336265e-06
  2.54528816e-03 -7.59238424e-02 -5.95160616e-02 -7.15436580e-02
 -1.49250662e-01  2.60191730e+00  3.73010205e-03  1.92954806e+00
  2.63244596e-03  4.84373118e-03  5.90881588e-08  3.26711607e-04
  5.34107059e-01 -7.81381477e-04  3.24298388e-01 -3.44996468e-05
  5.26499550e-01  2.17109223e-01  1.28850990e-01  1.08326325e-03
 -3.37663111e-01 -1.60100396e-01 -3.72013918e-02 -1.35964299e-01
 -1.32627343e+00 -5.42244821e-01 -2.67214768e-01 -4.99849958e-02
  5.76687631e-03  2.29126622e-02  1.92501980e-01  3.08921675e-03
 -3.81489988e-03 -3.60577479e-01 -5.09100463e-01 -5.70847835e-03
  1.60122869e-03  8.81764908e-02 -1.97472872e-04  2.96394897e-04
 -5.33940151e-03 -4.77729725e-02 -6.75182275e-01 -8.69073688e-03
  2.12174912e-01 -6.58049090e-01  1.92301329e+00 -5.46375534e+00
  6.47522054e-01 -6.52641336e-01  2.28989167e-01 -8.35970829e-01
 -6.98229979e-01]
supnorm grad right now is: 5.463755341861252
Weights right now are: 
[-1.82334346e+01 -3.82966703e+00  2.19247218e+00  1.12814747e+01
  1.84880033e+01  3.72097534e+00 -1.79353491e+00 -1.19975031e+01
  8.76262112e+01  8.13854654e+01  7.87565296e+01  3.07836094e+01
  3.03498549e+01  2.83929351e+01 -2.76013022e+01 -4.54102727e+00
  6.70672158e+00 -1.58430659e+00  4.21054061e+01  3.20628861e+00
  5.79799295e+01  3.54293421e+01  4.25413212e+00  3.29507715e+01
  2.84552721e+00  3.86613977e+01 -8.94707998e-01  6.47436495e+02
  2.38915459e+00 -1.44821004e+01  1.34165327e+01 -1.06434211e+02
  1.42092685e+01 -9.70327908e+00  2.04055144e+01 -2.72114249e+01
  6.11279381e+00 -1.55803326e+01  4.76685580e+00 -2.37611158e+01
 -1.89426890e+00 -1.62516630e+00 -9.77798308e+00  1.54027466e+01
  6.52809228e+01  5.50065938e+00  1.04709633e+00  9.22709972e+01
 -3.41589291e+01  4.47660046e+00  2.33491357e+01 -7.04074549e+01
  7.85542983e+01  7.53509281e+01 -2.16115621e+00  3.21362859e+01
  5.03740733e+00 -5.03044172e+00 -2.09860533e+00 -4.21135213e+00
  4.96871051e+00 -1.84152762e-02  5.72045263e+00 -4.45166312e+00
  3.10618100e+01]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1373.121780269123
gradient value of function right now is: [-4.39016719e-06  1.28508123e-02  2.94663486e-01  7.83975425e-04
  4.39016719e-06 -1.28508123e-02 -2.94663486e-01 -7.83975425e-04
 -1.87236917e-05  1.09442562e-05  1.23265784e-10  4.85931479e-07
  5.61681628e-03  2.44816026e-02  1.41506172e-02  1.97790590e-02
 -1.27381182e-01  5.03059373e-02 -5.40077995e-04  1.71712132e-02
 -6.73962011e-04 -2.35883980e-03 -3.93413853e-08 -1.70165773e-04
  5.15204485e-01  4.44700195e-04  4.85095250e-01  4.46257857e-07
 -1.40338856e-01 -7.15550111e-03 -1.62679778e-02 -2.35067665e-04
  1.04868207e-01  5.15529932e-02  1.25735896e-02  4.91783274e-02
  1.71409415e-02 -5.78192900e-03  8.46877663e-03  2.48137294e-03
 -2.32072656e-02 -1.28330511e-01 -5.16143565e-02 -1.75494176e-02
 -4.40954907e-04 -3.75074393e-03  4.21849805e-02 -2.43649722e-04
  3.58460089e-03  6.23670914e-02  9.55742866e-03  3.19481170e-03
  8.26645759e-04  8.80392491e-03  1.81866866e-01  1.70173396e-03
  2.78818628e-02  4.04065169e-02 -2.34154458e-01  8.28576933e-01
 -5.44953853e-02 -1.53835637e-01  1.64700329e-01 -2.12491090e-02
 -1.38658721e+00]
supnorm grad right now is: 1.3865872068951781
Weights right now are: 
[-1.77667895e+01 -3.63553570e+00  2.07628975e+00  1.30380047e+01
  1.80213583e+01  3.52684401e+00 -1.67735248e+00 -1.37540330e+01
  8.93909957e+01  7.93563110e+01  7.87568945e+01  3.06258039e+01
  2.83807270e+01  2.83846978e+01 -2.86929811e+01 -5.54218304e+00
  7.32566838e+00 -1.61347793e+00  4.27179076e+01  3.05444040e+00
  5.65600615e+01  3.44479156e+01  4.19181149e+00  3.15942184e+01
  2.79774283e+00  4.15751384e+01 -3.98645947e-01  6.63401684e+02
  1.98245833e+00 -1.46950696e+01  1.28275321e+01 -1.07109289e+02
  1.37879979e+01 -1.00557090e+01  1.79462924e+01 -2.87148384e+01
  6.45082828e+00 -1.50017868e+01  5.47801987e+00 -2.39953724e+01
 -2.09832717e+00 -2.25816703e+00 -9.46291810e+00  1.51790737e+01
  6.80881064e+01  4.93437556e+00  9.08380527e-01  9.48756872e+01
 -3.28746801e+01  4.21421694e+00  2.39498578e+01 -6.90466272e+01
  7.97094375e+01  7.58275880e+01 -2.55292664e+00  3.21132540e+01
  4.64794394e+00 -5.23015029e+00 -2.18809962e+00 -3.99136749e+00
  4.79573199e+00 -2.15092636e-01  5.50601301e+00 -4.91198507e+00
  3.11021024e+01]
(65,)
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1373.1194487727332
gradient value of function right now is: [-1.58388643e-08  1.47046879e-02  3.57805687e-01  8.45321681e-04
  1.58388643e-08 -1.47046879e-02 -3.57805687e-01 -8.45321681e-04
 -6.71495592e-06  1.46651109e-05  1.97966486e-10  8.30000449e-07
  6.58853925e-03  2.45036881e-02  1.46514664e-02  2.00921580e-02
 -1.22272018e-01 -4.32372387e-02 -5.17214412e-04 -2.37797772e-02
 -9.56086827e-04 -2.08989385e-03 -3.36411956e-08 -1.51944218e-04
  4.77811469e-01  2.85408640e-04  4.38809350e-01  1.52129424e-06
 -1.54010290e-01 -7.50289642e-03 -1.64344065e-02 -3.15281615e-04
  1.04232341e-01  4.87949995e-02  8.50007449e-03  4.60494409e-02
  4.66290699e-02 -1.08178671e-03  7.55909309e-03  6.51218350e-03
 -2.14020060e-02 -1.22763831e-01 -5.66325666e-02 -1.66168845e-02
 -4.28675087e-04  5.55703242e-03  5.42781425e-02 -8.21119184e-05
  4.13587121e-03  6.15938882e-02  1.22706748e-02  3.88759456e-03
  1.16422829e-03  1.07731077e-02  2.03580261e-01  2.44632068e-03
  3.07026273e-02  6.77037480e-02 -2.52709757e-01  9.96124937e-01
 -7.96288607e-02 -8.65800364e-02  1.74171848e-01  1.13953908e-02
 -1.46398545e+00]
supnorm grad right now is: 1.4639854537302956
Weights right now are: 
[-1.92774834e+01 -3.48026687e+00  2.28927084e+00  1.10538998e+01
  1.95320521e+01  3.37157518e+00 -1.89033357e+00 -1.17699282e+01
  9.22653711e+01  7.37672135e+01  7.87540424e+01  2.70494280e+01
  2.93441395e+01  2.99909922e+01 -2.74231473e+01 -4.20155465e+00
  6.72157745e+00 -1.47160814e+00  4.33422318e+01  2.84174485e+00
  5.55400027e+01  3.75881806e+01  4.22128363e+00  3.30415180e+01
  2.79537324e+00  4.43553887e+01 -1.00581958e+00  6.78195916e+02
  1.82056658e+00 -1.57053049e+01  1.25573477e+01 -1.07006282e+02
  1.50029430e+01 -8.66463927e+00  1.95591481e+01 -2.77894824e+01
  5.91547609e+00 -1.50455174e+01  4.97636371e+00 -2.53469313e+01
 -3.41004963e+00 -2.32161434e+00 -1.07095845e+01  1.45183120e+01
  7.05759023e+01  4.94903227e+00  1.34472923e+00  9.72042956e+01
 -3.33104496e+01  4.00332894e+00  2.32178423e+01 -7.20577088e+01
  7.94548691e+01  7.60618676e+01 -2.28377272e+00  3.10764996e+01
  4.68741648e+00 -5.30949040e+00 -2.14342479e+00 -4.17961742e+00
  5.32142395e+00 -2.83418679e-02  5.75936666e+00 -4.14033631e+00
  3.09867186e+01]
(65,)
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1373.1480323901242
gradient value of function right now is: [ 3.65982317e-06  1.49879942e-02  3.16581659e-01  8.42786658e-04
 -3.65982317e-06 -1.49879942e-02 -3.16581659e-01 -8.42786658e-04
  4.05763826e-06  1.63667652e-05  2.47914028e-10  1.14271643e-06
  6.81181010e-03  2.37566300e-02  1.52794355e-02  2.02534553e-02
 -1.17036771e-01 -9.66040273e-02 -5.04831224e-04 -8.21422451e-02
 -1.02690620e-03 -1.80738016e-03 -2.97142662e-08 -1.43494384e-04
  4.11776768e-01 -5.95471191e-05  4.04183427e-01  2.07984225e-07
 -1.10124979e-01 -4.35958623e-03 -1.28037280e-02 -3.27275948e-04
  9.79012990e-02  4.55702482e-02  1.18594050e-02  4.59881516e-02
  6.79342825e-02  5.80925350e-03  6.96513801e-03  1.01469953e-02
 -1.68454092e-02 -1.06432494e-01 -5.35227089e-02 -1.44233034e-02
  5.85369614e-05  1.76197685e-02  7.12979130e-02  5.88307957e-04
  4.02579771e-03  4.96854393e-02  1.27417294e-02  3.82767561e-03
  1.43698935e-03  1.15330430e-02  2.20787686e-01  3.05310062e-03
  2.23926379e-02  1.18515759e-01 -2.39802940e-01  1.01817173e+00
 -6.92108585e-02 -9.20797485e-02  1.43266126e-01  7.24791034e-02
 -1.30123115e+00]
supnorm grad right now is: 1.3012311528127343
Weights right now are: 
[-1.83712882e+01 -3.78681661e+00  2.18335370e+00  1.16915733e+01
  1.86258569e+01  3.67812492e+00 -1.78441643e+00 -1.24076017e+01
  9.40554162e+01  7.50954452e+01  7.87549287e+01  2.97897518e+01
  2.93163845e+01  2.99157271e+01 -2.80059674e+01 -4.62765995e+00
  6.52016681e+00 -1.86380910e+00  4.61583692e+01  2.88200583e+00
  5.49024882e+01  3.84264567e+01  4.20185054e+00  3.08777842e+01
  2.67288378e+00  4.66089837e+01 -1.08946390e+00  6.97265875e+02
  2.23702643e+00 -1.60561121e+01  1.25566535e+01 -1.04028937e+02
  1.43242482e+01 -9.28096131e+00  1.77828622e+01 -2.85205357e+01
  5.95053383e+00 -1.47215977e+01  5.32338969e+00 -2.39317007e+01
 -2.79933084e+00 -1.68586206e+00 -9.70450511e+00  1.51876581e+01
  7.06159576e+01  5.41755814e+00  7.91825608e-01  9.71116598e+01
 -3.46005217e+01  3.95828175e+00  2.22086525e+01 -7.57224689e+01
  8.16787142e+01  7.68967097e+01 -2.10203492e+00  3.21465337e+01
  4.99071048e+00 -4.95974711e+00 -1.84828278e+00 -4.16383257e+00
  4.74799819e+00 -7.18280479e-02  5.92881019e+00 -4.15959280e+00
  3.09677519e+01]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1373.1514831673787
gradient value of function right now is: [ 6.81546362e-06  1.67924079e-02  3.36274744e-01  9.64169595e-04
 -6.81546362e-06 -1.67924079e-02 -3.36274744e-01 -9.64169595e-04
  1.25572635e-05  1.89556008e-05  2.90644814e-10  1.40287406e-06
  7.60768647e-03  2.79879680e-02  1.89063055e-02  2.44098251e-02
 -1.22692617e-01 -9.80034076e-02 -3.88053781e-04 -8.14279022e-02
 -1.30932976e-03 -1.86434628e-03 -2.91565326e-08 -1.43693455e-04
  4.13509092e-01 -8.19555530e-05  3.90027696e-01  9.51785129e-07
 -1.15623221e-01 -5.64966467e-03 -1.38526694e-02 -3.14452276e-04
  1.03624351e-01  5.12741445e-02  1.32119298e-02  4.95428737e-02
  7.06614911e-02  8.69698934e-03  9.06903310e-03  9.28504597e-03
 -1.62792454e-02 -1.08370661e-01 -5.68740152e-02 -1.40800737e-02
  1.75574556e-05  2.04958010e-02  7.00729847e-02  4.91652992e-04
  4.42304881e-03  5.63656092e-02  1.03047463e-02  4.04118570e-03
  1.31164560e-03  1.17732263e-02  2.16496578e-01  2.83379051e-03
  2.95057566e-02  1.08473945e-01 -2.75192327e-01  1.08504632e+00
 -5.03727128e-02 -1.59371246e-01  1.47096322e-01  5.42976479e-02
 -1.42759405e+00]
supnorm grad right now is: 1.427594048907061
Weights right now are: 
[-1.75920115e+01 -4.55065702e+00  2.10585297e+00  1.18530436e+01
  1.78465802e+01  4.44196533e+00 -1.70691570e+00 -1.25690719e+01
  9.50807992e+01  7.65087333e+01  7.87561677e+01  3.24657555e+01
  2.94598979e+01  3.07746689e+01 -2.78175233e+01 -4.10890393e+00
  6.75217469e+00 -1.66366852e+00  4.89805211e+01  3.14291364e+00
  5.53516958e+01  3.92025901e+01  4.19391851e+00  2.72875928e+01
  2.88927283e+00  4.75360143e+01 -1.02324206e+00  7.05182944e+02
  2.15663605e+00 -1.69273848e+01  1.15541736e+01 -1.03852074e+02
  1.49008609e+01 -8.08836388e+00  1.94451247e+01 -2.77790477e+01
  6.25521751e+00 -1.48810812e+01  4.10034360e+00 -2.33003083e+01
 -2.53129462e+00 -1.79849428e+00 -9.62824481e+00  1.69694642e+01
  7.27884214e+01  5.84861773e+00  2.38010517e-01  9.87463722e+01
 -3.23022757e+01  3.99078663e+00  2.18594545e+01 -7.44701336e+01
  8.35783029e+01  7.76122357e+01 -2.38199465e+00  3.30193657e+01
  5.18699392e+00 -5.30423007e+00 -2.01176498e+00 -3.95324338e+00
  5.49286862e+00  8.70519714e-02  5.72817250e+00 -4.60055104e+00
  3.09939257e+01]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1373.1427964830123
gradient value of function right now is: [ 7.06602616e-06  1.62801288e-02  3.45757193e-01  1.00349833e-03
 -7.06602616e-06 -1.62801288e-02 -3.45757193e-01 -1.00349833e-03
  1.15497508e-05  2.09827636e-05  3.27067594e-10  1.57743207e-06
  7.41438160e-03  2.70961358e-02  1.77905291e-02  2.32060249e-02
 -1.20491330e-01 -1.07138108e-01 -3.73322994e-04 -8.66446051e-02
 -1.32911595e-03 -1.98503471e-03 -3.00976015e-08 -1.49587916e-04
  4.08024847e-01  7.86032053e-05  3.67701007e-01  7.69789130e-07
 -1.24190044e-01 -4.93560359e-03 -1.36523501e-02 -3.01376076e-04
  9.84970041e-02  5.22845327e-02  1.58292076e-02  4.84264378e-02
  7.20035842e-02  8.56781985e-03  7.84760337e-03  9.82013736e-03
 -1.47168062e-02 -1.06698534e-01 -5.36110586e-02 -1.22915704e-02
 -7.39764915e-05  1.55162229e-02  6.70255200e-02  3.95072694e-04
  4.47885029e-03  6.01049767e-02  9.71315520e-03  4.02399047e-03
  1.25724359e-03  1.17583909e-02  1.99879009e-01  2.64379352e-03
  3.34600051e-02  1.00248017e-01 -2.77977366e-01  1.07767048e+00
 -3.91867771e-02 -1.77115236e-01  1.49850102e-01  4.43437221e-02
 -1.39080741e+00]
supnorm grad right now is: 1.3908074096268175
Weights right now are: 
[-1.58821298e+01 -3.08624320e+00  2.02738362e+00  1.33149065e+01
  1.61366985e+01  2.97755151e+00 -1.62844635e+00 -1.40309349e+01
  9.79079527e+01  7.70808439e+01  7.87571274e+01  3.59161735e+01
  3.01794950e+01  3.06916714e+01 -2.87022730e+01 -4.49176441e+00
  6.78208519e+00 -1.60698899e+00  5.21356524e+01  3.06540252e+00
  5.28649730e+01  4.10449268e+01  4.19726870e+00  2.45574385e+01
  2.76489833e+00  4.94600752e+01 -1.13126984e+00  7.21619328e+02
  1.70551243e+00 -1.56391118e+01  1.18004697e+01 -1.13318208e+02
  1.52062584e+01 -8.52746393e+00  1.88091913e+01 -2.75016539e+01
  6.02513205e+00 -1.42060058e+01  4.82983339e+00 -2.38500546e+01
 -3.70349904e+00 -2.10343161e+00 -9.51040434e+00  1.46598979e+01
  7.55087822e+01  5.75363152e+00  1.05381448e+00  1.01492947e+02
 -3.08486081e+01  3.09298158e+00  2.24932970e+01 -7.29972210e+01
  8.41016937e+01  7.77125820e+01 -1.73386333e+00  3.35092366e+01
  5.54740897e+00 -5.03695451e+00 -1.66015236e+00 -4.18138334e+00
  4.86972804e+00  5.28774734e-02  5.94154151e+00 -4.13101492e+00
  3.09949055e+01]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1105.4442553204854
W_T_median: 1061.690245633256
W_T_pctile_5: 960.9844825210823
W_T_CVAR_5_pct: 930.969788356148
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.4
F value: -1373.1427964830123
-----------------------------------------------
