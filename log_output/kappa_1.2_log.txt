tracing parameter entered from terminal:  1.2


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2392.1286069702705
gradient value of function right now is: [ 2.30269524e+00  2.76355190e-01  1.52052240e-02  1.52868944e-02
 -2.30269524e+00 -2.76355190e-01 -1.52052240e-02 -1.52868944e-02
  3.31000691e+00  1.65692458e-01  2.41316323e+00  5.21938223e-01
 -1.58673614e+00 -1.03189866e-04 -5.21430100e-02 -1.74345016e-03
  5.90527744e-02  2.63846440e-02  5.58751714e-02  3.47173203e-02
  6.08198129e-02  2.76215455e-02  5.77114266e-02  3.61105073e-02
 -1.89671305e-02  5.83460492e-02 -1.43252678e+00 -1.81587567e-01
  3.93581055e-03  1.47561732e-04  7.32611401e-02  9.81801730e-03
  9.50044784e-03  1.39804852e-01  1.95077159e+00  1.61910589e-01
  4.98102877e-03  4.65768750e-03  3.83673862e-01  4.66399356e-02
  9.81119066e-03  6.46127868e-02  1.83226548e-02  1.11612388e-01
 -1.02173543e-01 -1.03849212e-01 -1.06083532e+00 -1.76158699e+00
 -1.69432990e-01 -7.70713705e-01 -4.68324673e-01 -2.33722145e+00
  5.50126182e-03  1.38918560e-01  4.54766357e-02  6.63823880e-01
  3.16498640e-01 -1.46503468e+00  1.57692647e+00 -3.11167985e+00
 -9.68586380e-01  2.44586580e+00 -7.27482637e-02  1.92269660e-02
 -7.68939973e+00]
supnorm grad right now is: 7.689399729895187
Weights right now are: 
[-1.46168116  3.24084611 -3.21327534 -3.86661671  1.71624987 -3.3495378
  3.61221261  3.15058833  3.9395462  -2.21840698 -3.0381609  -2.32624038
  2.25391304  3.49566839 11.49425157  8.18084186 10.00955928 -1.89066083
 -0.05772452 -1.16199429 10.01954155 -2.38467083 -0.12445851 -0.70815477
  3.83367888 -1.16938171 -2.10254026  0.18861875 -2.32014403 11.57086063
  8.46563404  3.16887899 -4.68348126 14.52175719 -0.42167666 -4.64805057
 -1.97845579 13.2063319   4.21538641 -0.39266865 -5.73029578 -0.31222489
  2.80337036  5.86428892 12.62786814 19.19026302 -4.31096064  2.60658684
  4.22095534  5.41728997 -1.22881022 -1.41753725  8.62936727  4.42706274
 10.50508944  0.38129451  5.20574031 -1.34686169 -1.72107835 -2.78762026
  7.26996235  2.5715251  -1.38802726  7.74775391 26.38397556]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2422.519677010482
gradient value of function right now is: [-3.42160830e+00 -8.23442814e-01 -2.08790072e-01 -2.14381365e-01
  3.42160830e+00  8.23442814e-01  2.08790072e-01  2.14381365e-01
 -2.28605832e+00 -1.55316531e-01 -2.81202078e+00 -2.99008684e-01
  1.08692693e+00  4.13289058e-03  1.96849245e+00  1.44820267e-02
 -6.75611794e-02 -2.04303340e-03 -7.25806937e-02 -2.08649543e-03
 -7.02813557e-02 -2.12255465e-03 -7.61444375e-02 -2.16970452e-03
  3.70493807e-03  1.42152478e+00 -3.22881716e+00 -1.13602327e+00
 -3.02713850e-03 -1.68513246e-05 -8.27189348e-02 -1.64515169e-02
  3.39939804e-03 -1.65509539e-01 -2.34992033e+00  1.40779769e-01
 -1.75184530e-03 -3.58004601e-04 -1.33668729e-01 -2.83253108e-02
 -4.27309583e-03 -1.62753395e-02 -1.70804177e-03 -5.82222441e-04
  5.06389797e-01  2.61604569e-01  8.95133390e+00  1.11800937e+01
  5.38825784e-01  1.20161243e+00  1.01026173e+00  1.01910374e+01
 -1.46237268e-01 -5.11122894e-01 -6.82260805e-01 -7.11635503e+00
 -6.61539660e-01  1.76404935e+01 -4.50674923e+00  1.93170112e+01
  9.35959708e+00 -3.50824955e+01  2.39391306e-02 -6.62146567e-03
  1.30725671e+01]
supnorm grad right now is: 35.082495522595856
Weights right now are: 
[-2.46555018  8.66478414 -1.60410836 -2.18745568  2.72011889 -8.77347583
  2.00304563  1.4714273  -2.9617769  -4.89290576  4.93315946 -2.57413066
  6.07858464 -0.44523096  7.1174806   3.69813201 23.47130332 -7.01470673
  6.96971375 -4.73142576 23.28767838 -7.40708439  6.86239385 -4.20433158
  4.70729955 -7.38592009  3.11585251 -6.61753477 -5.76057936 18.93057559
 15.82433948 -4.1212006  -3.93572595 27.66327258  1.28789987  1.42565379
 -5.06354302 23.8608819  11.5095421  -7.84085946 -4.68534668  1.84859303
  0.5054047   9.73163498 21.62389817 28.422352   -3.57378769  2.33837203
  3.53894385  7.58094399 -3.17971789 -0.94208579 17.88378305  1.75612338
 12.14504614  0.58741423  2.21645497 -1.44255736 -0.7191493  -2.05868172
  5.95263252  1.1901837   2.36991772 13.30006797 27.08277627]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2419.970401239318
gradient value of function right now is: [ 5.27521450e+00  3.07580992e+00  3.84253675e-02  3.95678741e-02
 -5.27521450e+00 -3.07580992e+00 -3.84253675e-02 -3.95678741e-02
 -3.71863604e-01 -5.69854984e-01 -3.86049144e+00 -1.10590497e+00
 -6.57872584e+00  1.21611609e-04  1.87039780e+00  1.27887447e-02
  1.12536098e-02 -3.01036765e-03 -8.86520473e-03 -2.68916154e-03
  1.04576615e-02 -2.53761081e-03 -7.75594555e-03 -2.26551314e-03
  1.48234264e-02  9.56295654e+00  3.34348947e+01 -7.77581837e-01
 -2.72758160e-03 -7.43853005e-07 -3.33541686e-02 -3.86193554e-02
  7.55620006e-03  4.64923186e-03  2.06741952e-01  6.14351070e-01
 -1.89609783e-03 -9.12834734e-04 -1.16840405e-01 -3.15178487e-02
 -1.97653907e-02 -5.62322700e-02 -5.24722754e-03 -1.07964160e-02
  7.35017744e-01  7.92731768e-01  3.32694548e+01  5.47934539e+01
  1.18434787e-01  8.57120245e-01 -3.87209162e+00 -4.22303593e-01
 -1.87135961e-01 -1.13413152e+00 -2.45763842e-01 -7.27110092e+00
 -2.73210369e+00  3.53645523e+01 -1.28041881e+01  6.19130047e+01
  1.54773414e+01 -7.06822787e+01  1.27333451e-01 -4.66870788e-02
  2.14777195e+01]
supnorm grad right now is: 70.6822787106
Weights right now are: 
[-2.59993023  8.26904237 -1.21386391 -1.62606131  2.85449894 -8.37773406
  1.61280118  0.91003293 -2.93989161 -1.92486936  5.49077494 -0.32203163
  5.7433701  11.23345929  6.51538453 16.16915152 38.8644604  -8.07702515
  8.96422412 -6.08092693 38.69926304 -8.42582023  9.05960768 -5.50367076
  3.60451871 -7.62987789  3.48981953 -7.46029065 -8.15214361 19.80359054
 24.21949504 -2.66827933  6.45298045 31.494225    0.46208835  3.84147222
 -3.61824635 40.87617035 10.34816015 -3.36657306 -3.01586923  0.62796328
  3.73340954 13.42020462 27.45158771 35.83787793 -3.13166228  2.18408839
  5.96665739  9.18046723 -3.52074814 -0.87313512 16.20947614 -1.17865873
 18.82122606  1.25718511  2.47292025 -1.786902   -0.70158587 -2.14202428
  6.47658044  1.32784092  4.65558894 13.42173856 27.15242419]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.8179734888095
gradient value of function right now is: [-7.49686702e-01 -2.32080282e-02 -1.28356734e-02 -1.26112542e-02
  7.49686702e-01  2.32080282e-02  1.28356734e-02  1.26112542e-02
 -1.85886707e+00 -7.41680458e-01 -2.82657238e+00 -1.23422485e+00
 -3.55981768e-01  4.67425805e-06  1.38330704e+00  1.30152190e-02
 -6.11270273e-03 -7.53205906e-04 -1.60390877e-02 -5.84028749e-04
 -5.75779959e-03 -7.24380391e-04 -1.49437229e-02 -5.60342419e-04
 -1.40135079e-03  1.40118733e+00  2.59756233e+00 -2.87311779e-01
 -4.28185034e-03 -1.17739156e-07 -1.39772581e-02 -1.01700880e-02
  1.21150581e-02 -4.56766985e-02 -3.45800327e-01  2.15607278e-01
 -2.36187861e-03 -2.49182915e-03 -1.83992974e-01 -1.69929670e-02
 -2.12466654e-02 -4.12770689e-02 -3.60146183e-03 -1.13206654e-02
  2.14007113e-01  1.66707972e-01  7.27693918e+00  9.44969091e+00
  2.16966002e-01  3.87887718e-01 -1.56569839e-01  4.04928808e+00
 -7.49311141e-02 -2.25071250e-01 -1.16330212e-01 -2.75700441e+00
 -1.02850993e+00  1.25708487e+01 -3.05309347e+00  1.61369528e+01
  4.42820475e+00 -1.68057529e+01  1.24808112e-01 -4.91213609e-02
  8.96441698e+00]
supnorm grad right now is: 16.805752884104102
Weights right now are: 
[-2.80857280e+00  7.72637714e+00 -3.12598296e+00 -3.53831610e+00
  3.06314152e+00 -7.83506883e+00  3.52492023e+00  2.82228772e+00
 -2.82768673e+00 -1.57868617e+00  5.78643089e+00 -6.64330115e-01
  5.46071743e+00  1.91327330e+01  5.59599258e+00  2.20664114e+01
  5.41331194e+01 -8.32307817e+00  6.92111382e+00 -5.83002683e+00
  5.42231248e+01 -8.72557701e+00  6.98189041e+00 -5.33648954e+00
  4.60628487e+00 -7.88338131e+00  3.58752142e+00 -9.14260547e+00
 -5.18848404e+00  1.98920901e+01  3.12357344e+01  7.47799533e+00
  6.45094254e+00  3.54273161e+01 -2.99676151e-02  2.93064801e+00
 -1.33482100e+00  5.51666827e+01  7.60090707e+00  3.22045196e+00
 -2.87746597e+00  1.11552304e+00  4.43524746e+00  1.49936329e+01
  3.27042259e+01  4.17137167e+01 -3.09253023e+00  2.01563662e+00
  8.97102744e+00  1.16554265e+01 -3.36633684e+00 -6.50980878e-01
  1.68154394e+01 -1.36007270e-01  2.52745154e+01  1.01207412e+00
  1.51496114e+00 -1.89342510e+00 -4.67219309e-01 -2.21915080e+00
  6.71849910e+00  1.34985131e+00  4.88336665e+00  9.83186514e+00
  2.71894318e+01]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2421.989373140016
gradient value of function right now is: [ 3.21065989e+00  2.22275235e+00 -5.83050615e-03 -5.75934221e-03
 -3.21065989e+00 -2.22275235e+00  5.83050615e-03  5.75934221e-03
 -1.96256135e+00 -1.08772237e+00 -5.26008584e+00 -2.29797563e+00
 -4.42264109e+00  2.42038579e-06  2.46422142e+00  3.53624798e-02
 -2.33727678e-03 -3.37731650e-03 -4.92285046e-03 -2.11852193e-03
 -2.25625644e-03 -3.27111785e-03 -4.71669703e-03 -2.05097785e-03
  9.35755454e-03  6.69597596e+00  2.20911895e+01 -5.69383744e-01
 -1.38898072e-02 -1.31815575e-08 -1.13065213e-02 -2.00418582e-02
  2.21023151e-02 -6.81491636e-02 -1.54915105e-01  5.23418472e-01
 -1.64895973e-02 -5.52114153e-03 -5.16342216e-01 -6.52961048e-02
 -5.13849626e-02 -1.42583304e-01 -7.94541219e-03 -3.88082922e-02
  5.66244242e-01  4.44334949e-01  2.59953500e+01  4.36811890e+01
  2.49099412e-01  6.96737337e-01 -3.53496840e+00  1.51793234e+00
 -1.71133561e-01 -6.93662808e-01 -1.46182334e-01 -5.78436661e+00
 -3.53215336e+00  3.89717792e+01 -9.26444298e+00  4.69299184e+01
  1.22169604e+01 -5.73477317e+01  3.97940995e-01 -1.39687830e-01
  2.13690938e+01]
supnorm grad right now is: 57.34773174917037
Weights right now are: 
[-2.72503387e+00  7.18728000e+00 -2.59192895e+00 -3.08071250e+00
  2.97960258e+00 -7.29597169e+00  2.99086622e+00  2.36468412e+00
 -2.75636136e+00 -1.11966003e+00  6.01989411e+00 -8.33473236e-01
  5.35409121e+00  2.00654391e+01  5.34841771e+00  2.30573720e+01
  6.89143720e+01 -8.21509569e+00  8.97801466e+00 -5.59614175e+00
  6.90275586e+01 -8.56961759e+00  9.01655081e+00 -5.05583113e+00
  4.18645054e+00 -8.11869996e+00  3.58280891e+00 -8.42270983e+00
 -6.16771240e+00  1.98909525e+01  4.15119655e+01  1.45011418e+01
  9.11570283e+00  3.81501412e+01  6.30974584e-02  4.54242754e+00
 -1.20407759e+00  6.68907311e+01  7.12714815e+00  6.03498297e+00
 -4.49015478e+00  7.81287870e-01  6.23133219e-01  1.42809262e+01
  3.81274743e+01  4.71084244e+01 -3.04826919e+00  2.05208479e+00
  7.39527725e+00  1.26225896e+01 -3.18952329e+00 -7.10271591e-01
  1.53754932e+01  8.76219617e-02  2.96924406e+01  1.41487551e+00
  1.79336805e+00 -1.94676798e+00 -6.94961738e-01 -2.36101372e+00
  7.06809980e+00  1.33413419e+00  4.27700882e+00  1.01273539e+01
  2.71868701e+01]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2422.736510899356
gradient value of function right now is: [-1.90029979e+00 -9.18631676e-01  2.98579793e-03  2.98082903e-03
  1.90029979e+00  9.18631676e-01 -2.98579793e-03 -2.98082903e-03
 -5.06269278e-01  3.15367244e-01  8.19284965e-01  6.14673045e-01
  1.79390120e+00 -9.48086923e-08 -2.93874668e-01 -6.64874278e-03
  2.17173764e-03 -2.83787844e-04  8.52627164e-03 -2.21928515e-04
  2.16517560e-03 -2.95869970e-04  8.50771144e-03 -2.31974211e-04
  2.57475281e-03 -1.55808944e+00 -8.62025915e+00 -3.28286230e-01
  2.32892117e-05  1.79148982e-09  2.73470014e-03  1.38555444e-03
 -2.70260763e-03  4.81411465e-03  4.32612505e-01  9.32531205e-02
  7.20333958e-06 -5.32225982e-04  1.15138672e-01 -3.89873262e-03
  2.51839025e-04  1.69669689e-03  5.45683966e-04  8.91603326e-03
 -2.67637614e-01 -2.00684576e-01 -8.46000805e+00 -1.05757948e+01
 -7.32667704e-02 -8.26549810e-02  2.38841375e-01  3.43291867e+00
 -7.14682718e-03 -6.48625779e-02 -1.26444750e-01 -3.39210535e+00
  1.49845573e+00 -1.90270415e+01  1.79740464e+00 -1.66294914e+01
  3.75344511e+00 -5.22505331e+00 -1.38442771e-02  1.22398825e-02
 -3.46170042e+00]
supnorm grad right now is: 19.027041489875977
Weights right now are: 
[-2.74359349e+00  7.27082465e+00 -8.29535346e+00 -8.85092058e+00
  2.99816220e+00 -7.37951634e+00  8.69429072e+00  8.13489219e+00
 -2.51136100e+00 -1.28237598e+00  6.53894706e+00 -1.08751988e+00
  5.51075610e+00  2.01790068e+01  5.35900423e+00  2.47824752e+01
  7.63407608e+01 -1.19218666e+01  8.45710873e+00 -9.04918385e+00
  7.63649091e+01 -1.23599970e+01  8.45785717e+00 -8.60650627e+00
  8.05396845e+00 -8.24068164e+00  3.62975283e+00 -1.01582926e+01
 -5.39231681e+00  1.98909845e+01  4.97728883e+01  1.22831060e+01
  9.18962283e+00  4.10580487e+01 -2.30041322e-02  4.20142837e+00
 -2.08253092e+00  7.59740153e+01  7.12914025e+00  6.16717377e+00
 -6.61637358e+00  7.91434157e-02 -1.57887174e+00  1.20503348e+01
  4.26054886e+01  5.12989764e+01 -3.12223369e+00  2.13838574e+00
  7.21849276e+00  1.43653556e+01 -3.80536502e+00 -5.48309708e-01
  1.34810944e+01  8.27603293e-01  3.15291912e+01  1.29295691e+00
  1.96013421e+00 -2.12559085e+00 -8.22770617e-01 -2.54748988e+00
  7.50355198e+00  1.33961332e+00  5.29226651e+00  9.61829156e+00
  2.71046648e+01]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -2423.263012637041
gradient value of function right now is: [ 3.39849264e+00  2.21565281e+00  4.22837385e-03  4.22576154e-03
 -3.39849264e+00 -2.21565281e+00 -4.22837385e-03 -4.22576154e-03
 -7.30579817e-01 -8.57761877e-01 -2.70425253e+00 -1.73900739e+00
 -3.99480790e+00  8.41078870e-08  2.51939738e-01  1.29311761e-02
  4.51925798e-03 -3.54376710e-04  1.00504747e-02 -2.22421308e-04
  4.51061664e-03 -4.13626363e-04  1.00558085e-02 -2.61660058e-04
 -4.77683213e-03  5.17653331e+00  1.82403253e+01 -1.87175998e-01
 -8.21382282e-03 -3.47083317e-09 -8.77543633e-03 -2.08003610e-02
  1.36733443e-02  6.90213143e-03  1.03619503e+00  2.78574400e-01
 -6.17863649e-03 -2.77307514e-03 -2.48330725e-01 -5.15733947e-02
 -2.45057313e-02 -6.65658201e-02 -2.29263932e-03 -1.49782902e-02
  2.22955276e-01  2.26811626e-01  1.90960923e+01  3.09824899e+01
  1.07057621e-01  3.33313923e-01 -2.61608625e+00 -1.72712332e+00
 -5.96298111e-02 -2.58299368e-01 -4.80623836e-02 -2.33244562e+00
 -2.19057195e+00  2.01740545e+01 -5.56460044e+00  2.87527550e+01
  7.09582340e+00 -3.44944581e+01  1.39782947e-01 -3.62383504e-02
  8.63988118e+00]
supnorm grad right now is: 34.49445814516135
Weights right now are: 
[-2.78507131e+00  7.35160014e+00 -1.21260897e+01 -1.26973705e+01
  3.03964002e+00 -7.46029183e+00  1.25250269e+01  1.19813421e+01
 -2.49569550e+00 -2.01417111e+00  6.23947343e+00 -1.50059342e+00
  5.18495296e+00  2.01536978e+01  5.60331389e+00  2.58242534e+01
  8.24136175e+01 -1.03005466e+01  9.20592224e+00 -7.10958385e+00
  8.24113734e+01 -1.07838639e+01  9.20421958e+00 -6.71987411e+00
  6.64495734e+00 -8.09438034e+00  3.70713892e+00 -1.08392278e+01
 -4.43054605e+00  1.98915358e+01  6.18505646e+01  1.61736634e+01
  8.87764246e+00  4.52097955e+01  1.66132434e-01  4.31945181e+00
  8.23837612e-02  8.67753453e+01  6.33525960e+00  6.65387634e+00
 -4.19289354e+00  2.07943576e+00  3.35365215e-01  1.38691162e+01
  4.67941520e+01  5.54967519e+01 -2.99072335e+00  2.18801650e+00
  7.33785306e+00  1.49674286e+01 -3.82282803e+00 -4.75920301e-01
  1.22571979e+01  1.12879172e+00  3.24709540e+01  1.62994153e+00
  1.56637463e+00 -2.13732442e+00 -9.13628021e-01 -2.41272114e+00
  7.69549256e+00  1.53432743e+00  3.55875293e+00  9.41371764e+00
  2.69705081e+01]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2421.484401755831
gradient value of function right now is: [ 3.46471388e-01 -9.62657154e-02  2.91940492e-03  2.96693279e-03
 -3.46471388e-01  9.62657154e-02 -2.91940492e-03 -2.96693279e-03
  2.16750969e+00  1.12122166e+00  3.63301674e+00  1.82465902e+00
  1.28003840e+00 -4.77442585e-06 -2.16395137e+00 -2.63471697e-02
  5.31477523e-03  3.84788185e-03  1.24884540e-02  1.67015870e-03
  5.52643772e-03  5.27558866e-03  1.24433280e-02  2.28343042e-03
  1.34382877e-02 -2.81480202e+00 -7.04227725e+00  2.82287375e-01
  2.64956374e-02  8.11487398e-11  2.82560662e-03  1.02045299e-02
 -6.69084226e-02  5.01710433e-02  1.01161400e+00 -2.62251196e-01
  2.24442208e-02  1.82942012e-03  3.63690901e-01  2.87900208e-02
  1.74183247e-01  3.36213844e-01  2.72405251e-02  8.20693571e-02
 -2.50291809e-01 -2.49422254e-01 -1.38865610e+01 -2.02205288e+01
 -2.01004314e-01 -4.10514997e-01  4.87088244e-01 -4.05011194e+00
  1.10879533e-01  3.96446436e-01  1.12863449e-01  3.09916177e+00
  2.11202541e+00 -2.12871059e+01  5.11262047e+00 -3.02807080e+01
 -7.31232182e+00  2.76335142e+01 -6.75390507e-01  4.01422657e-01
 -1.73188249e+01]
supnorm grad right now is: 30.28070803069296
Weights right now are: 
[ -2.77410069   7.43517751 -14.79287916 -15.33303513   3.0286694
  -7.5438692   15.19181643  14.61700675  -2.56313381  -1.11301411
   6.63741102  -0.89495126   5.17679298  20.22830197   5.50936776
  23.18062738  88.55972947  -7.8665975    8.55155395  -3.40894454
  88.63201282  -8.42683793   8.55785023  -3.07981773   5.08439159
  -8.52542936   3.47212001 -10.61937114  -4.20378452  19.89140703
  72.21935331  21.40158317  10.13522486  48.70369725   0.29814932
   5.34487591   1.55032264  96.28191742   7.5625106    7.36730162
  -4.19026445   2.52482007  -1.30276642  14.98015065  51.50274784
  60.02904875  -3.0177579    1.96432146   5.94376451  15.22723063
  -3.10844273  -0.78581861  10.70990703   0.58535039  35.3448817
   1.29951776   1.80645484  -2.24423624  -0.59489057  -2.50228174
   7.55183505   1.66369746   4.12606744   5.27344738  27.33963669]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2424.400886421253
gradient value of function right now is: [-1.97939639e+00 -4.63248787e-01  2.18035791e-03  2.18122042e-03
  1.97939639e+00  4.63248787e-01 -2.18035791e-03 -2.18122042e-03
 -1.84464422e+00 -4.66317158e-01 -6.83521001e-01 -7.72314118e-01
  1.27129701e+00  1.77971187e-07 -7.04794132e-01 -3.57903747e-03
  4.01808208e-03  5.30706115e-04  1.20522267e-02  2.26359346e-04
  4.04289481e-03  8.53234676e-04  1.19890114e-02  3.55191869e-04
 -1.09293414e-02 -1.15142608e+00 -6.04185860e+00 -1.93447576e-01
 -9.73098378e-04 -1.63392428e-10 -2.80887018e-03 -2.45483230e-03
  6.98038242e-03  9.95299024e-03  1.18465430e+00  1.07833395e-01
 -1.29251783e-03  1.18836485e-04  3.86884238e-02 -1.29427871e-02
 -1.42493769e-02 -2.09474399e-02 -7.23891598e-03 -2.10825811e-02
 -8.98567069e-02 -8.45022002e-02 -4.11682689e+00 -8.48225434e+00
  4.28489532e-02  8.98496471e-02  4.23348965e-01  3.70542282e+00
 -2.61323703e-02 -9.41554388e-02 -6.54021676e-02 -2.15051301e+00
  9.63137588e-01 -8.34394730e+00  9.01800979e-01 -8.26153783e+00
  1.13090902e+00  7.71777590e-01  1.65092853e-01 -1.54299181e-01
  1.12634287e+00]
supnorm grad right now is: 8.482254344912086
Weights right now are: 
[ -2.84330464   7.35565525 -19.29964585 -19.83478517   3.09787335
  -7.46434694  19.69858312  19.11875678  -2.58231532  -1.73464662
   6.69718205  -1.94298609   5.44606031  20.04780997   5.53754074
  22.94866993  91.3126035   -6.69883893   9.29151606  -1.14380811
  91.40025291  -7.34857103   9.29115472  -0.91133906   3.45381906
  -8.46007797   3.50207658 -10.88425372  -3.91590585  19.89140515
  78.47380239  22.32656675  10.77009133  52.88359695   0.62716895
   4.95109598   0.99373171 105.08740583   7.97766248  10.48853575
  -5.85902919   2.30192459  -3.95903276  15.08981731  55.94725865
  64.15083775  -3.00374253   2.01870909   7.9243552   17.58761523
  -3.28391605  -0.65070366  11.87237868   3.21046078  37.18846939
   1.24524119   1.43001916  -2.21861862  -0.783135    -2.53284834
   7.90963638   1.53616281   4.14973008   5.11932947  27.24670674]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2424.8900212081
gradient value of function right now is: [ 1.71770280e+00  6.58545099e-01  9.34909205e-05  7.47746735e-05
 -1.71770280e+00 -6.58545099e-01 -9.34909205e-05 -7.47746735e-05
  8.32420905e-01  8.75325677e-01  2.42526483e-01  7.39555211e-01
 -1.17135616e+00  5.49199079e-07  2.30271552e-01  7.34097512e-03
 -1.60395632e-04 -1.48443040e-03  1.10138484e-03 -7.07282762e-04
 -2.49277427e-04 -1.90596149e-03  1.03188581e-03 -9.08232658e-04
  1.82045980e-02  1.28906631e+00  5.75903503e+00 -4.68919508e-02
 -3.98162796e-03 -2.71138049e-11  2.73372551e-04 -1.32032600e-03
 -1.53599105e-02 -9.82666441e-04  2.92828400e-01  1.57685536e-01
  2.19006221e-04 -4.10221427e-04 -9.60533204e-02 -1.57934382e-02
  5.81902311e-02  1.80485923e-02  3.32488643e-02  3.49001370e-02
  1.15480466e-01  1.03940846e-01  6.76526440e+00  8.71185178e+00
 -8.28812957e-03  3.84508987e-02 -1.03340532e+00 -6.69867317e-01
 -3.44210162e-02 -1.41445747e-01 -5.12202602e-03 -4.94282033e-01
 -1.08903625e+00  1.20945464e+01 -1.79586550e+00  1.30655192e+01
  1.05230664e+00 -5.58137688e+00  3.40346430e-01 -4.39626940e-01
  3.58336315e+00]
supnorm grad right now is: 13.06551923426631
Weights right now are: 
[ -2.57125708   7.25584789 -23.63588489 -24.19632129   2.82582579
  -7.36453958  24.03482215  23.48029291  -2.34579208  -0.77292214
   6.99089025  -1.18699853   5.41334507  24.4909985    5.48638399
  24.65681578  93.46255063 -10.68708572   9.43779983  -4.52906538
  93.38803827 -11.31943769   9.44636091  -4.28097845   9.14743014
  -8.45381299   3.48436944  -9.78739501  -1.07106526  19.89140913
  92.77328405  22.4783034    9.16272279  54.54988373   0.42041674
   4.95139596   4.17386428 117.05436375   7.77482491  10.24378752
  -4.72555116   1.91665166  -0.30489559  19.19708244  60.1842384
  67.81234609  -2.9546409    2.17056466   5.67075355  17.04028983
  -2.91087756  -0.74057706  10.46253376   3.80549273  36.36486495
   1.60320497   1.39796166  -2.22205752  -0.82000054  -2.52866965
   8.02009996   1.74505492   4.70746095   4.11619196  27.29618113]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2416.8403892129722
gradient value of function right now is: [ 1.89228852e-01 -1.23634053e-01  1.88531068e-03  1.87471576e-03
 -1.89228852e-01  1.23634053e-01 -1.88531068e-03 -1.87471576e-03
  2.42185286e+00  5.87469015e-01  3.94036895e+00  1.73011603e+00
  1.49109690e+00 -4.86563455e-06 -1.95023323e+00 -2.86110995e-02
  5.94308148e-03  1.23075033e-03  1.24059295e-02  5.94157012e-04
  5.88298282e-03  1.32740456e-03  1.22185528e-02  6.37781773e-04
  6.43376175e-03 -2.99312844e+00 -8.31739705e+00  3.04461846e-01
  1.81406844e-02  2.20159049e-11  2.88271517e-03  8.83250475e-03
 -4.89374105e-02  3.25062381e-02  3.18260088e-01 -4.24845969e-01
  1.97352872e-02  2.15193089e-03  5.65178041e-01  6.76904233e-02
  5.85741763e-02  1.53967690e-01  1.03664464e-02  8.11325920e-02
 -2.28896139e-01 -1.71688360e-01 -1.38885696e+01 -2.18178938e+01
 -2.46975350e-01 -4.35496642e-01  6.62314261e-01 -3.21919059e+00
  9.74190412e-02  3.53401927e-01  8.14788698e-02  3.12214753e+00
  2.77604198e+00 -2.52913483e+01  4.58535201e+00 -2.64023551e+01
 -6.76070516e+00  2.62048576e+01 -1.28988544e+00  1.13173659e+00
 -2.08052565e+01]
supnorm grad right now is: 26.402355075671583
Weights right now are: 
[ -2.69944124   7.21123895 -27.03503962 -27.44167719   2.95400995
  -7.31993064  27.43397689  26.72564881  -2.32834532  -1.39111868
   7.11598373  -1.88862292   5.55988106  27.21714595   5.98989163
  26.25093843  97.33129569  -7.22891308   9.78198017  -0.69156056
  97.43846995  -7.69501013   9.80278621  -0.23437239   7.83901372
  -8.60724701   3.38778148  -9.46652861  -0.37373896  19.89141013
 101.47213501  25.84608477  11.37330233  58.33332317   0.75891786
   5.48612113   3.92407812 128.30171607   7.34787493   9.85692298
  -7.49615267   1.52065394  -7.84552716  16.98626453  64.42776514
  71.50006966  -2.97028192   2.02571203   5.44779665  16.97225382
  -3.06571381  -0.6519599    9.47373342   3.6694952   37.59193289
   1.54962404   1.81700766  -2.23146946  -0.55039785  -2.6835385
   7.88800158   1.75191364   4.20245576   4.60297107  27.02287619]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2420.1008657747284
gradient value of function right now is: [-3.34267232e-01 -1.80650052e-01  1.76947052e-03  1.77370439e-03
  3.34267232e-01  1.80650052e-01 -1.76947052e-03 -1.77370439e-03
  1.32190703e+00  2.77309720e-01  2.67393431e+00  9.77645715e-01
  1.34458455e+00 -1.26949532e-04 -1.61000616e+00 -1.86000004e-02
  6.50406129e-03  3.05029203e-03  1.12383359e-02  6.76451904e-04
  6.47128996e-03  3.22343170e-03  1.10906219e-02  7.13555228e-04
 -4.08577621e-02 -2.66694922e+00 -7.91393636e+00  2.24106799e-01
  3.14990763e-02  6.86569418e-12  1.64141410e-03  5.04798201e-03
 -4.64811294e-02  3.00227829e-02  6.07140334e-01 -3.19554236e-01
  1.82737685e-02  9.82454590e-04  3.56783203e-01  4.34972194e-02
  6.80056546e-02  1.73290451e-01  1.71783557e-03  5.18583187e-02
 -2.00442971e-01 -2.13989044e-01 -1.44149667e+01 -1.93825388e+01
 -1.56160932e-01 -2.99443141e-01  1.08864102e+00 -2.29144092e+00
  5.69115313e-02  1.84388185e-01  8.03527725e-02  1.90933832e+00
  2.54439539e+00 -2.29858039e+01  4.59477046e+00 -3.07693873e+01
 -6.00325733e+00  2.37868386e+01 -9.14867486e-01  9.28781503e-01
 -1.68200942e+01]
supnorm grad right now is: 30.769387265350392
Weights right now are: 
[ -2.7829392    7.37433015 -31.92233802 -32.2819157    3.03750791
  -7.48302184  32.32127529  31.56588731  -2.18526847  -1.49474586
   7.23928711  -2.03446569   5.57499139  31.74469095   6.01165846
  25.48643884  98.0507782   -4.11366552   9.28418318   2.23921024
  98.17263471  -4.56714529   9.28753086   2.70401783   6.3736917
  -8.58614373   3.43563396  -9.73133657   2.63500747  19.8914115
 114.00912983  25.74884496  11.2086191   61.93528264   0.59680763
   3.97362882   6.54500402 137.76450855   7.70101732  11.24589942
  -6.73973969   2.11836119  -6.13959096  17.50812086  68.1999676
  74.68940986  -3.06903918   2.14433418   5.00657198  17.72229237
  -2.52006215  -0.85829411   9.97088423   4.79561341  37.52453187
   1.06833994   1.25293312  -2.41292321  -0.65446756  -2.58276692
   8.33497455   1.93505074   5.07044574   4.22940898  27.15834772]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2423.2893351159887
gradient value of function right now is: [-2.07156950e+00 -1.05848660e+00 -9.37212203e-05 -8.78613200e-05
  2.07156950e+00  1.05848660e+00  9.37212203e-05  8.78613200e-05
 -3.59290812e-01  1.84818902e-01  3.63205424e-01  2.94209850e-01
  1.84506588e+00 -4.38464606e-05  9.25233293e-02  1.85847436e-03
 -4.54495802e-04  8.67671039e-04 -4.74958305e-03  1.01529637e-04
 -4.26280315e-04  9.12362188e-04 -4.67492224e-03  1.07738843e-04
 -2.88817992e-04 -2.02143658e+00 -9.18334961e+00  6.37099890e-02
  1.31685443e-02  1.31292744e-11  2.12603931e-04  2.65384166e-03
 -4.77626107e-02  5.26416153e-03 -1.42867328e-01 -1.05196344e-01
  1.20956625e-02  9.79266134e-05 -2.29943567e-02  1.79373894e-02
  4.65302253e-02  9.11796439e-02  5.64708655e-03  3.69009754e-02
 -1.14262207e-01 -1.26063276e-01 -9.12910167e+00 -1.41875985e+01
  3.61135133e-02  1.60062057e-02  2.26234074e+00  3.03762797e+00
  2.51412490e-02  7.05867257e-02  1.84056343e-02  4.75350200e-01
  1.73809639e+00 -1.44598143e+01  2.34222062e+00 -1.72711234e+01
 -2.88542036e+00  1.33147142e+01 -4.89330588e-01  2.78643697e-01
 -6.86631043e+00]
supnorm grad right now is: 17.2711233610248
Weights right now are: 
[ -2.76019405   7.0115321  -34.36390964 -34.66887599   3.01476276
  -7.12022379  34.76284691  33.95284761  -2.36989095  -1.02754654
   7.13866436  -1.98131555   5.72006559  38.29007549   6.62851485
  27.20091605 100.43506984  -4.45970654   7.00302148   2.50362113
 100.54081509  -4.89256551   7.00801463   2.98958521   7.09828376
  -8.61636766   3.43344666  -9.49264841   3.58789893  19.89141324
 122.40858336  22.9661497    9.6596162   66.93118336   0.90063815
   4.64305216   9.30031112 148.50198663   7.919546    11.45237993
  -7.05066226   1.83607663  -8.01964009  18.72727149  72.77670829
  78.37670082  -2.95522833   2.07704825   7.43450587  19.79550498
  -2.70859947  -0.60558402  10.42235595   5.66117758  38.95069561
   1.61548809   0.89287638  -2.35848524  -0.75524737  -2.50716224
   8.41573131   1.82427826   4.84346825   3.56020164  27.08445288]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.5464202065596
gradient value of function right now is: [ 7.09721606e-01  6.35670997e-01 -5.52321568e-05 -5.32561457e-05
 -7.09721606e-01 -6.35670997e-01  5.52321568e-05  5.32561457e-05
 -1.04489854e+00 -2.63795000e-01 -1.58907643e+00 -9.40950905e-01
 -1.23004540e+00  4.81079872e-04  1.62114455e-01  9.76100615e-03
 -3.34666081e-04 -7.72726574e-04  1.11657306e-03 -7.45790824e-04
 -3.25709376e-04 -7.61240243e-04  1.11274534e-03 -7.34549800e-04
  2.26820592e-02  1.25543191e+00  5.83063175e+00 -8.44312909e-02
 -1.17947122e-02 -6.15949452e-12 -8.05758214e-04 -2.17841794e-03
  5.11147320e-02  6.18038908e-03  9.92754071e-01  2.27676474e-01
 -1.64168940e-02 -3.22249006e-04 -2.08294777e-01 -3.74745247e-02
 -6.32938608e-02 -1.27281629e-01 -3.29575780e-03 -2.30706441e-02
  4.83031255e-02  5.09709530e-02  5.35367735e+00  8.05803933e+00
  7.83842896e-02  1.31388904e-01 -7.51922450e-01 -1.34689544e+00
 -7.07883969e-02 -1.90466851e-01 -5.45366088e-03 -8.29909833e-01
 -5.89879652e-01  7.06981302e+00 -1.06105300e+00  9.29012492e+00
  1.10396984e+00 -4.78233698e+00  9.68874765e-01 -1.09224037e+00
  5.89078175e+00]
supnorm grad right now is: 9.290124916954777
Weights right now are: 
[ -2.76878911   7.22793096 -36.33493549 -36.70861231   3.02335782
  -7.33662265  36.73387276  35.99258392  -2.73366841  -0.85349409
   7.28115843  -1.79179743   5.66953868  41.86141739   6.04527196
  29.50146314 103.71837992   0.17342048   7.54773086   4.88539069
 103.76063069  -0.3067672    7.5447475    5.5540776    8.66558429
  -8.30714634   3.37529113  -9.67606337   7.47911844  19.89141363
 131.61946398  21.63586192   8.98920168  70.27972902   0.82831217
   5.65642874   7.94643242 158.71244627   7.58568479   5.03866952
  -6.65812208   2.17436809  -8.15143426  20.44779629  76.61584863
  81.96419549  -2.86514543   2.3962814    9.26093612  20.16961649
  -2.38023642  -0.87650243   9.929093     6.0962015   38.28618905
   1.78743973   1.03563998  -2.41547646  -0.56322552  -2.54700024
   9.09507      1.93620673   5.27357639   4.01928054  27.19712198]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2424.331417733776
gradient value of function right now is: [-6.71604431e-01  1.79986948e-01 -1.07635883e-03 -1.07078176e-03
  6.71604431e-01 -1.79986948e-01  1.07635883e-03  1.07078176e-03
 -2.34609090e+00 -1.07238548e+00 -3.00413466e+00 -1.72799281e+00
 -4.80836988e-01  7.87508509e-09  1.65487072e+00  5.35376911e-03
 -4.80008962e-03 -1.39718007e-03 -1.27312541e-02 -1.58398890e-03
 -4.76739801e-03 -1.31516722e-03 -1.26771641e-02 -1.49122522e-03
 -3.06449212e-02  1.85711486e+00  5.16868444e+00 -4.30501126e-01
 -5.20833596e-02 -7.10883086e-12 -2.19461829e-03 -7.73507001e-03
  1.38524983e-01 -2.19627787e-02 -9.73101388e-01  3.65221925e-01
 -6.34814757e-02 -2.86129635e-04 -1.30824610e-01 -5.05393054e-02
 -1.41823176e-01 -3.21854053e-01 -3.75709092e-03 -4.56294552e-02
  1.62891103e-01  1.02738923e-01  1.21160397e+01  1.36237859e+01
  1.16685208e-01  2.48474091e-01 -8.52687238e-01  5.04969902e+00
 -8.95847353e-02 -2.85473073e-01 -8.52189538e-02 -4.08696072e+00
 -2.00509348e+00  2.28411339e+01 -1.82814480e+00  1.80897092e+01
  5.07300440e+00 -1.92344822e+01  1.47208688e+00 -1.45388026e+00
  1.45615299e+01]
supnorm grad right now is: 22.841133861320863
Weights right now are: 
[ -2.80519996   7.30859455 -39.68281389 -40.09265866   3.05976867
  -7.41728624  40.08175115  39.37663027  -2.31097201  -1.68497426
   7.55229624  -2.05757766   5.81043625  48.94989941   6.2636
  29.5246342  105.40094378   3.21767572   8.32054449   6.62151993
 105.42142648   2.73125278   8.31583756   7.31238012   8.87745108
  -8.35277422   3.25309247  -8.957807     3.67556098  19.89140989
 138.82985769  17.56358426   9.92708032  74.11414181   0.3481617
   5.75448829   3.27249718 166.95433747   9.71453651   5.02212343
  -5.26761411   3.13332197  -8.37294838  22.16746867  81.07353625
  85.6004002   -2.68514014   2.24796682   7.59681308  19.76563624
  -2.98578782  -0.76564864  11.73022472   7.15619331  41.24150169
   1.43774668   1.330698    -2.31309212  -0.8147853   -2.74076983
   8.95008028   1.83112159   4.65487333   4.0775917   27.29799281]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2422.23785131091
gradient value of function right now is: [ 2.16409749e+00  2.08249892e+00  6.23139302e-05  6.95226126e-05
 -2.16409749e+00 -2.08249892e+00 -6.23139302e-05 -6.95226126e-05
 -2.17758980e+00 -1.09920993e+00 -3.42176259e+00 -2.15717694e+00
 -3.51337948e+00  4.25136997e-07  1.14244246e+00  1.06120403e-02
  4.69984002e-04 -1.14356249e-03 -2.34951988e-03 -1.95874267e-03
  4.83708081e-04 -1.07425142e-03 -2.35401565e-03 -1.84056212e-03
 -8.22525947e-02  5.12014304e+00  1.93371418e+01 -1.02739910e+00
 -6.49290002e-02 -4.31024493e-12 -1.79581741e-03 -8.31994328e-03
  2.38154366e-01 -8.48931995e-03  6.38926345e-01  7.11165638e-01
 -1.23135598e-01 -9.29580177e-04 -2.58575822e-01 -1.08903402e-01
 -1.84478974e-01 -5.31358694e-01 -6.47261546e-03 -8.69488967e-02
  1.51225489e-01  1.41928139e-01  2.06468135e+01  3.48138010e+01
  9.68278281e-02  3.37855815e-01 -4.01510987e+00 -1.73349969e-01
 -1.21104582e-01 -5.46194969e-01 -1.40232351e-01 -7.02135985e+00
 -2.25161738e+00  2.26473832e+01 -2.51528576e+00  2.64356169e+01
  1.10329754e+01 -4.58725366e+01  3.46142263e+00 -4.29561520e+00
  2.25057497e+01]
supnorm grad right now is: 45.87253664054079
Weights right now are: 
[ -2.84103379   7.51488427 -40.49814463 -40.98577837   3.09560251
  -7.62357596  40.89708189  40.26974999  -2.4558005   -1.30177028
   7.64265618  -2.1614279    5.56737052  49.14540511   6.3134081
  30.96430033 109.10104281   6.15810398   8.62053703   9.81735796
 109.09730734   5.62122005   8.61107867  10.45030674   7.27747022
  -8.36657814   3.41243342  -7.48636453   4.07982886  19.89140955
 149.66329199  19.60595699  10.48982709  79.1397593    0.40024187
   5.94404363   2.8270652  173.38024061   8.50908465   6.69333796
  -5.71084535   3.2181132  -10.11489766  22.55098391  84.84307909
  88.51134316  -2.87787397   2.34186388   6.12033258  19.21445282
  -2.98661223  -0.69924175  12.26433186   7.27438615  41.78933611
   1.51046457   1.58559765  -2.51778772  -0.91493588  -2.79160398
   9.21775813   1.74063389   5.17657064   3.62156112  27.37467886]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2424.864310139452
gradient value of function right now is: [ 4.37118582e-01 -3.30831270e-01  9.89533860e-04  9.77141520e-04
 -4.37118582e-01  3.30831270e-01 -9.89533860e-04 -9.77141520e-04
  1.73211011e+00  9.88140355e-01  2.57240957e+00  1.68547333e+00
  6.94707652e-01 -8.12219403e-05 -1.36858865e+00 -1.33260674e-02
  4.38356283e-03  9.94419350e-04  1.07433435e-02  3.20680798e-03
  4.35445680e-03  9.40750382e-04  1.07839956e-02  3.03619011e-03
  2.91015219e-02 -1.38541025e+00 -4.99016149e+00  2.14871855e-01
  3.78045933e-02  1.22740639e-13  5.34221402e-04  3.19508812e-03
 -2.57481375e-01  9.08813795e-03  5.06566357e-01 -1.83916454e-01
  1.30548221e-01  5.46208879e-04  3.02292954e-01  3.87837614e-02
  3.32057297e-01  6.74537694e-01  1.56193246e-02  5.59584008e-02
 -6.73204247e-02 -8.33638858e-02 -7.46486191e+00 -1.04712460e+01
 -9.67302835e-02 -2.08775239e-01  6.43550027e-01 -1.94653019e+00
  3.40920225e-02  1.46511241e-01  3.67194495e-02  1.52692316e+00
  1.76562817e+00 -1.02691765e+01  2.02422680e+00 -1.63195199e+01
 -3.29099405e+00  1.40078689e+01 -1.02581717e+00  7.33288514e-01
 -1.32914893e+01]
supnorm grad right now is: 16.31951986865513
Weights right now are: 
[ -2.93934473   7.43672487 -45.60078849 -46.20216409   3.19391344
  -7.54541656  45.99972575  45.4861357   -2.43910194  -0.9215715
   7.54765778  -2.40823796   5.93249187  51.40156454   5.74984035
  31.35432147 108.43370253   6.70988927   6.67148057  10.83119309
 108.3727458    6.18322774   6.66474534  11.46773732   7.45064359
  -8.60234339   3.34717633  -7.29259582   7.12495508  19.89140927
 162.25738952  21.8638744    9.6452027   77.65895673   0.80550906
   5.22464245   4.32146824 182.23284986   8.10667187   6.27772855
  -5.52838135   3.39466144  -9.61423668  24.45636399  88.73568035
  91.94306498  -2.89491263   2.4481616    5.88134319  19.09628179
  -2.3735085   -0.85034578  12.01118407   7.12362416  42.02532721
   1.42562735   1.50746968  -2.48034973  -0.7400637   -2.62165713
   9.07735403   1.94007615   5.10038151   4.15326662  27.10783294]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2420.8381601235947
gradient value of function right now is: [-4.36715742e+00 -1.94888088e+00 -4.33024515e-04 -4.37354991e-04
  4.36715742e+00  1.94888088e+00  4.33024515e-04  4.37354991e-04
 -1.75851257e+00 -1.10593516e-01 -5.27214862e-02 -7.99205183e-02
  3.28095413e+00 -4.23215578e-06  3.20677753e-01 -9.35326402e-04
 -2.69143845e-03  1.72138595e-05 -7.03910222e-03  2.66385948e-04
 -2.72154713e-03  1.60440655e-05 -7.10897167e-03  2.47884119e-04
 -4.86855816e-03 -2.72398540e+00 -1.62690079e+01 -6.95763024e-02
 -5.58290778e-04  1.71225691e-14 -1.76433887e-04  3.32829416e-04
  1.04441298e-03 -3.83227496e-03 -7.26220891e-01 -5.29108463e-02
 -2.34721925e-03  9.46874950e-06  2.24986058e-02  1.00091578e-02
 -7.88369690e-03  2.99965673e-03 -8.18363470e-03 -6.32941942e-03
 -9.20655469e-02 -1.06580975e-01 -9.91506241e+00 -1.92747897e+01
  4.06970979e-02  3.54584310e-02  3.03366601e+00  8.19582486e+00
  1.02177826e-02  2.20428821e-02 -1.04495535e-02 -4.28212856e-01
  2.13168035e+00 -1.47588850e+01  2.90217010e+00 -1.71638974e+01
 -2.13045519e+00  1.19442729e+01 -1.71629805e-02 -1.48879819e-01
 -6.94752959e-01]
supnorm grad right now is: 19.274789701330146
Weights right now are: 
[ -2.95040864   7.28612741 -48.11104954 -48.82917035   3.20497735
  -7.3948191   48.5099868   48.11314197  -2.53804638  -0.89322321
   7.37349554  -2.23075823   6.12162075  53.03732289   5.89664516
  31.24176427 109.22727818   9.61947984   7.30294715  13.9147881
 109.14484871   9.05917452   7.29540771  14.50976637   7.58289238
  -8.60343952   3.31139433  -7.43269648   8.84887334  19.89140926
 175.04688575  22.80236198   8.70641239  82.21152104   0.4475019
   3.98074804   3.54653031 190.37178269   7.97792511   5.61847107
  -7.56815371   1.99618745 -13.02655601  23.00867528  92.85833692
  95.45160018  -2.9444677    2.23271981   7.30055027  19.74990039
  -2.71279532  -0.65414838  10.32335671   7.02471716  42.51502572
   1.68904985   1.41745422  -2.58471418  -0.22124449  -2.74508443
   8.97895578   1.91060686   5.40220726   4.30310019  27.46972421]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2423.9335895394715
gradient value of function right now is: [ 2.69763644e+00  1.05145278e+00  9.00509534e-04  9.08899168e-04
 -2.69763644e+00 -1.05145278e+00 -9.00509534e-04 -9.08899168e-04
  2.28728034e+00  6.06609060e-01  1.85965850e+00  1.03865655e+00
 -1.51810313e+00  4.33567171e-06 -1.29790209e+00 -1.03883195e-02
  4.74265409e-03 -1.44272290e-04  1.43291295e-02 -5.21841519e-04
  4.79316096e-03 -1.35022842e-04  1.45099491e-02 -4.86376078e-04
  1.87207628e-02  8.79855809e-01  6.45148013e+00  1.61731917e-01
  2.97952208e-03  5.63263758e-15  2.22638935e-04  2.90989617e-04
 -3.74485992e-02  1.26163322e-02  1.13683024e+00 -1.86235001e-01
  1.38949095e-02  5.17385428e-04  2.74363608e-01  3.05459894e-02
  3.60951778e-02  3.84201847e-02  1.88556848e-02  4.57020765e-02
  1.58894772e-02  1.41431040e-02  3.01762593e+00  4.94342918e+00
 -1.05433776e-01 -1.28780061e-01 -1.36490662e+00 -4.42634379e+00
  3.11923291e-02  5.66751816e-02  2.70429375e-02  8.88714373e-01
 -2.53428591e-01  3.00034942e+00  2.50057428e-01  1.16103642e+00
 -6.19686729e-01  5.77036384e-01 -5.91517987e-01  8.66987538e-01
 -6.89621045e+00]
supnorm grad right now is: 6.896210448166529
Weights right now are: 
[ -2.65971876   7.30980707 -49.41269234 -50.12049794   2.91428747
  -7.41849876  49.81162961  49.40446955  -2.05785656  -0.46241785
   7.38671973  -2.33721443   5.94818654  54.80508321   5.37735781
  33.08269431 112.76683192  12.30019626   7.34779244  13.28381229
 112.76641109  11.80449168   7.30704244  13.9107504    9.38377334
  -8.45499891   3.33492824  -7.16847642   8.07411623  19.89140927
 185.21183683  25.12622908   9.39255566  83.93785386   0.66863424
   2.77415853   4.51845921 199.85992644   7.38640497   6.18583123
  -5.92631482   1.60735458 -14.11223532  24.17500575  96.50821132
  98.78644126  -2.9261641    2.33627335   8.769597    20.53504006
  -2.65072229  -0.91779154  10.76268361   8.14753757  43.1479528
   1.36443367   0.61585314  -2.52643246  -0.41107146  -2.67624086
   9.26471634   1.9502313    5.821829     3.86984725  27.03759157]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2423.6724217942674
gradient value of function right now is: [-1.18206457e+00 -5.57838257e-01  4.96922359e-04  4.94140275e-04
  1.18206457e+00  5.57838257e-01 -4.96922359e-04 -4.94140275e-04
  3.61552961e-01 -3.10514236e-02  1.64738823e+00  4.39802043e-01
  1.23082098e+00 -1.39533237e-07 -1.35956697e+00 -1.57444126e-02
  2.73061060e-03 -6.19529879e-05  6.87540467e-03  2.61879602e-04
  2.73581081e-03 -5.96537470e-05  6.89781544e-03  2.56891249e-04
 -8.47045798e-03 -1.84959856e+00 -7.37749922e+00  1.91656801e-01
  9.94417699e-04  4.01368713e-15  2.52963358e-04  5.05085298e-04
 -1.61740131e-02  7.81768324e-03  2.22206186e-01 -1.92876585e-01
  3.72111460e-02  4.14686169e-04  2.77285531e-01  4.03759331e-02
 -7.05302316e-03 -6.46140124e-03  1.83669435e-02  2.21584651e-02
 -8.62860570e-02 -6.68919845e-02 -8.13915209e+00 -1.35322608e+01
 -1.46981877e-01 -1.65298946e-01  9.97518162e-01 -3.60229596e-02
  5.29902971e-02  6.94987488e-02  2.90961944e-02  1.27439118e+00
  2.05598480e+00 -1.64451047e+01  2.64562254e+00 -1.53961133e+01
 -3.36353516e+00  1.44425388e+01 -6.02954858e-01  1.01202540e+00
 -1.35788868e+01]
supnorm grad right now is: 16.44510466376284
Weights right now are: 
[ -2.79011574   7.37965618 -51.02906855 -51.94742019   3.04468445
  -7.48834787  51.42800581  51.2313918   -2.6073644   -1.58636544
   7.45865767  -2.09644435   6.07571582  58.31110509   5.30821387
  31.19636337 114.59392392  13.88601005   6.44179546  14.6778806
 114.59261899  13.36810085   6.45652651  15.27710518  10.26667285
  -8.44965076   3.32638993  -6.9000559    8.49087154  19.89140927
 193.91220916  26.73153868   9.32012338  87.7975234    0.41487844
   4.28425499   5.74935061 206.44747494   8.53375844   3.69393787
  -8.20853035  -0.96648841 -16.73908376  22.29100194 101.02730149
 102.79885912  -2.87168417   2.23483808   8.57644508  20.73941843
  -2.55866423  -0.7789877    9.45914534   6.68947162  42.51953495
   1.68447596   0.46855294  -2.48457346  -0.32170455  -2.72812726
   9.50639735   1.98342972   6.49420323   4.37585318  26.881864  ]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.616829067035
gradient value of function right now is: [-2.36593746e-02 -2.87189497e-01  2.15464028e-05  2.64134657e-05
  2.36593746e-02  2.87189497e-01 -2.15464029e-05 -2.64134657e-05
  6.35464355e-01  4.71495589e-01  5.65194748e-01  8.02445418e-01
  2.91084494e-01  4.18748974e-05  3.12618975e-01  1.86263565e-03
  2.11708483e-04 -1.28744617e-04  6.65019758e-04 -9.13611188e-04
  2.26015356e-04 -1.22563085e-04  6.82807706e-04 -8.70540514e-04
  1.76280351e-02  5.56280764e-01 -6.68113722e-01 -2.74947791e-01
  2.45184234e-03 -2.65764468e-17  4.54076503e-04  4.69353346e-04
 -2.55893460e-04 -2.59005158e-03  2.95196913e-02  5.37812248e-02
  4.53901257e-03 -1.82795418e-04 -1.51607563e-02  1.58917225e-05
 -1.00427146e-03 -1.73246436e-02  8.97426965e-03  1.66205354e-02
  1.05668051e-02  1.12285543e-02  3.00437216e+00  3.55130869e+00
 -2.56805533e-02 -1.71684971e-02 -4.69357488e-01  3.00820530e+00
 -4.01756135e-03 -1.49184575e-02 -3.99071288e-02 -1.90167710e+00
 -1.50622841e-01  2.27487059e+00 -9.30289679e-02  3.02049263e+00
  2.60066610e+00 -9.05731801e+00  1.33749844e-01 -2.83459404e-01
  1.68282510e-01]
supnorm grad right now is: 9.05731800795398
Weights right now are: 
[ -2.55148674   7.16958069 -51.08181711 -52.21850848   2.80605545
  -7.27827238  51.48075438  51.5024801   -2.38384647  -0.97506754
   7.47947239  -1.91015545   6.39399983  54.58796536   6.18584218
  32.90311492 116.30053027  20.57834721   9.0122598   21.16126963
 116.22823007  20.09745419   8.99648684  21.76269551   7.40301437
  -8.26071257   3.33612021  -7.35202401   7.79945537  19.89140927
 206.140055    16.12113809   8.17252756  90.84523797   0.72638032
   3.12191923   3.90224377 214.03897679   9.1271821    4.22812048
  -5.67639692   1.66742141 -14.1462765   24.93888989 104.36496745
 105.57562355  -2.94833941   2.49894133   6.46891434  19.33552219
  -2.7075506   -0.68856059   9.92648868   7.78239072  44.4560222
   1.43185227   0.65042205  -2.68661891  -0.42476773  -2.68686969
   9.34084366   1.86836653   6.00176932   4.69578662  27.10701798]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2420.542540451618
gradient value of function right now is: [-2.71228283e+00 -1.71283442e+00  4.85022316e-05  4.31228109e-05
  2.71228283e+00  1.71283442e+00 -4.85022316e-05 -4.31228109e-05
  7.38934530e-01  5.60029872e-01  2.14856315e+00  1.53609900e+00
  2.79520349e+00 -1.63871704e-05  8.02582230e-02 -3.16131195e-03
 -1.85642474e-05  4.72973593e-05 -1.14844482e-04  8.38368481e-04
 -3.19034739e-05  4.39357235e-05 -1.48189439e-04  7.81040452e-04
  3.88816357e-02 -2.64474490e+00 -1.45891322e+01  2.23186165e-01
  1.54989005e-02  2.75270915e-15  7.04512946e-04  3.38413119e-03
 -1.96255096e-01 -4.26006531e-03 -1.40824432e+00 -4.03648922e-01
  5.41724405e-02  2.15929147e-04  1.30738804e-01  6.59001385e-02
  8.93912659e-02  1.32853274e-01  7.91787675e-03  3.91369002e-02
 -1.08609466e-01 -1.31881894e-01 -1.31462636e+01 -1.82978729e+01
 -3.67756754e-02 -8.95979904e-02  4.86022683e+00  5.74228099e+00
  8.82718672e-02  1.80107716e-01  2.17429036e-02  1.60000174e+00
  1.75328740e+00 -2.01083932e+01  2.82730828e+00 -2.51664727e+01
 -2.86733506e+00  1.39619082e+01 -1.23760435e+00  1.35776652e+00
 -1.19670820e+01]
supnorm grad right now is: 25.166472708460887
Weights right now are: 
[-2.83210695e+00  7.10798647e+00 -5.22337968e+01 -5.34574019e+01
  3.08667566e+00 -7.21667816e+00  5.26327341e+01  5.27413735e+01
 -2.51105230e+00 -1.30082202e+00  7.71126153e+00 -2.07935140e+00
  6.18208074e+00  5.66856041e+01  5.85516551e+00  3.63549602e+01
  1.18474557e+02  2.40746519e+01  6.36979071e+00  2.12723933e+01
  1.18463332e+02  2.37034866e+01  6.37495793e+00  2.19955365e+01
  9.27774456e+00 -8.44492870e+00  3.29852319e+00 -6.56915158e+00
  1.15812129e+01  1.98914093e+01  2.15963307e+02  1.65971748e+01
  6.67512525e+00  9.28203247e+01  2.49283193e-01  3.98402251e+00
  4.70606778e+00  2.25920203e+02  7.52898901e+00  4.03786382e+00
 -5.95763753e+00  5.92275588e-01 -1.41078132e+01  2.63051911e+01
  1.08037121e+02  1.08537941e+02 -2.99112078e+00  2.33130240e+00
  8.24621856e+00  2.07184862e+01 -1.88533742e+00 -6.79433589e-01
  9.12971314e+00  7.34646527e+00  4.41131727e+01  1.71873133e+00
  1.87101924e-01 -2.73601014e+00 -7.68817360e-01 -2.71191521e+00
  9.38020194e+00  1.99496352e+00  6.15129248e+00  4.59039501e+00
  2.70456414e+01]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2424.585815263446
gradient value of function right now is: [ 1.88204038e+00  7.31352649e-01  8.92616434e-04  8.87076159e-04
 -1.88204038e+00 -7.31352649e-01 -8.92616434e-04 -8.87076159e-04
  1.17938417e+00  2.15715313e-01  1.04399018e+00  4.61014590e-01
 -9.63053139e-01 -7.70393843e-05 -1.07313423e+00 -1.09672527e-02
  3.84518949e-03  2.81648638e-04  9.28550586e-03  2.41036265e-03
  3.93548729e-03  2.64306101e-04  9.60987922e-03  2.26802776e-03
 -1.83320589e-02  1.48174411e-01  3.65976287e+00  2.60844175e-01
  7.37357152e-03  2.85251133e-15  3.84527001e-05  1.58632375e-03
 -5.47794176e-02  8.21207728e-03  6.22463268e-01 -1.44666962e-01
  3.11481971e-02  1.04479590e-03  2.83029668e-01  3.35577378e-02
  5.55176746e-02  9.90977458e-02  3.51447451e-03  1.30764349e-02
 -5.56375816e-03 -5.58125011e-03 -2.69691414e-01  2.89578104e-01
 -3.09849719e-02 -1.19862308e-01 -7.75635824e-01 -4.90454334e+00
  6.67626410e-03  7.52355711e-02  2.89553823e-02  1.56170385e+00
  2.68489167e-01 -8.76063857e-01  6.73496736e-01 -3.06943353e+00
 -1.60345161e+00  5.03055226e+00 -4.12229262e-01  5.68159046e-01
 -7.15582115e+00]
supnorm grad right now is: 7.155821150022286
Weights right now are: 
[ -2.73933156   7.34340828 -51.15401414 -52.61033928   2.99390028
  -7.45209997  51.55295141  51.89431089  -2.36223612  -1.20740209
   7.60436374  -2.42725898   6.15741594  54.13328642   5.36791505
  36.33666823 120.7783233   31.09355438   7.84916847  25.92523669
 120.61164345  30.72662607   7.80038965  26.68800124   5.92172854
  -8.53428784   3.46237598  -5.80121629   6.26707766  19.89140927
 227.66800389  16.30362764   8.49272068  92.08906879   0.69236367
   4.20717643   2.98211177 236.97425296   6.99037052   3.51163656
  -6.21949051   1.64344698 -16.43223636  25.57474923 111.8993273
 111.65769719  -2.95230337   2.43724559   7.93916594  20.96432945
  -2.47474039  -0.7718897    8.38466128   6.98298843  44.43817834
   1.61274551   1.76189731  -2.71128176  -1.18069918  -2.68239948
   9.14817526   2.04256921   5.82860979   4.49765216  27.04181463]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2424.987349960428
gradient value of function right now is: [-2.28648874e+00 -1.12317425e+00  3.15154831e-04  3.17350853e-04
  2.28648874e+00  1.12317425e+00 -3.15154831e-04 -3.17350853e-04
 -8.66797668e-01  3.61182727e-02  2.49605622e-01  7.90977966e-02
  1.58080940e+00 -5.52098938e-06 -4.32208843e-01 -3.43042203e-03
  1.50355922e-03  8.47909688e-06  4.90164894e-03  2.56446885e-04
  1.54665227e-03  7.95968219e-06  5.06979596e-03  2.41760558e-04
 -1.07484709e-02 -1.36542620e+00 -8.81943668e+00 -2.70243849e-01
 -2.79479898e-04  3.91580484e-16  7.12826522e-06  4.40351836e-04
  5.07203289e-03  3.64307298e-03  5.41945720e-01  9.88590331e-02
 -6.40540998e-03  6.75900407e-05  8.63732110e-02 -7.44912531e-03
  3.09772708e-03  1.13519712e-02  5.10108514e-04  3.56554569e-03
 -7.00559117e-02 -7.53447424e-02 -7.51986479e+00 -9.81599094e+00
 -3.52027452e-03 -1.27185307e-03  1.31264581e+00  2.96259004e+00
 -6.25417204e-03 -2.76163940e-02 -2.51940770e-02 -1.18573790e+00
  1.27983653e+00 -1.37342469e+01  1.71721918e+00 -1.45943440e+01
  3.03533882e-01  3.17799442e+00  3.16322404e-01 -8.57225970e-01
 -3.53530756e+00]
supnorm grad right now is: 14.594343982959504
Weights right now are: 
[ -2.90021953   7.0237134  -52.54739381 -54.07746582   3.15478824
  -7.13240509  52.94633107  53.36143743  -2.24662718  -1.011814
   7.70577541  -2.59203656   6.0993132   54.55072257   5.36971257
  36.6195694  122.67476491  34.44662454   5.99994446  24.82385815
 122.46401465  34.13730723   5.97520442  25.68990406   6.12653348
  -8.33078716   3.4258146   -5.30288965   9.23592641  19.89140927
 232.65456109  16.28807259   6.98214751  96.67760352   0.52808812
   3.61817989   3.56148061 247.60681762   7.66902387   4.47424937
  -8.70035423   1.50604601 -17.50690021  24.92865472 115.61925142
 114.20275594  -2.91440637   2.4315407    9.25894939  22.34894623
  -2.31166343  -0.84548073  10.92568537   8.37703034  43.71027764
   0.97564869   0.82735913  -2.73955602  -1.18247462  -2.89012336
   9.33286358   1.85104421   5.68597128   3.55908012  27.175     ]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.273739961664
gradient value of function right now is: [ 4.11789192e-02  4.05737568e-02 -5.87772740e-04 -5.87747761e-04
 -4.11789192e-02 -4.05737568e-02  5.87772740e-04  5.87747761e-04
 -7.07482005e-01 -3.58263696e-01 -1.09774076e+00 -8.22866738e-01
 -5.45766472e-01  2.94358430e-04  1.71691631e-02  3.30800561e-03
 -3.25725968e-03 -1.92379064e-04 -3.50933155e-04 -8.39343607e-04
 -3.35524460e-03 -1.88051384e-04 -3.40435802e-04 -8.20928650e-04
  1.72513919e-02  9.20486629e-01  3.87165461e+00  3.75965309e-02
 -9.68936566e-03 -4.77518453e-16 -4.41334487e-04 -9.84734890e-04
  9.23382136e-02 -4.63187160e-03  4.18144393e-01  1.42499561e-01
 -3.17867176e-02 -3.94760156e-05 -6.58504117e-02 -2.77051190e-02
 -4.96122695e-02 -8.99746276e-02 -1.77344913e-02 -3.38938874e-02
  4.51389468e-02  4.34890975e-02  5.77600629e+00  6.54307944e+00
  3.14603585e-02  6.46803131e-02 -7.98051663e-01  1.98341754e-03
 -2.14508865e-02 -5.58287391e-02  1.53494788e-03  6.85949211e-02
 -9.52506153e-01  1.00979873e+01 -1.28488830e+00  1.01795952e+01
  5.37995626e-01 -3.62259298e+00  3.65229694e-01 -2.96983585e-01
  2.32636068e+00]
supnorm grad right now is: 10.179595207213849
Weights right now are: 
[ -2.86345591   6.95667206 -52.99371335 -54.74037491   3.11802462
  -7.06536375  53.39265061  54.02434652  -2.55242878  -1.13655348
   7.58304287  -2.34986661   6.37140801  56.86927509   5.73491587
  34.03653332 123.76590982  38.57074579   8.06978655  27.73511718
 123.54979591  38.28548134   8.05329373  28.6707491    6.19371341
  -8.36127345   3.3506596   -4.33395823   7.06380868  19.89140927
 243.1177723   16.25084654   6.07489887  98.43108942   0.98277548
   3.88879923   4.60533066 254.24030686   9.32561232   4.14895354
  -8.0027291    1.1625503  -17.68404592  24.33579578 119.91756663
 117.83461969  -2.92700444   2.51192166   8.17664308  22.14330103
  -2.32717164  -0.8655181   11.27910681   8.12699765  44.66619979
   1.31928868   0.86646934  -2.57990115  -0.68534844  -2.73127398
   9.39551266   1.97812729   5.99561615   4.31311944  26.99816434]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.690873320213
gradient value of function right now is: [-1.76536822e+00 -6.72474801e-01  3.12083982e-05  3.82677733e-05
  1.76536822e+00  6.72474801e-01 -3.12083983e-05 -3.82677733e-05
 -7.16917318e-01 -7.24433623e-02  8.27073138e-02 -9.55179760e-02
  1.28532411e+00  2.47195485e-05 -3.34176326e-01 -2.27550399e-03
  5.64115689e-04 -3.25690446e-04  1.54051043e-03 -8.45374187e-04
  5.88022192e-04 -3.10135268e-04  1.61476258e-03 -8.05491766e-04
  6.57971870e-03 -9.24972219e-01 -6.55217881e+00 -3.71131167e-01
  1.25700867e-02 -6.63444152e-17 -1.10836101e-04  1.16967552e-04
  1.93478518e-02  2.16010942e-03  3.43436245e-01  4.36709916e-03
  1.05140828e-02  1.23828598e-05  5.83603750e-02 -2.18240269e-04
 -2.56729522e-02 -4.51103094e-02  3.09933377e-04 -1.83120757e-03
 -3.26595372e-02 -3.96729302e-02 -3.50241668e+00 -6.77311292e+00
 -5.87377175e-03 -4.08116551e-03  4.25952114e-01  3.91174490e+00
 -1.98144073e-03 -7.21094386e-03 -2.94898875e-02 -1.33894319e+00
  6.70977284e-01 -6.78479534e+00  1.14322618e+00 -8.16144740e+00
  6.90717266e-01 -1.33985990e-03  2.20755507e-01 -3.81299488e-01
  5.08409695e-01]
supnorm grad right now is: 8.161447400842205
Weights right now are: 
[ -2.68168514   7.28482806 -53.79481801 -55.58002076   2.93625385
  -7.39351975  54.19375527  54.86399237  -2.56993651  -1.05337341
   8.03325593  -2.86458984   6.56343859  56.87077399   5.24003848
  37.95130354 126.89972872  40.8640446    7.32547152  27.83001648
 126.77874706  40.5604407    7.29661327  28.74113099   8.41900438
  -8.32523526   3.29922342  -4.35626041   5.5319152   19.89140927
 256.56913198  15.56794014   6.05298802 103.79325697   0.34125053
   3.51928033   3.86046346 266.42766609   8.81948869   2.54909831
  -6.68270534   1.35537404 -15.5115866   26.50050714 123.42424806
 120.92887429  -2.97547108   2.28542187   9.8815194   22.56644721
  -2.5307342   -0.77872593  12.34288039   8.80897431  43.58299677
   1.20934906   0.62745196  -2.81642131  -0.50096865  -2.83158555
   9.98385984   1.93803166   6.71954258   4.50922459  27.40819839]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2426.0760370868543
gradient value of function right now is: [-1.02738897e+00 -2.68393613e-01 -2.45092487e-04 -2.42410350e-04
  1.02738897e+00  2.68393613e-01  2.45092487e-04  2.42410350e-04
 -1.29940265e+00 -3.02915020e-01 -1.23756847e+00 -6.82631396e-01
  3.10019722e-01  3.22389530e-04  4.53472552e-01  2.53756261e-03
 -1.17860761e-03 -5.38201581e-04 -2.79221595e-04 -8.13601936e-04
 -1.21451812e-03 -5.35240786e-04 -2.83681997e-04 -8.09202802e-04
 -8.41456078e-03  3.39077505e-01 -7.59408935e-01 -3.02596571e-01
 -2.79230486e-03 -8.00540788e-16 -3.31350140e-04 -1.52260390e-03
  1.29636702e-01 -2.92929492e-03  3.09431421e-01  2.78707668e-01
 -3.24747976e-02 -7.06526191e-05 -6.15469608e-02 -3.48760915e-02
 -8.22483671e-02 -1.37281894e-01 -3.79274896e-03 -2.64064297e-02
  1.70667029e-02  1.69556484e-02  2.49507208e+00  2.58012255e+00
  4.92995575e-02  9.15830414e-02 -2.18871193e-01  3.03783303e+00
 -4.01213254e-02 -9.14923379e-02 -2.76697215e-02 -1.27928833e+00
 -4.85603820e-01  4.17056520e+00 -7.66065239e-01  5.48075284e+00
  1.77847413e+00 -5.67698080e+00  1.10669809e+00 -1.56768760e+00
  6.54530119e+00]
supnorm grad right now is: 6.545301187249396
Weights right now are: 
[ -2.83454414   7.33083837 -55.62226542 -57.61568123   3.08911285
  -7.43953006  56.02120268  56.89965285  -2.64147444  -1.1570457
   7.93309633  -2.10654865   6.96368795  56.4270178    5.65702409
  36.22733104 125.11484772  43.20654258   5.60505832  31.00689345
 124.91472072  42.87284661   5.58603116  31.90341022   6.4015505
  -8.28721486   3.31865101  -5.26002781   5.31201529  19.89140927
 262.07778345  12.42672621   6.91458527 104.19482484   0.64782115
   3.14756411   4.63839341 268.10583702  10.91756315   2.33192103
  -5.39819735   0.73207921 -18.26919282  26.60507079 127.18225879
 123.79050103  -3.07499825   2.53324225  10.44367622  23.40528138
  -2.62702617  -0.71122482  11.04395025   8.48549742  45.71279969
   1.38058485   0.35182593  -2.75815206  -0.8448278   -2.83941591
   9.63727743   2.04328956   6.07511982   3.68980979  27.31752383]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -2422.639679049221
gradient value of function right now is: [-2.74900990e+00 -1.16435314e+00 -3.68134996e-04 -3.72858837e-04
  2.74900990e+00  1.16435314e+00  3.68134996e-04  3.72858837e-04
 -1.48464217e+00 -4.67025921e-01 -9.51318197e-01 -7.59974298e-01
  1.47651856e+00 -1.59809155e-05  5.82037988e-01 -1.86742191e-05
 -2.55072911e-03  5.77128662e-05 -6.45216398e-03  5.97334372e-05
 -2.65130943e-03  5.73739036e-05 -6.70670211e-03  5.93545802e-05
 -1.72960945e-02 -1.42311956e+00 -8.95036625e+00  2.41971683e-02
 -9.37727563e-03 -1.46700955e-15 -4.03143207e-04 -3.50714307e-04
  4.23124121e-02 -4.43301236e-03 -9.50860254e-01 -5.31337314e-02
 -1.98906065e-02  5.04467320e-06 -8.27511248e-03  3.70005087e-03
 -2.08314331e-02 -1.91311119e-02 -7.29110813e-03 -1.40870884e-02
 -3.94274646e-02 -4.73072226e-02 -6.10229330e+00 -9.53103570e+00
  5.40963072e-02  6.00779228e-02  1.99384883e+00  3.03615010e+00
  2.31290325e-03  9.61785728e-03  6.31884039e-03  1.12804759e-01
  1.12236709e+00 -9.11755599e+00  1.42065305e+00 -1.02281280e+01
 -1.96088173e+00  9.09610836e+00  7.93005056e-02 -2.68084294e-01
 -1.08306785e+00]
supnorm grad right now is: 10.228127965917256
Weights right now are: 
[-2.76175194e+00  7.14092941e+00 -5.64369041e+01 -5.85190864e+01
  3.01632065e+00 -7.24962110e+00  5.68358414e+01  5.78030580e+01
 -2.68660817e+00 -1.02877436e+00  7.56323206e+00 -2.58658710e+00
  7.01512530e+00  5.81570868e+01  5.91466439e+00  3.84261588e+01
  1.25769076e+02  4.46075275e+01  6.22778277e+00  3.32957709e+01
  1.25597577e+02  4.42498417e+01  6.21783258e+00  3.41860932e+01
  6.77107108e+00 -8.53436891e+00  3.29503845e+00 -5.42598972e+00
  4.28644176e+00  1.98914093e+01  2.64882664e+02  1.18199560e+01
  6.65230308e+00  1.06846235e+02  4.69734719e-01  2.42059935e+00
  4.29662038e+00  2.73535408e+02  1.09084090e+01  3.35512372e+00
 -6.09257211e+00  1.38077961e-01 -1.70030908e+01  2.62191707e+01
  1.31057256e+02  1.26822157e+02 -3.07931830e+00  2.30434063e+00
  1.15867808e+01  2.52718613e+01 -2.39564232e+00 -9.34600442e-01
  1.20206028e+01  9.89064492e+00  4.66147984e+01  1.41595484e+00
  8.62037357e-01 -2.64412096e+00 -1.17811931e+00 -2.81559346e+00
  9.42845750e+00  2.10031459e+00  6.71855931e+00  3.62116719e+00
  2.71883477e+01]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.825578548293
gradient value of function right now is: [-6.72877644e-01 -5.36057421e-01 -2.86856526e-05 -2.83039815e-05
  6.72877644e-01  5.36057421e-01  2.86856526e-05  2.83039815e-05
  3.90730327e-01  1.34267096e-01  7.48884117e-01  4.62525205e-01
  7.28041843e-01 -5.98076928e-05 -1.56266498e-01 -2.00285589e-03
 -9.46555433e-05 -1.78121596e-04  2.42158526e-04 -1.35720192e-04
 -9.89630606e-05 -1.80909400e-04  2.54047676e-04 -1.38430224e-04
  3.98681475e-02 -5.35074636e-01 -4.04346851e+00 -1.29863976e-03
  1.80500802e-02  6.94974035e-16  2.56971327e-04  1.35453203e-03
 -9.61010938e-02  1.54168481e-04 -1.21837669e-01 -1.34292845e-01
  4.51661810e-02  5.83815126e-06  4.72351302e-02  2.59735555e-02
 -8.77468681e-03 -1.65557648e-02 -4.19995646e-03 -3.64694277e-04
 -7.80199857e-03 -9.03416566e-03 -1.17980348e+00 -4.03680433e+00
 -3.67484743e-02 -5.15677411e-02  4.16448413e-01  2.01108713e+00
  2.03415676e-02  4.15073960e-02 -1.71398790e-04 -3.11763704e-02
  4.20826155e-01 -2.02133533e+00  7.81301320e-01 -2.84152314e+00
 -7.36661145e-01  3.53792309e+00 -1.08760963e-01  1.27963612e-01
 -4.81825379e+00]
supnorm grad right now is: 4.818253790631938
Weights right now are: 
[ -2.77822607   7.2217573  -56.94608544 -59.08616232   3.03279478
  -7.33044899  57.34502271  58.37013393  -2.36201089  -1.31738927
   7.80661558  -2.22713177   6.98620417  60.82333542   5.96537963
  39.79499198 127.68148017  45.00618793   6.02132695  35.14544098
 127.55020361  44.64148147   6.02043528  36.03662017   7.62161499
  -8.5682757    3.24533927  -4.88829977   5.66741028  19.89140926
 276.86741113  11.76037449   5.33717622 107.3333178    0.74704358
   3.2332172    6.07552406 276.7487885   10.25803925   3.19889017
  -8.39827489  -0.47262143 -17.89615587  24.32822442 135.04193509
 130.01989543  -2.85885901   2.33060541  10.02863987  24.82055733
  -2.334054    -0.86349477  11.52777179   9.7842733   45.82161302
   1.1891674    0.54763156  -2.6405185   -0.81724718  -2.8829228
   9.60498484   1.94187107   7.08815404   4.34000157  27.03314919]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2421.3298115507832
gradient value of function right now is: [-7.04872430e-01 -7.25993414e-01  1.33610911e-03  1.33793658e-03
  7.04872430e-01  7.25993414e-01 -1.33610911e-03 -1.33793658e-03
  1.60554424e+00  1.05167141e+00  2.90852408e+00  1.86786300e+00
  1.70831925e+00 -8.16941435e-03 -1.14021267e+00 -1.19530982e-02
  4.98220117e-03  3.55861538e-03  8.21527382e-03  2.32770407e-03
  5.14308612e-03  3.65594882e-03  8.50209349e-03  2.39132262e-03
 -2.02366770e-01 -2.74139864e+00 -1.14023788e+01  2.78314680e-01
  1.53854422e-01  2.58378648e-14  9.74953778e-04  5.76019708e-03
 -6.46262363e-01  9.30061933e-03  3.84732033e-01 -3.88906860e-01
  1.09835355e-01  1.10604994e-04  1.32835446e-01  4.48175396e-02
  2.91084916e-01  5.72785335e-01  4.02199586e-02  1.10479242e-01
 -9.50497503e-02 -9.68558780e-02 -1.38150052e+01 -1.97868457e+01
 -9.33735228e-02 -1.70496815e-01  1.82843081e+00  1.04073661e+00
  4.63436850e-02  1.28824628e-01  2.73931117e-02  8.01030090e-01
  2.89158508e+00 -2.32574809e+01  3.17343368e+00 -2.49082126e+01
 -3.62829780e+00  1.87118776e+01 -1.40631528e+00  1.45263725e+00
 -1.87891943e+01]
supnorm grad right now is: 24.90821259375194
Weights right now are: 
[-2.55947525e+00  7.09554239e+00 -5.84978486e+01 -6.07498107e+01
  2.81404396e+00 -7.20423408e+00  5.88967859e+01  6.00337824e+01
 -2.48199421e+00 -1.38961737e+00  7.78495928e+00 -1.42474544e+00
  6.84237668e+00  5.73416582e+01  5.22947276e+00  3.60889943e+01
  1.26000474e+02  4.90007499e+01  5.32755406e+00  4.00340481e+01
  1.25864744e+02  4.85894748e+01  5.31477649e+00  4.09069699e+01
  5.56409527e+00 -8.53515525e+00  3.39160871e+00 -3.95834400e+00
  5.16512456e+00  1.98914093e+01  2.83394097e+02  1.16619496e+01
  5.35654484e+00  1.06633048e+02  8.18727438e-02  3.68375548e+00
  5.82957472e+00  2.86294723e+02  9.77700422e+00  4.63571711e+00
 -6.03704655e+00  6.43467407e-01 -1.68815257e+01  2.39328510e+01
  1.38521501e+02  1.32672294e+02 -2.92729147e+00  2.29978060e+00
  1.24286554e+01  2.69057261e+01 -2.31210769e+00 -9.91915428e-01
  1.26576686e+01  1.01710871e+01  4.73133297e+01  9.60430437e-01
  8.15362596e-01 -2.84700369e+00 -9.22213977e-01 -2.99097409e+00
  9.52319947e+00  1.85660407e+00  7.08194900e+00  3.98196744e+00
  2.70079683e+01]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2421.4914059687367
gradient value of function right now is: [ 1.56897096e+00  2.15249197e-01  8.33330391e-04  8.35742638e-04
 -1.56897096e+00 -2.15249197e-01 -8.33330391e-04 -8.35742638e-04
  2.62902923e+00  1.34010538e+00  2.98595519e+00  2.19642689e+00
 -1.50715894e-01 -1.48525584e-03 -1.58929527e+00 -1.20946121e-02
  3.70476494e-03  1.43743786e-03  1.00368340e-02  1.32033830e-03
  3.84190501e-03  1.46642230e-03  1.04511144e-02  1.34719114e-03
 -1.71085366e-02 -4.63974051e-01 -5.79129207e-01  1.32964010e-01
  1.55611966e-02  7.25173803e-16  7.99009028e-04  2.91114955e-03
 -3.52091312e-01  7.28574402e-03  1.43453110e+00 -2.42532720e-01
  6.11170213e-02  2.91336849e-04  3.23741756e-01  4.92054189e-02
  2.74722165e-01  4.55846733e-01  4.69377767e-02  1.22692487e-01
 -4.07827794e-02 -4.16533349e-02 -4.52501243e+00 -4.03693449e+00
 -1.22721253e-01 -1.75130293e-01 -6.81005491e-01 -3.41716614e+00
  3.14180925e-02  7.77178399e-02  1.42002807e-02  4.06677542e-01
  1.41950486e+00 -1.05250475e+01  1.85407576e+00 -1.26112975e+01
 -6.03428097e-01  3.99513743e+00 -1.21663315e+00  1.20159421e+00
 -1.48732727e+01]
supnorm grad right now is: 14.873272706918064
Weights right now are: 
[ -2.58210874   7.11166853 -57.74891308 -60.0160342    2.83667745
  -7.22036022  58.14785035  59.30000581  -2.0620247   -1.27612366
   8.31930594  -1.90757594   6.81698472  58.1629533    5.22639777
  41.42230725 130.68147775  50.01151506   5.60503949  42.01112194
 130.56069713  49.5606652    5.57608289  42.85291816   6.35007181
  -8.29226468   3.29321686  -3.53373697   5.13369501  19.89140925
 288.32287984  13.2646519    6.39038289 109.17129396   0.8753902
   3.04200504   5.30542492 292.27742943   8.30812784   1.27393525
  -4.80469866   0.63553004 -14.07975597  25.23076421 142.22008214
 136.03692009  -2.76331537   2.46030675  10.41726156  25.80686798
  -2.37677747  -1.12010439  13.10205667   9.0684512   46.52087827
   1.07774739   0.83886353  -2.83169797  -0.81116617  -2.97906153
   9.94997675   1.92484897   6.9522342    3.8387778   26.96166615]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2421.708836785322
gradient value of function right now is: [-2.67038609e+00 -7.88759213e-01 -8.14178148e-04 -8.04535038e-04
  2.67038609e+00  7.88759213e-01  8.14178148e-04  8.04535038e-04
 -2.74074159e+00 -6.93895245e-01 -3.05457797e+00 -1.62819391e+00
  1.04206091e+00  1.86661855e-04  1.73796459e+00  7.63408776e-03
 -4.25005831e-03 -1.01260722e-03 -1.01537179e-02 -1.94054654e-03
 -4.35967442e-03 -1.00847975e-03 -1.03572174e-02 -1.91794915e-03
 -8.31340485e-03  3.00306312e-02 -4.24145821e+00 -5.40438556e-01
  3.82648156e-03 -4.38535477e-17 -8.96347332e-04 -2.99276701e-04
  3.36488285e-01 -1.14148016e-02 -9.42272008e-01  4.13182158e-01
 -5.60514077e-02 -2.97883831e-04 -2.71866296e-01 -5.48468361e-02
 -1.34648734e-01 -1.81151289e-01 -1.74577853e-01 -2.25167766e-01
  4.18778619e-02  3.51702931e-02  3.88549746e+00  1.44314131e+00
  1.77478131e-01  2.12687896e-01  1.08200169e+00  6.54625274e+00
 -4.74346029e-02 -7.21631028e-02 -5.11893601e-02 -1.49267257e+00
 -8.67003903e-01  1.10037521e+01 -1.49850249e+00  1.18736411e+01
  2.00050002e+00 -5.84873571e+00  1.39047921e+00 -2.15597323e+00
  1.71696736e+01]
supnorm grad right now is: 17.169673634421358
Weights right now are: 
[-2.84298317e+00  7.32244266e+00 -6.10257856e+01 -6.33255291e+01
  3.09755188e+00 -7.43113435e+00  6.14247229e+01  6.26095008e+01
 -2.58547122e+00 -1.53604097e+00  7.81431096e+00 -2.73807404e+00
  7.04745654e+00  6.14528772e+01  5.79342726e+00  4.52628644e+01
  1.27962204e+02  4.95924041e+01  6.57927877e+00  4.01079973e+01
  1.27918754e+02  4.91509290e+01  6.59279639e+00  4.09863775e+01
  9.34640911e+00 -8.36792665e+00  3.21530284e+00 -3.74601363e+00
  5.65394239e+00  1.98914093e+01  2.97919920e+02  1.30664950e+01
  5.57811994e+00  1.11146328e+02  3.99921799e-01  2.90361835e+00
  5.36496056e+00  2.99555645e+02  8.72281733e+00  2.74119363e+00
 -6.46186950e+00 -1.35418953e-01 -1.79295591e+01  2.20965884e+01
  1.45673389e+02  1.38818107e+02 -2.93004786e+00  2.39315000e+00
  1.06539219e+01  2.55420135e+01 -2.52564247e+00 -8.08974919e-01
  1.41305549e+01  1.09377424e+01  4.51543879e+01  4.05237542e-01
  5.29716103e-02 -2.77609785e+00 -6.97366243e-01 -2.89460375e+00
  9.47708415e+00  2.12889133e+00  7.13686285e+00  3.87861083e+00
  2.73948287e+01]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.7991867250835
gradient value of function right now is: [-1.22332286e+00 -4.76673098e-01 -1.69943343e-04 -1.67939164e-04
  1.22332286e+00  4.76673098e-01  1.69943343e-04  1.67939164e-04
 -3.93655984e-01 -1.81093640e-01  1.33751713e-04 -7.28688453e-02
  7.11444819e-01  4.94836512e-04 -1.44390891e-01  5.56250183e-04
 -1.26004638e-07 -1.14258437e-03  4.85469777e-04 -8.77069340e-04
  3.71473010e-06 -1.16821445e-03  5.08498230e-04 -8.96401682e-04
  5.39914531e-03 -2.22766903e-01 -3.50779354e+00 -4.37553431e-01
  3.61161328e-02  9.01509409e-19 -6.09369832e-05 -3.04801983e-04
  1.31977151e-01  2.84873521e-03  3.35354929e-01  6.85022894e-02
 -1.01448632e-02 -3.50580776e-05  1.54417043e-02 -2.74244170e-03
 -9.06582173e-02 -1.37511500e-01 -1.36915103e-02 -2.72074043e-02
 -1.13984128e-02 -1.74507910e-02 -3.86226873e-01 -1.83226968e+00
 -1.83765516e-03  6.79203569e-03  9.21806278e-02  2.35461240e+00
 -4.66904791e-03 -1.22241199e-02 -2.24063432e-02 -7.87970871e-01
  5.23751252e-01 -2.70858703e+00  1.06288155e+00 -3.76830490e+00
  8.34224927e-01 -1.79591182e+00  1.22484584e+00 -2.57407040e+00
  2.15056995e+00]
supnorm grad right now is: 3.7683048970926794
Weights right now are: 
[-2.52721266e+00  7.19846907e+00 -5.80823407e+01 -6.04301500e+01
  2.78178137e+00 -7.30716076e+00  5.84812780e+01  5.97141216e+01
 -2.45647770e+00 -1.50801462e+00  7.84946894e+00 -2.18744982e+00
  7.00281885e+00  5.71108187e+01  5.49038332e+00  4.36130911e+01
  1.30780679e+02  5.28802134e+01  7.77850204e+00  4.42259186e+01
  1.30731939e+02  5.24060080e+01  7.75684106e+00  4.50991028e+01
  6.61585043e+00 -8.19355461e+00  3.26501948e+00 -3.22754930e+00
  4.34957843e+00  1.98914093e+01  3.07316936e+02  1.28472366e+01
  6.14103941e+00  1.14189237e+02  6.03583685e-01  2.13922235e+00
  4.77261128e+00  3.05669732e+02  9.92939286e+00  3.08962900e+00
 -5.13544463e+00  1.55889365e-01 -1.67480759e+01  2.27851840e+01
  1.49499831e+02  1.41876881e+02 -2.85495120e+00  2.44075495e+00
  9.68015596e+00  2.47429317e+01 -2.16325845e+00 -9.74911544e-01
  1.46420608e+01  1.13249630e+01  4.55450067e+01  1.11470559e+00
  5.37263273e-01 -2.87042001e+00 -6.57771543e-01 -2.94099776e+00
  9.56685113e+00  1.93766247e+00  7.10974728e+00  3.51945942e+00
  2.72929971e+01]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2424.829962764405
gradient value of function right now is: [-7.66577146e-01 -7.38706779e-01  3.37533927e-04  3.35000097e-04
  7.66577146e-01  7.38706779e-01 -3.37533927e-04 -3.35000097e-04
  7.24509674e-01  2.83151060e-01  1.32879093e+00  8.62028921e-01
  9.54626703e-01 -1.56085251e-03 -2.79622115e-01 -3.62832985e-03
  6.66417845e-04  1.12146392e-03  4.65283170e-04  1.03436326e-03
  6.82526698e-04  1.14800252e-03  4.68802376e-04  1.05881412e-03
 -7.79202375e-02 -1.45328894e+00 -6.39633218e+00  3.10402901e-01
 -6.81016401e-03  6.18236027e-16  3.47173748e-04  5.20896749e-04
 -1.88907772e-01  2.59809323e-03 -4.22713577e-01 -2.62077445e-01
  3.62970529e-02  1.14012392e-04  9.30458654e-02  3.93995350e-02
  6.42917518e-02  1.50207555e-01  1.27607515e-01  1.87091733e-01
 -3.96583618e-02 -4.72789413e-02 -7.03215939e+00 -9.72639673e+00
 -3.78585308e-02 -8.56998432e-02  1.51271348e+00  2.12010413e-01
  1.88598894e-02  5.52930095e-02  2.40834411e-02  6.63486040e-01
  1.47831658e+00 -1.10000266e+01  2.10473485e+00 -1.38198766e+01
 -2.95298673e+00  1.24289012e+01 -1.15266670e+00  1.83509591e+00
 -1.00748923e+01]
supnorm grad right now is: 13.819876610233484
Weights right now are: 
[ -2.57012379   6.73616914 -55.45267226 -57.80828335   2.8246925
  -6.84486083  55.85160952  57.09225496  -2.42343108  -1.11824337
   8.07806782  -2.0139284    6.75217434  57.63741688   5.81035592
  46.75307198 135.40243158  54.41691058   6.86643839  46.95759073
 135.33786728  53.9355384    6.7943631   47.82705956   5.31745056
  -7.94342455   3.26035027  -2.86669391   4.51480858  19.89140925
 311.54009153  13.86935872   5.80216338 117.87071309   0.5371996
   2.6932206    4.6268104  308.93005333   9.91929721  -0.44485744
  -5.66585176  -0.3492763  -16.82211456  20.41394113 153.35450966
 144.82521447  -3.1047347    2.40360197  12.87926589  27.30276751
  -2.08166461  -1.03599916  15.78071032  12.66187365  48.27472922
   0.95632319   0.76267953  -2.8190503   -0.83953989  -2.88894558
   9.37583123   2.07165633   7.24155445   3.77786803  27.12190133]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2424.256952265727
gradient value of function right now is: [ 2.97745865e-01 -1.12655664e-01  6.02694112e-05  5.97437805e-05
 -2.97745865e-01  1.12655664e-01 -6.02694112e-05 -5.97437805e-05
  6.19179119e-01 -7.18424024e-02  8.50686252e-01  3.03143499e-01
  8.09741708e-02 -2.58573090e-04 -2.25161327e-01 -3.26006257e-03
  2.78104595e-04  5.99438012e-05 -1.13014603e-04  1.31101000e-04
  2.85943724e-04  5.99790621e-05 -1.28717556e-04  1.32833630e-04
  3.74018035e-02 -7.09731507e-01 -1.34803155e+00  5.15245016e-01
  2.50739345e-02  2.19501230e-16  2.99565971e-05  5.67401011e-04
 -2.15839740e-01  2.29078476e-03 -7.21466250e-01 -2.63707523e-01
  5.79740154e-02  1.81968481e-04  1.16443026e-01  4.90472655e-02
  1.21556767e-02  2.73362626e-02  7.10908576e-02  9.05454162e-02
 -1.99563137e-02 -2.08602332e-02 -3.86881652e+00 -4.77940738e+00
 -4.10671508e-02 -8.84852360e-02  7.45839359e-01 -2.29746409e+00
  3.26664543e-02  7.37669261e-02  2.44413103e-02  1.21831194e+00
  4.23511923e-01 -5.76725973e+00  1.25666059e+00 -7.73983712e+00
 -2.16670603e+00  8.22693940e+00 -8.66322034e-01  1.54461565e+00
 -9.47512161e+00]
supnorm grad right now is: 9.47512161336795
Weights right now are: 
[-2.59691023e+00  7.18568107e+00 -5.55379934e+01 -5.79243705e+01
  2.85147894e+00 -7.29437276e+00  5.59369306e+01  5.72083421e+01
 -2.88379182e+00 -1.60729835e+00  8.04079023e+00 -2.31750423e+00
  6.69521027e+00  6.12035291e+01  5.78688841e+00  4.95836410e+01
  1.34088197e+02  5.44749005e+01  6.09747211e+00  4.80815383e+01
  1.34003085e+02  5.39611130e+01  6.07623825e+00  4.89293666e+01
  7.22888205e+00 -7.94868344e+00  3.30781823e+00 -2.35132652e+00
  5.43920502e+00  1.98914093e+01  3.17650365e+02  1.51142893e+01
  4.97930811e+00  1.15912299e+02  3.24014967e-01  3.79288919e+00
  6.19706422e+00  3.12069321e+02  1.01879679e+01 -1.72575407e+00
 -6.72897344e+00 -1.06600676e+00 -1.60097053e+01  1.99871829e+01
  1.57207931e+02  1.48051778e+02 -3.18388883e+00  2.49298286e+00
  1.25032073e+01  2.73284996e+01 -2.19333143e+00 -8.86260373e-01
  1.75344671e+01  1.31881270e+01  4.89691138e+01  1.02973386e+00
  6.31774534e-02 -2.78089348e+00 -1.05105428e+00 -2.82447508e+00
  9.54306544e+00  2.07859866e+00  7.29951653e+00  4.24961842e+00
  2.68154900e+01]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2424.4942214903554
gradient value of function right now is: [ 2.31980252e+00  1.38576037e+00 -4.09991836e-04 -4.12119861e-04
 -2.31980252e+00 -1.38576037e+00  4.09991836e-04  4.12119861e-04
 -4.22212591e-01 -9.24222862e-01 -1.94967017e+00 -1.52998157e+00
 -2.20912269e+00  9.48761842e-04  6.19060123e-01  1.82967465e-03
 -4.97066516e-04 -1.86970479e-03 -2.04935178e-03 -1.08558051e-03
 -5.18155470e-04 -1.94284949e-03 -2.14057170e-03 -1.12805822e-03
  1.60885121e-02  2.29755713e+00  1.29131287e+01  4.71923963e-01
  4.83691171e-02 -5.86677016e-17 -6.98278339e-04 -1.17262915e-03
  3.11973020e-01 -2.09649798e-03 -6.91574573e-01 -2.19232384e-02
 -4.26690142e-02  1.90489840e-05 -5.86277499e-02 -3.73126937e-03
 -1.50631575e-01 -2.46885303e-01 -4.10247185e-02 -7.97841982e-02
  5.66060982e-02  7.03286619e-02  9.39808110e+00  1.49429543e+01
  5.78765707e-02  8.06243161e-02 -1.69385553e+00 -3.84541053e+00
 -2.45505379e-03 -1.20435657e-03  5.41413683e-03  7.73596825e-01
 -2.85715861e+00  1.75726515e+01 -3.73704565e+00  2.11082276e+01
  2.02337915e+00 -1.16150748e+01  2.54715341e-01  1.27908118e-01
  9.72532014e+00]
supnorm grad right now is: 21.108227552493357
Weights right now are: 
[-2.62178633e+00  7.12595154e+00 -5.37275649e+01 -5.61397725e+01
  2.87635504e+00 -7.23464323e+00  5.41265021e+01  5.54237441e+01
 -2.71588189e+00 -1.27162720e+00  7.79508839e+00 -2.45754864e+00
  6.62256986e+00  6.30128077e+01  5.92044217e+00  5.01927658e+01
  1.36603228e+02  5.57821118e+01  6.82891553e+00  5.06759542e+01
  1.36502013e+02  5.52305200e+01  6.81036257e+00  5.14966024e+01
  6.10795921e+00 -7.83258042e+00  3.29614499e+00 -2.12212088e+00
  4.29521071e+00  1.98914093e+01  3.26775075e+02  1.50376635e+01
  5.35583950e+00  1.20046799e+02  5.30858704e-01  2.56512705e+00
  5.07323283e+00  3.12760097e+02  1.14421832e+01 -8.14218584e-01
 -5.25176536e+00 -3.04346755e-01 -1.49768089e+01  2.05573275e+01
  1.60793432e+02  1.51094853e+02 -2.92248892e+00  2.24277020e+00
  1.34292928e+01  2.75484895e+01 -2.47685629e+00 -9.35979188e-01
  1.74375625e+01  1.37871275e+01  4.83317834e+01  9.51629240e-01
  1.20666148e-01 -2.85371158e+00 -1.07429453e+00 -2.91151698e+00
  9.91962206e+00  1.98991041e+00  6.75742155e+00  4.41955872e+00
  2.71536921e+01]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2421.2765492446383
gradient value of function right now is: [ 2.94429145e+00  2.15560286e+00 -1.47764598e-03 -1.48628540e-03
 -2.94429145e+00 -2.15560286e+00  1.47764598e-03  1.48628540e-03
 -1.15924066e+00 -5.37685610e-01 -3.46464903e+00 -1.74235927e+00
 -2.76167355e+00  3.45482806e-03  1.51751828e+00  7.87229229e-03
 -3.55897951e-03 -3.87113569e-03 -9.15894736e-03 -2.62750058e-03
 -3.71127213e-03 -4.03200572e-03 -9.55439900e-03 -2.73666808e-03
  1.13332605e-01  4.00777810e+00  1.96263202e+01 -7.78919839e-01
  1.13528814e-01 -3.55947099e-16 -3.23109322e-04 -5.98340080e-04
  1.13142101e+00 -6.61636392e-03  9.86925546e-02  6.41088235e-01
 -1.09234951e-01 -2.12974638e-04 -2.36281347e-01 -9.86682305e-02
 -3.38688515e-01 -7.17383239e-01 -1.10881365e-01 -2.31212682e-01
  9.05925043e-02  1.20993212e-01  1.89021977e+01  2.62739467e+01
  9.36717998e-02  2.19831948e-01 -2.90714155e+00 -7.61444650e-01
 -5.40994484e-02 -1.66990081e-01 -4.58228047e-02 -1.42829397e+00
 -4.06967878e+00  2.88730692e+01 -5.90357072e+00  3.97007864e+01
  6.13258490e+00 -2.70570060e+01  2.90402905e+00 -3.70710990e+00
  2.48850615e+01]
supnorm grad right now is: 39.700786418318
Weights right now are: 
[-2.75778057e+00  7.11128608e+00 -5.25249914e+01 -5.49811893e+01
  3.01234928e+00 -7.21997777e+00  5.29239286e+01  5.42651609e+01
 -2.56326955e+00 -5.27784860e-01  8.14721516e+00 -2.19562948e+00
  6.83644560e+00  6.49230488e+01  5.61858082e+00  5.42668293e+01
  1.36597909e+02  5.67429633e+01  5.66071346e+00  5.36127078e+01
  1.36479904e+02  5.61252562e+01  5.64345251e+00  5.43976981e+01
  6.19786920e+00 -7.77628642e+00  3.24358374e+00 -2.62346637e+00
  5.04916401e+00  1.98914093e+01  3.33465056e+02  2.08285120e+01
  4.35090980e+00  1.18777054e+02  7.78075137e-01  3.17233451e+00
  5.66824844e+00  3.14567301e+02  1.19086381e+01 -1.96502023e+00
 -5.96231329e+00 -7.68755216e-01 -1.44712691e+01  2.00750792e+01
  1.64918537e+02  1.53861557e+02 -2.88543138e+00  2.42501011e+00
  1.37780563e+01  2.86267568e+01 -2.36016598e+00 -1.12323368e+00
  1.76452591e+01  1.54101072e+01  4.89865296e+01  6.52659188e-01
  2.92879445e-01 -2.87793810e+00 -1.22099671e+00 -2.90023989e+00
  9.58498162e+00  2.07190601e+00  7.14332245e+00  3.47321798e+00
  2.72485718e+01]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2423.9995749033646
gradient value of function right now is: [-2.08838937e+00 -8.74432170e-01  1.81396806e-03  1.81826794e-03
  2.08838937e+00  8.74432170e-01 -1.81396806e-03 -1.81826794e-03
 -9.37834380e-01 -1.40708022e-01  2.43413459e-01 -9.94033895e-02
  1.44299035e+00 -3.25177450e-03 -7.53487095e-01 -3.45561166e-03
  3.76983564e-03  4.67448955e-03  1.04056133e-02  4.40785619e-03
  3.92945101e-03  4.85673870e-03  1.08647707e-02  4.57971374e-03
 -3.83186755e-01 -1.86946243e+00 -9.68443692e+00 -2.29950486e-01
 -2.29676591e-01 -3.49085519e-17 -4.87717225e-05  6.00687270e-05
 -1.61713335e-01  3.50252214e-03  9.80172659e-01  6.32152588e-02
 -2.28059175e-01 -7.29499767e-05  1.38869817e-02 -1.11395820e-02
  3.34287284e-01  7.26006502e-01  9.18683146e-03  1.25982962e-02
 -4.36525434e-02 -5.68705147e-02 -7.52698746e+00 -1.15733085e+01
 -1.81144829e-02 -1.95150997e-02  5.52193574e-01  1.72340239e+00
 -3.22649859e-03 -1.38083392e-02 -5.31120754e-03 -1.89144023e-01
  2.24394710e+00 -1.28118739e+01  2.37960449e+00 -1.61038855e+01
 -1.58674026e+00  9.48519093e+00  6.46703700e-01 -2.06098570e+00
 -3.79292554e+00]
supnorm grad right now is: 16.103885537769447
Weights right now are: 
[-2.77301637e+00  6.99762670e+00 -5.06518399e+01 -5.31388541e+01
  3.02758508e+00 -7.10631839e+00  5.10507771e+01  5.24228257e+01
 -2.82447185e+00 -1.55816079e+00  8.13860685e+00 -2.09715360e+00
  6.91698373e+00  6.51991869e+01  5.73401173e+00  5.62262285e+01
  1.37145066e+02  5.93677892e+01  4.46565656e+00  5.85946670e+01
  1.37024408e+02  5.86875702e+01  4.45531787e+00  5.93451475e+01
  5.48985880e+00 -7.66824961e+00  3.26046963e+00 -1.76719987e+00
  4.31951100e+00  1.98914093e+01  3.42714946e+02  2.10022491e+01
  4.69317703e+00  1.20755430e+02  8.10840057e-01  3.77935096e+00
  4.38077540e+00  3.16243095e+02  1.19523675e+01 -4.08501196e+00
 -3.82147554e+00 -2.25311665e-01 -1.28832920e+01  1.97759282e+01
  1.68792621e+02  1.56689326e+02 -3.00559913e+00  2.26614643e+00
  1.33466113e+01  2.92590124e+01 -2.77536374e+00 -1.17900445e+00
  1.90207512e+01  1.58320598e+01  5.07861613e+01  8.86830396e-01
  7.18383066e-01 -2.93943581e+00 -1.10320196e+00 -3.00014546e+00
  9.69803592e+00  2.06459923e+00  7.18860164e+00  3.29465947e+00
  2.74601759e+01]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2424.4504446290443
gradient value of function right now is: [-2.23522847e+00 -1.17365764e+00  1.53536363e-04  1.53836058e-04
  2.23522847e+00  1.17365764e+00 -1.53536363e-04 -1.53836058e-04
 -2.15028037e-01  3.23932533e-01  1.08441090e+00  7.69708797e-01
  2.08168403e+00 -3.30510458e-04 -1.80538899e-01 -9.97045968e-04
  4.27163297e-04  3.62622428e-04  6.63355074e-04  3.66671790e-04
  4.44908987e-04  3.76740739e-04  6.89195615e-04  3.80715263e-04
  6.29045676e-02 -2.32145758e+00 -1.22955479e+01 -3.16149775e-01
  2.34659281e-02  5.37785524e-17  2.20807234e-04  4.87546309e-04
 -3.90961792e-01  3.63442850e-03 -6.77760979e-02 -1.03189296e-01
  8.40615874e-02 -6.34418953e-06  4.27506785e-02  2.41803661e-02
  8.34727056e-02  1.34798664e-01  3.11539244e-02  7.19254574e-02
 -5.85124962e-02 -6.78340707e-02 -9.40922833e+00 -1.44963184e+01
 -2.01025437e-02 -3.86063388e-02  2.08648879e+00  4.16429449e+00
  1.66977651e-02  3.42509917e-02 -6.19107677e-03 -3.89748721e-01
  1.84577461e+00 -1.75011833e+01  2.44079689e+00 -1.91514318e+01
 -1.35624753e+00  9.72178285e+00 -2.48868805e-01 -2.78112982e-01
 -8.16482471e+00]
supnorm grad right now is: 19.151431799047163
Weights right now are: 
[-2.79063856e+00  7.39716170e+00 -5.04942851e+01 -5.29873507e+01
  3.04520727e+00 -7.50585340e+00  5.08932224e+01  5.22713223e+01
 -2.51196116e+00 -1.25866527e+00  7.96438173e+00 -2.18101379e+00
  6.80818209e+00  6.79981072e+01  6.23322804e+00  5.90111720e+01
  1.39656108e+02  5.90822542e+01  4.39749543e+00  5.89509227e+01
  1.39565565e+02  5.83761594e+01  4.38700329e+00  5.96913290e+01
  7.00441766e+00 -7.43408048e+00  3.26947690e+00 -2.24065112e+00
  5.53398200e+00  1.98914093e+01  3.54018661e+02  2.38290333e+01
  5.07687769e+00  1.23676675e+02  6.74546656e-01  3.30391125e+00
  5.63956011e+00  3.16451153e+02  1.28040820e+01 -2.76523989e+00
 -4.44713290e+00 -7.87331170e-01 -1.35651866e+01  1.98827120e+01
  1.72143042e+02  1.59293920e+02 -3.04571442e+00  2.25415441e+00
  1.37045928e+01  2.96641014e+01 -2.12723387e+00 -1.02095931e+00
  1.83564058e+01  1.58490175e+01  5.09627404e+01  2.65244652e-01
  4.33682030e-01 -2.93704755e+00 -6.82237656e-01 -2.96732258e+00
  1.01160381e+01  1.87094429e+00  6.91032057e+00  3.68538596e+00
  2.71521555e+01]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2422.9839091348276
gradient value of function right now is: [ 1.17766602e+00  1.48887027e-01  1.52333903e-03  1.56028094e-03
 -1.17766602e+00 -1.48887027e-01 -1.52333903e-03 -1.56028094e-03
  1.21418757e+00  2.25509579e-01  1.71906567e+00  6.03115960e-01
 -1.80464057e-01 -2.76023047e-03 -1.36170202e+00 -2.56115761e-03
  2.35000793e-03  5.78041382e-03  5.60299858e-03  1.28903857e-03
  2.48242450e-03  6.17295051e-03  5.90573233e-03  1.37727901e-03
 -1.30349195e-01 -8.45913864e-01 -5.37429869e-01  5.85610188e-01
 -3.06393376e-01  5.95979834e-17  9.42307375e-05  1.02052258e-03
 -4.99129968e-01  5.28277155e-03  6.27628162e-01 -3.59098686e-01
  3.25743148e-02  5.52460552e-05  9.32448214e-02  6.26238023e-02
  3.25938936e-01  7.29606774e-01  1.42913384e-03  3.93828093e-02
 -1.49022599e-02 -1.85844270e-02 -3.88457395e+00 -5.52006955e+00
 -7.71149041e-02 -1.59416112e-01 -6.99086793e-02 -3.41075248e+00
  2.41362091e-02  8.46130245e-02  3.01177797e-02  1.06288646e+00
  1.54143980e+00 -5.38233242e+00  2.25641613e+00 -9.81402933e+00
 -3.29209210e+00  1.21729471e+01 -1.27133385e+00  1.93876281e+00
 -1.46885801e+01]
supnorm grad right now is: 14.688580118779765
Weights right now are: 
[-2.64348753e+00  6.90096640e+00 -5.00830586e+01 -5.25807895e+01
  2.89805624e+00 -7.00965809e+00  5.04819958e+01  5.18647611e+01
 -2.62067041e+00 -1.26584055e+00  7.87497019e+00 -2.63908105e+00
  6.87426866e+00  6.66840859e+01  5.57638196e+00  5.57919043e+01
  1.41356216e+02  6.08618915e+01  5.91618212e+00  6.28142692e+01
  1.41269569e+02  6.01021958e+01  5.91618428e+00  6.35397503e+01
  6.18112132e+00 -7.21791198e+00  3.27806626e+00 -2.19991500e+00
  4.06456322e+00  1.98914093e+01  3.67934352e+02  3.16964999e+01
  5.31672772e+00  1.20860422e+02  6.80885781e-01  2.73717578e+00
  6.09848982e+00  3.19785393e+02  1.46984426e+01 -3.97598904e+00
 -3.81727993e+00 -3.12240428e-01 -1.30776360e+01  1.82752600e+01
  1.75977495e+02  1.62201767e+02 -2.97456002e+00  2.54388188e+00
  1.25017665e+01  3.01332074e+01 -2.51845669e+00 -8.77517955e-01
  1.55751423e+01  1.35426911e+01  5.19597067e+01  6.12690495e-01
  8.82173912e-01 -2.77015122e+00 -9.57814431e-01 -2.89523002e+00
  9.73747279e+00  2.25114085e+00  6.54224064e+00  3.62419724e+00
  2.68594074e+01]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2424.9983593103457
gradient value of function right now is: [-1.76239287e+00 -8.29881411e-01  9.57240277e-06  9.29360990e-06
  1.76239287e+00  8.29881411e-01 -9.57240264e-06 -9.29360977e-06
 -4.17865139e-01 -7.05944226e-02  3.48946446e-01  8.73124901e-02
  1.11177962e+00  2.19274794e-05 -3.10814808e-01 -4.85291736e-04
  2.50086216e-04 -1.38073500e-04  7.16996510e-04 -1.01586920e-04
  2.60694336e-04 -1.44886225e-04  7.49486200e-04 -1.06596914e-04
 -3.12304828e-02 -1.44217380e+00 -6.93244500e+00 -7.73557503e-02
  9.70613913e-04  9.28069719e-18  5.21807313e-05  1.16497624e-05
  6.63165598e-02  2.85164821e-03  1.96282698e-01 -1.15495773e-02
 -5.77759375e-03  6.98057174e-07  2.01097904e-02  3.03721419e-03
 -3.89837659e-02 -4.49869057e-02  1.01963401e-01  1.11846750e-01
 -3.12097965e-02 -4.30476159e-02 -6.13623582e+00 -8.67921036e+00
 -1.26587278e-02 -2.34132541e-02  1.00447189e+00  1.13039898e+00
  1.19749660e-03  1.81087760e-03  3.10184612e-03 -3.66476340e-02
  1.15839114e+00 -9.77816838e+00  1.93568631e+00 -1.30115382e+01
 -1.73943558e+00  8.85949445e+00  1.22588433e-01 -3.81078140e-01
 -3.61575874e+00]
supnorm grad right now is: 13.011538230436583
Weights right now are: 
[-2.67336016e+00  6.74001747e+00 -4.90702573e+01 -5.16131545e+01
  2.92792888e+00 -6.84870916e+00  4.94691945e+01  5.08971261e+01
 -2.38748623e+00 -1.14909942e+00  8.05335675e+00 -2.00188829e+00
  6.61772042e+00  6.84852268e+01  5.79020653e+00  5.97778388e+01
  1.42037081e+02  6.11456347e+01  5.09892361e+00  6.59177745e+01
  1.41938429e+02  6.02780596e+01  5.09981638e+00  6.65910081e+01
  5.62971135e+00 -7.35015594e+00  3.27771426e+00 -2.95191101e+00
  4.69676413e+00  1.98914093e+01  3.74352204e+02  3.32815780e+01
  5.56883381e+00  1.24490388e+02  7.39058339e-01  2.70802776e+00
  5.02107711e+00  3.19982252e+02  1.37963326e+01 -3.20044972e+00
 -5.00058911e+00 -1.09081836e+00 -1.26274836e+01  1.66318480e+01
  1.78993376e+02  1.64654893e+02 -3.08382730e+00  2.31077466e+00
  1.51507689e+01  3.17288438e+01 -2.24202660e+00 -1.13861699e+00
  1.68372778e+01  1.54176051e+01  5.46706533e+01  2.40041896e-01
  5.16606954e-01 -2.97334702e+00 -9.56294550e-01 -2.96811323e+00
  9.46271128e+00  2.04674962e+00  7.49891095e+00  3.49987273e+00
  2.72857593e+01]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2422.1749179123854
gradient value of function right now is: [ 6.43967665e-01 -3.82710066e-01  4.58514439e-03  4.71342225e-03
 -6.43967665e-01  3.82710066e-01 -4.58514439e-03 -4.71342225e-03
  1.27821466e+00  9.76434381e-01  2.53686697e+00  1.40520192e+00
  1.08630124e+00 -1.03408866e-02 -1.46472138e+00 -7.09846882e-03
  6.02975007e-03  1.63490940e-02  1.14018916e-02  5.46201241e-03
  6.44367355e-03  1.75170221e-02  1.21675016e-02  5.85314883e-03
 -7.94480062e-01 -2.46019785e+00 -7.69406727e+00  4.96210145e-01
 -8.14066708e-01  3.13193289e-16  3.10760178e-04  9.10999802e-04
 -1.37698425e+00  7.02531007e-03  8.86894073e-01 -3.51297104e-01
 -1.32678442e-01  9.25654537e-05  9.28165855e-02  6.67820215e-02
  1.46483229e+00  2.58487807e+00  1.02622564e-01  2.04370025e-01
 -5.87428989e-02 -5.82610392e-02 -1.09730929e+01 -1.47840403e+01
 -9.34227660e-02 -1.61147763e-01  7.84686976e-01 -7.24075976e-01
  2.59981232e-02  6.62698863e-02  2.02147770e-02  4.86968691e-01
  4.47389572e+00 -1.96732065e+01  3.25322228e+00 -2.15307846e+01
 -3.17444895e+00  1.59354103e+01 -1.65128961e+00  1.72431621e+00
 -1.99282219e+01]
supnorm grad right now is: 21.530784612456934
Weights right now are: 
[-2.52951256e+00  6.95655878e+00 -4.83589052e+01 -5.09280621e+01
  2.78408127e+00 -7.06525047e+00  4.87578425e+01  5.02120337e+01
 -2.47049633e+00 -1.07637331e+00  8.02438985e+00 -2.18993023e+00
  6.32151632e+00  7.09242371e+01  5.25294206e+00  5.96446452e+01
  1.43179129e+02  6.14725998e+01  4.48755404e+00  6.85644269e+01
  1.43061073e+02  6.05538307e+01  4.49030221e+00  6.91889755e+01
  5.71847856e+00 -7.35219119e+00  3.25497784e+00 -1.82750465e+00
  4.20019067e+00  1.98914092e+01  3.77569753e+02  3.02187879e+01
  5.02148829e+00  1.20924415e+02  3.50854910e-01  2.82243153e+00
  5.65649230e+00  3.23348957e+02  1.61558440e+01 -2.41029199e+00
 -3.50977589e+00  1.04636543e-01 -1.05877253e+01  1.64901329e+01
  1.82579338e+02  1.67450444e+02 -2.91205460e+00  2.19081855e+00
  1.58635523e+01  3.34020282e+01 -2.21482044e+00 -1.27526798e+00
  1.84322813e+01  1.54090255e+01  5.59839428e+01  4.15074717e-01
  5.02052056e-01 -2.95322731e+00 -9.80297551e-01 -3.08359898e+00
  9.64280389e+00  1.93328260e+00  6.84522668e+00  3.13262449e+00
  2.69927014e+01]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.8982483945515
gradient value of function right now is: [ 5.14840908e-01  3.83864150e-01 -4.05571510e-04 -4.13857670e-04
 -5.14840908e-01 -3.83864150e-01  4.05571510e-04  4.13857670e-04
 -3.51045226e-01 -5.64399132e-01 -8.23931230e-01 -7.31931033e-01
 -7.14397071e-01  4.73452848e-04  1.37340202e-01  8.80723888e-05
 -1.42873390e-03 -7.09516204e-04 -4.71119088e-03 -1.24962812e-04
 -1.50658195e-03 -7.70051585e-04 -4.93873743e-03 -1.35738708e-04
 -3.23075251e-02  7.48974237e-01  4.36772226e+00  1.36412411e-01
 -1.13704349e-02 -1.27919094e-16 -3.04108720e-04 -4.67359639e-04
  2.77174906e-01  2.75319904e-04 -2.97921374e-01  2.08227427e-02
 -4.48453512e-02  2.56128894e-06 -5.76525942e-03 -6.46287680e-03
 -8.48673315e-02 -1.51788312e-01 -1.41694178e-02 -4.47156810e-02
  1.66494257e-02  1.83473423e-02  2.87171031e+00  4.23112930e+00
  1.20404416e-02  1.90505213e-02 -4.38987149e-01 -1.67692343e+00
 -2.53015213e-03 -7.44467873e-03  8.53091390e-03  2.49191214e-01
 -7.15293420e-01  5.75268073e+00 -9.19179858e-01  5.84313505e+00
 -1.51939800e-01 -4.10721202e-01  2.36819684e-02  5.17065055e-01
  2.18615822e+00]
supnorm grad right now is: 5.843135053731059
Weights right now are: 
[-2.83641058e+00  6.89423110e+00 -4.81739962e+01 -5.07781260e+01
  3.09097929e+00 -7.00292279e+00  4.85729335e+01  5.00620976e+01
 -2.68810350e+00 -1.41478124e+00  8.14072857e+00 -2.13413661e+00
  6.47650401e+00  7.36021879e+01  5.79857918e+00  6.25836277e+01
  1.43164196e+02  6.09239778e+01  4.54543464e+00  7.09345621e+01
  1.43031027e+02  5.99277141e+01  4.55430106e+00  7.14906602e+01
  5.76487738e+00 -7.14384352e+00  3.36403915e+00 -2.22336458e+00
  4.18254681e+00  1.98914092e+01  3.88851127e+02  3.43173224e+01
  5.27331616e+00  1.20772045e+02  5.25002113e-01  2.47756177e+00
  6.57399073e+00  3.22053670e+02  1.59018259e+01 -4.23188575e+00
 -3.53395277e+00 -3.58098843e-01 -9.02173303e+00  1.58074323e+01
  1.86344559e+02  1.70051589e+02 -2.99937742e+00  2.30967859e+00
  1.60847925e+01  3.40210364e+01 -2.56851959e+00 -1.17563907e+00
  1.85850773e+01  1.60464064e+01  5.70920147e+01  5.74144286e-01
  5.30076154e-01 -2.85480394e+00 -1.17407868e+00 -3.00973167e+00
  9.81584450e+00  2.17748292e+00  6.80196513e+00  3.52326840e+00
  2.71580153e+01]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2417.741354086948
gradient value of function right now is: [-2.04838864e+00 -1.49252685e+00  7.25190589e-04  7.52578288e-04
  2.04838864e+00  1.49252685e+00 -7.25190589e-04 -7.52578288e-04
  6.18650154e-01  9.17718619e-01  2.03173608e+00  1.55063382e+00
  2.21660835e+00 -1.69725642e-03 -1.18516700e-01 -1.51417633e-03
  8.32852013e-04  2.53657417e-03  1.17596002e-03  8.26147397e-04
  9.04595858e-04  2.75249841e-03  1.27767935e-03  8.96936817e-04
 -7.55122286e-03 -2.59442813e+00 -1.30856008e+01  3.48195535e-01
 -6.18568302e-02  1.96660888e-16  2.63935677e-04  5.94758026e-04
 -7.06787775e-01  9.68690952e-05 -6.11100845e-01 -2.86563239e-01
  6.63692743e-02  4.91433774e-05  6.26080424e-02  4.04914680e-02
  3.07559783e-01  5.59049399e-01  1.60243565e-01  3.10524946e-01
 -5.87951987e-02 -8.14427466e-02 -1.07229578e+01 -1.54416411e+01
 -1.11240153e-02 -5.19107445e-02  3.44670329e+00  4.14102038e+00
  1.90071678e-02  6.74453756e-02  1.29206198e-02  6.25084442e-01
  2.17218026e+00 -1.97112958e+01  3.10475153e+00 -2.56744565e+01
 -2.53126962e+00  1.23373280e+01 -1.41875638e+00  1.70535422e+00
 -1.55246502e+01]
supnorm grad right now is: 25.674456508212096
Weights right now are: 
[-2.91222753e+00  6.91390237e+00 -4.65853784e+01 -4.92309977e+01
  3.16679624e+00 -7.02259406e+00  4.69843156e+01  4.85149693e+01
 -2.49809531e+00 -9.76294456e-01  8.13297666e+00 -1.73156754e+00
  6.45563177e+00  7.53542855e+01  6.23585094e+00  6.56266547e+01
  1.46283955e+02  6.14654708e+01  5.66895737e+00  7.61274792e+01
  1.46093941e+02  6.03772712e+01  5.67768159e+00  7.66040885e+01
  5.72425404e+00 -7.28700265e+00  3.22017056e+00 -1.74335839e+00
  4.24831177e+00  1.98914092e+01  4.02219053e+02  3.96359729e+01
  5.25501945e+00  1.24258181e+02  9.03307652e-01  3.05744741e+00
  5.76330313e+00  3.21694487e+02  1.40493529e+01 -4.25243093e+00
 -3.53689649e+00 -5.21778413e-01 -8.78527846e+00  1.41755134e+01
  1.89895343e+02  1.73061162e+02 -2.97360985e+00  2.00246628e+00
  1.56742602e+01  3.35437828e+01 -1.83584167e+00 -1.06033611e+00
  1.91769943e+01  1.76869355e+01  5.86502283e+01  6.36336060e-01
  3.76295479e-01 -2.91176512e+00 -1.24764502e+00 -2.88886581e+00
  1.00863115e+01  2.05574623e+00  6.84515650e+00  3.59585070e+00
  2.68570715e+01]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2425.313018223232
gradient value of function right now is: [-1.89359533e-01 -4.03571524e-01 -3.06037685e-05 -3.18499193e-05
  1.89359533e-01  4.03571524e-01  3.06037685e-05  3.18499193e-05
  8.76842195e-01  5.44609272e-01  1.27413728e+00  9.19464729e-01
  5.27660313e-01  1.03704035e-05 -2.16941134e-01 -8.94149737e-04
  6.70597683e-05 -1.32089133e-04 -3.66832315e-04 -6.76247218e-05
  6.98129215e-05 -1.41687628e-04 -3.90285813e-04 -7.27987091e-05
  6.59129977e-02 -1.09947471e+00 -3.84290753e+00  3.68156391e-01
  2.05478387e-02  4.13966241e-19  9.82681080e-05  5.68199071e-05
 -2.75508751e-01  3.02609240e-03 -2.33049105e-01 -1.24471389e-01
  7.18347540e-02  3.27126734e-05  3.73352611e-02  1.88828556e-02
  9.22698354e-02  1.09386921e-01  1.28688272e-01  2.53904383e-01
 -2.40103138e-02 -2.17822363e-02 -4.46768555e+00 -6.48517382e+00
 -4.03703903e-02 -5.35116207e-02  4.74308387e-01 -6.17988402e-01
  1.84810562e-02  2.89960927e-02  1.42932716e-02  5.07994439e-01
  8.85411847e-01 -8.51792679e+00  1.17392165e+00 -8.18768349e+00
 -1.98296948e+00  8.53992199e+00 -1.24442799e+00  2.10653300e+00
 -7.11060092e+00]
supnorm grad right now is: 8.539921993716554
Weights right now are: 
[-2.79859925e+00  6.99964985e+00 -4.64393033e+01 -4.91256154e+01
  3.05316796e+00 -7.10834154e+00  4.68382406e+01  4.84095870e+01
 -2.04067847e+00 -4.56274669e-01  8.35169794e+00 -1.84009929e+00
  6.49996154e+00  7.84097637e+01  6.25384191e+00  6.80669742e+01
  1.46790308e+02  6.08510857e+01  6.07723880e+00  7.69902698e+01
  1.46569202e+02  5.96722832e+01  6.07044317e+00  7.74142703e+01
  6.94606428e+00 -7.08592407e+00  3.17433084e+00 -1.86711514e+00
  5.38706447e+00  1.98914092e+01  4.08905120e+02  4.25255815e+01
  5.82655053e+00  1.25369019e+02  7.19735983e-01  3.79672593e+00
  5.96712947e+00  3.19609969e+02  1.56123219e+01 -5.59167309e+00
 -4.22527654e+00 -1.13465376e+00 -8.76688335e+00  1.38478891e+01
  1.93647198e+02  1.75924505e+02 -3.01510734e+00  2.09531580e+00
  1.46699248e+01  3.38029669e+01 -2.47886794e+00 -1.28169631e+00
  1.76721089e+01  1.60241807e+01  6.02239720e+01  6.35591585e-01
  1.10155001e-01 -2.95026363e+00 -7.28219233e-01 -3.07101140e+00
  9.61901487e+00  2.01471194e+00  6.38926982e+00  3.25443324e+00
  2.72373022e+01]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2426.5470462659305
gradient value of function right now is: [-2.79389440e-01 -2.61196538e-01 -8.89033905e-05 -9.20939021e-05
  2.79389440e-01  2.61196538e-01  8.89033905e-05  9.20939022e-05
  1.41251349e-01  5.03601799e-02  2.94278589e-01  1.65707847e-01
  2.41190947e-01  9.77128951e-05 -1.45979424e-01 -1.50376237e-04
 -2.05072637e-05 -2.69808320e-04  1.22140448e-04 -1.25314751e-04
 -2.45558741e-05 -2.90433528e-04  1.25408830e-04 -1.34869622e-04
  3.77975367e-02 -4.01104553e-01 -1.66714833e+00  8.15913299e-02
  2.15459549e-02  1.46213021e-17  3.35719694e-05  5.50973707e-05
 -5.21662232e-02  1.22991199e-03  4.26530329e-02 -5.22028616e-02
  2.67467828e-02  7.65653876e-06  1.15021218e-02  7.78393814e-03
 -2.28635968e-02 -3.13244481e-02  2.32548643e-02  4.20707272e-02
 -7.44785702e-03 -8.88207420e-03 -1.54069618e+00 -2.36614917e+00
 -9.78695791e-03 -1.99433384e-02  1.87473634e-01 -8.53164237e-02
  3.33479996e-03  1.01568968e-02  5.79681288e-03  1.51194934e-01
  2.36470674e-01 -2.54490344e+00  4.57819077e-01 -3.26831626e+00
 -8.39166877e-01  3.80661992e+00 -2.05818482e-01  4.26968844e-01
 -2.66944405e+00]
supnorm grad right now is: 3.8066199164706984
Weights right now are: 
[-2.47947474e+00  6.81989916e+00 -4.32444462e+01 -4.59474859e+01
  2.73404345e+00 -6.92859085e+00  4.36433834e+01  4.52314575e+01
 -2.43867999e+00 -9.73858227e-01  8.42481179e+00 -1.74171675e+00
  6.61294419e+00  7.67507233e+01  5.67602304e+00  6.93958818e+01
  1.49370812e+02  6.39446826e+01  4.22223819e+00  8.22878977e+01
  1.49176442e+02  6.27171196e+01  4.25551297e+00  8.26771493e+01
  5.89775898e+00 -6.95785429e+00  3.19544535e+00 -2.15070625e+00
  4.82050981e+00  1.98914092e+01  4.16101191e+02  4.81159261e+01
  4.50286632e+00  1.25469330e+02  6.47128323e-01  3.08478783e+00
  6.07105316e+00  3.16439299e+02  1.50408585e+01 -6.50263893e+00
 -4.17789104e+00 -2.59681398e-01 -7.64952157e+00  1.30500593e+01
  1.96946728e+02  1.78273786e+02 -3.20588089e+00  2.23510571e+00
  1.61542362e+01  3.54102964e+01 -2.22148151e+00 -1.14138009e+00
  1.96435563e+01  1.80006990e+01  5.95295614e+01 -2.18666074e-02
  5.72699177e-01 -3.00367468e+00 -1.02173200e+00 -2.94360371e+00
  9.46635522e+00  2.23096615e+00  6.78820374e+00  3.62697989e+00
  2.73905220e+01]
(65,)
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2426.5900866875736
gradient value of function right now is: [-3.18010736e-01 -2.76271425e-01 -8.89266957e-05 -9.20345456e-05
  3.18010736e-01  2.76271425e-01  8.89266956e-05  9.20345455e-05
  1.26088101e-01  5.18401126e-02  3.06870990e-01  1.68787417e-01
  2.73042007e-01  6.24849148e-05 -1.57713779e-01 -1.77900148e-04
 -1.77086155e-05 -2.47255715e-04  9.88919843e-05 -1.14857221e-04
 -2.12851980e-05 -2.66207686e-04  1.01042611e-04 -1.23601219e-04
  3.55070214e-02 -3.99812863e-01 -1.82429818e+00  3.62844265e-02
  2.30144363e-02  5.56977744e-18  3.99492336e-05  3.83106939e-05
 -5.40366193e-02  1.23540286e-03  6.78855651e-02 -3.73971044e-02
  2.76047906e-02  3.97476473e-06  1.17715012e-02  5.84473817e-03
 -2.19343931e-02 -2.69225939e-02  2.38127540e-02  4.24077491e-02
 -7.45552543e-03 -9.16064595e-03 -1.48555861e+00 -2.37413401e+00
 -1.11939427e-02 -2.00515799e-02  1.64677816e-01  3.20692617e-02
  2.59601748e-03  7.16692444e-03  4.48094571e-03  9.98552768e-02
  2.75660742e-01 -2.60904237e+00  5.21719644e-01 -3.39566812e+00
 -7.38031998e-01  3.51557843e+00 -1.31428689e-01  2.78230572e-01
 -2.64801506e+00]
supnorm grad right now is: 3.5155784330329203
Weights right now are: 
[-2.66661541e+00  7.01419151e+00 -4.27875808e+01 -4.55249286e+01
  2.92118412e+00 -7.12288320e+00  4.31865181e+01  4.48089002e+01
 -2.55805258e+00 -7.64084219e-01  8.56730563e+00 -2.03306847e+00
  6.84002412e+00  7.98635978e+01  5.95375410e+00  7.61052367e+01
  1.49112448e+02  6.36692528e+01  4.29636978e+00  8.32737325e+01
  1.48901641e+02  6.23710167e+01  4.32288379e+00  8.36021905e+01
  6.55056395e+00 -7.08075619e+00  3.16917661e+00 -1.37669348e+00
  5.36459927e+00  1.98914092e+01  4.22805686e+02  5.58697344e+01
  4.96610592e+00  1.28246173e+02  1.56754818e+00  3.07959766e+00
  6.07199279e+00  3.15898094e+02  1.50180294e+01 -7.54155306e+00
 -4.24130694e+00 -1.00567861e+00 -6.90387685e+00  1.18940200e+01
  2.00615915e+02  1.80852114e+02 -3.07698767e+00  1.89776985e+00
  1.69472481e+01  3.61903558e+01 -2.82621412e+00 -1.03355571e+00
  2.05161248e+01  1.93349541e+01  5.95737712e+01  6.22250496e-01
  3.24309397e-01 -2.97808931e+00 -1.14622314e+00 -3.04656723e+00
  9.60416751e+00  2.17986142e+00  6.78969128e+00  3.54766015e+00
  2.74566272e+01]
(65,)
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2426.5386255855674
gradient value of function right now is: [-3.26357745e-01 -2.74990632e-01 -1.05830610e-04 -1.10033666e-04
  3.26357745e-01  2.74990632e-01  1.05830610e-04  1.10033666e-04
  1.12810790e-01  3.89078386e-02  2.85945470e-01  1.50036537e-01
  2.51372607e-01  9.89072774e-05 -1.54820109e-01 -1.66504070e-04
 -3.78260347e-05 -3.07494762e-04  8.43471427e-05 -1.21414235e-04
 -4.36573770e-05 -3.32763531e-04  8.37725449e-05 -1.31338238e-04
  3.53154279e-02 -4.01796603e-01 -1.77453221e+00  7.06393743e-02
  2.53550664e-02  5.85177454e-18  3.72762399e-05  4.19754275e-05
 -4.12200465e-02  1.20271797e-03  6.88639522e-02 -2.88154995e-02
  2.60177953e-02  2.53661840e-06  1.05344309e-02  4.55712370e-03
 -2.75232338e-02 -3.69078259e-02  2.40141081e-02  4.00207817e-02
 -7.40311492e-03 -8.89531696e-03 -1.52990302e+00 -2.37057463e+00
 -1.11938267e-02 -1.95184293e-02  1.72119750e-01 -6.58791493e-02
  2.50552502e-03  6.36466843e-03  5.27833713e-03  1.42711603e-01
  2.71885904e-01 -2.62104786e+00  5.00435117e-01 -3.34238080e+00
 -8.01658678e-01  3.71600318e+00 -1.53987941e-01  3.60885314e-01
 -2.66734789e+00]
supnorm grad right now is: 3.7160031768619177
Weights right now are: 
[-2.66399554e+00  6.56000518e+00 -4.10895971e+01 -4.37948817e+01
  2.91856425e+00 -6.66869687e+00  4.14885343e+01  4.30788533e+01
 -2.43013025e+00 -1.59641282e+00  8.58835029e+00 -1.53552535e+00
  6.94728872e+00  7.83956588e+01  5.79743367e+00  7.40009332e+01
  1.49464304e+02  6.68615838e+01  3.08385806e+00  8.78163649e+01
  1.49339968e+02  6.54812053e+01  3.12949661e+00  8.81247898e+01
  6.30796100e+00 -6.98605107e+00  3.18474185e+00 -1.97847716e+00
  4.32507381e+00  1.98914092e+01  4.31900500e+02  5.98140081e+01
  4.97800897e+00  1.27652165e+02  4.77395737e-01  3.10334130e+00
  5.14081931e+00  3.18583836e+02  1.60216835e+01 -7.86349744e+00
 -4.54214054e+00 -1.17621008e+00 -6.60080605e+00  1.02221774e+01
  2.04284914e+02  1.83949118e+02 -3.15882662e+00  2.13954864e+00
  1.81628977e+01  3.68060998e+01 -2.53043075e+00 -1.32224360e+00
  2.07717477e+01  2.08349311e+01  5.82239901e+01  4.19588088e-01
  1.51843752e-01 -2.97420848e+00 -1.34189334e+00 -2.96085799e+00
  9.96125860e+00  2.16215822e+00  6.92926836e+00  3.68803744e+00
  2.71832807e+01]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2426.5505230163362
gradient value of function right now is: [-2.87593106e-01 -2.60448087e-01 -1.03448530e-04 -1.07609848e-04
  2.87593106e-01  2.60448087e-01  1.03448530e-04  1.07609848e-04
  1.31157758e-01  4.81176167e-02  2.94630451e-01  1.61196909e-01
  2.31263603e-01  9.68813964e-05 -1.52484501e-01 -1.32223559e-04
 -2.14153854e-05 -2.91747514e-04  1.05850896e-04 -1.31095450e-04
 -2.60689477e-05 -3.15993697e-04  1.06536607e-04 -1.41943250e-04
  3.56913039e-02 -3.90999001e-01 -1.68001071e+00  7.93064052e-02
  2.54908675e-02  6.03276738e-18  3.68591710e-05  3.82134772e-05
 -5.19508503e-02  1.19909860e-03  6.80161577e-02 -3.05498656e-02
  2.90373980e-02  1.65513436e-06  1.03889667e-02  4.68362305e-03
 -2.50773006e-02 -3.25979534e-02  2.90194834e-02  4.86708614e-02
 -7.45686644e-03 -8.79968656e-03 -1.54781420e+00 -2.29529414e+00
 -1.08814712e-02 -1.89876520e-02  1.62642335e-01 -1.36350396e-01
  2.71735900e-03  6.84328682e-03  5.50687247e-03  1.56731017e-01
  2.73124434e-01 -2.65927618e+00  4.78320995e-01 -3.30363051e+00
 -7.89465509e-01  3.66969267e+00 -1.74254123e-01  3.96834805e-01
 -2.69041288e+00]
supnorm grad right now is: 3.66969267165938
Weights right now are: 
[-2.52929066e+00  6.67274842e+00 -3.83342182e+01 -4.10921265e+01
  2.78385937e+00 -6.78144011e+00  3.87331554e+01  4.03760981e+01
 -2.88907790e+00 -1.33467633e+00  8.32594865e+00 -1.97262713e+00
  7.05634960e+00  7.81810768e+01  6.03496176e+00  7.80319531e+01
  1.52283039e+02  6.85786719e+01  4.80482432e+00  9.13010367e+01
  1.52142381e+02  6.70993552e+01  4.82018359e+00  9.15143476e+01
  5.45265826e+00 -6.91171500e+00  3.19222124e+00 -2.01526307e+00
  5.18687102e+00  1.98914092e+01  4.37766991e+02  6.18616222e+01
  4.29204332e+00  1.30130737e+02  5.97755870e-01  2.18100373e+00
  5.15464113e+00  3.13331108e+02  1.45386866e+01 -8.96530050e+00
 -3.67852417e+00 -6.54849859e-01 -5.67001299e+00  9.59916162e+00
  2.07619119e+02  1.86120830e+02 -3.17032493e+00  2.26011450e+00
  2.02184769e+01  3.84250227e+01 -2.67533894e+00 -1.33017455e+00
  2.42130927e+01  2.41345021e+01  5.86080527e+01  6.77954952e-01
  2.68939911e-01 -2.99717066e+00 -1.12053311e+00 -3.02420295e+00
  1.01553765e+01  1.80625905e+00  6.75388130e+00  3.42307575e+00
  2.69564261e+01]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2426.536631404615
gradient value of function right now is: [-3.00899063e-01 -2.62719502e-01 -1.23049986e-04 -1.27668866e-04
  3.00899063e-01  2.62719502e-01  1.23049986e-04  1.27668866e-04
  1.21512817e-01  3.43321869e-02  2.84377807e-01  1.53649973e-01
  2.29547971e-01  1.10288938e-04 -1.51898329e-01 -1.02442971e-04
 -4.52582265e-05 -3.07145022e-04  7.85474635e-05 -1.52285289e-04
 -5.16018458e-05 -3.32685917e-04  7.70337721e-05 -1.64903139e-04
  3.79371454e-02 -3.89310730e-01 -1.69268008e+00  7.23590419e-02
  2.56004633e-02  1.03144777e-17  3.85521411e-05  3.40190522e-05
 -4.84959716e-02  1.14054487e-03  6.73454861e-02 -3.18438844e-02
  3.03922635e-02  1.15460366e-06  1.01866006e-02  4.72574498e-03
 -2.95435821e-02 -3.87710963e-02  3.13372224e-02  5.15539625e-02
 -7.31421286e-03 -8.64149918e-03 -1.53912718e+00 -2.27678772e+00
 -1.06243873e-02 -1.85348622e-02  1.56095730e-01 -1.45161094e-01
  2.84742542e-03  7.11164803e-03  5.41338677e-03  1.55639596e-01
  2.62336200e-01 -2.62641379e+00  4.65006494e-01 -3.25584896e+00
 -7.80215982e-01  3.62251494e+00 -1.75302835e-01  4.06734154e-01
 -2.57735894e+00]
supnorm grad right now is: 3.622514943927586
Weights right now are: 
[ -2.67669148   6.85368203 -38.11060707 -40.89256368   2.93126019
  -6.96237372  38.50954432  40.17653528  -3.09452498  -0.54419291
   8.47148111  -1.89214033   7.38709119  81.42421434   5.37753916
  81.27319661 152.05421514  68.31448      2.44219255  91.34775737
 151.89196622  66.77269978   2.45627386  91.50418428   5.64665014
  -6.75023686   3.29697456  -2.66369119   5.02754967  19.89140925
 440.06668917  63.43467556   4.61304476 132.2804931    1.05105408
   2.73199594   5.362467   312.70194936  16.24016309  -9.60221582
  -4.72367806  -1.50275665  -4.68520225   9.37353958 210.82014948
 188.66715386  -3.06721193   2.38056124  22.48303439  40.05719565
  -2.29091042  -1.35199896  23.24447913  24.07935207  57.2632403
   0.77605208   0.46293877  -3.19149933  -0.96949441  -3.09887535
  10.2073183    1.92314248   7.54565553   3.480764    27.17815581]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1488.5670632475026
W_T_median: 1295.8480509051813
W_T_pctile_5: 741.0173946902897
W_T_CVAR_5_pct: 640.2996116190589
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.2
F value: -2426.536631404615
-----------------------------------------------
