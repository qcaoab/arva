Starting at: 
14-03-23_15:23

 numpy seed:  3  


 pytorch seed:  3  

Key parameters-------
paths: 256000
iterations: 40000
batchsize: 1000
remove neg:  False
w constaint activation:  yy_fix_jan29


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
3.3333333333333335% of MC simulations done.
6.666666666666667% of MC simulations done.
10.0% of MC simulations done.
13.333333333333334% of MC simulations done.
16.666666666666664% of MC simulations done.
20.0% of MC simulations done.
23.333333333333332% of MC simulations done.
26.666666666666668% of MC simulations done.
30.0% of MC simulations done.
33.33333333333333% of MC simulations done.
36.666666666666664% of MC simulations done.
40.0% of MC simulations done.
43.333333333333336% of MC simulations done.
46.666666666666664% of MC simulations done.
50.0% of MC simulations done.
53.333333333333336% of MC simulations done.
56.666666666666664% of MC simulations done.
60.0% of MC simulations done.
63.33333333333333% of MC simulations done.
66.66666666666666% of MC simulations done.
70.0% of MC simulations done.
73.33333333333333% of MC simulations done.
76.66666666666667% of MC simulations done.
80.0% of MC simulations done.
83.33333333333334% of MC simulations done.
86.66666666666667% of MC simulations done.
90.0% of MC simulations done.
93.33333333333333% of MC simulations done.
96.66666666666667% of MC simulations done.
100.0% of MC simulations done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/testing_pyt_decum/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)     True          10  
2     (10, 10)     True          10  
3      (10, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 4000, 'itbound_SGD_algorithms': 40000, 'nit_IterateAveragingStart': 36000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)      True          10  
0     (10, 10)      True          10  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
pre-loaded NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -0.9553,   1.0080],
        [-10.8614,   7.0624],
        [-12.4871,  -1.7089],
        [ -1.3744,  -9.5360],
        [ 12.5159,  -2.7972],
        [ -2.1049, -10.0500],
        [-49.9498,  -7.6964],
        [  8.9716,  -6.4039],
        [  2.6822, -10.7349],
        [ -0.9550,   1.0082]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-2.6515,  3.7595, 12.4347, -8.4650, -9.7612, -8.6210, -7.4386, -9.3722,
        -9.3796, -2.6513], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-4.3955e-03, -5.1370e-02, -1.0217e+00, -1.8801e-01, -3.4561e-01,
         -2.2617e-01, -1.0791e-01, -6.6659e-02, -2.2987e-01, -4.3959e-03],
        [-4.3955e-03, -5.1370e-02, -1.0217e+00, -1.8801e-01, -3.4561e-01,
         -2.2617e-01, -1.0791e-01, -6.6659e-02, -2.2987e-01, -4.3959e-03],
        [-4.3955e-03, -5.1370e-02, -1.0217e+00, -1.8801e-01, -3.4561e-01,
         -2.2617e-01, -1.0791e-01, -6.6659e-02, -2.2987e-01, -4.3959e-03],
        [-4.3955e-03, -5.1370e-02, -1.0217e+00, -1.8801e-01, -3.4561e-01,
         -2.2617e-01, -1.0791e-01, -6.6659e-02, -2.2987e-01, -4.3959e-03],
        [-3.7428e-03, -7.1506e+00, -8.9232e+00,  7.4431e+00,  1.0595e+01,
          8.6785e+00,  8.6733e+00,  5.8855e+00,  9.4683e+00, -2.9656e-03],
        [-4.3956e-03, -5.1370e-02, -1.0217e+00, -1.8801e-01, -3.4561e-01,
         -2.2617e-01, -1.0791e-01, -6.6659e-02, -2.2987e-01, -4.3959e-03],
        [-4.3955e-03, -5.1370e-02, -1.0217e+00, -1.8801e-01, -3.4561e-01,
         -2.2617e-01, -1.0791e-01, -6.6659e-02, -2.2987e-01, -4.3959e-03],
        [ 1.0166e-01, -6.0856e+00, -8.8140e+00,  6.8621e+00,  8.4896e+00,
          8.1946e+00,  7.0089e+00,  3.8004e+00,  9.3820e+00,  1.0114e-01],
        [-4.3955e-03, -5.1370e-02, -1.0217e+00, -1.8801e-01, -3.4561e-01,
         -2.2617e-01, -1.0791e-01, -6.6659e-02, -2.2987e-01, -4.3959e-03],
        [ 4.0560e-02,  1.5166e+00,  1.0292e+01, -7.4440e+00, -8.8579e+00,
         -8.0970e+00, -8.0951e+00, -1.0011e+01, -1.0933e+01,  4.0878e-02]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-1.1978, -1.1978, -1.1978, -1.1978, -3.9055, -1.1978, -1.1978, -3.2988,
        -1.1978,  0.5184], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 1.3266e-02,  1.3266e-02,  1.3266e-02,  1.3266e-02, -1.0848e+01,
          1.3266e-02,  1.3266e-02, -7.9416e+00,  1.3266e-02,  1.5741e+01]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 13.4805,   7.6035],
        [-12.5345,   3.0015],
        [ 13.9035,   2.7227],
        [  4.8417,   2.6225],
        [ -4.2711,   2.4017],
        [ -8.8058,   2.9486],
        [-12.9350,   7.4324],
        [ -6.9064,   7.2045],
        [ -1.6546,   0.3460],
        [  8.6300,  13.5385]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ 3.4188, 13.2654, -3.9433, -3.8553, -6.5076, 14.8300,  8.3296,  8.0741,
        -3.8364, 10.8957], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-4.9826e-01, -9.7229e-01, -1.1201e+00,  1.6596e+00,  6.1056e-01,
         -1.2558e+00, -4.6746e-02, -4.5508e+00, -1.9351e-01,  9.6934e-01],
        [ 9.8528e-01,  9.3675e-01,  1.3027e+00,  1.4003e-01,  8.3569e-02,
          2.0824e+00,  2.6821e-01,  4.0551e-01, -8.0092e-04,  6.3324e-01],
        [-6.5458e+00, -1.0958e+00, -4.7643e-01,  1.2700e+00,  1.5085e+00,
         -5.1117e+00,  3.4617e+00,  3.1687e+00,  7.1731e-02,  1.6790e-01],
        [-1.1016e+01,  5.7353e+00, -9.0153e+00, -3.2379e-01,  4.5142e-02,
          6.9574e+00, -5.3534e+00,  8.8213e-01,  9.6781e-02, -3.2389e+01],
        [-1.1087e+00,  6.3911e-01, -2.5974e+00,  5.3334e-01,  8.7565e-01,
         -4.2871e-01, -1.1494e+00, -4.4929e+00,  2.3809e-01,  2.4067e+00],
        [-1.7320e+00, -4.6672e-01, -2.4367e+00,  4.5303e-01,  6.3355e-01,
         -1.3885e+00,  7.0933e-01, -2.0046e+00,  1.9152e-02,  9.7596e-01],
        [ 6.7685e+00, -3.2627e+00, -1.2841e-01, -9.5673e+00, -2.7464e+00,
         -4.2618e+00,  6.1210e+00,  1.0082e+01,  5.5293e-02,  6.9224e-01],
        [-1.7696e+00, -4.2124e-01, -2.4507e+00,  4.1071e-02,  6.6775e-01,
         -9.0910e-01,  8.7740e-01, -1.5409e+00,  7.4274e-02,  4.5755e-01],
        [-4.6116e+00,  7.3086e+00, -8.0312e-01,  3.1587e+00, -1.7607e-02,
          2.6289e+00, -1.0784e+01, -7.6286e+00,  5.4661e-02, -8.4977e+00],
        [-2.1920e+01,  1.9811e+00, -9.7156e+00, -3.8452e-01,  1.0402e-02,
          2.1337e+00, -1.2178e+00,  6.3185e+00,  2.7708e-01, -2.8355e+01]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-2.5459,  2.9412, -1.1326,  1.7500, -2.2012, -2.7232, -7.1768, -2.4897,
        -0.0420, -0.9855], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[  1.5789,   0.2309,   3.0535,  -7.8657,   2.5689,   1.3467,   0.3864,
           1.6854,  -0.6410,  16.4837],
        [ -1.5792,  -0.2713,  -3.0455,   8.0614,  -2.5689,  -1.3466,  -0.4456,
          -1.6855,   0.5531, -16.4705]], device='cuda:0'))])
loaded xi:  59.100292
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1583.6866209228313
W_T_median: 1138.6857387434734
W_T_pctile_5: -127.4429131675796
W_T_CVAR_5_pct: -297.80727420155023
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1552.6966296778419
Current xi:  [59.131905]
objective value function right now is: -1552.6966296778419
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1563.292287839713
Current xi:  [59.43762]
objective value function right now is: -1563.292287839713
6.0% of gradient descent iterations done. Method = Adam
Current xi:  [58.673634]
objective value function right now is: -1561.8820611931346
8.0% of gradient descent iterations done. Method = Adam
Current xi:  [58.84873]
objective value function right now is: -1557.7618348934366
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1563.8893865256132
Current xi:  [58.79626]
objective value function right now is: -1563.8893865256132
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [58.79442]
objective value function right now is: -1559.7169421087244
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [59.02015]
objective value function right now is: -1557.0890471593061
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [58.778244]
objective value function right now is: -1556.7171243851803
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [58.90973]
objective value function right now is: -1561.1110533405426
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [58.480877]
objective value function right now is: -1562.5298941111002
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [58.493507]
objective value function right now is: -1558.541860959501
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [58.286385]
objective value function right now is: -1558.2100905692885
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [58.28188]
objective value function right now is: -1563.6543128918404
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [58.25301]
objective value function right now is: -1557.8405195042803
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [58.212673]
objective value function right now is: -1561.8354880673626
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [57.80542]
objective value function right now is: -1563.7888882197576
34.0% of gradient descent iterations done. Method = Adam
new min fval:  -1564.1798388523002
Current xi:  [58.234375]
objective value function right now is: -1564.1798388523002
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [58.317368]
objective value function right now is: -1563.9335908520618
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [58.729897]
objective value function right now is: -1562.2204287335119
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [58.923634]
objective value function right now is: -1563.7264581238785
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [59.2381]
objective value function right now is: -1560.7317567036116
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [59.3755]
objective value function right now is: -1563.5776743217807
46.0% of gradient descent iterations done. Method = Adam
new min fval:  -1564.9697408744473
Current xi:  [59.594864]
objective value function right now is: -1564.9697408744473
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [59.34082]
objective value function right now is: -1564.571895251302
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [59.413223]
objective value function right now is: -1563.2762426381769
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [59.458282]
objective value function right now is: -1556.6636429431512
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [59.74635]
objective value function right now is: -1562.5826665362656
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [59.64759]
objective value function right now is: -1562.0027718105634
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [60.074764]
objective value function right now is: -1556.1778079106043
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [59.92778]
objective value function right now is: -1562.6729192862506
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [60.58331]
objective value function right now is: -1564.6350996028689
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [60.49893]
objective value function right now is: -1564.3548645005949
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [60.707005]
objective value function right now is: -1558.7357776140368
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [60.743385]
objective value function right now is: -1564.0904116240079
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [60.82144]
objective value function right now is: -1562.177427368749
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -1565.3351775876436
Current xi:  [60.826176]
objective value function right now is: -1565.3351775876436
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -1566.3343106024074
Current xi:  [60.827164]
objective value function right now is: -1566.3343106024074
76.0% of gradient descent iterations done. Method = Adam
new min fval:  -1566.4899913596414
Current xi:  [60.786682]
objective value function right now is: -1566.4899913596414
78.0% of gradient descent iterations done. Method = Adam
new min fval:  -1566.7113981951318
Current xi:  [60.802094]
objective value function right now is: -1566.7113981951318
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [60.776524]
objective value function right now is: -1566.6214802635807
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [60.80518]
objective value function right now is: -1566.5640297517375
84.0% of gradient descent iterations done. Method = Adam
new min fval:  -1566.8106086289854
Current xi:  [60.84149]
objective value function right now is: -1566.8106086289854
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [60.8045]
objective value function right now is: -1565.6251438867837
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [61.014294]
objective value function right now is: -1566.025356680571
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [61.00172]
objective value function right now is: -1566.3502288672594
new min fval from sgd:  -1566.848984987087
new min fval from sgd:  -1566.8549954933503
new min fval from sgd:  -1566.9076242728243
new min fval from sgd:  -1566.9645834062944
new min fval from sgd:  -1567.0370137832106
new min fval from sgd:  -1567.0631567861496
new min fval from sgd:  -1567.1045437436444
new min fval from sgd:  -1567.1118215186987
new min fval from sgd:  -1567.111988320881
new min fval from sgd:  -1567.130124302818
new min fval from sgd:  -1567.1317822105577
new min fval from sgd:  -1567.1372344117078
new min fval from sgd:  -1567.1431954370123
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [61.07047]
objective value function right now is: -1566.1903826684907
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [61.170486]
objective value function right now is: -1566.690711801778
new min fval from sgd:  -1567.150634776464
new min fval from sgd:  -1567.17306933438
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [61.30422]
objective value function right now is: -1566.0759393766798
new min fval from sgd:  -1567.1790536895373
new min fval from sgd:  -1567.1807191479766
new min fval from sgd:  -1567.1884484347968
new min fval from sgd:  -1567.1997181277443
new min fval from sgd:  -1567.208436044705
new min fval from sgd:  -1567.2097963084473
new min fval from sgd:  -1567.2158703280088
new min fval from sgd:  -1567.2189571784231
new min fval from sgd:  -1567.2194618380438
new min fval from sgd:  -1567.2268072833747
new min fval from sgd:  -1567.2331186595518
new min fval from sgd:  -1567.2372863055118
new min fval from sgd:  -1567.2382298864215
new min fval from sgd:  -1567.2403692144912
new min fval from sgd:  -1567.2433069950062
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [61.287636]
objective value function right now is: -1567.2321811044847
new min fval from sgd:  -1567.247902694277
new min fval from sgd:  -1567.2518288361457
new min fval from sgd:  -1567.2537464798231
new min fval from sgd:  -1567.2567264829136
new min fval from sgd:  -1567.2690553040775
new min fval from sgd:  -1567.274073501968
new min fval from sgd:  -1567.2827994180986
new min fval from sgd:  -1567.2846762500471
new min fval from sgd:  -1567.284827938897
new min fval from sgd:  -1567.2924412808154
new min fval from sgd:  -1567.3059874553437
new min fval from sgd:  -1567.3178939910242
new min fval from sgd:  -1567.3207510450661
new min fval from sgd:  -1567.330842801192
new min fval from sgd:  -1567.3353283047718
new min fval from sgd:  -1567.3382739287413
new min fval from sgd:  -1567.3460854784237
new min fval from sgd:  -1567.3515538125407
new min fval from sgd:  -1567.3561539597813
new min fval from sgd:  -1567.3573390017168
new min fval from sgd:  -1567.361949307045
new min fval from sgd:  -1567.362627916344
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [61.285175]
objective value function right now is: -1567.331148871058
min fval:  -1567.362627916344
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -0.9693,   0.8618],
        [-12.7952,   7.7180],
        [-13.4842,  -4.2670],
        [  0.7858, -10.9633],
        [ 14.9905,  -2.7608],
        [ -2.6065, -11.9159],
        [-65.0589,  -8.9939],
        [ 13.7771,  -5.8972],
        [  4.1909, -12.4402],
        [ -0.9693,   0.8618]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([ -2.5056,   4.1818,  14.6496,  -9.9603, -12.7311,  -9.7198,  -8.3872,
        -11.6887, -10.6481,  -2.5056], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ 2.4202e-02,  9.0570e-03, -9.2309e-01, -8.8050e-02, -2.0278e-01,
         -2.0839e-01, -9.3706e-02, -2.0774e-01, -1.9714e-01,  2.4202e-02],
        [ 2.4202e-02,  9.0570e-03, -9.2309e-01, -8.8050e-02, -2.0278e-01,
         -2.0839e-01, -9.3706e-02, -2.0774e-01, -1.9714e-01,  2.4202e-02],
        [ 2.4202e-02,  9.0570e-03, -9.2309e-01, -8.8050e-02, -2.0278e-01,
         -2.0839e-01, -9.3706e-02, -2.0774e-01, -1.9714e-01,  2.4202e-02],
        [ 2.4202e-02,  9.0570e-03, -9.2309e-01, -8.8050e-02, -2.0278e-01,
         -2.0839e-01, -9.3706e-02, -2.0774e-01, -1.9714e-01,  2.4202e-02],
        [-8.4414e-02, -6.4000e+00, -1.0103e+01,  7.9107e+00,  1.2745e+01,
          9.6976e+00,  1.1355e+01,  7.5817e+00,  1.1335e+01, -8.4414e-02],
        [ 2.4202e-02,  9.0570e-03, -9.2309e-01, -8.8050e-02, -2.0278e-01,
         -2.0839e-01, -9.3706e-02, -2.0774e-01, -1.9714e-01,  2.4202e-02],
        [ 2.4202e-02,  9.0570e-03, -9.2309e-01, -8.8050e-02, -2.0278e-01,
         -2.0839e-01, -9.3706e-02, -2.0774e-01, -1.9714e-01,  2.4202e-02],
        [-5.3465e-02, -2.9460e+00, -8.6068e+00,  5.8230e+00,  1.0612e-01,
          8.1188e+00,  2.4887e+00, -6.0978e-01,  9.1213e+00, -5.3465e-02],
        [ 2.4202e-02,  9.0569e-03, -9.2309e-01, -8.8050e-02, -2.0278e-01,
         -2.0839e-01, -9.3706e-02, -2.0774e-01, -1.9714e-01,  2.4202e-02],
        [-5.8011e-02,  2.4853e+00,  1.1027e+01, -7.6269e+00, -9.6005e+00,
         -9.0969e+00, -1.1075e+01, -1.0800e+01, -1.3046e+01, -5.8011e-02]],
       device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([-1.1600, -1.1600, -1.1600, -1.1600, -5.2304, -1.1600, -1.1600, -4.1162,
        -1.1600,  1.3787], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[  0.0507,   0.0507,   0.0507,   0.0507, -15.2175,   0.0507,   0.0507,
          -5.0344,   0.0507,  16.4035]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ 16.0779,   9.2795],
        [-14.7975,   1.3430],
        [ 16.7649,   3.0236],
        [  8.0359,   2.2484],
        [ -2.9489,   4.0990],
        [-13.8543,   3.3590],
        [-17.0412,   9.2961],
        [-10.7232,   9.3496],
        [ -4.3326,   2.6450],
        [ 10.1435,  15.8763]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([ 3.8763, 15.2427, -5.3307, -7.2921, -3.2245, 13.5593,  9.5859, 11.1076,
        -6.2727, 12.7444], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-3.8877e+00, -2.5747e-01, -1.3821e+00,  3.2012e+00, -6.0372e-01,
         -3.7404e-01, -2.1082e+00, -5.0193e-01, -8.7320e-01,  2.0870e+00],
        [ 3.4816e+00, -4.2168e+00, -1.7264e-02,  2.7461e+00, -2.0307e-02,
         -4.1958e+00,  4.4154e+00,  1.1725e+01, -7.5626e-03,  7.6146e+00],
        [-3.0318e+00, -3.9268e-01, -1.8645e+00,  1.0174e+00, -2.7701e-03,
          3.5737e-02, -1.0027e+00,  6.3808e-01, -4.9552e-02, -6.9177e-01],
        [-1.6022e+01,  8.9832e+00, -9.5068e+00, -2.7645e-01, -3.8066e-02,
          5.7912e+00, -8.3643e+00,  9.7888e-01,  1.6675e-03, -3.3117e+01],
        [-3.9214e+00,  1.1208e-01, -1.8535e+00, -1.0947e+00, -7.9217e-02,
          3.2179e-01,  1.6104e+00, -9.9756e+00,  1.5716e-02,  5.8254e+00],
        [-2.7852e+00, -5.7598e-01, -1.9019e+00,  5.8396e-01,  1.1253e-01,
          8.8394e-04, -4.2196e-01,  5.9900e-01,  8.5711e-02, -9.5047e-01],
        [ 9.7047e+00, -2.6873e+00, -1.1229e+00, -1.4558e+01,  3.1184e+00,
         -6.1071e+00,  9.3739e+00,  1.0236e+01, -4.4820e+00, -7.8273e-01],
        [-2.5237e+00, -6.8549e-01, -1.7115e+00,  6.9263e-01,  9.0141e-02,
         -3.0524e-01, -5.5537e-01,  4.9428e-01,  7.5410e-02, -7.4515e-01],
        [-6.8459e+00,  6.0994e+00, -3.4992e+00, -1.3213e+00,  1.6205e-02,
          2.1659e+00, -9.0873e+00, -6.6478e+00,  1.2333e-02, -9.6613e+00],
        [-2.4114e+01,  2.6043e+00, -9.7387e+00, -5.0550e-02,  3.6478e-02,
          1.1800e+00, -1.0468e+00,  3.8529e+00,  3.8670e-03, -2.1374e+01]],
       device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-2.4773, -1.3381, -2.8544,  0.7974, -3.9126, -2.9341, -7.0482, -3.2273,
         1.5091, -2.1437], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[  2.8044,   0.2387,   0.9245,  -8.3888,   3.9905,   0.7422,   0.3735,
           0.4396,  -0.5107,  18.1020],
        [ -2.8044,  -0.2790,  -0.9245,   8.4746,  -3.9905,  -0.7423,  -0.4292,
          -0.4396,   0.4255, -18.0976]], device='cuda:0'))])
xi:  [61.292717]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 487.96720934937565
W_T_median: 238.01296669270945
W_T_pctile_5: 61.3057971255225
W_T_CVAR_5_pct: -42.24204611504755
Average q (qsum/M+1):  51.922784620715724
Optimal xi:  [61.292717]
Expected(across Rb) median(across samples) p_equity:  0.2878849243124326
obj fun:  tensor(-1567.3626, device='cuda:0', dtype=torch.float64)
-----------------------------------------------
Need to implement this
bond graph is mislabeled!
bond graph is mislabeled!
/home/marcchen/Documents/testing_pyt_decum/researchcode/fun_Plot_NN_control_DataHeatmaps.py:161: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format=save_Figures_format, bbox_inches="tight")
/home/marcchen/Documents/testing_pyt_decum/researchcode/fun_output_results_Pctiles.py:176: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.
  plt.savefig(fig_filename, format = save_Figures_format, bbox_inches = "tight")
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
