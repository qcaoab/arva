Starting at: 
15-11-22_14:20

 Random seed:  2  



############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
3.3333333333333335% of MC simulations done.
6.666666666666667% of MC simulations done.
10.0% of MC simulations done.
13.333333333333334% of MC simulations done.
16.666666666666664% of MC simulations done.
20.0% of MC simulations done.
23.333333333333332% of MC simulations done.
26.666666666666668% of MC simulations done.
30.0% of MC simulations done.
33.33333333333333% of MC simulations done.
36.666666666666664% of MC simulations done.
40.0% of MC simulations done.
43.333333333333336% of MC simulations done.
46.666666666666664% of MC simulations done.
50.0% of MC simulations done.
53.333333333333336% of MC simulations done.
56.666666666666664% of MC simulations done.
60.0% of MC simulations done.
63.33333333333333% of MC simulations done.
66.66666666666666% of MC simulations done.
70.0% of MC simulations done.
73.33333333333333% of MC simulations done.
76.66666666666667% of MC simulations done.
80.0% of MC simulations done.
83.33333333333334% of MC simulations done.
86.66666666666667% of MC simulations done.
90.0% of MC simulations done.
93.33333333333333% of MC simulations done.
96.66666666666667% of MC simulations done.
100.0% of MC simulations done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1  logistic_sigmoid   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer        4  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer        4  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1  logistic_sigmoid   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0       (2, 4)     False        None  
0       (4, 4)     False        None  
0       (4, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer        4  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer        4  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0       (2, 4)     False        None  
0       (4, 4)     False        None  
0       (4, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.4 0.6]
W_T_mean: 2852.5841256804665
W_T_median: 1758.8236953780975
W_T_pctile_5: -227.34822680303085
W_T_CVAR_5_pct: -434.4962643384009
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
Current xi:  [12.354447]
objective value function right now is: -1083.3830886452624
4.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.380694]
objective value function right now is: -1236.1788007991902
6.0% of gradient descent iterations done. Method = Adam
Current xi:  [7.4636087]
objective value function right now is: -1277.6105196669148
8.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.235452]
objective value function right now is: -1295.569147095875
10.0% of gradient descent iterations done. Method = Adam
Current xi:  [7.944154]
objective value function right now is: -1311.8251317131792
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [7.9547443]
objective value function right now is: -1315.7095921467007
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [8.382034]
objective value function right now is: -1308.2043710050089
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.347173]
objective value function right now is: -1322.0950098231706
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.348352]
objective value function right now is: -1319.5926764687401
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [7.8560743]
objective value function right now is: -1320.3281587174079
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.030464]
objective value function right now is: -1327.4004475167465
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.144104]
objective value function right now is: -1327.5238335064685
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.721866]
objective value function right now is: -1321.478437330151
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [8.371732]
objective value function right now is: -1329.2652962387028
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.112917]
objective value function right now is: -1330.2969564363855
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.986707]
objective value function right now is: -1322.265271610723
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.810469]
objective value function right now is: -1330.9717080477271
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.914427]
objective value function right now is: -1332.1084453995472
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.95221]
objective value function right now is: -1330.2112795312214
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.317395]
objective value function right now is: -1333.7527061698293
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.750531]
objective value function right now is: -1335.3237834031988
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.744055]
objective value function right now is: -1331.3801983880076
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.76759]
objective value function right now is: -1336.9205146420175
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.037976]
objective value function right now is: -1337.188947630479
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.631565]
objective value function right now is: -1333.2898197549903
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.422651]
objective value function right now is: -1339.3747998342794
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.07066]
objective value function right now is: -1339.1098467381503
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [8.943074]
objective value function right now is: -1336.7266792438663
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [8.648563]
objective value function right now is: -1335.939323511538
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.547756]
objective value function right now is: -1338.6793782598807
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.724148]
objective value function right now is: -1339.3519979850303
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.134109]
objective value function right now is: -1335.6043414792805
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [3.5915563]
objective value function right now is: -1524.9022481100014
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.45562646]
objective value function right now is: -1521.7062401903952
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.0014795]
objective value function right now is: -1512.9398906171025
72.0% of gradient descent iterations done. Method = Adam
Current xi:  [-4.5438952e-08]
objective value function right now is: -1526.8007640379137
74.0% of gradient descent iterations done. Method = Adam
Current xi:  [4.3222834e-12]
objective value function right now is: -1497.0972890232829
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [3.1431708e-11]
objective value function right now is: -1497.106215680553
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.00010577]
objective value function right now is: -1499.70886267717
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.0005791]
objective value function right now is: -1489.1497360889898
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.02061795]
objective value function right now is: -1480.5836195952222
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.2064737]
objective value function right now is: -1492.1580459939498
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.00012757]
objective value function right now is: -1498.6665656358696
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.9119145e-10]
objective value function right now is: -1493.5811490124222
new min fval:  1207.9088034924027
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.00549382]
objective value function right now is: -1493.395008600382
new min fval:  -1493.2319254121505
new min fval:  -1493.3555243458395
new min fval:  -1493.6875002853037
new min fval:  -1493.9957098699376
new min fval:  -1494.2635576069895
new min fval:  -1494.649814673511
new min fval:  -1495.0743217768897
new min fval:  -1495.5804609599834
new min fval:  -1496.1965495496174
new min fval:  -1496.8365286684784
new min fval:  -1497.5273674393698
new min fval:  -1498.1691977268385
new min fval:  -1498.6721036478007
new min fval:  -1499.0688966324326
new min fval:  -1499.3895240087788
new min fval:  -1499.7007054736125
new min fval:  -1500.0025244796798
new min fval:  -1500.2701507126187
new min fval:  -1500.4899976515487
new min fval:  -1500.6909996437003
new min fval:  -1500.885133007902
new min fval:  -1501.1217357109244
new min fval:  -1501.4022047934359
new min fval:  -1501.649504529092
new min fval:  -1501.8523274681559
new min fval:  -1502.0446354302628
new min fval:  -1502.216681167087
new min fval:  -1502.353044430792
new min fval:  -1502.4919148627441
new min fval:  -1502.6136607592334
new min fval:  -1502.7041700427221
new min fval:  -1502.7628141371868
new min fval:  -1502.8210518562234
new min fval:  -1502.8629946723927
new min fval:  -1502.9191673231287
new min fval:  -1502.9957378087165
new min fval:  -1503.0789175684934
new min fval:  -1503.153298877461
new min fval:  -1503.2014290876655
new min fval:  -1503.2347727868294
new min fval:  -1503.2586858857408
new min fval:  -1503.278063681375
new min fval:  -1503.2971841667857
new min fval:  -1503.3165572680505
new min fval:  -1503.3370279337382
new min fval:  -1503.3544376705856
new min fval:  -1503.372868709996
new min fval:  -1503.384547684847
new min fval:  -1503.401826967758
new min fval:  -1503.4082838052987
new min fval:  -1503.4158438008023
new min fval:  -1503.4267905487025
new min fval:  -1503.4298364870026
new min fval:  -1503.4396930582857
new min fval:  -1503.452582674194
new min fval:  -1503.4766556276138
new min fval:  -1503.4963822569173
new min fval:  -1503.5103056135886
new min fval:  -1503.5183806441628
new min fval:  -1503.5209434765386
new min fval:  -1503.527030874276
new min fval:  -1503.537666140995
new min fval:  -1503.5444383704062
new min fval:  -1503.5580922919712
new min fval:  -1503.5700233601149
new min fval:  -1503.59261145308
new min fval:  -1503.6010049232254
new min fval:  -1503.6113427570292
new min fval:  -1503.6232423574565
new min fval:  -1503.6438168034376
new min fval:  -1503.6538869645299
new min fval:  -1503.6551971793008
new min fval:  -1503.6612847738934
new min fval:  -1503.672590465853
new min fval:  -1503.6915498199257
new min fval:  -1503.714895798715
new min fval:  -1503.7436274013269
new min fval:  -1503.776082290645
new min fval:  -1503.8029524459905
new min fval:  -1503.8183592502075
new min fval:  -1503.839014847796
new min fval:  -1503.8658041176204
new min fval:  -1503.8886818664541
new min fval:  -1503.9040291427318
new min fval:  -1503.9150147374478
new min fval:  -1503.9363745543048
new min fval:  -1503.9613100987142
new min fval:  -1504.0039086796555
new min fval:  -1504.0528623744376
new min fval:  -1504.0657043292738
new min fval:  -1504.0920631652436
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.22135594]
objective value function right now is: -1496.7633127252352
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [1.1931398e-06]
objective value function right now is: -1502.3702581930236
new min fval:  -1504.095387831722
new min fval:  -1504.0987275448783
new min fval:  -1504.101481694144
new min fval:  -1504.1036605191077
new min fval:  -1504.1050339163673
new min fval:  -1504.1059234188945
new min fval:  -1504.1070976819526
new min fval:  -1504.108611750731
new min fval:  -1504.1117019308867
new min fval:  -1504.115041703463
new min fval:  -1504.1152239523326
new min fval:  -1504.1157595827988
new min fval:  -1504.1175048546593
new min fval:  -1504.120148131789
new min fval:  -1504.1225752519715
new min fval:  -1504.124389314323
new min fval:  -1504.1259211418023
new min fval:  -1504.1274347413687
new min fval:  -1504.1295057198074
new min fval:  -1504.1322408979483
new min fval:  -1504.1353208823755
new min fval:  -1504.1382864037869
new min fval:  -1504.1397703495684
new min fval:  -1504.1398995907346
new min fval:  -1504.1420659390494
new min fval:  -1504.1479549520288
new min fval:  -1504.1547146756827
new min fval:  -1504.1603317425527
new min fval:  -1504.161852666056
new min fval:  -1504.1629139542556
new min fval:  -1504.1651333625507
new min fval:  -1504.1681779951011
new min fval:  -1504.1701226143996
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [2.2357144e-06]
objective value function right now is: -1497.8982370054305
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.0857665]
objective value function right now is: -1502.0105795357463
new min fval:  -1504.170664727399
new min fval:  -1504.1728015175797
new min fval:  -1504.1747060528305
new min fval:  -1504.176880646571
new min fval:  -1504.1786887661906
new min fval:  -1504.180487437354
new min fval:  -1504.1826379338443
new min fval:  -1504.1855094000493
new min fval:  -1504.1882997716586
new min fval:  -1504.191138378426
new min fval:  -1504.193813840924
new min fval:  -1504.1961091062017
new min fval:  -1504.1984879625927
new min fval:  -1504.2010790393545
new min fval:  -1504.2045115939438
new min fval:  -1504.2085266751972
new min fval:  -1504.2124087349898
new min fval:  -1504.215139863755
new min fval:  -1504.2171718977936
new min fval:  -1504.218002140073
new min fval:  -1504.218045090317
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.01913799]
objective value function right now is: -1526.0851809114731
min fval:  -1504.218045090317
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 465.3074960006425
W_T_median: 181.88724361273785
W_T_pctile_5: -6.895385271281161
W_T_CVAR_5_pct: -125.40843363505967
Average q (qsum/M+1):  52.57905824722782
Optimal xi:  [0.01194863]
Expected(across Rb) median(across samples) p_equity:  0.29405824072161735
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
