tracing parameter entered from terminal:  0.7


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1704.6850744458668
gradient value of function right now is: [ 1.84514414e+00  2.22489213e+00  1.11553191e+00  1.02153622e+00
 -1.84514414e+00 -2.22489213e+00 -1.11553191e+00 -1.02153622e+00
  8.21390568e-01  5.55732523e-01  2.91627430e-01  1.78449640e+00
 -5.38839448e-01 -1.32816624e-01 -2.18053519e-02 -1.90537422e+00
 -4.57231509e-02 -6.95140035e-03 -1.01164339e-03 -2.72507341e-01
 -3.80282749e-02 -5.05973463e-03 -7.03381920e-04 -2.51994404e-01
  1.53091277e-01  1.50730559e-01  1.03263245e-01  7.31309092e-02
  3.26850452e-01  1.00177594e-01  9.03070029e-02  2.23669455e-02
  4.03708747e-01  4.22552089e-02  5.29082914e-02  4.66709804e-03
  3.26083432e-01  3.33155733e-01  1.56850557e-01  2.66974066e-01
 -3.63497295e-02 -1.44318740e+00 -8.32789905e-02 -9.17346333e-01
 -4.24752406e-02 -2.28470595e-01 -1.36624182e-01 -1.37247192e-01
  3.50003502e-03 -1.54975885e-01  1.00408548e-02 -8.02672018e-02
 -3.58222639e-01 -3.53207724e-01 -9.92359728e-01 -3.16520726e-01
 -7.20134089e-02  2.83797165e-01  1.90649617e+00 -1.54190012e+00
 -8.14432868e-01  1.01760714e+00  1.92609512e+00 -1.73920111e-01
 -9.99642512e+00]
supnorm grad right now is: 9.996425121235422
Weights right now are: 
[-2.14082753e+00  1.83295971e+00  1.34539124e+00  9.40770455e-01
  2.39539624e+00 -1.94165140e+00 -9.46453973e-01 -1.65679884e+00
  2.88675567e+00 -2.61149280e-01 -8.93722186e+00  3.59576011e+00
  1.98737826e+00  5.69298905e+00  1.29433355e+01  1.03236580e+00
  5.14579426e+00  4.09393210e+00  8.39175446e+00  4.66073465e+00
  4.88237975e+00  4.18214856e+00  8.34159076e+00  5.58110766e+00
  1.44642317e+00  2.00664445e+00  6.90103980e-03  6.41035891e+00
  2.14521172e+00  5.55723933e+00  4.89492959e+00  6.53425249e+00
  7.14425911e+00  6.47752138e+00  3.51357367e+00  6.70149552e+00
 -1.38607669e+00 -3.24503708e-01 -1.22616809e+00  8.85834319e+00
 -3.11323020e-01  2.57631769e-01 -2.58024758e+00  3.19784135e+00
  1.65742656e-01  4.89519921e+00 -2.64410099e+00  5.20396365e+00
  2.98388621e-02  4.69759893e+00  1.44775727e-01  3.49776228e+00
 -2.28172449e+00  1.13762431e+01 -5.08308702e+00  1.19412084e+01
  1.09788575e+01  1.84938082e+00  1.89417146e+00 -1.35698196e+00
  4.31819957e+00  3.06783575e+00  3.16220569e+00 -8.92375965e-01
  3.01445433e+01]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1705.3431789778635
gradient value of function right now is: [ 3.82092302e-01  1.30286875e+00  3.93357887e-01  3.12011040e-01
 -3.82092302e-01 -1.30286875e+00 -3.93357887e-01 -3.12011040e-01
 -9.80216590e-02 -1.21103057e-01 -9.81747257e-02  3.62522858e-01
 -1.07534458e-01 -1.10263603e-02 -4.98452910e-03 -2.26659639e+00
 -3.73338725e-03 -3.12729989e-04 -1.39538029e-04 -1.37955160e-01
 -1.42767314e-03 -1.65789410e-04 -4.68604422e-05 -7.03764104e-02
  1.97888531e-01  1.33315210e-01  1.06336161e-01  5.58332190e-02
  4.09100884e-02  3.91667530e-02  4.21329627e-02  1.57293666e-02
 -1.17699294e-02  3.21485507e-02  2.93738519e-02  1.15585060e-02
  3.97265070e-01  2.76164492e-01  1.52461247e-01  1.37835249e-01
  1.67541966e-01  5.16219834e-01  2.09489866e-01  4.73735478e-01
  9.76891365e-02 -2.38882549e-03  1.10600224e-01  2.60986940e-02
  5.28133602e-04  2.02191764e-02  2.63401758e-02  1.39022019e-02
 -1.26821906e-01 -1.59909182e-01 -3.24249526e-01 -1.38573272e-01
 -2.54876731e-02  1.21258360e-01  1.31408943e+00 -6.30251734e-01
 -4.26251469e-01  3.97639730e-01  9.96885354e-01 -1.14636440e+00
 -5.33865004e+00]
supnorm grad right now is: 5.338650035951962
Weights right now are: 
[-2.53084176  2.13206388  1.34609611  0.99883833  2.78541047 -2.24075557
 -0.94715884 -1.71486671  1.74094503 -1.35609951 -8.92453224  5.19199375
  3.82213497  7.77577807 20.22207362  1.54198013  8.75411598  6.36539372
 17.99276293  5.54074806  9.81156694  8.2594709  18.15998777  7.54881484
  3.49079697  1.52669539 -0.78779667  8.47108375  2.59445354  5.88141843
  3.25205114  8.46097594  8.87275872  4.85797486  0.68867606  3.05638139
 -1.37469948 -1.51974872 -5.37753316 10.28654376  2.5151499   0.8098243
 -3.73051334  2.56752395 -0.70007777  5.32595984 -2.95197924  6.74673278
  3.25188592  6.49568659  3.6911693   5.58566577 -2.45120655 15.02662081
 -5.5594262  15.73681287 18.00097062  2.81506871  2.65711633 -1.64567405
  4.54831255  2.43050291  3.38364073 -1.09382462 30.05022656]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1704.1510003864937
gradient value of function right now is: [ 2.63537662e+00  3.44612046e+00  2.36400234e+00  1.99923393e+00
 -2.63537662e+00 -3.44612046e+00 -2.36400234e+00 -1.99923393e+00
  1.96526348e-01  3.47168423e-01  1.20192184e-01  1.34537927e+00
  2.65663401e-03 -3.48605328e-02  1.21592632e-03 -2.19967788e+00
 -1.32145715e-04 -2.56504219e-03 -5.30463124e-05 -3.41027713e-01
 -7.84244138e-05 -9.67578139e-04 -4.53202249e-05 -1.99671029e-01
 -1.55522086e-02 -1.03853503e-03 -5.55960607e-03  5.36548063e-04
  4.40188297e-01  1.11505175e-01  6.36201168e-03  3.48809503e-02
  7.39509066e-02 -7.10121628e-03 -8.73102943e-03  8.74051528e-04
  1.08269613e+00  7.16303720e-01  1.79370384e-01  4.10872906e-01
 -1.08303240e-02 -7.88219688e-01 -4.51230155e-02 -6.23454753e-01
  2.09706817e-02  1.54785777e-02  4.99120109e-02 -5.05764534e-03
  2.62641952e-03  6.49615062e-02  2.32134762e-01  5.13527206e-02
 -3.26722545e-01 -2.80972795e-01 -1.31666879e+00 -3.08273675e-01
 -7.23921220e-02  2.94705960e-01  1.25419600e+00 -2.62833940e+00
 -1.80067811e+00  1.90482683e+00  1.55504419e+00 -2.24317148e+00
 -7.80871528e+00]
supnorm grad right now is: 7.808715275873538
Weights right now are: 
[-2.65388026  2.50934997  1.3005663   0.8903871   2.90844897 -2.61804166
 -0.90162903 -1.60641548  0.90435191 -2.50655969 -7.7098648   5.67627038
  5.46437693  9.03762522 26.11748249  1.85166154 12.74349762  8.73257262
 25.2271787   5.84677165 16.67871016 20.4250742  21.72633402  9.05556985
  6.46590072  1.64310382 -0.33593086  9.23655705  1.70741985  6.21414491
  1.4896804   6.88566385 11.3863693   2.97086294 -2.55003266  0.80463316
 -0.64003456 -1.80368162 -7.0272658  11.35984677  1.99065533  0.44728044
 -6.72407745  2.28640362 -0.29045064  5.42594071 -2.96797114  7.57782618
  8.09602597  7.5515236   2.98962313  4.31556612 -3.06543798 18.20253924
 -5.53617712 18.35894125 16.92079008  3.4070762   2.77381631 -1.95573325
  4.38477872  3.00541498  3.94042124 -1.11391595 30.20529671]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1705.1830949476894
gradient value of function right now is: [ 3.94268839e-01  7.96943570e-01 -6.33685009e-02 -1.26455103e-01
 -3.94268839e-01 -7.96943570e-01  6.33685009e-02  1.26455103e-01
  3.08045769e-01  6.60183816e-01  1.28849064e-01  1.22206558e+00
 -3.61240347e-03  5.66327705e-03 -2.54084195e-04 -2.21706011e+00
 -2.80299544e-05 -2.09677471e-04 -2.34296431e-06 -9.22833255e-02
 -3.98353411e-06 -4.55985859e-04 -4.34541782e-07 -6.63277817e-02
 -2.31758913e-02  8.68452504e-03  7.93175972e-03  2.85840738e-03
  3.43107409e-02  1.17121332e-01  1.16262461e-01  5.88503766e-02
  8.32150919e-02  2.34101633e-03  2.37836759e-03  1.12547717e-03
  1.44570017e-01  3.18017829e-01  1.46835333e-01  1.69389563e-01
  2.78175989e-02 -1.34538099e+00  2.95381265e-02 -1.06454759e+00
  1.26997769e-01  3.07432496e-02  1.56510304e-01  6.15191748e-02
  9.16463578e-04  2.98426201e-02  1.00670052e-01  1.59008550e-02
 -1.11349686e-01 -1.46372071e-01 -4.71230784e-01 -1.06707304e-01
 -3.36720772e-02  1.62464593e-01  1.31146610e+00 -8.21226652e-01
 -6.89538871e-01  5.56814059e-01  1.04233163e+00  3.04867806e-01
 -6.87227493e+00]
supnorm grad right now is: 6.872274932273659
Weights right now are: 
[-2.77125304  2.50699768  1.2900739   0.86868108  3.02582175 -2.61568937
 -0.89113663 -1.58470946  1.21528867 -3.53292335 -7.63229521  5.73538295
 10.95667765 11.56012796 32.59285937  1.69958761 20.3593067  10.29416844
 31.43904793  7.21057207 19.9308914  29.05062678 23.45150278  8.96700079
  8.80235423  1.61704202  0.05280915 10.06726343  1.78661633  5.76780355
  0.13617198  7.44329457 18.19212192  2.18422051 -2.94041857 -0.2745598
 -0.78311995 -1.39759831 -8.89147291 11.73034773  3.71528983  0.34181276
 -7.55675471  2.54270893 -0.69057583  5.81872509 -2.66777544  8.87698771
 10.09751973  7.49696879  3.89521643  2.76119763 -4.0500012  20.51084543
 -5.24974349 20.15903783 17.89892885  3.27470228  3.06519736 -1.66674596
  4.91729832  2.84437167  4.39119239 -1.18943224 30.14356151]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1704.9757059103183
gradient value of function right now is: [ 1.35111262e+00  2.86664327e+00  1.05925012e+00  1.04705935e+00
 -1.35111262e+00 -2.86664327e+00 -1.05925012e+00 -1.04705935e+00
  3.15358661e-02  2.23736167e-01  1.09893966e-02  1.11676484e+00
 -1.82119358e-03 -1.35605247e-01 -2.32840699e-04 -5.29645120e+00
 -7.12537038e-06 -9.80251410e-04 -2.85989007e-06 -1.48349922e-01
 -3.10349257e-06 -5.55491960e-04 -2.72775814e-06 -1.45578621e-01
  9.31588790e-03  7.56416668e-03  6.52318456e-03  1.96425044e-03
  1.41007844e+00  4.30980507e-01  2.30164181e-01  7.42606616e-02
  8.02997465e-03  3.82454901e-03  3.45501287e-03  2.13172177e-03
  9.51457559e-01  6.97272760e-01  2.80954448e-01  2.85516381e-01
 -2.06168275e-02 -3.19388349e-01 -8.46907746e-02 -2.33965383e-01
 -8.04527015e-02 -2.37889229e-01 -3.03948070e-01 -1.50423770e-01
  1.63641769e-03  8.98251308e-02  2.00049360e-01  3.80156109e-02
 -1.65132958e-01 -2.06257839e-01 -6.61047566e-01 -1.27636188e-01
 -4.68219122e-02  2.52129634e-01  2.16052856e+00 -1.84701161e+00
 -1.31987335e+00  1.28993655e+00  1.51257582e+00 -1.56239039e+00
 -1.15317966e+01]
supnorm grad right now is: 11.53179659781497
Weights right now are: 
[-2.80209642  2.63143672  1.33266649  0.85789078  3.05666513 -2.74012841
 -0.93372922 -1.57391916  1.11699289 -4.04567273 -9.48100256  6.01979766
 16.78154098 13.28943767 39.00559298  1.68010767 24.91732595 15.07968318
 32.48358948  7.4755675  20.63085735 41.5543488  24.11542856  7.55014862
 11.98623912  1.62275957 -0.48543332  8.12619988  2.00350864  6.24640329
 -0.19749337  7.25308391 24.33846819 -1.24348817 -4.85818425 -4.99066872
 -0.83430932 -0.85326602 -9.54869264 12.20351612  3.09838688  0.35453115
 -8.23542004  2.95441667 -1.28142013  5.29197443 -2.87231187  9.65543208
 12.67576949  8.48380187  3.9314675   1.96733142 -4.22375745 23.13801859
 -4.61900012 22.36801799 19.01748656  2.96555358  3.06943145 -1.73116358
  4.87402125  2.58068039  4.50093304 -1.5328995  30.13921794]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1705.5215612632985
gradient value of function right now is: [ 1.65976029e+00  1.84232993e+00  1.55494893e+00  1.55650664e+00
 -1.65976029e+00 -1.84232993e+00 -1.55494893e+00 -1.55650664e+00
 -7.49320057e-03  9.56005478e-02 -7.70586099e-03  2.82719572e-01
  7.75551444e-05  2.69982083e-02 -9.43705068e-05 -4.90088019e-01
 -7.37914732e-08 -7.78224374e-05 -1.48696558e-06 -2.43325115e-02
 -1.07027009e-07 -9.48415855e-05 -1.72642642e-06 -2.71226702e-02
 -4.34791927e-03 -6.54310799e-04 -6.78840653e-04  1.13590666e-04
 -7.20876638e-02 -4.79930405e-02 -9.32478151e-02  3.03627110e-03
 -2.97784004e-03  1.80929519e-03  1.58341010e-03  1.22962144e-03
  2.01916357e-01  1.72490042e-01  3.79743656e-02  6.46195915e-02
  7.96162301e-03  7.06159592e-02  3.37274362e-02  9.73376804e-02
 -9.33092690e-02  2.32327141e-02 -1.34115002e-01 -2.69580598e-02
  7.46388887e-04 -3.74996464e-02  1.24192727e-02 -1.69344103e-02
 -5.33240200e-02 -2.90763094e-02 -1.64264701e-01 -2.62633658e-02
 -3.24751621e-02  1.36120076e-01  1.15863651e-01 -5.28841249e-01
  8.19798442e-03  3.42370139e-01  3.61679639e-02 -6.28063985e-01
 -9.08783224e-01]
supnorm grad right now is: 1.842329933698653
Weights right now are: 
[ -2.70021256   2.69961326   1.33710465   0.88190483   2.95478127
  -2.80830495  -0.93816738  -1.59793321   2.01542265  -4.26865781
 -10.07512941   5.97088469  23.88128685  15.43722464  40.41509365
   1.65479511  25.65944708  20.35542148  38.83283586   8.5201267
  20.89135513  50.72830885  30.73675918   8.27219713  15.42110314
   1.27241129  -1.69694764   8.95202228   2.35979559   6.20937142
  -0.74130444   7.3250017   30.60226975  -3.48857107  -6.74706135
  -9.26937425  -1.09942659   0.11620298 -10.21006005  12.75250384
   4.7346219    0.47707177  -8.220867     3.43445461  -2.95517457
   5.85033045  -2.75673191  10.77619301  16.03272689   8.41806368
   3.67038495  -0.57407012  -4.24974086  24.64152083  -4.89098054
  23.98042191  17.80821816   2.96114093   3.0857533   -1.75653619
   5.16858648   2.73149073   4.74317042  -1.24795691  30.13770713]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -1702.777126602758
gradient value of function right now is: [ 1.99263124e+00  4.22808528e+00  1.48694707e+00  1.50828115e+00
 -1.99263124e+00 -4.22808528e+00 -1.48694707e+00 -1.50828115e+00
  5.22723461e-02  4.51178569e-01  3.16662578e-03  1.67365940e+00
 -4.03418797e-04 -1.46194255e-01 -3.21567099e-04 -8.36554610e+00
 -4.10515843e-07 -2.74102427e-04 -4.18090910e-06 -1.17698965e-01
 -4.66066772e-07 -2.62777610e-04 -5.31089567e-06 -1.42784223e-01
 -1.66641168e-02  3.15082874e-03  2.54818132e-03  1.24305995e-03
  2.05866576e+00  4.85143839e-01  3.21600201e-01  1.17675011e-01
  1.43186215e-02  6.52344324e-03  5.84177569e-03  4.42369169e-03
  1.18979987e+00  8.92830026e-01  4.02189088e-01  4.08387332e-01
 -5.18207881e-02 -6.18100134e-01 -1.80629508e-01 -4.05391961e-01
 -1.28583893e-01 -2.65738058e-01 -4.08726721e-01 -1.56798491e-01
  3.95931966e-03  1.13193946e-01  2.69718764e-01  2.84938094e-02
 -2.35085049e-01 -2.74725869e-01 -8.61167386e-01 -1.46723351e-01
 -1.06315209e-01  4.81727614e-01  3.16630903e+00 -2.44732312e+00
 -1.87330828e+00  1.66732621e+00  2.14297423e+00 -1.99054706e+00
 -1.93098303e+01]
supnorm grad right now is: 19.309830270560475
Weights right now are: 
[-2.73910879e+00  2.64933504e+00  1.33196699e+00  8.95997470e-01
  2.99367750e+00 -2.75802673e+00 -9.33029721e-01 -1.61202585e+00
  3.09817393e+00 -4.09107355e+00 -1.14770950e+01  6.04756510e+00
  2.80332256e+01  1.74123997e+01  4.29367023e+01  1.59261480e+00
  2.57229326e+01  2.58766654e+01  4.21773980e+01  8.63420008e+00
  2.09549476e+01  5.91924657e+01  3.42340017e+01  8.17152317e+00
  1.74984365e+01  1.24426913e+00 -4.17094614e+00  8.37188044e+00
  2.62458515e+00  6.58084649e+00 -1.29625182e+00  7.87249019e+00
  3.63225233e+01 -7.59238667e+00 -6.46391444e+00 -1.50354993e+01
 -1.46318322e+00 -1.40436232e-03 -1.00381605e+01  1.24538072e+01
  3.84657698e+00  6.17281928e-01 -9.40744303e+00  3.54780312e+00
 -3.09586870e+00  6.21633740e+00 -2.49030513e+00  1.24811868e+01
  1.35442188e+01  1.01097767e+01  3.93339602e+00 -1.98111273e+00
 -4.71363742e+00  2.55829763e+01 -4.89840110e+00  2.52608355e+01
  1.73568007e+01  3.08503210e+00  3.16957639e+00 -1.82545647e+00
  4.93947063e+00  2.49124726e+00  4.96210650e+00 -1.57292218e+00
  3.00305493e+01]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1724.6990110778238
gradient value of function right now is: [-9.02809627e-01 -3.73037168e-01 -7.67343278e-01 -9.18549055e-01
  9.02809627e-01  3.73037168e-01  7.67343278e-01  9.18549055e-01
  7.71039406e-02  1.00689255e+00 -7.34591443e-02  2.09487783e+00
 -3.52044891e-03 -1.32711262e-01  6.84097728e-02 -3.35984824e+00
  3.72524911e-07  1.54705179e-05  1.57711083e-02  7.37435667e-02
 -2.08992854e-06 -6.64338589e-05  2.39314136e-02  7.73428166e-02
  2.76732878e-02  5.14448809e-02  3.49287110e-02  2.27645137e-02
  2.66279372e+00  7.12507821e-01  3.11087003e-01  9.54945772e-02
 -5.61014612e+00 -5.20184302e+00 -3.52572090e-01 -5.35998460e+00
 -7.96547553e-01  1.69937554e-01  7.57857474e-02 -1.36928885e-01
  1.61650291e-02 -1.44840068e+00  3.64419929e-01 -6.15200804e-01
 -3.93232866e-01 -3.24463485e-01 -3.87098195e+00 -1.99100685e-01
 -2.29356034e-02  6.95198838e-02 -5.72857239e-01  2.19034133e-02
 -9.31775648e-01 -1.42392820e-01 -4.22370956e+00 -1.67914493e-01
 -1.12129201e-01  9.74568475e-01  1.67932148e+00 -4.27484582e+00
 -4.54609142e+00  1.05186276e+01  2.18763645e+00 -5.56549247e+00
 -1.25168632e+01]
supnorm grad right now is: 12.516863217361363
Weights right now are: 
[-3.26054786e+00  3.81382092e+00  1.45819077e+00  1.14726411e+00
  3.51511657e+00 -3.92251261e+00 -1.05925350e+00 -1.86329249e+00
  3.95763265e+00 -4.37200403e+00 -1.27091373e+01  5.86998409e+00
  3.53841295e+01  2.00199953e+01  4.48326810e+01  2.14125276e+00
  2.58887250e+01  3.92121254e+01  4.80526231e+01  1.04066026e+01
  2.02623265e+01  7.59109843e+01  3.86901626e+01  7.53498812e+00
  1.73851787e+01 -4.99191130e+00 -1.14132385e+01  2.50148084e+00
  2.33146192e+00  4.44295144e+00 -3.00851888e+00  4.58030279e+00
  3.41688258e+01 -1.17509832e+01 -3.95524126e+00 -2.00437591e+01
 -1.36274702e+00  3.67448167e-01 -9.22548763e+00  4.63626211e+00
 -1.14584184e-02  5.10255416e-01 -7.46377134e+00  3.49913370e+00
 -2.21356243e+00  6.33302702e+00 -3.50059528e+00  1.12516742e+01
  5.17831925e+00  1.08358817e+01  3.39677791e+00 -3.66547691e+00
 -8.41587177e-01  3.20411260e+01 -5.26252122e+00  2.83377000e+01
  1.77390966e+01  1.23856250e+00  2.06912037e+00 -2.74177100e+00
  3.60934157e+00  1.57815858e+00  4.35588475e+00 -2.07220108e+00
  2.99877030e+01]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1724.5128474003286
gradient value of function right now is: [-7.22320696e-01 -1.19285387e+00 -1.22979575e-01 -2.38438499e-01
  7.22320696e-01  1.19285387e+00  1.22979575e-01  2.38438499e-01
 -4.58548063e-02  5.97812150e-03 -8.39163893e-02 -1.22702224e+00
 -1.46281225e-03  1.80472538e-02  7.61666229e-02  3.23147374e+00
 -2.01669104e-08  1.46565869e-05  3.00053553e-03  8.34869666e-02
 -1.28429524e-06  4.16775459e-05  9.94909298e-03  2.48056171e-01
  4.69059151e-02  2.51536975e-02  1.84693059e-02  1.49730941e-02
 -3.62677213e-01 -1.48086785e-02  8.50580955e-02  3.61646440e-02
 -4.51386881e+00 -3.97571670e+00 -8.95560292e-01 -4.37737120e+00
 -1.01502451e+00 -4.34072627e-01  5.12840612e-02 -1.91468298e-03
  4.23639868e-02 -2.80068239e-02  1.62852343e+00  2.51923682e-01
 -9.64414429e-02 -2.69583244e-02 -3.62680058e+00 -2.09069677e-03
 -4.20912409e-02 -4.69813347e-02 -3.03031489e-01 -4.72489634e-02
  2.51261261e-01  3.46082411e-05 -1.71220045e+00  3.36256407e-02
  2.14521697e-02 -7.52878520e-02  9.41666732e-01 -1.18074647e+00
 -2.72064629e+00  6.97293154e+00  4.25022374e-01 -1.68589580e-01
  3.68259661e+00]
supnorm grad right now is: 6.9729315386595525
Weights right now are: 
[ -3.34757121   4.53611449   1.58962882   1.7112711    3.60213992
  -4.64480618  -1.19069155  -2.42729949   5.10991246  -4.82083667
 -11.3120119    5.91361119  35.53769729  22.80582596  44.78953005
   2.23048278  26.20222759  45.66400952  51.62121641  10.39730863
  19.17007447  89.05062375  39.70575642   8.17395802  19.15955879
  -4.93661177 -11.53215115   1.32337134   2.43599232   4.59513944
  -2.35146287   5.46369068  34.05423078 -11.71432186  -1.11084859
 -20.21363205  -0.90646137  -0.79249892  -6.82423703   4.09863019
  -1.9012684   -0.10168841  -6.67930455   4.3903177   -1.74029336
   7.16599131  -3.30931459  12.3717258    6.92040316   9.05105977
   2.04773043  -1.48080877  -0.838106    36.38111504  -6.04629628
  28.85572626  18.71921912   1.59905682   1.90274607  -2.81794958
   3.27783857   1.51896339   5.12869909  -1.98780729  30.10800704]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1722.0525912729765
gradient value of function right now is: [ 3.59142374e-01  5.46377422e-01  1.27523115e-03  4.88607908e-03
 -3.59142374e-01 -5.46377422e-01 -1.27523115e-03 -4.88607908e-03
  1.38745357e-01  9.64438766e-02  3.87013586e-01  1.14744580e+00
  7.62694743e-03  2.63823453e-02 -5.98665198e-02 -2.90922053e+00
 -3.10634577e-08  5.43205596e-06  5.49361395e-05  2.76862975e-03
  1.42457819e-08 -1.39452803e-06 -3.92325189e-05 -1.43372629e-03
 -2.12201873e-01 -1.26836109e-01 -9.57593624e-02 -7.59296367e-02
  8.34216832e-01 -6.08988841e-01 -8.93136544e-01 -2.85809069e-01
  5.81201570e+00  4.91550634e+00  3.98205714e-01  5.50699236e+00
 -8.25514733e-01 -1.36991467e+00 -2.18937550e-01 -1.82351467e+00
 -1.57660422e-01 -5.80809865e-02 -1.29021977e-01 -7.03033205e-01
  1.10271859e+00  3.21156504e-01  6.23308916e+00  1.63899716e-01
  1.21562063e-02 -7.87538247e-02 -2.18492811e-01  2.76080372e-02
  1.12419695e+00  1.40431355e-01  4.50353201e+00  2.45779869e-01
  1.58005080e-01 -1.77276598e+00 -1.78017099e+00  6.77397654e+00
  5.89688987e+00 -1.75572735e+01 -2.03116964e+00  1.23154070e+01
  1.22553790e+00]
supnorm grad right now is: 17.557273507552875
Weights right now are: 
[-3.86447774e+00  5.91401175e+00 -1.86531802e+00 -8.02915086e-02
  4.11904645e+00 -6.02270344e+00  2.26425528e+00 -6.35736874e-01
  6.96550350e+00 -5.44363583e+00 -1.27457413e+01  6.65413347e+00
  3.61607579e+01  2.42304483e+01  4.50503117e+01  1.62332782e+00
  2.62837667e+01  4.74402135e+01  5.74706549e+01  1.26138381e+01
  1.94957914e+01  9.68786136e+01  3.31984041e+01  1.05601118e+01
  1.99732126e+01 -5.93059074e+00 -1.22810626e+01 -7.31219741e-01
  2.43852548e+00  3.44324470e+00 -2.06550256e+00  3.00035110e+00
  3.33675324e+01 -1.25372428e+01 -1.95928164e+00 -2.10378925e+01
 -6.89891373e-01 -2.50994308e+00 -6.84809600e+00  3.12936205e+00
  2.15883375e+00 -1.63847425e-01 -8.39613617e+00  3.83166600e+00
 -7.92492064e-01  6.31499239e+00 -2.77413533e+00  1.23240965e+01
  8.58757790e+00  1.05042232e+01  2.21765870e+00  2.83757685e+00
 -1.16339465e+00  3.79831539e+01 -5.89948321e+00  2.81779200e+01
  2.03360130e+01  1.19043621e+00  1.94233548e+00 -2.61892431e+00
  3.99125473e+00  1.49251312e+00  4.57614184e+00 -1.75289121e+00
  2.99454887e+01]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1724.6501923409662
gradient value of function right now is: [ 2.57926421e-01  1.17391140e-01  7.12903771e-07 -5.61119810e-06
 -2.57926421e-01 -1.17391140e-01 -7.12903771e-07  5.61119810e-06
  5.83166459e-02  1.02105712e+00 -2.22873486e-01  1.12243225e+00
 -1.25214169e-03 -6.81245734e-02  2.41505591e-02 -1.91087442e+00
  6.85417692e-09 -7.54898257e-07 -1.55011862e-07 -1.71978916e-05
  2.31576091e-09  2.06155434e-08 -7.12055235e-06 -5.00413726e-05
 -1.78561296e-02  2.23494232e-02  1.46128371e-02  1.40405575e-02
  2.06011499e+00  6.28133601e-01  3.57173723e-01  2.69516456e-01
 -3.53887998e+00 -2.81006094e+00 -1.88246605e-01 -3.39728951e+00
 -4.84753644e-01  1.41707097e+00  9.08765349e-02  1.68448999e+00
 -1.50087578e-04 -1.98520759e+00  1.31340703e-01 -6.70295566e-01
  1.12774174e-01 -1.85159780e-01 -4.60512845e+00 -4.99988321e-02
  4.50624529e-03  1.38876901e-02  5.62775406e-01  1.08741363e-02
  8.04037358e-02 -6.21127161e-02 -2.83748688e+00 -5.80225285e-02
 -1.78705096e-02  4.55705074e-02  1.51683410e+00 -2.71374873e+00
 -5.40886022e+00  1.26034244e+01  2.54562804e+00 -1.51369716e+00
 -7.74390325e+00]
supnorm grad right now is: 12.603424388975528
Weights right now are: 
[ -4.33802959   8.0829224   -5.80295697  -4.14645207   4.5925983
  -8.19161409   6.20189424   3.43042368   8.29345609  -5.59323077
 -13.88811664   7.53898205  37.24240592  25.38593547  43.75172386
   2.1205855   26.28435261  48.72434779  52.90848374  13.62551695
  19.49643913  97.0637144   35.33101919  13.35347573  21.43480748
  -7.03442888 -13.03756773  -0.66999215   2.3400058    3.04458048
  -0.61082347   3.00756466  32.78579228 -13.12162684  -0.24734875
 -21.74209807  -0.73521171  -2.92549515 -11.42171117   2.89314845
   1.88658744  -0.48788399  -8.25605624   4.77145624  -0.7404922
   5.86977262  -2.22626184  13.23300901   8.94592816  11.50888521
   4.09785428   2.73870998  -0.96885564  38.87050029  -5.31737299
  27.01261559  20.24860027   0.87703911   1.39731723  -2.99122095
   3.82545755   1.55209198   4.2278347   -1.95133532  30.0017003 ]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1724.4288907954592
gradient value of function right now is: [ 8.99773224e-02 -1.38408549e-01 -3.16647163e-05 -2.37248043e-05
 -8.99773224e-02  1.38408549e-01  3.16647163e-05  2.37248043e-05
 -7.00355011e-02 -5.16053573e-03  2.09340568e-01  6.02859868e-01
  1.12678740e-02  1.06033683e-01 -4.27546214e-02  2.01654195e+00
 -1.55015308e-06 -6.40933043e-06  2.30308887e-05 -7.89506110e-04
 -1.08477560e-06 -8.90826418e-07  2.33857478e-05 -5.08505221e-04
 -2.73289267e-01 -2.13089078e-01 -1.52816562e-01 -1.51916047e-01
 -1.50535506e+00 -5.77329197e-01 -3.38478955e-01 -1.15296369e-01
  4.52562345e+00  3.66499576e+00  2.22420613e-01  4.23245747e+00
 -1.14159545e+00 -1.05717525e+00 -2.64633488e-02 -1.20609997e+00
 -2.60502623e-02  9.32614280e-01 -4.57856586e-01  3.90108228e-01
  3.57983438e-01  3.83020559e-01  5.43027587e+00  1.40041907e-01
 -1.44553769e-02  2.36896522e-02 -7.62371992e-01 -9.36519278e-03
  4.58994584e-01  7.69775297e-02  4.68424615e+00  1.43024736e-01
  6.65254304e-02 -9.32459846e-01 -1.60242187e+00  3.99095219e+00
  5.55583563e+00 -1.60169374e+01 -1.59595046e+00  5.59068682e+00
  6.38177634e+00]
supnorm grad right now is: 16.016937402221565
Weights right now are: 
[ -4.54091716   9.36117839 -14.21962726 -12.43978691   4.79548587
  -9.46987008  14.61856453  11.72375852   7.59968287  -4.86592764
 -14.44789471   7.90593263  38.32807609  26.86153408  43.82363854
   2.10266343  26.29687627  49.00350011  43.13410493  11.5340811
  19.52501938  96.27748616  35.52199974  11.47578256  22.38726608
  -8.60116952 -13.9892871   -2.13941095   2.17155799   3.36984102
   1.43074049   3.23861303  32.66524749 -12.86216224   2.50020621
 -21.76811315  -0.4563923   -3.6606908  -16.91818385   2.63507673
   0.11887054  -0.32257721  -8.05088206   4.68312414  -1.16022015
   4.50098739  -2.30692428  12.35082136   8.86964113  10.43865805
   4.19383565   2.0308975   -0.79857051  41.42947008  -4.92892742
  26.63427972  20.67884118   0.18588536   1.28366724  -3.10004764
   4.25249841   1.47682842   4.28997348  -2.14790501  30.03951336]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1723.3758085152313
gradient value of function right now is: [-2.76631039e-01 -6.94767215e-01 -1.76019818e-04 -7.75885955e-05
  2.76631039e-01  6.94767215e-01  1.76019818e-04  7.75885955e-05
 -2.05859505e-01 -8.76302355e-01 -1.16247202e-01 -1.45334581e+00
 -1.52780951e-03  2.65764295e-01  1.94654553e-02  1.16739412e+01
  6.40295836e-07 -1.34831503e-04  5.91095416e-05 -7.37951197e-03
  3.14264779e-07 -2.43869922e-05  4.46243291e-05 -3.25545105e-03
  1.16163949e-01  3.27921169e-02  2.19519565e-02  2.90785896e-02
 -6.88200092e+00 -2.20848108e+00 -3.05464925e-01 -4.42842567e-01
 -6.30700506e-01 -3.91550132e-01 -1.41306385e-01 -5.05484404e-01
 -1.41492198e+00 -1.42366843e+00 -7.15365044e-02 -1.10824450e+00
  1.39434406e-01  2.00506108e+00  1.30517227e+00  1.38798898e+00
  3.60096831e-01  2.87458660e-01  2.58207951e-01  2.99459419e-01
 -1.50209098e-02 -2.27414722e-02 -5.90248358e-01 -5.45071825e-02
  3.80852004e-01  8.90659139e-02  1.17640267e+00  2.23383703e-01
  3.36359816e-02 -9.78741988e-01 -5.41980045e-01  3.44816169e+00
 -2.61923626e-01  4.08752059e-01 -1.46523063e+00  6.63633138e+00
  1.30433994e+01]
supnorm grad right now is: 13.043399447646895
Weights right now are: 
[-5.13000067e+00  1.00676933e+01 -2.06207393e+01 -1.85780860e+01
  5.38456938e+00 -1.01763850e+01  2.10196766e+01  1.78620576e+01
  8.09920935e+00 -4.84721284e+00 -1.46161488e+01  7.56245761e+00
  3.92852900e+01  2.80163531e+01  4.38930363e+01  2.30849889e+00
  2.66925668e+01  4.90919246e+01  3.97883842e+01  1.10157681e+01
  1.98495290e+01  9.42799353e+01  3.73876066e+01  1.12501914e+01
  2.22733270e+01 -9.67258974e+00 -1.40387756e+01 -1.52392907e-01
  2.34235675e+00  2.77923189e+00  8.79591216e-01  3.28930265e+00
  3.24307928e+01 -1.26638542e+01  3.32611930e+00 -2.19297456e+01
 -4.96530455e-01 -3.72586849e+00 -2.29597399e+01  3.06399147e+00
  2.52744793e+00 -3.67702814e-02 -6.92628663e+00  4.42435392e+00
 -1.26470829e+00  4.16930739e+00 -2.23911376e+00  1.33171024e+01
  9.99264922e+00  9.93619776e+00  4.59146742e+00  2.40619921e+00
 -5.70875972e-01  4.47647415e+01 -5.05347485e+00  2.66699993e+01
  2.15927343e+01 -4.51772786e-01  1.15287214e+00 -3.18311940e+00
  4.05975372e+00  1.53142862e+00  4.10239492e+00 -2.00610457e+00
  2.99810789e+01]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -1716.2800835984954
gradient value of function right now is: [-7.16722936e-01 -2.25327224e-01 -7.13975460e-05 -3.84449046e-05
  7.16722936e-01  2.25327224e-01  7.13975460e-05  3.84449046e-05
 -1.98583205e-01 -1.76901170e+00 -4.37248252e-01 -4.20290517e+00
 -4.41767377e-03  9.92735640e-02  1.46774681e-02  3.64784248e+00
  6.25085907e-07 -8.13100714e-05 -5.80393971e-05 -2.85075204e-03
  3.29980989e-07 -7.59085891e-06 -4.80671402e-05 -1.45732636e-03
  2.51513699e-01  9.05968186e-02  5.03065036e-02  5.68929608e-02
 -4.45407879e+00 -6.08609684e-01  2.52131443e-02 -9.03556219e-02
 -4.64780058e+00 -3.63251654e+00 -1.02445360e-01 -4.24493948e+00
  4.35504791e+00  1.45513088e+00  3.15323719e-02  2.03029474e+00
  1.32895458e-01  2.56199253e+00  1.43820000e+00  1.58881475e+00
  4.37735992e-02 -1.31197061e-03 -5.02702429e+00 -1.65034640e-02
  1.93882224e-03 -1.95165621e-02  9.78951802e-01  7.39024798e-03
  3.81143459e-02 -2.28108901e-02 -4.95461990e+00 -8.76953155e-02
 -9.30855208e-03  2.91682759e-02  7.21442766e-01 -2.25735157e+00
 -4.72707850e+00  1.89627481e+01 -9.43049171e-03 -7.09063354e+00
  1.26049413e+01]
supnorm grad right now is: 18.96274811649283
Weights right now are: 
[ -5.7580229   10.77373421 -24.43459788 -22.44977171   6.01259161
 -10.8824259   24.83353515  21.73374333   8.86859427  -5.2472788
 -14.98594651   7.13793664  40.63306343  29.20728369  43.50625091
   2.49682844  27.19483243  48.08047687  38.22550676  12.16348196
  20.21019057  92.32262456  37.50149299  12.38002677  21.50100971
 -11.26828419 -14.38756429   0.33215367   2.36003004   2.92779908
   0.83480489   3.90201187  32.11861067 -12.65604446   5.04433629
 -22.25861849  -0.28199732  -3.7560606  -26.7187055    3.21412577
   0.26398194  -0.11292262  -7.20437661   4.16498513  -1.00971885
   4.16866317  -2.39929955  13.81011727  11.90429831  10.52322709
   5.72788187   3.27412768  -0.50260036  47.68020921  -4.89177809
  26.08648959  22.76885788  -0.32773891   0.73611536  -3.43016957
   3.96648237   1.46152686   3.98314743  -2.09582526  30.19986015]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1725.5535440198162
gradient value of function right now is: [-2.01215248e-01 -1.00133421e-01  1.39926847e-05  1.67513611e-05
  2.01215248e-01  1.00133421e-01 -1.39926847e-05 -1.67513611e-05
 -1.78846519e-01 -9.38099241e-01  1.42169005e-02 -1.02174287e+00
  3.38732397e-02  1.04255060e-01 -3.21658734e-02  2.22925412e+00
 -8.55321069e-06 -2.38790205e-05  4.46287170e-05  5.31874004e-04
 -6.41915620e-06 -1.12572879e-06  3.58530702e-05  6.16197339e-04
 -7.32775018e-01 -6.52139722e-01 -4.07026213e-01 -4.03018762e-01
 -2.63914390e+00 -7.51387792e-01 -3.07459592e-01 -6.97136862e-02
  2.69131764e+00  2.14019519e+00  7.12201610e-03  2.49525314e+00
  6.84873470e-01 -2.54087299e-01 -5.47280923e-03 -3.22833918e-01
 -1.20187165e-02  2.20468475e+00  7.63235572e-02  1.16877476e+00
  2.52666163e-01  2.29312272e-01  3.95156697e+00  2.30461089e-01
 -9.35863387e-04 -5.83497673e-02 -5.57118492e-01 -1.75652623e-02
  2.97258113e-01  5.33849404e-02  4.08814874e+00  1.66704031e-01
  5.11762871e-02 -7.68831497e-01 -6.34692217e-02  2.75169766e+00
  6.79774028e+00 -1.43279410e+01 -2.37239375e+00  6.68340427e+00
  8.29648304e+00]
supnorm grad right now is: 14.327941044458463
Weights right now are: 
[-5.76636784e+00  1.14597389e+01 -2.92680497e+01 -2.72622437e+01
  6.02093655e+00 -1.15684306e+01  2.96669870e+01  2.65462153e+01
  8.50376459e+00 -4.91641168e+00 -1.48480983e+01  7.66468048e+00
  3.98311900e+01  2.94621915e+01  4.41559258e+01  2.32997357e+00
  2.77031781e+01  4.77091821e+01  3.97851713e+01  1.18670322e+01
  2.05943522e+01  9.01660463e+01  3.95946349e+01  1.20225178e+01
  2.20434444e+01 -1.14696523e+01 -1.29034512e+01 -1.16110083e+00
  2.38347925e+00  3.02980866e+00  1.16433986e+00  4.53470044e+00
  3.20774003e+01 -1.22091472e+01  7.06496842e+00 -2.22056981e+01
 -5.61661497e-01 -4.25971386e+00 -3.04784965e+01  3.10456780e+00
 -1.81609233e-01  1.08869204e-01 -6.79384925e+00  4.05889345e+00
 -1.68521670e+00  2.86177570e+00 -2.21306426e+00  1.53165057e+01
  1.25053581e+01  1.13393367e+01  6.05030188e+00  6.46262127e-01
 -1.03481271e+00  5.02273368e+01 -4.62857953e+00  2.60044242e+01
  2.45710953e+01  1.30682066e-02  1.10754572e+00 -3.40706966e+00
  4.31204362e+00  1.44187705e+00  3.93398440e+00 -2.06846931e+00
  2.99571861e+01]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1721.6594491167057
gradient value of function right now is: [-1.25864180e-01 -9.82281044e-01 -1.26941763e-04 -7.47307799e-05
  1.25864180e-01  9.82281044e-01  1.26941763e-04  7.47307799e-05
 -9.87124922e-02 -2.46158452e-01 -1.06880903e-01 -9.62888751e-01
  2.75181055e-04  3.01646816e-01  2.26783744e-02  1.99601843e+01
  1.00182535e-07 -6.62321270e-05 -1.39473032e-05 -7.50410860e-03
  1.09426062e-07 -1.44018554e-05 -9.06844231e-06 -4.06583276e-03
  1.74100232e-02  4.61299449e-04  4.60352994e-03  2.28990646e-02
 -7.01579311e+00 -2.97186157e+00 -4.57239635e-01 -6.56556635e-01
 -1.29192687e+00 -9.59438017e-01 -2.74063699e-02 -1.12159252e+00
 -2.73026562e+00 -1.86482510e+00 -2.87742851e-02 -1.57349127e+00
  8.11925179e-02  1.42109140e+00  1.43708542e+00  8.33061445e-01
 -4.80285391e-02  4.08555724e-01 -2.08907717e+00  2.78557713e-02
 -9.58262534e-03  1.20284324e-02 -2.66231330e-01 -2.78589480e-02
  2.35759345e-01  6.80041374e-02 -3.35869919e-03  1.22867170e-01
  7.54439074e-03 -2.08682792e-01 -1.72947910e+00  2.65073839e+00
  1.04569872e+00  5.33022867e-01 -9.56391233e-01  9.04662646e-01
  1.72585889e+01]
supnorm grad right now is: 19.96018428690252
Weights right now are: 
[-5.74960188e+00  1.17471059e+01 -3.27486038e+01 -3.07188965e+01
  6.00417059e+00 -1.18557976e+01  3.31475410e+01  3.00028682e+01
  8.67071408e+00 -4.18977886e+00 -1.51195691e+01  7.19893684e+00
  3.87109127e+01  2.96603184e+01  4.41345930e+01  2.52115489e+00
  2.80243368e+01  4.70098098e+01  3.95738525e+01  1.22262451e+01
  2.09366130e+01  8.82201757e+01  3.94795988e+01  1.25912846e+01
  2.27087968e+01 -1.08870177e+01 -1.06314268e+01  7.62291525e-01
  2.70480550e+00  2.88679253e+00  1.16270393e+00  3.23620449e+00
  3.18312495e+01 -1.19164221e+01  1.13695204e+01 -2.22749470e+01
 -8.77277168e-01 -4.49487345e+00 -3.44615820e+01  3.06526393e+00
  1.56365050e+00  3.17977276e-01 -6.18145706e+00  3.90577439e+00
 -2.13664875e+00  3.66818518e+00 -2.41320358e+00  1.61838886e+01
  1.23200668e+01  1.18392702e+01  7.07950152e+00 -3.06055600e+00
 -8.98295556e-01  5.33315323e+01 -4.99610852e+00  2.62643526e+01
  2.53816083e+01 -8.61088036e-02  7.62718994e-01 -3.57971114e+00
  4.25285291e+00  1.36590582e+00  4.75038965e+00 -2.10790367e+00
  3.01372035e+01]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1723.7014850644478
gradient value of function right now is: [-1.92208953e-01 -1.60287126e-01 -2.29238010e-05 -1.40177088e-05
  1.92208953e-01  1.60287126e-01  2.29238010e-05  1.40177088e-05
 -1.76036049e-01 -5.35618629e-01 -3.20475082e-01 -1.31137848e+00
 -4.17724590e-03 -2.82550200e-02  3.69141398e-02  2.98012005e+00
  1.81148448e-07 -2.70933675e-06 -1.71286608e-05 -1.27779656e-03
  6.59930604e-08 -8.32036909e-07 -9.89351554e-06 -7.19105428e-04
  1.82319983e-01  7.61737718e-02  4.47246952e-02  4.03940658e-02
  7.28023711e-02  3.15470095e-01  1.06019786e-01 -7.52185574e-02
 -3.93259292e+00 -2.88684748e+00 -1.23141656e-02 -3.45332763e+00
 -2.32157185e-01 -1.11070650e-01 -9.26344833e-04 -5.99694251e-03
  1.02156544e-01  7.77065924e-01  1.90833732e+00  9.71711660e-01
 -2.06313236e-01 -3.66760453e-01 -6.01489878e+00 -2.67264706e-01
 -1.66275108e-04 -2.00760179e-02  1.75810064e-01 -1.11328603e-03
 -1.57330561e-01 -5.93982008e-02 -5.76113791e+00 -2.14113878e-01
 -3.57724397e-02  5.39347193e-01  1.29326738e+00 -4.34372661e+00
 -2.72135328e+00  1.49018562e+01  1.58571050e+00 -1.27153349e+01
  4.79987597e-01]
supnorm grad right now is: 14.901856244832272
Weights right now are: 
[ -6.32244027  12.61960065 -33.48530371 -31.31411285   6.57700898
 -12.72829234  33.88424098  30.59808446   9.16784296  -4.62044613
 -14.7741962    7.01784483  39.26806285  30.10562148  44.6227644
   2.42172272  28.12143436  46.43664915  38.49262614  13.37256375
  21.02660746  87.76483434  38.65591157  13.89875926  22.65236267
 -11.53147967 -10.06364264   1.96285031   2.73585045   2.871723
   1.85072831   3.27731521  31.29725059 -11.88453704  14.99937714
 -22.59783836  -0.9973076   -4.76306325 -37.09332023   3.6274193
   0.46493385   0.58755151  -6.11187278   3.68310284  -1.26450949
   2.99278803  -2.2262928   17.63689864  15.0981007   13.64418744
   8.83687233  -3.14432214  -1.47436114  56.63949869  -4.65928829
  26.77585851  27.22984265  -0.48277889   0.74950844  -3.7806139
   4.81009478   1.27801586   4.57738421  -2.2011993   30.06042989]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1724.0670238877694
gradient value of function right now is: [ 3.32119902e-01 -3.85410454e-01 -4.74035989e-06 -1.71138701e-06
 -3.32119902e-01  3.85410454e-01  4.74035989e-06  1.71138701e-06
  2.56059548e-01  1.46429922e+00  1.31983897e-01  2.10454481e+00
 -2.33921774e-04  1.18959302e-01  3.26760832e-02  9.08704648e+00
  2.66099938e-08 -2.03243438e-06 -1.27085604e-06 -3.11268723e-04
  1.46450941e-08 -2.79032187e-07 -4.64127362e-07 -1.02217512e-04
 -1.28269613e-01  9.89749031e-03  1.64957920e-02  3.74728629e-02
 -1.91552967e+00 -1.19575256e+00 -1.83668854e-01 -2.06526577e-01
 -1.44973860e+00 -1.15280224e+00 -9.71259171e-02 -1.33538594e+00
 -2.48354762e+00 -4.84939011e-01 -2.74105388e-03 -4.47495885e-01
 -9.73268738e-02 -2.94774752e+00  1.58843391e+00 -1.52340331e+00
  7.33206374e-02 -8.10248611e-02 -1.89610524e+00 -1.40229680e-02
 -1.34239905e-04  4.99526691e-03  2.04239736e-01  1.86702067e-04
  1.15803448e-01 -1.41982387e-02 -1.98137970e+00  4.43876843e-03
  1.73805919e-02 -3.74548640e-01  3.34394169e-01 -1.45665872e+00
 -1.79650933e+00  4.98604055e+00  1.36189617e+00  1.20238345e+00
 -2.99791234e+00]
supnorm grad right now is: 9.087046481066976
Weights right now are: 
[-6.37147383e+00  1.32167001e+01 -3.45029912e+01 -3.19939531e+01
  6.62604254e+00 -1.33253918e+01  3.49019285e+01  3.12779247e+01
  9.14180452e+00 -4.11884062e+00 -1.45229329e+01  7.15321623e+00
  3.92404178e+01  3.04101540e+01  4.68361590e+01  2.39650265e+00
  2.82059537e+01  4.49144371e+01  3.73209108e+01  1.42980007e+01
  2.10628881e+01  8.74173063e+01  3.78965286e+01  1.51806426e+01
  2.27278409e+01 -1.15776933e+01 -9.30528325e+00  2.52494161e+00
  2.74201945e+00  2.82534926e+00  1.13091087e+00  4.18262791e+00
  3.07729606e+01 -1.18847377e+01  1.54234527e+01 -2.28377223e+01
 -1.17259728e+00 -6.35846487e+00 -3.75483512e+01  3.23643065e+00
  4.39209681e-02  3.88619134e-01 -6.06331756e+00  3.22559092e+00
 -5.21145784e-01  3.03110052e+00 -1.91295635e+00  1.77524756e+01
  2.16180735e+01  1.57690877e+01  1.12601732e+01 -5.29476041e+00
 -2.74864017e+00  6.00945785e+01 -4.52523562e+00  2.76342070e+01
  3.28976954e+01 -3.77278836e-01  5.80191587e-01 -3.67914402e+00
  5.10208226e+00  1.20079099e+00  5.33145184e+00 -2.07084431e+00
  2.99467825e+01]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1725.8926281358122
gradient value of function right now is: [-5.52115885e-02  7.37985751e-03 -2.62146262e-07 -7.72082919e-08
  5.52115885e-02 -7.37985751e-03  2.62146262e-07  7.72082919e-08
 -1.98018554e-01 -3.39439196e-01 -9.42366821e-02 -1.87608701e-01
  1.17150351e-02  6.28284386e-03  3.86943146e-03 -3.00180282e-01
 -1.94076959e-07 -9.91035556e-07  6.32138935e-08 -1.54685505e-05
 -8.60064519e-08  3.03517708e-08  4.56118626e-08 -4.92044232e-06
 -1.69415424e-01 -2.27117011e-01 -1.96494195e-01 -1.77453979e-01
 -3.38127105e-01  3.53152784e-01  9.03572431e-02  6.07867674e-02
  3.11770349e-01  2.50941750e-01  9.89004108e-03  3.73873406e-01
 -1.31234424e-01 -9.50750606e-02 -2.23868328e-03 -9.79229985e-02
  5.61012824e-02  1.20713891e+00  1.81411917e-01  1.07465154e+00
  6.35838622e-02 -1.34197531e-01  7.39955072e-01  6.33355178e-02
 -2.04375791e-05 -2.25673814e-02 -5.71779347e-02 -1.69276879e-03
  5.19674537e-02 -6.45086589e-03  6.84846644e-01  3.34841889e-02
  1.04718057e-02 -3.88645678e-01  7.69601277e-01 -3.90955972e-01
  6.44576510e-01 -1.36836314e+00 -8.94617167e-02  1.32637566e+00
  3.55869869e+00]
supnorm grad right now is: 3.5586986874909345
Weights right now are: 
[ -6.56094605  13.67079101 -34.83303563 -32.2013634    6.81551476
 -13.7794827   35.2319729   31.48533502   8.96235802  -3.87247642
 -15.02789976   7.13524749  39.31434951  30.17331913  47.25763795
   2.39477445  28.23790608  44.32651924  36.92893786  14.66162062
  21.08417616  87.29959509  37.63533433  15.4743061   22.44437361
 -11.75174632  -8.18892639   2.21085073   2.75823349   3.18736134
   2.51165387   4.91979208  30.35397543 -11.59149548  16.56349241
 -22.99728507  -1.23766542  -6.89122486 -33.59027981   3.89405626
   1.61368629   0.94762676  -6.00405007   3.38162837  -1.71606326
   2.77690928  -1.50647624  17.75611477  28.20936723  17.95232745
  11.87500957  -6.81468169  -3.3347959   62.00812721  -4.68773175
  27.49880854  34.16552886  -0.98480382   0.9797358   -3.79792154
   5.53371551   1.08206702   5.20659447  -2.27146489  30.17630054]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1719.682263623412
gradient value of function right now is: [-4.96228262e-01 -3.88119368e-01 -1.95960299e-06 -9.58700501e-07
  4.96228262e-01  3.88119368e-01  1.95960299e-06  9.58700501e-07
 -3.71045747e-01 -1.92548753e+00 -4.51128162e-01 -3.81502640e+00
 -8.81186455e-03  1.46089872e-01  2.67700992e-02  9.52476062e+00
  4.61487983e-08 -2.18856784e-06 -5.31462053e-07 -1.24690206e-04
  2.14631325e-08 -1.62280303e-07 -3.03679973e-07 -5.64287757e-05
  4.19387188e-01  1.62625310e-01  1.08769566e-01  9.72925143e-02
 -4.52567705e+00 -8.93729570e-01 -6.52385814e-03 -2.11735604e-01
 -3.69901679e+00 -2.11493867e+00 -2.35396593e-02 -3.13402526e+00
  3.72047011e-01 -4.28504713e-01 -4.86757203e-04 -4.92844338e-01
  1.28703952e-01  3.31730174e+00  3.42007646e+00  1.92025905e+00
 -8.30390625e-02  3.86444525e-02 -5.56644584e+00 -1.20130921e-01
 -6.06917916e-06  9.75737280e-03  2.18801693e-01  3.03291769e-03
 -4.33466273e-02 -4.52272702e-02 -4.82386728e+00 -1.18975383e-01
 -4.23139068e-02  4.71355901e-01  4.56408960e-01 -4.77737606e+00
 -1.29242513e+00  1.12145706e+01 -4.53892100e-01 -9.78371667e+00
  1.19379474e+01]
supnorm grad right now is: 11.937947404464309
Weights right now are: 
[ -6.88510776  14.12470552 -34.89611115 -32.24028789   7.13967647
 -14.23339721  35.29504842  31.5242595    9.3085859   -3.94231493
 -15.40484389   6.74901323  40.10050119  30.5500427   46.96052319
   2.46033401  28.25223259  43.79294853  36.83506231  15.67415409
  21.09605747  87.25355825  37.55449757  16.12657058  21.96652297
 -12.30670898  -7.37184409   3.44675044   2.73130353   3.38311952
   2.15932952   4.45967734  29.76383853 -11.40107267  17.15210195
 -23.31750661  -1.04394847  -8.26503461 -23.95001398   3.54006987
   2.50591625   1.36043589  -6.1669318    2.97603978  -3.54763592
   4.1942147   -1.09535094  17.42621449  33.61334904  19.58917619
  13.39768089  -8.29397724  -3.53738558  63.64583571  -5.18670856
  27.11997079  34.65269254  -1.23820009   0.80238049  -3.45528461
   5.70751636   1.08605834   5.15184404  -2.32404861  30.00582165]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1725.8212126577973
gradient value of function right now is: [ 1.03979391e-01  6.53796291e-03 -1.27011034e-06 -1.23825512e-06
 -1.03979391e-01 -6.53796291e-03  1.27011034e-06  1.23825512e-06
  3.83411361e-02  4.39241892e-01 -3.58153591e-02  7.75201848e-01
 -1.25295953e-02 -1.22671348e-01  1.27856799e-02 -5.56905697e-01
  1.77004577e-07  5.78647684e-06 -1.55129912e-06 -8.55799244e-05
  5.27700722e-08  2.05621337e-07 -6.95589197e-07 -7.05241784e-05
  2.46145195e-01  2.36576781e-01  1.48361866e-01  1.01765346e-01
  2.89948978e+00  8.73249576e-01  1.54631199e-01  3.96443414e-02
 -1.44497395e+00 -7.57259871e-01  1.07129901e-01 -1.26204510e+00
 -1.06679748e+00 -2.34244457e-01 -6.11659636e-04 -3.26185661e-01
 -3.58358414e-02 -1.34000549e+00 -2.49599103e-02 -4.52101825e-01
 -1.01530197e-01 -4.29504503e-01 -3.77002941e+00 -2.32819706e-01
  5.33407335e-06  1.08174377e-03 -1.01435164e-01 -5.44140490e-04
 -7.16087785e-02 -5.50871463e-02 -2.78138144e+00 -1.16524508e-01
 -3.35262374e-02  7.39493626e-01  1.19058858e+00 -4.17378290e+00
 -6.68698143e-01  5.23856191e+00  1.02449129e+00 -6.53408790e+00
 -6.27593051e+00]
supnorm grad right now is: 6.534087899557933
Weights right now are: 
[ -6.90207345  14.41202363 -35.21853258 -32.41840518   7.15664216
 -14.52071532  35.61746985  31.70237679   9.7134574   -3.78523734
 -15.12798163   6.71423611  40.64972512  31.67336118  46.84605803
   2.49274397  28.2791271   41.99962968  36.43200548  14.64401314
  21.12087224  87.144489    37.25563332  15.39475703  22.47885432
 -12.54857993  -6.16835378   5.12604658   2.86601445   3.74736164
   1.86724766   4.97633369  29.18075191 -10.97328324  17.55362349
 -23.49988306  -1.06059379  -7.73333004 -21.55765287   3.84392302
   0.67540403   0.36623865  -6.55677086   3.05521785  -5.15280459
   3.70518708  -0.86761982  15.34814263  36.29281958  24.00546983
  13.00119542  -9.31622774  -1.87723197  64.02040774  -4.86992072
  27.30330072  37.00987095  -1.18475027   0.94174655  -3.55704037
   5.61187959   0.97650708   5.52145416  -2.49655523  30.02392029]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1723.1053379914342
gradient value of function right now is: [-2.72573210e-01 -3.08744468e-01 -2.82255425e-06 -1.22453823e-06
  2.72573210e-01  3.08744468e-01  2.82255425e-06  1.22453823e-06
 -1.12868469e-01 -8.85613098e-01 -2.54935155e-01 -2.54252955e+00
 -9.36976746e-03  1.41711985e-01 -2.35315134e-03  8.05964528e+00
  1.35261373e-07 -3.78600610e-06  5.02589859e-08 -1.86753188e-04
  7.63186926e-08 -4.00115084e-07  4.99668874e-08 -7.43282085e-05
  2.91192345e-01  1.86276521e-01  1.30320419e-01  1.05689612e-01
 -4.08005651e+00 -1.20582808e+00 -3.80947084e-02 -1.64588360e-01
 -1.76731209e+00 -1.06792492e+00 -1.38191481e-01 -1.54852016e+00
  4.05473895e-01 -1.34483675e-01  9.21591098e-04 -3.62094721e-03
  5.82303590e-02  1.92117865e+00  2.15027535e+00  9.63395041e-01
  8.79488162e-03  3.49784042e-01 -1.15097397e+00  7.53540418e-02
 -6.04801715e-06  1.82297408e-02  2.97234522e-01  2.35031799e-03
  1.76354357e-02  2.16769656e-02 -1.57388347e+00  3.85372411e-02
  1.09625404e-03 -8.36505740e-02 -5.67130277e-01  6.16172753e-01
 -9.49374704e-01  4.76030978e+00 -5.87892729e-01 -1.67290919e-01
  1.17365095e+01]
supnorm grad right now is: 11.736509474303181
Weights right now are: 
[ -7.3703094   14.70492333 -35.4061604  -32.52775434   7.62487811
 -14.81361503  35.80509767  31.81172596  10.42877322  -3.97561885
 -15.59370722   6.4315228   41.65836826  33.02963603  47.33766174
   2.50240953  28.29382018  41.21447811  36.32331315  14.77832129
  21.13051949  87.09209077  37.1685765   15.19010466  21.767158
 -13.28901403  -6.06075817   5.2186948    2.77748049   3.88995906
   2.97484993   5.50483726  28.39718217 -11.11060853  15.89912171
 -24.04298976  -1.16258042  -8.07900436 -15.240979     3.7288732
   1.17477005   0.8039216   -6.51137285   2.96488697  -5.73536939
   4.06564314  -0.42781389  13.40370674  39.83847034  27.50515031
  13.76560446 -13.25181136  -1.7264319   64.50868543  -5.19165005
  26.60073685  40.15473828  -1.52715676   0.75291177  -3.5214238
   5.45146849   0.73967718   6.331414    -2.41746383  30.15245857]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1725.1796070440967
gradient value of function right now is: [-9.52774456e-02 -5.99282185e-02  1.32386751e-06  1.09570043e-06
  9.52774456e-02  5.99282185e-02 -1.32386751e-06 -1.09570043e-06
  7.35520088e-02 -4.49306979e-01  1.77899378e-01 -8.02259522e-01
  1.26978218e-02  2.32406175e-01 -6.53248605e-02  2.15480194e+00
 -5.30149917e-08 -9.30127751e-07  1.51403178e-06  7.62787384e-05
 -5.60906112e-09 -8.77134903e-08  9.32485837e-07  5.96065904e-05
 -2.83904066e-01 -2.17885966e-01 -4.20347085e-02 -4.43988807e-03
 -4.71956632e+00 -2.55147857e+00 -2.69691881e-01 -1.31260090e-01
  3.61560449e+00  2.04280665e+00  3.34477401e-01  2.92412920e+00
  1.46026281e+00  2.86339509e-01 -1.07260325e-02  5.27908448e-01
 -3.61996597e-02  1.43949156e+00 -2.43671450e+00 -6.28294666e-02
  1.44444562e-02  1.00351067e+00  4.52029609e+00  2.15262981e-01
 -3.22654504e-06 -4.82075135e-03 -5.37962811e-01 -2.26708674e-03
  1.23893407e-02  2.01171573e-01  6.05030426e+00  1.40603695e-01
  1.23574161e-02 -8.72901129e-02 -6.53812056e+00  1.58233509e+01
  4.63387836e+00 -1.61359327e+01 -1.84757539e+00  6.18310724e+00
  1.11397634e+01]
supnorm grad right now is: 16.135932742565586
Weights right now are: 
[-6.89805790e+00  1.52227013e+01 -3.54823130e+01 -3.25735392e+01
  7.15262661e+00 -1.53313930e+01  3.58812503e+01  3.18575108e+01
  1.08535418e+01 -3.60406081e+00 -1.48574332e+01  7.07199427e+00
  4.22153328e+01  3.35247747e+01  4.81514107e+01  2.53851954e+00
  2.83082150e+01  4.08250478e+01  3.63929038e+01  1.57608897e+01
  2.11419012e+01  8.70430954e+01  3.71869230e+01  1.61892957e+01
  2.17687970e+01 -1.36994598e+01 -5.66762923e+00  5.26681936e+00
  2.66931933e+00  3.65395610e+00  1.94565231e+00  5.85201928e+00
  2.79289007e+01 -1.04039425e+01  1.74138912e+01 -2.41358888e+01
 -8.51019948e-01 -7.54850186e+00 -1.10455957e+01  3.04013267e+00
  1.49775812e+00  9.78048589e-01 -6.79414760e+00  2.85265722e+00
 -7.31864436e+00  4.40650187e+00 -5.27216844e-02  1.24288270e+01
  4.17353936e+01  3.46883869e+01  1.28630429e+01 -1.46259425e+01
 -1.45684593e+00  6.49861681e+01 -4.87666297e+00  2.67870542e+01
  3.97367658e+01 -2.09762236e+00  8.40950975e-01 -3.33849380e+00
  6.04427641e+00  9.29236964e-01  5.65355741e+00 -2.58940205e+00
  2.98855359e+01]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1723.7969131604652
gradient value of function right now is: [ 3.61029440e-01 -7.10233644e-02  3.10984378e-07 -1.75840284e-07
 -3.61029440e-01  7.10233644e-02 -3.10984378e-07  1.75840284e-07
  3.09728937e-01  1.47374788e+00  4.25414212e-01  2.77949747e+00
 -1.81319989e-03  2.90155086e-02 -5.70729743e-03  2.00193401e+00
  2.37206944e-08  3.60214503e-06  3.70512116e-07  8.42305196e-06
  1.77000079e-08  8.60277154e-08  1.93183426e-07 -1.15713189e-05
 -1.42702913e-01  4.46481487e-02  4.44675426e-02  3.86202742e-02
  6.69613830e-01 -4.96935196e-01 -2.09548126e-02 -1.45708963e-02
  2.31229008e+00  9.70936918e-01  5.81675462e-02  1.90495076e+00
 -1.80378533e+00 -1.98102335e-01 -4.86023536e-03 -3.74699689e-01
 -9.72731928e-02 -2.68673673e+00 -1.44081564e+00 -1.95042508e+00
  6.44034882e-03  3.39280541e-01  1.96639239e+00  5.86347732e-03
 -5.69697649e-06  6.05370215e-03 -1.54283796e-01 -9.61359467e-05
  1.16516361e-02  3.16238065e-02  3.27559988e+00  6.46895185e-02
  1.27773217e-02  2.67417251e-02 -1.63514953e+00  3.05356183e+00
  6.95535296e-01 -6.32294023e+00  4.73361198e-01  4.30495827e+00
 -3.23410092e+00]
supnorm grad right now is: 6.3229402337804395
Weights right now are: 
[ -6.95176006  15.47568833 -35.5990827  -32.63392184   7.20632877
 -15.58438002  35.99801997  31.91789346  10.22945231  -3.59684578
 -14.89863939   7.34902752  42.97624389  34.04074359  50.50830787
   2.51767512  28.31071303  40.27507559  36.53984311  15.04263101
  21.14564848  86.99754005  37.25478278  15.66975552  21.85390367
 -14.19347153  -5.87353439   6.33351751   2.8732295    4.39354519
   3.90938161   6.07501364  27.28459851 -10.04025897  17.99507793
 -24.26530232  -1.05116452  -8.51671924 -10.31124044   2.4779653
   1.2682744    0.34196239  -6.98449689   3.07390014  -8.24073653
   4.75361455   0.46603213  11.00419928  41.94645458  36.94340539
  13.00406997 -16.84536197   0.38154279  65.28824159  -4.6814024
  27.20673344  39.96304398  -2.27578216   0.78468999  -3.54899358
   5.86404119   0.99397253   6.53910136  -2.48540474  30.0010455 ]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1723.6007653875477
gradient value of function right now is: [-3.26286904e-01 -1.00284983e-01 -1.63759051e-06 -2.98682500e-07
  3.26286904e-01  1.00284983e-01  1.63759051e-06  2.98682500e-07
 -1.73822101e-01 -1.41873657e+00 -2.64002221e-01 -2.64946125e+00
 -7.33790084e-03  4.44900959e-02  8.52949586e-04  2.69885936e+00
  7.58287736e-08 -5.71382861e-06 -2.94798035e-07 -9.37907078e-05
  2.58255901e-08 -1.36667717e-07 -1.23164467e-07 -1.73038743e-05
  3.09026320e-01  1.45192862e-01  9.13752311e-02  8.40076674e-02
 -2.37613743e+00 -3.37890469e-01 -1.09274633e-02 -7.30711702e-02
 -1.68390062e+00 -7.22002806e-01 -8.54473484e-02 -1.40785694e+00
  1.45456816e+00 -5.03739664e-02  1.62880903e-03  5.32614022e-02
  1.85017160e-01  2.03847406e+00  1.39152838e+00  1.22911088e+00
  6.71088099e-03 -7.26877129e-02 -1.29396409e+00  4.75730650e-02
  3.38339645e-07  5.73700278e-03  1.93103103e-01  2.16190541e-04
  2.97890492e-04 -4.70003071e-03 -2.24228502e+00 -1.69989754e-02
 -5.36905060e-03 -7.34427144e-02  3.65247359e-01 -1.31257793e+00
 -7.84434262e-01  5.66345030e+00 -4.93506023e-01 -1.98821969e+00
  4.64908170e+00]
supnorm grad right now is: 5.66345030318767
Weights right now are: 
[ -7.84195951  15.74713002 -35.73860244 -32.70496981   8.09652822
 -15.85582171  36.13753971  31.98894143  10.25405194  -4.19347921
 -15.72593024   6.88474417  43.46598218  34.88268117  50.82334489
   2.51446406  28.33536871  39.62583152  37.04626217  15.14087293
  21.15753243  86.9155991   37.43248146  15.97795243  21.30675061
 -14.49515089  -5.56924687   6.89329025   2.53616478   4.68677639
   2.22053919   5.62993746  26.61626705  -9.9000912   17.74857549
 -24.61333806  -0.47825762 -10.05946156  -8.17384133   2.20667725
   1.03288688   0.81700741  -6.64812678   3.16439793  -7.37013637
   4.57037785   0.72339351  10.22520319  41.01780905  40.8859142
  13.70213534 -18.90974698   2.76898252  65.69059906  -4.68364008
  26.63422092  36.90907935  -3.24768373   0.64344595  -3.2687158
   5.9883126    0.97665198   6.65414758  -2.70437331  29.94438824]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1721.1955863307294
gradient value of function right now is: [ 5.20180802e-02  4.82316572e-03 -2.18538380e-06 -9.55455502e-07
 -5.20180802e-02 -4.82316572e-03  2.18538380e-06  9.55455502e-07
 -6.53347038e-02  6.55196536e-01 -4.44450474e-01  1.20502483e-01
  7.95200822e-03 -1.53594433e-01  7.51698236e-02 -3.01744151e-01
 -2.36957286e-07  1.34412971e-05 -7.55499274e-06 -1.44364137e-04
 -6.39588328e-08  1.85389313e-07 -1.22947991e-06 -5.35726598e-05
 -2.16730962e-01 -2.06233350e-01 -2.04018377e-01 -2.28330839e-01
  3.99952977e+00  1.30316601e+00  1.83723571e-02  7.00297761e-02
 -7.19006592e+00 -3.00772411e+00 -4.27239057e-01 -6.04586358e+00
 -9.62756354e-01 -2.88807477e-03  4.32646395e-03 -8.97442314e-02
  1.26985097e-01 -9.76626756e-01  4.15629486e+00  4.67497991e-01
 -2.96722939e-02 -1.17408443e+00 -7.25804360e+00 -2.61312753e-01
  2.03798984e-05  6.66938639e-03  7.21162031e-01  3.03619590e-03
 -4.40474623e-02 -2.79506574e-01 -1.23466875e+01 -2.83817090e-01
 -1.36568479e-02  7.13889645e-02  6.66935227e+00 -2.20516209e+01
 -4.15003025e+00  2.06617132e+01  1.84250028e+00 -1.04451851e+01
 -1.04609738e+01]
supnorm grad right now is: 22.051620932855545
Weights right now are: 
[ -7.76247622  15.91157131 -35.99662281 -32.75841337   8.01704493
 -16.020263    36.39556008  32.04238498  10.231193    -3.8773373
 -15.84853115   7.27813831  44.16080391  36.09697615  53.25863284
   2.6232138   28.40665218  37.30664684  37.14718201  14.31926307
  21.17160927  86.84830046  37.42177432  16.26520201  20.47704002
 -15.02344893  -6.75901828   6.18485775   2.79332307   4.9799413
   3.35609722   7.15707189  26.31651938  -9.60974255  17.66771083
 -24.48630883  -0.64116001  -9.59420116  -9.42634106   1.81348532
   1.13852684   1.17398457  -6.80665413   3.18799539  -8.95762439
   5.13364819   1.16191664   9.56125535  40.66650616  44.46204485
  12.94860034 -22.66893059   3.20623778  65.12297194  -4.7773512
  26.19705227  35.09635658  -2.2065681    0.71374741  -3.57497597
   5.9678877    0.96362006   6.45757761  -2.68468309  30.08145541]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1724.1697725379172
gradient value of function right now is: [-8.05244019e-02 -3.06032869e-01 -3.88229916e-06 -5.51496696e-07
  8.05244019e-02  3.06032869e-01  3.88229916e-06  5.51496696e-07
 -2.45561221e-01 -7.70568681e-01  1.02698516e-01 -2.84544665e-01
  6.19349822e-02  1.03746637e-01 -2.46441055e-02  9.22986382e+00
 -2.21840460e-06 -5.12567443e-07  1.33155824e-06 -2.94458441e-04
 -2.15310091e-07 -7.30468889e-08  1.82993020e-07 -3.48681496e-05
 -1.26986731e+00 -1.18405512e+00 -4.71202879e-01 -4.36229465e-01
 -1.91704179e+00 -1.39268021e+00 -1.14030828e-01 -1.31773465e-01
  3.98820925e+00  1.79724409e+00  2.69865656e-01  3.55830011e+00
  8.21112737e-02 -1.92407367e-01 -8.50755407e-03 -4.44087321e-01
 -2.76464168e-02  2.83887228e+00 -2.45194363e+00  9.05147429e-01
 -7.04831587e-03  5.03983207e-01  2.63612827e+00  2.21536518e-02
 -2.95117924e-05 -3.78470233e-02 -6.02526630e-01 -2.40327795e-03
  2.86761736e-02  1.46131761e-01  6.56897746e+00  7.97726027e-02
 -3.16774676e-03  4.04938962e-02 -4.21727577e+00  8.96690333e+00
  4.73190725e+00 -1.46598086e+01 -1.21438135e+00  1.66674655e+00
  1.04637199e+01]
supnorm grad right now is: 14.659808570477448
Weights right now are: 
[ -7.71931528  16.14283791 -36.21943728 -32.81130203   7.97388399
 -16.2515296   36.61837455  32.09527365  11.17343924  -3.59584309
 -16.02417875   7.36721797  43.93023893  37.05989158  52.56489697
   2.61272958  28.4372556   35.00321424  38.0999679   14.03617333
  21.17787284  86.78480138  37.60294843  16.00184056  20.60993069
 -14.59872775  -6.49057335   7.05771307   2.88893959   5.04377425
   3.51675485   6.76624019  25.88649743  -9.11200755  18.19614682
 -24.5001775   -0.97245596  -9.76064195  -8.39628758   1.56082815
   0.86851906   0.88044802  -6.77543643   3.15563755  -7.34276806
   4.90953056   1.27317652   8.33002588  39.98463392  47.67068891
  12.37025858 -21.1888786    1.55126667  64.75937975  -4.38928193
  26.09451046  38.24718567  -1.29672204   0.53569596  -3.48426407
   6.05824713   0.85070544   5.76609444  -2.75297614  29.92682038]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -1722.261153140648
gradient value of function right now is: [ 1.53493620e-01  7.89563860e-02 -8.36406336e-06 -3.47101847e-06
 -1.53493620e-01 -7.89563860e-02  8.36406336e-06  3.47101847e-06
  5.19255624e-02  1.21552580e+00 -3.63737808e-01  1.05492034e+00
 -2.59321469e-02 -1.11532470e-01  5.30575084e-02 -2.86530204e+00
  1.20748259e-06  2.04855327e-05 -2.01607573e-05 -4.55022516e-04
  1.40670301e-07  1.39968326e-07 -5.46606095e-06 -1.74758251e-04
  5.11764774e-01  4.84070732e-01  1.59594066e-01  1.50086174e-01
  2.98202644e+00  1.40681920e+00  8.19575665e-02  1.09774550e-01
 -6.90942014e+00 -2.40427533e+00 -2.41571647e-01 -5.91735709e+00
 -1.71971797e+00  8.02663765e-02  1.00759253e-02  4.46131210e-01
  1.04378813e-01 -2.90141111e+00  2.87519634e+00 -2.92511952e-01
  1.33507583e-03 -1.25213705e+00 -5.58160825e+00 -1.73173939e-01
  6.76337945e-06  1.58818667e-02  6.15090968e-01  1.45558133e-03
 -1.46275321e-02 -2.84296004e-01 -1.27353884e+01 -2.83270626e-01
 -6.47965761e-03 -7.91884783e-02  7.16942935e+00 -2.10348069e+01
 -5.59916061e+00  2.15782449e+01  1.95002778e+00 -8.03012421e+00
 -1.48278024e+01]
supnorm grad right now is: 21.578244911717917
Weights right now are: 
[ -8.28523637  16.19240714 -36.41468934 -32.89003551   8.53980508
 -16.30109883  36.81362661  32.17400713  11.62446982  -3.89615343
 -16.00251574   6.94509497  43.67793033  38.48707914  53.51532682
   2.70552754  28.50697864  33.44828562  38.43903062  13.87018633
  21.18525644  86.71603942  37.63376613  15.43730587  20.71121242
 -14.17245084  -6.60565873   7.63015128   2.73099878   4.91398677
   3.34402825   6.84139348  25.62035833  -8.81228033  17.09162685
 -24.50143235  -0.83103093  -9.41306508  -7.27660386   1.94349129
   2.11060084   0.72967903  -7.13042883   2.89307597  -7.70414729
   4.94454859   1.45762115   8.20724035  39.3221807   48.84894449
  12.45710384 -22.55887808   1.38598688  64.75510007  -4.59422491
  23.56367502  37.37049847  -2.67915385   0.78231964  -3.40006824
   6.01264277   1.25634817   6.4327236   -2.49880757  30.00543209]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -1725.5955842230978
gradient value of function right now is: [ 4.64087663e-03 -1.73141686e-01 -9.35856665e-07 -2.59288214e-08
 -4.64087663e-03  1.73141686e-01  9.35856665e-07  2.59288214e-08
 -1.84667275e-02 -1.78772382e-02  3.86404696e-02  8.00424087e-02
  1.63859352e-02  1.31234471e-01 -1.02978696e-02  5.38950080e+00
 -9.35314228e-08 -4.21837452e-06  1.98003542e-07 -5.91088562e-05
 -1.81600937e-08 -1.00493103e-07  7.63468225e-08 -1.95372959e-06
 -3.53341122e-01 -3.11087713e-01 -1.02673025e-01 -1.06198556e-01
 -3.60627565e+00 -1.27118443e+00 -6.38176563e-02 -1.09492640e-01
  1.23631477e+00  3.45914788e-01 -5.97323920e-02  9.73568843e-01
 -2.54770806e-01 -5.99876145e-02 -3.36892936e-03  8.60539651e-02
  2.03249420e-02  5.12587509e-01 -1.71703672e-01  2.48095628e-01
  3.65593648e-02  3.37160779e-01  1.99320637e+00  1.92206821e-01
 -2.52021640e-05 -2.82380036e-03 -7.24942141e-02 -2.14021032e-04
  5.26527430e-02  1.10469054e-01  3.56741801e+00  1.82079116e-01
  1.01742851e-02 -2.11502256e-01 -1.99928201e+00  7.93385795e+00
  1.70534779e+00 -7.49867183e+00 -6.56348118e-01  5.94305058e+00
  6.57165064e+00]
supnorm grad right now is: 7.933857953494366
Weights right now are: 
[ -8.37854961  16.61123104 -36.39558422 -32.89003678   8.63311832
 -16.71992273  36.79452148  32.1740084   11.81994676  -3.93715407
 -16.55122865   7.24523707  43.28459816  39.73828594  55.27862731
   2.54306908  28.58716422  31.73923708  38.97825086  15.7998266
  21.19209529  86.6524803   37.72477424  16.72999699  20.29694554
 -13.56963598  -6.90193629   7.55070547   2.75387584   4.98903949
   1.4362974    6.82952994  25.25988821  -8.60980668  17.26441942
 -24.62203683  -0.7244711  -10.75214582  -5.85248901   1.54767701
   1.50270344   0.30049103  -6.78228138   3.30411831  -7.33155735
   4.23906654   1.19076662   7.6201605   40.09757432  52.18882083
  12.12301678 -23.03775685   1.3363851   64.64480599  -4.62381045
  23.1517216   39.64677153  -1.25758729   1.11699614  -3.38615889
   6.22908219   0.95332684   6.50356197  -2.24043995  30.06350943]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1716.6753022460125
gradient value of function right now is: [-8.46334109e-01 -4.81170597e-01 -4.79587268e-05 -9.00906044e-07
  8.46334109e-01  4.81170597e-01  4.79587268e-05  9.00906044e-07
 -4.00940264e-01 -4.12144993e+00 -2.35968951e-01 -8.06274383e+00
  3.04767700e-02  4.18867820e-01 -6.35548980e-02  1.46996431e+01
 -3.28342395e-06 -2.56855365e-04  8.38307140e-06 -3.04513632e-03
 -1.65982368e-07 -2.05683854e-06  1.58251688e-06 -5.78295652e-05
 -2.61070089e-01 -5.36535345e-01 -8.46629642e-02 -6.63645275e-02
 -1.48230816e+01 -4.11190406e+00 -1.39735448e-01 -4.63578392e-01
  2.84631017e+00  1.42095445e+00  3.09215819e-01  2.37281098e+00
  4.72106581e+00 -4.66070302e-02 -3.39416329e-03  1.60274209e-01
  8.35963544e-02  8.21041825e+00 -6.03809675e-01  2.43814134e+00
  4.69744448e-02  2.72384185e+00  4.32579772e+00  5.42409620e-01
 -2.19544896e-05 -4.54555330e-02 -5.48145201e-01 -5.15972945e-03
  6.54406609e-02  3.70866368e-01  7.60845764e+00  3.04137698e-01
  1.23683169e-02 -2.41051105e-01 -1.17237248e+01  2.46800069e+01
  5.95151752e+00 -1.48666799e+01 -3.66794309e+00  6.08460603e+00
  4.65211673e+01]
supnorm grad right now is: 46.52116733523178
Weights right now are: 
[ -8.47419614  16.672118   -37.32685859 -33.04385289   8.72876486
 -16.78080969  37.72579586  32.32782451  11.90009322  -3.74821281
 -16.99561299   6.88154686  44.22077256  41.00918065  54.47867007
   2.63874768  28.7747987   26.42017638  40.322874    13.38573581
  21.19841259  86.57509245  37.92828517  15.04944478  20.21485703
 -14.25847247  -7.45058848   8.227771     2.72906595   5.49898986
   0.25968112   5.88346346  24.93127217  -8.15024123  18.05109654
 -24.42493495  -0.79296453 -10.3882055   -5.52350568   1.56931668
   0.65603659   0.79354747  -6.75398433   3.17771785  -6.2426472
   5.42685103   1.39838503   6.93695252  41.92941659  52.32861393
  11.9109521  -23.6176613    0.24272408  64.92048985  -4.49897236
  22.54456157  42.50708632  -1.31812255   0.57942177  -3.49748735
   5.97266845   1.12060234   6.13582714  -2.45991381  30.20264555]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1721.9719462638113
gradient value of function right now is: [ 4.53803958e-02  2.71253546e-01  3.03982229e-05 -1.40014318e-06
 -4.53803958e-02 -2.71253546e-01 -3.03982229e-05  1.40014318e-06
 -1.00927790e-01  2.83960821e-01 -2.34128048e-01  5.87419052e-01
 -3.10619682e-02 -2.53159430e-01  5.09660473e-02 -8.48309916e+00
  4.49369459e-06  1.86134409e-04 -4.64354386e-05  1.99272520e-03
  5.21379600e-08  6.32271601e-07 -3.91341120e-06 -6.30418814e-05
  7.16081223e-01  5.55049416e-01  1.51597040e-01  1.50990240e-01
  7.20734960e+00  2.63579269e+00  1.17903810e-01  2.81752692e-01
 -4.56617842e+00 -1.29106230e+00 -9.21593937e-02 -3.77677632e+00
  6.62347420e-01  2.40410099e-01  4.20378782e-03  6.39283330e-01
  5.50545104e-02 -8.02781380e-01  1.13211777e+00  4.44114664e-01
 -1.81669689e-02 -1.43556979e+00 -3.21275538e+00 -2.68360789e-01
  3.66791930e-05  3.11776085e-02  2.63487246e-01  3.98405881e-03
 -5.75693489e-02 -2.45827791e-01 -9.22899089e+00 -2.75218492e-01
 -9.60727099e-03  1.20345268e-01  6.85416185e+00 -1.73349369e+01
 -3.58733681e+00  1.65342497e+01  1.53437977e+00 -8.51793761e+00
 -1.93675677e+01]
supnorm grad right now is: 19.36756771167622
Weights right now are: 
[ -8.37002926  16.95673725 -37.14863386 -33.04188689   8.62459797
 -17.06542894  37.54757113  32.32585851  11.91966448  -3.46341284
 -17.56853325   7.04687874  44.14949496  41.99611925  53.88619414
   2.56592447  28.77622412  26.10156374  40.65915414  13.0602518
  21.20406765  86.51359263  38.01663702  16.28360443  20.06673086
 -13.93425885  -8.0220403    8.21032412   2.89171151   5.13889167
  -0.42813228   5.6142011   24.90875838  -7.6154528   18.22855231
 -24.15777203  -0.29841331 -11.24087228  -4.99112723   1.82072098
   0.99378872   1.07228948  -7.00978822   3.64727725  -4.93040596
   5.36279261   1.72303839   6.80181755  44.79481887  55.17893216
  11.95921878 -25.29378202  -0.72210099  64.88503914  -4.35128116
  21.5737698   43.33704253  -1.59645539   0.97078349  -3.4045056
   6.0429698    0.99516567   5.6604015   -2.58398009  29.66162279]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1725.6412893328522
gradient value of function right now is: [-5.55861706e-02 -1.39889803e-01 -9.86553913e-05  4.86790597e-07
  5.55861706e-02  1.39889803e-01  9.86553913e-05 -4.86790597e-07
 -6.19880100e-02 -1.92074787e-01 -3.92150575e-02 -6.16720934e-01
  5.36728174e-03  1.55425144e-01 -1.23133103e-02  4.59237675e+00
 -4.58653553e-06 -6.69092138e-04  1.86482895e-05 -6.75351334e-03
 -4.00986733e-09 -4.64068947e-07  5.35677313e-07  2.56266841e-05
 -9.88361610e-02 -8.52049001e-02  2.26720151e-02  2.36177998e-02
 -4.81844579e+00 -1.51179931e+00 -3.41061590e-02 -8.37930619e-02
  9.41869586e-01  1.05357993e-01 -6.54694532e-02  7.42066033e-01
  3.99779629e-01  1.67639259e-02 -1.44348757e-03  2.27375601e-01
  7.61060292e-03  1.21062573e+00  4.01481825e-01  5.01523999e-01
  3.08683992e-02  7.10455018e-01  2.04639722e+00  2.47977810e-01
 -1.37009620e-05 -2.88261126e-03  7.59322273e-02 -7.88932380e-05
  4.34855935e-02  9.84192213e-02  3.25223585e+00  1.89662553e-01
  1.12111275e-02 -2.37564748e-01 -2.57055690e+00  7.49829920e+00
  9.28552466e-01 -4.05938096e+00 -8.13960285e-01  5.41303284e+00
  9.88457550e+00]
supnorm grad right now is: 9.884575502866413
Weights right now are: 
[ -8.44808462  17.04602596 -40.06241434 -33.13835395   8.70265333
 -17.15471765  40.46135161  32.42232556  11.61928146  -3.46266985
 -17.55484234   7.08557635  44.49852332  43.70113217  55.17286605
   2.55555804  28.7640578   21.37028175  42.23942916  11.49861682
  21.21178826  86.34587444  38.08093567  15.47651971  20.24455534
 -13.93011018  -7.59949888   8.62381173   2.90055067   5.16660636
  -1.99501411   6.81710134  24.45946373  -7.63300827  17.93881688
 -24.14082947  -0.77148568 -11.61713944  -5.02860574   1.56196985
   0.74218415   0.58962622  -6.3992963    3.20638684  -4.95649069
   5.11045134   1.61623112   6.6322386   48.98368541  59.46233947
  12.13526298 -22.22245949  -1.46121949  64.2618462   -4.22576126
  20.624018    47.13762254  -1.19273234   0.66131111  -3.49405195
   5.93149203   1.12242465   6.01080448  -2.24894017  30.00321628]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1720.7074655285862
gradient value of function right now is: [-4.11482207e-01 -4.87195046e-01 -1.31827913e-04  3.75124289e-07
  4.11482207e-01  4.87195046e-01  1.31827913e-04 -3.75124289e-07
 -5.28810178e-01 -2.31455744e+00 -2.44030817e-01 -3.61803617e+00
  1.88411480e-02  2.90993933e-01 -1.35887832e-02  1.55987064e+01
 -8.51764478e-06 -9.53025742e-04  2.08467052e-05 -8.97466619e-03
 -2.82101662e-08 -5.56180912e-07  7.82027906e-07  1.26595433e-05
 -5.66971125e-02 -3.41108661e-01 -7.11005958e-02 -9.71138721e-02
 -1.01257906e+01 -3.02302008e+00 -1.66828606e-01 -5.42058021e-01
  2.45054407e+00  7.15420802e-01 -6.89240520e-02  2.31874948e+00
  1.77885718e+00 -1.58999169e-01 -1.02058043e-02  8.54940479e-02
  9.03741303e-02  5.27357714e+00 -3.49114849e-01  2.40148290e+00
  8.89839512e-03  1.27076051e+00  3.32461422e+00  3.61767432e-01
 -7.88532690e-06 -1.94541273e-02 -2.78523094e-01 -3.00667299e-03
  1.02094615e-02  1.99707124e-01  7.07372610e+00  2.20488796e-01
 -7.78456544e-03 -1.42238334e-01 -5.40540385e+00  1.30471605e+01
  4.02217244e+00 -1.11036317e+01 -2.85715901e+00  3.48503716e+00
  3.11315645e+01]
supnorm grad right now is: 31.13156452729773
Weights right now are: 
[ -8.49357266  17.00144274 -40.46454908 -33.15466137   8.74814137
 -17.11013443  40.86348635  32.43863299  12.27264837  -3.5115474
 -16.49018082   7.18920416  44.72150607  44.60044199  57.6729511
   2.72697509  29.06657179  19.97328481  43.15334375  12.4146621
  21.21724889  86.2086114   38.15277146  16.36287636  19.81894695
 -13.82595917  -7.7210585    8.65099311   3.00604476   5.32493526
  -4.06521857   5.89200698  24.18208129  -7.17118149  17.84789831
 -24.08466656  -0.88150403 -11.57580523  -5.29426678   1.77079566
   2.6466921    0.60243575  -6.62525367   3.52287151  -4.99759622
   5.65964399   1.92502598   6.31083869  53.80697295  64.35771974
  11.31808521 -19.15800586   0.19971887  63.77205156  -4.04931746
  20.52701225  49.65480171  -2.61996146   0.76804889  -3.59048495
   5.79467488   1.08457521   5.25427269  -2.64477498  30.19556815]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1725.4782963883977
gradient value of function right now is: [ 9.48322344e-02  1.40841319e-01  3.00071106e-05  5.05851150e-06
 -9.48322344e-02 -1.40841319e-01 -3.00071106e-05 -5.05851150e-06
  1.18607913e-01  4.50867599e-01  1.67200959e-01  9.70055767e-01
  8.30993138e-03  2.37962515e-02 -3.19833604e-02 -3.74789633e+00
 -6.94707216e-07  2.55950326e-05  1.59227246e-05  1.79700322e-03
 -2.43335125e-08  1.66857385e-07  2.55503252e-06  2.56942733e-04
 -2.95590098e-01 -1.52962972e-01 -2.67641365e-02 -3.91545752e-02
 -2.39373563e-01 -3.34725600e-01 -4.13948112e-02  6.70281565e-02
  2.65376039e+00  7.75248797e-01  1.00632422e-01  2.07265216e+00
  9.37288823e-01  2.03694153e-01 -8.17932191e-04  8.04387815e-01
 -1.07634615e-02 -3.07929117e-01 -1.45750269e+00 -4.43445760e-01
  1.26565951e-02  2.36179879e-01  2.64247720e+00  1.09948756e-01
 -6.66805743e-06 -1.23128559e-02 -2.94341511e-01 -1.57664559e-03
  1.32218065e-02  9.12136816e-02  4.94950053e+00  1.19294725e-01
  6.09347607e-03 -8.61174774e-02 -1.79402979e+00  6.86158680e+00
  1.82503999e+00 -6.89936086e+00 -2.82114546e-01  3.79685062e+00
 -4.49789470e-01]
supnorm grad right now is: 6.8993608572847345
Weights right now are: 
[ -8.83480948  17.1666472  -40.04470617 -33.23484375   9.08937819
 -17.27533889  40.44364344  32.51881536  12.69957261  -3.45287748
 -16.91249015   7.11804721  44.77486964  45.51145741  56.81467061
   2.53218668  29.43934442  19.96509308  43.41956568  13.31454964
  21.21956558  86.11051604  38.17654238  15.44556259  19.20865824
 -13.56767812  -7.96018911   9.11365796   3.02929687   5.21315367
  -5.79756256   6.55149936  24.09508648  -6.34903321  18.77843829
 -24.01553926  -0.87777192 -12.79611426  -3.46896828   2.18855683
   1.58198653   0.48969941  -6.55229527   3.17960076  -5.32957064
   5.5497076    2.04429035   5.84869173  57.00865457  67.96015354
  10.81721005 -17.36134794  -1.35136399  63.4872028   -4.14024021
  18.99127403  52.16900762  -1.66137428   1.03378207  -3.39520547
   5.74559871   1.15695853   5.86485207  -2.41931945  29.92890905]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1722.90499993058
gradient value of function right now is: [-4.91832457e-01 -3.47036183e-01 -2.73747165e-04 -5.47145737e-07
  4.91832457e-01  3.47036183e-01  2.73747165e-04  5.47145737e-07
 -1.81853596e-01 -2.37676628e+00 -9.76745095e-02 -5.16945639e+00
  8.75906502e-03  2.28309088e-01 -2.94385250e-02  1.07092813e+01
 -1.03182264e-05 -2.42801011e-03  8.24392818e-06 -1.73468653e-02
 -1.11894721e-08 -5.33477470e-07  1.17325620e-07 -3.28759064e-05
  5.39027388e-02 -1.51238346e-01 -6.62350649e-03 -1.46004183e-02
 -9.80084606e+00 -2.13447302e+00 -2.49751929e-02 -2.85099540e-01
  1.29860941e+00  6.98706814e-01  1.37534006e-01  1.10734651e+00
  3.21800567e+00 -1.02371841e-01  1.23971471e-05 -2.06024770e-01
  1.86670811e-02  4.70948773e+00 -2.79900187e-01  1.69551488e+00
  5.95146383e-03  1.43358347e+00  1.49696213e+00  3.38039361e-01
 -2.32735205e-06 -2.31021033e-02 -3.38174881e-01 -3.79758919e-03
  1.33612878e-02  1.92172010e-01  3.59543969e+00  1.35553126e-01
  3.31102187e-03 -4.95165650e-02 -6.12374860e+00  1.22736597e+01
  3.40668374e+00 -7.50817583e+00 -2.21817185e+00  1.29967507e+00
  2.31301364e+01]
supnorm grad right now is: 23.130136411983713
Weights right now are: 
[ -9.38177123  17.13648709 -41.82729214 -33.25424915   9.63633994
 -17.24517878  42.22622941  32.53822077  12.73836206  -3.86716232
 -17.16136657   6.78117084  45.43181655  46.30263029  57.21546928
   2.6275305   29.46373911  18.0945602   44.32600157  12.01850676
  21.22152669  86.01068543  38.28885951  16.35504774  19.38695506
 -13.83523845  -8.81000025   9.64655489   2.9122514    5.72273964
  -5.85289846   6.23619017  23.93483341  -5.63187004  19.11611776
 -23.90572065  -0.62965576 -13.6570292   -1.86471204   1.11034871
   0.64990345   0.40416081  -6.58200183   2.95757242  -6.2783333
   5.84962425   1.70105317   5.87512879  59.24756431  69.33401504
  11.29184383 -15.73851294  -2.29889771  63.80670154  -4.32195541
  17.60162103  52.51902569  -1.34968443   0.7830753   -3.23547503
   5.76184528   1.22663689   5.33355974  -2.38915972  30.06953227]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1725.8969652636856
gradient value of function right now is: [-8.88594075e-02  1.06578884e-01 -1.88205357e-06  6.47276940e-08
  8.88594075e-02 -1.06578884e-01  1.88205357e-06 -6.47276940e-08
 -1.50287312e-01 -7.01834189e-01 -6.76865415e-03 -6.45137295e-01
 -5.60969209e-03  6.36583995e-04 -1.25910811e-02 -3.53967990e+00
  1.80950067e-07 -5.15587023e-05  5.73079870e-07 -8.97531798e-05
  3.41096510e-09  5.13577955e-09  1.21640974e-08  4.23314622e-06
  2.73062466e-01  1.05933829e-01  1.79992314e-02  2.52189258e-02
 -5.48646822e-01  3.99765376e-01  8.03713493e-02  1.89132672e-01
  1.78149820e+00  6.34317683e-01  4.82481220e-02  1.58621375e+00
  5.61324523e-01  1.79553848e-02  3.86834730e-04 -2.71391780e-02
  4.71161950e-03  1.62978529e+00 -1.21788834e+00  9.01515747e-01
  3.09306293e-03  2.29485822e-01  9.67490090e-01  6.90548263e-02
 -1.49206646e-06  1.14585213e-02 -1.80984620e-01 -5.06330061e-04
  4.07886208e-03  3.41552557e-02  3.20920694e+00  3.85722400e-02
  7.18018550e-04 -3.08515995e-02 -1.11635452e+00  4.34529421e+00
  8.52986653e-01 -3.72634153e+00 -6.47787120e-01 -2.66370668e-02
  2.87132592e+00]
supnorm grad right now is: 4.345294207191813
Weights right now are: 
[ -9.19265464  17.36853147 -41.21072758 -33.28291586   9.44722335
 -17.47722316  41.60966485  32.56688748  12.17005667  -3.82881339
 -17.10665496   7.03339717  44.9780603   47.37190851  58.49910533
   2.56620856  29.64681619  19.50697511  45.37939563  13.51816357
  21.22445047  85.87356628  38.34844397  17.00282675  20.45957224
 -12.93164844  -8.38160199  10.95259381   3.05383657   5.57921958
  -7.28390263   6.67189559  23.75528576  -5.39194451  17.72586537
 -23.76599168  -1.02561234 -12.90206992  -3.10491455   0.96785305
   2.12918901   0.62307451  -6.29803786   2.99589811  -5.29361415
   6.06696577   2.10706197   4.9767013   62.16564148  70.29547795
  11.43389071 -15.56887045  -1.33484633  64.28041439  -4.22790398
  16.28711971  56.56833419  -0.63778334   0.86602968  -3.31163522
   5.53434474   1.06267272   5.71033245  -2.50764063  29.99831071]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1725.0183102769308
gradient value of function right now is: [-5.80919533e-02 -6.64794662e-02  3.64717277e-06  2.10114885e-07
  5.80919533e-02  6.64794662e-02 -3.64717277e-06 -2.10114885e-07
 -2.16913547e-01 -7.32028020e-01  4.12146773e-02 -1.42726586e-01
  1.60019006e-02  4.90283793e-02 -3.61343281e-02  2.30374684e+00
 -3.46453392e-06 -1.55499514e-05  6.97796072e-06  1.27332147e-04
 -5.73237520e-08  3.70623841e-08  6.33075583e-07  1.14342193e-05
 -2.05410812e-01 -3.05745836e-01 -8.14104843e-02 -1.15290551e-01
 -1.03584318e+00 -1.07710974e+00 -1.87659573e-01 -2.81240052e-01
  4.37781319e+00  1.39594066e+00  9.62935289e-02  3.84027183e+00
  4.05083724e-01 -3.82803804e-02 -2.17459787e-03 -1.49999888e-01
 -1.15692866e-02  2.12058043e+00 -2.09037774e+00  9.56057331e-01
  1.27775321e-02  3.21524951e-01  1.81142905e+00  3.25399608e-02
 -7.65284288e-06 -3.14039410e-02 -4.29912242e-01 -4.04840787e-03
  8.24632439e-02  1.68622489e-01  8.65631379e+00  1.79042302e-01
  1.64204833e-03 -5.82879031e-02 -3.21542017e+00  1.12241926e+01
  4.20541156e+00 -1.48769915e+01 -1.18967300e+00  2.17625799e+00
  5.04981785e+00]
supnorm grad right now is: 14.876991454768913
Weights right now are: 
[-9.31948646e+00  1.73925537e+01 -4.18869318e+01 -3.33526575e+01
  9.57405517e+00 -1.75012454e+01  4.22858690e+01  3.26366291e+01
  1.23262369e+01 -3.61686370e+00 -1.74644432e+01  6.92742055e+00
  4.57124057e+01  4.80997152e+01  5.87277901e+01  2.63928042e+00
  2.95619624e+01  1.93593537e+01  4.59923549e+01  1.28777422e+01
  2.12257208e+01  8.57731382e+01  3.84122052e+01  1.54116095e+01
  1.92542738e+01 -1.34191871e+01 -1.03426050e+01  1.06046660e+01
  3.21552015e+00  5.04446916e+00 -7.06336301e+00  6.44382993e+00
  2.36708115e+01 -4.67615408e+00  1.79634194e+01 -2.36987604e+01
 -1.09099835e+00 -1.23168341e+01 -5.51622973e+00  1.69900374e+00
 -9.93869052e-02  5.66789730e-01 -6.59090376e+00  3.32218744e+00
 -6.23864019e+00  5.87110957e+00  1.80118600e+00  4.46306022e+00
  6.38413937e+01  7.06825447e+01  1.08476228e+01 -1.39682292e+01
  5.72263979e-01  6.49134746e+01 -4.00299202e+00  1.55670281e+01
  6.19837906e+01  2.37066553e-03  1.32595019e+00 -3.22537225e+00
  5.52196372e+00  1.08084984e+00  5.33455810e+00 -2.45252323e+00
  2.99674070e+01]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1725.5037033597612
gradient value of function right now is: [ 1.98114700e-02  7.19211776e-02  2.26395944e-05  5.46434086e-07
 -1.98114700e-02 -7.19211776e-02 -2.26395944e-05 -5.46434086e-07
 -1.45523990e-01 -7.32710764e-02 -7.22093955e-02  3.96762251e-01
  1.69111537e-02 -1.82654055e-02 -1.18886103e-02 -2.20425819e+00
 -1.41134457e-06  1.75330219e-04  1.25786442e-06  1.44243632e-03
 -1.13502012e-07  6.32622176e-07  1.18257739e-07  3.33472091e-05
 -3.41764014e-01 -3.06401261e-01 -1.69683740e-02 -3.44321116e-02
  1.82446472e+00 -4.49954867e-01 -2.62263539e-02 -1.07684804e-02
  1.12876203e+00  3.65682736e-01 -2.97165071e-02  9.13211687e-01
 -6.07533923e-02  3.45584099e-02  3.94109850e-05 -3.58276615e-02
  4.74972228e-03  5.70412183e-01 -1.09390564e+00  3.90153637e-01
 -2.66111190e-03 -3.64557946e-02 -7.20193508e-03 -1.06470587e-01
 -7.04200204e-07 -1.68506572e-02 -4.46308692e-02 -1.27789017e-03
  3.76781944e-03  9.81941361e-02  2.72190926e+00  4.56398148e-02
 -8.36694856e-04 -2.90989502e-02 -2.71786659e+00  6.23907010e+00
  1.19627709e+00 -2.53283405e+00 -1.18446869e-01  1.29939748e-01
  1.20928443e+00]
supnorm grad right now is: 6.239070100345728
Weights right now are: 
[ -9.37821438  17.53419451 -42.81220185 -33.48114792   9.63278309
 -17.6428862   43.21113912  32.76511953  12.37323402  -3.70834302
 -17.32312706   6.95049292  47.03259152  48.92447185  60.13491399
   2.59387828  29.5427713   17.60886254  46.30506125  13.11512778
  21.2256589   85.66698055  38.55723847  14.80153684  18.43948935
 -14.19274649 -10.00382193  11.39658875   3.39903187   5.12030815
  -6.65105027   7.04174159  23.32186015  -4.56764555  17.49300954
 -23.66872403  -1.19409876 -13.07726341  -3.79277601   1.18516692
   2.48030097   0.37621918  -6.14788486   3.54694694  -4.6898073
   6.06345101   1.83174026   3.73589322  66.31078002  71.43350713
  11.59009633 -10.04237898  -1.39109027  65.67972643  -3.9244178
  14.76029288  64.32745084  -1.40038033   0.71825233  -3.24210656
   5.46045546   1.18781862   5.65255353  -2.43574708  29.98125533]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1724.8642689777826
gradient value of function right now is: [ 2.62691497e-01  2.39977701e-01  5.06336925e-05 -7.51406683e-09
 -2.62691497e-01 -2.39977701e-01 -5.06336925e-05  7.51406683e-09
  3.54568157e-01  1.58122006e+00  1.00490069e-01  2.48649225e+00
 -1.72590416e-02 -1.85795752e-01  4.09869793e-02 -8.07064573e+00
  5.20575081e-06  4.96676628e-04 -6.78332969e-06  3.38465600e-03
  1.52215694e-08  2.08196856e-07 -2.47461795e-07  3.34783683e-08
  1.37198499e-01  3.04513548e-01  5.30967945e-02  7.34480415e-02
  7.14115220e+00  2.04838788e+00  7.27375078e-02  2.53679573e-01
 -3.98864338e+00 -1.24189894e+00 -1.10275197e-01 -3.53935841e+00
 -1.69010377e+00  3.67574630e-02  1.53397206e-03 -5.04351326e-02
 -4.72873272e-03 -4.04227978e+00  1.49392557e+00 -1.62477050e+00
 -5.53475384e-03 -1.08981213e+00 -2.78833407e+00 -3.81315478e-01
  4.34095975e-06  2.17105301e-02  3.86448051e-01  5.86384019e-03
 -1.03352309e-02 -2.04260279e-01 -8.94108521e+00 -3.73755003e-01
 -1.14207192e-03  5.50643803e-02  5.42704827e+00 -1.46278697e+01
 -4.40012074e+00  1.40153106e+01  2.08203663e+00 -5.25416122e+00
 -1.85645717e+01]
supnorm grad right now is: 18.564571672435463
Weights right now are: 
[ -9.28266034  17.75357092 -42.57209406 -33.44965653   9.53722905
 -17.86226261  42.97103133  32.73362815  13.06282568  -3.71154088
 -16.50750346   6.92235441  46.8208134   49.58426779  61.48008936
   2.5544857   29.56997815  18.9606308   46.94144786  13.23343359
  21.22897023  85.59264599  38.6812122   16.8582898   18.47830007
 -13.78506437 -10.24373411  11.52565891   3.30211336   5.65731605
  -6.9141393    6.47034048  23.26628755  -4.17524591  17.18179025
 -23.45160244  -1.05228403 -13.17586054  -3.58112069   1.40567751
   2.52890262   0.44151636  -5.99082327   2.98877393  -4.03708686
   6.12191241   1.89777802   2.93176457  68.1130383   69.62845135
  10.89681987  -9.67501216  -2.03576974  67.20075783  -4.08995336
  14.558857    68.62382947  -1.22497083   1.007179    -3.49271055
   5.52771135   1.19066075   5.35227595  -2.13563277  29.94164082]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1725.2085136020291
gradient value of function right now is: [ 1.06247535e-01  1.47921043e-01  2.75509112e-05  1.48747559e-07
 -1.06247535e-01 -1.47921043e-01 -2.75509112e-05 -1.48747559e-07
 -7.62452870e-03  2.60453865e-01  1.12195958e-01  1.43363918e+00
 -1.04771824e-02 -1.32264191e-01  1.41701820e-02 -4.93746838e+00
  1.69046690e-06  2.18465426e-04 -6.57473759e-07  1.81089410e-03
  9.63462213e-09  2.46995290e-07 -4.09754419e-08  8.68322092e-06
  2.55442431e-01  1.89144358e-01  2.40522163e-02  3.17918961e-02
  4.63609163e+00  1.68880113e+00  6.56701427e-02  1.98599914e-01
  6.88490222e-01  6.70815451e-02 -3.64165801e-02  7.18958024e-01
 -5.40168101e-01  5.84780216e-03 -1.21427359e-03 -1.13454969e-01
 -5.83253860e-04 -1.17533569e+00 -7.21906519e-01 -1.98397083e-01
  4.87639462e-04 -6.41770818e-01 -3.35651068e-01 -1.52629854e-01
 -4.73017158e-06  2.71499379e-02  2.80445458e-02  5.26327827e-03
  6.26781038e-03 -8.34012727e-02  8.58249605e-01 -1.96863891e-02
  1.20509776e-03 -4.44029652e-02  3.19534207e+00 -3.49324495e+00
 -7.21785374e-01 -8.78164390e-01  6.90402228e-01 -9.36286456e-02
 -1.05482353e+01]
supnorm grad right now is: 10.548235311009078
Weights right now are: 
[ -9.41013336  17.96845429 -42.21462599 -33.48225593   9.66470207
 -18.07714598  42.61356326  32.76622755  13.02198427  -3.88065687
 -16.8611322    7.0926325   45.89727706  50.32825479  62.66386165
   2.55915194  29.51852686  19.42558064  47.34185105  13.56848599
  21.23021373  85.52714374  38.76502298  16.59543092  19.22152142
 -12.58698766  -9.37423829  13.48578385   3.30538902   5.23733416
  -6.99933435   6.42673354  22.98893093  -3.9881516   17.05466965
 -23.46267815  -0.82829629 -12.84962022  -5.68947519   0.70854736
   3.79829741   0.28106965  -6.07785226   3.31037191  -3.47045988
   5.72436718   2.38931611   2.69724597  70.72027698  72.1384692
  10.23909898  -5.47289825  -2.7506269   67.16657884  -4.018558
  13.38786592  70.82664689  -1.06371801   1.50451526  -3.42564904
   5.55290577   1.02828886   5.59510037  -2.22695038  29.96405226]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1723.966095434707
gradient value of function right now is: [ 2.53655318e-02  8.83737664e-02 -7.78042838e-06  1.20588514e-06
 -2.53655318e-02 -8.83737664e-02  7.78042838e-06 -1.20588514e-06
  1.74645075e-01 -3.26132711e-02  4.52160936e-01  5.47442615e-01
  1.44962000e-02  5.48252713e-02 -3.25080816e-02 -2.80294628e+00
 -1.23885367e-06 -1.39083272e-04  1.29305390e-06 -4.41781788e-04
 -8.64972408e-08 -7.67418852e-08  8.56760334e-07  7.61428475e-05
 -4.48625610e-01 -2.70395411e-01 -5.97014330e-02 -8.22777004e-02
 -1.52645200e+00 -8.96768708e-01 -2.41416827e-01 -2.10140515e-01
  5.91264801e+00  1.44152823e+00  2.98513876e-02  5.01387299e+00
  1.15626086e+00  4.61930744e-02 -4.86129301e-04 -4.97127537e-02
 -1.69450627e-03  9.23574138e-01 -2.30300034e+00 -3.57628035e-01
  1.78624559e-03  5.47207769e-01  1.98316996e+00  1.09586952e-01
 -4.28290552e-06 -3.59980128e-02 -2.94529956e-01 -6.13735453e-03
  8.14402080e-03  1.40250990e-01  1.04476885e+01  3.47092900e-01
  2.55479202e-03 -3.72372598e-02 -3.19440894e+00  9.81950322e+00
  3.63894147e+00 -1.44405726e+01 -9.62339672e-01  5.91808321e+00
  4.47480202e+00]
supnorm grad right now is: 14.440572560244336
Weights right now are: 
[ -9.57258614  18.01396807 -42.25628111 -33.59105089   9.82715485
 -18.12265976  42.65521838  32.87502251  13.71759774  -3.84792054
 -17.06105444   7.18209732  45.95945668  51.01317606  62.79220204
   2.54179477  29.45293328  20.16868594  47.89023084  14.30146105
  21.23109682  85.43816401  38.83743372  14.74595972  17.96582967
 -12.59800829 -10.59191765  12.57833708   3.11194008   5.46561872
  -8.81687491   6.25197235  23.16433495  -3.55789969  17.49288593
 -23.21101857  -0.95923395 -12.67033627  -5.52681796   0.37135243
   4.54467028   0.33509857  -6.14516719   3.32783618  -3.68147164
   6.54860384   1.85632035   2.97906755  72.99935582  70.21090433
  10.60860922  -3.66644238  -3.24784112  68.47366452  -3.86786711
  12.8674616   74.54623421  -1.55365908   1.15655392  -3.3640022
   5.44172524   1.19872421   5.24494542  -2.0025002   29.91083018]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1724.6624992126149
gradient value of function right now is: [-2.71282669e-01 -1.55092649e-01 -1.08028939e-04 -3.15362703e-07
  2.71282669e-01  1.55092649e-01  1.08028939e-04  3.15362703e-07
 -1.74598037e-01 -1.34340565e+00 -1.52419504e-01 -2.92951078e+00
 -3.80401649e-05  4.65004518e-02  2.54535261e-03  5.02821105e+00
 -3.69921477e-06 -9.32852210e-04 -2.42499587e-06 -6.89838702e-03
 -1.43322773e-10 -2.28745084e-07 -8.00109626e-08 -1.99417175e-05
  2.29271888e-01  2.70585678e-03  1.01294443e-02  1.12865065e-02
 -2.96059879e+00 -4.44887268e-01  2.44176133e-02 -6.56943971e-02
 -9.28363459e-01 -1.80284680e-01 -1.22622446e-02 -6.68329913e-01
  1.87456385e+00 -3.54815830e-02 -1.71785958e-03  8.82084387e-02
  1.50420985e-02  2.60743901e+00  7.62227239e-01  1.29081324e+00
  2.08530925e-03  4.19312419e-01  2.58960990e-01  1.73161900e-01
 -8.10321432e-08  5.17088645e-04  1.49268782e-02 -7.85435622e-05
  3.06173757e-03  1.20856388e-02 -8.87563034e-01  9.98990331e-03
 -3.80675328e-03 -9.22944382e-02 -4.75175801e-01  9.59906974e-02
  2.74794014e-01  1.61578259e+00 -6.19633111e-01 -1.25183336e+00
  9.84916830e+00]
supnorm grad right now is: 9.849168302844834
Weights right now are: 
[ -9.86030294  17.99667054 -43.36818621 -33.5858333   10.11487165
 -18.10536223  43.76712348  32.86980492  13.04104472  -3.85103797
 -18.37495935   6.69997497  46.48146085  51.44436055  62.10388622
   2.71751388  29.57409652  19.52512209  48.34696618  11.96029913
  21.23265096  85.29463067  39.00092321  16.34541415  18.07637376
 -12.45632052 -10.0939967   13.83201415   3.16295155   5.36982402
  -7.64263797   6.4282313   22.77609927  -3.60681016  17.67585624
 -23.22115968  -0.63584198 -11.61748203  -5.2164674    1.31013784
   7.58535298   0.479234    -6.1713269    3.06245655  -4.77223316
   5.86348659   2.00408623   2.33477685  75.26127229  72.3578863
  10.58918714   0.52360384  -5.0398918   68.94603745  -4.04418586
  11.01696285  74.69269536  -1.22788346   1.32281302  -3.38817371
   5.24368195   1.19224067   5.82018507  -2.23709786  30.13422783]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1724.7132002378564
gradient value of function right now is: [-3.60598711e-02  4.51590087e-02 -7.27752978e-06  1.16589792e-06
  3.60598711e-02 -4.51590087e-02  7.27752978e-06 -1.16589792e-06
 -1.17870055e-01 -3.97531175e-01  6.08654946e-02 -2.18835854e-01
  5.76946609e-03  1.57208332e-01 -5.51209084e-02 -9.69287246e-01
 -1.12838871e-06 -1.42603722e-04  1.03730076e-05 -5.30115974e-04
 -5.33803324e-09 -2.00369346e-07  8.02573832e-07  6.64198025e-05
 -3.61331092e-02 -8.57097854e-02  1.59730324e-02  1.88452828e-02
 -5.59264303e+00 -1.70898029e+00  4.72760438e-02  7.68933212e-02
  4.96587493e+00  1.35231997e+00  1.60086908e-01  4.08707211e+00
  1.08854026e+00  9.44272254e-02  3.97595723e-05  5.54066660e-01
  5.49790693e-03  1.88184613e+00 -2.16877171e+00  6.93921643e-01
  3.44954725e-03  9.98807710e-01  3.08961323e+00  3.50691706e-01
 -1.39512065e-06 -1.02734896e-02 -4.04980683e-01 -4.52069900e-03
  6.38234572e-03  2.26624170e-01  1.06695758e+01  4.24836705e-01
  2.35942765e-04 -6.06189057e-02 -6.18248678e+00  1.89608433e+01
  3.63988405e+00 -1.40807900e+01 -1.27954981e+00  5.13137856e+00
  1.43044883e+01]
supnorm grad right now is: 18.960843329616356
Weights right now are: 
[ -9.72567779  18.30259406 -41.71017189 -33.61357648   9.98024651
 -18.41128575  42.10910916  32.8975481   13.55461506  -3.89555279
 -18.47485613   7.11201944  46.40907469  52.28482785  61.70657939
   2.60537788  29.60020785  20.90001284  48.71019273  13.41986323
  21.23437273  85.217518    39.08786641  16.32790259  18.29482963
 -11.96986874 -11.24743513  13.8005645    3.20234202   5.250127
  -6.69898146   7.309223    22.58853824  -3.34250196  17.73437457
 -23.1042672   -1.14620768 -12.75010504  -5.03203438   1.65001645
   4.75724715   0.1942043   -6.05594383   3.49421999  -3.47699281
   5.98258894   2.35534182   2.56199846  75.42101004  72.55932167
  10.66784312   4.46363699  -2.52180963  69.83718108  -3.90647486
  10.78835413  79.71186243  -1.54054409   1.28574849  -3.30557525
   5.44093318   1.1713763    5.42377624  -2.10674038  30.1054471 ]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1725.324597719403
gradient value of function right now is: [ 1.83313250e-01 -1.03392079e-01  1.75597313e-05 -2.38724563e-07
 -1.83313250e-01  1.03392079e-01 -1.75597313e-05  2.38724563e-07
  6.10373309e-02  9.58068222e-01 -3.70135426e-03  2.05460748e+00
 -1.94458967e-03 -3.89638411e-02  1.91874464e-02  3.38990114e+00
  1.78822734e-06  2.39114643e-04 -1.34556917e-06  1.00181396e-03
  2.34115002e-09  1.15584218e-07 -1.05240380e-07 -1.52814766e-05
 -1.03494235e-01  3.73663505e-02  1.17816400e-02  1.58928326e-02
  2.27905749e+00  2.47889034e-01  2.49367669e-02 -1.35154823e-02
 -1.34425167e+00 -4.65808724e-01 -8.09361128e-02 -1.15612777e+00
 -2.15702662e+00 -1.03863297e-01 -2.03897566e-04 -3.28166225e-01
 -3.02861169e-03 -2.37055784e+00  3.21147979e-01 -8.21341860e-01
 -7.06508789e-03 -3.16853394e-01 -1.25716849e+00 -1.71802680e-01
 -3.43033129e-08  7.02642769e-03  2.01617033e-01  1.57667502e-03
 -6.86575459e-03 -5.54058661e-02 -2.97118831e+00 -9.91468827e-02
 -2.87812551e-03  7.29853988e-02  1.36462291e+00 -4.43403506e+00
 -1.61013937e+00  4.32721199e+00  1.08324596e+00 -1.84470872e-01
 -9.45653576e+00]
supnorm grad right now is: 9.456535764226091
Weights right now are: 
[ -9.6650762   18.30527367 -42.15875855 -33.63736628   9.91964492
 -18.41396536  42.55769582  32.92133789  13.47127829  -3.73448909
 -18.31931751   7.16708019  47.13846447  53.03109789  63.86726155
   2.72031441  29.80292945  20.32360698  49.6403346   13.6824796
  21.23572004  85.11574824  39.19370249  16.70114351  17.79650337
 -12.24864475 -12.1574564   13.29912183   3.39852895   5.06614452
  -8.10901601   6.49618037  22.26503871  -3.33607447  17.5155389
 -23.06688889  -1.27452681 -11.62619496  -7.03397137   0.91701495
   3.03065409   0.26997046  -6.15562598   3.37735973  -3.74162847
   7.05522159   1.89501805   2.02165982  75.90131005  74.29477449
   9.98379829   8.90694911  -5.89762554  70.92257075  -3.57277918
  10.70579131  83.73435603   0.15542859   1.11637802  -3.24007657
   5.40188934   1.40369382   4.90861508  -2.05905495  29.88312016]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1721.6231912052408
gradient value of function right now is: [ 3.11358102e-01  3.30124700e-01  1.02354056e-04  2.05189145e-06
 -3.11358102e-01 -3.30124700e-01 -1.02354056e-04 -2.05189145e-06
  2.73610489e-01  1.50809345e+00  1.56826038e-01  3.69379573e+00
 -7.15217078e-03 -1.87051048e-01  3.28527042e-03 -1.12491797e+01
  4.17101346e-06  8.38742152e-04 -2.28142846e-07  6.70278765e-03
  5.84589883e-08  2.49209661e-06 -2.01266076e-07  1.29246002e-04
 -1.23913311e-01  1.27180978e-01  2.05383370e-02  3.03523654e-02
  8.93534668e+00  1.71533946e+00  4.11721826e-02  1.69800931e-01
 -2.62947062e-01 -2.63559284e-01 -9.32325303e-02 -4.86866200e-01
 -2.05047327e+00  1.14882517e-01  7.79605851e-04  1.32537488e-02
 -8.09924761e-03 -5.11537456e+00 -9.95956989e-01 -2.45810963e+00
 -2.22435294e-02 -8.16948785e-01 -1.52093845e+00 -4.55169458e-01
 -3.09921102e-07  1.16965141e-02  1.98642968e-01  1.34516962e-03
  1.96931129e-03 -2.96464330e-02 -6.95199140e-01 -1.05800862e-02
  1.69826289e-03  3.53082682e-03  1.79376045e+00 -2.21775186e+00
 -2.54668928e+00  3.56060625e+00  1.51704937e+00  2.02425415e+00
 -1.88277600e+01]
supnorm grad right now is: 18.82775996731081
Weights right now are: 
[-10.1476505   18.43385625 -42.7502564  -33.86980858  10.40221921
 -18.54254794  43.14919367  33.1537802   13.81673906  -4.04735148
 -17.93277481   6.80059541  46.97115753  53.36881105  65.42781497
   2.58455718  29.65999499  20.68249196  49.22511319  12.92630968
  21.23796121  84.99365451  39.30743816  14.65446332  17.24408807
 -11.84968702 -12.52027282  13.48556478   3.51706188   5.36963907
  -7.3468905    6.39431579  22.09831482  -3.1903456   16.74782413
 -23.09385021  -1.21419023 -12.14585486  -7.89967188   1.28023719
   4.9647511   -0.13913294  -6.17991212   3.34342828  -4.98616736
   7.04363046   1.68230491   1.22504895  75.92591771  74.24201207
  10.45251749  12.92502349  -4.2412589   72.19057446  -3.60407251
   9.18416024  85.97244059  -0.89281054   0.80634903  -3.27090971
   5.23205399   1.26258291   5.17532789  -1.92558744  29.78928941]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1726.6650286812176
gradient value of function right now is: [ 1.65530243e-02 -6.29642915e-03  2.97385072e-06 -3.08539124e-07
 -1.65530243e-02  6.29642915e-03 -2.97385072e-06  3.08539124e-07
 -7.98018301e-02  2.00382430e-02 -7.00210284e-02  2.69965477e-01
 -3.22056922e-03 -2.35538343e-02  7.02114912e-03  1.05769051e-01
  3.95305557e-07  3.47936470e-05 -5.59964474e-07  1.82657175e-04
  1.41615855e-08  1.70451858e-07 -2.79736270e-07 -1.88514030e-05
  1.09619942e-01  6.02180037e-02  1.65482719e-02  2.23940519e-02
  9.66697700e-01  3.03800486e-01  3.89906217e-02  7.46058459e-02
 -4.93904466e-01 -1.12163894e-01 -1.80911117e-02 -3.71967383e-01
 -4.44212657e-01 -3.11352291e-02 -1.93039513e-04 -1.06193305e-01
  2.54389838e-03  8.24599830e-03  7.72488781e-02  2.85899395e-01
 -5.82800992e-06 -1.45802964e-01 -3.91475246e-01 -5.46804922e-02
 -2.30168602e-07  6.23826764e-03  5.57963754e-02  1.44023030e-03
  1.00322276e-03 -2.68585112e-02 -9.73346480e-01 -4.35148741e-02
 -3.70857180e-04 -2.40648161e-02  7.68152445e-01 -1.76549059e+00
 -6.25941215e-01  1.97626656e+00  1.98137704e-01 -7.50265459e-01
 -2.73648273e+00]
supnorm grad right now is: 2.7364827325042813
Weights right now are: 
[-1.02084216e+01  1.83446556e+01 -4.19127142e+01 -3.39027882e+01
  1.04629904e+01 -1.84533473e+01  4.23116514e+01  3.31867598e+01
  1.50086164e+01 -3.86147365e+00 -1.76758633e+01  6.69725730e+00
  4.62696945e+01  5.36038024e+01  6.46562481e+01  2.77474968e+00
  2.96726932e+01  2.18346955e+01  5.00318841e+01  1.62962732e+01
  2.12430073e+01  8.49014545e+01  3.99680433e+01  1.57533717e+01
  1.70618242e+01 -1.08953484e+01 -1.28100930e+01  1.38282821e+01
  3.26549638e+00  5.48252195e+00 -7.55286957e+00  7.26347880e+00
  2.18973551e+01 -2.79278572e+00  1.83190439e+01 -2.31656957e+01
 -1.12189248e+00 -1.19724147e+01 -6.78698454e+00  1.21444451e+00
  6.25294337e+00  6.56746255e-02 -6.16930568e+00  3.53198208e+00
 -1.95420495e+00  6.99004495e+00  2.07090189e+00  2.28529594e+00
  7.61748870e+01  7.35760749e+01  9.60113988e+00  1.55818133e+01
 -3.92423427e+00  7.32127592e+01 -3.57858640e+00  9.29209719e+00
  8.79189795e+01 -3.28758684e+00  9.49817747e-01 -3.46572995e+00
  5.29266894e+00  1.24745630e+00  4.14547566e+00 -2.03906488e+00
  3.00804373e+01]
(65,)
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1726.6479615705312
gradient value of function right now is: [ 3.28700003e-02 -1.94084850e-03  1.83031670e-06 -1.53102421e-07
 -3.28700003e-02  1.94084850e-03 -1.83031670e-06  1.53102421e-07
 -6.62605804e-02  1.14258904e-01 -5.91341713e-02  4.48233958e-01
 -3.16730678e-03 -2.28759073e-02  6.59524679e-03 -2.99855686e-02
  2.51641748e-07  2.18893145e-05 -2.34719008e-07  1.10324731e-04
  7.81610844e-09  1.07850187e-07 -1.50108668e-07 -9.41289003e-06
  8.72254522e-02  5.87859480e-02  1.38598282e-02  1.80286878e-02
  1.00712704e+00  3.03721200e-01  3.81458796e-02  7.61256325e-02
 -4.14262349e-01 -9.03022002e-02 -1.44804392e-02 -3.13029490e-01
 -5.39679191e-01 -2.69414029e-02 -2.05568033e-04 -1.01638221e-01
  2.81077257e-03 -1.72539283e-01  4.15202382e-02  2.00518226e-01
 -1.26861212e-05 -1.41364198e-01 -3.59005358e-01 -5.38376721e-02
 -2.24228068e-07  6.25312769e-03  4.45016789e-02  1.35119118e-03
  8.49133368e-04 -2.63266998e-02 -8.90213188e-01 -4.22041000e-02
 -3.14521608e-04 -2.23363488e-02  7.10335086e-01 -1.68991204e+00
 -5.47788963e-01  1.71456749e+00  2.68836179e-01 -5.89128892e-01
 -2.90502524e+00]
supnorm grad right now is: 2.905025239743177
Weights right now are: 
[-10.06486027  18.66920369 -41.89217358 -33.94728966  10.31942899
 -18.77789538  42.29111085  33.23126127  14.33087961  -4.03062148
 -18.0025129    6.95051929  47.4739692   53.86786044  64.54444924
   2.65642942  29.69091102  21.74138231  50.08091445  15.11542639
  21.24378471  84.8494378   40.04591012  15.90910768  17.55259055
 -11.37446593 -12.96391183  14.42963996   3.44011561   5.04196797
  -9.13293006   7.25459276  21.50324642  -2.86996967  17.87916996
 -23.05389175  -1.13653723 -11.83321754  -4.88910768   1.05615996
   2.28971392   0.33218962  -5.35041028   3.39696367  -3.55653219
   6.64942273   2.20914839   1.80132909  76.29256982  74.52716557
   9.38148728  18.46715271  -8.74669972  74.13611548  -3.53382304
   8.89294772  90.71946238  -0.84453216   1.05682854  -3.36733167
   5.49174361   1.30676248   4.23233529  -2.14114338  29.93498102]
(65,)
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1726.6717652909033
gradient value of function right now is: [ 3.05051689e-02 -1.44729970e-03  1.75324115e-06 -1.11721335e-07
 -3.05051689e-02  1.44729970e-03 -1.75324115e-06  1.11721335e-07
 -5.89912655e-02  1.07477472e-01 -5.47857688e-02  4.11710799e-01
 -2.96188024e-03 -2.11193176e-02  6.36917889e-03 -3.83303310e-02
  2.28425163e-07  2.02114878e-05 -2.08432840e-07  1.05036112e-04
  5.95948156e-09  8.63800386e-08 -1.14913040e-07 -6.91526829e-06
  8.44198685e-02  5.58829255e-02  1.39450136e-02  1.80784373e-02
  9.26485857e-01  2.90227904e-01  4.10084845e-02  8.13781211e-02
 -4.34973906e-01 -9.82207578e-02 -1.44750350e-02 -3.33387035e-01
 -4.98622001e-01 -2.50199571e-02 -1.80509495e-04 -8.62464934e-02
  2.63472316e-03 -1.66590643e-01  7.55048156e-02  1.88676585e-01
  1.18195233e-05 -1.39057969e-01 -3.30041271e-01 -4.78587579e-02
 -2.07579555e-07  6.67872418e-03  4.47792383e-02  1.37682623e-03
  7.72709787e-04 -2.68351256e-02 -9.14668985e-01 -3.99921522e-02
 -1.99825013e-04 -2.02359858e-02  7.28073581e-01 -1.69803712e+00
 -5.47530840e-01  1.73703971e+00  2.44306288e-01 -5.14984266e-01
 -2.82647689e+00]
supnorm grad right now is: 2.826476891102051
Weights right now are: 
[ -9.69655058  18.89024631 -40.98776676 -33.96061399   9.95111929
 -18.998938    41.38670403  33.2445856   13.83265503  -3.60742941
 -17.96200829   7.27358587  47.53405051  54.50061596  66.23355828
   2.62728547  29.72656659  21.75840143  50.25418879  14.25702011
  21.24432565  84.80637266  40.16142971  16.40091887  17.5898758
 -10.79915323 -13.10229525  14.79594865   3.38634844   5.21303446
  -7.73432394   7.25818317  21.52656494  -2.73660768  16.93513306
 -22.73924913  -0.90586713 -11.54783831  -7.42299785   0.93516949
   2.36884723   0.54674596  -6.01486577   3.49661168  -3.43284924
   6.48157373   2.11778637   2.72037021  75.97524987  74.60533743
   9.19876615  19.31026589  -8.40417099  74.92614004  -3.61950705
   7.73059301  94.53062315  -1.6612246    1.32203442  -3.19340029
   5.12530555   1.21686408   5.44337759  -2.09004187  29.89216643]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1726.685467111208
gradient value of function right now is: [ 3.58382353e-02 -1.86557313e-03  1.62822607e-06 -1.01196589e-07
 -3.58382353e-02  1.86557313e-03 -1.62822607e-06  1.01196589e-07
 -4.84906435e-02  1.36542987e-01 -4.44296146e-02  4.69582565e-01
 -2.82555173e-03 -2.08588567e-02  6.46031263e-03 -2.40044812e-02
  1.99005348e-07  1.83249140e-05 -1.87007633e-07  9.59694305e-05
  5.05597919e-09  8.14847821e-08 -1.04194644e-07 -6.28196310e-06
  7.52404744e-02  5.35511538e-02  1.40194431e-02  1.80613767e-02
  9.29837734e-01  2.92270582e-01  4.28891974e-02  8.50637123e-02
 -4.15092081e-01 -9.18452456e-02 -1.14483878e-02 -3.19337029e-01
 -5.43480968e-01 -2.68548810e-02 -1.78067998e-04 -9.34249851e-02
  2.43458887e-03 -2.53742672e-01  6.12591976e-02  1.44555152e-01
  1.36555348e-05 -1.40246672e-01 -3.30164562e-01 -4.66025121e-02
 -1.86664340e-07  6.55336058e-03  3.87870757e-02  1.24390678e-03
  7.16695350e-04 -2.80225098e-02 -9.14373540e-01 -4.12388523e-02
 -1.19434945e-04 -1.91292032e-02  7.53916723e-01 -1.80265208e+00
 -5.34952007e-01  1.70302253e+00  2.70090960e-01 -4.23463234e-01
 -2.89028297e+00]
supnorm grad right now is: 2.8902829712582774
Weights right now are: 
[-10.04444724  18.93746827 -39.95398488 -33.9677215   10.29901595
 -19.04615996  40.35292215  33.25169311  13.94457382  -3.83152349
 -18.68799859   6.78831874  48.33165538  55.30819566  64.75511961
   2.71262381  29.72880955  23.99101791  50.35091058  16.07667507
  21.24511141  84.76179039  40.25187757  16.92677686  17.06733586
 -11.02294371 -13.96862336  14.35602461   3.52933105   5.02966778
  -8.17895209   6.56472574  21.47982007  -2.50093843  17.7773041
 -22.47513093  -1.35981587 -10.69811857  -5.41641653   1.17200326
   3.27561529   0.32202048  -5.75103967   3.0271165   -5.21882878
   6.96756587   1.76643251   2.73837949  76.30918008  75.13529274
  10.7058249   21.44560247 -11.41593621  75.32267577  -3.68184807
   6.65453027  95.80016186  -1.71661137   1.30917937  -3.35883443
   5.39385614   1.14198533   5.08806671  -2.005369    29.77265001]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1726.6760720827997
gradient value of function right now is: [ 3.48115695e-02 -3.57596136e-03  1.47616598e-06 -9.00007583e-08
 -3.48115695e-02  3.57596136e-03 -1.47616598e-06  9.00007583e-08
 -4.90134065e-02  1.30800989e-01 -4.41488696e-02  4.56150647e-01
 -2.79353190e-03 -2.02233290e-02  6.92962300e-03  3.83044753e-02
  1.72734539e-07  1.59750088e-05 -1.82045496e-07  8.63488349e-05
  4.34572306e-09  7.42389196e-08 -9.28965900e-08 -5.61027090e-06
  7.57522425e-02  5.33682906e-02  1.40494258e-02  1.79432594e-02
  9.14091004e-01  2.82194663e-01  4.18739216e-02  8.21954778e-02
 -4.31891510e-01 -1.00735926e-01 -1.52993652e-02 -3.30928092e-01
 -5.34471305e-01 -2.75076641e-02 -2.05307344e-04 -9.55535872e-02
  3.04025744e-03 -2.32168245e-01  6.78297267e-02  1.48324234e-01
 -4.63003004e-06 -1.33353760e-01 -3.35663236e-01 -4.50748626e-02
 -1.15313380e-07  6.69872195e-03  4.28718965e-02  1.23218960e-03
  4.76854655e-04 -2.92240708e-02 -9.45760801e-01 -4.32533151e-02
 -2.72961264e-04 -1.77682214e-02  7.63328507e-01 -1.90649868e+00
 -5.41338088e-01  1.75564581e+00  2.50215079e-01 -4.44374425e-01
 -2.87413982e+00]
supnorm grad right now is: 2.87413982139201
Weights right now are: 
[ -9.95418918  19.18523603 -39.88700852 -33.99838629  10.20875789
 -19.29392772  40.28594579  33.28235791  14.25334761  -4.03627225
 -17.44850424   7.04456745  48.63808372  55.87771021  66.91332581
   2.65041253  29.75110802  24.25939663  50.39871458  14.90991301
  21.24593464  84.69913368  40.31527091  16.37370809  17.06063751
 -10.9167605  -14.30023377  14.34939104   3.38666551   5.51938789
  -7.957319     6.96840622  21.33060312  -2.30176498  17.61977733
 -22.35503454  -1.0039369  -12.25343871  -7.59165871   0.75000137
   1.68604965   0.25333849  -6.04043261   2.89834983  -1.20803554
   7.41820959   2.05886646   2.3185124   76.31049993  73.67251183
   9.88702437  22.4173812  -12.07677766  77.00376775  -3.51278897
   7.45779306  98.10431944  -2.11529484   1.09849882  -3.42718565
   5.62018949   1.21649228   5.75369679  -1.60727866  29.94444084]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1267.6537149981364
W_T_median: 1107.4695347805875
W_T_pctile_5: 898.9790057245737
W_T_CVAR_5_pct: 839.346820939712
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.7
F value: -1726.6760720827997
-----------------------------------------------
