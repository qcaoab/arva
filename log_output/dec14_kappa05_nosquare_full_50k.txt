Starting at: 
14-12-22_14:12

 Random seed:  2  



############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
3.3333333333333335% of MC simulations done.
6.666666666666667% of MC simulations done.
10.0% of MC simulations done.
13.333333333333334% of MC simulations done.
16.666666666666664% of MC simulations done.
20.0% of MC simulations done.
23.333333333333332% of MC simulations done.
26.666666666666668% of MC simulations done.
30.0% of MC simulations done.
33.33333333333333% of MC simulations done.
36.666666666666664% of MC simulations done.
40.0% of MC simulations done.
43.333333333333336% of MC simulations done.
46.666666666666664% of MC simulations done.
50.0% of MC simulations done.
53.333333333333336% of MC simulations done.
56.666666666666664% of MC simulations done.
60.0% of MC simulations done.
63.33333333333333% of MC simulations done.
66.66666666666666% of MC simulations done.
70.0% of MC simulations done.
73.33333333333333% of MC simulations done.
76.66666666666667% of MC simulations done.
80.0% of MC simulations done.
83.33333333333334% of MC simulations done.
86.66666666666667% of MC simulations done.
90.0% of MC simulations done.
93.33333333333333% of MC simulations done.
96.66666666666667% of MC simulations done.
100.0% of MC simulations done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1  logistic_sigmoid   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)    False        None  
2     (10, 10)    False        None  
3      (10, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)    False        None  
2     (10, 10)    False        None  
3      (10, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1  logistic_sigmoid   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)     False        None  
0     (10, 10)     False        None  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)     False        None  
0     (10, 10)     False        None  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1579.8088921591966
W_T_median: 1137.3149081751399
W_T_pctile_5: -129.57910035187072
W_T_CVAR_5_pct: -296.09225597438984
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1584.6723013142312
Current xi:  [-101.52215]
objective value function right now is: -1584.6723013142312
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1589.6802848453026
Current xi:  [-131.85028]
objective value function right now is: -1589.6802848453026
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1594.9481164093195
Current xi:  [-148.23769]
objective value function right now is: -1594.9481164093195
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -1596.3462890925382
Current xi:  [-158.54689]
objective value function right now is: -1596.3462890925382
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1597.0344065320778
Current xi:  [-164.13525]
objective value function right now is: -1597.0344065320778
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [-168.46846]
objective value function right now is: -1590.5190974676902
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [-171.02428]
objective value function right now is: -1593.7581299179876
16.0% of gradient descent iterations done. Method = Adam
new min fval:  -1599.317791025842
Current xi:  [-173.25046]
objective value function right now is: -1599.317791025842
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [-174.41054]
objective value function right now is: -1596.1095948845345
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [-172.40973]
objective value function right now is: -1593.4328446674722
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -1603.288005370694
Current xi:  [-170.57536]
objective value function right now is: -1603.288005370694
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [-169.39383]
objective value function right now is: -1597.6466843919368
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [-168.50208]
objective value function right now is: -1591.651114130217
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [-168.00009]
objective value function right now is: -1598.7074393143462
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [-167.20267]
objective value function right now is: -1597.9161518175986
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [-166.76363]
objective value function right now is: -1590.9479499931863
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [-166.17029]
objective value function right now is: -1599.7943228286686
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [-165.51996]
objective value function right now is: -1594.3048679555682
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [-165.08131]
objective value function right now is: -1596.5974637320392
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [-164.07721]
objective value function right now is: -1595.388598450597
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [-164.20685]
objective value function right now is: -1602.1810208483312
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [-164.38612]
objective value function right now is: -1601.1633212304976
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [-163.88718]
objective value function right now is: -1597.4586138060035
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [-164.11336]
objective value function right now is: -1600.7271336482104
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [-164.19046]
objective value function right now is: -1596.6353476844372
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [-164.3206]
objective value function right now is: -1599.2492342649734
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [-165.08989]
objective value function right now is: -1580.4404751372108
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [-164.98927]
objective value function right now is: -1598.0651090382812
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [-164.93513]
objective value function right now is: -1592.8570518745407
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [-164.56816]
objective value function right now is: -1602.8250393808614
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [-164.84363]
objective value function right now is: -1587.4825082790878
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [-165.23332]
objective value function right now is: -1597.1398410437132
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [-165.28632]
objective value function right now is: -1600.0178715419543
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [-165.66045]
objective value function right now is: -1594.694198313379
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [-165.5949]
objective value function right now is: -1602.15261080354
72.0% of gradient descent iterations done. Method = Adam
Current xi:  [-165.80681]
objective value function right now is: -1601.244090882603
74.0% of gradient descent iterations done. Method = Adam
Current xi:  [-166.06097]
objective value function right now is: -1588.0662978750966
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [-166.80391]
objective value function right now is: -1601.69757672219
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [-165.87914]
objective value function right now is: -1600.520925575245
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [-165.97942]
objective value function right now is: -1601.4205804948058
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [-164.79488]
objective value function right now is: -1601.3207086425584
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [-164.43459]
objective value function right now is: -1595.4805521044455
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [-165.12889]
objective value function right now is: -1599.0682294459373
88.0% of gradient descent iterations done. Method = Adam
new min fval:  -1603.4673423521408
Current xi:  [-164.7895]
objective value function right now is: -1603.4673423521408
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [-165.95891]
objective value function right now is: -1599.9397200726428
new min fval from sgd:  -1603.692414674268
new min fval from sgd:  -1604.244205411401
new min fval from sgd:  -1604.626582529883
new min fval from sgd:  -1605.0207084169763
new min fval from sgd:  -1605.6447502623607
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [-166.38593]
objective value function right now is: -1596.8982033996554
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [-167.11809]
objective value function right now is: -1599.2436398522402
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [-168.13254]
objective value function right now is: -1584.937818514524
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [-167.8747]
objective value function right now is: -1603.4686513011102
new min fval from sgd:  -1605.814352060755
new min fval from sgd:  -1606.0607473930418
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [-169.66876]
objective value function right now is: -1597.7836559885254
Traceback (most recent call last):
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/decumulation_driver.py", line 863, in <module>
    fun_RUN__wrapper.RUN__wrapper_ONE_stage_optimization(
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/fun_RUN__wrapper.py", line 116, in RUN__wrapper_ONE_stage_optimization
    RUN__wrapper_training_testing_NN(
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/fun_RUN__wrapper.py", line 216, in RUN__wrapper_training_testing_NN
    res_adam = fun_train_NN.train_NN( theta0 = theta0,
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/fun_train_NN.py", line 196, in train_NN
    result_pyt_adam = run_Gradient_Descent_pytorch(NN_list= NN_list,
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/fun_train_NN_SGD_algorithms.py", line 256, in run_Gradient_Descent_pytorch
    min_fval, _ = objfun_pyt(NN_list_min, params, xi_min)
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/fun_eval_objfun_NN_strategy.py", line 31, in eval_obj_NN_strategy_pyt
    params, g, qsum_T_vector = fun_invest_NN_strategy.withdraw_invest_NN_strategy(NN_list, params)
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/fun_invest_NN_strategy.py", line 183, in withdraw_invest_NN_strategy
    a_t_n_output = NN_list[1].forward(phi_2)
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_NN_Pytorch.py", line 83, in forward
    return self.model(input_tensor)
  File "/home/marcchen/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/marcchen/.local/lib/python3.10/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/marcchen/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/marcchen/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py", line 290, in forward
    return torch.sigmoid(input)
RuntimeError: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 23.69 GiB total capacity; 22.30 GiB already allocated; 58.75 MiB free; 22.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
