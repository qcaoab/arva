Starting at: 
26-11-22_09:10

 Random seed:  2  



############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
3.3333333333333335% of MC simulations done.
6.666666666666667% of MC simulations done.
10.0% of MC simulations done.
13.333333333333334% of MC simulations done.
16.666666666666664% of MC simulations done.
20.0% of MC simulations done.
23.333333333333332% of MC simulations done.
26.666666666666668% of MC simulations done.
30.0% of MC simulations done.
33.33333333333333% of MC simulations done.
36.666666666666664% of MC simulations done.
40.0% of MC simulations done.
43.333333333333336% of MC simulations done.
46.666666666666664% of MC simulations done.
50.0% of MC simulations done.
53.333333333333336% of MC simulations done.
56.666666666666664% of MC simulations done.
60.0% of MC simulations done.
63.33333333333333% of MC simulations done.
66.66666666666666% of MC simulations done.
70.0% of MC simulations done.
73.33333333333333% of MC simulations done.
76.66666666666667% of MC simulations done.
80.0% of MC simulations done.
83.33333333333334% of MC simulations done.
86.66666666666667% of MC simulations done.
90.0% of MC simulations done.
93.33333333333333% of MC simulations done.
96.66666666666667% of MC simulations done.
100.0% of MC simulations done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       8  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       8  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1  logistic_sigmoid   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 8)    False        None  
2       (8, 8)    False        None  
3       (8, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       8  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       8  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 8)    False        None  
2       (8, 8)    False        None  
3       (8, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer        8  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer        8  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1  logistic_sigmoid   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0       (2, 8)     False        None  
0       (8, 8)     False        None  
0       (8, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer        8  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer        8  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0       (2, 8)     False        None  
0       (8, 8)     False        None  
0       (8, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1576.8182150775267
W_T_median: 1136.7449346433505
W_T_pctile_5: -127.64084552288806
W_T_CVAR_5_pct: -295.72244238283764
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
Current xi:  [12.9292345]
objective value function right now is: -1086.8078004096733
4.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.37825]
objective value function right now is: -1263.459620363613
6.0% of gradient descent iterations done. Method = Adam
Current xi:  [4.6361876]
objective value function right now is: -1543.8327426969468
8.0% of gradient descent iterations done. Method = Adam
Current xi:  [1.1169442]
objective value function right now is: -1543.457193539692
10.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.09338741]
objective value function right now is: -1545.0638644121798
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [1.8357362]
objective value function right now is: -1564.0903690024197
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [7.5180693]
objective value function right now is: -1575.6136740321988
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.083101]
objective value function right now is: -1577.5326323508643
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.15343]
objective value function right now is: -1578.0858170133251
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.060165]
objective value function right now is: -1580.3982381382395
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.139506]
objective value function right now is: -1585.8890286195813
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.446169]
objective value function right now is: -1580.6790352412513
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.719323]
objective value function right now is: -1581.1212853421678
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [8.153623]
objective value function right now is: -1584.1135533334584
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [6.797555]
objective value function right now is: -1560.791728407214
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [7.3156543]
objective value function right now is: -1547.6862978845422
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.550645]
objective value function right now is: -1589.8441989846556
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.767878]
objective value function right now is: -1589.7735498678219
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.051205]
objective value function right now is: -1578.6329178500773
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.669685]
objective value function right now is: -1584.7711871796855
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.045454]
objective value function right now is: -1584.274863676294
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.9049835]
objective value function right now is: -1592.469064398994
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.912589]
objective value function right now is: -1587.0787921405129
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.111106]
objective value function right now is: -1585.8374227623335
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.073601]
objective value function right now is: -1591.403659240743
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.970621]
objective value function right now is: -1589.6290015430793
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.3266115]
objective value function right now is: -1593.0548840398951
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [9.38962]
objective value function right now is: -1571.7052385616107
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [8.459783]
objective value function right now is: -1592.9944525653732
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.968609]
objective value function right now is: -1594.3615377976523
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.1221695]
objective value function right now is: -1589.1025432370302
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.468576]
objective value function right now is: -1586.0988907872909
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.077566]
objective value function right now is: -1580.0644156414985
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.1466875]
objective value function right now is: -1592.9181793381522
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.333143]
objective value function right now is: -1594.4105836564343
72.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.374183]
objective value function right now is: -1582.2162965242471
74.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.795152]
objective value function right now is: -1593.5180267876494
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.934669]
objective value function right now is: -1594.7050713500018
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.014258]
objective value function right now is: -1594.2341846737104
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.051839]
objective value function right now is: -1588.9549494761995
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.595921]
objective value function right now is: -1594.303464741132
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.182322]
objective value function right now is: -1580.13806693972
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.301494]
objective value function right now is: -1585.7662132811568
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.274551]
objective value function right now is: -1595.6200283820472
new min fval:  119.60964958104827
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.20215]
objective value function right now is: -1566.4245470925548
new min fval:  -1567.2243851193
new min fval:  -1568.4031702057464
new min fval:  -1570.1787031936008
new min fval:  -1572.604775210932
new min fval:  -1575.4507212259632
new min fval:  -1578.5015158543113
new min fval:  -1581.4143496067654
new min fval:  -1584.0842132211294
new min fval:  -1586.0793605915474
new min fval:  -1586.9738012909745
new min fval:  -1587.2274802598013
new min fval:  -1587.3983887950258
new min fval:  -1588.2142411880359
new min fval:  -1588.7835074633613
new min fval:  -1589.1520252917758
new min fval:  -1589.4013101759595
new min fval:  -1589.5958352583523
new min fval:  -1589.794266955423
new min fval:  -1590.0449525382528
new min fval:  -1590.3750336763164
new min fval:  -1590.7506055136291
new min fval:  -1591.018876543993
new min fval:  -1591.2066108783702
new min fval:  -1591.363270613932
new min fval:  -1591.50424470572
new min fval:  -1591.676500732177
new min fval:  -1591.8987148558574
new min fval:  -1592.1302332194425
new min fval:  -1592.2879533805558
new min fval:  -1592.3929064457968
new min fval:  -1592.4729260587123
new min fval:  -1592.5598863767195
new min fval:  -1592.6782002520517
new min fval:  -1592.8387722918503
new min fval:  -1593.0157193975197
new min fval:  -1593.1378171497543
new min fval:  -1593.2266618400174
new min fval:  -1593.302231302923
new min fval:  -1593.3844555458497
new min fval:  -1593.4911170829205
new min fval:  -1593.6158304774171
new min fval:  -1593.716759048065
new min fval:  -1593.771830261921
new min fval:  -1593.8030217477835
new min fval:  -1593.8384941902943
new min fval:  -1593.898976073101
new min fval:  -1594.0026927280999
new min fval:  -1594.0822669643778
new min fval:  -1594.1500966672902
new min fval:  -1594.2188280120076
new min fval:  -1594.2992455746667
new min fval:  -1594.3783051096345
new min fval:  -1594.4416075631104
new min fval:  -1594.4957130732485
new min fval:  -1594.56473024511
new min fval:  -1594.6456651469996
new min fval:  -1594.7196973423845
new min fval:  -1594.7945990554929
new min fval:  -1594.8574102598807
new min fval:  -1594.9161336317447
new min fval:  -1594.9753367546666
new min fval:  -1595.0300746465693
new min fval:  -1595.085697687445
new min fval:  -1595.148306978455
new min fval:  -1595.228934710651
new min fval:  -1595.2975618125752
new min fval:  -1595.3546381574442
new min fval:  -1595.4163077796122
new min fval:  -1595.481290752376
new min fval:  -1595.5401877239237
new min fval:  -1595.582976909725
new min fval:  -1595.6025986056425
new min fval:  -1595.6106981410232
new min fval:  -1595.6270607622814
new min fval:  -1595.6614253976131
new min fval:  -1595.7182604358668
new min fval:  -1595.7423297554058
new min fval:  -1595.7564747531908
new min fval:  -1595.7611359313462
new min fval:  -1595.7847422518587
new min fval:  -1595.8246537527702
new min fval:  -1595.8449388222825
new min fval:  -1595.8511553162066
new min fval:  -1595.8591794835645
new min fval:  -1595.8771796890096
new min fval:  -1595.895431960412
new min fval:  -1595.8992935085219
new min fval:  -1595.9047803037026
new min fval:  -1595.9164063687488
new min fval:  -1595.9300463863403
new min fval:  -1595.9409310673047
new min fval:  -1595.9494625394454
new min fval:  -1595.9579174324988
new min fval:  -1595.976017745695
new min fval:  -1595.9906703198826
new min fval:  -1595.9991893090444
new min fval:  -1596.006707093284
new min fval:  -1596.0192434328917
new min fval:  -1596.028633524818
new min fval:  -1596.0312157887113
new min fval:  -1596.0319847078147
new min fval:  -1596.0404692646107
new min fval:  -1596.0485233613997
new min fval:  -1596.0531017668773
new min fval:  -1596.0634310975236
new min fval:  -1596.0776363661782
new min fval:  -1596.098432332084
new min fval:  -1596.1087800616774
new min fval:  -1596.119351910205
new min fval:  -1596.1417682538877
new min fval:  -1596.168389273657
new min fval:  -1596.1823638449014
new min fval:  -1596.198551692333
new min fval:  -1596.2157232721495
new min fval:  -1596.2325592635596
new min fval:  -1596.2506456807016
new min fval:  -1596.2652219764343
new min fval:  -1596.2898860446849
new min fval:  -1596.3225730861109
new min fval:  -1596.3409225606513
new min fval:  -1596.3543254000447
new min fval:  -1596.3649606494569
new min fval:  -1596.3665784288548
new min fval:  -1596.380267057899
new min fval:  -1596.4000350881315
new min fval:  -1596.4445532375164
new min fval:  -1596.4560878849975
new min fval:  -1596.4693766885941
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.998854]
objective value function right now is: -1594.8190980712288
new min fval:  -1596.4800935686337
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.266896]
objective value function right now is: -1596.7911223922526
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.223901]
objective value function right now is: -1586.032670144622
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.926405]
objective value function right now is: -1585.4681344353844
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [9.518275]
objective value function right now is: -1585.920646285453
min fval:  -1596.4800935686337
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 659.6313223106895
W_T_median: 326.1691366311278
W_T_pctile_5: 90.05564634767363
W_T_CVAR_5_pct: -14.7858730950665
Average q (qsum/M+1):  51.994735225554436
Optimal xi:  [9.191657]
Expected(across Rb) median(across samples) p_equity:  0.33383878171443937
obj fun:  tensor(-1596.4801, device='cuda:0', dtype=torch.float64,
       grad_fn=<MeanBackward0>)
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
