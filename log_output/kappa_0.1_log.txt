tracing parameter entered from terminal:  0.1


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.733547409756
gradient value of function right now is: [ 2.10672916e-01  1.54523437e-01  1.96145187e-01  1.97733726e-01
 -2.10672916e-01 -1.54523437e-01 -1.96145187e-01 -1.97733726e-01
  1.18546251e-02  8.21840679e-03  1.09333064e-02  3.46132835e-03
  1.52853706e-02  1.30546464e-01  2.29132539e-02  7.80074756e-03
  2.64747565e-03  6.22078747e-02  5.92521530e-03  2.81983081e-03
  2.62658783e-03  6.30826732e-02  5.95166194e-03  2.84898512e-03
 -1.94181310e-01 -1.90023223e-01 -3.56198766e-02 -8.04887580e-02
 -1.71226527e-01 -1.70479702e-01 -1.08996508e-01 -9.03050091e-03
 -2.29115848e-01 -2.23372661e-01 -1.94894700e-02 -1.13688083e-01
 -7.88754036e-02 -7.73687426e-02 -3.47679415e-02 -2.60088217e-02
  2.40138809e-02  1.37796316e-02  2.49950443e-02  2.01718177e-02
  1.69218743e-02  1.50037167e-02  2.86656369e-02  2.28311218e-02
  4.17924105e-02 -2.05195190e-02 -4.53467616e-02 -3.48913632e-02
  1.94905412e-01 -1.00782630e-02 -4.59421660e-02 -3.16543348e-02
  7.62925872e-02 -5.21552134e-01 -3.71870247e-02 -4.19702542e-01
  6.14483479e-02 -1.33816750e+00  9.79840711e-03 -9.11937198e-01
 -9.39484955e+00]
supnorm grad right now is: 9.394849554145612
Weights right now are: 
[ -2.53225716   1.98869486   1.50873866   0.96574588   2.78682587
  -2.09738655  -1.1098014   -1.68177426  17.2124221   17.56691506
  17.15734562  13.89535662   6.28613335  -0.62117581   6.93096406
   4.33925967   6.0324865    0.87024121   7.16845884   4.13425319
   5.22476727   0.90969444   7.55745939   4.66639836   3.20275923
   3.82433037  -3.65618272  -5.18327326   1.52101169   2.35953238
   1.15811726  -9.63181009   3.49541584   3.60117078  -3.60816997
  -6.16383111   3.21369188   4.29325687  -2.77561382  -3.83646428
 -13.89750908 -15.57100435 -10.77360605 -13.78622058 -10.37751138
 -14.44034699 -12.68141664 -13.7355555   -6.58495157  -3.46042059
   6.40750386   1.77473745   1.80246708   8.24091983  13.65131298
  11.93817699  -4.6181742   -4.18660447  -0.19360479  -4.27315072
   1.99658464  -3.32519017   1.20257891  -3.67341566  31.04128714]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.8607566096096
gradient value of function right now is: [-1.68497618e-02 -1.17291996e+00 -6.98259162e-01 -6.81630086e-01
  1.68497618e-02  1.17291996e+00  6.98259162e-01  6.81630086e-01
 -2.66800027e-03 -1.32332929e-02 -2.18993672e-02 -5.13496203e-04
  8.51331963e-02  8.66508705e-01  6.48719798e-01  1.68654239e-02
  2.82586871e-02  2.80240174e-01  2.18953311e-01  5.65440483e-03
  2.78834764e-02  2.76829042e-01  2.16064877e-01  5.58333358e-03
 -7.77326252e-01 -7.44964910e-01 -5.38699845e-01 -2.15239851e-01
 -5.22761602e-01 -4.93282469e-01 -2.80838531e-01 -1.80887065e-01
 -5.11533591e+00 -4.93164163e+00 -3.62736033e+00 -1.34376204e+00
 -1.25062926e-01 -1.19399158e-01 -8.39483359e-02 -3.53711164e-02
  8.03830807e-02  1.65775558e-02  1.54736612e-02  1.50907565e-02
  1.83127318e-01  3.01958772e-02  2.63349900e-02  2.59855304e-02
 -8.93735155e-01 -1.04767483e-01 -7.62329666e-02 -7.76424442e-02
 -1.75636450e+00 -1.79000482e-01 -1.26520620e-01 -1.29229609e-01
  7.79916324e-01 -2.27813659e+00  8.01076141e-01 -2.21459488e+00
  8.82333205e-01 -2.99191661e+00  7.97030052e-01 -2.60490197e+00
 -5.09490817e+00]
supnorm grad right now is: 5.115335909660852
Weights right now are: 
[ -3.40124896   2.07248502   1.46234438   0.92233166   3.65581767
  -2.18117671  -1.06340711  -1.63836005  17.43807694  20.88020331
  18.36994883  15.02473436   6.03919174   0.19062965   5.6685462
   5.0967767    6.96315599   1.74128186   7.65663702   4.48777672
   6.05817194   1.75509572   7.93948086   4.98109151   3.75518164
   4.24299321  -3.53389064  -5.53864605   1.98457639   2.67056243
  -0.46879407 -10.77867225   3.30059245   3.31606401  -4.40733431
  -6.96086333   4.07767869   4.94537978  -2.79593101  -4.76646552
 -17.75483244 -20.06356195 -12.03118165 -16.20322437 -10.60233741
 -18.60816029 -14.97991126 -16.83862774  -5.21889229   0.99554374
  12.79454597   8.10594394   2.24409118   8.57584685  14.70124508
  12.83264655  -3.76598744  -3.45682051   0.61605855  -4.1208784
   2.71393265  -3.74837926   2.2719489   -3.8674124   31.12893031]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.4033736162125
gradient value of function right now is: [-3.60219745e-02  2.58795471e-01 -6.58835174e-02 -7.02065669e-02
  3.60219745e-02 -2.58795471e-01  6.58835174e-02  7.02065669e-02
 -3.74638055e-04 -8.97695607e-03 -2.04931256e-02 -2.18872313e-04
 -2.30869729e-02 -4.41811869e-01 -5.01209128e-01 -1.93006015e-02
 -7.49025163e-04 -1.44764977e-02 -2.32050973e-02 -5.94279252e-04
 -6.42835801e-04 -1.18789175e-02 -1.96893536e-02 -5.13985236e-04
  1.62706961e-01  1.53565024e-01  1.06038429e-01  6.12086268e-02
  3.69689959e-01  3.59330635e-01  2.46379558e-01  7.73886013e-02
  1.63409773e+00  1.56918275e+00  1.16601303e+00  4.85269781e-01
  1.38523111e-01  1.30395505e-01  8.89855065e-02  5.40702366e-02
 -2.53087237e-02 -5.53988113e-03 -4.46255192e-03 -4.21888015e-03
 -5.99806004e-02 -9.42095217e-03 -6.16081194e-03 -5.94998376e-03
  3.13071424e-01  2.26458861e-02  1.11153964e-02  1.07864127e-02
  6.49633759e-01  6.78789275e-02  2.89933613e-02  2.96467530e-02
 -4.73396331e-01  1.44458606e+00 -3.05382466e-01  9.26039332e-01
 -1.84386394e-01  8.30275455e-01 -1.71790511e-01  7.44587431e-01
  3.03577691e+00]
supnorm grad right now is: 3.035776905037457
Weights right now are: 
[ -3.68461918   2.69273135   1.38339979   0.85362879   3.93918789
  -2.80142304  -0.98446252  -1.56965717  19.12441604  23.87988282
  17.01607708  18.21465283   7.57152545   0.5440738    3.3570209
   8.16623603   7.58587599   1.94354047  10.52101677   3.70667507
   6.79025133   1.86179994  11.06483613   4.24381991   4.75532279
   4.98011625  -3.24682104  -7.53579613   2.34121068   2.82768035
  -0.74477387 -10.57755725   3.36967232   3.26275924  -4.78334829
  -7.37068175   4.82676052   5.36294724  -2.97560956  -8.50055208
 -21.68976839 -23.4786087  -10.87595057 -16.01462193 -12.07876478
 -22.75868751 -16.92361018 -19.4454701   -4.52473875  -1.21182272
  15.08887379   9.83719997   3.09849322   9.82285607  16.83005227
  14.9056491   -4.16314375  -3.3708814   -0.10916337  -4.14339208
   3.15796226  -3.95329482   2.73415208  -4.05011198  31.1219682 ]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.3767355210355
gradient value of function right now is: [-1.33613696e-01  4.23605249e-01 -8.97864879e-02 -9.57605880e-02
  1.33613696e-01 -4.23605249e-01  8.97864879e-02  9.57605880e-02
  1.36559150e-04 -4.72832278e-03  3.65166213e-02  9.02517602e-05
 -9.67018704e-03 -1.84033976e-01 -5.20926675e-01 -8.70966646e-03
 -8.09674542e-04 -1.32014935e-02 -4.23602773e-02 -7.66830144e-04
 -8.54131072e-04 -1.39353657e-02 -4.39873720e-02 -8.12532225e-04
  1.00341148e-01  9.91652430e-02  6.26569296e-02  2.25528523e-02
  4.52091361e-01  4.47583543e-01  2.18962778e-01  7.19796340e-02
  1.48476247e+00  1.46071377e+00  9.59745478e-01  3.13120859e-01
  9.52276812e-02  9.42978191e-02  5.84433110e-02  2.14516564e-02
 -7.00763145e-03 -1.91116578e-03 -1.34773209e-03 -1.24718203e-03
 -2.14040030e-02 -4.61045984e-03 -2.56142363e-03 -2.44948723e-03
  4.15715348e-01  8.29297903e-02  3.11730866e-02  3.20774647e-02
  5.51184591e-01  9.31546949e-02  3.81647763e-02  3.83435292e-02
 -2.13692715e-02  1.55574364e-01 -3.83949054e-01  8.42837207e-01
 -4.41731121e-01  1.02279913e+00 -3.74385995e-01  8.52171964e-01
 -3.16326715e+00]
supnorm grad right now is: 3.163267148123483
Weights right now are: 
[ -3.92080148   3.17671316   1.31722693   0.86224269   4.17537019
  -3.28540485  -0.91828966  -1.57827107  23.30095607  26.07933909
  15.2761244   24.35979792   9.57090549   2.05870061   2.23946799
  10.60473749   8.08193108  -0.21660593  14.23432122   3.74475019
   6.96980876  -0.7525362   14.74592509   3.95120634   5.08544936
   4.8949801   -3.35513924  -9.79040371   2.67600267   2.87193302
  -0.99559928 -10.42754279   3.49299008   3.27502361  -5.41853974
  -7.84659348   5.05388855   5.11929883  -3.06134613 -11.01111506
 -25.26153381 -25.74628887  -7.94520204 -14.0521865  -14.37759169
 -26.69914008 -17.49526768 -20.81776933  -3.8828855   -1.71588275
  17.61655058  12.04863147   2.10191186  10.63844491  18.61233591
  16.71953902  -4.06187811  -3.67448021  -0.45936831  -4.22254914
   2.6235808   -3.95204057   2.24375382  -4.10344903  31.06562739]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.6410302318693
gradient value of function right now is: [ 4.11690345e-01  4.51010039e-01  5.18755456e-01  5.17232018e-01
 -4.11690345e-01 -4.51010039e-01 -5.18755456e-01 -5.17232018e-01
  2.07832036e-04  4.05345637e-02  5.23500840e-02  1.48590944e-04
  2.64128146e-03  2.83992207e-01  2.33994217e-01  2.39070694e-03
  6.48308927e-05  7.96525418e-04 -6.60878382e-03  7.36678719e-05
  9.22593542e-05  2.85603794e-03 -6.14382083e-03  1.01073924e-04
 -3.91909366e-02 -3.73790259e-02 -2.30949185e-02 -1.02641417e-02
 -1.55146557e+00 -1.53537334e+00 -7.72813693e-01 -2.14150518e-01
 -5.98103863e-01 -5.83872528e-01 -3.18396152e-01 -1.86630784e-01
 -3.84168083e-02 -3.64193123e-02 -2.26702140e-02 -9.95344793e-03
  8.66148124e-03  2.13499111e-03  1.46038328e-03  1.41699659e-03
  1.83153787e-02  3.74575289e-03  2.45416242e-03  2.36917063e-03
 -2.51814267e-01 -4.53127851e-02 -2.60460458e-02 -2.58921387e-02
 -5.38632019e-01 -7.78203589e-02 -4.33972937e-02 -4.24401074e-02
  1.91111592e-01 -5.88681493e-01  2.69210174e-01 -7.72363809e-01
  3.33642752e-01 -1.08869266e+00  2.85873081e-01 -9.17036354e-01
 -5.77604952e+00]
supnorm grad right now is: 5.7760495154094365
Weights right now are: 
[ -3.74789921   2.98489157   1.22016396   0.83762572   4.00246792
  -3.09358326  -0.82122669  -1.5536541   28.92447344  27.59022309
  14.14888937  30.19142723  10.75637079   2.491436     1.40221601
  11.95078729   7.57717466  -0.38793254  17.70634497   3.32986246
   6.43644157  -1.27516899  17.99200232   3.54570365   5.77945825
   5.19326899  -2.83210431 -10.92251405   2.47398226   2.48289959
  -1.45112965 -10.32994466   3.60703      3.35525523  -5.62047258
  -8.82208497   5.79262989   5.41085902  -2.51232118 -12.02460114
 -28.65702341 -28.47241058  -6.01299506 -12.99188415 -16.41774023
 -30.24451696 -17.78037693 -21.86318155  -3.50753689  -3.09627679
  18.26725868  12.47059365   1.75120095  11.38890225  20.81605264
  18.91959444  -4.59146026  -3.68621508  -0.11164226  -4.26114412
   3.01643871  -3.94127149   2.62091356  -4.08782273  31.09037442]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.3403801728143
gradient value of function right now is: [ 2.49005070e-01  1.19449677e+00  3.90360540e-01  4.11733102e-01
 -2.49005070e-01 -1.19449677e+00 -3.90360540e-01 -4.11733102e-01
  1.17811717e-04  3.02964061e-02  6.94386063e-02  9.22596868e-05
 -4.13842598e-03 -3.23733568e-01 -5.91061083e-01 -4.38014105e-03
 -1.45110797e-04 -2.01923062e-02 -2.63280477e-02 -1.42776334e-04
 -2.57025783e-04 -3.27237452e-02 -3.97708220e-02 -2.57211521e-04
  3.95312167e-02  3.93425883e-02  2.09809049e-02  1.31219814e-02
 -1.75994017e-01 -1.78072427e-01 -8.77748706e-02  6.62816965e-02
  7.32610960e-01  7.29035234e-01  4.87906007e-01  1.21414734e-01
  4.53633062e-02  4.51433691e-02  2.36166443e-02  1.57277524e-02
 -9.75827155e-03 -4.20469604e-03 -4.41976959e-03 -3.96928928e-03
 -1.04650151e-02 -4.26932799e-03 -4.30545643e-03 -3.89057304e-03
  1.14010641e-01  2.34356384e-02  1.11501891e-02  1.03779331e-02
  1.06956427e-01  2.99856219e-02  2.27870028e-02  2.11368108e-02
 -1.71133009e-04  3.86642199e-01 -8.27248104e-02  5.35987925e-01
 -1.12857249e-01  8.42127128e-01 -1.05824645e-01  7.20412459e-01
 -5.67047724e+00]
supnorm grad right now is: 5.670477235451162
Weights right now are: 
[ -3.46754478   3.18566914   0.94641633   0.65798332   3.72211349
  -3.29436083  -0.54747906  -1.3740117   35.45357022  28.47554032
  15.22089673  37.26998293  12.267943     2.7550615    1.17891088
  13.58266157   4.18495279   0.28310123  19.12125272  -0.17254387
   3.7014571   -1.10852251  19.06420956   0.82249802   6.1876339
   5.1989717   -2.63603909 -12.15060669   2.5622757    2.44088491
  -1.57177385 -10.37895885   3.88433092   3.61088078  -6.34714851
  -8.63299293   6.1663286    5.36072448  -2.36260414 -13.26389939
 -31.89006754 -30.67442612  -4.28345901 -12.04489023 -18.85486316
 -33.21465529 -17.71850933 -22.51078863  -3.19030933  -3.21878186
  19.45764141  13.43011857   1.78374557  12.35506084  22.72314863
  20.89913123  -4.63787529  -3.73900499  -0.1319577   -4.20401088
   2.96586082  -3.90614011   2.4713392   -4.05309162  31.0395515 ]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.3931345647309
gradient value of function right now is: [ 4.70140286e-01  2.50248277e+00  8.63283231e-01  9.80530135e-01
 -4.70140286e-01 -2.50248277e+00 -8.63283231e-01 -9.80530135e-01
  1.00741050e-04  5.08942189e-02  7.64642755e-02  8.46838665e-05
 -1.20114091e-02 -1.28452212e+00 -1.07778628e+00 -1.32460991e-02
 -2.94159415e-04 -6.26278606e-02 -4.76315697e-02 -2.99849533e-04
 -6.77364172e-04 -1.29627219e-01 -9.38413369e-02 -6.99439420e-04
  1.42488187e-01  1.40836335e-01  7.88786248e-02  5.08676154e-02
  8.64861139e-01  8.45031074e-01  4.82130293e-01  4.86862755e-01
  2.41372419e+00  2.39720046e+00  1.45487408e+00  5.58521852e-01
  1.70273314e-01  1.68164054e-01  9.41991868e-02  6.18177653e-02
 -3.49680036e-02 -1.61146344e-02 -1.43658858e-02 -1.34973742e-02
 -4.50111155e-02 -1.71451641e-02 -1.37898937e-02 -1.31227572e-02
  5.17722711e-01  9.19338424e-02  4.23742161e-02  4.26888409e-02
  8.66059048e-01  1.60583808e-01  8.29491890e-02  8.29181399e-02
 -4.61922360e-01  2.13151420e+00 -7.60434934e-01  2.73771354e+00
 -6.63832731e-01  3.07954398e+00 -6.38167606e-01  2.84319657e+00
  7.74112770e+00]
supnorm grad right now is: 7.7411276984969515
Weights right now are: 
[-3.02669959e+00  3.02087721e+00  9.04920564e-01  7.55724267e-01
  3.28126830e+00 -3.12956890e+00 -5.05983295e-01 -1.47175265e+00
  4.29431270e+01  2.99729690e+01  1.57852121e+01  4.43203117e+01
  1.38872015e+01  2.52795959e+00  1.09299466e+00  1.53178701e+01
  3.76912358e+00  1.90014605e+00  2.12615677e+01 -4.10366998e-02
  4.98434628e+00 -1.70028668e-01  2.08356810e+01  2.69382771e+00
  6.76736221e+00  5.35491668e+00 -2.31368284e+00 -1.31693385e+01
  2.66847565e+00  2.44938623e+00 -1.61575820e+00 -1.02200087e+01
  4.23971102e+00  4.01308178e+00 -6.55496298e+00 -9.19257181e+00
  6.74160780e+00  5.49912388e+00 -2.02973448e+00 -1.42699029e+01
 -3.45120326e+01 -3.27621399e+01 -3.41544937e+00 -1.20037391e+01
 -2.07161308e+01 -3.55564101e+01 -1.77693839e+01 -2.33030008e+01
 -3.23429429e+00 -4.42669384e+00  2.01807240e+01  1.37706440e+01
  2.03360823e+00  1.36862089e+01  2.46965090e+01  2.29625459e+01
 -4.50082290e+00 -4.13189174e+00 -4.33791739e-01 -4.31233047e+00
  3.09726616e+00 -3.99652922e+00  2.55313685e+00 -4.12229606e+00
  3.10795962e+01]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.4318439123315
gradient value of function right now is: [-1.30156793e-01 -6.27469290e-01 -2.25041969e-01 -2.89762179e-01
  1.30156793e-01  6.27469290e-01  2.25041969e-01  2.89762179e-01
 -4.86017554e-05 -1.89533121e-02 -8.71699323e-03 -4.38714861e-05
  9.25442945e-03  4.92879956e-01  4.76326490e-01  1.03900564e-02
  8.74407447e-06  2.39040489e-03  9.90973073e-04  8.38764430e-06
  5.23400816e-05  2.10603208e-02  1.09991729e-02  4.70179418e-05
 -1.37896161e-01 -1.31834391e-01 -8.09034221e-02 -5.10592483e-02
 -1.87119531e-01 -1.67428853e-01 -2.10161729e-01 -1.78706456e-01
 -4.90562084e-01 -4.79585097e-01 -2.84708272e-01 -1.37184405e-01
 -1.68385912e-01 -1.60829831e-01 -9.83010556e-02 -6.28622523e-02
  8.50669318e-03  1.20658527e-03 -2.97797475e-04 -3.98865726e-05
  1.64215922e-02  2.71284422e-03  6.34372760e-04  8.73178563e-04
 -1.96725304e-01 -1.84206565e-02 -3.07610097e-03 -4.57344038e-03
 -4.89347365e-01 -4.23530350e-02 -6.62013151e-03 -9.62934522e-03
  3.82658053e-01 -9.03270088e-01  3.59570171e-01 -6.90988948e-01
  2.19778239e-01 -3.01058477e-01  2.33670039e-01 -3.61493888e-01
 -4.99155442e-01]
supnorm grad right now is: 0.9032700884904528
Weights right now are: 
[-2.85188144e+00  2.97819446e+00  3.83227064e-01  8.50086083e-01
  3.10645015e+00 -3.08688615e+00  1.57102053e-02 -1.56611447e+00
  5.01149198e+01  3.19120640e+01  1.56723179e+01  5.12198994e+01
  1.60205350e+01  2.48162120e+00  1.25571210e+00  1.74732871e+01
  5.15422807e-01  6.23054541e+00  2.57915113e+01 -3.15234083e+00
  4.56147792e+00 -1.19727763e+00  2.31651668e+01  2.85758212e+00
  6.83109145e+00  4.95006460e+00 -2.57106952e+00 -1.48020443e+01
  2.55260490e+00  2.29056621e+00 -1.40328220e+00 -1.04154654e+01
  4.24144230e+00  4.06012521e+00 -7.39525976e+00 -9.74949557e+00
  6.80129368e+00  5.06419403e+00 -2.27799046e+00 -1.58071474e+01
 -3.78889565e+01 -3.57328620e+01 -3.61323053e+00 -1.30896554e+01
 -2.22335753e+01 -3.88711574e+01 -1.92045643e+01 -2.54884034e+01
 -3.35075044e+00 -2.96990202e+00  2.21275287e+01  1.55318789e+01
  1.83673936e+00  1.40586826e+01  2.60227729e+01  2.42301749e+01
 -4.53738996e+00 -4.25709201e+00  9.94090420e-02 -4.35232395e+00
  3.56039459e+00 -4.02530213e+00  2.83492326e+00 -4.19082941e+00
  3.11163955e+01]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.344121660872
gradient value of function right now is: [ 3.09954103e-01  8.10035548e-02  3.41113756e-01  4.05004293e-01
 -3.09954103e-01 -8.10035548e-02 -3.41113756e-01 -4.05004293e-01
  8.10861783e-06  3.78367688e-02  1.47087479e-02  7.30822522e-06
  3.27310145e-03  1.03740952e+00  4.52130890e-01  3.92068829e-03
  1.46761674e-06  6.78019811e-03  1.96258682e-03  1.33712902e-06
  2.44987658e-04  1.06891959e-01  2.61934558e-02  2.80121741e-04
 -5.44962979e-02 -5.21545333e-02 -2.94415557e-02 -1.87804773e-02
 -2.46404532e+00 -2.44186128e+00 -1.20899785e+00 -4.07791922e-01
 -1.15766195e+00 -1.13876656e+00 -5.84237831e-01 -3.63145712e-01
 -7.03041420e-02 -6.71503103e-02 -3.79827531e-02 -2.45163112e-02
  1.78286081e-02  5.71229676e-03  4.76059463e-03  4.54166381e-03
  2.59423552e-02  6.95029353e-03  5.38700585e-03  5.20927985e-03
 -3.69714872e-01 -5.68857610e-02 -3.60649851e-02 -3.70564285e-02
 -7.55124795e-01 -1.04349970e-01 -5.83361404e-02 -6.01711398e-02
  3.47029079e-01 -1.41961893e+00  4.55315578e-01 -1.57260001e+00
  4.88096447e-01 -2.06693317e+00  4.70148907e-01 -1.90453838e+00
 -3.74463388e+00]
supnorm grad right now is: 3.74463387793136
Weights right now are: 
[ -2.47589749   2.85799679  -0.23192548   0.82644337   2.7304662
  -2.96668848   0.63086275  -1.54247175  53.07397953  33.63880404
  17.12629984  54.00977697  16.75520492   2.11127983   1.03756735
  18.22197747   1.41335717  26.9589743   24.96366097  -2.31003513
   5.25805564  -2.17764289  25.61282784   4.05477052   7.80686488
   5.56447097  -2.16824018 -15.08817609   2.27177928   1.89392584
  -1.27760001  -9.59958962   4.74488811   4.60983294  -7.67472801
 -10.68258713   7.74682176   5.64615069  -1.89260159 -16.0995602
 -40.88493776 -37.45354813  -2.17680862 -12.64451796 -24.32804149
 -41.59785856 -19.53665284 -26.71686635  -3.50712879  -2.90439576
  22.60502082  15.55835536   2.11108258  14.69569717  27.38794736
  25.69555091  -4.82000501  -4.09346028   0.35944115  -4.55555124
   3.62190054  -4.32064114   2.87870497  -4.46933146  31.1528889 ]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.3814760389605
gradient value of function right now is: [-4.12278479e-02  1.00196729e+00  2.83689672e-02  2.83844697e-01
  4.12278479e-02 -1.00196729e+00 -2.83689672e-02 -2.83844697e-01
 -1.47083382e-06 -1.29252308e-02 -3.74068992e-02 -5.62168554e-07
 -9.08812156e-03 -1.76013101e+00 -1.08202818e+00 -9.82934316e-03
 -1.05873002e-07 -6.92289253e-04 -1.74752477e-03 -5.39491891e-08
 -2.55777835e-04 -1.36236504e-01 -2.87280369e-02 -2.59581306e-04
  1.43589203e-01  1.38185367e-01  8.06852678e-02  5.93739335e-02
  2.38845508e+00  2.34279376e+00  1.59695923e+00  6.56741470e-01
  2.06219824e+00  2.02280921e+00  1.09526164e+00  6.63264750e-01
  1.66152589e-01  1.59743578e-01  9.34298549e-02  6.92892797e-02
 -3.76863820e-02 -1.29876878e-02 -1.01062523e-02 -9.19065264e-03
 -5.20123174e-02 -1.51093720e-02 -1.06743987e-02 -9.85011448e-03
  4.74498361e-01  7.36203777e-02  3.97001832e-02  3.81385999e-02
  1.11108912e+00  1.60931645e-01  7.52572582e-02  7.34017506e-02
 -7.20227664e-01  3.23137834e+00 -8.27160314e-01  3.18911317e+00
 -5.71917698e-01  3.14385696e+00 -5.42466795e-01  2.83929672e+00
  2.36069538e+01]
supnorm grad right now is: 23.606953764722807
Weights right now are: 
[ -2.23673487   2.78703811  -0.1068745    0.85274976   2.49130358
  -2.8957298    0.50581177  -1.56877814  55.07429528  32.93338598
  17.26342764  55.81556841  18.24162507   2.1548649    1.13592813
  19.64951494   2.02889429  42.96572189  27.79177685  -1.76768514
   5.12811257  -2.9360135   28.22091558   4.41002083   8.43952287
   5.61068565  -2.10614744 -15.70434448   2.50449911   2.039379
  -1.226521    -9.3543384    5.08262988   5.01763608  -8.20648297
 -11.84878447   8.42088357   5.72972926  -1.76065684 -16.62361878
 -43.98351934 -39.52252071  -0.73543115 -12.20801414 -25.79017641
 -44.21449877 -19.68793929 -27.71866535  -3.5179056   -3.4936545
  24.45777205  16.82932907   2.10937098  15.76550678  28.76762637
  27.23505317  -4.99823164  -4.10651289  -0.43033778  -4.59427047
   3.65158788  -4.41209762   2.93263844  -4.58233659  31.18078533]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1042.4476935296436
gradient value of function right now is: [ 3.35164002e-01 -1.45916745e+00  2.25763405e-01  2.81032588e-01
 -3.35164002e-01  1.45916745e+00 -2.25763405e-01 -2.81032588e-01
  1.97534670e-06  1.63767154e-02 -9.94775729e-03  1.80799962e-06
  2.09492450e-02  2.28276556e+00  2.02612550e+00  2.20719775e-02
  3.08587689e-07  1.70818160e-03 -6.93586998e-05  2.64461642e-07
  3.82426523e-04  9.69631207e-02  4.44012832e-02  3.82154922e-04
 -3.70063090e-01 -3.59170651e-01 -2.02703748e-01 -1.41736976e-01
 -3.41128765e+00 -3.36283911e+00 -1.73004307e+00 -9.39402209e-01
 -3.02483974e+00 -2.98901649e+00 -1.70748725e+00 -8.96331050e-01
 -4.15730542e-01 -4.03112913e-01 -2.27557628e-01 -1.60300331e-01
  6.44197965e-02  2.47614592e-02  2.14618576e-02  2.02498124e-02
  7.63335457e-02  2.41584446e-02  1.95724130e-02  1.86782572e-02
 -7.28252491e-01 -1.14320960e-01 -6.92486962e-02 -6.92755578e-02
 -1.53993182e+00 -2.24985412e-01 -1.38793905e-01 -1.38055994e-01
  1.17281909e+00 -5.08752636e+00  1.13135487e+00 -4.70734349e+00
  1.05701480e+00 -5.40623713e+00  1.05029256e+00 -5.11077491e+00
 -8.52885600e+00]
supnorm grad right now is: 8.528855999249384
Weights right now are: 
[ -1.81600325   2.83116865  -0.08979577   0.82077027   2.07057196
  -2.93986034   0.48873304  -1.53679865  56.17166046  30.41494144
  17.88780229  56.93222744  19.93724015   2.20903522   1.66597543
  21.33702943   2.35186833  63.16129095  26.73328282  -1.49086887
   5.48088418  -2.88466095  30.32645242   5.00467375   8.58931266
   5.2712744   -2.61363205 -16.8888825    2.47065856   1.92423854
  -0.91705041  -9.60542041   5.24776961   5.16444492  -8.86782338
 -12.92355404   8.56678706   5.38715779  -2.2548262  -17.78653505
 -46.93253898 -41.15289414   1.82377829 -10.71437079 -26.9280694
 -47.07457892 -19.61965919 -28.58632056  -3.76679069  -3.71230204
  24.97219161  17.13102266   2.18955983  16.14163429  30.11898404
  28.70657277  -4.4633388   -4.44313863   0.26996101  -4.81657229
   3.35158501  -4.61443538   2.72624103  -4.74876908  31.21553207]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.6289879743013
gradient value of function right now is: [-2.02375847e-01 -6.01172925e-02 -7.28314729e-02 -4.68824872e-01
  2.02375847e-01  6.01172925e-02  7.28314729e-02  4.68824872e-01
 -4.77074252e-07 -9.98864516e-03  5.34652741e-03 -4.32324449e-07
 -2.24540504e-03 -2.84020596e-01 -4.18686666e-01 -2.37015369e-03
 -8.86354794e-08 -4.00578277e-03  6.87392781e-05 -6.84174767e-08
  1.14234662e-05  3.85125390e-02  3.18502276e-03  1.07102278e-05
  3.55434848e-02  3.38901553e-02  2.14138314e-02  1.81051287e-02
  8.87305338e-01  8.77407404e-01  4.23475822e-01  1.37451815e-01
  5.13482019e-02  4.84759764e-02  7.39173228e-02  2.31212291e-02
  3.98445617e-02  3.79718398e-02  2.40287432e-02  2.03644909e-02
 -3.79822998e-03 -6.54173148e-04 -6.13520428e-04 -5.43753741e-04
 -4.44833215e-03 -3.85365047e-04 -2.60976989e-04 -2.30308170e-04
  1.21780558e-01  1.65953452e-02  4.05024621e-03  5.20440923e-03
  2.08618836e-01  1.52461989e-02  5.26853955e-03  5.71455190e-03
 -1.26352310e-01  4.72384212e-01 -1.02866713e-01  2.38916845e-01
 -1.21695225e-01  1.50412306e-01 -1.18290840e-01  1.66343100e-01
 -2.44194556e+00]
supnorm grad right now is: 2.441945564335796
Weights right now are: 
[ -1.66947447   2.83089175  -0.90747147   0.50664281   1.92404318
  -2.93958344   1.30640874  -1.22267119  57.22110985  24.7259409
  20.35128197  58.00176882  20.49882482   1.99119244   1.11240355
  21.84626325   2.640258    79.35012763  31.86545219  -1.24870077
   1.80126818  -4.4647177   30.81671311   1.62592034   9.77503088
   5.88888258  -1.91355662 -16.61678816   2.540917     1.89393109
  -1.15975009  -9.12330335   5.65936178   5.599351    -9.45783989
 -13.74345468   9.77200615   6.02233392  -1.52861924 -17.45527823
 -50.25276142 -43.23190794   3.10048106 -10.20808471 -28.36172875
 -50.29011794 -20.62884172 -30.27221063  -3.18312378  -3.61409611
  27.31693796  19.05398684   2.27396465  16.74860901  30.87429377
  29.60192065  -4.58000731  -4.06507276   0.10189824  -4.77672177
   3.25624771  -4.52318672   2.75918097  -4.65387589  31.04318182]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.196297704385
gradient value of function right now is: [ 2.63390035e-01 -8.60733475e-01  1.30121929e-01  4.42563023e-01
 -2.63390035e-01  8.60733475e-01 -1.30121929e-01 -4.42563023e-01
 -3.54780284e-07 -2.26826487e-04 -3.09989090e-02 -1.75253561e-07
 -4.10340914e-03 -6.06679605e-01  1.75713800e-01 -4.65760889e-03
  5.79649004e-08  4.00056571e-03 -7.68709467e-05  5.30577431e-08
 -3.89525054e-05 -4.56454884e-02  5.17277810e-03 -4.15493858e-05
  7.43837055e-02  7.16227837e-02  4.14986480e-02  3.31255221e-02
 -2.22828487e-01 -2.39345669e-01  1.31001040e-02  1.94750127e-01
 -1.03973584e-01 -1.20580412e-01 -4.33673633e-01  2.45532336e-01
  8.95198172e-02  8.61404785e-02  5.00819952e-02  3.99437232e-02
 -1.99046915e-02 -8.34009475e-03 -6.24298221e-03 -5.91112959e-03
 -2.39187262e-02 -8.46128851e-03 -5.92226565e-03 -5.65348739e-03
 -3.98917456e-01 -4.22013466e-02  8.63055607e-03  5.27635173e-03
 -1.37742241e-01  2.36161719e-02  2.91234124e-02  2.69495498e-02
 -4.89751553e-01  1.98988911e+00 -1.06694562e-01  1.36109983e+00
  3.58903744e-02  1.44465799e+00  4.23524348e-02  1.32717892e+00
  9.90653205e+00]
supnorm grad right now is: 9.906532053257859
Weights right now are: 
[ -1.50980262   2.64245827  -0.9984785    0.73320523   1.76437133
  -2.75114996   1.39741577  -1.44923361  58.31062766  18.09614067
  22.21403419  59.17353993  21.80810329   1.55404658   1.42812422
  23.19068215   2.81786481  93.17460082  33.43240288  -1.10470961
  -0.32955421  -4.28946972  32.92258174  -0.44222621  10.05184003
   5.7516533   -2.63448543 -17.80534897   2.53404698   1.82247343
  -1.18588916  -9.0081028    5.78436047   5.77730112 -10.30480568
 -14.34191763  10.00630301   5.82932894  -2.27729991 -18.65840886
 -53.2896079  -46.19349549   2.24863468 -11.53311273 -28.99815757
 -53.88715166 -23.27148289 -33.28695201  -3.83638336  -4.01295681
  28.49398444  19.95817048   2.59956978  16.56478095  30.87262173
  29.6243106   -4.74269823  -4.2575329    0.1418398   -4.54963251
   3.49644041  -4.51631395   3.03571435  -4.61440109  31.13543478]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.1906702436256
gradient value of function right now is: [ 5.46317529e-02 -1.68140217e+00  9.47628340e-02 -3.52277099e-01
 -5.46317529e-02  1.68140217e+00 -9.47628340e-02  3.52277099e-01
 -7.14993087e-06 -3.75033124e-02 -3.41001724e-02 -6.83996214e-06
  3.24495099e-03  1.70766731e+00  9.21788751e-01  3.59207167e-03
  2.11035704e-08  3.08398012e-03 -2.44576104e-04  2.05390868e-08
  8.64193111e-05  1.70149966e-01  4.86136494e-02  8.96213381e-05
 -6.84174209e-02 -6.39785694e-02 -3.76394558e-02 -2.82760930e-02
 -1.20710490e+00 -1.17691531e+00 -4.61257051e-01 -3.29685112e-01
 -1.79768370e+00 -1.76203798e+00 -1.04789991e+00 -5.13719135e-01
 -8.01847127e-02 -7.48743425e-02 -4.40937759e-02 -3.33504590e-02
  1.71613302e-02  4.86675762e-03  3.29720033e-03  3.21281126e-03
  3.07243139e-02  6.99226411e-03  4.28660424e-03  4.23208786e-03
 -5.80767876e-01 -7.53266036e-02 -3.05271030e-02 -3.20148072e-02
 -8.16249388e-01 -9.34464956e-02 -3.97151387e-02 -4.10584149e-02
  5.19764941e-01 -1.98881480e+00  4.95494033e-01 -1.64137349e+00
  5.19584936e-01 -1.84751611e+00  4.96452401e-01 -1.72438441e+00
 -3.61194785e+00]
supnorm grad right now is: 3.6119478526587203
Weights right now are: 
[ -1.5385375    2.65476625  -1.16483226   0.66831307   1.79310621
  -2.76345794   1.56376953  -1.38434145  60.04941657  13.1588198
  22.42304313  61.03094462  23.14149855   1.63168436   1.4910556
  24.52402495   2.90006764 104.55213095  30.38253471  -1.03538505
  -4.74463754  -2.83493444  34.26994987  -4.93522054  10.5410263
   5.65776004  -2.93159618 -18.61529804   2.54140655   1.79175997
  -1.10723308  -9.62054613   6.28230044   6.29771728 -10.49526178
 -14.7006759   10.50219453   5.74082452  -2.57161085 -19.45759666
 -56.56683721 -47.9417782    3.10037968 -11.31920948 -29.38806466
 -57.22253938 -25.51260771 -36.01470016  -3.55108293  -4.07112684
  28.37713744  19.62496979   2.68454531  16.13924985  30.75861817
  29.57415848  -4.19638702  -4.28085286   0.71819613  -4.76472299
   4.04672166  -4.69195905   3.54656199  -4.79138345  31.1539608 ]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.2170112286292
gradient value of function right now is: [-2.46340828e-01  1.20374706e+00 -8.84593338e-02 -1.14033347e-01
  2.46340828e-01 -1.20374706e+00  8.84593338e-02  1.14033347e-01
  2.24374715e-06  2.71876548e-03  1.85887357e-02  2.26943988e-06
 -4.65996795e-03 -1.71354110e+00 -1.12832324e+00 -5.22443758e-03
 -2.99233016e-08 -4.37793973e-03  3.94774023e-04 -2.84225980e-08
 -6.66396042e-05 -8.89918215e-02 -3.49640848e-02 -7.10723351e-05
  9.46337748e-02  9.02158537e-02  5.20569939e-02  4.20504845e-02
  1.27664917e+00  1.25309325e+00  4.53922713e-01  2.84476043e-01
  1.67250604e+00  1.63074457e+00  9.45404480e-01  5.50276542e-01
  1.12031199e-01  1.06710143e-01  6.16626207e-02  4.99472979e-02
 -2.54199567e-02 -7.70723551e-03 -7.99105894e-03 -6.95138760e-03
 -3.91878027e-02 -8.55228746e-03 -7.93880798e-03 -6.98190672e-03
  4.51469775e-01  5.22413248e-02  3.61852482e-02  3.31420716e-02
  6.63394632e-01  7.31444586e-02  5.29805833e-02  4.79579796e-02
 -6.82301490e-01  2.88295684e+00 -3.79963839e-01  1.72260327e+00
 -5.19351435e-01  2.55892934e+00 -4.45031823e-01  2.18878306e+00
  8.49160797e+00]
supnorm grad right now is: 8.491607970592401
Weights right now are: 
[ -1.56908753   2.89670295  -1.59931876   0.70381343   1.82365624
  -3.00539464   1.99825603  -1.41984182  62.37562562  11.11339829
  26.01191363  63.42395073  24.192799     1.06092233   1.54094633
  25.59142086   2.93291697 112.10991464  28.47802502  -1.00704027
  -9.79496815  -3.12909961  32.5626123  -10.0103857   11.33028662
   5.71578664  -3.03198898 -19.14001251   2.70916086   1.86178091
  -1.45018069  -9.25983511   6.58870602   6.61557721 -11.23159283
 -15.09487388  11.2918743    5.79139021  -2.67087503 -19.96881141
 -60.20796246 -49.83795349   5.06235809 -10.07162992 -29.0475459
 -60.90744797 -27.3346444  -38.41107493  -3.62912087  -4.10007139
  30.12242822  21.12690488   3.0833077   15.91517323  30.71311735
  29.65409964  -4.17346995  -4.32733782   0.7753455   -4.87883022
   3.64411052  -4.53799208   3.32743896  -4.71298772  31.08803877]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.1870125156424
gradient value of function right now is: [ 1.08005273e-01  1.23546324e-01  7.17053396e-02  2.85737872e-01
 -1.08005273e-01 -1.23546324e-01 -7.17053396e-02 -2.85737872e-01
  6.01851400e-07 -4.07186590e-03 -1.36235228e-02  6.49865392e-07
 -7.70737173e-04 -3.13609597e-01 -2.79280094e-02 -8.55344445e-04
  4.40625955e-09  2.20737157e-03 -8.72199476e-05  4.05239746e-09
 -3.73443880e-05 -1.10804574e-01 -5.02255411e-03 -3.91472663e-05
  1.38684126e-02  1.39088373e-02  8.00813314e-03  6.98372131e-03
 -1.35172165e-01 -1.32688354e-01  7.97386677e-02  3.35803982e-02
  4.74035249e-01  4.69278587e-01  1.73647497e-01  1.93769661e-01
  1.61900547e-02  1.62314436e-02  9.37343294e-03  8.18641020e-03
 -8.90117946e-03 -3.56761987e-03 -3.98141032e-03 -3.27192853e-03
 -1.04107086e-02 -3.66670713e-03 -3.76878215e-03 -3.12803381e-03
  1.43125795e-02  7.71211238e-03  1.42180662e-02  1.14108771e-02
  1.17354193e-01  2.65461679e-02  2.36769072e-02  1.99608467e-02
 -1.23460638e-01  7.76915710e-01 -1.16083030e-01  6.78937526e-01
 -1.32461671e-01  1.15354146e+00 -1.03937534e-01  9.23255112e-01
  1.65244437e+01]
supnorm grad right now is: 16.52444374675238
Weights right now are: 
[ -1.5236921    2.65813781  -1.48509449   0.86770435   1.77826081
  -2.7668295    1.88403175  -1.58373274  64.567662    10.17245377
  26.19831148  65.7544659   24.87442251   1.52318772   1.66837309
  26.26181902   2.95359155 118.13266562  22.66314002  -0.98891946
  -9.37757513  -2.44966907  33.67592795  -9.73280661  12.02186491
   5.79121376  -3.09354459 -19.48537203   2.7492167    1.81594046
  -1.53761413  -9.92342314   6.87595407   6.82471331 -11.52049836
 -15.66721954  11.99089191   5.87696302  -2.72195851 -20.30161624
 -63.75723105 -51.05665461   8.12555569  -7.78250385 -29.21404559
 -64.76606025 -29.037109   -40.78641344  -3.94944883  -4.08263901
  31.20163489  22.12296746   3.05473067  15.11551466  30.1786988
  29.15312504  -4.02603767  -4.42542467   0.57989565  -5.04267931
   3.72267708  -4.67848014   3.40720021  -4.91446483  31.23593353]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.7214766147597
gradient value of function right now is: [-1.10809435e+00 -1.28271911e+00 -2.84455517e-01 -1.40849040e+00
  1.10809435e+00  1.28271911e+00  2.84455517e-01  1.40849040e+00
 -2.21167381e-06 -6.38741601e-02 -8.76111348e-03 -2.11984636e-06
  1.35921588e-04  1.99706965e-01  9.59890721e-03  1.44532698e-04
 -3.46228119e-08 -1.04252453e-02 -8.62355612e-04 -2.70989170e-08
  5.24875885e-06  7.63269651e-02  6.07013918e-03  5.11936229e-06
 -4.30132961e-03 -2.99126912e-03 -2.11077526e-03 -1.75196539e-03
  1.82849679e+00  1.83706986e+00  6.44008341e-01  7.54193694e-02
  1.00411654e-01  1.14100154e-01  1.19818850e-01 -6.25573779e-03
 -4.84803851e-03 -3.38961631e-03 -2.39523674e-03 -1.96711595e-03
  2.68758403e-03  2.22754724e-04 -1.64209242e-04 -9.64760408e-05
  5.40795997e-03  8.77383099e-04  4.70922033e-04  3.96802808e-04
  2.35921012e-01  3.41163430e-02  1.05500711e-02  1.06384350e-02
  3.18503523e-01  3.41938728e-02  1.50485988e-02  1.37216575e-02
  4.34676304e-02 -2.37564225e-01 -1.13645423e-01  1.37343163e-01
 -2.10089347e-01  3.14926762e-01 -1.73010490e-01  2.59337935e-01
  5.44956237e+00]
supnorm grad right now is: 5.449562369925123
Weights right now are: 
[ -1.63016779   2.81353346  -1.43653906   0.76717035   1.8847365
  -2.92222515   1.83547633  -1.48319874  66.4881146   10.2605842
  28.09906034  67.79809894  25.69522332   1.30195135   1.97532911
  27.04770912   2.96538087 124.35783469  20.10071393  -0.97839029
 -10.86737777  -1.66352246  34.52065159 -11.20462778  12.7138548
   5.66760329  -3.19142852 -19.87320248   2.9154898    1.82151569
  -1.18281093 -10.47578906   7.2512986    7.1282016  -11.67741121
 -16.11131264  12.70240347   5.77239826  -2.78619532 -20.64475394
 -68.15538975 -53.00456962  10.91947007  -5.80178015 -29.23320125
 -69.33226158 -31.09654822 -43.61271845  -3.85236798  -3.63991876
  33.07012187  23.80358095   3.06767461  13.72956008  28.94746574
  27.87865923  -3.68839483  -4.35484844   0.45845262  -5.10841807
   3.93836836  -4.65198486   3.64961474  -4.95648973  31.11183732]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.9116979936312
gradient value of function right now is: [ 3.74787809e-01 -1.02797756e+00  1.74510364e-01  2.61738385e-01
 -3.74787809e-01  1.02797756e+00 -1.74510364e-01 -2.61738385e-01
 -5.42939162e-06 -8.88250279e-03 -6.62389664e-03 -5.29758708e-06
  3.88956773e-03  1.67673293e+00  1.63839415e+00  4.02169579e-03
  7.88867168e-09  2.80457607e-03  4.78851798e-06  6.53484195e-09
  2.63826233e-05  6.84547541e-02  1.89009018e-02  2.58578455e-05
 -9.08061301e-02 -8.40244373e-02 -4.95913549e-02 -4.21188583e-02
 -1.39990447e+00 -1.35951495e+00 -6.19428291e-01 -3.60721010e-01
 -2.14854635e+00 -2.09093101e+00 -1.22947703e+00 -7.15973716e-01
 -9.84338793e-02 -9.09923137e-02 -5.37843612e-02 -4.58166285e-02
  2.63968114e-02  7.98827778e-03  8.02162934e-03  6.15281246e-03
  4.45691375e-02  9.63764480e-03  8.01812285e-03  6.23805656e-03
 -6.54422222e-01 -8.10564012e-02 -4.10005194e-02 -3.36183590e-02
 -9.31641864e-01 -1.08973645e-01 -6.00553165e-02 -4.83238634e-02
  8.39997410e-01 -3.20454787e+00  6.30507387e-01 -2.07654801e+00
  7.08607367e-01 -2.81408991e+00  5.44240497e-01 -2.13587562e+00
 -1.08328817e+01]
supnorm grad right now is: 10.83288165012923
Weights right now are: 
[ -1.57956655   2.80810011  -1.00353456   0.94770775   1.83413526
  -2.9167918    1.40247183  -1.66373614  68.4064315    9.46142785
  29.71492294  69.75367848  27.13952235   1.18687089   2.01903627
  28.49347947   2.97410803 131.73969449  15.69320953  -0.97130229
 -11.20737607  -1.79483143  35.39530079 -11.55696987  13.2812767
   5.11180811  -3.43946874 -20.63963771   3.14117257   1.83382737
  -1.23361571  -9.70979614   7.15846708   6.98442649 -12.56231613
 -16.62469735  13.27410703   5.22378408  -3.02703502 -21.41394967
 -71.72185978 -53.8178346   14.49029078  -3.28278997 -28.56961181
 -72.36697097 -32.02807268 -45.45501816  -4.22613199  -3.11455734
  34.3873571   25.05549086   3.17180265  13.39532916  28.51111675
  27.43569238  -3.71771072  -4.50782245   0.28831287  -5.08541926
   3.98546081  -4.57224191   3.680858    -4.89580897  31.13857487]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1043.9472225924076
gradient value of function right now is: [ 7.07358700e-01  1.71734045e+00  1.73608963e-01  9.26036457e-01
 -7.07358700e-01 -1.71734045e+00 -1.73608963e-01 -9.26036457e-01
  1.05952197e-07  4.87914496e-02  9.63314700e-03  1.00549936e-07
 -1.51894232e-03 -1.30027081e+00 -7.76039895e-01 -1.74270801e-03
  1.21121151e-09  4.12805009e-03  1.14602370e-03  1.00186323e-09
 -1.68560551e-06 -7.62618354e-02 -1.47497795e-02 -1.81780133e-06
  2.98291502e-02  2.95624135e-02  1.85526274e-02  1.73185036e-02
 -6.21297072e-01 -6.30203320e-01 -1.48937522e-01  7.03747752e-02
  9.78989976e-01  9.56199784e-01  5.73178171e-01  3.59080316e-01
  3.58587683e-02  3.55200602e-02  2.23295968e-02  2.08534919e-02
 -1.20224193e-02 -4.79775928e-03 -4.51567835e-03 -2.92589190e-03
 -1.91074176e-02 -5.15919150e-03 -3.84629516e-03 -2.51941291e-03
  1.97694798e-01  2.21375787e-02  1.00875943e-02  5.97829362e-03
  2.52746039e-01  2.83581016e-02  1.21411598e-02  7.21523264e-03
 -3.22771090e-01  1.47039902e+00 -2.33581295e-01  9.92466310e-01
 -1.54930757e-01  8.91711156e-01 -9.02481651e-02  5.75779956e-01
 -1.07022277e+01]
supnorm grad right now is: 10.702227679793289
Weights right now are: 
[ -1.48936757   2.80966563  -1.09730507   0.87109931   1.74393628
  -2.91835732   1.49624234  -1.5871277   70.21051328  10.11478231
  31.24939313  71.71936917  27.09419672   0.71383622   1.90044161
  28.47664801   2.97926279 137.17793522  12.19285483  -0.96688261
 -11.42052471  -0.9168437   35.13564769 -12.01668595  14.69508538
   6.0479399   -2.76572034 -20.37985633   3.26890264   1.65154417
  -1.19075509  -9.92728053   7.64504152   7.37040012 -12.98377783
 -15.94388444  14.65633772   6.13348265  -2.38593088 -21.19527687
 -74.18494506 -55.46588735  16.42542841  -1.97867521 -30.84185272
 -75.8501682  -33.05354477 -47.17674439  -4.11109932  -3.33890348
  36.14359416  26.44863484   3.06260051  12.9788749   27.19427216
  26.01744813  -4.37814093  -4.56722511  -0.25952664  -4.86470476
   3.93202442  -4.45958998   3.86949612  -4.88436699  30.98081472]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.3318593084284
gradient value of function right now is: [ 9.53962998e-02 -5.15157371e-01  9.22159851e-02 -1.17047428e-02
 -9.53962998e-02  5.15157371e-01 -9.22159851e-02  1.17047428e-02
 -3.84189996e-06 -1.02546389e-02 -2.65555799e-02 -4.20605050e-06
  2.13910406e-03  3.51526879e-01  1.18543434e-01  2.47158201e-03
 -5.07682585e-09  9.15769313e-04 -2.33970537e-03 -3.25146879e-09
  6.75471547e-05  9.61095899e-02  3.15420538e-02  7.55926109e-05
 -4.68945818e-02 -4.57910719e-02 -2.57102215e-02 -2.46206905e-02
 -1.29421323e-01 -1.33641585e-01  1.78866985e-01 -1.50386037e-02
 -3.38657821e-01 -3.42911970e-01 -1.23045243e-01 -1.57609993e-01
 -5.67304199e-02 -5.53629032e-02 -3.11480769e-02 -2.97950513e-02
  1.48772011e-02  5.59219121e-03  6.72993827e-03  4.23500510e-03
  7.74944622e-03  4.16230683e-03  5.01612197e-03  3.17861201e-03
 -3.44807170e-02 -2.03328370e-02 -1.80303096e-02 -1.20414070e-02
  3.65335220e-02 -1.99951463e-02 -2.77530934e-02 -1.77505257e-02
 -3.09657388e-02 -1.18558385e+00  2.99887712e-02 -7.78697024e-01
  1.39619980e-01 -1.25990035e+00  8.89016837e-02 -8.14242051e-01
 -1.15102761e+01]
supnorm grad right now is: 11.510276078381137
Weights right now are: 
[-1.74533136e+00  2.70317468e+00 -1.18178284e+00  9.64374385e-01
  1.99990007e+00 -2.81186637e+00  1.58072011e+00 -1.68040277e+00
  7.14935679e+01  8.75035524e+00  3.15730647e+01  7.31316382e+01
  2.88075413e+01  1.05244154e+00  1.38873384e+00  3.02012731e+01
  2.98103526e+00  1.43725096e+02  1.13300156e+01 -9.65288655e-01
 -1.13595934e+01 -1.93774647e+00  3.66160093e+01 -1.21806577e+01
  1.46708473e+01  5.04385307e+00 -3.74784473e+00 -2.16927510e+01
  3.36557226e+00  1.52062983e+00 -1.03303239e+00 -9.80679778e+00
  7.97871560e+00  7.69672393e+00 -1.29821329e+01 -1.60235292e+01
  1.46293691e+01  5.11916610e+00 -3.36339862e+00 -2.25129674e+01
 -7.78352148e+01 -5.69871662e+01  1.88168138e+01 -4.64197357e-01
 -3.00374828e+01 -7.84693576e+01 -3.36966826e+01 -4.87518386e+01
 -4.28058933e+00 -3.51515598e+00  3.71343173e+01  2.73330220e+01
  3.07580807e+00  1.13844129e+01  2.56509937e+01  2.42186241e+01
 -4.54734630e+00 -4.55744952e+00  5.39761133e-02 -5.19098569e+00
  4.38725390e+00 -4.62947530e+00  4.18750546e+00 -5.13752449e+00
  3.10382379e+01]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.7008535615223
gradient value of function right now is: [-5.13926527e-01 -1.24976429e+00 -1.44193534e-01 -7.49742063e-01
  5.13926527e-01  1.24976429e+00  1.44193534e-01  7.49742063e-01
 -2.77354168e-06 -4.91027582e-02 -3.66944484e-03 -2.96775183e-06
  4.07994123e-04  8.27067826e-01  5.62700518e-01  4.61286479e-04
 -1.00225417e-09 -3.04465588e-03  1.67240183e-03 -1.00005368e-09
  1.06544776e-05  9.64499398e-02  1.57012487e-02  1.15305893e-05
 -1.11847702e-02 -8.95200279e-03 -5.94939109e-03 -5.26693366e-03
  4.31998467e-01  4.57154888e-01 -5.64115021e-02 -4.25983650e-02
 -8.47750480e-01 -8.29838128e-01 -4.21550327e-01 -3.25457490e-01
 -1.32573930e-02 -1.06001781e-02 -7.06859882e-03 -6.26478713e-03
  1.16579799e-02  3.54122262e-03  4.01858684e-03  2.23014355e-03
  1.66311941e-02  4.46003606e-03  4.56286723e-03  2.54291421e-03
 -1.64828120e-01 -2.74733239e-02 -1.87049749e-02 -1.00454171e-02
 -1.92782151e-01 -2.51624043e-02 -1.64133334e-02 -7.63359116e-03
  3.00842769e-01 -1.27160935e+00  1.88104412e-01 -7.28204937e-01
  2.67179621e-01 -1.15844176e+00  1.32608953e-01 -5.90954998e-01
  3.03095393e+00]
supnorm grad right now is: 3.030953933234396
Weights right now are: 
[ -1.76394555   2.74780026  -1.33727066   0.95647559   2.01851426
  -2.85649195   1.73620793  -1.67250397  73.7411906    8.6283737
  33.11379544  75.57800541  28.99463435   0.98772157   1.59496895
  30.3672025    2.98278456 149.58027407  10.06474936  -0.96382001
 -12.58059518  -2.06667197  37.32498689 -13.76400387  15.8878727
   4.94879204  -2.88963523 -21.22945816   3.74516255   1.41265994
  -1.3093966   -8.8722346    7.85323811   7.51074661 -13.19335113
 -17.40907831  15.85826671   5.04227231  -2.49423423 -22.04207441
 -81.6242651  -58.25973189  23.76098774   3.44850717 -29.13971352
 -81.64731176 -34.01918953 -50.20390296  -4.13430752  -2.89016574
  38.41010748  28.15570709   2.97123952  10.90718541  24.14571727
  22.59646323  -3.59779437  -4.78525703   0.20859777  -5.31374013
   4.49345983  -4.40596561   4.45278667  -5.07036067  31.16041522]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.3623094208053
gradient value of function right now is: [ 4.57809541e-01  2.05718312e-01  1.82118461e-01  4.54338372e-01
 -4.57809541e-01 -2.05718312e-01 -1.82118461e-01 -4.54338372e-01
 -8.41549260e-07  3.60134127e-03 -1.00971568e-03 -9.28960191e-07
 -1.05979589e-03  4.97588200e-02  2.51541407e-01 -1.20967081e-03
  6.29584421e-10  3.09398067e-03 -5.06903970e-05  6.04345968e-10
 -3.92562766e-06  4.21904494e-03  2.55879564e-03 -4.45404962e-06
  1.70937914e-02  2.60074976e-02  8.71670701e-03  1.08909630e-02
 -6.03672858e-01 -5.70726047e-01 -1.21227644e-01 -2.69809919e-02
 -2.36374040e-01 -1.93358806e-01 -1.27966707e-01 -6.97040544e-02
  2.02914889e-02  3.10904963e-02  1.03154858e-02  1.29440221e-02
 -1.84983349e-03 -2.64036299e-03 -1.04791268e-02 -3.87544492e-03
  4.74207218e-03  4.00415586e-04 -2.40753710e-03 -8.91259624e-04
 -1.02400278e-01 -2.27903236e-02 -1.68396066e-03 -1.48922722e-03
 -1.14951111e-01 -2.00831744e-02  4.27432831e-03  4.32892499e-04
  1.86276095e-01  4.08447288e-02  1.13812796e-01  6.77102509e-02
  2.19254615e-01  2.75962591e-03  8.17419728e-02  7.26850726e-02
 -1.03501388e+01]
supnorm grad right now is: 10.35013881399323
Weights right now are: 
[-1.49794646e+00  2.74932273e+00 -1.38855370e+00  1.06120095e+00
  1.75251517e+00 -2.85801442e+00  1.78749097e+00 -1.77722934e+00
  7.62915400e+01  9.10433733e+00  3.36441375e+01  7.83734703e+01
  2.95176312e+01  7.79319454e-01  1.37690543e+00  3.08992891e+01
  2.98393975e+00  1.55686173e+02  1.10425517e+01 -9.62868422e-01
 -1.24212128e+01 -1.83333826e+00  3.66759944e+01 -1.37357122e+01
  1.68428990e+01  5.02352506e+00 -2.75169448e+00 -2.14347781e+01
  4.22634413e+00  9.84393445e-01 -1.12452548e+00 -7.58731690e+00
  7.90769262e+00  7.52120323e+00 -1.37806731e+01 -1.76321390e+01
  1.68028211e+01  5.11253897e+00 -2.37477571e+00 -2.22655750e+01
 -8.54735301e+01 -5.94092588e+01  2.84767694e+01  6.99073261e+00
 -2.62067884e+01 -8.50447105e+01 -3.51911918e+01 -5.29351025e+01
 -3.83438297e+00 -3.06118693e+00  3.98170862e+01  2.93958717e+01
  3.20033397e+00  8.77123518e+00  2.19468230e+01  1.96106280e+01
 -2.95422616e+00 -4.91858500e+00 -1.16570092e-02 -5.17133317e+00
  4.29025453e+00 -3.79472332e+00  4.58546786e+00 -4.76073772e+00
  3.09949669e+01]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.4034294674752
gradient value of function right now is: [ 5.23578102e-01  1.98079756e+00  8.03563956e-02  1.09236315e+00
 -5.23578102e-01 -1.98079756e+00 -8.03563956e-02 -1.09236315e+00
  3.00175921e-06  9.33656022e-02  1.71540798e-02  3.26966687e-06
 -2.51718749e-03 -1.36552956e+00 -7.73262564e-01 -2.81954254e-03
  1.57782209e-10  2.39134550e-03  2.24004930e-04  1.42019564e-10
 -1.37113894e-04 -2.40894661e-01 -3.87832611e-02 -1.51665791e-04
  4.75979735e-02  5.83475563e-02  2.39971533e-02  2.94294089e-02
 -7.12815295e-01 -7.22689576e-01 -1.05104985e-01 -1.47787936e-02
  1.25795552e+00  1.31380392e+00  6.23709765e-01  5.26837168e-01
  5.55735966e-02  6.80897097e-02  2.80537858e-02  3.43861089e-02
 -2.31825008e-02 -9.31886406e-03 -3.16583393e-02 -8.69555569e-03
 -2.54622823e-02 -6.56795689e-03 -1.46145635e-02 -4.10615123e-03
  3.19002359e-01  4.67959807e-02  4.65071476e-02  1.29674356e-02
  3.41232618e-01  4.66416893e-02  6.42916404e-02  1.56906357e-02
 -4.99856709e-01  2.50570172e+00 -2.91132848e-01  1.23237200e+00
 -5.36601097e-01  2.37898582e+00 -1.34413457e-01  7.40398153e-01
  1.35306852e+01]
supnorm grad right now is: 13.530685207823064
Weights right now are: 
[-1.84974933e+00  2.68095342e+00 -1.51339731e+00  9.99973605e-01
  2.10431805e+00 -2.78964511e+00  1.91233458e+00 -1.71600199e+00
  7.89015652e+01  1.00107221e+01  3.40451949e+01  8.11992027e+01
  3.01186292e+01  1.02354877e+00  1.38658591e+00  3.14703414e+01
  2.98442033e+00  1.61501877e+02  1.24083146e+01 -9.62467128e-01
 -1.07407932e+01 -2.06000595e+00  3.66347730e+01 -1.20508677e+01
  1.75246296e+01  4.41188660e+00 -2.30628117e+00 -2.14841632e+01
  4.37187896e+00  3.96965415e-01 -1.17454076e+00 -7.61943432e+00
  8.47325331e+00  7.89176933e+00 -1.36386566e+01 -1.78231529e+01
  1.75110537e+01  4.51996519e+00 -1.90458191e+00 -2.22915573e+01
 -8.90786675e+01 -6.10400726e+01  3.22371747e+01  9.31776255e+00
 -2.33104730e+01 -8.78687072e+01 -3.48818398e+01 -5.46422577e+01
 -3.45214656e+00 -1.43227980e+00  4.15266939e+01  3.14835638e+01
  3.13194124e+00  5.33604463e+00  1.83956143e+01  1.45751870e+01
 -3.09604743e+00 -4.99302879e+00 -1.12883398e-01 -5.53839887e+00
  4.64858145e+00 -3.74426990e+00  5.19056894e+00 -5.05210687e+00
  3.11518568e+01]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.6983000735465
gradient value of function right now is: [-2.25206212e-01 -1.20455780e+00 -5.28638564e-02 -4.05301900e-01
  2.25206212e-01  1.20455780e+00  5.28638564e-02  4.05301900e-01
 -2.22240331e-06 -2.55289926e-02 -7.37722625e-03 -2.47841261e-06
  5.02262624e-05  6.16385068e-01  5.51069813e-01  5.27526289e-05
 -8.37374717e-11 -1.27435283e-03  9.93522051e-05 -7.71874869e-11
  2.95010519e-05  7.89216222e-02  1.82365700e-02  3.30621721e-05
 -2.10855365e-03 -2.17018821e-03  1.14726034e-04 -2.24524261e-04
  1.33325362e-01  1.45954743e-01 -6.67642140e-02 -5.34561305e-02
 -7.72197166e-01 -7.68397976e-01 -3.80723886e-01 -3.09159899e-01
 -2.42009263e-03 -2.48839889e-03  1.64452390e-04 -2.30055487e-04
  1.26058090e-02  4.38469922e-03  1.28828350e-02  3.28438857e-03
  1.77483338e-02  4.01016782e-03  8.37478628e-03  2.03115055e-03
 -2.29720779e-01 -2.84183469e-02 -3.16783394e-02 -7.31759094e-03
 -2.26310635e-01 -2.51979357e-02 -3.72333925e-02 -6.99031394e-03
  2.50323637e-01 -1.31043764e+00  1.30319423e-01 -5.93597709e-01
  4.14714842e-01 -1.60082246e+00  7.80039695e-02 -3.75006634e-01
  5.14591705e+00]
supnorm grad right now is: 5.145917051005335
Weights right now are: 
[ -1.9131034    2.61132615  -1.41089427   1.01278133   2.16767211
  -2.72001784   1.80983154  -1.72880972  82.14410657  10.74403934
  34.07386595  84.77002081  30.38469532   1.00935184   1.36879977
  31.73024639   2.98472265 167.84016128  14.54597745  -0.96220944
 -10.68510459  -1.85123629  36.65829008 -11.88373709  18.15348847
   4.29021331  -1.97601095 -21.46054435   4.7129008    0.31433747
  -1.37951733  -7.14645664   8.72631152   7.79275686 -14.71341455
 -17.5869587   18.14436657   4.39501774  -1.56631628 -22.26550581
 -92.70944842 -63.81378837  33.7195923    9.06372162 -19.1463815
 -89.53343745 -33.57132557 -55.16553079  -3.88264447  -1.44649858
  42.72374853  32.91395248   3.52214231   3.09980152  16.26872489
  10.61292227  -3.38779532  -5.03319328   0.52292429  -5.6340162
   4.61030648  -3.88882389   5.38142686  -5.37787075  31.19115106]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.8243069093232
gradient value of function right now is: [-1.41902237e-01 -8.57983502e-01  9.20847279e-02 -4.15098528e-01
  1.41902237e-01  8.57983502e-01 -9.20847279e-02  4.15098528e-01
 -1.04933198e-05 -6.39136152e-02 -2.09113665e-02 -1.22161016e-05
  2.94584827e-03  1.94236292e-01 -1.39658025e-01  3.48973532e-03
 -1.72588687e-10  7.10433354e-04 -7.58221986e-04 -1.44887041e-10
  2.49626999e-05  8.48582074e-02  2.09168193e-02  2.91346110e-05
 -5.39239700e-02 -6.54782535e-02 -2.95125643e-02 -3.77311519e-02
  4.34496645e-01  3.99861718e-01  2.52070423e-01  2.04169514e-01
 -9.65827836e-02 -1.25187205e-01 -3.46136503e-02 -3.96166631e-02
 -6.64041951e-02 -8.06026708e-02 -3.63403963e-02 -4.64482153e-02
  5.15170453e-03  3.37954981e-03  1.30240845e-02  3.32759370e-03
 -2.44967198e-03  1.16344855e-03  3.72066357e-03  9.93251639e-04
 -5.13409445e-02 -5.66271209e-03 -7.95834017e-03 -1.98773467e-03
 -1.02113855e-02  1.55698456e-03 -1.21450585e-02 -2.97382873e-03
 -1.06881209e-01 -3.99654939e-01  9.88538434e-03 -3.22475792e-01
  5.21431674e-02 -2.12551450e-01  1.64393752e-02 -1.21138231e-01
 -3.78881710e+00]
supnorm grad right now is: 3.788817102314515
Weights right now are: 
[-1.90873358e+00  2.56965202e+00 -9.73615887e-01  9.85108479e-01
  2.16330229e+00 -2.67834371e+00  1.37255316e+00 -1.70113686e+00
  8.44011930e+01  1.11301430e+01  3.29417229e+01  8.73381799e+01
  3.09214462e+01  1.20487677e+00  9.54928986e-01  3.22651110e+01
  2.98490062e+00  1.74195522e+02  1.35209360e+01 -9.62056586e-01
 -1.22189448e+01 -1.47593697e+00  3.77211206e+01 -1.34495767e+01
  1.80189165e+01  4.17265383e+00 -2.86217164e+00 -2.20593704e+01
  5.16833929e+00  1.37965989e-01 -1.15904859e+00 -6.68580786e+00
  9.36503597e+00  8.04937809e+00 -1.46640482e+01 -1.71146571e+01
  1.79910924e+01  4.25857729e+00 -2.46796155e+00 -2.28815273e+01
 -9.58909547e+01 -6.65317709e+01  3.27614872e+01  6.83212619e+00
 -1.55370182e+01 -9.15899163e+01 -3.35133024e+01 -5.61495479e+01
 -4.44734997e+00 -6.58796602e-01  4.41410841e+01  3.44495711e+01
  3.13649952e+00  2.55590931e+00  1.62567326e+01  9.26064429e+00
 -3.38578649e+00 -5.14437749e+00  8.38460640e-01 -5.38569267e+00
  4.73386789e+00 -3.79874292e+00  6.24782163e+00 -5.04741455e+00
  3.11229685e+01]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.8354231740666
gradient value of function right now is: [-1.62388250e-01  5.02530441e-02 -1.87691837e-02  1.13474471e-01
  1.62388250e-01 -5.02530441e-02  1.87691837e-02 -1.13474471e-01
  1.24061378e-05  1.37968792e-03 -1.73215414e-02  1.46292205e-05
 -7.89307118e-04 -5.70948256e-01 -2.55066718e-01 -9.32161168e-04
 -9.48127696e-11 -6.12639202e-04 -4.59188719e-04 -7.35963292e-11
 -7.07922949e-04 -1.80597671e-01 -3.36214393e-03 -8.38619510e-04
  1.43061950e-02  2.01113071e-02  2.00342066e-03  6.32627590e-03
  4.37700324e-01  4.22948715e-01  2.01572252e-01  1.29827243e-01
  7.01361716e-01  7.15772742e-01  2.13780338e-01  4.24669519e-01
  1.72545817e-02  2.43019775e-02  2.33638148e-03  7.58351151e-03
 -2.19599812e-02 -1.16431791e-02 -3.37462751e-02 -1.04330105e-02
 -3.15239249e-02 -7.72615491e-03 -1.65153396e-02 -4.86085185e-03
 -2.69265240e-02  1.59481472e-02  4.73418349e-02  1.41911932e-02
  2.61906732e-02  3.07836614e-02  7.71237645e-02  2.41347255e-02
 -5.18820581e-01  2.23429969e+00 -2.73786186e-01  1.37778447e+00
 -4.74236607e-01  2.43063727e+00 -1.35428443e-01  7.92510911e-01
  2.14707601e+01]
supnorm grad right now is: 21.470760068621523
Weights right now are: 
[-1.87345873e+00  2.45155144e+00 -1.37938214e+00  1.17034586e+00
  2.12802745e+00 -2.56024313e+00  1.77831941e+00 -1.88637424e+00
  8.68796261e+01  1.21269651e+01  3.45158534e+01  9.02618294e+01
  3.13696341e+01  1.33526947e+00  1.37632378e+00  3.27048844e+01
  2.98505067e+00  1.79839976e+02  1.63833048e+01 -9.61920131e-01
 -7.21798834e+00 -1.28425238e+00  3.71096260e+01 -8.31924712e+00
  1.84593239e+01  4.11957441e+00 -3.17052977e+00 -2.23179484e+01
  5.17895916e+00  8.92594605e-02 -1.46219476e+00 -6.80633581e+00
  9.78616776e+00  7.95415404e+00 -1.52139705e+01 -1.66337370e+01
  1.84316105e+01  4.20553194e+00 -2.77164087e+00 -2.31371994e+01
 -9.89491407e+01 -6.92338258e+01  3.27301530e+01  5.76358865e+00
 -1.14321434e+01 -9.33306115e+01 -3.28005265e+01 -5.64663513e+01
 -4.45185711e+00 -1.62701674e+00  4.53980316e+01  3.60044807e+01
  3.41831928e+00  1.88425461e+00  1.59952688e+01  7.70383049e+00
 -3.13254730e+00 -5.38038861e+00  1.38678233e+00 -5.42759964e+00
  4.55753625e+00 -3.83617088e+00  5.70024598e+00 -5.03130600e+00
  3.12562593e+01]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.9533857482766
gradient value of function right now is: [ 6.36998193e-01  1.33588918e+00  1.67679065e-01  7.11471030e-01
 -6.36998193e-01 -1.33588918e+00 -1.67679065e-01 -7.11471030e-01
 -3.27586487e-06  3.14670595e-02  8.82009667e-03 -3.94047171e-06
  8.11213993e-04 -3.03264681e-01 -7.95683964e-01  9.77339963e-04
  6.29754740e-10  2.56323448e-03  4.60496545e-04  6.54822547e-10
  6.69459663e-05 -5.46655077e-03 -5.65285863e-03  8.02398345e-05
 -9.85587316e-03 -2.02280270e-02 -4.73589504e-03 -9.69912794e-03
 -6.00246310e-01 -6.73303624e-01 -1.35679273e-01 -1.33487786e-02
  3.32446364e-01  2.11794138e-01  1.99976268e-01  1.40598833e-01
 -1.22816224e-02 -2.51595115e-02 -5.90277618e-03 -1.20662289e-02
 -1.53873794e-03  2.20377756e-03  1.09296804e-02  3.16355573e-03
 -3.47979121e-02 -9.66223429e-04  1.18411316e-03  4.91481785e-04
  5.11659717e-02 -8.10437373e-03 -6.37928326e-03 -2.98184985e-03
  2.64823406e-02 -1.92511603e-02 -3.09064518e-02 -1.23157015e-02
 -3.56550258e-01  3.60821600e-01 -8.28897225e-02 -5.53829596e-02
  1.09943604e-02 -1.53202453e-01  2.01190819e-02 -1.20990695e-01
 -9.51967995e+00]
supnorm grad right now is: 9.519679951867012
Weights right now are: 
[-1.84866266e+00  2.69077181e+00 -1.23411835e+00  1.19618349e+00
  2.10323137e+00 -2.79946350e+00  1.63305562e+00 -1.91221187e+00
  8.83184365e+01  1.32795002e+01  3.42241594e+01  9.19856647e+01
  3.14955790e+01  1.09057961e+00  1.10467082e+00  3.28259699e+01
  2.98516670e+00  1.84886279e+02  1.92818290e+01 -9.61808108e-01
 -1.85403860e+00 -5.58592311e-01  3.83301937e+01 -2.81260844e+00
  1.93094639e+01  4.10836061e+00 -2.75104289e+00 -2.21760867e+01
  5.58432478e+00  1.00766505e-01 -1.62481759e+00 -6.47816049e+00
  1.04783550e+01  8.16075253e+00 -1.53290923e+01 -1.60933819e+01
  1.92754113e+01  4.19352293e+00 -2.35581069e+00 -2.29973599e+01
 -1.02244123e+02 -7.15813375e+01  3.35156800e+01  5.47159531e+00
 -7.26289560e+00 -9.54806137e+01 -3.20495250e+01 -5.68028969e+01
 -4.60367654e+00 -2.54839851e+00  4.59439175e+01  3.66863437e+01
  3.92616673e+00  2.28064801e-01  1.58082742e+01  7.15201163e+00
 -4.04783807e+00 -5.14160561e+00  1.12006220e+00 -5.66457507e+00
  4.80211043e+00 -3.97483057e+00  5.74708277e+00 -5.29232805e+00
  3.09942338e+01]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.8868880193888
gradient value of function right now is: [ 7.09093193e-01  1.66706662e-01  1.38049217e-01  8.59566285e-01
 -7.09093193e-01 -1.66706662e-01 -1.38049217e-01 -8.59566285e-01
 -1.44840474e-06  4.73869708e-02  2.18710112e-03 -1.74269285e-06
  3.53379589e-03  5.84254646e-01  8.24240822e-01  4.22033607e-03
  8.85066347e-11  1.76637625e-03  6.28716577e-05  9.31355184e-11
  7.72268931e-05 -3.35512598e-03  6.21413142e-03  9.25251907e-05
 -7.36543391e-02 -7.55596272e-02 -4.20912290e-02 -5.00411798e-02
 -1.32370571e+00 -1.29063442e+00 -4.55608952e-01 -4.22019782e-01
 -6.62599200e-01 -6.30000816e-01 -3.35474835e-01 -3.47170134e-01
 -9.14049748e-02 -9.38107098e-02 -5.22161670e-02 -6.21018783e-02
  2.87476881e-02  1.08658133e-02  3.53496919e-02  1.10899468e-02
  2.97118203e-02  5.39335246e-03  1.38743783e-02  4.27431582e-03
 -1.43898182e-01 -2.09889877e-02 -3.63206248e-02 -1.20414318e-02
 -2.47179156e-01 -4.55429557e-02 -7.83768682e-02 -2.81757234e-02
  6.47220015e-01 -3.16471758e+00  2.03005963e-01 -1.22632426e+00
  4.00544062e-01 -1.86255976e+00  1.32886361e-01 -7.24576958e-01
 -1.58443814e+01]
supnorm grad right now is: 15.844381389275755
Weights right now are: 
[-1.73422254e+00  2.56992342e+00 -8.81841604e-01  1.36673100e+00
  1.98879125e+00 -2.67861511e+00  1.28077887e+00 -2.08275939e+00
  9.00756025e+01  1.42582094e+01  3.60774680e+01  9.40796272e+01
  3.18769310e+01  1.23129589e+00  1.45931920e+00  3.32100324e+01
  2.98525729e+00  1.90437805e+02  2.09366761e+01 -9.61718052e-01
 -1.33473342e+00 -2.72327204e-01  3.82066363e+01 -2.32024172e+00
  2.03210671e+01  4.50472381e+00 -3.19579108e+00 -2.24047523e+01
  5.54824354e+00 -3.15269639e-02 -1.61396905e+00 -6.14385341e+00
  1.05267703e+01  8.06146150e+00 -1.59609262e+01 -1.59369135e+01
  2.02872675e+01  4.58715155e+00 -2.78968975e+00 -2.32203180e+01
 -1.04667179e+02 -7.43480336e+01  3.31849624e+01  4.51137048e+00
 -7.37891771e+00 -9.72785783e+01 -3.16656639e+01 -5.73456626e+01
 -4.39548016e+00 -1.73129238e+00  4.73323246e+01  3.82916493e+01
  3.59738184e+00  4.29693564e-01  1.65200952e+01  7.09021444e+00
 -3.40040875e+00 -5.29257159e+00  9.67816152e-01 -5.68102631e+00
  4.65307067e+00 -3.98173542e+00  5.18074483e+00 -5.18441337e+00
  3.10809792e+01]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.0424463684
gradient value of function right now is: [-1.85718801e+00 -2.74501838e+00 -1.76177320e-01 -2.56318225e+00
  1.85718801e+00  2.74501838e+00  1.76177320e-01  2.56318225e+00
 -1.76658553e-05 -1.82628089e-01 -2.38110862e-02 -2.09184644e-05
  1.75234143e-03  4.44942731e-01 -1.23168171e-01  2.07267189e-03
 -9.33404752e-10 -3.21680874e-03 -1.27586604e-04 -9.49679549e-10
  6.57514464e-05  1.90946639e-01  2.64116008e-02  7.81495385e-05
 -3.57232959e-02 -3.56577553e-02 -2.18616098e-02 -2.51499547e-02
  2.31704407e+00  2.23646639e+00  8.28297021e-01  6.56205383e-01
 -1.17980523e-02 -5.74361909e-02  5.06622394e-02 -5.70672069e-02
 -4.37843045e-02 -4.37122526e-02 -2.67929849e-02 -3.08257167e-02
  3.59939789e-03  1.71353686e-03  7.06953463e-03  1.82971246e-03
 -9.52095542e-03  1.66262843e-03  6.32051883e-03  2.02073072e-03
  2.22256965e-01  3.04561028e-02 -1.67207349e-03  2.40053966e-04
  3.76909220e-01  7.05348137e-02  4.01942953e-02  1.78830112e-02
 -1.98729050e-01 -1.39911287e-01  1.63753269e-02 -3.16878816e-01
 -3.86488679e-01  8.00191454e-03 -7.67455803e-02 -1.24148566e-01
  8.08714474e+00]
supnorm grad right now is: 8.08714473641901
Weights right now are: 
[-1.98005131e+00  2.63680563e+00 -8.46081116e-01  1.04304522e+00
  2.23462002e+00 -2.74549732e+00  1.24501838e+00 -1.75907360e+00
  9.20764505e+01  1.34107081e+01  3.61331548e+01  9.64848077e+01
  3.25124753e+01  1.30168255e+00  1.18728032e+00  3.38391989e+01
  2.98556280e+00  1.97789876e+02  2.04904123e+01 -9.61393943e-01
  4.89758169e+00  3.90564409e-01  3.82150141e+01  4.12896392e+00
  2.09612651e+01  4.00510561e+00 -3.19629489e+00 -2.27768597e+01
  5.67818513e+00  8.79271706e-02 -1.16945619e+00 -6.20009360e+00
  1.06490047e+01  8.21010865e+00 -1.62449128e+01 -1.60275862e+01
  2.09295872e+01  4.09018643e+00 -2.78178905e+00 -2.35866341e+01
 -1.07076138e+02 -7.67800180e+01  3.43099952e+01  5.13463188e+00
 -5.44790854e+00 -9.89757936e+01 -3.05186799e+01 -5.72935604e+01
 -4.45283212e+00 -2.58499137e+00  4.79475648e+01  3.84523275e+01
  4.14835352e+00  3.74421909e-01  1.60147208e+01  5.97293323e+00
 -2.73724794e+00 -5.32717086e+00  1.13208946e+00 -5.73408821e+00
  4.81883469e+00 -4.15242838e+00  5.93559672e+00 -5.31672849e+00
  3.11516629e+01]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.651156878646
gradient value of function right now is: [-2.19538207e-01 -1.10824263e+00  7.91987465e-02 -4.48936770e-01
  2.19538207e-01  1.10824263e+00 -7.91987465e-02  4.48936770e-01
 -3.68063604e-06 -4.83312846e-02 -9.83324359e-03 -4.56568856e-06
  1.10519438e-03  3.00570625e-01  5.56637408e-01  1.36155958e-03
 -7.51254587e-11  1.13166350e-04 -9.32381868e-04 -8.20322447e-11
  2.09810853e-05  6.96704163e-02  1.32184804e-02  2.60570946e-05
 -2.32878622e-02 -2.39336669e-02 -1.33973577e-02 -1.61954199e-02
  3.02832574e-01  2.96098021e-01  1.12167208e-01  1.13814789e-01
 -4.89968329e-01 -4.58242001e-01 -3.17828946e-01 -1.71149669e-01
 -2.97793112e-02 -3.06223686e-02 -1.71261159e-02 -2.07121823e-02
  7.05496930e-03  2.60049986e-03  9.22328264e-03  2.60456701e-03
  1.68847622e-02  2.47337623e-03  5.05417455e-03  1.45512773e-03
 -1.80913900e-01 -2.03843509e-02 -1.08957552e-02 -3.00807092e-03
 -1.50235027e-01 -1.61614073e-02 -9.46725756e-03 -2.47383676e-03
  1.24724162e-01 -7.68366512e-01  6.64999227e-02 -4.01152129e-01
  1.25866772e-01 -4.63009400e-01  3.88168895e-02 -1.86271917e-01
  7.04510730e+00]
supnorm grad right now is: 7.04510729669621
Weights right now are: 
[-2.03599746e+00  2.62748565e+00 -8.77580292e-01  1.29418349e+00
  2.29056617e+00 -2.73617734e+00  1.27651756e+00 -2.01021187e+00
  9.37540048e+01  1.45955003e+01  3.76805263e+01  9.85134394e+01
  3.26983301e+01  1.39608805e+00  1.62838433e+00  3.40295773e+01
  2.98561655e+00  2.03049128e+02  1.64254564e+01 -9.61348313e-01
  8.16952393e+00  1.35774688e-01  3.76525964e+01  7.53141708e+00
  2.16123330e+01  3.95836423e+00 -3.06151760e+00 -2.28114760e+01
  5.70995610e+00  1.82409503e-01 -1.44360603e+00 -6.26438150e+00
  1.05100410e+01  8.30797904e+00 -1.67841242e+01 -1.61930403e+01
  2.15621295e+01  4.02536987e+00 -2.65882570e+00 -2.36356565e+01
 -1.08952238e+02 -7.89618228e+01  3.46040596e+01  4.77774289e+00
 -6.42465811e+00 -1.01157157e+02 -2.98853747e+01 -5.76566038e+01
 -4.01455812e+00 -1.33897697e+00  4.86949156e+01  3.93963919e+01
  3.45825890e+00 -9.03745168e-01  1.61804721e+01  5.03242753e+00
 -3.40067669e+00 -5.45921878e+00  7.95220797e-01 -5.84098044e+00
  4.84508812e+00 -4.05865146e+00  5.47514526e+00 -5.32120903e+00
  3.11517316e+01]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.154285482833
gradient value of function right now is: [ 8.03319593e-01  2.36377688e+00  1.83151800e-01  1.22711984e+00
 -8.03319593e-01 -2.36377688e+00 -1.83151800e-01 -1.22711984e+00
  3.05747531e-06  7.24881420e-02  2.30075092e-02  3.80536867e-06
 -2.36450748e-03 -9.15304166e-01 -1.04492041e+00 -2.93705533e-03
  5.25674677e-11  1.60668390e-03  6.75998191e-04  5.66820228e-11
 -7.78380956e-05 -1.61838944e-01 -4.07169372e-02 -9.72648663e-05
  5.25024926e-02  5.28833452e-02  2.89127759e-02  3.50325182e-02
 -4.49062160e-01 -4.96783072e-01 -4.39091844e-02  9.23319200e-02
  1.25112444e+00  1.08876483e+00  6.08079324e-01  6.07894014e-01
  6.76263027e-02  6.81403485e-02  3.72157580e-02  4.51140530e-02
 -3.10663308e-02 -1.08539000e-02 -3.30316780e-02 -9.08639407e-03
 -7.43713786e-02 -1.07342103e-02 -1.95371072e-02 -5.90418969e-03
  2.18031200e-01  2.50390167e-02  4.39644235e-02  1.30431864e-02
  1.22984227e-01  8.41029789e-03  4.24116582e-02  7.56418956e-03
 -6.84178429e-01  3.72567196e+00 -4.29866183e-01  1.88079871e+00
 -4.22816677e-01  2.33715196e+00 -1.60183638e-01  8.72901276e-01
 -4.02120530e-01]
supnorm grad right now is: 3.7256719560405926
Weights right now are: 
[-2.04817197e+00  2.74221045e+00 -7.21250820e-01  1.44018402e+00
  2.30274068e+00 -2.85090214e+00  1.12018809e+00 -2.15621241e+00
  9.50185823e+01  1.49244371e+01  3.81120949e+01  1.00081922e+02
  3.31519411e+01  1.56854612e+00  1.45096389e+00  3.44755324e+01
  2.98571912e+00  2.09335688e+02  1.83474945e+01 -9.61241535e-01
  9.79666545e+00 -6.37944765e-01  3.84870093e+01  9.13573590e+00
  2.18590455e+01  3.78708578e+00 -3.42712665e+00 -2.31519805e+01
  5.61299669e+00  4.63721916e-02 -1.39921229e+00 -6.57035570e+00
  1.07695340e+01  8.55814419e+00 -1.68689981e+01 -1.58943327e+01
  2.18030808e+01  3.84929589e+00 -3.02834068e+00 -2.39800716e+01
 -1.11711799e+02 -8.17070875e+01  3.50681512e+01  4.33628654e+00
 -5.56842725e+00 -1.02860991e+02 -2.93634495e+01 -5.81866545e+01
 -3.65945292e+00 -9.56537076e-01  4.94112908e+01  4.05598408e+01
  4.18348674e+00 -1.43454457e-01  1.69172227e+01  5.55698102e+00
 -3.35203803e+00 -5.04288831e+00  6.80560947e-01 -5.49701523e+00
  4.85380403e+00 -3.89909276e+00  4.20886203e+00 -5.26934185e+00
  3.10225800e+01]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.5316380668767
gradient value of function right now is: [ 6.06850292e-01  7.36401384e-01  1.11284399e-01  7.48415327e-01
 -6.06850292e-01 -7.36401384e-01 -1.11284399e-01 -7.48415327e-01
 -1.37879581e-06  4.75071201e-02  3.78490392e-03 -1.76907731e-06
  2.21000543e-03  1.74055133e-01  8.00951982e-02  2.79283038e-03
  2.09191104e-11  1.16511377e-03  5.54412520e-05  2.40548471e-11
  4.74698108e-05 -1.11788216e-02 -6.11528916e-04  6.06852146e-05
 -4.72702675e-02 -4.91672238e-02 -2.77396907e-02 -3.34527097e-02
 -9.42401754e-01 -9.59253470e-01 -2.77201512e-01 -2.87124728e-01
 -3.31251274e-02 -8.01889421e-02  1.55136067e-03 -5.11790050e-02
 -6.18948188e-02 -6.44226415e-02 -3.62862865e-02 -4.37918762e-02
  1.32845071e-02  6.49028676e-03  2.08468487e-02  7.63498844e-03
 -5.00425540e-03  9.58734038e-04  5.24961339e-03  1.90917692e-03
 -1.45700115e-02 -9.18181622e-03 -1.54229121e-02 -6.20886842e-03
 -7.25408767e-02 -2.77714585e-02 -4.57035632e-02 -1.97580760e-02
  2.17364698e-01 -1.52830243e+00  2.19035260e-02 -5.86995715e-01
  1.26071068e-01 -6.60265674e-01  5.24510936e-02 -3.44563546e-01
  2.84110697e+00]
supnorm grad right now is: 2.8411069736708656
Weights right now are: 
[-1.98404359e+00  2.63637263e+00 -8.37895374e-01  1.29956707e+00
  2.23861230e+00 -2.74506432e+00  1.23683264e+00 -2.01559545e+00
  9.60387023e+01  1.51385675e+01  3.69443468e+01  1.01368237e+02
  3.34584698e+01  1.56029844e+00  1.22383141e+00  3.47811232e+01
  2.98575932e+00  2.15437214e+02  2.08012091e+01 -9.61199056e-01
  1.43356169e+01  3.02995373e-01  4.01640318e+01  1.37346220e+01
  2.25072014e+01  3.51963266e+00 -3.23111746e+00 -2.32667980e+01
  5.64449261e+00 -7.36512548e-02 -1.67839923e+00 -6.18141164e+00
  1.10137462e+01  8.56422266e+00 -1.71526408e+01 -1.56163151e+01
  2.24398710e+01  3.56764236e+00 -2.82930724e+00 -2.40990762e+01
 -1.13245302e+02 -8.34301052e+01  3.59056489e+01  4.41312097e+00
 -4.78664243e+00 -1.04603694e+02 -2.84023741e+01 -5.85498193e+01
 -4.66150437e+00 -2.97278808e+00  4.98881003e+01  4.07344789e+01
  3.91527768e+00 -8.08591654e-02  1.68375571e+01  5.23896375e+00
 -3.05748939e+00 -5.54899383e+00  9.37570926e-01 -5.86776837e+00
  4.92048077e+00 -4.16145651e+00  5.54682949e+00 -5.22079883e+00
  3.11610067e+01]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.545887402257
gradient value of function right now is: [ 2.87845928e-01  2.06042785e-01  9.06794474e-02  3.47459857e-01
 -2.87845928e-01 -2.06042785e-01 -9.06794474e-02 -3.47459857e-01
  2.83547899e-07  1.28017816e-02  2.60013941e-03  3.33769966e-07
  7.10907115e-03  1.63610362e-01  3.62408559e-01  8.86231836e-03
  3.77438226e-10  9.31397799e-04  3.67619306e-04  4.36704042e-10
  7.34473967e-05 -1.55493312e-02 -3.86788903e-03  9.22573508e-05
 -1.52327031e-01 -1.68881823e-01 -8.17617739e-02 -1.06902086e-01
 -4.60480263e-01 -4.74750542e-01 -1.52223818e-01 -1.47534169e-01
 -6.82531309e-02 -1.03999297e-01 -8.31378157e-02 -2.40398943e-02
 -1.96252675e-01 -2.17741512e-01 -1.05241056e-01 -1.37718360e-01
  2.02314577e-02  1.07662336e-02  3.91871904e-02  1.38407377e-02
  2.94804286e-03  4.87164192e-04  4.39578449e-03  1.49733787e-03
 -9.97880597e-02 -9.80511269e-03 -8.29237284e-03 -3.08451893e-03
 -1.57460307e-01 -2.87240147e-02 -5.32175433e-02 -2.06073569e-02
  3.32271997e-01 -2.39553789e+00  5.81618929e-02 -9.47754932e-01
  8.35340082e-03  9.01103992e-02  2.01979327e-02 -2.23418718e-01
  2.28944720e+00]
supnorm grad right now is: 2.3955378866328956
Weights right now are: 
[-2.00789470e+00  2.66188085e+00 -1.26453474e+00  1.31304463e+00
  2.26246341e+00 -2.77057254e+00  1.66347201e+00 -2.02907301e+00
  9.73391338e+01  1.51373222e+01  3.86962798e+01  1.03029160e+02
  3.41400537e+01  1.39892564e+00  1.53796573e+00  3.54439137e+01
  2.98581015e+00  2.20910247e+02  2.03434113e+01 -9.61143988e-01
  2.03730810e+01 -4.75815443e-01  3.84111415e+01  1.98873958e+01
  2.24340065e+01  2.57652323e+00 -3.42053179e+00 -2.38436747e+01
  5.89867229e+00  2.71262463e-01 -1.21147678e+00 -6.48535284e+00
  1.10808230e+01  8.61139094e+00 -1.73946100e+01 -1.58184326e+01
  2.23708737e+01  2.63434964e+00 -3.00727159e+00 -2.46648631e+01
 -1.14936369e+02 -8.57564593e+01  3.67748278e+01  4.73745280e+00
 -5.36765713e+00 -1.06383889e+02 -2.75481366e+01 -5.87424027e+01
 -4.65258117e+00 -1.46731637e+00  5.07383505e+01  4.16734038e+01
  3.42565547e+00 -3.84131137e-02  1.66843649e+01  4.84574376e+00
 -3.01376929e+00 -5.59787044e+00  1.05445514e+00 -5.81535086e+00
  5.12377093e+00 -4.11183218e+00  5.55491662e+00 -5.17674930e+00
  3.11771620e+01]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.722753682697
gradient value of function right now is: [-1.68000980e-01  2.16571637e-01 -6.52640744e-02 -1.66904910e-01
  1.68000980e-01 -2.16571637e-01  6.52640744e-02  1.66904910e-01
  2.68408084e-06 -5.25639399e-03 -1.79949940e-03  3.34812486e-06
 -2.00292917e-03 -2.79653123e-01 -5.73587717e-01 -2.48310222e-03
  2.12700036e-11 -8.16407281e-04  1.64842567e-04  3.59856528e-11
 -7.94199201e-05 -1.13834920e-02 -1.20249944e-03 -9.90454851e-05
  4.42678294e-02  5.05425588e-02  2.23060907e-02  3.03647390e-02
  4.19896925e-01  4.04330303e-01  2.00831572e-01  1.33996710e-01
  3.12188978e-01  2.99960817e-01  1.54183247e-01  1.84198059e-01
  5.68191149e-02  6.48867601e-02  2.86282304e-02  3.89783359e-02
 -1.29193429e-02 -6.30008087e-03 -1.86477899e-02 -1.00761105e-02
 -9.93000883e-03 -2.82338410e-03 -6.73823654e-03 -3.67981023e-03
  6.53045738e-02  1.87754684e-02  1.60422727e-02  9.48830482e-03
  8.61822633e-02  2.15612659e-02  3.03826747e-02  1.78076952e-02
 -2.68088932e-01  1.52344393e+00 -1.19834207e-01  8.32981015e-01
 -1.84218943e-01  6.88392232e-01 -1.24152294e-01  5.76726226e-01
 -3.50968643e+00]
supnorm grad right now is: 3.5096864334727504
Weights right now are: 
[-1.93993840e+00  2.66645349e+00 -1.24775807e+00  1.37026586e+00
  2.19450711e+00 -2.77514519e+00  1.64669534e+00 -2.08629424e+00
  9.84388656e+01  1.61641389e+01  3.80523983e+01  1.04430808e+02
  3.39410889e+01  9.89032357e-01  1.26740376e+00  3.52251900e+01
  2.98584616e+00  2.26658250e+02  2.38438399e+01 -9.61106204e-01
  1.99343106e+01 -2.18614307e-01  4.04661662e+01  1.94268017e+01
  2.35154659e+01  3.01418010e+00 -3.07443236e+00 -2.34880923e+01
  5.97631247e+00  2.83754301e-01 -1.26195069e+00 -6.14139064e+00
  1.10047307e+01  9.05009819e+00 -1.74330900e+01 -1.61759978e+01
  2.34499473e+01  3.07952488e+00 -2.65490785e+00 -2.43012962e+01
 -1.16756343e+02 -8.79917056e+01  3.64968089e+01  4.26533089e+00
 -5.03791486e+00 -1.08315300e+02 -2.75591165e+01 -5.98675649e+01
 -4.66635186e+00 -5.52241578e-01  5.18428234e+01  4.29110057e+01
  3.64635759e+00  2.84775655e-01  1.79461466e+01  6.01839871e+00
 -3.09052168e+00 -5.52619500e+00  1.36369583e+00 -5.65576992e+00
  4.96900333e+00 -4.19112135e+00  5.02198538e+00 -4.81448185e+00
  3.10737521e+01]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.795035496799
gradient value of function right now is: [-9.38407744e-01 -1.37647629e+00 -3.75491084e-01 -1.21123608e+00
  9.38407744e-01  1.37647629e+00  3.75491084e-01  1.21123608e+00
 -1.37627110e-06 -5.43589792e-02 -5.44540883e-03 -1.64598183e-06
  1.36208482e-04  2.92487095e-01  2.36162268e-01  1.61430645e-04
 -2.55801298e-11 -2.76744752e-03  5.32889814e-04 -2.82293433e-11
  9.51349116e-06  7.92658666e-02  1.06792034e-02  1.13862464e-05
 -4.31457195e-03 -3.20356381e-03 -2.21204463e-03 -2.29959616e-03
  1.09368119e+00  1.07819519e+00  1.14513619e-01  1.76955336e-01
 -2.50708779e-01 -2.47689169e-01 -1.03920567e-01 -1.46506933e-01
 -5.30097671e-03 -3.94981455e-03 -2.72455735e-03 -2.83551407e-03
  7.27672300e-03  3.19112803e-03  6.25679873e-03  2.93119319e-03
 -1.25569337e-03  2.67822721e-03  5.03660044e-03  2.42785211e-03
  1.55679816e-02 -8.37451364e-04 -9.33822503e-03 -3.56504413e-03
  1.09200966e-01  2.86536757e-02  1.73204527e-02  1.48391595e-02
  6.03447641e-02 -7.03208019e-01  6.84477323e-02 -5.23473606e-01
 -2.26887022e-02 -3.71058659e-01  3.67889765e-03 -2.88878940e-01
  4.82386692e+00]
supnorm grad right now is: 4.823866917561817
Weights right now are: 
[-2.16738628e+00  2.64419474e+00 -1.23758571e+00  1.26567957e+00
  2.42195499e+00 -2.75288643e+00  1.63652298e+00 -1.98170795e+00
  9.97779557e+01  1.61505850e+01  3.86240927e+01  1.06079938e+02
  3.38117956e+01  1.63708461e+00  1.55070877e+00  3.50687781e+01
  2.98588421e+00  2.33020914e+02  2.14990509e+01 -9.61067971e-01
  2.58406492e+01  1.35877585e-01  4.12657397e+01  2.54564421e+01
  2.39977838e+01  3.57722219e+00 -3.50590082e+00 -2.34983707e+01
  5.98791999e+00  2.09258761e-01 -1.63150328e+00 -6.24077488e+00
  1.11534671e+01  8.87287716e+00 -1.75540568e+01 -1.60936830e+01
  2.39444375e+01  3.65454034e+00 -3.05479996e+00 -2.42864424e+01
 -1.18751007e+02 -8.97962095e+01  3.69773277e+01  4.97459908e+00
 -5.66579554e+00 -1.09971033e+02 -2.67953607e+01 -5.99063286e+01
 -4.41261568e+00 -2.07440929e+00  5.19590150e+01  4.29467630e+01
  3.85605033e+00 -2.65732339e-01  1.89288799e+01  6.44842388e+00
 -3.68062635e+00 -5.57311300e+00  8.68908759e-01 -5.71355718e+00
  5.25094565e+00 -4.38082800e+00  5.09032718e+00 -5.22796238e+00
  3.11319158e+01]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.3972656766039
gradient value of function right now is: [ 7.49970347e-01  1.60605323e+00  1.37733415e-01  9.15732544e-01
 -7.49970347e-01 -1.60605323e+00 -1.37733415e-01 -9.15732544e-01
 -8.60673730e-07  5.44801873e-02  1.93316398e-02 -1.04783048e-06
  8.35888430e-04 -3.52361004e-02 -3.33238057e-01  9.96987285e-04
  1.67652303e-11  1.52741198e-03  6.22091488e-04  1.78366745e-11
  2.40957459e-05 -2.49321861e-02 -1.35208638e-02  2.92414878e-05
 -1.84910502e-02 -1.93885785e-02 -1.08444221e-02 -1.32582842e-02
 -1.04728329e+00 -1.06835185e+00 -2.91634615e-01 -2.70880377e-01
  1.78429362e-01  1.06990380e-01  1.39948437e-01  2.99184694e-02
 -2.28085297e-02 -2.39285175e-02 -1.33609886e-02 -1.63472000e-02
  7.15519030e-03  4.29841610e-03  1.22588617e-02  6.22100993e-03
 -2.33800152e-02 -5.41509677e-04  2.92721793e-03  1.40427107e-03
  8.53167737e-02 -2.79708350e-03 -9.72359232e-03 -5.38750969e-03
  9.31312819e-03 -2.46514910e-02 -3.59699604e-02 -2.20437959e-02
  8.32372969e-02 -8.82764782e-01 -7.31934526e-02 -3.10797878e-01
  6.20212099e-02 -5.21371345e-01  2.39691141e-02 -3.04871338e-01
 -6.66146714e+00]
supnorm grad right now is: 6.661467142375622
Weights right now are: 
[-2.16218293e+00  2.80761735e+00 -9.53676467e-01  1.35186070e+00
  2.41675164e+00 -2.91630904e+00  1.35261374e+00 -2.06788908e+00
  1.00308277e+02  1.67606077e+01  3.82679681e+01  1.06715864e+02
  3.42224952e+01  1.56337838e+00  1.25608220e+00  3.54812677e+01
  2.98590426e+00  2.38892819e+02  2.11138801e+01 -9.61048491e-01
  3.21875792e+01  7.03137718e-01  4.20863378e+01  3.19127780e+01
  2.42902492e+01  3.07442304e+00 -3.70395236e+00 -2.39064774e+01
  5.84508966e+00 -1.27072275e-01 -1.45737393e+00 -6.06737340e+00
  1.10605036e+01  8.99781718e+00 -1.75915863e+01 -1.67329529e+01
  2.42330765e+01  3.14774912e+00 -3.25063389e+00 -2.46953458e+01
 -1.20620997e+02 -9.18026830e+01  3.78494353e+01  5.52118911e+00
 -5.10164046e+00 -1.11468377e+02 -2.63293694e+01 -6.06878660e+01
 -4.50160398e+00 -1.57515392e+00  5.27680282e+01  4.38556928e+01
  3.73862844e+00 -1.63654473e+00  1.83762133e+01  5.33154952e+00
 -3.30855490e+00 -5.57157839e+00  1.03383215e+00 -5.82832522e+00
  4.89917818e+00 -4.34626088e+00  4.74433321e+00 -5.10536908e+00
  3.10823776e+01]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.8130964008958
gradient value of function right now is: [ 4.84411375e-01  4.74725625e-02  1.24898995e-01  5.07041553e-01
 -4.84411375e-01 -4.74725625e-02 -1.24898995e-01 -5.07041553e-01
 -9.59049045e-07  1.58818529e-02  2.36983114e-03 -1.16201181e-06
  2.91619938e-04  3.32533765e-01  8.29854611e-01  3.46668097e-04
  3.81249260e-11  1.39560817e-03  4.70388467e-04  4.28175068e-11
  9.51134952e-06  8.54130169e-03  2.81268581e-03  1.15164550e-05
 -7.77404727e-03 -6.64688023e-03 -4.29529034e-03 -4.81058713e-03
 -9.37180534e-01 -8.70645907e-01 -3.19233723e-01 -2.91693939e-01
 -6.13792928e-01 -4.73648361e-01 -2.62629571e-01 -3.36494168e-01
 -9.57176239e-03 -8.19647418e-03 -5.28864251e-03 -5.92808691e-03
  1.25584232e-02  3.67389407e-03  8.99866591e-03  4.66709400e-03
  4.78640222e-02  4.81161247e-03  6.88574835e-03  3.76232200e-03
 -1.36381624e-01 -1.58298787e-02 -1.93987623e-02 -1.13602892e-02
 -1.67460512e-01 -2.54711092e-02 -3.54140881e-02 -2.18275256e-02
  4.38266122e-01 -1.65673770e+00  2.03849907e-01 -7.17189201e-01
  3.39039457e-01 -1.20680074e+00  1.88897735e-01 -6.71851292e-01
 -1.03096437e+00]
supnorm grad right now is: 1.6567376959792715
Weights right now are: 
[-2.01791301e+00  2.77976184e+00 -1.26664940e+00  1.37173732e+00
  2.27248173e+00 -2.88845353e+00  1.66558667e+00 -2.08776571e+00
  1.00901781e+02  1.68569483e+01  3.99659256e+01  1.07439298e+02
  3.42810458e+01  1.42414745e+00  1.48343513e+00  3.55274935e+01
  2.98596196e+00  2.44327565e+02  1.98424944e+01 -9.60985981e-01
  3.84323663e+01  8.80866998e-01  4.15540440e+01  3.84890624e+01
  2.47169567e+01  2.84992781e+00 -3.59796871e+00 -2.39581961e+01
  5.91400686e+00  2.28388073e-01 -1.77570107e+00 -6.30762353e+00
  1.09958197e+01  8.91857429e+00 -1.78916339e+01 -1.64986433e+01
  2.46582834e+01  2.92466822e+00 -3.14110837e+00 -2.47430161e+01
 -1.21947260e+02 -9.38775534e+01  3.79328098e+01  5.20609189e+00
 -6.54402297e+00 -1.12887165e+02 -2.57561830e+01 -6.10923111e+01
 -4.64461330e+00  4.50890770e-01  5.38682398e+01  4.52694048e+01
  4.05002818e+00 -3.00471380e+00  1.94031980e+01  5.65295396e+00
 -3.50311747e+00 -5.50589595e+00  1.46359095e+00 -5.97435252e+00
  5.65773783e+00 -4.37546584e+00  5.09816413e+00 -5.18898527e+00
  3.11491950e+01]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.1651320413398
gradient value of function right now is: [ 5.41292899e-01  5.66832854e-01  1.46926597e-01  6.12682461e-01
 -5.41292899e-01 -5.66832854e-01 -1.46926597e-01 -6.12682461e-01
 -1.62993568e-07  2.12860452e-02 -8.55156909e-03 -2.07539455e-07
 -1.86788805e-03 -2.53027363e-01 -7.86896927e-01 -2.30804270e-03
  1.10052881e-11  7.44749032e-04 -3.80102417e-04  1.32667529e-11
  1.42618962e-06 -4.67944305e-03  1.30330346e-02  1.81341280e-06
  3.92346352e-02  3.64353511e-02  2.72864771e-02  2.97221404e-02
 -3.66461509e-01 -3.95070173e-01  1.39794195e-02 -2.46770693e-02
  4.13731577e-03 -2.52733565e-02  2.71909775e-02  1.97432731e-02
  5.01367338e-02  4.65741042e-02  3.48273529e-02  3.79573635e-02
 -6.04718031e-03 -8.61157841e-04 -3.77639923e-03 -1.31751022e-03
 -8.14654172e-03  1.15993439e-03  9.02595238e-04  6.91225110e-04
 -3.29309191e-02 -9.95017599e-03 -5.18571890e-03 -3.91496800e-03
 -8.74139496e-02 -3.07403902e-02 -1.66055184e-02 -1.37062684e-02
 -2.18476171e-01  8.65666498e-01 -2.53711538e-02  6.90235086e-02
  1.70417143e-01 -4.68303124e-01  8.27311298e-02 -1.59872316e-01
  9.72915665e+00]
supnorm grad right now is: 9.72915664580699
Weights right now are: 
[  -2.11307569    2.63406822   -0.57798373    1.61599569    2.3676444
   -2.74275991    0.976921     -2.33202407  101.82960876   18.30218898
   39.36332195  108.59865534   33.93967472    1.67877256    1.396867
   35.19182146    2.98600639  248.52416987   18.36555886   -0.96093861
   45.22244703    0.66246028   43.41952903   45.59342845   25.24850404
    2.98370276   -3.29161725  -23.72438496    5.9838456     0.30478614
   -1.55926532   -6.81103637   11.38275771    9.10079708  -17.45159647
  -16.62520163   25.16517273    3.03700775   -2.85665938  -24.53094645
 -124.04845977  -95.56488766   39.16038927    5.90774863   -6.01732851
 -114.47059415  -24.48056402  -61.48519442   -4.95241665    2.26565679
   53.78578495   45.92185841    4.17326249   -6.17016437   19.95389277
    4.55399392   -3.58859383   -5.35120716    1.41060506   -6.15915043
    5.95267717   -4.53904691    5.09650873   -5.48974341   31.18204848]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.9558668178856
gradient value of function right now is: [ 3.29045504e-01  3.83897018e-02  2.79488741e-02  4.83615764e-01
 -3.29045504e-01 -3.83897018e-02 -2.79488741e-02 -4.83615764e-01
 -2.70302718e-07  4.10871078e-02 -2.16078479e-03 -3.44672670e-07
  4.80694108e-04  3.18603054e-01  4.25501684e-01  5.97328387e-04
  1.73906164e-12  4.66025960e-04 -3.09438476e-07  2.07401528e-12
  1.35068508e-05 -1.49335347e-02  4.94586549e-03  1.71087107e-05
 -1.17742858e-02 -1.12195725e-02 -6.49964596e-03 -7.78142783e-03
 -1.06725239e+00 -9.93579066e-01 -4.16924538e-01 -3.87852056e-01
 -3.14009930e-01 -2.67369603e-01 -1.62743672e-01 -1.62592707e-01
 -1.51488708e-02 -1.44593874e-02 -8.35136292e-03 -1.00133621e-02
  1.28192613e-02  3.93902874e-03  1.16167717e-02  5.13320759e-03
 -1.22915128e-03  2.00316449e-03  5.67751581e-03  2.50659496e-03
 -3.57061496e-02 -2.01327791e-02 -1.63231158e-02 -8.21429268e-03
 -7.77788939e-02 -2.70550577e-02 -2.95854586e-02 -1.49793733e-02
  3.55499250e-01 -1.70813611e+00  4.59178778e-02 -5.33096200e-01
  2.22131573e-01 -9.45186670e-01  1.11548076e-01 -4.60734193e-01
 -4.36059138e-01]
supnorm grad right now is: 1.7081361083205295
Weights right now are: 
[-2.25433743e+00  2.35167583e+00 -1.44156758e+00  1.45668579e+00
  2.50890614e+00 -2.46036752e+00  1.84050485e+00 -2.17271417e+00
  1.02310927e+02  1.80216272e+01  3.95110900e+01  1.09206422e+02
  3.42469272e+01  1.66646325e+00  1.39140305e+00  3.54921665e+01
  2.98602065e+00  2.55692246e+02  2.60856981e+01 -9.60924505e-01
  4.89863841e+01  3.92982652e-01  4.35484879e+01  4.94555286e+01
  2.53996801e+01  2.91147293e+00 -4.23125973e+00 -2.43112966e+01
  5.73025490e+00 -8.22272908e-02 -2.23058847e+00 -5.82947753e+00
  1.12726210e+01  9.33323629e+00 -1.77916751e+01 -1.65222090e+01
  2.53167310e+01  2.95756602e+00 -3.77374807e+00 -2.51093629e+01
 -1.25077650e+02 -9.70967023e+01  3.95784018e+01  5.86470363e+00
 -6.68409449e+00 -1.17106804e+02 -2.42187081e+01 -6.24936276e+01
 -4.87399302e+00  3.96477096e+00  5.44676826e+01  4.68612724e+01
  5.01736288e+00 -6.04290946e+00  2.07714719e+01  3.89904439e+00
 -3.56976635e+00 -5.45262530e+00  9.47217007e-01 -6.03927313e+00
  5.51754271e+00 -4.28090121e+00  5.08990086e+00 -5.23281846e+00
  3.11765246e+01]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1044.580644113689
gradient value of function right now is: [ 6.09213689e-01  2.30198361e+00  1.44918836e-01  1.04730583e+00
 -6.09213689e-01 -2.30198361e+00 -1.44918836e-01 -1.04730583e+00
  5.17776245e-06  6.52279646e-02  1.53689302e-02  6.41961044e-06
 -3.46606762e-03 -9.54585344e-01 -1.13935020e+00 -4.24306938e-03
  1.16592543e-11  8.61575343e-04 -1.13405682e-04  1.42657911e-11
 -1.64393214e-04 -1.55679932e-01 -3.14299126e-02 -2.03788740e-04
  8.21156775e-02  8.94915745e-02  4.53124663e-02  5.75143931e-02
 -2.24517458e-01 -2.30410057e-01  9.93855467e-02  1.31854466e-01
  1.13517054e+00  1.00794074e+00  5.82542608e-01  6.01809104e-01
  1.03865465e-01  1.13279068e-01  5.72525166e-02  7.27369530e-02
 -2.88799935e-02 -1.71010107e-02 -3.58605583e-02 -1.55729934e-02
 -5.25115020e-02 -1.23926767e-02 -1.53593202e-02 -6.99588472e-03
  1.39078910e-01  3.39266124e-02  3.26332087e-02  1.49724532e-02
  7.66751207e-02  2.68668670e-02  3.70122411e-02  1.37069892e-02
 -7.82995656e-01  3.64288137e+00 -7.37598386e-01  2.98999102e+00
 -3.16285057e-01  1.49528875e+00 -2.08967573e-01  1.03339959e+00
  8.42550867e+00]
supnorm grad right now is: 8.425508673591668
Weights right now are: 
[-2.24755752e+00  2.78860139e+00 -1.00786480e+00  1.35996917e+00
  2.50212623e+00 -2.89729308e+00  1.40680207e+00 -2.07599755e+00
  1.02934631e+02  1.78977187e+01  4.10092011e+01  1.09976868e+02
  3.48330769e+01  1.71049554e+00  1.10067023e+00  3.60650215e+01
  2.98603195e+00  2.61443814e+02  2.77468324e+01 -9.60913006e-01
  4.89144298e+01  1.23526706e-01  4.26377191e+01  4.95577628e+01
  2.57565218e+01  2.85856886e+00 -4.80880162e+00 -2.47134763e+01
  5.88032100e+00  2.93696175e-01 -1.51588148e+00 -5.99474190e+00
  1.15614216e+01  9.95053287e+00 -1.77048354e+01 -1.63856188e+01
  2.56729777e+01  2.92466950e+00 -4.35963371e+00 -2.55034405e+01
 -1.26100421e+02 -9.85922745e+01  4.04788847e+01  6.09563075e+00
 -7.16911257e+00 -1.20070977e+02 -2.41568285e+01 -6.37127281e+01
 -5.52716030e+00  5.12363864e+00  5.46785211e+01  4.67387774e+01
  5.30151053e+00 -5.56912359e+00  2.12922118e+01  3.68052342e+00
 -2.72892919e+00 -5.67442541e+00  1.08661662e+00 -5.53026231e+00
  5.32879109e+00 -4.19476955e+00  5.08100759e+00 -5.09508566e+00
  3.10886857e+01]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.3542120470493
gradient value of function right now is: [ 5.53860004e-01  2.60894605e-01  1.17116835e-01  6.82022124e-01
 -5.53860004e-01 -2.60894605e-01 -1.17116835e-01 -6.82022124e-01
 -2.48263362e-07  3.13166520e-02 -2.11761292e-03 -3.15182537e-07
  6.91917514e-04  1.07762031e-01  3.59703498e-01  8.54623763e-04
  5.07477843e-12  1.10653761e-03 -6.66246827e-05  5.90143437e-12
  3.29706057e-06 -2.19130057e-02  3.24367111e-03  4.16844363e-06
 -1.59435839e-02 -1.56776459e-02 -9.51920048e-03 -1.12273174e-02
 -9.21771179e-01 -8.89558726e-01 -2.31416667e-01 -2.55714272e-01
 -2.63833989e-01 -2.30552109e-01 -1.65909361e-01 -1.01931780e-01
 -2.03405789e-02 -2.00147213e-02 -1.21353680e-02 -1.43222764e-02
  6.13755056e-03  2.29659794e-03  6.48162115e-03  2.51478784e-03
  1.42768684e-02  1.54270973e-03  2.36432314e-03  9.44333885e-04
 -1.18775721e-01 -1.25888246e-02 -7.95488560e-03 -3.93470231e-03
 -1.81814141e-01 -3.64881420e-02 -3.04717262e-02 -1.74128519e-02
  1.97952563e-01 -8.89853144e-01  5.65255399e-02 -3.10261630e-01
  2.04063233e-01 -5.26799584e-01  7.45618154e-02 -1.90126747e-01
  8.60039420e+00]
supnorm grad right now is: 8.600394198678046
Weights right now are: 
[-2.09993981e+00  2.64568962e+00 -9.80475505e-01  1.44616925e+00
  2.35450852e+00 -2.75438131e+00  1.37941277e+00 -2.16219763e+00
  1.03228159e+02  1.86849283e+01  4.02739102e+01  1.10349645e+02
  3.53783891e+01  1.62137083e+00  1.43682983e+00  3.66106712e+01
  2.98603542e+00  2.66234984e+02  2.56048202e+01 -9.60909227e-01
  5.06452217e+01  7.01345104e-01  4.29654744e+01  5.15824326e+01
  2.61078864e+01  2.41807367e+00 -4.94607905e+00 -2.50744275e+01
  5.65852612e+00  1.56412998e-01 -1.36486696e+00 -6.23611898e+00
  1.11854321e+01  9.46136266e+00 -1.85591097e+01 -1.67471488e+01
  2.60135276e+01  2.48136610e+00 -4.50440695e+00 -2.58674562e+01
 -1.27711085e+02 -9.98385099e+01  4.24963818e+01  6.96598852e+00
 -7.12817591e+00 -1.21765499e+02 -2.28409730e+01 -6.42354132e+01
 -5.59769217e+00  6.31833431e+00  5.43955840e+01  4.69380059e+01
  4.77752757e+00 -6.44189244e+00  2.11343564e+01  2.52833016e+00
 -3.31132780e+00 -5.59891231e+00  1.23268123e+00 -6.00294329e+00
  5.41950049e+00 -4.36495120e+00  5.07241403e+00 -5.45895554e+00
  3.11934646e+01]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.7382853325903
gradient value of function right now is: [-5.68067547e-02 -1.18185978e+00  1.72233408e-03 -2.28088664e-01
  5.68067547e-02  1.18185978e+00 -1.72233408e-03  2.28088664e-01
 -7.82392583e-07 -2.11297711e-02 -6.06644654e-03 -9.72206394e-07
  6.31173963e-04  5.74043428e-01  1.16717606e+00  7.70566275e-04
  1.79687939e-13  2.10153514e-05  3.47295068e-05  1.02300497e-13
  1.25028502e-05  6.16467015e-02  1.21897163e-02  1.55153552e-05
 -1.51121341e-02 -1.39020913e-02 -9.23468327e-03 -1.04383897e-02
 -4.56516961e-01 -3.61724248e-01 -3.04196599e-01 -2.59186326e-01
 -9.11999385e-01 -7.17387891e-01 -4.75252560e-01 -4.41044653e-01
 -1.90822673e-02 -1.75769028e-02 -1.16467912e-02 -1.31793500e-02
  1.72620695e-02  4.47843306e-03  1.41786404e-02  5.03796709e-03
  6.90292622e-02  6.16348214e-03  1.00462044e-02  3.91115354e-03
 -2.09594853e-01 -2.12682836e-02 -2.23445445e-02 -9.43200922e-03
 -2.17940519e-01 -3.03289548e-02 -2.13015714e-02 -8.80123217e-03
  6.49871748e-01 -2.33036411e+00  3.02332600e-01 -1.06978401e+00
  3.82481861e-01 -1.17565947e+00  1.86407275e-01 -5.83384358e-01
 -7.16478817e+00]
supnorm grad right now is: 7.164788166554061
Weights right now are: 
[  -2.13225746    2.57366827   -1.20706908    1.35783181    2.38682617
   -2.68235996    1.60600635   -2.0738602   103.7817217    19.3530767
   40.56625616  111.04772098   34.84617196    1.90688648    1.53200648
   36.06527102    2.98604638  269.79826829   21.51328217   -0.9608981
   55.59961294    1.43757329   43.58903012   56.85173426   26.92178629
    2.94788197   -4.65540138  -24.68784966    5.70499631    0.29814028
   -1.79412186   -5.97389171   11.43897045    9.82824071  -18.33470917
  -16.8686416    26.82671249    3.01952423   -4.20873859  -25.47355394
 -129.27596048 -101.89716321   42.13984734    5.86439832   -5.9387625
 -123.28891312  -22.10659226  -64.95146861   -5.35560954    6.17876553
   54.91281741   47.83892983    4.63901436   -7.70957098   22.88181029
    2.83969882   -3.24597413   -5.58377334    1.55345984   -6.0269596
    5.96789294   -4.13293871    5.38479424   -5.32474954   31.15512186]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.915255069621
gradient value of function right now is: [ 1.39402009e-01 -2.77806251e-02 -5.52399780e-02  2.61077711e-01
 -1.39402009e-01  2.77806251e-02  5.52399780e-02 -2.61077711e-01
 -6.97865084e-08  3.24015902e-02  3.49237472e-03 -9.25319693e-08
 -2.23672987e-05  1.70180142e-01  4.88923087e-01 -3.29315850e-05
  8.78186723e-13 -3.86673099e-04  7.82620085e-05  9.94439498e-13
 -4.83206140e-06 -1.92831351e-02 -7.31675143e-04 -6.24056409e-06
 -2.93879176e-04  2.14958097e-03 -1.09844552e-03  6.63876247e-05
 -7.13368135e-01 -6.08268127e-01 -3.98644197e-01 -3.19275359e-01
 -3.87322542e-01 -2.82206263e-01 -2.27971125e-01 -1.68423448e-01
 -2.80581404e-04  2.91062727e-03 -1.37834143e-03  1.55930102e-04
  5.43768355e-03  5.21882201e-04 -1.31434671e-03 -4.27343612e-04
  3.44544454e-02  2.52926709e-03  8.69005743e-04  4.40729799e-04
 -1.52036743e-01 -1.72841748e-02 -5.02049993e-03 -3.11276312e-03
 -1.99009438e-01 -2.66865132e-02 -6.18354980e-03 -2.73713030e-03
  4.00479887e-01 -8.48776465e-01  1.48508701e-01 -2.55067820e-01
  2.28777378e-01 -3.68977673e-01  9.49490246e-02 -1.12636390e-01
 -6.99604995e+00]
supnorm grad right now is: 6.9960499526183355
Weights right now are: 
[-2.49671574e+00  2.65394785e+00 -1.26829727e+00  1.22506218e+00
  2.75128445e+00 -2.76263954e+00  1.66723454e+00 -1.94109056e+00
  1.04132340e+02  2.03242840e+01  4.07362378e+01  1.11505084e+02
  3.52607746e+01  1.80778991e+00  1.62771178e+00  3.64781939e+01
  2.98605635e+00  2.73812331e+02  2.38970193e+01 -9.60886959e-01
  5.72844748e+01  1.08206919e+00  4.44196398e+01  5.86551717e+01
  2.68737712e+01  2.51086671e+00 -4.90318649e+00 -2.50365519e+01
  5.64842394e+00  1.40069737e-01 -1.64587730e+00 -6.45884775e+00
  1.16297932e+01  9.78516751e+00 -1.86753078e+01 -1.59802507e+01
  2.67596603e+01  2.56122006e+00 -4.46818449e+00 -2.58384608e+01
 -1.31295161e+02 -1.03461270e+02  4.29373916e+01  6.17511687e+00
 -5.93245208e+00 -1.25828349e+02 -2.17689561e+01 -6.57633232e+01
 -5.97317111e+00  5.18582744e+00  5.51566752e+01  4.78714271e+01
  4.60476029e+00 -7.43183430e+00  2.25291761e+01  2.20673649e+00
 -2.84870073e+00 -5.47314805e+00  1.75507900e+00 -5.59889401e+00
  5.64136886e+00 -4.40045257e+00  5.57059994e+00 -5.31275523e+00
  3.10605443e+01]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.7992373656912
gradient value of function right now is: [ 1.24399147e-01 -4.98432553e-02  1.36873256e-01  1.71147572e-01
 -1.24399147e-01  4.98432553e-02 -1.36873256e-01 -1.71147572e-01
  1.74793845e-06 -5.86993635e-03 -1.58107879e-02  2.22593612e-06
  1.90562339e-03 -5.21154666e-02  2.69175951e-02  2.38075102e-03
  3.19373738e-13  7.67643765e-04 -2.14291868e-04  8.85557758e-13
 -1.34637908e-04 -3.70455784e-02  1.00958610e-02 -1.71700553e-04
 -3.44439076e-02 -3.75425712e-02 -2.12066594e-02 -2.64768009e-02
  1.02926221e-02 -8.44886135e-03  1.70386055e-01  5.85493281e-02
  1.43472673e-01  1.08596830e-01  1.84596251e-03  1.26358361e-01
 -4.41137304e-02 -4.81033214e-02 -2.71943427e-02 -3.39440386e-02
 -3.00944062e-03 -3.93483021e-04  1.16852278e-03  1.20189123e-04
  5.34529074e-03 -1.70322741e-03 -5.02015805e-03 -2.06576543e-03
 -5.56784134e-02  2.79536491e-03  1.03830720e-02  4.21967212e-03
 -3.19801350e-02 -1.55508181e-03 -9.85322323e-04 -1.90368047e-03
 -1.44015873e-01  2.83217352e-01 -4.61020577e-02  2.27261363e-01
 -1.30574896e-01  7.25746563e-01 -5.67790366e-02  3.07993874e-01
  4.90746604e+00]
supnorm grad right now is: 4.90746604444063
Weights right now are: 
[-2.12501737e+00  2.46597078e+00 -8.44225040e-01  1.50073200e+00
  2.37958608e+00 -2.57466247e+00  1.24316231e+00 -2.21676038e+00
  1.04588230e+02  1.98567150e+01  4.06590552e+01  1.12110726e+02
  3.57064881e+01  1.89831387e+00  1.43972060e+00  3.69044468e+01
  2.98607037e+00  2.79343696e+02  2.48155177e+01 -9.60870701e-01
  6.29814155e+01  8.54646535e-01  4.37379875e+01  6.47704040e+01
  2.67245806e+01  1.94800367e+00 -5.47952919e+00 -2.56405449e+01
  5.75960407e+00  1.50269523e-01 -1.73077272e+00 -5.73373370e+00
  1.15214448e+01  1.00617716e+01 -1.88195196e+01 -1.62752899e+01
  2.66145747e+01  2.00791065e+00 -5.03597349e+00 -2.64336433e+01
 -1.32296649e+02 -1.04835479e+02  4.37287755e+01  6.58040937e+00
 -5.39463880e+00 -1.27491761e+02 -2.12446037e+01 -6.64721944e+01
 -5.62159674e+00  5.88990692e+00  5.63273156e+01  4.93857323e+01
  5.13906754e+00 -8.01360814e+00  2.24503626e+01  1.43446596e+00
 -3.26032889e+00 -5.70294386e+00  2.22518110e+00 -5.94698472e+00
  5.06228206e+00 -4.13766302e+00  4.99924568e+00 -5.18948494e+00
  3.11292607e+01]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1045.7787679873109
gradient value of function right now is: [ 1.19197456e-01  9.84872262e-01  2.04972735e-02  3.86457672e-01
 -1.19197456e-01 -9.84872262e-01 -2.04972735e-02 -3.86457672e-01
  9.21216609e-07  2.44705620e-02  4.69595093e-03  1.13800684e-06
 -1.26113562e-03 -5.49456315e-01 -4.92274536e-01 -1.54318736e-03
  1.91088519e-13  5.53962362e-05  3.85752095e-05  2.35258342e-13
 -1.51549245e-04 -1.23844762e-01 -1.54090977e-02 -1.86758089e-04
  3.28617635e-02  3.80357995e-02  1.59876383e-02  2.28507974e-02
  1.76761458e-01  1.85611699e-01  1.04505459e-01  1.70650799e-01
  6.75558637e-01  5.88381140e-01  3.11942548e-01  3.59126715e-01
  4.15656557e-02  4.81539734e-02  2.01809149e-02  2.88899241e-02
 -2.09496328e-02 -6.61601627e-03 -3.17346391e-02 -1.00757187e-02
 -3.04272734e-02 -4.99015393e-03 -1.61237874e-02 -5.57992223e-03
  7.62713088e-02  1.46370846e-02  3.20779591e-02  1.17017826e-02
  8.26025781e-02  2.26208217e-02  4.51836509e-02  1.65800349e-02
 -4.87965667e-01  2.68849443e+00 -2.21877243e-01  1.23203116e+00
 -3.92883523e-01  1.60464925e+00 -1.96472096e-01  8.20822022e-01
  7.71540822e+00]
supnorm grad right now is: 7.715408216758103
Weights right now are: 
[-2.18979646e+00  2.54232531e+00 -1.31854150e+00  1.46132992e+00
  2.44436517e+00 -2.65101700e+00  1.71747877e+00 -2.17735830e+00
  1.04826914e+02  2.05036457e+01  4.17059202e+01  1.12420009e+02
  3.53148837e+01  1.75678245e+00  1.43758488e+00  3.64832593e+01
  2.98607553e+00  2.83775479e+02  2.90509578e+01 -9.60865172e-01
  6.69461912e+01  9.98058692e-01  4.38468128e+01  6.92800949e+01
  2.76387809e+01  2.55807498e+00 -5.31598182e+00 -2.52901826e+01
  5.68658564e+00  1.34651909e-01 -1.63099633e+00 -5.97794882e+00
  1.14622345e+01  1.02523669e+01 -1.86690570e+01 -1.65905466e+01
  2.75349689e+01  2.62887370e+00 -4.85656346e+00 -2.60674407e+01
 -1.33742734e+02 -1.06533272e+02  4.40124513e+01  6.22020755e+00
 -4.81206391e+00 -1.28754403e+02 -2.09138151e+01 -6.73789335e+01
 -5.71934085e+00  5.82729900e+00  5.67674854e+01  5.01096606e+01
  4.70976177e+00 -6.97353026e+00  2.36556392e+01  2.76881993e+00
 -3.16893633e+00 -5.60729947e+00  1.73857612e+00 -6.07076132e+00
  5.09888598e+00 -4.06120467e+00  4.52075960e+00 -5.31730696e+00
  3.11051602e+01]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1046.1445652709488
gradient value of function right now is: [ 3.43052772e-01  4.58039108e-01  1.05098626e-01  3.57975671e-01
 -3.43052772e-01 -4.58039108e-01 -1.05098626e-01 -3.57975671e-01
 -2.25180579e-07  9.07406122e-03  1.06633197e-03 -2.84983544e-07
 -1.80023587e-05 -1.24807637e-02 -8.43991996e-02 -2.37411406e-05
  1.29540264e-12  9.61479594e-04  5.18399551e-05  1.54207902e-12
 -1.52368497e-07  3.07196965e-03  2.51387388e-04 -1.68675003e-07
  3.01553554e-04  7.85808256e-04 -1.38161149e-04  1.78831656e-04
 -4.34578464e-01 -4.38208358e-01 -4.35574278e-02 -6.54082836e-02
  5.68904833e-02  3.62269547e-02  4.34050485e-02  1.78006473e-02
  4.20301578e-04  1.03842067e-03 -1.58071587e-04  2.51497287e-04
  8.65643770e-04  3.50422557e-04  3.54239703e-04  2.69853411e-04
 -1.27969200e-02  2.74779661e-05  4.09497409e-04  2.14913355e-04
  2.14254228e-02 -2.25088199e-03 -1.84930316e-03 -1.28110746e-03
 -1.13224484e-03 -1.36801395e-02 -1.20169415e-02 -8.86775789e-03
 -1.11731790e-02 -1.06866172e-01 -2.62110186e-02 -4.72075680e-03
  6.22961460e-02 -1.99966737e-01  2.11081579e-02 -5.59561905e-02
 -1.25736383e+00]
supnorm grad right now is: 1.2573638261161493
Weights right now are: 
[-2.18234220e+00  2.58396915e+00 -4.94650592e-01  1.28663861e+00
  2.43691092e+00 -2.69266084e+00  8.93587861e-01 -2.00266699e+00
  1.05114347e+02  1.97723846e+01  4.26890561e+01  1.12787052e+02
  3.54622803e+01  1.69071397e+00  1.32551406e+00  3.66250106e+01
  2.98607938e+00  2.89286127e+02  3.14020128e+01 -9.60861061e-01
  7.16656597e+01  8.46396729e-01  4.37457517e+01  7.44593394e+01
  2.77316103e+01  2.26503320e+00 -5.56816174e+00 -2.55951317e+01
  5.73138719e+00  2.70730913e-01 -1.24851704e+00 -5.46017511e+00
  1.16861154e+01  1.03875781e+01 -1.85325989e+01 -1.65100570e+01
  2.76103808e+01  2.30931100e+00 -5.10572329e+00 -2.63806130e+01
 -1.34957153e+02 -1.07813075e+02  4.50294618e+01  6.28573292e+00
 -5.89799722e+00 -1.30202282e+02 -1.98767434e+01 -6.79061903e+01
 -5.49445817e+00  5.45094179e+00  5.72162825e+01  5.10304373e+01
  4.32111637e+00 -6.91591345e+00  2.30280420e+01  1.87985585e+00
 -3.72772945e+00 -5.67213916e+00  1.93155581e+00 -6.12566725e+00
  5.26116791e+00 -4.60336526e+00  4.96304538e+00 -5.62416390e+00
  3.11351891e+01]
(65,)
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1046.141784572141
gradient value of function right now is: [ 3.56690445e-01  4.76058094e-01  1.12746406e-01  3.74855350e-01
 -3.56690445e-01 -4.76058094e-01 -1.12746406e-01 -3.74855350e-01
 -2.13783978e-07  9.04988618e-03  5.79927605e-04 -2.73216975e-07
 -5.04448591e-05 -2.16501949e-02 -8.29053336e-02 -6.46580141e-05
  1.44732247e-12  9.91098910e-04  5.04681832e-05  1.75368601e-12
 -8.97663278e-07  1.46176845e-03  4.91128328e-04 -1.11108979e-06
  1.08474663e-03  1.62773613e-03  2.55107729e-04  7.10917133e-04
 -4.39125354e-01 -4.41295023e-01 -4.02162268e-02 -6.45130063e-02
  6.32479734e-02  4.47869062e-02  4.57968401e-02  2.22418963e-02
  1.43930001e-03  2.13760739e-03  3.51427529e-04  9.43780412e-04
  4.51525542e-04  1.31481913e-04 -2.89661787e-04 -1.12151729e-05
 -1.20099519e-02 -7.31825122e-05  1.24529779e-04  9.03773852e-05
  2.01085438e-02 -1.89115435e-03 -1.22928314e-03 -9.89619606e-04
 -7.24997868e-03 -1.48882816e-02 -1.16814632e-02 -9.01745631e-03
 -6.73722136e-03 -6.11316223e-02 -3.09558567e-02  2.85814660e-02
  6.38605682e-02 -1.73510633e-01  1.94984429e-02 -3.60821996e-02
 -1.24277343e+00]
supnorm grad right now is: 1.2427734290517118
Weights right now are: 
[  -2.29716731    2.56323012   -1.38887321    1.34390912    2.55173602
   -2.67192181    1.78781048   -2.0599375   105.49090427   20.34983956
   42.09944511  113.27329954   35.43488216    1.35726651    1.72567968
   36.56938382    2.98608406  293.64572415   30.49644288   -0.96085597
   76.35417461    0.30896712   45.14357395   79.61823263   28.12019636
    2.56881397   -6.08352015  -25.78217712    5.69985852    0.35212986
   -1.44005128   -5.53154449   11.34191738   10.15834184  -19.17158642
  -16.643892     28.00373586    2.62108549   -5.60727488  -26.55507157
 -136.44097758 -109.79524802   44.37584448    5.30345387   -5.79922477
 -131.43249422  -19.71138589  -68.78442877   -4.90501474    5.65527846
   58.54510836   52.64529623    4.35234733   -7.02622755   23.9570161
    2.17101082   -3.66705051   -5.68092911    1.85449266   -5.98032237
    5.43066205   -4.62774044    4.99298321   -5.31307781   31.11798374]
(65,)
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1046.1403216467895
gradient value of function right now is: [ 3.54655062e-01  4.56298805e-01  1.18032277e-01  3.70839645e-01
 -3.54655062e-01 -4.56298805e-01 -1.18032277e-01 -3.70839645e-01
 -1.86088282e-07  8.07892054e-03  7.63760761e-05 -2.36487772e-07
 -3.45157310e-05 -2.27306078e-02 -8.00801943e-02 -4.58479391e-05
  1.24613601e-12  9.98596157e-04  6.32648410e-05  1.49976584e-12
 -1.91855696e-06  1.08022062e-03  9.43310013e-04 -2.38633774e-06
  8.02959026e-04  1.47994055e-03 -7.09474296e-05  4.50139183e-04
 -4.27337584e-01 -4.28907154e-01 -3.53387839e-02 -5.83105217e-02
  5.32202982e-02  3.84778459e-02  3.82974608e-02  2.05335037e-02
  1.10545672e-03  1.96745369e-03 -4.26409612e-05  6.31317905e-04
  2.56146920e-04  1.12826242e-05 -6.84736793e-04 -1.80409934e-04
 -9.71614610e-03 -3.56150568e-05 -4.15747505e-05  2.43327802e-05
  1.25990067e-02 -2.14399543e-03 -8.88479822e-04 -8.16998398e-04
 -1.20193780e-02 -1.37656466e-02 -1.10089305e-02 -8.25342471e-03
 -3.17740439e-03 -4.07062374e-02 -2.34617737e-02  3.70566324e-02
  6.63980562e-02 -1.56625116e-01  2.11050249e-02 -2.42954634e-02
 -1.23889077e+00]
supnorm grad right now is: 1.2388907707645618
Weights right now are: 
[  -2.25661189    2.78628191   -1.14302335    1.50352695    2.5111806
   -2.8949736     1.54196062   -2.21955533  105.81764107   21.27818307
   43.72324663  113.68184183   35.09223788    1.80585964    1.14067371
   36.19109625    2.98609117  297.82250663   28.91244469   -0.96084856
   82.3172433     0.31988039   43.65454838   86.16214485   28.64268341
    2.90825269   -6.1391146   -25.67120199    5.90082188    0.44862385
   -1.37298748   -5.94117112   11.47954372   10.186423    -19.24815699
  -16.53724508   28.5253293     2.95448834   -5.64448732  -26.43572996
 -138.3017618  -110.97816433   45.4741596     5.88402378   -6.45405607
 -133.0261549   -19.06180575  -69.37887769   -5.27810921    4.01360529
   58.88436512   52.97115823    4.92607557   -6.26070392   24.14766442
    2.3509199    -3.5016289    -5.6153055     1.91893934   -6.22380192
    5.31630291   -4.21266883    5.25411298   -5.44451282   31.04974298]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1046.144226804672
gradient value of function right now is: [ 3.47468396e-01  4.64572616e-01  1.17684355e-01  3.60773537e-01
 -3.47468396e-01 -4.64572616e-01 -1.17684355e-01 -3.60773537e-01
 -1.72927136e-07  7.43667187e-03  8.60636074e-04 -2.20030236e-07
 -3.56633561e-05 -2.03049303e-02 -8.69135132e-02 -4.74280301e-05
  1.12261510e-12  9.82858065e-04  1.11433357e-04  1.33712001e-12
 -1.85279004e-06  1.46009734e-03  3.09933871e-04 -2.30717485e-06
  7.56482161e-04  1.51598138e-03 -9.90363379e-05  4.51020595e-04
 -4.15519894e-01 -4.17964890e-01 -4.10851364e-02 -5.45449996e-02
  5.26230001e-02  3.69451189e-02  3.83055820e-02  1.98631193e-02
  1.04938490e-03  2.01395649e-03 -7.56700789e-05  6.34353803e-04
  3.35078382e-04  3.81218344e-05 -6.59956351e-04 -1.47718165e-04
 -9.23788624e-03 -1.26065287e-05  1.67779951e-05  4.71267533e-05
  1.02226103e-02 -2.63130950e-03 -1.02221114e-03 -8.49016881e-04
 -1.24301107e-02 -1.30734478e-02 -1.07143272e-02 -7.55976221e-03
  5.17192939e-04 -5.20363088e-02 -2.18292823e-02  3.09337502e-02
  6.69175136e-02 -1.61501353e-01  2.18042848e-02 -2.53972379e-02
 -1.23888453e+00]
supnorm grad right now is: 1.2388845286180508
Weights right now are: 
[-2.06019670e+00  2.57128579e+00 -7.08189194e-01  1.57619504e+00
  2.31476542e+00 -2.67997748e+00  1.10712646e+00 -2.29222342e+00
  1.05871461e+02  2.14331611e+01  4.30382220e+01  1.13758660e+02
  3.51083465e+01  1.52534852e+00  1.79363293e+00  3.61965954e+01
  2.98609507e+00  3.03038680e+02  2.71709858e+01 -9.60844325e-01
  8.85536066e+01  9.44933517e-01  4.57414445e+01  9.30558203e+01
  2.86046606e+01  2.50152025e+00 -6.23841402e+00 -2.58848828e+01
  5.70803055e+00  1.36743022e-01 -1.82390507e+00 -5.44403567e+00
  1.15347307e+01  1.02949336e+01 -1.92156300e+01 -1.65933803e+01
  2.84543904e+01  2.52458060e+00 -5.76882619e+00 -2.66719345e+01
 -1.40218821e+02 -1.12386465e+02  4.68698821e+01  6.07484068e+00
 -5.16911429e+00 -1.35079344e+02 -1.77704771e+01 -6.99485348e+01
 -5.82065486e+00  4.50287159e+00  5.88513679e+01  5.32418927e+01
  4.93604691e+00 -5.51037661e+00  2.38139193e+01  1.67425610e+00
 -3.35468246e+00 -5.52843797e+00  1.63412012e+00 -6.12164059e+00
  5.26102202e+00 -4.37342823e+00  5.08902095e+00 -5.81936984e+00
  3.10921391e+01]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1046.1430591977723
gradient value of function right now is: [ 3.56450244e-01  4.60803132e-01  1.19887848e-01  3.69495478e-01
 -3.56450244e-01 -4.60803132e-01 -1.19887848e-01 -3.69495478e-01
 -1.73200179e-07  7.46004795e-03  9.65078971e-04 -2.22829304e-07
 -5.77295227e-05 -1.42171003e-02 -7.35377533e-02 -7.47996457e-05
  1.13628147e-12  9.98067773e-04  1.31938738e-04  1.36326136e-12
 -1.26837020e-06  1.84833352e-03  4.09812226e-04 -1.59057755e-06
  1.18448177e-03  1.90515718e-03  2.34467207e-04  7.98628614e-04
 -4.32348536e-01 -4.33647251e-01 -5.07915468e-02 -5.90703404e-02
  3.49682490e-02  2.28248661e-02  2.89087852e-02  1.18128787e-02
  1.59251108e-03  2.51762274e-03  3.40304135e-04  1.07423388e-03
  5.16201352e-04  1.00022664e-04 -5.14896217e-04 -7.93899377e-05
 -7.62025777e-03  8.97495179e-05  1.87973561e-04  1.16173979e-04
  3.97563507e-03 -3.34654299e-03 -1.47389680e-03 -1.04764596e-03
 -1.87542758e-02 -1.37081203e-02 -1.12094894e-02 -7.54589226e-03
  1.11573717e-02 -8.08548783e-02 -1.78051923e-02  1.38303183e-02
  7.47207352e-02 -1.89182031e-01  2.51401625e-02 -3.63646681e-02
 -1.33706457e+00]
supnorm grad right now is: 1.3370645682398918
Weights right now are: 
[-2.19142227e+00  2.74610144e+00 -1.27498010e+00  1.38960643e+00
  2.44599098e+00 -2.85479313e+00  1.67391737e+00 -2.10563481e+00
  1.06053441e+02  2.22121523e+01  4.27967203e+01  1.14007129e+02
  3.59517785e+01  1.81514166e+00  1.44506481e+00  3.70382919e+01
  2.98610251e+00  3.05773402e+02  2.56469002e+01 -9.60836123e-01
  8.81367901e+01  9.84239306e-01  4.57336678e+01  9.30424862e+01
  2.85858421e+01  1.82423540e+00 -6.59979044e+00 -2.64080897e+01
  5.76153930e+00  2.56218422e-01 -1.73889085e+00 -6.11712141e+00
  1.14836379e+01  1.06559850e+01 -1.89998418e+01 -1.71856684e+01
  2.84264388e+01  1.84686159e+00 -6.14450944e+00 -2.72021090e+01
 -1.41558668e+02 -1.13592601e+02  4.81524791e+01  6.59920138e+00
 -6.55024948e+00 -1.36881428e+02 -1.74149642e+01 -7.11509803e+01
 -6.05240872e+00  4.35933420e+00  5.93809965e+01  5.36760923e+01
  5.17644045e+00 -6.35767375e+00  2.34399175e+01 -1.05542007e-01
 -3.53079486e+00 -5.55436736e+00  1.14321141e+00 -6.11086114e+00
  5.83611262e+00 -4.38756510e+00  5.46268696e+00 -5.69443975e+00
  3.11187446e+01]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1062.5619947441053
W_T_median: 1050.1033704884944
W_T_pctile_5: 967.9613968636185
W_T_CVAR_5_pct: 939.8910868484111
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.1
F value: -1046.1430591977723
-----------------------------------------------
