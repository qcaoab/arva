Starting at: 
26-01-23_17:31

 Random seed:  2  

Key parameters-------
paths: 256000
iterations: 50000
batchsize: 1000
remove neg:  False


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
3.3333333333333335% of MC simulations done.
6.666666666666667% of MC simulations done.
10.0% of MC simulations done.
13.333333333333334% of MC simulations done.
16.666666666666664% of MC simulations done.
20.0% of MC simulations done.
23.333333333333332% of MC simulations done.
26.666666666666668% of MC simulations done.
30.0% of MC simulations done.
33.33333333333333% of MC simulations done.
36.666666666666664% of MC simulations done.
40.0% of MC simulations done.
43.333333333333336% of MC simulations done.
46.666666666666664% of MC simulations done.
50.0% of MC simulations done.
53.333333333333336% of MC simulations done.
56.666666666666664% of MC simulations done.
60.0% of MC simulations done.
63.33333333333333% of MC simulations done.
66.66666666666666% of MC simulations done.
70.0% of MC simulations done.
73.33333333333333% of MC simulations done.
76.66666666666667% of MC simulations done.
80.0% of MC simulations done.
83.33333333333334% of MC simulations done.
86.66666666666667% of MC simulations done.
90.0% of MC simulations done.
93.33333333333333% of MC simulations done.
96.66666666666667% of MC simulations done.
100.0% of MC simulations done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      12  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      12  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer      12  logistic_sigmoid   
4        obj.layers[4]        4  output_layer       1              none   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 12)     True          12  
2     (12, 12)     True          12  
3     (12, 12)     True          12  
4      (12, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      12  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      12  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer      12  logistic_sigmoid   
4        obj.layers[4]        4  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 12)     True          12  
2     (12, 12)     True          12  
3     (12, 12)     True          12  
4      (12, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       12  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       12  logistic_sigmoid   
0        obj.layers[3]         3  hidden_layer       12  logistic_sigmoid   
0        obj.layers[4]         4  output_layer        1              none   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 12)      True          12  
0     (12, 12)      True          12  
0     (12, 12)      True          12  
0      (12, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       12  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       12  logistic_sigmoid   
0        obj.layers[3]         3  hidden_layer       12  logistic_sigmoid   
0        obj.layers[4]         4  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 12)      True          12  
0     (12, 12)      True          12  
0     (12, 12)      True          12  
0      (12, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
{'methods': ['Adam'], 'output_progress': False, 'tol': 1e-06, 'itbound_scipy_algorithms': 1000, 'check_exit_criteria': False, 'nit_running_min': 5000, 'itbound_SGD_algorithms': 50000, 'nit_IterateAveragingStart': 45000, 'batchsize': 1000, 'SGD_learningrate': 50.0, 'Adagrad_epsilon': 1e-08, 'Adagrad_eta': 1.0, 'Adadelta_ewma': 0.9, 'Adadelta_epsilon': 1e-08, 'RMSprop_ewma': 0.8, 'RMSprop_epsilon': 1e-08, 'RMSprop_eta': 0.1, 'Adam_ewma_1': 0.9, 'Adam_ewma_2': 0.998, 'Adam_eta': 0.05, 'Adam_epsilon': 1e-08, 'Adam_weight_decay': 0.0001, 'running_min_from_avg': False, 'running_min_from_sgd': True, 'lr_schedule': True}
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1576.8182150775267
W_T_median: 1136.7449346433505
W_T_pctile_5: -127.64084552288806
W_T_CVAR_5_pct: -295.72244238283764
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1662.590220149605
Current xi:  [-46.66635]
objective value function right now is: -1662.590220149605
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1674.9648839370702
Current xi:  [-92.60655]
objective value function right now is: -1674.9648839370702
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1685.7987530868784
Current xi:  [-138.29202]
objective value function right now is: -1685.7987530868784
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -1694.2987271328577
Current xi:  [-183.25623]
objective value function right now is: -1694.2987271328577
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1703.1267427015064
Current xi:  [-228.04582]
objective value function right now is: -1703.1267427015064
12.0% of gradient descent iterations done. Method = Adam
new min fval:  -1710.2523346400533
Current xi:  [-271.7691]
objective value function right now is: -1710.2523346400533
14.000000000000002% of gradient descent iterations done. Method = Adam
new min fval:  -1716.4802367241796
Current xi:  [-314.62082]
objective value function right now is: -1716.4802367241796
16.0% of gradient descent iterations done. Method = Adam
new min fval:  -1721.354155146133
Current xi:  [-356.5262]
objective value function right now is: -1721.354155146133
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -1725.27560420413
Current xi:  [-397.20154]
objective value function right now is: -1725.27560420413
20.0% of gradient descent iterations done. Method = Adam
new min fval:  -1729.1581697787915
Current xi:  [-436.78387]
objective value function right now is: -1729.1581697787915
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -1731.645087660624
Current xi:  [-474.1904]
objective value function right now is: -1731.645087660624
24.0% of gradient descent iterations done. Method = Adam
new min fval:  -1733.1817288971865
Current xi:  [-510.19412]
objective value function right now is: -1733.1817288971865
26.0% of gradient descent iterations done. Method = Adam
new min fval:  -1734.0360942272216
Current xi:  [-543.6696]
objective value function right now is: -1734.0360942272216
28.000000000000004% of gradient descent iterations done. Method = Adam
new min fval:  -1735.402315639489
Current xi:  [-574.5897]
objective value function right now is: -1735.402315639489
30.0% of gradient descent iterations done. Method = Adam
new min fval:  -1735.851575802506
Current xi:  [-601.10583]
objective value function right now is: -1735.851575802506
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [-621.79987]
objective value function right now is: -1735.605695284739
34.0% of gradient descent iterations done. Method = Adam
new min fval:  -1736.0367998826257
Current xi:  [-635.9171]
objective value function right now is: -1736.0367998826257
36.0% of gradient descent iterations done. Method = Adam
new min fval:  -1736.222826763603
Current xi:  [-644.35767]
objective value function right now is: -1736.222826763603
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [-647.92847]
objective value function right now is: -1735.7918444696627
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [-646.51434]
objective value function right now is: -1735.3430225023405
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [-645.8493]
objective value function right now is: -1736.0505062295404
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [-645.8308]
objective value function right now is: -1735.7577416351498
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [-646.2661]
objective value function right now is: -1735.4340195864281
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [-644.7609]
objective value function right now is: -1734.978194456047
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [-646.3017]
objective value function right now is: -1736.1149775855174
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [-645.608]
objective value function right now is: -1735.986792113603
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [-646.728]
objective value function right now is: -1736.0319254841102
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [-644.99817]
objective value function right now is: -1736.046126735868
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [-646.053]
objective value function right now is: -1735.950243008808
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [-646.87244]
objective value function right now is: -1735.9113410325474
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [-647.1636]
objective value function right now is: -1736.1359453872872
64.0% of gradient descent iterations done. Method = Adam
new min fval:  -1736.2667494764337
Current xi:  [-647.24756]
objective value function right now is: -1736.2667494764337
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [-647.3019]
objective value function right now is: -1735.886668095808
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [-647.22656]
objective value function right now is: -1735.6114537360183
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [-646.0808]
objective value function right now is: -1735.9593152658506
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -1736.3060833297084
Current xi:  [-645.6117]
objective value function right now is: -1736.3060833297084
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -1736.3249924591046
Current xi:  [-645.88385]
objective value function right now is: -1736.3249924591046
76.0% of gradient descent iterations done. Method = Adam
new min fval:  -1736.3381785339175
Current xi:  [-645.2172]
objective value function right now is: -1736.3381785339175
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [-644.61926]
objective value function right now is: -1736.2479515783896
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [-644.78705]
objective value function right now is: -1736.2831681262455
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [-645.1119]
objective value function right now is: -1736.2969303845261
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [-645.60956]
objective value function right now is: -1736.232515077052
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [-645.8431]
objective value function right now is: -1736.1713283106988
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [-645.5798]
objective value function right now is: -1736.301381243127
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [-645.2165]
objective value function right now is: -1736.3356667491166
new min fval from sgd:  -1736.3388861272497
new min fval from sgd:  -1736.3416454628534
new min fval from sgd:  -1736.3445175740426
new min fval from sgd:  -1736.3461088283868
new min fval from sgd:  -1736.346124114563
new min fval from sgd:  -1736.3486266839775
new min fval from sgd:  -1736.3491389299022
new min fval from sgd:  -1736.3502920276394
new min fval from sgd:  -1736.3526861630571
new min fval from sgd:  -1736.3540223451778
new min fval from sgd:  -1736.3554742861427
new min fval from sgd:  -1736.3556923759584
new min fval from sgd:  -1736.3562446810158
new min fval from sgd:  -1736.3584851216867
new min fval from sgd:  -1736.3596520134504
new min fval from sgd:  -1736.360290523226
new min fval from sgd:  -1736.3622949651017
new min fval from sgd:  -1736.3654324070023
new min fval from sgd:  -1736.3668217475436
new min fval from sgd:  -1736.3683430294036
new min fval from sgd:  -1736.3733463876974
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [-645.1473]
objective value function right now is: -1736.083946740214
new min fval from sgd:  -1736.3737050825632
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [-645.34235]
objective value function right now is: -1736.312944710698
new min fval from sgd:  -1736.3739102355814
new min fval from sgd:  -1736.3751105470076
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [-645.61285]
objective value function right now is: -1736.3474945759865
new min fval from sgd:  -1736.3755960576814
new min fval from sgd:  -1736.3758923676946
new min fval from sgd:  -1736.3761409857445
new min fval from sgd:  -1736.3763586538369
new min fval from sgd:  -1736.3767511450808
new min fval from sgd:  -1736.3789680262016
new min fval from sgd:  -1736.3808749736204
new min fval from sgd:  -1736.3827976671419
new min fval from sgd:  -1736.384512422835
new min fval from sgd:  -1736.3864865093879
new min fval from sgd:  -1736.3868192825141
new min fval from sgd:  -1736.3871477383955
new min fval from sgd:  -1736.3876928901498
new min fval from sgd:  -1736.3881591182737
new min fval from sgd:  -1736.3889440549654
new min fval from sgd:  -1736.3905920263494
new min fval from sgd:  -1736.3921407636622
new min fval from sgd:  -1736.3924515471037
new min fval from sgd:  -1736.3925521610709
new min fval from sgd:  -1736.3926345990672
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [-645.48785]
objective value function right now is: -1736.378192888893
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [-645.4571]
objective value function right now is: -1736.375956522251
min fval:  -1736.3926345990672
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ 6.3405e-16,  7.4985e-18],
        [ 2.5811e-16,  7.1115e-14],
        [ 4.8325e-17, -3.7452e-16],
        [-7.1922e-15, -1.0104e-13],
        [-6.9179e-15, -8.2972e-17],
        [-9.6966e-14, -9.0024e-13],
        [ 6.7706e-14, -1.4983e-14],
        [-1.6947e-14, -4.4922e-17],
        [-2.4716e-12,  7.9181e-13],
        [-3.2769e-13, -1.6821e-17],
        [-1.5061e-19, -3.6815e-15],
        [ 2.2771e-13, -1.4950e-14]], device='cuda:0')), ('0.model.hidden_layer_1.bias', tensor([-3.6356e-14, -3.4829e-13,  5.0264e-17,  3.0539e-16, -2.9957e-13,
         1.3896e-16,  9.6327e-14, -2.3498e-12, -4.0368e-17,  1.2032e-14,
        -3.6929e-16, -6.2468e-15], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-3.2598e-15,  3.0418e-17, -1.9316e-13, -5.4708e-13, -3.9380e-17,
         -7.7512e-17, -3.4264e-17, -1.4120e-14, -5.2406e-15, -2.4233e-13,
          4.8355e-14, -4.1797e-17],
        [ 4.9159e-14, -5.8025e-13, -7.8461e-13,  7.0069e-18, -5.4141e-14,
          6.4434e-15, -4.3817e-17, -2.1090e-14, -2.2754e-14,  3.9958e-17,
         -1.5468e-16, -4.2864e-16],
        [ 1.2312e-15, -1.5630e-17, -8.9554e-17,  2.9540e-16, -1.1910e-15,
         -2.0172e-14, -2.2101e-14, -9.8173e-17, -1.1254e-15,  2.2898e-14,
          1.7835e-14, -4.8249e-15],
        [ 2.7079e-15, -4.5191e-13, -2.0934e-12, -8.1598e-17, -3.4947e-14,
          1.5834e-15, -8.0938e-15, -6.7551e-17,  5.5584e-15, -1.5343e-14,
          1.0788e-15,  1.3520e-16],
        [-5.6008e-13, -1.0289e-13,  2.1354e-17, -1.8046e-13,  1.0546e-13,
         -3.7853e-15,  3.9031e-17,  5.5671e-17, -1.3441e-15,  9.6203e-19,
         -9.6347e-14,  2.7251e-15],
        [ 3.6660e-16,  7.9673e-14, -6.1933e-17, -1.3787e-15, -8.0368e-14,
         -9.5775e-15, -1.1414e-13,  2.1527e-13, -5.1859e-16, -3.4926e-12,
          1.1722e-16,  1.6218e-12],
        [-1.9886e-14, -1.9581e-15,  5.4512e-14, -1.6366e-14,  3.6521e-17,
         -6.4832e-15, -4.4588e-17, -2.5908e-13, -1.0903e-14, -4.3219e-16,
          1.2613e-13,  4.5854e-14],
        [ 6.7707e-18, -2.6383e-16, -5.3397e-13,  1.9983e-15,  2.5545e-17,
         -2.0248e-15, -1.7027e-15, -3.3410e-14,  1.3832e-15,  1.1059e-12,
          2.7107e-15, -1.1267e-12],
        [-2.4006e-16,  1.5613e-14, -6.2601e-16,  3.7319e-13, -1.2478e-17,
         -5.0360e-17,  8.2391e-15, -7.5244e-17, -1.3543e-18, -2.8858e-16,
          1.6414e-16, -1.8097e-16],
        [-2.0830e-18, -9.2674e-15,  5.1748e-16,  5.4384e-17, -9.4790e-17,
         -5.3019e-14, -6.5754e-16,  1.7127e-16, -8.7888e-16,  3.2424e-17,
         -5.0113e-14,  5.2304e-17],
        [ 3.6504e-17, -3.5765e-14, -2.6741e-17, -1.4515e-14, -8.1893e-16,
         -2.6363e-15,  9.3005e-15, -1.8463e-14, -1.0471e-13,  3.3294e-16,
         -3.7416e-14,  2.0778e-14],
        [-1.0930e-15, -8.4926e-16, -4.9990e-14, -7.0986e-15,  2.1673e-15,
          6.3724e-17,  2.9247e-14,  6.2828e-14, -7.2362e-14,  2.0118e-14,
          1.0269e-14,  8.0830e-13]], device='cuda:0')), ('0.model.hidden_layer_2.bias', tensor([ 1.4143e-14,  9.5812e-15,  6.0631e-14,  1.4900e-14,  5.7720e-13,
         8.6784e-18, -2.6657e-16,  1.0117e-16,  3.5530e-13, -3.8766e-15,
        -1.0833e-15, -5.0612e-14], device='cuda:0')), ('0.model.hidden_layer_3.weight', tensor([[ 1.9780e-16,  1.4687e-15,  4.5535e-15, -8.0455e-14, -3.6312e-16,
          1.3861e-15, -1.1043e-13,  6.0541e-15, -1.1229e-17, -4.8936e-15,
          1.1719e-16,  3.3506e-14],
        [ 9.6300e-14, -2.2325e-12, -9.6283e-14, -8.7370e-17,  1.5330e-16,
          6.0243e-15, -2.9292e-16,  3.0870e-13,  1.9186e-17,  1.2175e-12,
         -2.8557e-14,  4.4812e-13],
        [-2.8088e-19, -3.1478e-18,  1.9223e-16,  2.3155e-16,  2.6730e-15,
          2.9244e-16,  5.6846e-17, -2.3058e-15,  4.6381e-13, -2.8999e-17,
          4.0670e-16,  1.4437e-16],
        [ 1.2220e-14,  1.2124e-15, -9.4207e-14,  4.9789e-15,  4.2626e-12,
          2.4846e-13, -2.9051e-14, -1.5349e-17, -3.9067e-13, -6.6120e-13,
          3.0156e-15,  9.6936e-13],
        [ 1.2466e-16, -2.1059e-15, -1.2001e-16, -2.3675e-13,  2.4686e-16,
          6.2628e-17,  4.7292e-16, -1.9446e-14,  1.0976e-14, -8.6192e-15,
          7.5909e-17, -7.0910e-14],
        [-1.9373e-12, -5.8820e-13, -1.7784e-17, -1.4088e-13,  2.1171e-16,
          1.0043e-16,  1.5933e-12,  6.4977e-17, -6.2875e-14, -4.0919e-16,
          1.3650e-14, -1.5300e-14],
        [-6.4808e-17, -1.3849e-15, -7.0732e-15, -1.8593e-14,  2.4059e-14,
          2.6308e-14, -1.5246e-17, -4.5372e-16, -9.3863e-17,  1.2109e-12,
         -1.6694e-15,  8.7660e-13],
        [ 6.6484e-16, -3.2936e-14,  2.7970e-12, -1.3655e-14,  8.8862e-15,
         -4.4858e-16,  7.1920e-15,  9.1493e-18, -2.1384e-15,  4.4618e-16,
          2.5533e-14, -7.4701e-17],
        [ 1.3663e-17,  1.7078e-17, -1.3749e-13,  5.0399e-17, -2.9760e-15,
         -4.3438e-15, -1.0254e-13,  1.5383e-14,  1.7052e-13,  3.3538e-17,
         -8.6118e-15, -4.8466e-14],
        [ 2.0177e-13,  9.5737e-17,  1.4194e-16,  1.5736e-16,  1.9061e-13,
         -1.5296e-14, -2.0773e-13, -1.0067e-14,  2.6658e-17, -4.8739e-16,
         -4.2888e-13, -4.9254e-13],
        [-1.1418e-13,  3.8464e-14, -8.3385e-13, -1.0925e-17,  1.8239e-16,
          1.8514e-13,  1.3688e-13,  3.3898e-16,  1.1085e-16,  5.1019e-16,
          4.7601e-18, -2.2850e-13],
        [ 1.2515e-13,  3.5748e-13, -4.9260e-15, -8.3306e-17, -3.0031e-16,
          1.9672e-13,  1.7976e-14, -3.3654e-16, -5.0495e-16, -6.0073e-16,
          5.7120e-13, -6.0966e-19]], device='cuda:0')), ('0.model.hidden_layer_3.bias', tensor([-7.6058e-13, -6.1285e-13, -5.1225e-14, -2.3430e-15,  5.1100e-15,
        -5.6070e-15, -9.0696e-17, -1.2133e-15, -6.9299e-17,  1.4130e-14,
         4.1125e-17, -1.7916e-14], device='cuda:0')), ('0.model.output_layer_4.weight', tensor([[ 7.7065e-13,  9.2770e-13,  5.4509e-13,  4.9928e-13,  5.5319e-13,
          8.8009e-13,  6.8458e-13,  8.1750e-13,  8.5923e-13,  1.8988e-12,
         -3.7770e-12,  6.1466e-13]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[  5.4011,  -8.0644],
        [ -9.0510,  -0.9627],
        [  9.4644,   3.4810],
        [ -2.5381,   5.2059],
        [ -1.9335,  -0.5468],
        [  4.4009,   6.8874],
        [ -0.3781,  10.7340],
        [ -1.2296,   0.9794],
        [ -1.2296,   0.9789],
        [-11.2055,   0.0953],
        [-11.4337,   0.1086],
        [  5.9949,  -5.6702]], device='cuda:0')), ('1.model.hidden_layer_1.bias', tensor([-7.9246,  4.0514,  0.8738, -1.4722, -4.1485,  6.7696,  9.6887, -2.0737,
        -2.0737,  9.2299,  9.8473, -5.9676], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-7.7818e-01, -2.7403e-01, -9.2464e-01, -7.8727e-02, -1.9973e-01,
         -7.1932e-01, -4.4707e-01, -7.9639e-03, -7.9695e-03, -3.3391e-01,
         -4.0216e-01, -8.5038e-01],
        [-7.7818e-01, -2.7403e-01, -9.2464e-01, -7.8727e-02, -1.9973e-01,
         -7.1932e-01, -4.4707e-01, -7.9639e-03, -7.9695e-03, -3.3391e-01,
         -4.0216e-01, -8.5038e-01],
        [-7.7818e-01, -2.7402e-01, -9.2465e-01, -7.8729e-02, -1.9974e-01,
         -7.1932e-01, -4.4707e-01, -7.9643e-03, -7.9699e-03, -3.3390e-01,
         -4.0215e-01, -8.5038e-01],
        [-6.3372e+00,  4.2654e-01,  8.3364e-01,  9.3220e-02,  7.6735e-02,
          5.6472e+00,  6.8348e+00,  1.6407e-01,  1.6401e-01, -3.7386e-02,
         -1.7785e+00, -4.6483e+00],
        [ 2.0350e+00, -4.5247e+00,  1.5242e+00,  9.6239e-01,  4.9008e-02,
         -3.0482e+00,  3.0041e+00,  1.9926e-01,  1.9909e-01, -8.1335e+00,
         -8.3762e+00,  1.6342e+00],
        [ 4.2467e-01,  3.4359e-01, -2.7090e+00,  5.6571e-02,  2.4600e+00,
         -1.4962e+00, -3.9821e-01, -3.7547e-02, -3.7619e-02, -2.2784e+00,
         -2.5994e+00,  3.9877e-01],
        [-3.9707e+00,  9.5207e-01,  3.4143e+00,  2.0878e-02,  2.2449e-01,
          4.7340e+00,  8.7406e+00,  7.3718e-02,  7.3616e-02, -4.9700e+00,
         -5.4914e+00, -2.2848e+00],
        [-3.7410e+00, -1.4464e+00,  7.3657e+00, -9.1958e-03,  4.7231e+00,
          6.6327e+00,  1.1601e+01,  5.9035e-02,  5.9020e-02, -6.0338e+00,
         -6.5587e+00, -1.8709e+00],
        [-7.7818e-01, -2.7403e-01, -9.2464e-01, -7.8727e-02, -1.9973e-01,
         -7.1932e-01, -4.4707e-01, -7.9639e-03, -7.9695e-03, -3.3391e-01,
         -4.0216e-01, -8.5038e-01],
        [-3.8417e-01, -4.1720e+00,  1.0257e+01, -2.2074e-02, -3.4021e+00,
          6.9914e+00,  3.3825e+00,  1.4124e-01,  1.4133e-01, -3.4145e+00,
         -2.2201e+00, -4.3964e-01],
        [-3.6899e+00,  4.9188e+00, -3.0708e+00,  1.3101e+00,  4.5862e+00,
         -9.2939e-01,  1.2101e+00, -1.4098e-01, -1.4034e-01,  3.1605e+00,
          2.8094e+00, -4.4316e+00],
        [-3.4411e+00,  3.1254e+00, -3.8235e+00,  3.8863e+00, -6.3139e-01,
         -3.7469e+00,  1.1307e+00,  2.2181e-01,  2.2069e-01,  3.6541e+00,
          4.6116e+00, -3.2319e+00]], device='cuda:0')), ('1.model.hidden_layer_2.bias', tensor([-1.2696, -1.2696, -1.2696, -2.3546,  0.1694, -0.2742,  1.4221,  2.3823,
        -1.2696,  4.8934,  0.9973, -0.3153], device='cuda:0')), ('1.model.hidden_layer_3.weight', tensor([[ -0.0542,  -0.0542,  -0.0542,  -0.2123,  -0.3223,  -0.9455,  -0.5383,
          -1.4770,  -0.0542,  -1.2992,  -0.8934,  -0.0203],
        [ -0.0542,  -0.0542,  -0.0542,  -0.2123,  -0.3223,  -0.9455,  -0.5383,
          -1.4770,  -0.0542,  -1.2992,  -0.8934,  -0.0203],
        [  0.2251,   0.2251,   0.2252,  -1.4829,  -4.5810,  -1.5604,  -3.2869,
         -11.3490,   0.2251,   4.4764,  -0.5130,   1.3892],
        [ -0.0542,  -0.0542,  -0.0542,  -0.2123,  -0.3223,  -0.9455,  -0.5383,
          -1.4770,  -0.0542,  -1.2992,  -0.8934,  -0.0203],
        [ -0.0542,  -0.0542,  -0.0542,  -0.2123,  -0.3223,  -0.9455,  -0.5383,
          -1.4770,  -0.0542,  -1.2992,  -0.8934,  -0.0203],
        [ -0.0312,  -0.0312,  -0.0312,   2.8570,   0.1020,  -4.9511,  -0.4663,
          -2.8538,  -0.0312,  -8.3159,   0.5283,   5.8771],
        [ -0.0542,  -0.0542,  -0.0542,  -0.2123,  -0.3223,  -0.9455,  -0.5383,
          -1.4770,  -0.0542,  -1.2992,  -0.8934,  -0.0203],
        [ -0.0542,  -0.0542,  -0.0542,  -0.2123,  -0.3223,  -0.9455,  -0.5383,
          -1.4770,  -0.0542,  -1.2992,  -0.8934,  -0.0203],
        [ -0.0502,  -0.0502,  -0.0502,  -3.8756,  -2.5558,  -2.3162,  -1.5615,
          -4.5370,  -0.0502,   4.6885,  -1.0129,  -0.1435],
        [ -0.0542,  -0.0542,  -0.0542,  -0.2123,  -0.3223,  -0.9455,  -0.5383,
          -1.4770,  -0.0542,  -1.2992,  -0.8934,  -0.0203],
        [ -0.0458,  -0.0458,  -0.0458,   3.1032,  -0.1768,  -0.9861,   1.8044,
           0.0255,  -0.0458,  -3.3417,   1.6092,   1.9356],
        [ -0.0542,  -0.0542,  -0.0542,  -0.2123,  -0.3223,  -0.9455,  -0.5383,
          -1.4770,  -0.0542,  -1.2992,  -0.8934,  -0.0203]], device='cuda:0')), ('1.model.hidden_layer_3.bias', tensor([-2.3277, -2.3277, -2.7770, -2.3277, -2.3277, -0.8744, -2.3277, -2.3277,
        -0.2995, -2.3277, -2.7384, -2.3277], device='cuda:0')), ('1.model.output_layer_4.weight', tensor([[ 0.0257,  0.0257, -5.8441,  0.0257,  0.0257,  7.0175,  0.0257,  0.0257,
         -0.9605,  0.0257,  0.5956,  0.0257],
        [-0.0256, -0.0256,  5.8492, -0.0256, -0.0256, -7.0178, -0.0256, -0.0256,
          1.1336, -0.0256, -0.5886, -0.0256]], device='cuda:0'))])
xi:  [-645.5134]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 243.79274503689578
W_T_median: 113.84505032457648
W_T_pctile_5: -645.1377132369248
W_T_CVAR_5_pct: -805.8487549877486
Average q (qsum/M+1):  57.31241730720766
Optimal xi:  [-645.5134]
Expected(across Rb) median(across samples) p_equity:  0.3073451514045397
obj fun:  tensor(-1736.3926, device='cuda:0', dtype=torch.float64,
       grad_fn=<MeanBackward0>)
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.05
-----------------------------------------------
