Starting at: 
08-01-23_00:05

 Random seed:  2  

Key parameters-------
paths: 256000
iterations: 50000
batchsize: 1000


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
3.3333333333333335% of MC simulations done.
6.666666666666667% of MC simulations done.
10.0% of MC simulations done.
13.333333333333334% of MC simulations done.
16.666666666666664% of MC simulations done.
20.0% of MC simulations done.
23.333333333333332% of MC simulations done.
26.666666666666668% of MC simulations done.
30.0% of MC simulations done.
33.33333333333333% of MC simulations done.
36.666666666666664% of MC simulations done.
40.0% of MC simulations done.
43.333333333333336% of MC simulations done.
46.666666666666664% of MC simulations done.
50.0% of MC simulations done.
53.333333333333336% of MC simulations done.
56.666666666666664% of MC simulations done.
60.0% of MC simulations done.
63.33333333333333% of MC simulations done.
66.66666666666666% of MC simulations done.
70.0% of MC simulations done.
73.33333333333333% of MC simulations done.
76.66666666666667% of MC simulations done.
80.0% of MC simulations done.
83.33333333333334% of MC simulations done.
86.66666666666667% of MC simulations done.
90.0% of MC simulations done.
93.33333333333333% of MC simulations done.
96.66666666666667% of MC simulations done.
100.0% of MC simulations done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      14  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      14  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1  logistic_sigmoid   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 14)    False        None  
2     (14, 14)    False        None  
3      (14, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      14  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      14  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 14)    False        None  
2     (14, 14)    False        None  
3      (14, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       14  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       14  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1  logistic_sigmoid   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 14)     False        None  
0     (14, 14)     False        None  
0      (14, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       14  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       14  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 14)     False        None  
0     (14, 14)     False        None  
0      (14, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       14  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       14  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1  logistic_sigmoid   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 14)     False        None  
0     (14, 14)     False        None  
0      (14, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       14  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       14  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 14)     False        None  
0     (14, 14)     False        None  
0      (14, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1576.8182150775267
W_T_median: 1136.7449346433505
W_T_pctile_5: -127.64084552288806
W_T_CVAR_5_pct: -295.72244238283764
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1763.948826757654
Current xi:  [-424.13428]
objective value function right now is: -1763.948826757654
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1794.008498599602
Current xi:  [-715.57886]
objective value function right now is: -1794.008498599602
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1801.82490645118
Current xi:  [-859.79816]
objective value function right now is: -1801.82490645118
8.0% of gradient descent iterations done. Method = Adam
Current xi:  [-914.4608]
objective value function right now is: -1801.7465876538693
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1802.5784920448814
Current xi:  [-931.5023]
objective value function right now is: -1802.5784920448814
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [-935.40753]
objective value function right now is: -1802.233092777765
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [-949.1478]
objective value function right now is: -1802.3150159921388
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [-943.8237]
objective value function right now is: -1802.276525322477
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [-935.3301]
objective value function right now is: -1802.3655457248842
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [-931.24]
objective value function right now is: -1802.073934014897
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [-934.2319]
objective value function right now is: -1800.6844950154675
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [-950.9322]
objective value function right now is: -1801.3656161678161
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [-957.7826]
objective value function right now is: -1800.3079514212386
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [-949.2129]
objective value function right now is: -1800.591809625305
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [-956.91254]
objective value function right now is: -1801.2454066800333
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [-934.156]
objective value function right now is: -1802.0957185946734
34.0% of gradient descent iterations done. Method = Adam
new min fval:  -1802.678882599887
Current xi:  [-928.9328]
objective value function right now is: -1802.678882599887
36.0% of gradient descent iterations done. Method = Adam
new min fval:  -1802.776208190463
Current xi:  [-926.7391]
objective value function right now is: -1802.776208190463
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [-928.29565]
objective value function right now is: -1802.1702718125252
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [-923.30273]
objective value function right now is: -1802.65620077091
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [-931.07886]
objective value function right now is: -1802.4558064972018
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [-932.194]
objective value function right now is: -1802.4899013836318
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [-928.47046]
objective value function right now is: -1802.7058922321503
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [-922.36597]
objective value function right now is: -1802.1826249581009
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [-938.7802]
objective value function right now is: -1802.3398741712842
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [-933.4354]
objective value function right now is: -1802.6971644612674
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [-929.129]
objective value function right now is: -1802.3608169303457
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [-925.9692]
objective value function right now is: -1802.6477479831765
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [-927.2216]
objective value function right now is: -1802.6439346710567
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [-962.81793]
objective value function right now is: -1800.9765566617587
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [-938.85364]
objective value function right now is: -1801.2065241729308
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [-935.88995]
objective value function right now is: -1802.410907697348
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [-940.5594]
objective value function right now is: -1802.2858947406569
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [-944.3247]
objective value function right now is: -1800.8579996478306
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [-975.2677]
objective value function right now is: -1799.4330766241337
72.0% of gradient descent iterations done. Method = Adam
Current xi:  [-926.41223]
objective value function right now is: -1802.5556280300348
74.0% of gradient descent iterations done. Method = Adam
Current xi:  [-979.19196]
objective value function right now is: -1800.6827402718138
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [-917.7341]
objective value function right now is: -1802.4537638687625
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [-971.5881]
objective value function right now is: -1800.9870748525314
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [-994.2597]
objective value function right now is: -1792.3470862762779
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [-985.73737]
objective value function right now is: -1800.812173794542
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [-974.1728]
objective value function right now is: -1800.9799926626656
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [-966.7789]
objective value function right now is: -1800.65101036902
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [-1071.7584]
objective value function right now is: -1797.5784751415838
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [-969.2997]
objective value function right now is: -1798.5301955602783
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [-957.9317]
objective value function right now is: -1800.9599497175684
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [-959.903]
objective value function right now is: -1801.1756717766316
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [-960.0005]
objective value function right now is: -1800.5133069581698
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [-964.2255]
objective value function right now is: -1801.192153351719
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [-950.84937]
objective value function right now is: -1800.4074999880743
min fval:  -1802.4764415228842
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -4.6284,   0.9104],
        [ -3.8108,   1.3983],
        [ -2.8664,   1.6176],
        [-14.9773,  -4.8729],
        [  8.6271,   5.3905],
        [ 14.1219,   6.7559],
        [ -4.1841,   1.3102],
        [ -4.0286,   1.3491],
        [ -1.7368,  -2.7294],
        [-11.1645,  -0.7334],
        [ -1.8992,   1.8708],
        [ -3.6828,   1.4236],
        [  3.2434,  -1.4432],
        [ -2.2491,   1.7748]], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-2.5824e+01, -1.8944e+01, -1.9675e+01, -1.5298e+01, -1.2620e+01,
          1.0213e+00, -1.9754e+01, -1.8954e+01, -5.7381e+00, -1.4270e+01,
         -1.9787e+01, -1.9648e+01, -6.0726e+00, -2.0300e+01],
        [-2.2208e+01, -1.4754e+01, -1.5389e+01, -1.5077e+01, -1.1651e+01,
         -2.2651e-01, -1.5013e+01, -1.4819e+01, -6.0445e+00, -1.3285e+01,
         -1.5873e+01, -1.5203e+01, -6.0437e+00, -1.6049e+01],
        [-2.4179e+01, -2.0166e+01, -2.1134e+01, -1.5553e+01, -1.4788e+01,
         -3.3754e+00, -2.1998e+01, -2.1698e+01, -5.6862e+00, -1.4254e+01,
         -2.1194e+01, -2.1562e+01, -6.1744e+00, -2.1179e+01],
        [-3.5981e+01, -2.9583e+01, -3.0064e+01, -1.5189e+01, -1.3833e+01,
          5.1277e+00, -3.0449e+01, -2.9749e+01, -5.2072e+00, -1.5391e+01,
         -2.9576e+01, -3.0357e+01, -5.6595e+00, -3.0076e+01],
        [-4.4875e+01, -5.2850e+01, -5.1232e+01, -1.0904e+01, -1.6936e+01,
          6.1723e+00, -5.3975e+01, -5.3736e+01, -1.9589e+00, -2.0170e+01,
         -4.8467e+01, -5.3138e+01, -2.4164e+00, -5.0033e+01],
        [-7.1162e+00,  5.3373e-02, -3.1660e-01, -1.2330e+01, -1.1326e+00,
          5.9472e-01, -7.0417e-01, -1.6513e-01, -6.4766e+00, -9.9168e+00,
         -5.3825e-01, -1.6213e-01, -7.1808e+00, -6.6211e-01],
        [-4.1328e+01, -3.8191e+01, -3.7775e+01, -1.3501e+01, -1.4626e+01,
          6.4108e+00, -3.9946e+01, -3.9307e+01, -4.5191e+00, -1.6541e+01,
         -3.7113e+01, -3.9687e+01, -4.4064e+00, -3.7433e+01],
        [ 5.4113e+01,  7.3642e+01,  7.0782e+01,  5.9406e+00,  2.4334e+01,
         -4.8565e+00,  7.3907e+01,  7.3770e+01, -1.8409e+00,  2.5101e+01,
          6.7514e+01,  7.2716e+01, -1.3174e+00,  6.8866e+01],
        [-4.7879e+01, -5.7623e+01, -5.5595e+01, -9.1085e+00, -1.7313e+01,
          7.9415e+00, -5.8999e+01, -5.8398e+01, -4.9674e-01, -2.1061e+01,
         -5.2951e+01, -5.7643e+01, -9.8695e-01, -5.3955e+01],
        [ 8.4386e+00,  5.7922e+01,  5.6324e+01, -2.3147e+00,  3.5843e+01,
          3.2022e+01,  5.6416e+01,  5.7370e+01, -3.4467e+00,  5.9589e-01,
          5.3936e+01,  5.7184e+01, -3.6383e+00,  5.4667e+01],
        [-5.5176e+00,  2.1926e-02, -2.5369e-01, -1.0309e+01,  1.0606e-02,
         -2.5069e-01, -1.5571e+00, -1.1999e+00, -7.1220e+00, -8.0143e+00,
         -3.1114e-01, -1.2407e+00, -7.2320e+00, -6.8087e-01],
        [-6.6196e+01, -6.9487e+01, -6.7482e+01, -7.5063e+00, -2.4673e+00,
          2.7369e+01, -7.1433e+01, -6.9871e+01,  7.4691e-01, -2.3263e+01,
         -6.3894e+01, -7.0130e+01,  7.9087e-01, -6.5390e+01],
        [-2.1071e+01, -1.4223e+01, -1.4994e+01, -1.5772e+01, -1.1712e+01,
         -1.3900e+00, -1.4641e+01, -1.4232e+01, -5.8278e+00, -1.2603e+01,
         -1.5461e+01, -1.4689e+01, -6.2030e+00, -1.5534e+01],
        [-1.5107e+01, -6.6266e+00, -7.6932e+00, -1.4184e+01, -8.3792e+00,
         -9.9051e-01, -6.7895e+00, -7.0124e+00, -5.9577e+00, -1.1581e+01,
         -8.5230e+00, -7.5158e+00, -6.6762e+00, -8.4865e+00]], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[  2.0880,   1.7540,   1.9301,   3.0395,   6.3436,   0.9171,   4.2175,
         -13.8061,   7.8920,  38.5062,   0.5995,  20.6718,   1.7060,   1.3423]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -3.1178,   2.2375],
        [ -4.6408,   1.0085],
        [-24.3412,  -6.1515],
        [ -3.5234,   2.0092],
        [-12.3043,   0.6065],
        [ -0.1732,   3.8568],
        [ -5.7699,   0.5130],
        [ -4.3131,   1.2082],
        [ 19.4356,   8.0470],
        [  3.7838,  -0.1424],
        [ 13.2438,   7.3388],
        [ -4.8448,   0.8083],
        [ -2.9032,   2.1126],
        [-25.2455,  -3.6330]], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-1.0991e+02, -1.6393e+01,  2.8544e+01, -8.2541e+01,  1.4518e+01,
         -1.8130e+02, -4.5727e+00, -3.3062e+01, -1.9680e+02,  2.7782e+00,
         -2.3186e+02, -1.9277e+01, -1.2021e+02,  1.5485e+01],
        [-2.9648e+01, -2.8752e+01, -2.0279e+01, -2.5271e+01, -4.5367e+01,
         -3.6794e+01, -1.9356e+01, -2.4982e+01, -9.5123e+00, -3.2541e+00,
         -2.0223e+01, -2.4284e+01, -3.8568e+01, -4.2388e+01],
        [-2.8139e+01, -2.8530e+01, -1.9737e+01, -2.4465e+01, -4.5983e+01,
         -3.6042e+01, -1.9739e+01, -2.4949e+01, -9.7324e+00, -2.9866e+00,
         -2.1105e+01, -2.4046e+01, -3.8867e+01, -4.3913e+01],
        [-2.2647e+01, -2.9077e+01, -2.1289e+01, -2.1713e+01, -3.3455e+01,
         -3.5931e+01, -2.1834e+01, -2.5055e+01, -9.0378e+00, -4.1196e+00,
         -2.3758e+01, -2.5286e+01, -3.4509e+01, -2.3551e+01],
        [-2.3818e+01, -2.8831e+01, -2.1115e+01, -2.2307e+01, -3.6014e+01,
         -3.5997e+01, -2.1255e+01, -2.4679e+01, -9.1203e+00, -3.9551e+00,
         -2.3416e+01, -2.4764e+01, -3.5379e+01, -2.8188e+01],
        [-2.4475e+01, -2.8609e+01, -2.1191e+01, -2.2547e+01, -3.8441e+01,
         -3.6288e+01, -2.0419e+01, -2.4787e+01, -9.2265e+00, -3.6167e+00,
         -2.2914e+01, -2.4683e+01, -3.6318e+01, -3.3444e+01],
        [-4.2116e+01, -2.8717e+01, -1.8250e+01, -3.3173e+01, -6.5444e+01,
         -3.7906e+01, -1.6046e+01, -2.6163e+01, -1.1510e+01, -3.8400e-02,
         -1.9359e+01, -2.4448e+01, -4.5265e+01, -5.2309e+01],
        [-5.2339e+01, -7.0483e+00, -3.1696e+01, -4.5058e+01, -5.7918e+01,
         -4.4184e+01,  6.8793e+00, -1.1572e+01, -3.9417e+00,  3.2933e-01,
         -3.8520e+00, -3.6512e+00, -3.3500e+01, -3.1747e+00],
        [-2.8777e+01, -2.8781e+01, -2.0624e+01, -2.4871e+01, -4.3286e+01,
         -3.6700e+01, -1.9539e+01, -2.4927e+01, -9.3755e+00, -3.4401e+00,
         -2.0731e+01, -2.4460e+01, -3.7816e+01, -3.9445e+01],
        [-1.7265e+01, -1.4943e+01, -2.4751e-01, -9.1526e+00,  6.3001e+00,
         -5.0495e+01, -1.4335e+01, -1.4586e+01, -1.5813e+01,  2.1998e+00,
         -7.1300e+01, -1.5909e+01, -2.3696e+01,  4.5188e+00],
        [ 3.1737e+01,  4.6187e+01,  2.8577e+01,  4.0607e+01,  5.5029e+01,
          3.3851e-01,  4.4194e+01,  4.6117e+01,  5.4181e-01, -3.8797e+00,
          3.4811e+00,  4.7188e+01,  2.5969e+01,  2.2788e+01],
        [-2.5726e+01, -2.8664e+01, -2.1565e+01, -2.3539e+01, -4.1215e+01,
         -3.6628e+01, -1.9342e+01, -2.4765e+01, -9.4125e+00, -3.0798e+00,
         -2.2676e+01, -2.4408e+01, -3.7936e+01, -3.7575e+01],
        [-2.7662e+01, -2.8322e+01, -1.9784e+01, -2.4475e+01, -4.3771e+01,
         -3.6155e+01, -2.0122e+01, -2.4908e+01, -9.5471e+00, -3.3014e+00,
         -2.0782e+01, -2.4362e+01, -3.8155e+01, -4.2526e+01],
        [-2.7139e+01, -2.8893e+01, -2.0298e+01, -2.4257e+01, -4.1575e+01,
         -3.6098e+01, -1.9978e+01, -2.4961e+01, -9.2680e+00, -3.7119e+00,
         -2.0640e+01, -2.4821e+01, -3.7172e+01, -3.8876e+01]], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ 12.3705, -13.3775, -13.5064, -13.8046, -13.5608, -13.6898, -14.2658,
          -5.8772, -13.4045, -12.5017,   0.5807, -14.1827, -13.5732, -13.4203],
        [-12.5197,  13.3978,  13.7162,  13.5774,  13.7476,  14.0222,  14.4566,
           6.1521,  13.4594,  12.5410,  -0.6625,  14.1397,  13.5759,  13.3792]],
       device='cuda:0'))])
xi:  [-969.2997]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: -245.8912915498973
W_T_median: -396.9166316400578
W_T_pctile_5: -926.3945798458351
W_T_CVAR_5_pct: -1058.022492507019
Average q (qsum/M+1):  59.86055632560484
Optimal xi:  [-969.2997]
Expected(across Rb) median(across samples) p_equity:  0.17505048257529557
obj fun:  tensor(-1802.4764, device='cuda:0', dtype=torch.float64,
       grad_fn=<MeanBackward0>)
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.05
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       14  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       14  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1  logistic_sigmoid   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 14)     False        None  
0     (14, 14)     False        None  
0      (14, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       14  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       14  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 14)     False        None  
0     (14, 14)     False        None  
0      (14, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1576.8182150775267
W_T_median: 1136.7449346433505
W_T_pctile_5: -127.64084552288806
W_T_CVAR_5_pct: -295.72244238283764
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1685.7658305437135
Current xi:  [-279.72787]
objective value function right now is: -1685.7658305437135
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1694.8622161688218
Current xi:  [-389.60587]
objective value function right now is: -1694.8622161688218
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1697.210896373089
Current xi:  [-428.10376]
objective value function right now is: -1697.210896373089
8.0% of gradient descent iterations done. Method = Adam
Current xi:  [-432.99854]
objective value function right now is: -1693.8501122905743
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1698.7552372460514
Current xi:  [-434.1738]
objective value function right now is: -1698.7552372460514
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [-431.34528]
objective value function right now is: -1694.9924114584849
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [-441.61902]
objective value function right now is: -1691.8154204523435
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [-440.8197]
objective value function right now is: -1696.624488418816
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [-444.12244]
objective value function right now is: -1698.1842360373344
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [-462.6536]
objective value function right now is: -1687.8128370379247
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [-448.07788]
objective value function right now is: -1690.869392317179
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [-462.04822]
objective value function right now is: -1692.313057654054
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [-455.75204]
objective value function right now is: -1691.7099138672622
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [-462.02902]
objective value function right now is: -1692.3103343701564
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [-436.5966]
objective value function right now is: -1695.7988891313726
32.0% of gradient descent iterations done. Method = Adam
new min fval:  -1699.5774878197406
Current xi:  [-437.14874]
objective value function right now is: -1699.5774878197406
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [-462.06647]
objective value function right now is: -1681.1118155162642
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [-445.61127]
objective value function right now is: -1696.4742357677276
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [-455.11066]
objective value function right now is: -1693.043006944085
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [-452.3809]
objective value function right now is: -1693.543109023647
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [-454.85483]
objective value function right now is: -1692.1905814468143
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [-465.98096]
objective value function right now is: -1693.2324356659105
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [-472.11383]
objective value function right now is: -1686.1639225747535
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [-462.21085]
objective value function right now is: -1683.8510563445213
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [-455.7008]
objective value function right now is: -1692.0483877503732
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [-464.98386]
objective value function right now is: -1691.5309100326626
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [-457.977]
objective value function right now is: -1692.876019840545
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [-466.91336]
objective value function right now is: -1692.8340817474145
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [-460.0055]
objective value function right now is: -1689.2090556173903
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [-466.87875]
objective value function right now is: -1692.6557807798224
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [-471.0568]
objective value function right now is: -1689.5574031297563
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [-464.64636]
objective value function right now is: -1693.048235375186
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [-461.11157]
objective value function right now is: -1693.1784529594188
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [-474.45758]
objective value function right now is: -1685.4643103639066
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [-467.43445]
objective value function right now is: -1691.7997162232693
72.0% of gradient descent iterations done. Method = Adam
Current xi:  [-469.97116]
objective value function right now is: -1691.916877071686
74.0% of gradient descent iterations done. Method = Adam
Current xi:  [-469.0893]
objective value function right now is: -1689.911331499053
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [-483.83426]
objective value function right now is: -1691.1411201522471
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [-462.09332]
objective value function right now is: -1690.722509446913
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [-463.25525]
objective value function right now is: -1691.079048894157
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [-505.34103]
objective value function right now is: -1689.5316998609962
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [-467.78943]
objective value function right now is: -1692.1184558531693
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [-463.75388]
objective value function right now is: -1692.2274727586441
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [-653.04987]
objective value function right now is: -1588.942218543799
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [-588.43396]
objective value function right now is: -1687.204144196556
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [-539.5005]
objective value function right now is: -1689.2311269314598
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [-519.7071]
objective value function right now is: -1671.6995365355754
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [-488.00565]
objective value function right now is: -1681.9698310448941
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [-469.18588]
objective value function right now is: -1682.1100467461815
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [-459.12592]
objective value function right now is: -1686.8895633959687
min fval:  -1675.3125583436322
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-0.4410, -2.2374],
        [-0.4315, -2.2078],
        [-0.3487, -1.9432],
        [ 0.6978,  3.0666],
        [ 0.7195,  3.1309],
        [11.8944,  8.1966],
        [ 0.6913,  3.0467],
        [ 0.7316,  3.1672],
        [ 0.6926,  3.0507],
        [ 0.6915,  3.0472],
        [ 0.7498,  3.2206],
        [ 0.7480,  3.2142],
        [ 0.6915,  3.0475],
        [ 0.6920,  3.0496]], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[  1.2657,   1.1043,   0.9181, -15.7004, -10.2218,  -9.9000, -18.8702,
          -8.6940, -17.9915, -18.6993,  -7.7001,  -7.7163, -18.8640, -18.2995],
        [ -2.1759,  -1.8409,  -1.6413,  15.1623,   9.6483,   8.3781,  18.4748,
           8.4235,  17.8103,  18.7979,   7.0825,   7.5359,  18.3440,  18.1607],
        [  1.4395,   1.4481,   0.7385, -15.4013, -10.5010, -10.0038, -19.1234,
          -8.9544, -18.2857, -18.6489,  -7.9229,  -7.9476, -18.5990, -18.5182],
        [  1.4225,   1.4670,   1.1174, -15.4857, -10.1176, -10.3770, -19.9017,
          -9.0014, -18.2959, -19.5589,  -7.4333,  -7.7008, -19.2351, -18.8263],
        [  1.4189,   1.3661,   0.9169, -15.5908, -10.3861, -10.0238, -18.8030,
          -9.1398, -18.1653, -18.8483,  -7.9649,  -8.2216, -18.9843, -18.3340],
        [  1.3120,   1.3984,   0.9670, -15.4448, -10.3929, -10.1600, -19.2569,
          -8.8170, -18.6201, -19.1579,  -7.5073,  -7.5134, -19.1012, -18.4235],
        [  1.5319,   1.4288,   0.9507, -15.3621,  -9.9667, -10.2907, -19.7501,
          -8.5077, -18.5056, -19.5770,  -7.6680,  -7.4677, -19.2378, -18.8143],
        [  1.3683,   1.3540,   0.9375, -15.5196, -10.2626,  -9.9275, -18.9180,
          -9.2236, -18.1963, -18.9358,  -7.9150,  -8.1266, -18.8361, -18.2832],
        [ -2.0686,  -2.0009,  -1.6424,  14.7030,   9.5856,   7.8416,  18.7263,
           8.3647,  18.0174,  18.7035,   7.2601,   7.3822,  18.3749,  18.4480],
        [ -1.8650,  -2.1060,  -1.7451,  14.9020,   9.5607,   8.2314,  18.3258,
           8.0690,  17.6137,  18.1275,   7.1718,   6.9473,  18.6036,  17.7760],
        [  1.3095,   1.1858,   0.9912, -15.4813, -10.1378,  -9.9942, -18.9413,
          -8.9757, -18.3566, -18.8237,  -7.6399,  -7.8398, -19.0762, -18.2135],
        [ -2.1093,  -2.1516,  -1.4120,  15.0264,   9.5033,   8.3155,  18.7315,
           8.5811,  17.8110,  18.3371,   7.4037,   7.0455,  18.5341,  18.0352],
        [ -2.1487,  -1.9902,  -1.5827,  15.0467,   9.4015,   8.5135,  18.5840,
           8.1926,  17.3678,  18.3283,   7.2977,   6.9351,  18.2439,  18.0557],
        [  1.4629,   1.0563,   0.8057, -15.8765, -10.1462,  -9.9247, -18.6698,
          -8.9561, -17.9317, -18.8464,  -7.7259,  -7.9772, -18.6912, -18.3263]],
       device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ -8.9801,  12.6578,  -9.3004, -10.8248,  -9.1325,  -9.7404, -10.7548,
          -8.8922,  12.0588,  12.2073,  -9.1744,  12.3753,  11.9935,  -8.6089]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -6.1521,   1.4111],
        [ -5.0245,   2.7730],
        [  7.9900,   4.6340],
        [ -4.9093,   0.5553],
        [ -5.3090,   1.1900],
        [ -5.4302,   1.2624],
        [  5.9662,   2.1195],
        [-26.0655,  -6.9754],
        [ -2.8400,   3.3651],
        [ -2.2986,   3.4473],
        [-17.3404,   0.1043],
        [  5.8054,  -0.4323],
        [ 14.2721,   5.0133],
        [ -8.0887,   0.6169]], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-5.4929e+00, -3.4484e+00, -4.6316e+00, -7.1743e+00, -3.4651e+00,
         -5.9227e+00, -1.0507e+01, -7.7953e+00, -2.9334e+00, -2.0892e+00,
         -1.0101e+01, -1.3345e+01, -5.8149e+00, -6.6744e+00],
        [ 4.1803e+00, -5.0883e+01, -2.1160e+02, -1.0177e+01, -3.8033e+01,
         -3.4382e+01,  3.2168e+00,  2.3433e+01, -1.0783e+02, -1.2912e+02,
          2.2707e+01,  2.4823e+00, -8.9513e+01, -1.4233e+01],
        [ 2.8736e+01,  2.6985e+00,  6.1094e+00,  3.4706e+01,  5.5698e+01,
          5.6089e+01, -7.5401e+00, -1.0406e+01, -7.8852e-01, -3.9736e-01,
          1.8491e+01, -8.5250e+00,  7.9009e+00,  1.1103e+02],
        [-7.5125e+00, -8.2295e+01, -2.0809e+01, -1.1805e+01, -5.9209e+01,
         -6.7366e+01,  2.9488e+00, -3.2922e+01, -9.5834e+01, -7.9750e+01,
          5.8769e+00,  7.1700e-01, -5.3333e+00, -8.0760e+01],
        [-7.8335e+00, -3.6399e+00, -4.7711e+00, -7.0101e+00, -6.2883e+00,
         -6.4440e+00, -1.0663e+01, -8.1589e+00, -4.9384e+00, -5.3932e+00,
         -9.6973e+00, -1.2996e+01, -7.1716e+00, -7.5733e+00],
        [ 1.2903e+00, -7.2422e+00, -4.1577e-02, -2.9985e+00,  2.2852e+00,
          4.2111e+00, -6.6966e+00, -8.1367e+00, -9.4516e+00, -1.3403e+01,
         -3.6785e+00, -8.7251e+00, -8.0874e-01, -3.4763e+01],
        [-1.0609e+01, -7.1635e+00, -7.0410e+00, -1.4297e+01, -1.2107e+01,
         -8.6629e+00, -7.6072e+00, -1.6045e+01, -1.1988e+01, -1.1997e+01,
         -7.4581e+00, -1.1055e+01, -8.0059e+00, -2.7853e+01],
        [-5.5987e+00, -5.4815e+00, -6.6934e+00, -1.2275e+01, -3.6828e+00,
         -7.5633e+00, -7.9063e+00, -1.1638e+01, -5.5491e+00, -7.0221e+00,
         -7.5936e+00, -1.0915e+01, -5.4775e+00, -1.8360e+01],
        [-8.5888e+00, -3.8047e+00, -1.3348e+01, -6.2655e+00, -7.6773e+00,
         -8.5754e+00, -9.4187e+00, -6.0423e+00, -6.7747e+00, -9.9477e-01,
         -1.0910e+01, -1.3065e+01, -1.2503e+01, -6.2286e+00],
        [ 9.3735e+00, -2.0657e+01, -1.1716e+00,  1.1319e+01,  3.6516e+00,
         -1.2589e+00, -5.0611e+00, -3.4331e+00, -2.2988e+01, -1.8951e+01,
          1.0669e+00, -7.2076e+00,  4.1622e+00, -2.9370e+01],
        [-1.1800e+00, -5.4087e+00, -3.5868e+00, -5.0515e+00,  1.7138e+00,
         -3.2892e+00, -7.9437e+00, -9.2696e+00, -4.8775e+00, -6.8788e+00,
         -7.9173e+00, -8.0369e+00, -4.5718e+00, -1.9600e+01],
        [-5.0881e-01, -3.9595e+01, -1.9156e+00, -2.0668e+00, -8.7667e+00,
         -9.6859e+00,  1.9171e+00,  6.0091e-01, -3.8824e+01, -3.5743e+01,
         -1.3331e+00,  3.3214e+00, -9.1837e+00, -3.8632e+01],
        [-1.2105e+01, -1.3027e+02, -1.4208e+02, -1.1738e+01, -6.2556e+01,
         -7.2352e+01,  7.9667e+00,  2.0925e+01, -1.6349e+02, -1.6466e+02,
          5.1907e+00,  3.9275e+00, -5.3943e+01, -7.9951e+01],
        [ 1.0802e+01, -5.0224e+01, -2.7553e+00,  2.7860e+01,  1.0883e+01,
          4.2088e+00,  2.1690e-01, -1.1547e+01, -4.4133e+01, -3.8902e+01,
          2.1294e+00, -1.0576e+00, -1.8366e+00, -5.8820e+01]], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ -0.4595,   7.0672,   0.9499,   2.1003,  -0.4791,  -3.9297,   1.2852,
          -0.7483,  -0.2739,  -8.0252,  -3.0089, -10.8101,   3.6371,  -4.3401],
        [  0.1380,  -7.0958,  -0.9548,  -1.8967,   0.2309,   3.8765,  -1.1074,
           0.5728,   0.6109,   7.9572,   2.9430,  10.6118,  -3.6617,   4.0182]],
       device='cuda:0'))])
xi:  [-588.43396]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: -27.120055825155102
W_T_median: -200.53498303555068
W_T_pctile_5: -433.76300095086697
W_T_CVAR_5_pct: -477.25455409656206
Average q (qsum/M+1):  57.90538369455645
Optimal xi:  [-588.43396]
Expected(across Rb) median(across samples) p_equity:  0.21381215578100335
obj fun:  tensor(-1675.3126, device='cuda:0', dtype=torch.float64,
       grad_fn=<MeanBackward0>)
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.2
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       14  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       14  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1  logistic_sigmoid   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 14)     False        None  
0     (14, 14)     False        None  
0      (14, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       14  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       14  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 14)     False        None  
0     (14, 14)     False        None  
0      (14, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
loaded continuation NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-0.4410, -2.2374],
        [-0.4315, -2.2078],
        [-0.3487, -1.9432],
        [ 0.6978,  3.0666],
        [ 0.7195,  3.1309],
        [11.8944,  8.1966],
        [ 0.6913,  3.0467],
        [ 0.7316,  3.1672],
        [ 0.6926,  3.0507],
        [ 0.6915,  3.0472],
        [ 0.7498,  3.2206],
        [ 0.7480,  3.2142],
        [ 0.6915,  3.0475],
        [ 0.6920,  3.0496]], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[  1.2657,   1.1043,   0.9181, -15.7004, -10.2218,  -9.9000, -18.8702,
          -8.6940, -17.9915, -18.6993,  -7.7001,  -7.7163, -18.8640, -18.2995],
        [ -2.1759,  -1.8409,  -1.6413,  15.1623,   9.6483,   8.3781,  18.4748,
           8.4235,  17.8103,  18.7979,   7.0825,   7.5359,  18.3440,  18.1607],
        [  1.4395,   1.4481,   0.7385, -15.4013, -10.5010, -10.0038, -19.1234,
          -8.9544, -18.2857, -18.6489,  -7.9229,  -7.9476, -18.5990, -18.5182],
        [  1.4225,   1.4670,   1.1174, -15.4857, -10.1176, -10.3770, -19.9017,
          -9.0014, -18.2959, -19.5589,  -7.4333,  -7.7008, -19.2351, -18.8263],
        [  1.4189,   1.3661,   0.9169, -15.5908, -10.3861, -10.0238, -18.8030,
          -9.1398, -18.1653, -18.8483,  -7.9649,  -8.2216, -18.9843, -18.3340],
        [  1.3120,   1.3984,   0.9670, -15.4448, -10.3929, -10.1600, -19.2569,
          -8.8170, -18.6201, -19.1579,  -7.5073,  -7.5134, -19.1012, -18.4235],
        [  1.5319,   1.4288,   0.9507, -15.3621,  -9.9667, -10.2907, -19.7501,
          -8.5077, -18.5056, -19.5770,  -7.6680,  -7.4677, -19.2378, -18.8143],
        [  1.3683,   1.3540,   0.9375, -15.5196, -10.2626,  -9.9275, -18.9180,
          -9.2236, -18.1963, -18.9358,  -7.9150,  -8.1266, -18.8361, -18.2832],
        [ -2.0686,  -2.0009,  -1.6424,  14.7030,   9.5856,   7.8416,  18.7263,
           8.3647,  18.0174,  18.7035,   7.2601,   7.3822,  18.3749,  18.4480],
        [ -1.8650,  -2.1060,  -1.7451,  14.9020,   9.5607,   8.2314,  18.3258,
           8.0690,  17.6137,  18.1275,   7.1718,   6.9473,  18.6036,  17.7760],
        [  1.3095,   1.1858,   0.9912, -15.4813, -10.1378,  -9.9942, -18.9413,
          -8.9757, -18.3566, -18.8237,  -7.6399,  -7.8398, -19.0762, -18.2135],
        [ -2.1093,  -2.1516,  -1.4120,  15.0264,   9.5033,   8.3155,  18.7315,
           8.5811,  17.8110,  18.3371,   7.4037,   7.0455,  18.5341,  18.0352],
        [ -2.1487,  -1.9902,  -1.5827,  15.0467,   9.4015,   8.5135,  18.5840,
           8.1926,  17.3678,  18.3283,   7.2977,   6.9351,  18.2439,  18.0557],
        [  1.4629,   1.0563,   0.8057, -15.8765, -10.1462,  -9.9247, -18.6698,
          -8.9561, -17.9317, -18.8464,  -7.7259,  -7.9772, -18.6912, -18.3263]],
       device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ -8.9801,  12.6578,  -9.3004, -10.8248,  -9.1325,  -9.7404, -10.7548,
          -8.8922,  12.0588,  12.2073,  -9.1744,  12.3753,  11.9935,  -8.6089]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -6.1521,   1.4111],
        [ -5.0245,   2.7730],
        [  7.9900,   4.6340],
        [ -4.9093,   0.5553],
        [ -5.3090,   1.1900],
        [ -5.4302,   1.2624],
        [  5.9662,   2.1195],
        [-26.0655,  -6.9754],
        [ -2.8400,   3.3651],
        [ -2.2986,   3.4473],
        [-17.3404,   0.1043],
        [  5.8054,  -0.4323],
        [ 14.2721,   5.0133],
        [ -8.0887,   0.6169]], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-5.4929e+00, -3.4484e+00, -4.6316e+00, -7.1743e+00, -3.4651e+00,
         -5.9227e+00, -1.0507e+01, -7.7953e+00, -2.9334e+00, -2.0892e+00,
         -1.0101e+01, -1.3345e+01, -5.8149e+00, -6.6744e+00],
        [ 4.1803e+00, -5.0883e+01, -2.1160e+02, -1.0177e+01, -3.8033e+01,
         -3.4382e+01,  3.2168e+00,  2.3433e+01, -1.0783e+02, -1.2912e+02,
          2.2707e+01,  2.4823e+00, -8.9513e+01, -1.4233e+01],
        [ 2.8736e+01,  2.6985e+00,  6.1094e+00,  3.4706e+01,  5.5698e+01,
          5.6089e+01, -7.5401e+00, -1.0406e+01, -7.8852e-01, -3.9736e-01,
          1.8491e+01, -8.5250e+00,  7.9009e+00,  1.1103e+02],
        [-7.5125e+00, -8.2295e+01, -2.0809e+01, -1.1805e+01, -5.9209e+01,
         -6.7366e+01,  2.9488e+00, -3.2922e+01, -9.5834e+01, -7.9750e+01,
          5.8769e+00,  7.1700e-01, -5.3333e+00, -8.0760e+01],
        [-7.8335e+00, -3.6399e+00, -4.7711e+00, -7.0101e+00, -6.2883e+00,
         -6.4440e+00, -1.0663e+01, -8.1589e+00, -4.9384e+00, -5.3932e+00,
         -9.6973e+00, -1.2996e+01, -7.1716e+00, -7.5733e+00],
        [ 1.2903e+00, -7.2422e+00, -4.1577e-02, -2.9985e+00,  2.2852e+00,
          4.2111e+00, -6.6966e+00, -8.1367e+00, -9.4516e+00, -1.3403e+01,
         -3.6785e+00, -8.7251e+00, -8.0874e-01, -3.4763e+01],
        [-1.0609e+01, -7.1635e+00, -7.0410e+00, -1.4297e+01, -1.2107e+01,
         -8.6629e+00, -7.6072e+00, -1.6045e+01, -1.1988e+01, -1.1997e+01,
         -7.4581e+00, -1.1055e+01, -8.0059e+00, -2.7853e+01],
        [-5.5987e+00, -5.4815e+00, -6.6934e+00, -1.2275e+01, -3.6828e+00,
         -7.5633e+00, -7.9063e+00, -1.1638e+01, -5.5491e+00, -7.0221e+00,
         -7.5936e+00, -1.0915e+01, -5.4775e+00, -1.8360e+01],
        [-8.5888e+00, -3.8047e+00, -1.3348e+01, -6.2655e+00, -7.6773e+00,
         -8.5754e+00, -9.4187e+00, -6.0423e+00, -6.7747e+00, -9.9477e-01,
         -1.0910e+01, -1.3065e+01, -1.2503e+01, -6.2286e+00],
        [ 9.3735e+00, -2.0657e+01, -1.1716e+00,  1.1319e+01,  3.6516e+00,
         -1.2589e+00, -5.0611e+00, -3.4331e+00, -2.2988e+01, -1.8951e+01,
          1.0669e+00, -7.2076e+00,  4.1622e+00, -2.9370e+01],
        [-1.1800e+00, -5.4087e+00, -3.5868e+00, -5.0515e+00,  1.7138e+00,
         -3.2892e+00, -7.9437e+00, -9.2696e+00, -4.8775e+00, -6.8788e+00,
         -7.9173e+00, -8.0369e+00, -4.5718e+00, -1.9600e+01],
        [-5.0881e-01, -3.9595e+01, -1.9156e+00, -2.0668e+00, -8.7667e+00,
         -9.6859e+00,  1.9171e+00,  6.0091e-01, -3.8824e+01, -3.5743e+01,
         -1.3331e+00,  3.3214e+00, -9.1837e+00, -3.8632e+01],
        [-1.2105e+01, -1.3027e+02, -1.4208e+02, -1.1738e+01, -6.2556e+01,
         -7.2352e+01,  7.9667e+00,  2.0925e+01, -1.6349e+02, -1.6466e+02,
          5.1907e+00,  3.9275e+00, -5.3943e+01, -7.9951e+01],
        [ 1.0802e+01, -5.0224e+01, -2.7553e+00,  2.7860e+01,  1.0883e+01,
          4.2088e+00,  2.1690e-01, -1.1547e+01, -4.4133e+01, -3.8902e+01,
          2.1294e+00, -1.0576e+00, -1.8366e+00, -5.8820e+01]], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ -0.4595,   7.0672,   0.9499,   2.1003,  -0.4791,  -3.9297,   1.2852,
          -0.7483,  -0.2739,  -8.0252,  -3.0089, -10.8101,   3.6371,  -4.3401],
        [  0.1380,  -7.0958,  -0.9548,  -1.8967,   0.2309,   3.8765,  -1.1074,
           0.5728,   0.6109,   7.9572,   2.9430,  10.6118,  -3.6617,   4.0182]],
       device='cuda:0'))])
loaded xi:  -588.43396
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1576.8182150775267
W_T_median: 1136.7449346433505
W_T_pctile_5: -127.64084552288806
W_T_CVAR_5_pct: -295.72244238283764
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1592.3680061974171
Current xi:  [-253.14122]
objective value function right now is: -1592.3680061974171
4.0% of gradient descent iterations done. Method = Adam
Current xi:  [-202.89726]
objective value function right now is: -1584.7836773854783
6.0% of gradient descent iterations done. Method = Adam
Current xi:  [-190.23227]
objective value function right now is: -1587.444491575875
8.0% of gradient descent iterations done. Method = Adam
Current xi:  [-182.86876]
objective value function right now is: -1589.8840599495238
10.0% of gradient descent iterations done. Method = Adam
Current xi:  [-175.89418]
objective value function right now is: -1587.2287861877426
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [-175.40097]
objective value function right now is: -1588.8702930892923
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [-176.54471]
objective value function right now is: -1591.0198205151191
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [-135.9741]
objective value function right now is: -1590.1983555107606
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -1592.749714326711
Current xi:  [-145.38406]
objective value function right now is: -1592.749714326711
20.0% of gradient descent iterations done. Method = Adam
new min fval:  -1593.6242863088628
Current xi:  [-149.81375]
objective value function right now is: -1593.6242863088628
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [-148.52563]
objective value function right now is: -1593.1978724347014
24.0% of gradient descent iterations done. Method = Adam
new min fval:  -1594.1737620454921
Current xi:  [-148.62906]
objective value function right now is: -1594.1737620454921
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [-149.68509]
objective value function right now is: -1593.991103604659
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [-147.45973]
objective value function right now is: -1591.8667349116313
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [-148.99875]
objective value function right now is: -1588.793389177003
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [-146.86826]
objective value function right now is: -1594.090880490035
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [-148.05658]
objective value function right now is: -1593.823729146644
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [-149.29312]
objective value function right now is: -1593.7682901365858
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [-152.30812]
objective value function right now is: -1591.1877925610072
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [-151.6409]
objective value function right now is: -1592.3294262742927
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [-151.04677]
objective value function right now is: -1588.899234514543
44.0% of gradient descent iterations done. Method = Adam
new min fval:  -1596.5560296579847
Current xi:  [-152.31714]
objective value function right now is: -1596.5560296579847
46.0% of gradient descent iterations done. Method = Adam
new min fval:  -1596.5940952047915
Current xi:  [-152.94]
objective value function right now is: -1596.5940952047915
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [-152.67836]
objective value function right now is: -1594.3764269493968
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [-152.15196]
objective value function right now is: -1592.9155719288854
52.0% of gradient descent iterations done. Method = Adam
new min fval:  -1596.7514496873846
Current xi:  [-152.8886]
objective value function right now is: -1596.7514496873846
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [-153.26846]
objective value function right now is: -1596.4440712691273
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [-152.87518]
objective value function right now is: -1592.749507014201
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [-155.0279]
objective value function right now is: -1591.4531565174564
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [-153.81975]
objective value function right now is: -1592.1687690631902
62.0% of gradient descent iterations done. Method = Adam
new min fval:  -1596.9027635261662
Current xi:  [-153.24437]
objective value function right now is: -1596.9027635261662
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [-152.95036]
objective value function right now is: -1592.3146157771187
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [-150.41089]
objective value function right now is: -1596.3420186359851
68.0% of gradient descent iterations done. Method = Adam
new min fval:  -1598.3211160492715
Current xi:  [-144.0544]
objective value function right now is: -1598.3211160492715
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [-141.7117]
objective value function right now is: -1597.234808293354
72.0% of gradient descent iterations done. Method = Adam
Current xi:  [-142.67851]
objective value function right now is: -1596.4069198907782
74.0% of gradient descent iterations done. Method = Adam
new min fval:  -1598.9480125305165
Current xi:  [-141.15436]
objective value function right now is: -1598.9480125305165
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [-141.4008]
objective value function right now is: -1596.2580157065602
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [-138.96742]
objective value function right now is: -1597.7169299797954
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [-142.37752]
objective value function right now is: -1590.530116092794
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [-142.50632]
objective value function right now is: -1591.9659487245822
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [-148.03531]
objective value function right now is: -1596.1745969440108
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [-161.52646]
objective value function right now is: -1596.1342508519954
88.0% of gradient descent iterations done. Method = Adam
new min fval:  -1602.422867459111
Current xi:  [-163.55516]
objective value function right now is: -1602.422867459111
new min fval from sgd:  -1602.4903432090657
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [-166.37552]
objective value function right now is: -1602.4903432090657
new min fval from sgd:  -1603.0353997019
new min fval from sgd:  -1603.1543370810948
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [-168.07967]
objective value function right now is: -1602.4087434089504
new min fval from sgd:  -1603.168830829149
new min fval from sgd:  -1603.3364104656448
new min fval from sgd:  -1603.6828681324666
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [-168.77826]
objective value function right now is: -1599.8609143112349
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [-169.64203]
objective value function right now is: -1597.9636503203606
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [-167.23364]
objective value function right now is: -1598.2971458329134
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [-166.92258]
objective value function right now is: -1599.9601123649493
min fval:  -1603.6828681324666
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -12.1400,   -2.7214],
        [   2.7341,   -3.2341],
        [-267.1001,    0.2791],
        [  -0.7877,    4.2216],
        [  -0.7922,    4.2364],
        [   9.6308,   11.2671],
        [  -0.7891,    4.2133],
        [  -0.7926,    4.2402],
        [  -0.7917,    4.2151],
        [  -0.7890,    4.2135],
        [  -0.7944,    4.2439],
        [  -0.7939,    4.2437],
        [  -0.7886,    4.2137],
        [  -0.7925,    4.2145]], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ -51.7059,  -22.0973,  -30.0802,  -17.2519,  -13.6138,   24.4285,
          -19.8847,  -12.7685,  -19.2254,  -19.7668,  -12.2589,  -12.2745,
          -19.8096,  -19.5071],
        [  -2.4290,   -3.2469,   -7.6662,   34.6890,   29.7664, -116.3152,
           37.7320,   28.7554,   37.1245,   38.0622,   27.6535,   28.0821,
           37.6157,   37.4584],
        [   2.0834,    1.4721,    1.3159,  -37.5495,  -33.2383,    4.8252,
          -41.0009,  -31.9038,  -40.2185,  -40.5326,  -31.1172,  -31.1162,
          -40.4923,  -40.4344],
        [   2.2260,    1.8340,    1.3667,  -37.5088,  -32.7330,    3.0617,
          -41.6548,  -31.8293,  -40.1044,  -41.3184,  -30.5069,  -30.7486,
          -41.0037,  -40.6187],
        [   2.1488,    1.5276,    1.3186,  -37.6950,  -33.0831,    4.2755,
          -40.6356,  -32.0500,  -40.0533,  -40.6873,  -31.1207,  -31.3517,
          -40.8326,  -40.2057],
        [   2.0753,    1.5629,    1.3297,  -37.5601,  -33.0999,    4.9312,
          -41.1013,  -31.7372,  -40.5198,  -41.0084,  -30.6730,  -30.6535,
          -40.9609,  -40.3073],
        [   2.2709,    1.7168,    1.3427,  -37.4159,  -32.6125,   -0.8845,
          -41.5336,  -31.3658,  -40.3443,  -41.3668,  -30.7717,  -30.5457,
          -41.0370,  -40.6366],
        [   2.1005,    1.4710,    1.3176,  -37.6541,  -32.9899,    4.7687,
          -40.7806,  -32.1647,  -40.1145,  -40.8052,  -31.1013,  -31.2873,
          -40.7146,  -40.1850],
        [  -3.8301,   -5.2768,    4.3551,   35.4233,   30.8070,   -8.5577,
           39.2380,   29.7535,   38.5817,   39.2186,   28.9053,   28.9960,
           38.9016,   39.0199],
        [ -10.2710,  -13.0700,  -27.0548,   21.1565,   16.3071, -159.8795,
           24.3740,   14.9999,   23.7153,   24.1839,   14.3298,   14.0808,
           24.6651,   23.8751],
        [   2.0699,    1.2669,    1.2961,  -37.6047,  -32.8556,    4.8151,
          -40.7922,  -31.9085,  -40.2630,  -40.6815,  -30.8177,  -30.9924,
          -40.9426,  -40.1035],
        [  -3.1174,   -4.1656,   -1.1128,   34.8004,   29.8779,  -56.1859,
           38.2324,   29.1728,   37.3691,   37.8458,   28.2362,   27.8540,
           38.0496,   37.5772],
        [ -10.4810,  -12.9080,  -27.0806,   20.9749,   15.7970, -165.4336,
           24.3191,   14.7649,   23.1549,   24.0714,   14.0924,   13.7050,
           23.9916,   23.8431],
        [   2.0039,    0.7650,    1.2627,  -37.9780,  -32.8363,    5.0544,
          -40.4994,  -31.8594,  -39.8172,  -40.6836,  -30.8726,  -31.0989,
          -40.5366,  -40.1959]], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ -9.4157,  16.2536, -14.2271, -16.0996, -14.3406, -14.7504, -15.8619,
         -14.0787,  15.9944,   7.2463, -14.1402,  13.7836,   7.6398, -13.2707]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[-2.8555e+01, -5.3759e+00],
        [-1.1431e+01, -6.4730e+00],
        [ 8.6863e+00, -6.8360e+00],
        [-2.8453e+01, -5.3523e+00],
        [-8.4852e+00,  1.7183e+00],
        [-8.4250e+00,  1.7107e+00],
        [ 3.7040e+00, -1.4261e+00],
        [-4.1418e+01, -1.0603e+01],
        [-6.5875e+00, -4.7822e-02],
        [ 5.4849e+00,  1.3361e+00],
        [-7.5988e+01, -1.8321e+01],
        [ 2.4980e+01, -6.0778e+00],
        [ 2.5219e+01,  8.8740e+00],
        [-1.1218e+01,  2.1977e+00]], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-5.4944e+00, -3.4550e+00, -4.7252e+00, -7.1371e+00, -3.6638e+00,
         -6.1209e+00, -1.0739e+01, -5.3294e+00, -2.9418e+00, -2.0361e+00,
         -1.0103e+01, -1.1237e+01, -6.3166e+00, -6.8651e+00],
        [-7.7962e+00, -6.9183e+01, -2.5229e+02, -1.4941e+01, -3.8568e+01,
         -3.5217e+01,  8.4283e+00,  3.0433e+01, -1.2334e+02, -1.4327e+02,
          3.8254e+01,  1.0086e+01, -7.4220e+01, -3.0745e+01],
        [ 7.0631e+01,  1.1574e+00,  2.5708e+00,  6.3469e+01,  1.8285e+02,
          1.8357e+02, -7.1420e+00, -1.8121e+01, -3.4460e+01,  4.1037e+00,
         -7.8769e+01, -9.7248e+00,  7.6618e+00,  2.4915e+02],
        [ 2.9579e+01, -3.8280e+01,  6.6138e-01,  2.1813e+01, -4.2017e+01,
         -4.8958e+01,  4.2736e+00, -2.6440e+01, -3.5725e+01, -5.8409e+01,
          2.0872e+01,  2.7762e+00, -2.6846e+01, -6.7596e+01],
        [-7.8365e+00, -3.6400e+00, -4.7703e+00, -6.9968e+00, -6.2933e+00,
         -6.4485e+00, -1.0746e+01, -5.9677e+00, -4.9384e+00, -5.3929e+00,
         -9.6988e+00, -1.1064e+01, -7.3937e+00, -7.5593e+00],
        [ 3.6805e+00, -2.2346e+01, -1.6644e+01, -6.3740e+00,  3.2178e+00,
          4.4390e+00, -9.4604e+00,  1.8398e+00, -2.2942e+01, -2.6430e+01,
         -8.0284e+00, -7.0212e+00, -8.9134e-01, -3.6244e+01],
        [-1.0612e+01, -7.1646e+00, -7.0609e+00, -1.4314e+01, -1.2113e+01,
         -8.6686e+00, -8.0832e+00, -1.6560e+01, -1.1989e+01, -1.1999e+01,
         -7.4581e+00, -1.2120e+01, -7.7501e+00, -2.7859e+01],
        [-5.5411e+00, -5.4654e+00, -6.6621e+00, -1.2250e+01, -3.5902e+00,
         -7.4759e+00, -8.1465e+00, -1.0560e+01, -5.5277e+00, -6.9953e+00,
         -7.5930e+00, -1.0435e+01, -7.8961e+00, -1.8272e+01],
        [-2.5727e+01,  9.0361e-01, -2.3675e+01, -2.3923e+01, -1.9624e+02,
         -1.9693e+02,  8.6264e+00,  7.1229e+00, -5.1951e+01, -2.0435e+00,
          5.8342e+00, -5.2292e+00, -1.8083e+01, -1.8638e+02],
        [ 5.7155e+00, -2.9250e+01, -9.9773e+00,  1.0362e+01,  3.8512e+00,
         -9.3100e-01, -1.2192e+01, -4.8495e+00, -3.2632e+01, -2.8231e+01,
         -1.5898e+01, -1.3618e+01,  2.0516e+00, -2.7936e+01],
        [-4.6693e-01, -4.1658e+00, -1.7043e+01, -4.1617e+00,  2.9333e+00,
         -1.7420e+00, -9.1148e+00, -2.5143e+00, -4.6704e+00, -6.5160e+00,
         -9.4188e+00, -4.7396e+00, -9.3834e+00, -1.5612e+01],
        [ 4.2293e+00, -4.7999e+01, -1.6119e+01,  1.1660e+00, -1.4109e-01,
         -8.5176e-01, -2.1423e-01,  5.2049e+00, -4.9454e+01, -4.7894e+01,
          9.0468e+00,  5.1917e+00, -5.0276e+00, -2.3003e+01],
        [-1.6958e+01, -1.5929e+02, -1.5924e+02, -1.5650e+01, -6.9345e+01,
         -7.9497e+01,  1.0263e+01,  2.5716e+01, -1.9423e+02, -1.9312e+02,
          2.7775e+01,  8.6534e+00, -4.8295e+01, -9.1569e+01],
        [-3.0664e-01, -6.2986e+01, -2.3877e+01,  2.7060e+01,  1.2242e+00,
         -4.2975e+00, -3.1673e+00, -1.6957e+00, -6.2183e+01, -5.7446e+01,
         -4.1028e+00, -6.3990e+00, -6.4655e+00, -5.7270e+01]], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ -2.6729,  16.3080,   2.8653,  -2.5502,  -2.4520,  -5.9054,   0.4912,
          -2.3315,  -6.5312,  -2.7034,  -5.8973,  -8.6095,  13.1670,  -1.4143],
        [  2.3513, -16.3413,  -2.8702,   2.7539,   2.2038,   5.8520,  -0.3133,
           2.1560,   6.8617,   2.6367,   5.8311,   8.4100, -13.1948,   1.0922]],
       device='cuda:0'))])
xi:  [-168.18655]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 111.36339118612622
W_T_median: -20.375775012858412
W_T_pctile_5: -168.05980515763915
W_T_CVAR_5_pct: -220.7920706172585
Average q (qsum/M+1):  55.29350034652218
Optimal xi:  [-168.18655]
Expected(across Rb) median(across samples) p_equity:  0.2869942812947556
obj fun:  tensor(-1603.6829, device='cuda:0', dtype=torch.float64,
       grad_fn=<MeanBackward0>)
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.5
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       14  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       14  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1  logistic_sigmoid   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 14)     False        None  
0     (14, 14)     False        None  
0      (14, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       14  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       14  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 14)     False        None  
0     (14, 14)     False        None  
0      (14, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
loaded continuation NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[ -12.1400,   -2.7214],
        [   2.7341,   -3.2341],
        [-267.1001,    0.2791],
        [  -0.7877,    4.2216],
        [  -0.7922,    4.2364],
        [   9.6308,   11.2671],
        [  -0.7891,    4.2133],
        [  -0.7926,    4.2402],
        [  -0.7917,    4.2151],
        [  -0.7890,    4.2135],
        [  -0.7944,    4.2439],
        [  -0.7939,    4.2437],
        [  -0.7886,    4.2137],
        [  -0.7925,    4.2145]], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ -51.7059,  -22.0973,  -30.0802,  -17.2519,  -13.6138,   24.4285,
          -19.8847,  -12.7685,  -19.2254,  -19.7668,  -12.2589,  -12.2745,
          -19.8096,  -19.5071],
        [  -2.4290,   -3.2469,   -7.6662,   34.6890,   29.7664, -116.3152,
           37.7320,   28.7554,   37.1245,   38.0622,   27.6535,   28.0821,
           37.6157,   37.4584],
        [   2.0834,    1.4721,    1.3159,  -37.5495,  -33.2383,    4.8252,
          -41.0009,  -31.9038,  -40.2185,  -40.5326,  -31.1172,  -31.1162,
          -40.4923,  -40.4344],
        [   2.2260,    1.8340,    1.3667,  -37.5088,  -32.7330,    3.0617,
          -41.6548,  -31.8293,  -40.1044,  -41.3184,  -30.5069,  -30.7486,
          -41.0037,  -40.6187],
        [   2.1488,    1.5276,    1.3186,  -37.6950,  -33.0831,    4.2755,
          -40.6356,  -32.0500,  -40.0533,  -40.6873,  -31.1207,  -31.3517,
          -40.8326,  -40.2057],
        [   2.0753,    1.5629,    1.3297,  -37.5601,  -33.0999,    4.9312,
          -41.1013,  -31.7372,  -40.5198,  -41.0084,  -30.6730,  -30.6535,
          -40.9609,  -40.3073],
        [   2.2709,    1.7168,    1.3427,  -37.4159,  -32.6125,   -0.8845,
          -41.5336,  -31.3658,  -40.3443,  -41.3668,  -30.7717,  -30.5457,
          -41.0370,  -40.6366],
        [   2.1005,    1.4710,    1.3176,  -37.6541,  -32.9899,    4.7687,
          -40.7806,  -32.1647,  -40.1145,  -40.8052,  -31.1013,  -31.2873,
          -40.7146,  -40.1850],
        [  -3.8301,   -5.2768,    4.3551,   35.4233,   30.8070,   -8.5577,
           39.2380,   29.7535,   38.5817,   39.2186,   28.9053,   28.9960,
           38.9016,   39.0199],
        [ -10.2710,  -13.0700,  -27.0548,   21.1565,   16.3071, -159.8795,
           24.3740,   14.9999,   23.7153,   24.1839,   14.3298,   14.0808,
           24.6651,   23.8751],
        [   2.0699,    1.2669,    1.2961,  -37.6047,  -32.8556,    4.8151,
          -40.7922,  -31.9085,  -40.2630,  -40.6815,  -30.8177,  -30.9924,
          -40.9426,  -40.1035],
        [  -3.1174,   -4.1656,   -1.1128,   34.8004,   29.8779,  -56.1859,
           38.2324,   29.1728,   37.3691,   37.8458,   28.2362,   27.8540,
           38.0496,   37.5772],
        [ -10.4810,  -12.9080,  -27.0806,   20.9749,   15.7970, -165.4336,
           24.3191,   14.7649,   23.1549,   24.0714,   14.0924,   13.7050,
           23.9916,   23.8431],
        [   2.0039,    0.7650,    1.2627,  -37.9780,  -32.8363,    5.0544,
          -40.4994,  -31.8594,  -39.8172,  -40.6836,  -30.8726,  -31.0989,
          -40.5366,  -40.1959]], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ -9.4157,  16.2536, -14.2271, -16.0996, -14.3406, -14.7504, -15.8619,
         -14.0787,  15.9944,   7.2463, -14.1402,  13.7836,   7.6398, -13.2707]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[-2.8555e+01, -5.3759e+00],
        [-1.1431e+01, -6.4730e+00],
        [ 8.6863e+00, -6.8360e+00],
        [-2.8453e+01, -5.3523e+00],
        [-8.4852e+00,  1.7183e+00],
        [-8.4250e+00,  1.7107e+00],
        [ 3.7040e+00, -1.4261e+00],
        [-4.1418e+01, -1.0603e+01],
        [-6.5875e+00, -4.7822e-02],
        [ 5.4849e+00,  1.3361e+00],
        [-7.5988e+01, -1.8321e+01],
        [ 2.4980e+01, -6.0778e+00],
        [ 2.5219e+01,  8.8740e+00],
        [-1.1218e+01,  2.1977e+00]], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-5.4944e+00, -3.4550e+00, -4.7252e+00, -7.1371e+00, -3.6638e+00,
         -6.1209e+00, -1.0739e+01, -5.3294e+00, -2.9418e+00, -2.0361e+00,
         -1.0103e+01, -1.1237e+01, -6.3166e+00, -6.8651e+00],
        [-7.7962e+00, -6.9183e+01, -2.5229e+02, -1.4941e+01, -3.8568e+01,
         -3.5217e+01,  8.4283e+00,  3.0433e+01, -1.2334e+02, -1.4327e+02,
          3.8254e+01,  1.0086e+01, -7.4220e+01, -3.0745e+01],
        [ 7.0631e+01,  1.1574e+00,  2.5708e+00,  6.3469e+01,  1.8285e+02,
          1.8357e+02, -7.1420e+00, -1.8121e+01, -3.4460e+01,  4.1037e+00,
         -7.8769e+01, -9.7248e+00,  7.6618e+00,  2.4915e+02],
        [ 2.9579e+01, -3.8280e+01,  6.6138e-01,  2.1813e+01, -4.2017e+01,
         -4.8958e+01,  4.2736e+00, -2.6440e+01, -3.5725e+01, -5.8409e+01,
          2.0872e+01,  2.7762e+00, -2.6846e+01, -6.7596e+01],
        [-7.8365e+00, -3.6400e+00, -4.7703e+00, -6.9968e+00, -6.2933e+00,
         -6.4485e+00, -1.0746e+01, -5.9677e+00, -4.9384e+00, -5.3929e+00,
         -9.6988e+00, -1.1064e+01, -7.3937e+00, -7.5593e+00],
        [ 3.6805e+00, -2.2346e+01, -1.6644e+01, -6.3740e+00,  3.2178e+00,
          4.4390e+00, -9.4604e+00,  1.8398e+00, -2.2942e+01, -2.6430e+01,
         -8.0284e+00, -7.0212e+00, -8.9134e-01, -3.6244e+01],
        [-1.0612e+01, -7.1646e+00, -7.0609e+00, -1.4314e+01, -1.2113e+01,
         -8.6686e+00, -8.0832e+00, -1.6560e+01, -1.1989e+01, -1.1999e+01,
         -7.4581e+00, -1.2120e+01, -7.7501e+00, -2.7859e+01],
        [-5.5411e+00, -5.4654e+00, -6.6621e+00, -1.2250e+01, -3.5902e+00,
         -7.4759e+00, -8.1465e+00, -1.0560e+01, -5.5277e+00, -6.9953e+00,
         -7.5930e+00, -1.0435e+01, -7.8961e+00, -1.8272e+01],
        [-2.5727e+01,  9.0361e-01, -2.3675e+01, -2.3923e+01, -1.9624e+02,
         -1.9693e+02,  8.6264e+00,  7.1229e+00, -5.1951e+01, -2.0435e+00,
          5.8342e+00, -5.2292e+00, -1.8083e+01, -1.8638e+02],
        [ 5.7155e+00, -2.9250e+01, -9.9773e+00,  1.0362e+01,  3.8512e+00,
         -9.3100e-01, -1.2192e+01, -4.8495e+00, -3.2632e+01, -2.8231e+01,
         -1.5898e+01, -1.3618e+01,  2.0516e+00, -2.7936e+01],
        [-4.6693e-01, -4.1658e+00, -1.7043e+01, -4.1617e+00,  2.9333e+00,
         -1.7420e+00, -9.1148e+00, -2.5143e+00, -4.6704e+00, -6.5160e+00,
         -9.4188e+00, -4.7396e+00, -9.3834e+00, -1.5612e+01],
        [ 4.2293e+00, -4.7999e+01, -1.6119e+01,  1.1660e+00, -1.4109e-01,
         -8.5176e-01, -2.1423e-01,  5.2049e+00, -4.9454e+01, -4.7894e+01,
          9.0468e+00,  5.1917e+00, -5.0276e+00, -2.3003e+01],
        [-1.6958e+01, -1.5929e+02, -1.5924e+02, -1.5650e+01, -6.9345e+01,
         -7.9497e+01,  1.0263e+01,  2.5716e+01, -1.9423e+02, -1.9312e+02,
          2.7775e+01,  8.6534e+00, -4.8295e+01, -9.1569e+01],
        [-3.0664e-01, -6.2986e+01, -2.3877e+01,  2.7060e+01,  1.2242e+00,
         -4.2975e+00, -3.1673e+00, -1.6957e+00, -6.2183e+01, -5.7446e+01,
         -4.1028e+00, -6.3990e+00, -6.4655e+00, -5.7270e+01]], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ -2.6729,  16.3080,   2.8653,  -2.5502,  -2.4520,  -5.9054,   0.4912,
          -2.3315,  -6.5312,  -2.7034,  -5.8973,  -8.6095,  13.1670,  -1.4143],
        [  2.3513, -16.3413,  -2.8702,   2.7539,   2.2038,   5.8520,  -0.3133,
           2.1560,   6.8617,   2.6367,   5.8311,   8.4100, -13.1948,   1.0922]],
       device='cuda:0'))])
loaded xi:  -168.18655
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1576.8182150775267
W_T_median: 1136.7449346433505
W_T_pctile_5: -127.64084552288806
W_T_CVAR_5_pct: -295.72244238283764
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1515.3955382450401
Current xi:  [-75.62057]
objective value function right now is: -1515.3955382450401
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1521.1346830136372
Current xi:  [-17.850267]
objective value function right now is: -1521.1346830136372
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1536.9777809077991
Current xi:  [17.720167]
objective value function right now is: -1536.9777809077991
8.0% of gradient descent iterations done. Method = Adam
new min fval:  -1543.8947082981163
Current xi:  [32.76681]
objective value function right now is: -1543.8947082981163
10.0% of gradient descent iterations done. Method = Adam
Current xi:  [31.457384]
objective value function right now is: -1535.3211921803245
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [33.092373]
objective value function right now is: -1538.9037648197511
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [35.900608]
objective value function right now is: -1542.350868324573
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [34.68701]
objective value function right now is: -1533.8830833550599
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [34.424652]
objective value function right now is: -1536.1123568862351
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [33.88579]
objective value function right now is: -1531.7210436576443
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [36.66476]
objective value function right now is: -1539.8553085224326
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [35.719883]
objective value function right now is: -1536.2629064403484
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [36.159035]
objective value function right now is: -1541.5215130916229
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [38.019524]
objective value function right now is: -1543.745785725069
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [35.150425]
objective value function right now is: -1535.5680410724103
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [23.018482]
objective value function right now is: -1441.1687376993923
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [35.30682]
objective value function right now is: -1538.857155244781
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [33.1993]
objective value function right now is: -1510.873622444081
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [37.150955]
objective value function right now is: -1540.8752370422437
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [39.676723]
objective value function right now is: -1535.34112411079
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [40.358204]
objective value function right now is: -1536.2089415458174
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [38.16316]
objective value function right now is: -1542.1174844146376
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [36.693512]
objective value function right now is: -1534.219867909794
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [41.361034]
objective value function right now is: -1537.5313578945318
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [38.2362]
objective value function right now is: -1538.3975560309775
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [39.910473]
objective value function right now is: -1543.6788643377095
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [41.853214]
objective value function right now is: -1541.9982839987138
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [45.548885]
objective value function right now is: -1533.9004379127603
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [37.519726]
objective value function right now is: -1534.6459825583138
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [39.888527]
objective value function right now is: -1543.8647106345252
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [37.692654]
objective value function right now is: -1529.3982867090592
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [34.66614]
objective value function right now is: -1542.5569327843398
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [41.14947]
objective value function right now is: -1529.6212474822669
68.0% of gradient descent iterations done. Method = Adam
new min fval:  -1546.4202950295273
Current xi:  [39.05789]
objective value function right now is: -1546.4202950295273
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [40.38181]
objective value function right now is: -1538.047504574627
72.0% of gradient descent iterations done. Method = Adam
new min fval:  -1546.8311315370897
Current xi:  [40.47489]
objective value function right now is: -1546.8311315370897
74.0% of gradient descent iterations done. Method = Adam
Current xi:  [40.603947]
objective value function right now is: -1546.5289708572318
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [42.44404]
objective value function right now is: -1533.68905414226
78.0% of gradient descent iterations done. Method = Adam
new min fval:  -1549.0684704656267
Current xi:  [43.001293]
objective value function right now is: -1549.0684704656267
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [41.368694]
objective value function right now is: -1547.6257081739261
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [41.68204]
objective value function right now is: -1546.5108740705532
84.0% of gradient descent iterations done. Method = Adam
new min fval:  -1550.1439885875634
Current xi:  [46.699345]
objective value function right now is: -1550.1439885875634
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [43.90849]
objective value function right now is: -1547.342754391916
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [39.604317]
objective value function right now is: -1535.7989581360575
new min fval from sgd:  -1554.0419355579065
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [51.63138]
objective value function right now is: -1554.0419355579065
new min fval from sgd:  -1554.1523752344194
new min fval from sgd:  -1555.396787420005
new min fval from sgd:  -1555.5507677937196
new min fval from sgd:  -1555.7177590514236
new min fval from sgd:  -1555.8664365727757
new min fval from sgd:  -1555.9745141243254
new min fval from sgd:  -1556.8235485717207
new min fval from sgd:  -1557.5703231887212
new min fval from sgd:  -1558.4802851790562
new min fval from sgd:  -1558.8648943650617
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [55.308468]
objective value function right now is: -1549.253636923771
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [52.27795]
objective value function right now is: -1544.345846563383
new min fval from sgd:  -1559.7750898833829
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [34.323425]
objective value function right now is: -1534.3361790486113
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [-82.791176]
objective value function right now is: -1455.3076439605945
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [-69.30992]
objective value function right now is: -1494.8249222925338
min fval:  -1559.7750898833829
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-25.5809,  -2.2690],
        [  0.8468,   6.8972],
        [-93.7508,   2.4031],
        [ -5.9738,   5.8422],
        [ -5.9797,   5.8473],
        [ -6.2037,  24.3541],
        [ -5.9691,   5.8380],
        [ -5.9804,   5.8486],
        [ -5.9704,   5.8386],
        [ -5.9694,   5.8379],
        [ -5.9822,   5.8507],
        [ -5.9815,   5.8498],
        [ -5.9697,   5.8384],
        [ -5.9701,   5.8392]], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-179.8759, -196.7117,  -30.0617,   18.2071,   21.0345, -220.5165,
           16.0010,   21.6777,   16.5360,   16.0942,   22.0855,   22.0481,
           16.0826,   16.3210],
        [ -13.2735, -182.3688,    1.1321,   12.8261,    7.7664, -409.1212,
           15.9489,    6.7264,   15.3190,   16.2664,    5.6048,    6.0137,
           15.8375,   15.6578],
        [   2.7267,   -1.8586,    1.0680,  -62.0298,  -57.8978,    9.6715,
          -65.3526,  -56.6152,  -64.5893,  -64.8838,  -55.8893,  -55.8652,
          -64.8515,  -64.8130],
        [   2.5322,    5.1493,    1.2305,  -63.3011,  -58.6851,    1.9910,
          -67.3125,  -57.8271,  -65.7880,  -66.9787,  -56.5645,  -56.7823,
          -66.6794,  -66.3072],
        [   2.6551,   -0.5061,    1.1144,  -62.5993,  -58.1703,    9.7664,
          -65.4056,  -57.1913,  -64.8447,  -65.4571,  -56.3239,  -56.5313,
          -65.6115,  -65.0039],
        [   2.5527,    1.7762,    1.4323,  -62.3221,  -58.0415,    9.2106,
          -65.7312,  -56.7325,  -65.1707,  -65.6381,  -55.7302,  -55.6869,
          -65.5997,  -64.9655],
        [   2.5808,    5.1571,    0.7117,  -63.1315,  -58.4943,    2.3815,
          -67.1125,  -57.2956,  -65.9493,  -66.9480,  -56.7613,  -56.5114,
          -66.6328,  -66.2456],
        [   2.7313,   -1.8381,    1.0293,  -62.1450,  -57.6603,    9.6803,
          -65.1422,  -56.8875,  -64.4959,  -65.1663,  -55.8851,  -56.0480,
          -65.0841,  -64.5730],
        [  -4.4857,   -4.9574,   11.8631,   58.0810,   53.5818,  -11.4911,
           61.7980,   52.5546,   61.1400,   61.7664,   51.7616,   51.8156,
           61.4775,   61.5802],
        [-311.1187,   -3.1534,  -45.4281,   34.5576,   30.2944, -276.6481,
           37.4470,   29.2177,   36.9107,   37.3232,   28.6879,   28.4917,
           37.6956,   37.1362],
        [   2.8147,   -2.0938,    0.5445,  -61.9004,  -57.3237,    9.5936,
          -64.9628,  -56.4272,  -64.4522,  -64.8507,  -55.3965,  -55.5466,
          -65.1215,  -64.2994],
        [ -42.2850,   -5.5591,  -13.3143,   73.2964,   68.4743,  -13.5302,
           76.6359,   67.7837,   75.7989,   76.2689,   66.8875,   66.5052,
           76.4766,   76.0140],
        [  -1.7041,   -0.8884,  -89.0452,   58.3701,   53.5097, -127.0497,
           61.5205,   52.5756,   60.4407,   61.3061,   51.9659,   51.6088,
           61.2049,   61.1234],
        [   2.9514,   -7.8124,   -2.7339,  -61.9716,  -57.0059,   19.3064,
          -64.3823,  -56.0570,  -63.7036,  -64.5525,  -55.1217,  -55.3145,
          -64.4323,  -64.0699]], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-31.4578, -29.0612, -19.1343, -25.1739, -20.2739, -21.0854, -24.4594,
         -19.0988,  15.9472,  49.6748, -18.5550,  30.4260,  28.9972, -12.2838]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[-69.3671, -20.2927],
        [-24.5212, -10.3048],
        [ 26.8416, -19.6499],
        [-67.5287, -21.2866],
        [  1.2377,   4.3352],
        [  1.2265,   4.3252],
        [ -0.7958,  -4.7281],
        [-42.2077, -17.2026],
        [  1.8450,   4.3617],
        [  6.0544,   4.2683],
        [-58.5360, -17.7660],
        [  6.1624,   3.0737],
        [ 25.9423,  20.2869],
        [  1.2908,   4.3170]], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-6.4329e+00, -2.3006e+01, -8.2009e+00, -9.0836e+00, -1.5267e+01,
         -1.7639e+01, -1.4190e+01,  2.3088e+00, -1.5827e+01, -9.8645e+00,
         -1.8915e+01, -4.6165e+01, -3.5291e+01, -1.8354e+01],
        [-7.7962e+00, -6.9183e+01, -2.5229e+02, -1.4941e+01, -3.8568e+01,
         -3.5217e+01,  8.4283e+00,  3.0433e+01, -1.2334e+02, -1.4327e+02,
          3.8254e+01,  1.0086e+01, -7.4220e+01, -3.0745e+01],
        [ 4.6782e+01, -5.2018e+00, -2.8865e+00,  3.6997e+01,  2.8445e+02,
          2.8526e+02, -1.3025e+01, -2.1565e+00,  9.0683e+01, -1.0404e+00,
         -1.9243e+01,  3.7006e+00,  1.2798e+01,  3.2976e+02],
        [ 3.1040e+01, -3.3954e+01, -2.4373e+00,  2.6496e+01, -2.0687e+02,
         -2.1257e+02,  1.9622e+00, -2.2317e+01, -1.9901e+02, -1.1679e+02,
          2.8401e+01, -1.7003e+02, -6.6629e+01, -2.2955e+02],
        [-1.6599e+01, -4.3777e+00, -1.0836e+00, -1.5982e+01, -1.6704e+01,
         -1.6740e+01, -6.9649e+00,  1.3262e+01, -1.3526e+01, -3.8117e-01,
         -2.5348e+01, -1.9192e+01, -3.5227e+01, -1.8063e+01],
        [ 3.6805e+00, -2.2344e+01, -1.6683e+01, -6.3740e+00,  2.5139e+00,
          3.7366e+00, -1.1547e+01,  1.8831e+00, -2.3004e+01, -2.6580e+01,
         -8.0284e+00, -9.4645e+00, -3.3264e+00, -3.6741e+01],
        [-1.1078e+01, -2.4489e+01, -5.9282e-01, -1.4537e+01, -2.4821e+01,
         -2.1611e+01, -1.5656e+00, -3.7697e+01, -1.9059e+01, -6.3432e-01,
         -9.4597e+00, -1.1597e+00, -2.5806e+00, -3.9973e+01],
        [-6.7992e+00, -1.4186e+01, -2.9925e+00, -1.3642e+01, -1.4626e+01,
         -1.8670e+01, -4.4203e+00, -2.9089e+01, -1.3510e+01,  2.9235e+00,
         -1.3482e+01, -5.3109e+00, -1.9473e+00, -2.8938e+01],
        [-9.6323e+00,  5.5925e+00, -1.7558e+01,  3.0154e+00, -2.7070e+02,
         -2.7121e+02,  1.5322e+01,  1.6723e+01, -1.4301e+02, -9.7227e-01,
          8.8701e+00, -2.5478e+01, -9.1847e+00, -3.0825e+02],
        [ 5.7155e+00, -2.9247e+01, -1.1611e+01,  1.0362e+01,  3.0538e+00,
         -1.7285e+00, -1.3825e+01, -4.4859e+00, -3.3059e+01, -2.9351e+01,
         -1.5898e+01, -1.4213e+01,  1.0970e+00, -2.8727e+01],
        [-4.6693e-01, -4.1238e+00, -1.7237e+01, -4.1617e+00,  1.8368e+00,
         -2.8382e+00, -9.8822e+00, -2.4325e+00, -4.8409e+00, -6.5397e+00,
         -9.4188e+00, -5.6772e+00, -1.1166e+01, -1.6677e+01],
        [ 4.2293e+00, -4.7996e+01, -1.9664e+01,  1.1660e+00, -4.6930e+00,
         -5.4116e+00, -7.2551e+00,  5.3506e+00, -5.5801e+01, -5.1648e+01,
          9.0468e+00, -9.4696e-01, -1.1142e+01, -2.7108e+01],
        [-1.6958e+01, -1.5929e+02, -1.5924e+02, -1.5650e+01, -6.9345e+01,
         -7.9497e+01,  1.0263e+01,  2.5716e+01, -1.9423e+02, -1.9312e+02,
          2.7775e+01,  8.6534e+00, -4.8295e+01, -9.1569e+01],
        [-3.0664e-01, -6.2986e+01, -2.3896e+01,  2.7060e+01,  1.1561e+00,
         -4.3654e+00, -3.9822e+00, -1.6953e+00, -6.2188e+01, -5.7459e+01,
         -4.1028e+00, -7.3163e+00, -7.3835e+00, -5.7308e+01]], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ -0.0677,  16.3080,   0.3217,  26.6190,  -8.3260,  -5.3780,  11.4556,
           9.6718,  -4.9540,  -1.0128,  -5.6390,  -1.8295,  13.1670,  -0.9253],
        [ -0.2538, -16.3413,  -0.3266, -26.4141,   8.0777,   5.3246, -11.2778,
          -9.8473,   5.2903,   0.9460,   5.5728,   1.6300, -13.1948,   0.6031]],
       device='cuda:0'))])
xi:  [46.440544]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 616.2325449770198
W_T_median: 261.61297500410194
W_T_pctile_5: 48.43852508698932
W_T_CVAR_5_pct: -54.84986655284655
Average q (qsum/M+1):  52.08874117943548
Optimal xi:  [46.440544]
Expected(across Rb) median(across samples) p_equity:  0.34336787462234497
obj fun:  tensor(-1559.7751, device='cuda:0', dtype=torch.float64,
       grad_fn=<MeanBackward0>)
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.0
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       14  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       14  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1  logistic_sigmoid   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 14)     False        None  
0     (14, 14)     False        None  
0      (14, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       14  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       14  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 14)     False        None  
0     (14, 14)     False        None  
0      (14, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
loaded continuation NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-25.5809,  -2.2690],
        [  0.8468,   6.8972],
        [-93.7508,   2.4031],
        [ -5.9738,   5.8422],
        [ -5.9797,   5.8473],
        [ -6.2037,  24.3541],
        [ -5.9691,   5.8380],
        [ -5.9804,   5.8486],
        [ -5.9704,   5.8386],
        [ -5.9694,   5.8379],
        [ -5.9822,   5.8507],
        [ -5.9815,   5.8498],
        [ -5.9697,   5.8384],
        [ -5.9701,   5.8392]], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-179.8759, -196.7117,  -30.0617,   18.2071,   21.0345, -220.5165,
           16.0010,   21.6777,   16.5360,   16.0942,   22.0855,   22.0481,
           16.0826,   16.3210],
        [ -13.2735, -182.3688,    1.1321,   12.8261,    7.7664, -409.1212,
           15.9489,    6.7264,   15.3190,   16.2664,    5.6048,    6.0137,
           15.8375,   15.6578],
        [   2.7267,   -1.8586,    1.0680,  -62.0298,  -57.8978,    9.6715,
          -65.3526,  -56.6152,  -64.5893,  -64.8838,  -55.8893,  -55.8652,
          -64.8515,  -64.8130],
        [   2.5322,    5.1493,    1.2305,  -63.3011,  -58.6851,    1.9910,
          -67.3125,  -57.8271,  -65.7880,  -66.9787,  -56.5645,  -56.7823,
          -66.6794,  -66.3072],
        [   2.6551,   -0.5061,    1.1144,  -62.5993,  -58.1703,    9.7664,
          -65.4056,  -57.1913,  -64.8447,  -65.4571,  -56.3239,  -56.5313,
          -65.6115,  -65.0039],
        [   2.5527,    1.7762,    1.4323,  -62.3221,  -58.0415,    9.2106,
          -65.7312,  -56.7325,  -65.1707,  -65.6381,  -55.7302,  -55.6869,
          -65.5997,  -64.9655],
        [   2.5808,    5.1571,    0.7117,  -63.1315,  -58.4943,    2.3815,
          -67.1125,  -57.2956,  -65.9493,  -66.9480,  -56.7613,  -56.5114,
          -66.6328,  -66.2456],
        [   2.7313,   -1.8381,    1.0293,  -62.1450,  -57.6603,    9.6803,
          -65.1422,  -56.8875,  -64.4959,  -65.1663,  -55.8851,  -56.0480,
          -65.0841,  -64.5730],
        [  -4.4857,   -4.9574,   11.8631,   58.0810,   53.5818,  -11.4911,
           61.7980,   52.5546,   61.1400,   61.7664,   51.7616,   51.8156,
           61.4775,   61.5802],
        [-311.1187,   -3.1534,  -45.4281,   34.5576,   30.2944, -276.6481,
           37.4470,   29.2177,   36.9107,   37.3232,   28.6879,   28.4917,
           37.6956,   37.1362],
        [   2.8147,   -2.0938,    0.5445,  -61.9004,  -57.3237,    9.5936,
          -64.9628,  -56.4272,  -64.4522,  -64.8507,  -55.3965,  -55.5466,
          -65.1215,  -64.2994],
        [ -42.2850,   -5.5591,  -13.3143,   73.2964,   68.4743,  -13.5302,
           76.6359,   67.7837,   75.7989,   76.2689,   66.8875,   66.5052,
           76.4766,   76.0140],
        [  -1.7041,   -0.8884,  -89.0452,   58.3701,   53.5097, -127.0497,
           61.5205,   52.5756,   60.4407,   61.3061,   51.9659,   51.6088,
           61.2049,   61.1234],
        [   2.9514,   -7.8124,   -2.7339,  -61.9716,  -57.0059,   19.3064,
          -64.3823,  -56.0570,  -63.7036,  -64.5525,  -55.1217,  -55.3145,
          -64.4323,  -64.0699]], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-31.4578, -29.0612, -19.1343, -25.1739, -20.2739, -21.0854, -24.4594,
         -19.0988,  15.9472,  49.6748, -18.5550,  30.4260,  28.9972, -12.2838]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[-69.3671, -20.2927],
        [-24.5212, -10.3048],
        [ 26.8416, -19.6499],
        [-67.5287, -21.2866],
        [  1.2377,   4.3352],
        [  1.2265,   4.3252],
        [ -0.7958,  -4.7281],
        [-42.2077, -17.2026],
        [  1.8450,   4.3617],
        [  6.0544,   4.2683],
        [-58.5360, -17.7660],
        [  6.1624,   3.0737],
        [ 25.9423,  20.2869],
        [  1.2908,   4.3170]], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-6.4329e+00, -2.3006e+01, -8.2009e+00, -9.0836e+00, -1.5267e+01,
         -1.7639e+01, -1.4190e+01,  2.3088e+00, -1.5827e+01, -9.8645e+00,
         -1.8915e+01, -4.6165e+01, -3.5291e+01, -1.8354e+01],
        [-7.7962e+00, -6.9183e+01, -2.5229e+02, -1.4941e+01, -3.8568e+01,
         -3.5217e+01,  8.4283e+00,  3.0433e+01, -1.2334e+02, -1.4327e+02,
          3.8254e+01,  1.0086e+01, -7.4220e+01, -3.0745e+01],
        [ 4.6782e+01, -5.2018e+00, -2.8865e+00,  3.6997e+01,  2.8445e+02,
          2.8526e+02, -1.3025e+01, -2.1565e+00,  9.0683e+01, -1.0404e+00,
         -1.9243e+01,  3.7006e+00,  1.2798e+01,  3.2976e+02],
        [ 3.1040e+01, -3.3954e+01, -2.4373e+00,  2.6496e+01, -2.0687e+02,
         -2.1257e+02,  1.9622e+00, -2.2317e+01, -1.9901e+02, -1.1679e+02,
          2.8401e+01, -1.7003e+02, -6.6629e+01, -2.2955e+02],
        [-1.6599e+01, -4.3777e+00, -1.0836e+00, -1.5982e+01, -1.6704e+01,
         -1.6740e+01, -6.9649e+00,  1.3262e+01, -1.3526e+01, -3.8117e-01,
         -2.5348e+01, -1.9192e+01, -3.5227e+01, -1.8063e+01],
        [ 3.6805e+00, -2.2344e+01, -1.6683e+01, -6.3740e+00,  2.5139e+00,
          3.7366e+00, -1.1547e+01,  1.8831e+00, -2.3004e+01, -2.6580e+01,
         -8.0284e+00, -9.4645e+00, -3.3264e+00, -3.6741e+01],
        [-1.1078e+01, -2.4489e+01, -5.9282e-01, -1.4537e+01, -2.4821e+01,
         -2.1611e+01, -1.5656e+00, -3.7697e+01, -1.9059e+01, -6.3432e-01,
         -9.4597e+00, -1.1597e+00, -2.5806e+00, -3.9973e+01],
        [-6.7992e+00, -1.4186e+01, -2.9925e+00, -1.3642e+01, -1.4626e+01,
         -1.8670e+01, -4.4203e+00, -2.9089e+01, -1.3510e+01,  2.9235e+00,
         -1.3482e+01, -5.3109e+00, -1.9473e+00, -2.8938e+01],
        [-9.6323e+00,  5.5925e+00, -1.7558e+01,  3.0154e+00, -2.7070e+02,
         -2.7121e+02,  1.5322e+01,  1.6723e+01, -1.4301e+02, -9.7227e-01,
          8.8701e+00, -2.5478e+01, -9.1847e+00, -3.0825e+02],
        [ 5.7155e+00, -2.9247e+01, -1.1611e+01,  1.0362e+01,  3.0538e+00,
         -1.7285e+00, -1.3825e+01, -4.4859e+00, -3.3059e+01, -2.9351e+01,
         -1.5898e+01, -1.4213e+01,  1.0970e+00, -2.8727e+01],
        [-4.6693e-01, -4.1238e+00, -1.7237e+01, -4.1617e+00,  1.8368e+00,
         -2.8382e+00, -9.8822e+00, -2.4325e+00, -4.8409e+00, -6.5397e+00,
         -9.4188e+00, -5.6772e+00, -1.1166e+01, -1.6677e+01],
        [ 4.2293e+00, -4.7996e+01, -1.9664e+01,  1.1660e+00, -4.6930e+00,
         -5.4116e+00, -7.2551e+00,  5.3506e+00, -5.5801e+01, -5.1648e+01,
          9.0468e+00, -9.4696e-01, -1.1142e+01, -2.7108e+01],
        [-1.6958e+01, -1.5929e+02, -1.5924e+02, -1.5650e+01, -6.9345e+01,
         -7.9497e+01,  1.0263e+01,  2.5716e+01, -1.9423e+02, -1.9312e+02,
          2.7775e+01,  8.6534e+00, -4.8295e+01, -9.1569e+01],
        [-3.0664e-01, -6.2986e+01, -2.3896e+01,  2.7060e+01,  1.1561e+00,
         -4.3654e+00, -3.9822e+00, -1.6953e+00, -6.2188e+01, -5.7459e+01,
         -4.1028e+00, -7.3163e+00, -7.3835e+00, -5.7308e+01]], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ -0.0677,  16.3080,   0.3217,  26.6190,  -8.3260,  -5.3780,  11.4556,
           9.6718,  -4.9540,  -1.0128,  -5.6390,  -1.8295,  13.1670,  -0.9253],
        [ -0.2538, -16.3413,  -0.3266, -26.4141,   8.0777,   5.3246, -11.2778,
          -9.8473,   5.2903,   0.9460,   5.5728,   1.6300, -13.1948,   0.6031]],
       device='cuda:0'))])
loaded xi:  46.440544
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1576.8182150775267
W_T_median: 1136.7449346433505
W_T_pctile_5: -127.64084552288806
W_T_CVAR_5_pct: -295.72244238283764
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1472.821226945337
Current xi:  [69.03499]
objective value function right now is: -1472.821226945337
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1504.6660893504682
Current xi:  [65.69505]
objective value function right now is: -1504.6660893504682
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1536.1898685655758
Current xi:  [89.90772]
objective value function right now is: -1536.1898685655758
8.0% of gradient descent iterations done. Method = Adam
Current xi:  [94.57315]
objective value function right now is: -1518.1083016032237
10.0% of gradient descent iterations done. Method = Adam
Current xi:  [56.413616]
objective value function right now is: -1464.086414183367
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [26.699438]
objective value function right now is: -1464.439999996305
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [27.140856]
objective value function right now is: -1456.3974243431958
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [25.816837]
objective value function right now is: -1456.8611544472117
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [29.896368]
objective value function right now is: -1472.7917408492729
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [28.84354]
objective value function right now is: -1471.6317361959927
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [25.967339]
objective value function right now is: -1468.8566742874286
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [27.7362]
objective value function right now is: -1473.3608217129063
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [27.322273]
objective value function right now is: -1473.504920346459
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [27.553621]
objective value function right now is: -1476.3661662254358
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [27.694647]
objective value function right now is: -1471.0070271441814
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [27.99707]
objective value function right now is: -1472.1846504135274
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [25.629698]
objective value function right now is: -1472.3003475144658
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [29.499887]
objective value function right now is: -1472.1053764183466
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [27.416336]
objective value function right now is: -1462.4171378416893
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [26.738977]
objective value function right now is: -1462.4717099323711
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [25.102558]
objective value function right now is: -1470.2986561309865
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [25.94482]
objective value function right now is: -1470.9077208116014
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [27.40644]
objective value function right now is: -1475.7435560318856
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [28.37622]
objective value function right now is: -1472.4768613138535
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [27.823935]
objective value function right now is: -1474.0033260541743
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [27.794548]
objective value function right now is: -1471.8801985768866
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [25.95389]
objective value function right now is: -1470.488798793322
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [27.704931]
objective value function right now is: -1475.2167923088618
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [28.899132]
objective value function right now is: -1475.4998308830402
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [25.803082]
objective value function right now is: -1474.5090110375106
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [27.907831]
objective value function right now is: -1467.4964407120979
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [24.880512]
objective value function right now is: -1465.628214040953
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [28.406273]
objective value function right now is: -1473.008346324325
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [29.342884]
objective value function right now is: -1468.741581058151
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [26.410788]
objective value function right now is: -1468.2640238518475
72.0% of gradient descent iterations done. Method = Adam
Current xi:  [29.12489]
objective value function right now is: -1471.4861891567032
74.0% of gradient descent iterations done. Method = Adam
Current xi:  [27.257149]
objective value function right now is: -1469.2740494349516
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [25.44533]
objective value function right now is: -1473.843072900317
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [28.217138]
objective value function right now is: -1474.171023413253
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [25.282877]
objective value function right now is: -1463.4891402407704
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [27.115396]
objective value function right now is: -1476.584852985451
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [27.28692]
objective value function right now is: -1471.832713085866
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [28.34777]
objective value function right now is: -1471.5743348280275
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [27.349457]
objective value function right now is: -1475.7017010581972
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [26.91291]
objective value function right now is: -1459.3344234089961
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [26.975088]
objective value function right now is: -1470.7275668177224
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [26.719217]
objective value function right now is: -1462.196316743922
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [25.87956]
objective value function right now is: -1467.9655950351137
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [26.634634]
objective value function right now is: -1472.898396731217
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [27.80757]
objective value function right now is: -1471.0488854092196
min fval:  -1491.2390531055146
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-26.2687,  -2.0638],
        [ -0.4209,   6.3491],
        [-97.3478,   2.8981],
        [ -7.4550,   5.9354],
        [ -7.4621,   5.9403],
        [ -9.7337,  21.1128],
        [ -7.4506,   5.9318],
        [ -7.4644,   5.9416],
        [ -7.4508,   5.9322],
        [ -7.4503,   5.9319],
        [ -7.4671,   5.9437],
        [ -7.4652,   5.9432],
        [ -7.4501,   5.9317],
        [ -7.4520,   5.9332]], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-1.7930e+02, -2.1383e+02, -3.0033e+01,  1.7246e+01,  2.0061e+01,
         -2.3145e+02,  1.5055e+01,  2.0702e+01,  1.5583e+01,  1.5144e+01,
          2.1109e+01,  2.1066e+01,  1.5134e+01,  1.5370e+01],
        [-1.4795e+01, -1.9797e+02,  5.5993e+00,  1.0849e+01,  5.7691e+00,
         -4.2368e+02,  1.3991e+01,  4.7247e+00,  1.3352e+01,  1.4304e+01,
          3.6020e+00,  4.0049e+00,  1.3877e+01,  1.3693e+01],
        [ 3.1161e+00, -2.1065e+00,  1.4019e+00, -6.3008e+01, -5.8884e+01,
          1.1552e+01, -6.6324e+01, -5.7604e+01, -6.5562e+01, -6.5855e+01,
         -5.6881e+01, -5.6855e+01, -6.5823e+01, -6.5786e+01],
        [ 2.9124e+00,  5.5728e+00,  1.6501e+00, -6.3827e+01, -5.9218e+01,
          3.6989e+00, -6.7833e+01, -5.8363e+01, -6.6308e+01, -6.7499e+01,
         -5.7103e+01, -5.7319e+01, -6.7199e+01, -6.6829e+01],
        [ 3.0481e+00, -9.8272e-02,  1.4868e+00, -6.3415e+01, -5.8995e+01,
          1.0944e+01, -6.6217e+01, -5.8018e+01, -6.5657e+01, -6.6269e+01,
         -5.7153e+01, -5.7359e+01, -6.6422e+01, -6.5817e+01],
        [ 2.9084e+00,  3.7759e+00,  1.7463e+00, -6.2463e+01, -5.8188e+01,
          9.8358e+00, -6.5873e+01, -5.6881e+01, -6.5311e+01, -6.5779e+01,
         -5.5881e+01, -5.5835e+01, -6.5740e+01, -6.5108e+01],
        [ 2.9613e+00,  5.6153e+00,  1.1404e+00, -6.3672e+01, -5.9042e+01,
          4.1157e+00, -6.7650e+01, -5.7846e+01, -6.6486e+01, -6.7485e+01,
         -5.7315e+01, -5.7063e+01, -6.7169e+01, -6.6785e+01],
        [ 3.1225e+00, -2.0792e+00,  1.3670e+00, -6.3119e+01, -5.8642e+01,
          1.1556e+01, -6.6110e+01, -5.7872e+01, -6.5464e+01, -6.6134e+01,
         -5.6872e+01, -5.7034e+01, -6.6051e+01, -6.5542e+01],
        [-5.2201e+00, -5.0343e+00,  1.1677e+01,  5.8975e+01,  5.4478e+01,
         -1.1948e+01,  6.2692e+01,  5.3450e+01,  6.2033e+01,  6.2659e+01,
          5.2659e+01,  5.2712e+01,  6.2371e+01,  6.2475e+01],
        [-3.2220e+02, -3.0689e+00, -4.5434e+01,  3.7747e+01,  3.3529e+01,
         -2.7599e+02,  4.0585e+01,  3.2468e+01,  4.0069e+01,  4.0467e+01,
          3.1945e+01,  3.1748e+01,  4.0843e+01,  4.0287e+01],
        [ 3.2046e+00, -2.4377e+00,  8.7298e-01, -6.2896e+01, -5.8327e+01,
          1.1515e+01, -6.5952e+01, -5.7433e+01, -6.5442e+01, -6.5839e+01,
         -5.6405e+01, -5.6554e+01, -6.6110e+01, -6.5290e+01],
        [-4.2510e+01, -6.0632e+00, -1.9322e+01,  7.3445e+01,  6.8622e+01,
         -1.4177e+01,  7.6788e+01,  6.7929e+01,  7.5951e+01,  7.6420e+01,
          6.7032e+01,  6.6650e+01,  7.6629e+01,  7.6165e+01],
        [-2.0171e+00, -1.6323e+00, -9.2482e+01,  5.7941e+01,  5.3098e+01,
         -1.2442e+02,  6.1072e+01,  5.2168e+01,  6.0003e+01,  6.0861e+01,
          5.1560e+01,  5.1205e+01,  6.0762e+01,  6.0681e+01],
        [ 3.4483e+00, -5.9256e+00, -2.0545e+00, -6.2745e+01, -5.7783e+01,
          2.0720e+01, -6.5157e+01, -5.6834e+01, -6.4478e+01, -6.5326e+01,
         -5.5900e+01, -5.6092e+01, -6.5207e+01, -6.4844e+01]], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-29.1539, -28.9216, -19.6609, -25.5311, -20.5862, -21.2728, -24.7599,
         -19.6251,  15.2743,  52.2765, -19.1256,  32.3667,  28.6171, -11.9016]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[-70.2052, -19.3405],
        [-24.9526, -11.0448],
        [ 26.9712, -21.2673],
        [-65.1959, -23.4524],
        [  1.7946,   4.0861],
        [  1.8891,   4.1173],
        [  1.0806,  -2.9891],
        [-40.1958, -19.1811],
        [  1.9056,   4.3690],
        [  8.1660,   4.2639],
        [-48.6021, -27.1965],
        [  7.5501,   3.6825],
        [ 29.0734,  16.9538],
        [  1.6161,   4.0162]], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-6.4329e+00, -2.3006e+01, -8.2008e+00, -9.0836e+00, -1.5267e+01,
         -1.7639e+01, -1.4190e+01,  2.3088e+00, -1.5827e+01, -9.8645e+00,
         -1.8915e+01, -4.6165e+01, -3.5291e+01, -1.8354e+01],
        [-7.7962e+00, -6.9183e+01, -2.5229e+02, -1.4941e+01, -3.8568e+01,
         -3.5217e+01,  8.4283e+00,  3.0433e+01, -1.2334e+02, -1.4327e+02,
          3.8254e+01,  1.0086e+01, -7.4220e+01, -3.0745e+01],
        [ 4.4511e+01, -1.3164e+01, -2.6261e+00,  2.8558e+01,  2.8296e+02,
          2.8360e+02, -1.2745e+01, -8.6179e+00,  8.9755e+01,  1.7373e+00,
         -2.0461e+01,  5.9537e+00,  1.0599e+01,  3.2863e+02],
        [ 3.3121e+01, -3.4160e+01, -2.6602e+00,  2.6522e+01, -2.0745e+02,
         -2.1333e+02,  1.7536e+00, -2.2540e+01, -1.9885e+02, -1.2193e+02,
          2.8184e+01, -1.7567e+02, -1.0656e+02, -2.2970e+02],
        [-1.5685e+01, -5.8839e+00, -2.3223e+00, -1.6445e+01, -1.8240e+01,
         -1.8109e+01, -8.1896e+00,  1.1705e+01, -1.5444e+01, -4.1430e+00,
         -2.7566e+01, -1.9573e+01, -4.3124e+01, -1.9984e+01],
        [ 3.6805e+00, -2.2344e+01, -1.6685e+01, -6.3740e+00,  2.5139e+00,
          3.7366e+00, -1.1549e+01,  1.8829e+00, -2.3004e+01, -2.6580e+01,
         -8.0285e+00, -9.4648e+00, -3.3263e+00, -3.6741e+01],
        [-1.2103e+01, -2.2828e+01, -1.4108e+00, -1.4979e+01, -2.9152e+01,
         -2.6165e+01, -2.3522e+00, -4.0480e+01, -2.0728e+01, -4.3339e-01,
         -1.1156e+01, -2.0926e+00, -6.8856e+00, -4.3744e+01],
        [-6.8243e+00, -1.0806e+01, -2.9278e+00, -1.3745e+01, -2.0906e+01,
         -2.5184e+01, -4.3235e+00, -3.1935e+01, -1.7466e+01,  2.0775e+00,
         -1.3299e+01, -6.4617e+00, -5.9246e+00, -3.4599e+01],
        [-6.6151e+00,  6.4681e+00, -1.9153e+01,  8.1359e+00, -2.7397e+02,
         -2.7440e+02,  1.3784e+01,  1.8106e+01, -1.4663e+02, -1.3487e+01,
          1.1336e+01, -2.1583e+01, -1.9918e+01, -3.1176e+02],
        [ 5.7155e+00, -2.9247e+01, -1.1610e+01,  1.0362e+01,  3.0538e+00,
         -1.7285e+00, -1.3824e+01, -4.4859e+00, -3.3059e+01, -2.9351e+01,
         -1.5898e+01, -1.4213e+01,  1.0983e+00, -2.8727e+01],
        [-4.6693e-01, -4.1394e+00, -1.7309e+01, -4.1617e+00,  1.8363e+00,
         -2.8387e+00, -9.9533e+00, -2.4319e+00, -4.8416e+00, -6.5422e+00,
         -9.4198e+00, -5.6807e+00, -1.1167e+01, -1.6678e+01],
        [ 4.2293e+00, -4.7996e+01, -1.9675e+01,  1.1660e+00, -4.6928e+00,
         -5.4114e+00, -7.2668e+00,  5.3481e+00, -5.5801e+01, -5.1648e+01,
          9.0440e+00, -9.5213e-01, -1.1141e+01, -2.7108e+01],
        [-1.6958e+01, -1.5929e+02, -1.5924e+02, -1.5650e+01, -6.9345e+01,
         -7.9497e+01,  1.0263e+01,  2.5716e+01, -1.9423e+02, -1.9312e+02,
          2.7775e+01,  8.6534e+00, -4.8295e+01, -9.1569e+01],
        [-3.0664e-01, -6.2986e+01, -2.3896e+01,  2.7060e+01,  1.1561e+00,
         -4.3654e+00, -3.9823e+00, -1.6953e+00, -6.2188e+01, -5.7459e+01,
         -4.1028e+00, -7.3163e+00, -7.3835e+00, -5.7308e+01]], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ -0.0673,  16.3080,   0.3771,  27.5853,  -7.0811,  -5.3778,  10.7863,
          10.1857,  -3.1508,  -1.0132,  -5.6325,  -1.8262,  13.1670,  -0.9252],
        [ -0.2543, -16.3413,  -0.3819, -27.3804,   6.8386,   5.3245, -10.6085,
         -10.3612,   3.4877,   0.9465,   5.5663,   1.6266, -13.1948,   0.6030]],
       device='cuda:0'))])
xi:  [26.91291]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 662.9298482709353
W_T_median: 349.9430941132291
W_T_pctile_5: 92.65008459665535
W_T_CVAR_5_pct: -23.736719487880563
Average q (qsum/M+1):  50.72310909148185
Optimal xi:  [26.91291]
Expected(across Rb) median(across samples) p_equity:  0.31886082887649536
obj fun:  tensor(-1491.2391, device='cuda:0', dtype=torch.float64,
       grad_fn=<MeanBackward0>)
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.5
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       14  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       14  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1  logistic_sigmoid   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 14)     False        None  
0     (14, 14)     False        None  
0      (14, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       14  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       14  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 14)     False        None  
0     (14, 14)     False        None  
0      (14, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
loaded continuation NN:  OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-26.2687,  -2.0638],
        [ -0.4209,   6.3491],
        [-97.3478,   2.8981],
        [ -7.4550,   5.9354],
        [ -7.4621,   5.9403],
        [ -9.7337,  21.1128],
        [ -7.4506,   5.9318],
        [ -7.4644,   5.9416],
        [ -7.4508,   5.9322],
        [ -7.4503,   5.9319],
        [ -7.4671,   5.9437],
        [ -7.4652,   5.9432],
        [ -7.4501,   5.9317],
        [ -7.4520,   5.9332]], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[-1.7930e+02, -2.1383e+02, -3.0033e+01,  1.7246e+01,  2.0061e+01,
         -2.3145e+02,  1.5055e+01,  2.0702e+01,  1.5583e+01,  1.5144e+01,
          2.1109e+01,  2.1066e+01,  1.5134e+01,  1.5370e+01],
        [-1.4795e+01, -1.9797e+02,  5.5993e+00,  1.0849e+01,  5.7691e+00,
         -4.2368e+02,  1.3991e+01,  4.7247e+00,  1.3352e+01,  1.4304e+01,
          3.6020e+00,  4.0049e+00,  1.3877e+01,  1.3693e+01],
        [ 3.1161e+00, -2.1065e+00,  1.4019e+00, -6.3008e+01, -5.8884e+01,
          1.1552e+01, -6.6324e+01, -5.7604e+01, -6.5562e+01, -6.5855e+01,
         -5.6881e+01, -5.6855e+01, -6.5823e+01, -6.5786e+01],
        [ 2.9124e+00,  5.5728e+00,  1.6501e+00, -6.3827e+01, -5.9218e+01,
          3.6989e+00, -6.7833e+01, -5.8363e+01, -6.6308e+01, -6.7499e+01,
         -5.7103e+01, -5.7319e+01, -6.7199e+01, -6.6829e+01],
        [ 3.0481e+00, -9.8272e-02,  1.4868e+00, -6.3415e+01, -5.8995e+01,
          1.0944e+01, -6.6217e+01, -5.8018e+01, -6.5657e+01, -6.6269e+01,
         -5.7153e+01, -5.7359e+01, -6.6422e+01, -6.5817e+01],
        [ 2.9084e+00,  3.7759e+00,  1.7463e+00, -6.2463e+01, -5.8188e+01,
          9.8358e+00, -6.5873e+01, -5.6881e+01, -6.5311e+01, -6.5779e+01,
         -5.5881e+01, -5.5835e+01, -6.5740e+01, -6.5108e+01],
        [ 2.9613e+00,  5.6153e+00,  1.1404e+00, -6.3672e+01, -5.9042e+01,
          4.1157e+00, -6.7650e+01, -5.7846e+01, -6.6486e+01, -6.7485e+01,
         -5.7315e+01, -5.7063e+01, -6.7169e+01, -6.6785e+01],
        [ 3.1225e+00, -2.0792e+00,  1.3670e+00, -6.3119e+01, -5.8642e+01,
          1.1556e+01, -6.6110e+01, -5.7872e+01, -6.5464e+01, -6.6134e+01,
         -5.6872e+01, -5.7034e+01, -6.6051e+01, -6.5542e+01],
        [-5.2201e+00, -5.0343e+00,  1.1677e+01,  5.8975e+01,  5.4478e+01,
         -1.1948e+01,  6.2692e+01,  5.3450e+01,  6.2033e+01,  6.2659e+01,
          5.2659e+01,  5.2712e+01,  6.2371e+01,  6.2475e+01],
        [-3.2220e+02, -3.0689e+00, -4.5434e+01,  3.7747e+01,  3.3529e+01,
         -2.7599e+02,  4.0585e+01,  3.2468e+01,  4.0069e+01,  4.0467e+01,
          3.1945e+01,  3.1748e+01,  4.0843e+01,  4.0287e+01],
        [ 3.2046e+00, -2.4377e+00,  8.7298e-01, -6.2896e+01, -5.8327e+01,
          1.1515e+01, -6.5952e+01, -5.7433e+01, -6.5442e+01, -6.5839e+01,
         -5.6405e+01, -5.6554e+01, -6.6110e+01, -6.5290e+01],
        [-4.2510e+01, -6.0632e+00, -1.9322e+01,  7.3445e+01,  6.8622e+01,
         -1.4177e+01,  7.6788e+01,  6.7929e+01,  7.5951e+01,  7.6420e+01,
          6.7032e+01,  6.6650e+01,  7.6629e+01,  7.6165e+01],
        [-2.0171e+00, -1.6323e+00, -9.2482e+01,  5.7941e+01,  5.3098e+01,
         -1.2442e+02,  6.1072e+01,  5.2168e+01,  6.0003e+01,  6.0861e+01,
          5.1560e+01,  5.1205e+01,  6.0762e+01,  6.0681e+01],
        [ 3.4483e+00, -5.9256e+00, -2.0545e+00, -6.2745e+01, -5.7783e+01,
          2.0720e+01, -6.5157e+01, -5.6834e+01, -6.4478e+01, -6.5326e+01,
         -5.5900e+01, -5.6092e+01, -6.5207e+01, -6.4844e+01]], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-29.1539, -28.9216, -19.6609, -25.5311, -20.5862, -21.2728, -24.7599,
         -19.6251,  15.2743,  52.2765, -19.1256,  32.3667,  28.6171, -11.9016]],
       device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[-70.2052, -19.3405],
        [-24.9526, -11.0448],
        [ 26.9712, -21.2673],
        [-65.1959, -23.4524],
        [  1.7946,   4.0861],
        [  1.8891,   4.1173],
        [  1.0806,  -2.9891],
        [-40.1958, -19.1811],
        [  1.9056,   4.3690],
        [  8.1660,   4.2639],
        [-48.6021, -27.1965],
        [  7.5501,   3.6825],
        [ 29.0734,  16.9538],
        [  1.6161,   4.0162]], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-6.4329e+00, -2.3006e+01, -8.2008e+00, -9.0836e+00, -1.5267e+01,
         -1.7639e+01, -1.4190e+01,  2.3088e+00, -1.5827e+01, -9.8645e+00,
         -1.8915e+01, -4.6165e+01, -3.5291e+01, -1.8354e+01],
        [-7.7962e+00, -6.9183e+01, -2.5229e+02, -1.4941e+01, -3.8568e+01,
         -3.5217e+01,  8.4283e+00,  3.0433e+01, -1.2334e+02, -1.4327e+02,
          3.8254e+01,  1.0086e+01, -7.4220e+01, -3.0745e+01],
        [ 4.4511e+01, -1.3164e+01, -2.6261e+00,  2.8558e+01,  2.8296e+02,
          2.8360e+02, -1.2745e+01, -8.6179e+00,  8.9755e+01,  1.7373e+00,
         -2.0461e+01,  5.9537e+00,  1.0599e+01,  3.2863e+02],
        [ 3.3121e+01, -3.4160e+01, -2.6602e+00,  2.6522e+01, -2.0745e+02,
         -2.1333e+02,  1.7536e+00, -2.2540e+01, -1.9885e+02, -1.2193e+02,
          2.8184e+01, -1.7567e+02, -1.0656e+02, -2.2970e+02],
        [-1.5685e+01, -5.8839e+00, -2.3223e+00, -1.6445e+01, -1.8240e+01,
         -1.8109e+01, -8.1896e+00,  1.1705e+01, -1.5444e+01, -4.1430e+00,
         -2.7566e+01, -1.9573e+01, -4.3124e+01, -1.9984e+01],
        [ 3.6805e+00, -2.2344e+01, -1.6685e+01, -6.3740e+00,  2.5139e+00,
          3.7366e+00, -1.1549e+01,  1.8829e+00, -2.3004e+01, -2.6580e+01,
         -8.0285e+00, -9.4648e+00, -3.3263e+00, -3.6741e+01],
        [-1.2103e+01, -2.2828e+01, -1.4108e+00, -1.4979e+01, -2.9152e+01,
         -2.6165e+01, -2.3522e+00, -4.0480e+01, -2.0728e+01, -4.3339e-01,
         -1.1156e+01, -2.0926e+00, -6.8856e+00, -4.3744e+01],
        [-6.8243e+00, -1.0806e+01, -2.9278e+00, -1.3745e+01, -2.0906e+01,
         -2.5184e+01, -4.3235e+00, -3.1935e+01, -1.7466e+01,  2.0775e+00,
         -1.3299e+01, -6.4617e+00, -5.9246e+00, -3.4599e+01],
        [-6.6151e+00,  6.4681e+00, -1.9153e+01,  8.1359e+00, -2.7397e+02,
         -2.7440e+02,  1.3784e+01,  1.8106e+01, -1.4663e+02, -1.3487e+01,
          1.1336e+01, -2.1583e+01, -1.9918e+01, -3.1176e+02],
        [ 5.7155e+00, -2.9247e+01, -1.1610e+01,  1.0362e+01,  3.0538e+00,
         -1.7285e+00, -1.3824e+01, -4.4859e+00, -3.3059e+01, -2.9351e+01,
         -1.5898e+01, -1.4213e+01,  1.0983e+00, -2.8727e+01],
        [-4.6693e-01, -4.1394e+00, -1.7309e+01, -4.1617e+00,  1.8363e+00,
         -2.8387e+00, -9.9533e+00, -2.4319e+00, -4.8416e+00, -6.5422e+00,
         -9.4198e+00, -5.6807e+00, -1.1167e+01, -1.6678e+01],
        [ 4.2293e+00, -4.7996e+01, -1.9675e+01,  1.1660e+00, -4.6928e+00,
         -5.4114e+00, -7.2668e+00,  5.3481e+00, -5.5801e+01, -5.1648e+01,
          9.0440e+00, -9.5213e-01, -1.1141e+01, -2.7108e+01],
        [-1.6958e+01, -1.5929e+02, -1.5924e+02, -1.5650e+01, -6.9345e+01,
         -7.9497e+01,  1.0263e+01,  2.5716e+01, -1.9423e+02, -1.9312e+02,
          2.7775e+01,  8.6534e+00, -4.8295e+01, -9.1569e+01],
        [-3.0664e-01, -6.2986e+01, -2.3896e+01,  2.7060e+01,  1.1561e+00,
         -4.3654e+00, -3.9823e+00, -1.6953e+00, -6.2188e+01, -5.7459e+01,
         -4.1028e+00, -7.3163e+00, -7.3835e+00, -5.7308e+01]], device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ -0.0673,  16.3080,   0.3771,  27.5853,  -7.0811,  -5.3778,  10.7863,
          10.1857,  -3.1508,  -1.0132,  -5.6325,  -1.8262,  13.1670,  -0.9252],
        [ -0.2543, -16.3413,  -0.3819, -27.3804,   6.8386,   5.3245, -10.6085,
         -10.3612,   3.4877,   0.9465,   5.5663,   1.6266, -13.1948,   0.6030]],
       device='cuda:0'))])
loaded xi:  26.91291
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1576.8182150775267
W_T_median: 1136.7449346433505
W_T_pctile_5: -127.64084552288806
W_T_CVAR_5_pct: -295.72244238283764
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1492.6372945103558
Current xi:  [147.89793]
objective value function right now is: -1492.6372945103558
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1504.7380370220828
Current xi:  [144.14442]
objective value function right now is: -1504.7380370220828
6.0% of gradient descent iterations done. Method = Adam
Current xi:  [170.16937]
objective value function right now is: -1457.5202875140842
8.0% of gradient descent iterations done. Method = Adam
Current xi:  [147.29913]
objective value function right now is: -1440.0965766586203
10.0% of gradient descent iterations done. Method = Adam
Current xi:  [138.61172]
objective value function right now is: -1440.9662506445388
12.0% of gradient descent iterations done. Method = Adam
new min fval:  -1513.4311233236847
Current xi:  [152.49174]
objective value function right now is: -1513.4311233236847
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [148.72786]
objective value function right now is: -1503.4113096018468
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [140.6917]
objective value function right now is: -1513.0560578622465
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -1528.1861689880554
Current xi:  [143.06534]
objective value function right now is: -1528.1861689880554
