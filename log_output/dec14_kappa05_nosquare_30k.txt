Starting at: 
14-12-22_10:43

 Random seed:  2  



############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
3.3333333333333335% of MC simulations done.
6.666666666666667% of MC simulations done.
10.0% of MC simulations done.
13.333333333333334% of MC simulations done.
16.666666666666664% of MC simulations done.
20.0% of MC simulations done.
23.333333333333332% of MC simulations done.
26.666666666666668% of MC simulations done.
30.0% of MC simulations done.
33.33333333333333% of MC simulations done.
36.666666666666664% of MC simulations done.
40.0% of MC simulations done.
43.333333333333336% of MC simulations done.
46.666666666666664% of MC simulations done.
50.0% of MC simulations done.
53.333333333333336% of MC simulations done.
56.666666666666664% of MC simulations done.
60.0% of MC simulations done.
63.33333333333333% of MC simulations done.
66.66666666666666% of MC simulations done.
70.0% of MC simulations done.
73.33333333333333% of MC simulations done.
76.66666666666667% of MC simulations done.
80.0% of MC simulations done.
83.33333333333334% of MC simulations done.
86.66666666666667% of MC simulations done.
90.0% of MC simulations done.
93.33333333333333% of MC simulations done.
96.66666666666667% of MC simulations done.
100.0% of MC simulations done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1  logistic_sigmoid   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)    False        None  
2     (10, 10)    False        None  
3      (10, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)    False        None  
2     (10, 10)    False        None  
3      (10, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1  logistic_sigmoid   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)     False        None  
0     (10, 10)     False        None  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)     False        None  
0     (10, 10)     False        None  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1576.8182150775267
W_T_median: 1136.7449346433505
W_T_pctile_5: -127.64084552288806
W_T_CVAR_5_pct: -295.72244238283764
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1579.2813250204633
Current xi:  [-124.82249]
objective value function right now is: -1579.2813250204633
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1592.2253561923524
Current xi:  [-142.6974]
objective value function right now is: -1592.2253561923524
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1593.850577881522
Current xi:  [-154.91594]
objective value function right now is: -1593.850577881522
8.0% of gradient descent iterations done. Method = Adam
Current xi:  [-163.20483]
objective value function right now is: -1592.233203258417
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1596.4055771669327
Current xi:  [-170.05914]
objective value function right now is: -1596.4055771669327
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [-173.31116]
objective value function right now is: -1582.2904836197465
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [-173.45248]
objective value function right now is: -1572.6310155780602
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [-172.5631]
objective value function right now is: -1586.8953279107866
18.0% of gradient descent iterations done. Method = Adam
new min fval:  -1597.3226828296959
Current xi:  [-173.7992]
objective value function right now is: -1597.3226828296959
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [-174.3405]
objective value function right now is: -1596.542362623422
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [-175.08635]
objective value function right now is: -1596.1566002345053
24.0% of gradient descent iterations done. Method = Adam
new min fval:  -1598.3260655707988
Current xi:  [-175.86732]
objective value function right now is: -1598.3260655707988
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [-177.31099]
objective value function right now is: -1556.0377377924206
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [-180.77838]
objective value function right now is: -1587.650749034342
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [-179.49905]
objective value function right now is: -1596.8028251382405
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [-179.21216]
objective value function right now is: -1594.8777955904202
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [-178.56558]
objective value function right now is: -1596.6826037526284
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [-178.78163]
objective value function right now is: -1594.7638063922227
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [-180.11147]
objective value function right now is: -1596.081410631394
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [-179.7886]
objective value function right now is: -1596.7132179359007
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [-178.69751]
objective value function right now is: -1596.1111897277017
44.0% of gradient descent iterations done. Method = Adam
new min fval:  -1599.095905212359
Current xi:  [-177.39392]
objective value function right now is: -1599.095905212359
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [-177.11931]
objective value function right now is: -1595.3062218562577
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [-176.41904]
objective value function right now is: -1585.8955885896046
50.0% of gradient descent iterations done. Method = Adam
new min fval:  -1600.3181562506184
Current xi:  [-175.50183]
objective value function right now is: -1600.3181562506184
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [-174.37251]
objective value function right now is: -1597.9508779099071
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [-172.92671]
objective value function right now is: -1598.6328836519103
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [-171.47371]
objective value function right now is: -1586.1971283905953
57.99999999999999% of gradient descent iterations done. Method = Adam
new min fval:  -1600.98303583628
Current xi:  [-172.67668]
objective value function right now is: -1600.98303583628
60.0% of gradient descent iterations done. Method = Adam
new min fval:  -1602.123033809846
Current xi:  [-171.9351]
objective value function right now is: -1602.123033809846
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [-171.5487]
objective value function right now is: -1590.8331401219718
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [-170.4359]
objective value function right now is: -1599.4134326098897
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [-170.1731]
objective value function right now is: -1601.2580013433833
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [-170.78612]
objective value function right now is: -1598.3030780764207
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [-170.75781]
objective value function right now is: -1592.3064114832407
72.0% of gradient descent iterations done. Method = Adam
Current xi:  [-170.15944]
objective value function right now is: -1596.8191855043117
74.0% of gradient descent iterations done. Method = Adam
Current xi:  [-169.66908]
objective value function right now is: -1594.7281315122061
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [-169.98601]
objective value function right now is: -1598.218804357293
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [-170.04703]
objective value function right now is: -1600.8813930197507
80.0% of gradient descent iterations done. Method = Adam
new min fval:  -1603.511557238383
Current xi:  [-169.6175]
objective value function right now is: -1603.511557238383
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [-170.32011]
objective value function right now is: -1595.0873988136393
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [-171.92793]
objective value function right now is: -1597.677937587556
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [-172.83974]
objective value function right now is: -1600.0457648608315
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [-172.41489]
objective value function right now is: -1601.8715989816808
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [-172.72478]
objective value function right now is: -1597.505639617879
new min fval from sgd:  -1603.6400946204756
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [-171.60228]
objective value function right now is: -1599.5619959494616
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [-171.05196]
objective value function right now is: -1598.6935929510396
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [-172.829]
objective value function right now is: -1586.3590702628142
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [-175.1828]
objective value function right now is: -1587.1120225643172
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [-177.65271]
objective value function right now is: -1588.9771771973378
min fval:  -1603.6400946204756
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[  0.3129,  -2.3095],
        [-24.8493,  -0.1468],
        [ -0.3791,   3.6980],
        [ -0.3712,   3.5112],
        [ -0.3705,   3.5124],
        [ -0.3821,   3.7769],
        [ -0.3711,   3.5097],
        [  0.3226,  -2.5039],
        [ -0.3712,   3.5113],
        [ -0.3707,   3.5175]], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[  9.0302,   4.9807,   7.3732,   5.2809,   5.9090,  11.7880,   5.2403,
           8.5091,   5.4907,   5.8765],
        [-10.3091,  -4.7663,  -6.4994,  -4.0651,  -5.6095,  -8.5054,  -4.7328,
          -9.9484,  -3.9709,  -4.4082],
        [-10.2936,  -4.8875,  -6.7651,  -3.3622,  -4.3797,  -8.6341,  -4.0978,
         -10.1457,  -3.6016,  -3.6309],
        [-10.6624,  -5.1277,  -6.7250,  -3.0279,  -3.7309,  -8.3349,  -3.0440,
          -9.9693,  -2.8355,  -3.3606],
        [-10.5969,  -5.2553,  -6.7585,  -3.1652,  -3.7898,  -8.3472,  -3.1885,
         -10.0337,  -2.9175,  -3.4887],
        [-10.6010,  -4.9457,  -6.9408,  -3.2827,  -4.5237,  -8.6536,  -3.7256,
          -9.8902,  -3.0973,  -3.4554],
        [  1.6487,   2.5961, -10.8052, -30.9165, -31.7937,  -9.0615, -31.5698,
           2.1004, -30.8730, -29.9702],
        [-10.1337,  -4.7195,  -6.5097,  -3.7023,  -4.8714,  -9.1331,  -3.9969,
         -10.2283,  -3.4480,  -3.6452],
        [  2.0422,   2.3982, -10.3537, -31.7858, -32.3197,  -9.0835, -32.7094,
           2.2154, -31.8122, -30.1364],
        [  2.2523,   1.9559, -11.0555, -34.1910, -30.9977,  -9.5711, -34.5999,
           2.7768, -34.1174, -29.0508]], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[ 24.1041,  -0.5871,  -0.5061,  -0.3748,  -0.3153,  -0.4770, -20.3181,
          -0.5882, -23.5968, -27.8446]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[-13.7474,  -7.0993],
        [-57.7231, -11.3009],
        [ -4.1884,   1.8526],
        [-11.1435,  -2.9928],
        [-74.6143, -12.4867],
        [  1.3282,   2.9354],
        [ 30.3264,  -6.8028],
        [ -3.7639,   0.9041],
        [-10.2048,   0.4211],
        [-29.0603,  -9.1190]], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-7.3707e+00,  1.3397e+01,  8.0303e+01,  2.4743e+01,  2.4253e+01,
          2.7728e+00, -3.4414e+00,  3.5085e+01, -3.5112e+01, -2.1266e+01],
        [-1.3182e+01, -4.2649e+00, -1.4848e+01,  9.1714e+00,  6.9229e-01,
         -7.0226e+01, -9.4958e+00, -3.2540e+01, -2.6728e+01,  1.5014e+01],
        [-2.4019e+01, -9.4243e+00, -3.0869e+00,  5.2964e+00, -9.0514e+00,
         -2.0263e+01, -2.0272e+01, -2.2367e+01, -4.8404e+00,  1.9701e+00],
        [ 4.4941e-01, -2.3945e+02, -7.5605e+00, -1.2023e+01, -1.6931e+02,
         -7.4955e+00, -2.7380e+00, -2.7938e+01, -4.7326e+01, -5.7490e+01],
        [ 5.8307e-02, -3.3476e+02,  3.5006e+01,  2.2582e+01, -2.7923e+02,
         -4.4345e+01, -5.0204e+00, -4.4443e+01, -5.9008e+01, -1.1250e+00],
        [-1.1262e+01, -6.2673e+00, -1.1356e+01, -1.0458e+01, -5.7631e+00,
         -1.7171e+01, -2.0143e+01, -1.5533e+01, -1.2058e+01, -4.0653e+00],
        [-3.3976e+00, -4.4577e+01, -5.6833e+00, -2.8913e+01, -4.0510e+01,
         -1.2247e+02, -9.0120e+00, -1.3529e+02, -1.2742e+02,  1.1603e+01],
        [-8.2034e+00, -2.1179e+01,  1.7472e+01,  1.0013e+00, -1.7357e+01,
         -1.8238e+01, -1.7263e+01, -1.3165e+01, -5.8110e+00, -2.0065e+01],
        [-1.1983e+01,  9.6584e+00,  3.8038e+01, -3.5463e+00,  1.0212e+01,
         -3.3962e+01, -9.9306e+00,  5.9001e+01,  1.4990e+01, -4.0572e+00],
        [-1.5320e+01, -5.6473e+00, -1.1243e+01, -1.0312e+01, -5.1264e+00,
         -1.5289e+01, -2.0876e+01, -1.4042e+01, -1.1184e+01, -2.8761e+00]],
       device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[  0.5123,  -3.0874,  -0.2724,   6.6667, -16.5868,  -1.4596,  -8.7903,
          -3.9266,   6.4563,  -0.9605],
        [ -0.4316,   3.5173,   0.3990,  -6.0708,  16.6593,   1.6776,   8.5720,
           4.2484,  -6.6570,   1.0606]], device='cuda:0'))])
xi:  [-171.76712]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 239.55489003864963
W_T_median: 21.786864709733898
W_T_pctile_5: -171.44441887453314
W_T_CVAR_5_pct: -234.60680724641142
Average q (qsum/M+1):  55.51585732736895
Optimal xi:  [-171.76712]
Expected(across Rb) median(across samples) p_equity:  0.31086931662990763
obj fun:  tensor(-1603.6401, device='cuda:0', dtype=torch.float64,
       grad_fn=<MeanBackward0>)
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.5
-----------------------------------------------
