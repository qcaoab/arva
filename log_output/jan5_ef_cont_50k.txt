Starting at: 
05-01-23_10:48

 Random seed:  2  



############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
3.3333333333333335% of MC simulations done.
6.666666666666667% of MC simulations done.
10.0% of MC simulations done.
13.333333333333334% of MC simulations done.
16.666666666666664% of MC simulations done.
20.0% of MC simulations done.
23.333333333333332% of MC simulations done.
26.666666666666668% of MC simulations done.
30.0% of MC simulations done.
33.33333333333333% of MC simulations done.
36.666666666666664% of MC simulations done.
40.0% of MC simulations done.
43.333333333333336% of MC simulations done.
46.666666666666664% of MC simulations done.
50.0% of MC simulations done.
53.333333333333336% of MC simulations done.
56.666666666666664% of MC simulations done.
60.0% of MC simulations done.
63.33333333333333% of MC simulations done.
66.66666666666666% of MC simulations done.
70.0% of MC simulations done.
73.33333333333333% of MC simulations done.
76.66666666666667% of MC simulations done.
80.0% of MC simulations done.
83.33333333333334% of MC simulations done.
86.66666666666667% of MC simulations done.
90.0% of MC simulations done.
93.33333333333333% of MC simulations done.
96.66666666666667% of MC simulations done.
100.0% of MC simulations done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1  logistic_sigmoid   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)    False        None  
2     (10, 10)    False        None  
3      (10, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer      10  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer      10  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1      (2, 10)    False        None  
2     (10, 10)    False        None  
3      (10, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1  logistic_sigmoid   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)     False        None  
0     (10, 10)     False        None  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)     False        None  
0     (10, 10)     False        None  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1  logistic_sigmoid   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)     False        None  
0     (10, 10)     False        None  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)     False        None  
0     (10, 10)     False        None  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1576.8182150775267
W_T_median: 1136.7449346433505
W_T_pctile_5: -127.64084552288806
W_T_CVAR_5_pct: -295.72244238283764
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -904.6526269865798
Current xi:  [18.4432]
objective value function right now is: -904.6526269865798
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1240.791599804513
Current xi:  [18.976341]
objective value function right now is: -1240.791599804513
6.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.929596]
objective value function right now is: -1134.2503026254647
8.0% of gradient descent iterations done. Method = Adam
Current xi:  [18.48226]
objective value function right now is: -1152.9702433258929
10.0% of gradient descent iterations done. Method = Adam
Current xi:  [18.986269]
objective value function right now is: -1041.0891142405546
12.0% of gradient descent iterations done. Method = Adam
new min fval:  -1307.2050486967883
Current xi:  [19.286963]
objective value function right now is: -1307.2050486967883
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [19.661566]
objective value function right now is: -952.1715139068463
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [20.70574]
objective value function right now is: -1115.9165800410049
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.72663]
objective value function right now is: -591.3204636875971
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.67039]
objective value function right now is: -1280.2491598827542
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.984728]
objective value function right now is: -1207.5987368575381
24.0% of gradient descent iterations done. Method = Adam
new min fval:  -1437.1199234936546
Current xi:  [20.320938]
objective value function right now is: -1437.1199234936546
26.0% of gradient descent iterations done. Method = Adam
new min fval:  -1465.2955082749074
Current xi:  [20.175028]
objective value function right now is: -1465.2955082749074
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [20.17669]
objective value function right now is: -227.94215531477985
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [18.483696]
objective value function right now is: -1100.8750125042639
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [20.081839]
objective value function right now is: -1310.196026924321
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.826725]
objective value function right now is: -1403.507301507221
36.0% of gradient descent iterations done. Method = Adam
new min fval:  -1501.2722114249516
Current xi:  [19.101358]
objective value function right now is: -1501.2722114249516
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.950893]
objective value function right now is: -1280.9120845652683
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [20.748526]
objective value function right now is: -1424.0831790009527
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [20.046722]
objective value function right now is: -1319.8397137703687
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.513412]
objective value function right now is: -609.2564223982107
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [20.227285]
objective value function right now is: -1237.9646280405482
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.229471]
objective value function right now is: -1472.6989806491065
50.0% of gradient descent iterations done. Method = Adam
new min fval:  -1524.2838648248076
Current xi:  [20.066874]
objective value function right now is: -1524.2838648248076
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [20.926546]
objective value function right now is: -1457.4030970461317
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.450037]
objective value function right now is: -1234.5548641484306
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [19.426088]
objective value function right now is: -1353.5914262828512
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [20.670258]
objective value function right now is: -1329.6202398135813
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [20.216393]
objective value function right now is: -1453.955051868183
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.351711]
objective value function right now is: -1417.98139137202
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.675316]
objective value function right now is: -1331.660166008235
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [20.14114]
objective value function right now is: -1159.6906028252788
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.762697]
objective value function right now is: -1415.0072625418084
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [20.715996]
objective value function right now is: -1360.9074156952634
72.0% of gradient descent iterations done. Method = Adam
Current xi:  [20.113953]
objective value function right now is: -1043.3635720250445
74.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.17147]
objective value function right now is: -717.6502866965624
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.161102]
objective value function right now is: -1191.0531828031826
78.0% of gradient descent iterations done. Method = Adam
new min fval:  -1563.267748336664
Current xi:  [20.08882]
objective value function right now is: -1563.267748336664
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [18.30226]
objective value function right now is: -1077.425972777633
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [20.11955]
objective value function right now is: -1254.0893706433985
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.432806]
objective value function right now is: -1416.3990379600893
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [18.95502]
objective value function right now is: -994.9152984802057
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.66231]
objective value function right now is: -1086.4147207352853
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.786493]
objective value function right now is: -836.0745247697087
new min fval from sgd:  -1563.3779236118387
new min fval from sgd:  -1563.6281046818501
new min fval from sgd:  -1567.4592494977592
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.378733]
objective value function right now is: -1457.180223205983
new min fval from sgd:  -1569.1263081682796
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.251257]
objective value function right now is: -1356.898146732803
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.388905]
objective value function right now is: -1149.8976486023373
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [19.137625]
objective value function right now is: -1462.8173542282966
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [20.084007]
objective value function right now is: -1522.1087513035236
min fval:  -1569.1263081682796
saved model: 
OrderedDict([('0.model.hidden_layer_1.weight', tensor([[-1.1252,  0.0034],
        [-0.3657,  0.0901],
        [ 0.6188, -1.3940],
        [ 1.5368, -1.3990],
        [ 1.2898, -1.3826],
        [-0.8374,  0.5164],
        [ 1.0053, -1.2258],
        [ 1.1609, -1.3303],
        [ 0.4109, -1.6111],
        [ 1.6609, -0.9800]], device='cuda:0')), ('0.model.hidden_layer_2.weight', tensor([[ 0.8104,  0.8584,  1.4275,  1.3830,  0.9760,  0.9366,  1.1967,  1.3997,
          1.0127,  0.8682],
        [ 0.9374,  1.3005,  0.8847,  1.3505,  1.0686,  0.7584,  1.2926,  0.9328,
          1.1332,  1.3597],
        [ 1.2479,  0.7210,  1.3787,  1.3391,  1.3853,  0.8174,  1.0486,  0.8406,
          1.4212,  1.2996],
        [-0.8941, -0.6537, -0.7569, -0.8962, -0.7466, -0.9001, -0.9910, -0.6455,
         -0.5852, -0.5653],
        [ 0.9851,  0.8643,  0.9695,  0.9778,  1.0220,  0.9040,  1.3693,  1.1911,
          1.3203,  1.2597],
        [ 0.1693,  0.1008,  0.6921,  1.3801,  0.5560, -0.1814,  0.8274,  0.4151,
          0.2640,  0.9272],
        [ 0.7875,  0.8171,  1.3013,  0.8426,  1.1321,  0.7277,  1.3749,  1.1935,
          0.9892,  1.2354],
        [-0.0731, -0.0324,  1.0290,  1.3499,  0.4779, -0.1437,  0.7025,  0.8302,
          0.8639,  1.0432],
        [ 1.0710,  0.9891,  1.2787,  1.2280,  1.3345,  1.0235,  1.0593,  1.5247,
          1.1007,  1.0896],
        [ 1.3872,  1.0804,  1.5421,  1.2085,  1.1168,  1.4020,  1.0112,  1.0662,
          1.0752,  1.3667]], device='cuda:0')), ('0.model.output_layer_3.weight', tensor([[-4.9915, -5.0264, -4.6566, -0.5958, -5.2782, -2.1895, -5.2629, -2.8023,
         -5.1417, -4.6217]], device='cuda:0')), ('1.model.hidden_layer_1.weight', tensor([[ -2.6421,   4.1343],
        [-28.0664,  -0.7259],
        [-12.6241,  -2.9989],
        [ -4.2676,   3.8597],
        [ -1.9268,   4.1462],
        [ -1.9883,   4.2170],
        [ -2.4290,   4.2522],
        [  9.5800,   4.6104],
        [ -1.6318,   4.2965],
        [ -1.5868,   4.3283]], device='cuda:0')), ('1.model.hidden_layer_2.weight', tensor([[-2.8400e+00, -5.3446e+01, -7.2349e+01, -7.9942e+00, -3.5103e+00,
         -8.2586e-02,  4.0430e+00, -4.3132e+01, -1.8426e+00, -1.8825e+00],
        [-1.3785e+00, -5.3669e+01, -7.2533e+01, -8.0137e+00, -3.1941e+00,
         -6.7750e-02,  4.5692e+00, -4.3029e+01, -1.8954e+00, -1.3789e+00],
        [-9.6846e-01, -5.4614e+01, -7.3068e+01, -6.9024e+00, -2.0536e+00,
          1.0721e+00,  5.5061e+00, -4.2778e+01, -6.4678e-01, -9.4773e-01],
        [-1.2255e+02, -5.5924e+01, -6.9903e+01, -1.0910e+02, -1.2070e+02,
         -1.3773e+02, -1.3916e+02, -5.1250e+01, -1.2993e+02, -1.2507e+02],
        [-5.7216e+01,  3.9018e+00,  1.0347e+01, -3.6815e+01, -5.5546e+01,
         -6.9613e+01, -7.4455e+01, -1.3595e+01, -6.3239e+01, -6.0821e+01],
        [-3.0894e+01, -1.6018e+01,  1.1884e+00, -8.5240e+01, -1.6093e+01,
         -2.1178e+01, -3.2110e+01, -2.9075e+00, -1.3689e+01, -1.2602e+01],
        [-3.1368e+02, -8.8780e+01, -5.6657e+00, -3.5265e+02, -2.8570e+02,
         -3.1668e+02, -3.3664e+02, -1.6637e+01, -2.8587e+02, -2.7669e+02],
        [ 6.6551e+00, -5.4981e+01, -7.3469e+01,  3.5367e+00,  3.0282e+00,
          1.2259e+00,  5.6243e+00, -4.2203e+01, -8.9921e-01, -6.3216e-01],
        [ 8.1146e+01,  7.8579e+00, -2.8270e+01,  6.5854e+01,  7.5501e+01,
          8.8071e+01,  8.5105e+01,  1.3945e+02,  8.5783e+01,  8.4477e+01],
        [-2.4852e+02, -1.0602e+02, -6.0454e+01, -3.2230e+02, -2.0449e+02,
         -2.4006e+02, -2.6927e+02, -4.1285e+00, -1.9837e+02, -1.8664e+02]],
       device='cuda:0')), ('1.model.output_layer_3.weight', tensor([[ -3.7632,  -3.8735,  -4.0613,  -3.3278,  -9.2408,  -5.1864,  13.5036,
          -3.9612,   0.5058,   6.8153],
        [  4.0213,   3.9461,   3.8004,   3.8497,   9.4639,   5.0399, -13.5005,
           4.3955,  -0.6813,  -6.5010]], device='cuda:0'))])
xi:  [19.937197]
-----------------------------------------------
Selected results: NN-strategy-on-TRAINING dataset (temp implementation
W_T_mean: 1197.082119617445
W_T_median: 970.6019744904956
W_T_pctile_5: 196.79850352991272
W_T_CVAR_5_pct: 9.718574634776912
Average q (qsum/M+1):  35.0
Optimal xi:  [19.937197]
Expected(across Rb) median(across samples) p_equity:  0.23378851413726806
obj fun:  tensor(-1569.1263, device='cuda:0', dtype=torch.float64,
       grad_fn=<MeanBackward0>)
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: B10_and_VWD
Objective function: mean_cvar_single_level
Tracing param: 50.0
-----------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1  logistic_sigmoid   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)     False        None  
0     (10, 10)     False        None  
0      (10, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer       10  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer       10  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0      (2, 10)     False        None  
0     (10, 10)     False        None  
0      (10, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1576.8182150775267
W_T_median: 1136.7449346433505
W_T_pctile_5: -127.64084552288806
W_T_CVAR_5_pct: -295.72244238283764
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1077.1074187863524
Current xi:  [18.929316]
objective value function right now is: -1077.1074187863524
4.0% of gradient descent iterations done. Method = Adam
Current xi:  [18.138231]
objective value function right now is: -1070.492901912162
6.0% of gradient descent iterations done. Method = Adam
new min fval:  -1484.0026081858953
Current xi:  [15.850433]
objective value function right now is: -1484.0026081858953
8.0% of gradient descent iterations done. Method = Adam
Current xi:  [16.12675]
objective value function right now is: -1409.709128151366
10.0% of gradient descent iterations done. Method = Adam
new min fval:  -1485.646287423146
Current xi:  [15.870923]
objective value function right now is: -1485.646287423146
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [16.441986]
objective value function right now is: -1483.8831563569183
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [16.921938]
objective value function right now is: -1458.1222518253091
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [16.035635]
objective value function right now is: -1469.084243001324
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [17.00403]
objective value function right now is: -1480.8290182526614
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [16.670586]
objective value function right now is: -1424.6478708479851
22.0% of gradient descent iterations done. Method = Adam
new min fval:  -1501.9333874376273
Current xi:  [16.729116]
objective value function right now is: -1501.9333874376273
Traceback (most recent call last):
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/decumulation_driver.py", line 881, in <module>
    fun_RUN__wrapper.RUN__wrapper_ONE_stage_optimization(
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/fun_RUN__wrapper.py", line 116, in RUN__wrapper_ONE_stage_optimization
    RUN__wrapper_training_testing_NN(
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/fun_RUN__wrapper.py", line 216, in RUN__wrapper_training_testing_NN
    res_adam = fun_train_NN.train_NN( theta0 = theta0,
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/fun_train_NN.py", line 196, in train_NN
    result_pyt_adam = run_Gradient_Descent_pytorch(NN_list= NN_list,
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/fun_train_NN_SGD_algorithms.py", line 145, in run_Gradient_Descent_pytorch
    params_it = copy.deepcopy(params)  # Create a copy of input data for this iteration
  File "/usr/lib/python3.10/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/usr/lib/python3.10/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/usr/lib/python3.10/copy.py", line 153, in deepcopy
    y = copier(memo)
KeyboardInterrupt
