tracing parameter entered from terminal:  0.25


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.0812786551646
gradient value of function right now is: [-3.68475402e-01 -1.34399012e+00 -2.03931051e+00 -9.57923525e-01
  3.68475402e-01  1.34399012e+00  2.03931051e+00  9.57923525e-01
  1.91046859e-01  8.31556068e-02  1.28563403e-01  1.15677166e-01
 -3.26599469e-01 -3.08701411e-01 -5.16918205e-01 -2.99701937e-01
  1.21502310e+00  7.09499292e-01  1.08791332e+00  8.59399267e-01
  6.63297101e-01  3.27714000e-01  4.95515724e-01  4.27457007e-01
 -3.21813545e-01  5.39292541e-03 -1.19746710e+00 -1.00595781e-02
 -4.83779649e-01 -5.83680808e-03 -4.43733718e-01 -9.64252511e-03
 -1.26286728e+00 -1.67172137e-02 -1.28871023e+00 -3.50229026e-02
  7.82665991e-01  1.37958559e-02  1.28756665e+00  2.35106781e-02
  9.84410010e-03 -4.46256396e-01 -1.04843150e+00  9.76329330e-03
  2.34358647e-02  8.51004175e-02  5.83398479e-02  2.45817257e-02
  1.62159415e-01  2.50606739e+00  4.63321129e+00  1.71837801e-01
  5.38943992e-04 -1.35722835e-01 -2.70086340e-01 -9.78375155e-05
  8.17954777e-01 -1.38999609e+00  9.54195204e-01 -2.11761820e+00
 -3.77171951e-01  5.66100898e-01  7.22083780e-01 -1.27012457e+00
 -8.08036089e+00]
supnorm grad right now is: 8.080360886377154
Weights right now are: 
[ 1.56208295 -1.32918274  2.42918677  1.59437998 -1.30751424  1.22049105
 -2.0302495  -2.31040836  5.64654462  5.18906203  5.90000896 -0.94949724
  6.83786116 -1.71012698 -0.39186952  0.8693911   2.6482496   0.56862986
  2.7843033  -4.41295585  3.58827483  1.77295438  4.83047868 -2.23519911
  7.71054839 -4.22052221 -0.26204206  8.01867757 -0.47517715  5.19725658
  7.50124519 -4.78656903 -1.66157863  6.63475839  6.69440202 -5.4153275
  2.95757686  2.67323207  3.78430402  2.72466043 13.03941763  4.22838882
 -2.29167747 12.29118153 -5.65816021  2.0368878   5.42752636 -3.42374135
 -9.64193024  0.39312186  1.63069932 -8.07129636  9.30808029 12.56209627
 -1.5792435   9.68179751  2.34799228 -2.56261926 -3.31258837 -1.85217951
 -1.77904747  1.85048674  2.21382785 -2.56731212 31.01396292]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.7880390783353
gradient value of function right now is: [-1.07876128e-02 -2.62163088e-02 -6.03802690e-01 -1.62360226e-01
  1.07876128e-02  2.62163088e-02  6.03802690e-01  1.62360226e-01
  5.07131880e-02 -7.81913938e-04 -1.71671781e-02  4.27151417e-03
 -9.50222141e-03 -9.30814023e-02 -2.71577505e-01 -7.44420963e-03
  1.21176466e+00  5.14613335e-02  1.99539610e-01  1.57710352e-01
  3.51900660e-01  9.11478848e-04 -2.29434273e-02  4.04055898e-02
 -1.90938843e-01 -6.48156716e-02 -2.12769414e+00 -2.11068524e-02
 -2.82667876e-01 -8.60284371e-04 -9.12653442e-02 -1.05264435e-01
  7.50668558e-02  6.62256109e-04  1.05488749e-01  9.45078292e-02
  1.03719304e-01  5.74699606e-03  2.61234422e-01 -5.77946250e-03
  1.12398316e-01  2.36678225e-01  9.71856147e-01  1.13786377e-01
 -5.09544298e-02 -5.76081626e-02 -1.97454407e-01 -5.10801558e-02
 -5.01044103e-02  1.88922913e-01  1.91466067e-01 -4.78932533e-02
  4.83336328e-02  3.29099035e-03  1.04634729e-02  4.71942462e-02
 -2.06810680e-01  2.09232905e+00  2.47149357e-01  4.76891296e-02
  2.27827441e-02 -7.13720823e-01 -1.89640594e-01  1.92506854e+00
  7.61467586e+00]
supnorm grad right now is: 7.614675864505309
Weights right now are: 
[  2.10443446  -2.51494747   3.22603832   1.78188078  -1.84986575
   2.40625578  -2.82710105  -2.49790916   9.41983328   8.48857641
   9.52084626   3.51492732  13.12956112  -6.30691133   2.62856785
   4.88507429   2.69286483   1.84292608   2.46001456  -3.86323581
   5.08867617   2.79082721   6.24730187   1.51920041   6.58836722
  -4.47325968  -0.05696821   8.12324288   1.51184467  10.31629393
  11.4075581  -10.14530262  -3.08741297   8.27204868   7.21801281
  -8.86086955   3.7814958    5.17979452   3.97591904   0.69651484
  16.13253801   3.17568532  -1.78102363  15.35681222  -5.72792289
  -1.4956873    7.34775237  -3.16323719 -11.57687371   0.14203176
   1.96329245  -9.8886085   10.55479133  17.26401845  -1.83919102
  11.14329226   2.78213632  -2.59788114  -3.73558004  -2.64516514
  -2.39661157   1.30806366   2.52349161  -2.63011301  31.16925904]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1206.1345066419863
gradient value of function right now is: [ 3.06594237e-02  2.21940686e-01  1.46387957e+00  2.02207307e-01
 -3.06594237e-02 -2.21940686e-01 -1.46387957e+00 -2.02207307e-01
 -1.29416451e-02 -3.18316593e-04 -1.64122063e-02 -5.28577416e-03
  3.32807586e-02  9.79236604e-02  4.63729519e-01  4.17572953e-02
 -2.02930186e+00 -7.91258119e-02 -1.55820482e+00 -3.29852650e-01
 -1.09761255e-01 -2.31860702e-03 -8.87334736e-02 -2.73979641e-02
  1.30838226e-01  1.37617189e-01  2.07939665e+00 -3.41831392e-03
  1.85663008e-01  9.95903631e-04  8.56590904e-02  8.22047353e-02
  8.58553020e-01  1.23145672e-02  8.59635698e-01  9.92437577e-02
 -2.92085848e-01 -9.43868082e-03 -3.69707977e-01 -3.94029014e-02
  2.34693783e-02  3.48649510e-01  1.55067795e+00  2.34965991e-02
  8.70355584e-02  2.64031556e-01  2.97760120e-01  9.30534474e-02
 -1.36968615e-01 -1.08546166e+00 -3.79883134e+00 -1.42356560e-01
  5.47622116e-02  1.57648424e-01  1.42564798e+00  5.38600483e-02
 -3.47353772e-01  2.74021084e+00 -7.29236938e-01  4.48204470e+00
  1.68018903e-01 -1.57237157e+00 -4.19731839e-01  2.66777318e+00
 -1.54258016e+00]
supnorm grad right now is: 4.482044701672122
Weights right now are: 
[ 2.12658872e+00 -2.76909134e+00  3.97570398e+00  1.33342266e+00
 -1.87202001e+00  2.66039965e+00 -3.57676671e+00 -2.04945104e+00
  1.50649750e+01  1.52504714e+01  1.41870641e+01  9.99357227e+00
  2.01681409e+01 -5.49023897e+00  4.82320764e+00  8.23417317e+00
  2.53135054e+00  1.92363791e+00  3.32873256e+00 -2.85838212e+00
  7.81623315e+00  5.57605944e+00  8.26295361e+00  6.83415924e+00
  8.41940977e+00 -4.57518595e+00  1.48721447e-01  9.99863972e+00
  2.22758573e+00  1.52300882e+01  1.35838216e+01 -1.10274014e+01
 -3.92549365e+00  1.17503180e+01  7.96279426e+00 -1.27590502e+01
  4.55771723e+00  6.29520029e+00  4.19037789e+00  6.85679337e-03
  1.63504945e+01  3.32448324e+00 -1.40252385e+00  1.57956315e+01
 -7.00915182e+00 -2.18906097e+00  7.53847596e+00 -2.96149396e+00
 -1.30603753e+01 -2.45067366e-01  1.91142953e+00 -1.11421264e+01
  1.03779530e+01  2.26253282e+01 -1.09824721e+00  1.16445364e+01
  3.06455237e+00 -2.85128666e+00 -4.38045078e+00 -2.58323220e+00
 -2.15727662e+00  1.15672715e+00  2.56936185e+00 -2.91258223e+00
  3.10342231e+01]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.1169301924751
gradient value of function right now is: [ 7.16832450e-03  1.44907867e-01  7.26110080e-01  1.84627068e-02
 -7.16832450e-03 -1.44907867e-01 -7.26110080e-01 -1.84627068e-02
 -6.64328180e-03 -6.25754877e-04 -1.09958388e-02 -4.38606466e-03
  3.10831416e-02  5.86955923e-03  2.75361695e-01  5.25298905e-02
  5.09368826e-01 -1.39696170e-01 -1.40850943e+00 -2.60473546e-01
 -9.87690285e-04 -1.28525681e-04 -2.17184405e-03 -8.02694795e-04
  2.99833606e-02 -4.97970554e-02 -6.48636533e-01 -7.50327058e-03
  1.58991570e-01  2.85095504e-03  1.53517329e-01  1.77223437e-02
  6.12049444e-01  1.11249368e-02  6.11226770e-01  5.46245602e-02
 -3.91546082e-01  4.43930748e-03 -1.98907852e-01 -4.46846143e-02
  6.11754905e-02  6.96735032e-01  2.14069227e+00  7.41624479e-02
 -1.98820009e-02 -3.92166676e-01 -3.65021329e-01 -4.15321644e-02
 -9.91939017e-02 -1.36991977e+00 -3.55996876e+00 -1.17328676e-01
  3.95071371e-02  9.40161732e-02  7.49460963e-01  3.77564593e-02
 -1.12751316e+00  2.17777615e+00 -1.17556483e+00  3.22927742e+00
  1.12073914e+00 -1.64942153e+00 -1.21758789e+00  2.31843345e+00
  9.04004767e+00]
supnorm grad right now is: 9.040047669457598
Weights right now are: 
[  4.38928024  -3.49371593   3.96356449  -0.04062481  -4.13471153
   3.38502424  -3.56462722  -0.67540358  19.55428932  22.45933695
  18.47010803  12.67746356  25.3705757   -7.04555824   5.10466436
  10.82597606   2.94207807   3.08775049   3.20207133  -2.55186658
  16.47755351  12.73990271  13.91939617  15.95712665   9.1134693
  -4.64491036   0.27168001  15.6478279    0.84055032  16.91093939
  13.62117944 -12.93638509  -3.68420392  12.84479062   8.63763282
 -15.14064534   5.23293558   9.19207729   3.68433704   0.86856585
  15.77796102   2.64964337  -0.62476764  15.56258323  -6.86125776
  -2.94690215   7.73268209  -1.11626442 -14.66152125  -0.28512446
   2.05582451 -12.42317826   8.7320656   26.66717098  -1.22563331
  10.91271537   3.24825698  -2.86323209  -3.61949975  -3.18057998
  -1.89227693   0.69900753   2.55666651  -3.00602861  31.15611801]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.9153006474526
gradient value of function right now is: [-1.47886977e-02 -1.70290113e-02 -1.20067531e+00 -1.01547297e-02
  1.47886977e-02  1.70290113e-02  1.20067531e+00  1.01547297e-02
  9.61198254e-03  3.35429375e-04  1.22347752e-02  6.38604048e-03
 -7.76748348e-03  3.27878727e-02  6.15801442e-02 -5.73074038e-03
  3.09398409e+00 -3.95745696e-02 -1.37796576e-01  2.21553841e-01
  2.07045710e-03  7.57177338e-05  2.79979983e-03  1.42654731e-03
 -8.93731612e-02 -3.20515645e-01 -2.60548847e+00  8.70269720e-04
  8.92319086e-02  9.50023193e-04  4.71141255e-02  3.35254591e-02
  5.04001941e-03 -1.90487988e-03 -1.31526715e-01 -2.79069553e-02
  1.67412820e-04  2.97139346e-02  3.83172634e-01  2.14746105e-03
  3.03602243e-02  5.52717648e-01  5.95249055e-01  2.99082450e-02
 -1.73735714e-01 -1.23822366e+00 -1.14028000e+00 -1.74762261e-01
  1.58962109e-02 -5.32993868e-01 -5.09250639e-01  1.22232419e-02
 -1.35478228e-02 -1.68078703e-02 -6.85923309e-02 -1.17431761e-02
 -1.01926954e+00 -2.67496275e-01 -5.54395269e-01  1.89255906e-01
  1.41061767e+00 -2.19836599e-01 -4.70056006e-01 -2.49112658e-01
  4.38918873e+00]
supnorm grad right now is: 4.389188729533603
Weights right now are: 
[  5.92073376  -3.59385453   3.60138182   1.5225997   -5.66616505
   3.48516284  -3.20244455  -2.23862808  22.42305279  24.74871107
  18.59474253  13.57480062  30.96821437  -7.41485751   5.75390553
  13.10986298   2.62358678   3.29513244   3.23692964  -2.62629629
  23.3066311   18.52078726  18.78450906  22.30140124   9.67688501
  -4.76409904   0.09069069  15.49584932   0.992499    18.97992783
  13.82058747 -14.41351405  -4.32438343  14.7178914    8.96671121
 -17.99824917   7.17589782  10.31548699   3.31126734   0.35142804
  15.42042426   2.77366322  -0.51516837  15.22482283  -8.0407951
  -3.26007069   7.80864227  -1.22498155 -16.82388252  -0.61670607
   2.21037728 -14.46537991   7.29317106  29.90219393  -0.69789473
  10.30618918   3.28730931  -2.95923127  -4.31421645  -3.2036143
  -1.76794809   0.84364178   3.25758773  -3.14806832  31.06685259]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.3483098908457
gradient value of function right now is: [-1.89883402e-02 -1.67041417e-01  7.73951498e-01 -4.50460364e-03
  1.89883402e-02  1.67041417e-01 -7.73951498e-01  4.50460364e-03
  4.78487484e-03  9.48498919e-04  1.43644687e-02  8.78139196e-03
 -1.62616458e-02 -2.28591954e-01 -5.90971738e-01 -4.80416020e-02
 -2.68051066e+00  6.32053178e-02  6.48221172e-01 -6.38014556e-01
  1.66856944e-04  2.53834908e-05  3.92162653e-04  2.76359484e-04
  1.70332194e-01  8.19070996e-02  2.66638275e+00  4.06306411e-02
 -3.71290991e-01 -2.30545333e-03 -3.11952851e-01 -2.14849932e-01
 -1.34747684e-01 -1.32172174e-03 -2.45696438e-01 -8.00979235e-02
  1.49041040e-01 -1.79657641e-02 -4.58784486e-01  1.17348914e-01
 -1.24679636e-01 -4.75478056e-01 -1.95059020e+00 -9.56267767e-02
  5.45267426e-02  4.31451984e-01  5.30014917e-01  4.84592675e-02
  1.60450919e-01  1.80746402e-01  3.18555719e+00  1.17790158e-01
 -1.77095521e-01 -2.59573291e-01 -3.69528141e+00 -1.28486436e-01
  9.76559540e-01 -5.20246219e+00  1.41669004e+00 -8.42306036e+00
 -6.75730842e-01  2.59633019e+00  6.58168579e-01 -3.96064776e+00
 -1.30908649e+01]
supnorm grad right now is: 13.090864861791324
Weights right now are: 
[  4.95463473  -4.1291366    3.71258668   0.2639265   -4.70006602
   4.02044491  -3.31364941  -0.97995488  25.67276939  25.71328174
  19.94052687  15.87922639  36.47637463  -7.97108227   5.86316895
  15.59975041   2.67386356   3.9560905    3.28331062  -2.58783401
  31.69583046  25.09951541  26.76849339  31.49645271  10.36053472
  -4.99500075   0.18187746  16.02705168   1.28400308  19.04871039
  12.83962875 -16.60661087  -4.60588178  16.11652664   9.99289289
 -19.86501804   8.21418798  11.82597514   2.81659636   0.11480428
  15.4779791    3.0219267   -0.04183702  15.21352609  -9.37355507
  -2.50155839   8.30507959  -2.17535817 -19.11411486  -0.70267131
   2.34760959 -16.98321407   5.76573451  31.85742266  -0.53798125
   9.30444068   3.52656667  -2.89758631  -4.24980561  -3.43583428
  -2.22278066   0.86357421   3.60350637  -3.23547193  31.14301726]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.0384842800343
gradient value of function right now is: [ 5.95477731e-02  2.36803809e-01  1.84776969e-01  1.04799727e-02
 -5.95477731e-02 -2.36803809e-01 -1.84776969e-01 -1.04799727e-02
 -4.72388215e-03 -2.82658543e-03 -3.22177685e-02 -1.31143105e-02
  2.46799519e-02  4.00137694e-02  2.51824064e-01  3.77195174e-02
  8.27045661e-01 -1.22949218e-01 -8.15337566e-01  3.82684627e-02
 -1.22800123e-04 -2.86122471e-05 -3.46598506e-04 -2.08584953e-04
 -2.18192593e-01 -3.41892332e-02 -1.50669107e+00 -4.23381549e-02
  1.99298855e-01  1.97143482e-03  2.61380918e-01  5.27388874e-02
  3.43336699e-01  4.33916295e-03  5.58109642e-01  7.84371075e-02
 -1.57918393e-01  4.63874845e-03  2.42609617e-03 -4.88080913e-02
  1.67344117e-01  7.48871763e-01  3.13087097e+00  1.14980339e-01
 -2.03711802e-02 -1.95076677e-01 -2.49052619e-01 -1.76312844e-02
 -1.49964231e-01 -8.86635468e-01 -3.70703707e+00 -9.88715716e-02
  1.33239599e-01  1.51222073e-01  2.06433624e+00  8.94342164e-02
 -1.27318678e+00  5.34288601e+00 -1.27167913e+00  5.72979560e+00
  6.94079017e-01 -1.87727514e+00 -8.02192625e-01  3.72799582e+00
  1.45322342e+01]
supnorm grad right now is: 14.532234215087213
Weights right now are: 
[ 4.41580885e+00 -3.37460216e+00  3.44167581e+00 -1.67725799e-02
 -4.16124014e+00  3.26591047e+00 -3.04273854e+00 -6.99255803e-01
  2.99577501e+01  2.72533241e+01  2.04851122e+01  1.88165638e+01
  4.07303744e+01 -8.13393314e+00  6.55432054e+00  1.78372755e+01
  2.63507058e+00  3.71583470e+00  3.35617928e+00 -2.53492773e+00
  4.61134292e+01  3.07520552e+01  3.56819776e+01  4.44780933e+01
  1.12631658e+01 -4.38372757e+00  1.27143336e-01  1.55828787e+01
  8.21138679e-01  1.89250112e+01  1.21934522e+01 -1.84844581e+01
 -4.80548020e+00  1.77653244e+01  1.03093540e+01 -2.19381417e+01
  9.05373585e+00  1.48593453e+01  2.98886802e+00 -6.31495853e-01
  1.45932980e+01  2.46990880e+00  6.75830740e-02  1.41036140e+01
 -8.58517082e+00 -3.39998208e+00  8.74303795e+00 -6.08443219e-01
 -2.17314343e+01 -9.11060060e-01  2.22240268e+00 -2.00457019e+01
  4.88628344e+00  3.35461929e+01 -1.13341341e-02  8.88208000e+00
  3.56787073e+00 -2.79144242e+00 -4.19366566e+00 -3.61244391e+00
 -1.96015219e+00  6.88656687e-01  3.86805698e+00 -3.19976439e+00
  3.11506475e+01]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.4844793122209
gradient value of function right now is: [-1.00649988e-02  1.03158995e-01 -1.57958658e-01 -1.88684662e-03
  1.00649988e-02 -1.03158995e-01  1.57958658e-01  1.88684662e-03
  1.10954302e-02 -6.77713416e-04 -7.66336154e-03  2.78085427e-03
  5.83097510e-03  1.72714563e-02  1.41317892e-01  1.76319276e-02
  2.61312343e-01 -9.75680118e-02 -5.30439863e-01  1.02754813e-01
  3.30626054e-04 -5.87881809e-06 -8.39827680e-05  1.33973690e-04
 -1.96400198e-01  2.55945882e-02 -7.17891817e-01 -3.03525326e-02
  1.42162797e-01  6.95181632e-04  1.86632391e-01  3.28196451e-02
  1.74471565e-01  8.77099215e-04  2.38037629e-01  3.47897638e-02
 -1.12930545e-01  1.14194036e-03  3.59784672e-02 -3.89654236e-02
  1.01090448e-01  7.30800063e-01  2.40436541e+00  7.54617829e-02
  3.00924124e-02 -1.04618000e-02 -3.04699771e-03  2.76517742e-02
 -5.17982958e-02 -6.17872841e-01 -2.02965448e+00 -3.77099129e-02
  6.02913492e-02  7.00549798e-02  1.08579793e+00  4.62844441e-02
 -6.30409107e-01  2.39140117e+00 -7.21137249e-01  2.93087663e+00
  2.92473323e-01 -5.21499613e-01 -4.51759138e-01  1.95600471e+00
  7.63015562e+00]
supnorm grad right now is: 7.630155623963663
Weights right now are: 
[  4.35691653  -3.19664757   3.28057322   0.78917962  -4.10234782
   3.08795588  -2.88163595  -1.505208    31.26036155  31.56328821
  22.22908718  20.53129079  44.70719762  -8.99049162   6.33929015
  20.847262     2.88472317   3.99470856   3.27527949  -2.93935301
  49.32173099  38.09893441  44.84674415  49.39689479  12.1523986
  -4.35557201   0.24768142  14.56608137   0.84224053  14.65572714
  11.55531257 -19.95871313  -4.84541487  16.21515855  10.21713913
 -24.46900491   9.51079125  19.01902076   2.92606089  -2.0717073
  14.51154758   2.12653079   0.41186625  13.88102042  -8.04052284
  -3.57136653  10.01666822   0.6778782  -23.75966055  -1.01457557
   2.18747601 -22.7447043    4.3813268   34.78105949   0.57089067
   8.8874434    3.66101433  -3.09551733  -4.2823227   -3.78508457
  -1.83496225   0.52181795   4.09813306  -3.34505063  31.12441081]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.1685476692885
gradient value of function right now is: [-1.68716131e-02 -1.20234571e-01  1.77718882e+00 -1.74465786e-03
  1.68716131e-02  1.20234571e-01 -1.77718882e+00  1.74465786e-03
 -2.03168923e-03  6.02621736e-04  1.02629181e-02  3.79514206e-03
 -5.84775139e-03 -9.78555889e-02 -2.41874642e-01 -1.66008070e-02
 -2.42185442e+00  1.45683891e-02  3.57871468e-01 -5.96593594e-01
  6.15612441e-05  2.18147363e-05  3.53146186e-04  2.49129912e-04
  2.97610111e-01  8.87654191e-02  3.71044655e+00  1.48457712e-02
 -1.68139076e-01 -7.05249018e-04 -1.61784518e-01 -7.83954592e-02
 -1.45887731e-01 -9.98074410e-04 -2.38369389e-01 -6.12063114e-02
 -1.86289430e-02 -1.16398092e-02 -9.19005981e-01  3.91900860e-02
 -1.31067592e-01 -1.02548782e+00 -2.33359898e+00 -1.08237018e-01
  8.78650168e-02  3.56693959e-01  3.82016171e-01  8.49961161e-02
  5.64571317e-02 -3.29882250e-01  1.08638962e+00  4.24785132e-02
 -7.85226346e-02 -1.14951556e-01 -1.74902293e+00 -5.95499409e-02
  8.03758592e-01 -2.95932696e+00  9.98890380e-01 -4.42062074e+00
 -3.48591125e-01  6.73974051e-01  5.44611456e-01 -2.44135332e+00
 -7.16375461e+00]
supnorm grad right now is: 7.16375461199405
Weights right now are: 
[ 4.54750585e+00 -2.87439992e+00  3.35582622e+00  1.91560481e+00
 -4.29293714e+00  2.76570823e+00 -2.95688895e+00 -2.63163319e+00
  3.47475872e+01  3.33825858e+01  2.31110414e+01  2.12840801e+01
  4.81785999e+01 -9.70054807e+00  6.52377162e+00  2.38399078e+01
  2.90627085e+00  3.74317454e+00  3.61041240e+00 -3.04287989e+00
  5.41370557e+01  4.28561273e+01  4.88952508e+01  5.11670758e+01
  1.29927943e+01 -3.98550155e+00  3.40592678e-01  1.46315909e+01
  1.33786098e+00  7.70768048e+00  1.07938465e+01 -2.26107238e+01
 -6.88221490e+00  1.33884583e+01  9.38793037e+00 -2.69348608e+01
  1.01185348e+01  2.31686261e+01  2.38757965e+00 -2.66686755e+00
  1.45696411e+01  1.75511240e+00  6.30186851e-01  1.41288382e+01
 -8.14256650e+00 -4.00725968e+00  1.12014847e+01  7.10612045e-01
 -2.65401888e+01 -1.00679494e+00  2.19472826e+00 -2.60969900e+01
  4.19956725e+00  3.53595127e+01  8.09377452e-01  8.78426487e+00
  3.66762489e+00 -3.18575906e+00 -4.23939366e+00 -3.93088705e+00
 -1.75870911e+00 -4.55997969e-02  3.71061023e+00 -3.48543189e+00
  3.11284831e+01]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1206.4753069089513
gradient value of function right now is: [ 3.10890351e-01  7.08845953e-01  5.27033920e-01  3.60569910e-02
 -3.10890351e-01 -7.08845953e-01 -5.27033920e-01 -3.60569910e-02
 -6.08371260e-02 -5.49776901e-03 -1.41894536e-01 -2.25106953e-02
  5.27921439e-02  8.47087224e-02  4.52729398e-01  2.37707943e-02
  1.85657106e+00 -4.67701442e-02 -1.12560176e+00  1.81653940e-01
 -1.57189486e-03 -9.61440965e-05 -2.38292435e-03 -5.24611259e-04
 -1.80894001e-01 -1.67231104e-01 -3.52912974e+00 -3.58403402e-03
  2.60569645e-01  3.49715676e-02  4.55851268e-01  8.98502496e-02
  1.14709919e+00  1.23480408e-01  2.51762053e+00  1.19639012e-01
 -9.23743454e-02  5.05953806e-03  4.11849837e-01 -1.27721021e-02
  1.86628831e-01  2.84496629e+00  4.23216981e+00  1.49167801e-01
 -1.09692095e-01 -8.35771464e-01 -9.05526635e-01 -9.72625154e-02
 -1.39875470e-01 -1.60133675e+00 -3.67617960e+00 -1.11672309e-01
  8.21329449e-02  1.87024431e-01  1.27329273e+00  6.72697949e-02
 -2.35522429e+00  6.06466063e+00 -2.75683349e+00  9.30071414e+00
  1.97285606e+00 -2.11362331e+00 -1.61227005e+00  4.95979046e+00
  3.01914519e+01]
supnorm grad right now is: 30.191451907046726
Weights right now are: 
[  4.86628753  -2.66702609   3.09369443   0.6116335   -4.61171882
   2.5583344   -2.69475716  -1.32766189  38.02049668  34.55765011
  22.62849606  19.25272961  50.712381   -10.22936245   7.73206564
  28.63493349   3.02388884   5.18738717   3.912372    -3.04898763
  62.98210721  48.72195597  56.77314853  53.55932756  12.88454505
  -3.42814855   0.44554993  16.19129922   1.43137286  -0.378464
  10.1129889  -24.84105456  -9.20217811  10.18128755   8.75143006
 -25.77807349  10.22927868  26.75836734   2.31136839  -4.76936662
  14.66336325   1.23972837   1.12695645  14.05058356  -9.10623989
  -5.02588266  12.4109938   -0.34325056 -29.51059648  -1.17885095
   1.55632009 -29.64565107   5.70504092  37.1861777    1.9671446
  10.16051958   3.42027949  -3.59106917  -4.27691829  -3.77144932
  -1.3473153   -1.13074423   3.70725974  -3.76969575  31.18229504]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1203.4428376684837
gradient value of function right now is: [-2.88480707e-01 -9.82014312e-01 -1.27652786e+00 -2.29195363e-02
  2.88480707e-01  9.82014312e-01  1.27652786e+00  2.29195363e-02
  2.26509358e-02  3.82801632e-03  1.29339745e-01  3.88968278e-03
 -4.91806416e-02 -1.86473350e-01 -8.89136400e-01 -1.09021386e-02
 -9.41997832e-01  6.88946610e-02  2.00948351e+00 -9.23726345e-02
  2.02619116e-03  1.80465239e-04  5.42087019e-03  2.87095877e-04
  4.08548987e-01  1.53696701e-01  2.78404887e+00  5.83239083e-02
 -4.84813847e-01 -7.60762823e-02 -9.63191659e-01 -2.37265939e-01
 -9.89936917e-01 -1.43917033e-01 -2.73015226e+00 -2.42514745e-01
  5.14606626e-02  6.99990969e-03 -4.28180896e-02  1.91814162e-02
 -2.59841957e-01 -1.68572606e+00 -4.18750105e+00 -2.41493210e-01
  9.21125396e-02  2.74184901e-01  3.84367063e-01  8.62579704e-02
  1.30186431e-01  2.28712752e-01  2.24849241e+00  1.24368138e-01
 -2.15354284e-01 -3.67895427e-01 -2.70157501e+00 -2.08438732e-01
  1.82142098e+00 -8.18528982e+00  3.15114694e+00 -1.35841459e+01
  7.08563176e-01 -3.17310017e+00  1.61081630e+00 -8.45154928e+00
 -9.63590285e+00]
supnorm grad right now is: 13.584145906026214
Weights right now are: 
[ 3.67255222e+00 -3.01156460e+00  3.18437090e+00  2.57349400e+00
 -3.41798351e+00  2.90287291e+00 -2.78543364e+00 -3.28952238e+00
  4.26524302e+01  3.63489148e+01  2.23651340e+01  2.12773349e+01
  5.18035224e+01 -1.15807688e+01  7.97875841e+00  3.04452316e+01
  3.41916127e+00  6.04859004e+00  3.66125728e+00 -3.06012300e+00
  6.94289762e+01  5.59130569e+01  6.53005757e+01  5.48988048e+01
  1.24806444e+01 -2.57740311e+00  5.21661710e-01  1.78622721e+01
  4.35552953e-01 -1.71560023e+00  9.95556257e+00 -2.67008551e+01
 -1.12095334e+01  7.35406616e+00  7.93724181e+00 -2.34094362e+01
  1.17100511e+01  3.30258265e+01  2.79055709e+00 -4.38742246e+00
  1.41915961e+01  7.69894398e-01  1.62237007e+00  1.40095218e+01
 -8.71067079e+00 -5.74119166e+00  1.38073394e+01 -4.27591349e-02
 -3.29424801e+01 -6.92665184e-01  1.22768633e+00 -3.32601322e+01
  7.78189534e+00  3.79084794e+01  1.65620009e+00  1.18119135e+01
  3.64561442e+00 -3.69157125e+00 -3.20933254e+00 -4.18218310e+00
 -1.49405406e+00 -1.47390308e+00  4.00439914e+00 -3.68699277e+00
  3.12666023e+01]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.62873422676
gradient value of function right now is: [-9.31565139e-02 -9.81243054e-02 -1.55398700e+00 -1.10433617e-02
  9.31565139e-02  9.81243054e-02  1.55398700e+00  1.10433617e-02
  1.48105949e-02  2.49872056e-04  3.05514411e-02  4.17870026e-04
 -8.49579255e-03  5.25297111e-02  7.01883194e-02 -2.16546575e-04
  1.25533816e+00 -7.14214493e-03 -3.00149068e-01  9.05547914e-02
  1.83490348e-03  2.36473443e-05  2.47631809e-03  4.72999216e-05
 -2.68899400e-01 -1.67827370e-01 -3.22850535e+00 -4.84252950e-03
  8.34438084e-02  2.52504937e-02  1.15846783e-01  5.10369191e-02
 -1.50076714e-02 -1.66524734e-02 -2.79171684e-01 -1.79512701e-02
  1.72558249e-02  9.61813553e-03  3.64361638e-01  4.42982987e-05
  5.58232329e-02  1.77996924e+00  1.37744432e+00  3.95581590e-02
 -5.52163686e-02 -6.80538338e-01 -5.17318237e-01 -4.63601220e-02
  1.39500264e-02 -1.20323700e-01 -1.54899928e-01  1.31114859e-02
 -5.06006607e-03  3.23361718e-03  8.16960274e-02 -4.99033282e-03
 -7.62865068e-01 -1.61616158e-01 -9.17025302e-01  1.10941196e+00
  1.13820089e+00 -2.00634669e-01 -4.14492872e-01 -2.78981008e-01
 -1.22210722e+00]
supnorm grad right now is: 3.2285053526060232
Weights right now are: 
[  4.43931051  -2.80456508   3.03987725   3.32645535  -4.1847418
   2.69587339  -2.64093998  -4.04248374  46.32712003  36.67095222
  21.08127     23.10173169  54.2801719  -11.37911297   9.3861492
  32.94574231   3.30951468   7.72892129   3.34534913  -4.47884601
  72.17517643  62.35234976  66.77138344  52.3848155   12.20229746
  -3.13484987   0.59438754  16.63157716   1.20324743  -0.31031229
  10.68994211 -26.97836617 -12.08231032   5.12467494   8.24039822
 -21.94665796  14.66348085  41.67128926   1.93066142  -2.62332803
  13.70323822   0.79063671   1.74614575  13.88934448  -9.1142339
  -6.51853981  14.37262836  -0.41914013 -36.68403252  -1.15684623
   1.02917978 -36.89884238  10.85276541  39.5062033    1.86819189
  14.33463187   3.01991926  -3.73337067  -4.26853372  -3.69802417
  -1.40769674  -1.51688989   3.43976359  -3.75282914  31.00565136]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.6563955629135
gradient value of function right now is: [-5.67337358e-02  2.94436323e-02 -2.72448422e+00 -1.68977711e-02
  5.67337358e-02 -2.94436323e-02  2.72448422e+00  1.68977711e-02
  4.42371564e-02 -4.87154617e-04 -2.00017333e-02  5.85272814e-04
 -1.92456225e-02  4.22977648e-02  1.06287267e-01 -2.64040732e-04
  2.16456765e+00 -4.91748453e-03 -9.76609146e-02  8.28861781e-02
  2.08717806e-03  4.33220941e-06  2.57532097e-04  1.29156356e-05
 -5.81543364e-01 -4.20922481e-01 -5.28628430e+00 -2.01393850e-02
  8.54523846e-02  3.39336854e-02  1.42357026e-01  4.84099469e-02
  7.96728837e-02  3.93522601e-02  1.44510591e-01  3.76905884e-02
  2.28293346e-02  6.40632209e-03  3.84117629e-01 -2.86865415e-06
  1.94208409e-01  1.28471694e+00  1.99371286e+00  1.67714227e-01
 -1.55588052e-01 -5.40865610e-01 -6.46447138e-01 -1.36193399e-01
 -4.55346056e-03  1.25169528e-02 -6.55830239e-02 -6.21301021e-03
  3.12603356e-02  6.10269709e-02  3.37595222e-01  3.02975426e-02
 -9.13740843e-01  2.63154927e+00 -7.18401898e-01  2.99817537e+00
  3.82676710e-01  2.34596096e-01 -5.10059657e-01  2.38558250e+00
  1.64906229e+01]
supnorm grad right now is: 16.490622896963007
Weights right now are: 
[  5.12855703  -2.95636789   2.9162278    1.02059     -4.87398832
   2.8476762   -2.51729053  -1.73661838  50.73357343  38.27524285
  19.18745556  28.82006459  56.08770772 -11.58419706   9.39832822
  31.46087352   3.12202966   8.43469646   4.07800761  -5.23147042
  78.00211857  69.20994083  71.33879097  56.2351621   11.63758169
  -3.14573735   0.51510805  15.80565793   1.17285756  -1.17502018
  10.42090016 -27.77982144 -12.03565609   5.21498199   8.63405493
 -20.8032192   16.59684242  50.12964714   2.21195492   4.69058811
  13.77946534   0.4792057    2.09104076  14.46151465 -10.6888691
  -6.97834043  14.40331275  -1.45784236 -39.52696211  -1.07020326
   1.05954023 -39.89171086  13.61241899  40.85213831   2.35096663
  16.57495956   3.10817923  -3.94042878  -3.43125176  -3.87216662
  -1.87629254  -1.78822379   3.84483707  -3.91822655  31.12125407]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.122223211143
gradient value of function right now is: [-1.10758836e-01 -1.47990218e-01 -2.66840422e-01 -1.45757223e-02
  1.10758836e-01  1.47990218e-01  2.66840422e-01  1.45757223e-02
  3.08970474e-02  1.34705535e-04  3.92818409e-02  3.42665178e-04
 -3.30281481e-02  2.76805154e-02 -3.67272851e-02 -5.36548329e-04
 -8.48925272e-01  2.89162090e-03  8.57307505e-01 -5.02391727e-02
  2.14772685e-03  4.01331016e-06  9.51967631e-04  9.42145135e-06
  2.55337497e-02  7.68017661e-02  1.87754745e+00 -1.24356540e-02
  3.38403035e-02  1.92462616e-02  5.42943865e-02  3.86425940e-02
 -6.27710256e-01 -1.97061363e-02 -1.29570964e+00  1.28775449e-02
 -1.27625767e-02 -3.56054976e-03 -2.64413678e-01  1.83151481e-05
 -5.75798368e-02 -1.93409817e+00 -2.69606629e+00 -4.31094077e-02
  7.58931255e-02  3.33775480e-01  3.14212882e-01  6.74822560e-02
  2.93742034e-02  1.07963518e+00  1.81193074e+00  2.47665017e-02
  1.92553411e-02  4.58869542e-03  1.42676370e-01  2.06151399e-02
  1.30298617e+00 -9.83850975e-01  9.17238492e-01 -6.30356933e-01
 -1.20966522e-04 -1.90802823e-01  9.80428291e-01 -6.49619330e-01
 -7.70333269e+00]
supnorm grad right now is: 7.703332685058874
Weights right now are: 
[  4.62357329  -3.30248751   3.07809027   2.0830508   -4.36900458
   3.19379582  -2.67915301  -2.79907918  53.22231038  39.66503518
  19.42565239  31.93510769  57.94774763 -12.29581919  10.17377404
  31.11362933   3.40867891  10.79622873   3.58098921  -5.78978855
  83.92929573  71.82660078  72.68309665  58.17215993  11.56435239
  -3.07935124   0.68148602  16.58502987   1.5766716    0.58449309
  11.24622707 -28.02573329 -12.47395905   4.46182207   8.34945001
 -20.08155959  18.85350999  58.5158095    2.30237565  11.56057447
  13.52107473   0.15273109   1.90528083  14.69709615  -9.37474056
  -7.17457529  15.46703788  -0.21302672 -42.9696872   -0.96087196
   1.26144021 -43.18824116  16.39310562  41.59875648   2.19624265
  18.92264914   3.65246072  -3.62949964  -4.10635259  -4.091046
  -1.93577643  -1.69902655   4.1145365   -3.5500017   31.08164808]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.4070653433926
gradient value of function right now is: [-5.96094707e-02 -1.13602926e-01  4.48248019e-01 -2.65149355e-03
  5.96094707e-02  1.13602926e-01 -4.48248019e-01  2.65149355e-03
  4.36427913e-03  2.96751235e-04  4.89732633e-02 -9.21739859e-05
 -7.27448654e-03 -2.97483832e-02 -9.52154381e-02  1.80167625e-05
 -4.29221964e-01  3.14377659e-03  4.67201271e-01 -4.27799268e-02
  1.12116263e-04  2.45023186e-06  3.29183375e-04 -5.05759346e-07
  1.79902650e-01 -3.76339475e-02  1.22375834e+00 -6.24916800e-03
 -5.00908776e-02 -1.48106773e-02 -6.79850366e-02 -2.23406047e-02
 -3.72945286e-01 -8.88625751e-02 -7.70664601e-01 -5.41749991e-02
 -2.30112452e-02 -3.70251197e-03 -2.67928721e-01  7.37400392e-07
 -6.58434120e-02 -1.48389637e+00 -1.63055289e+00 -5.46950731e-02
 -6.55986341e-03  2.87877839e-01  2.62468405e-01 -1.15748022e-02
  1.74874792e-02  2.16061758e-01  5.03384942e-01  1.70899071e-02
 -1.40180515e-02 -3.96710067e-02 -2.06995903e-01 -1.38350557e-02
  8.14808205e-01 -1.40781902e+00  6.03107686e-01 -1.82493322e+00
 -1.00318177e-01 -5.07634733e-01  6.41544222e-01 -1.42243005e+00
 -3.27564292e+00]
supnorm grad right now is: 3.2756429226278416
Weights right now are: 
[  5.55943535  -3.05713409   3.06324116   1.2710616   -5.30486664
   2.9484424   -2.66430389  -1.98708999  54.41932444  42.69198857
  17.92973907  28.63732851  62.42766711 -12.90681714  10.48710163
  34.98138771   3.16141248  11.20788703   2.89664611  -7.01281203
  90.28487413  73.16846753  73.78196274  58.19652615  10.56394294
  -3.09778744   0.42535832  15.73233162   1.726216    -0.51662087
  11.31110577 -28.64065946 -12.03927686   4.60765406   8.65246204
 -20.02531216  18.15954684  65.9079781    1.60464942  15.11732867
  13.26148756  -0.242183     1.97633445  15.10580838 -10.32628062
  -7.5336749   15.53871923  -1.05884985 -46.48757338  -0.37324948
   0.74245095 -46.49822425  17.49568166  43.29511872   2.3191239
  19.28809615   3.35627252  -4.03177394  -3.65033451  -4.27377937
  -1.62933475  -2.06110989   3.7475555   -3.97939616  31.10917969]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.3975560232568
gradient value of function right now is: [ 6.81556470e-02  1.29399657e-01 -6.41004993e-01  1.01362084e-03
 -6.81556470e-02 -1.29399657e-01  6.41004993e-01 -1.01362084e-03
 -1.01736113e-02 -6.47831382e-04 -6.77682833e-02 -8.09364727e-06
  8.85428180e-03  1.47989397e-02  8.77698720e-02  2.86698555e-06
  1.51129498e+00 -1.56131381e-03 -1.03582196e-01  1.27309061e-02
 -4.43502684e-05 -4.07392726e-06 -3.94894377e-04  7.47414567e-08
 -8.46362311e-02 -2.87170551e-01 -3.19355166e+00  5.74427769e-03
  4.92048199e-02  1.83175978e-02  9.83262669e-02  2.37142420e-02
  2.87284929e-01  9.23804326e-02  8.51086964e-01  6.04634455e-02
 -4.47079887e-04  1.55157795e-03  9.47274420e-02  3.58786923e-07
  1.27604736e-01  3.47119581e-01  7.91941967e-01  1.16134634e-01
 -1.34292436e-01 -3.93363044e-01 -4.44312329e-01 -1.20719068e-01
 -2.81418361e-02 -1.18839491e-01 -3.00611510e-01 -2.63348263e-02
  2.21877888e-02  4.97067260e-02  2.47876245e-01  2.18252203e-02
 -9.19761129e-01  2.90438780e+00 -4.68122823e-01  2.28006034e+00
  5.69739190e-01 -4.52981312e-01 -6.44135201e-01  2.81395786e+00
  2.34272839e+01]
supnorm grad right now is: 23.427283888660245
Weights right now are: 
[  6.5497542   -3.14820314   3.14666996   2.8659367   -6.29518549
   3.03951145  -2.74773269  -3.58196508  55.39696492  44.96949049
  18.87496791  33.05846224  65.80928454 -13.04681611  10.99164853
  31.01692293   3.4252429   15.72489201   3.90267714  -7.04489917
  98.27596307  73.80447681  77.13982074  58.302344    11.02599558
  -2.932118     0.46462886  15.20684142   1.58387158  -0.57627322
  10.63836435 -29.75818611 -12.86081401   3.85708821   8.57868942
 -18.98836798  19.839596    74.44179907   2.30432091  17.02050069
  14.92814926   0.16915746   1.76223837  18.13017919 -10.4676434
  -8.05357484  15.8380341   -0.44284333 -49.94140385  -0.67919094
   1.13498063 -49.33529098  19.70071184  44.31099508   1.99226467
  20.60415911   3.16811322  -4.19600428  -4.69632785  -4.26278346
  -2.1577155   -2.01674847   3.79775279  -4.15375123  31.26134514]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.8183376092913
gradient value of function right now is: [ 5.15382272e-02  2.39990831e-02  1.68279311e+00  3.71624672e-03
 -5.15382272e-02 -2.39990831e-02 -1.68279311e+00 -3.71624672e-03
 -3.37714291e-02  2.25947205e-06 -9.36739351e-06 -3.76953632e-06
  1.43916056e-02 -2.01026150e-02 -3.77452092e-02  1.49808549e-06
 -1.02585857e+00  1.07421331e-04 -1.18489068e-03 -1.04766301e-03
 -2.88212112e-04 -1.97655747e-07 -6.34368090e-05 -2.57061787e-08
  4.51024464e-01  3.54999312e-01  2.89732796e+00  4.47753760e-03
 -3.12520936e-02 -1.48670786e-02 -3.70580692e-02 -1.83756901e-02
  4.30537001e-02  8.79209332e-03  1.42488735e-01 -2.84979497e-02
 -7.45280263e-04 -1.33196509e-04 -7.36741063e-03 -1.20448554e-08
 -9.31085129e-02 -6.89770289e-01 -8.53493466e-01 -7.85300973e-02
  7.16238498e-02  2.75205399e-01  2.78966606e-01  6.06349901e-02
 -2.66413088e-03 -4.74885838e-01 -3.38005552e-01  5.20949277e-05
 -9.32752553e-03 -2.62984029e-02 -1.17141375e-01 -8.53145081e-03
  2.42767671e-01 -1.03639919e+00  2.66815925e-01 -1.29647782e+00
 -1.65459849e-01 -1.02355090e-01  1.74655849e-01 -1.03169085e+00
  2.93933938e+00]
supnorm grad right now is: 2.939339381801275
Weights right now are: 
[  6.24737071  -2.88408814   3.09938187   0.64129683  -5.992802
   2.77539645  -2.7004446   -1.35732521  60.19301476  45.44385655
  18.45222108  37.1138897   65.80855534 -13.70253483  10.11853957
  26.69045745   2.99399178  12.39421356   3.28005988  -7.57223035
 107.30094879  75.58655474  79.90125023  58.61797824  10.40796286
  -2.75637399   0.8257169   15.51419891   1.84131155  -0.48070139
  11.22110329 -30.29350656 -12.68681286   3.77993681   8.63455877
 -18.55562309  18.5967489   80.53905669   2.19896464  19.27023929
  13.13177212   0.19834349   1.98889354  16.39935151 -10.29651615
  -8.52250787  16.51551186  -0.40179728 -53.13358295  -1.17054173
   0.87778931 -52.80601465  21.44128916  47.07989302   2.73091125
  22.01164975   3.12680409  -4.24771064  -3.89740727  -4.25857154
  -1.37301927  -2.1729565    3.93761225  -4.2256725   31.14961803]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.1981269570515
gradient value of function right now is: [-8.83915409e-02 -1.87159949e-01 -5.59374666e-01 -2.01978927e-03
  8.83915409e-02  1.87159949e-01  5.59374666e-01  2.01978927e-03
  2.09230400e-02  7.93861415e-04  7.28831832e-02  5.07272462e-06
 -1.56573081e-02 -8.29612646e-02 -2.44381744e-01 -5.20604620e-06
 -6.27110640e-01  1.31162043e-02  9.92467391e-01 -1.85526376e-02
 -1.86290072e-04 -2.51311084e-06 -2.11000656e-04 -8.24744358e-09
 -5.31648395e-02  5.32438655e-02  7.66891175e-01 -3.96092190e-03
 -2.37908258e-01 -1.03663133e-01 -3.80061543e-01 -1.19870976e-01
 -7.71384957e-01 -2.00406124e-01 -1.54569268e+00 -1.13963471e-01
 -9.11517379e-03 -1.29235225e-03 -1.31982369e-01  9.23979052e-08
 -4.49800381e-02 -1.03923020e+00 -1.52483698e+00 -3.71412205e-02
  6.31000810e-02  2.88467291e-01  3.15459915e-01  5.51604315e-02
  3.95961485e-02  5.32257228e-01  1.16129585e+00  3.60443130e-02
 -3.85348354e-02 -9.44538037e-02 -5.34273202e-01 -3.68786507e-02
  1.05018308e+00 -3.29396075e+00  1.38480828e+00 -5.07457521e+00
 -3.17732925e-02 -9.58839834e-01  7.97724297e-01 -3.14375554e+00
 -1.10857620e+01]
supnorm grad right now is: 11.085761988029226
Weights right now are: 
[ 6.47993222e+00 -3.50832957e+00  3.03188486e+00 -2.45137574e+00
 -6.22536351e+00  3.39963788e+00 -2.63294759e+00  1.73534736e+00
  6.13504442e+01  4.84243029e+01  1.83482506e+01  4.01521493e+01
  6.96855747e+01 -1.37653159e+01  1.03818546e+01  2.40633436e+01
  3.02673630e+00  1.41433586e+01  3.61902282e+00 -8.06005600e+00
  1.18543880e+02  7.57675002e+01  9.03987434e+01  5.86561197e+01
  1.02207241e+01 -2.86251053e+00  4.24178133e-01  1.59846837e+01
  2.25523203e+00 -1.17625740e+00  1.11043795e+01 -3.05631532e+01
 -1.24058704e+01  4.48395069e+00  8.95466393e+00 -1.91727417e+01
  1.88897759e+01  8.87733036e+01  2.38654151e+00  2.27129599e+01
  1.43932638e+01 -7.90239321e-02  2.12879193e+00  1.84611681e+01
 -9.67122276e+00 -8.86988235e+00  1.66532036e+01  2.17326461e-01
 -5.57605687e+01 -6.40814342e-01  1.06089297e+00 -5.54900939e+01
  2.16051667e+01  4.83594475e+01  2.87717393e+00  2.17862944e+01
  3.53514058e+00 -4.17947824e+00 -3.98441158e+00 -4.51687050e+00
 -1.99073248e+00 -2.35884607e+00  4.02204730e+00 -4.16226296e+00
  3.11238358e+01]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1206.809094352977
gradient value of function right now is: [ 3.46072951e-02  8.13545818e-02  1.49298100e+00  3.91038532e-04
 -3.46072951e-02 -8.13545818e-02 -1.49298100e+00 -3.91038532e-04
 -9.34509900e-03 -1.22961363e-04 -3.57764875e-02 -6.16081770e-05
  7.16314729e-03  3.80380382e-02  1.09991335e-01  6.77020077e-05
 -9.59407565e-01 -4.57694593e-03 -6.21965549e-01 -2.49232651e-02
  3.96284422e-05 -4.80541786e-09  1.17083766e-06  2.53557581e-08
  1.26374221e-01  6.00835945e-02  2.37591971e+00  1.78094654e-03
  7.08418570e-02  1.57531939e-02  1.12630972e-01  3.98095477e-02
  4.11035575e-01  3.00653936e-02  8.84633741e-01  4.78391276e-02
 -8.69611642e-03 -3.23505389e-03 -2.12098832e-01 -1.82984894e-05
 -2.20453431e-02  1.86160193e-01  7.69047308e-01 -2.08217992e-02
  3.80873633e-02  2.66090317e-01  2.76922469e-01  3.17233819e-02
 -1.76345900e-02 -2.84778972e-01 -1.00325064e+00 -1.51538872e-02
  1.06749687e-02  3.05569413e-02  2.90422542e-01  9.63274741e-03
 -8.59682414e-02  1.15266188e+00 -2.25483986e-01  1.60349634e+00
 -1.04742552e+00  2.13952767e+00 -1.65335161e-01  1.06545135e+00
 -7.62206305e+00]
supnorm grad right now is: 7.62206305124326
Weights right now are: 
[ 6.10549213e+00 -3.23288048e+00  3.13684792e+00 -1.56594519e+00
 -5.85092342e+00  3.12418879e+00 -2.73791065e+00  8.49916810e-01
  6.26796697e+01  4.87042646e+01  1.88906837e+01  4.22538125e+01
  7.32730032e+01 -1.24977626e+01  1.09118032e+01  2.35403594e+01
  3.38917895e+00  1.41552185e+01  3.15341974e+00 -8.87524241e+00
  1.28600787e+02  7.58959626e+01  9.96786455e+01  5.86582465e+01
  1.08606500e+01 -3.35201849e+00  6.34804632e-01  1.56559022e+01
  2.85176454e+00 -5.82623695e-01  1.17674118e+01 -3.07658725e+01
 -1.27961605e+01  3.87990995e+00  9.02118377e+00 -1.90955623e+01
  1.97192131e+01  9.45070102e+01  2.18434408e+00  2.38387727e+01
  1.42585470e+01  1.12890653e-01  2.23181696e+00  1.91565570e+01
 -1.08044520e+01 -9.88965500e+00  1.73674251e+01 -1.21432335e+00
 -5.92277178e+01 -8.40997064e-01  6.08338342e-01 -5.86975098e+01
  2.34538136e+01  5.06683715e+01  3.43766804e+00  2.31157225e+01
  3.27319723e+00 -4.17563978e+00 -4.43745405e+00 -4.36139687e+00
 -2.47974296e+00 -1.75943029e+00  3.68977830e+00 -4.22499423e+00
  3.09934818e+01]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.505855161782
gradient value of function right now is: [ 5.70113089e-02  1.24084462e-01  1.64921639e+00  3.88573497e-04
 -5.70113089e-02 -1.24084462e-01 -1.64921639e+00 -3.88573497e-04
 -1.00560931e-02 -1.42341038e-04 -5.18671879e-02  5.77682466e-05
  7.33411817e-03  5.51159202e-02  1.50303915e-01 -1.63163252e-05
 -1.03284888e+00 -5.11927519e-03 -7.10541585e-01 -3.81073497e-02
  8.90440218e-06  1.51093803e-08  6.02671529e-06  5.49763704e-09
  1.61673052e-01  9.68533973e-02  2.45909594e+00  3.16270273e-03
  9.46326396e-02  2.96707387e-02  1.43992329e-01  5.40913163e-02
  5.10849171e-01  8.09085025e-02  1.08268445e+00  8.98311566e-02
 -2.16133893e-02 -3.50076377e-03 -3.25936353e-01 -7.31194464e-06
 -1.20156648e-02 -8.32511185e-02  4.98407173e-01 -1.26159406e-02
  5.46598302e-02  3.30053350e-01  3.02104999e-01  4.95476207e-02
 -2.50936299e-02 -1.83835022e-01 -7.85838610e-01 -1.90940849e-02
  2.25204519e-02  5.07254584e-02  4.00513250e-01  1.72105983e-02
 -3.31894747e-02  2.15324041e+00 -2.00244222e-01  2.53305425e+00
 -9.59176271e-01  1.91385633e+00 -9.39102872e-02  1.65918207e+00
  8.33642558e+00]
supnorm grad right now is: 8.336425575329143
Weights right now are: 
[ 6.51296086e+00 -3.32021419e+00  3.18432337e+00 -7.02198073e-01
 -6.25839215e+00  3.21152250e+00 -2.78538610e+00 -1.38303096e-02
  6.37252881e+01  5.24252263e+01  1.93510459e+01  4.36339515e+01
  7.70095871e+01 -1.21448079e+01  1.08324646e+01  2.13086940e+01
  3.32603219e+00  1.66081480e+01  3.23889001e+00 -9.34854944e+00
  1.29653292e+02  7.60798846e+01  1.10671490e+02  5.86268734e+01
  1.08489781e+01 -2.86843719e+00  6.28246141e-01  1.32327743e+01
  3.36833333e+00 -3.69756688e-01  1.19173358e+01 -3.07161243e+01
 -1.23878162e+01  3.90057793e+00  9.04054712e+00 -1.93260660e+01
  1.90670189e+01  1.02396483e+02  1.95531442e+00  2.55122595e+01
  1.40073150e+01 -2.88096642e-01  2.34697303e+00  1.93160747e+01
 -9.41324731e+00 -1.01305274e+01  1.75535524e+01 -3.18240461e-02
 -6.17920981e+01 -8.18546096e-01  9.12504912e-01 -6.12080898e+01
  2.42426391e+01  5.19520663e+01  3.66541030e+00  2.36423982e+01
  3.84757979e+00 -4.21261970e+00 -3.93864460e+00 -4.34895576e+00
 -2.40978658e+00 -1.95210344e+00  4.11285441e+00 -4.45971813e+00
  3.11148940e+01]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1206.2541858717545
gradient value of function right now is: [-1.09816189e-01 -2.78304122e-01 -1.15519313e+00 -4.01056110e-04
  1.09816189e-01  2.78304122e-01  1.15519313e+00  4.01056110e-04
  1.48970503e-02  1.01972969e-03  9.99179198e-02  1.36846871e-07
 -1.23367117e-02 -1.49281612e-01 -3.73299195e-01  4.92424265e-09
  1.21539236e-01  1.77261707e-02  7.95908915e-01 -3.00714543e-03
 -1.33247095e-06 -3.70920445e-08 -3.92284852e-06 -2.61105114e-11
 -5.62810756e-02  7.25863560e-04 -5.63134928e-01  6.76112802e-03
 -3.88253225e-01 -2.24027343e-01 -6.25951489e-01 -2.07645990e-01
 -5.43577891e-01 -2.79960252e-01 -1.24552575e+00 -1.48135282e-01
 -1.70265695e-03  9.75018629e-05 -2.56006861e-02  6.85749818e-10
 -2.42487583e-02  8.18049785e-02 -2.34697985e-01 -2.55836728e-02
  1.27778340e-02  1.79870144e-02  6.96983236e-02  1.05177258e-02
  3.82294929e-02  1.74088410e-02  3.87099091e-01  3.52404188e-02
 -5.87406022e-02 -1.24988673e-01 -6.42813483e-01 -5.48605487e-02
  4.84556008e-01 -4.13139009e+00  1.23087769e+00 -6.70507594e+00
  2.66981801e-01 -1.38150274e+00  4.27283247e-01 -3.92509808e+00
 -1.97684009e+00]
supnorm grad right now is: 6.705075936050225
Weights right now are: 
[ 6.31026282e+00 -3.36468478e+00  2.93821562e+00 -4.93985752e-01
 -6.05569411e+00  3.25599309e+00 -2.53927835e+00 -2.22042631e-01
  6.70778402e+01  5.58367594e+01  1.92052403e+01  5.02033216e+01
  7.84303247e+01 -1.30069660e+01  1.03683889e+01  1.64830141e+01
  3.19337492e+00  1.73840521e+01  2.82359838e+00 -9.50856463e+00
  1.40755938e+02  7.61250188e+01  1.22503876e+02  5.86100742e+01
  1.03351029e+01 -2.56504365e+00  5.61635954e-01  1.48210163e+01
  3.19267577e+00 -1.19058778e+00  1.12788735e+01 -3.20506043e+01
 -1.28327150e+01  4.08942288e+00  9.01591678e+00 -1.83289859e+01
  1.83999436e+01  1.04487699e+02  2.11092693e+00  2.66689974e+01
  1.42438851e+01 -1.14667717e-01  2.53287205e+00  1.96638917e+01
 -9.77619521e+00 -1.05876228e+01  1.79111626e+01 -9.76117654e-02
 -6.44525986e+01 -8.98558371e-01  1.26291003e+00 -6.42142476e+01
  2.49819078e+01  5.35931148e+01  3.46271056e+00  2.43980546e+01
  3.26195081e+00 -4.46070772e+00 -3.63289846e+00 -4.68075668e+00
 -1.88920009e+00 -2.66607709e+00  3.96926592e+00 -4.44932085e+00
  3.12170992e+01]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.009307975781
gradient value of function right now is: [ 2.19435431e-03  2.49002476e-02  8.38846532e-02 -2.88437829e-04
 -2.19435431e-03 -2.49002476e-02 -8.38846532e-02  2.88437829e-04
  7.36396516e-03 -9.07104298e-05 -1.66377743e-02  3.20451783e-05
 -1.20796393e-03 -9.10180570e-03  1.25414824e-02 -1.20026635e-05
 -6.85208319e-01  1.12685236e-03  3.37039242e-01 -1.46018728e-03
  5.68669113e-06  4.43334811e-09  1.48298280e-06  1.09115841e-09
 -1.29368299e-01  1.25257869e-01  9.97812198e-01 -9.35930184e-03
 -1.02218178e-02  7.79458835e-03  5.21918482e-03  2.06879645e-03
 -1.34986844e-01  2.91502004e-02 -1.51365849e-01  3.31446433e-02
  8.43212509e-04 -5.01421852e-04 -2.08615722e-02  2.27900316e-06
 -1.42987117e-03 -4.35604867e-01 -5.25894661e-01  4.23369025e-03
  3.44980915e-02  1.34192051e-01  1.22526576e-01  2.92991947e-02
  1.35490251e-03  3.35808685e-01  6.86128287e-01 -9.53157175e-04
  1.46117509e-02  4.31408273e-03  5.53603048e-02  1.52241755e-02
  4.50692040e-01  4.88329869e-01  4.40670821e-01 -8.95821489e-02
 -9.92485220e-02  2.72177879e-01  2.69711549e-01  7.67210467e-01
 -1.42538620e+01]
supnorm grad right now is: 14.253862016967137
Weights right now are: 
[ 6.29774291e+00 -3.27189696e+00  3.11852520e+00 -8.34849452e-02
 -6.04317420e+00  3.16320527e+00 -2.71958793e+00 -6.32543438e-01
  6.78834370e+01  5.81116081e+01  1.90288993e+01  4.57657232e+01
  8.21050717e+01 -1.34976189e+01  1.11266036e+01  1.60387186e+01
  3.31155495e+00  1.87561342e+01  3.15189107e+00 -9.44770809e+00
  1.51000051e+02  7.62171581e+01  1.32865500e+02  5.86045554e+01
  9.63206371e+00 -2.28298436e+00  5.85575559e-01  1.24312562e+01
  3.99923530e+00 -1.99408265e-01  1.18029991e+01 -3.18115540e+01
 -1.27373539e+01  3.89004472e+00  9.20552119e+00 -1.90663191e+01
  1.83763336e+01  1.09575430e+02  2.35491630e+00  2.79565714e+01
  1.37144240e+01 -4.86724954e-01  2.47242557e+00  1.95832768e+01
 -1.03300567e+01 -1.08511224e+01  1.83362726e+01 -8.63025808e-01
 -6.74110471e+01 -8.23765121e-01  1.45449821e+00 -6.74575259e+01
  2.64648945e+01  5.56486362e+01  3.73725495e+00  2.57318316e+01
  3.18015672e+00 -4.06646436e+00 -3.54051929e+00 -4.68466237e+00
 -1.92612012e+00 -2.11686694e+00  3.87013325e+00 -3.98980442e+00
  3.09498443e+01]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.4426942583955
gradient value of function right now is: [ 9.02098337e-02  8.73972144e-02  1.78161793e+00  2.36781059e-03
 -9.02098337e-02 -8.73972144e-02 -1.78161793e+00 -2.36781059e-03
 -2.73261932e-02 -8.21707844e-05 -2.48632604e-02 -1.86832789e-04
  1.22157258e-02  4.33967835e-03  3.71844317e-02  8.31604837e-05
 -1.07892000e+00 -1.12222472e-03 -2.21365657e-01 -9.43686709e-03
  3.05931775e-05  2.45157878e-08  9.84314432e-06  3.91131274e-08
  3.51461827e-01  2.03328759e-01  3.18037145e+00  8.23337569e-03
  1.98480369e-02  9.55641674e-03  3.91132958e-02  1.15121308e-02
  2.17409080e-01  2.79116673e-02  4.78722558e-01  1.76812073e-02
 -3.98927421e-03 -1.50425147e-03 -8.26862539e-02  3.58360175e-07
 -6.58610563e-02 -3.06661332e-01 -4.13624992e-01 -5.60577940e-02
  9.39072683e-02  2.73059228e-01  2.68617971e-01  8.62236929e-02
 -9.98563008e-03 -2.23721913e-01 -4.33547326e-01 -7.86481109e-03
  3.78847817e-03  4.32454001e-03  4.02548831e-02  3.19459954e-03
  1.46310675e-01  2.86139834e-01  5.40642328e-02  2.68784399e-01
 -3.02648929e-01 -8.96694529e-03  7.65944046e-02  3.69207532e-02
 -9.87985339e+00]
supnorm grad right now is: 9.879853386741441
Weights right now are: 
[ 6.35143133e+00 -3.64856088e+00  2.93404250e+00 -6.03530393e-01
 -6.09686262e+00  3.53986919e+00 -2.53510523e+00 -1.12497990e-01
  6.93892010e+01  6.54859641e+01  1.96681566e+01  4.82718695e+01
  8.49939069e+01 -1.24662743e+01  1.09345483e+01  1.18207446e+01
  3.40638115e+00  1.70875176e+01  3.09278785e+00 -1.00305500e+01
  1.57940196e+02  7.63206956e+01  1.40192832e+02  5.86078949e+01
  1.06258212e+01 -2.50905450e+00  7.18593043e-01  1.35845127e+01
  4.23617926e+00  2.66804971e-01  1.17305657e+01 -3.20577423e+01
 -1.24304584e+01  3.75419407e+00  9.57980991e+00 -1.88016695e+01
  1.63226072e+01  1.13284457e+02  2.45583609e+00  2.91041639e+01
  1.29850745e+01 -1.58307545e-01  2.41407076e+00  1.93862843e+01
 -9.25782026e+00 -1.10889787e+01  1.92331390e+01  2.43786607e-01
 -7.08011078e+01 -1.40552378e+00  1.11031395e+00 -7.10081887e+01
  2.60684295e+01  5.77378164e+01  3.83309434e+00  2.48704327e+01
  3.57462424e+00 -4.24524454e+00 -4.01509902e+00 -4.57588385e+00
 -2.09076302e+00 -2.19859457e+00  3.99870390e+00 -4.37943115e+00
  3.09808320e+01]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.0885339989766
gradient value of function right now is: [-8.78232425e-02 -1.00177926e-01 -1.02640648e+00 -1.74808338e-04
  8.78232425e-02  1.00177926e-01  1.02640648e+00  1.74808338e-04
  2.56328415e-02  1.94531903e-04  6.14312847e-02  2.62786440e-04
 -1.31147525e-02  3.16231357e-02 -1.61546790e-02 -1.00976250e-04
  4.15118483e-02  2.19282267e-03  5.65384698e-01 -3.11523647e-02
 -1.15767957e-05 -4.28384905e-08 -1.20575934e-05 -5.12846881e-08
 -2.43416008e-01 -5.53303112e-02 -5.79864984e-01 -9.44273113e-03
  1.39432892e-02  8.25947357e-03  5.56207009e-03  1.60048569e-02
 -6.09071612e-01 -7.83468915e-02 -1.30420721e+00 -6.10258039e-02
 -1.74182874e-02 -1.40392479e-03 -3.16641827e-01  7.79388630e-07
 -1.23362687e-02 -2.06833905e-01 -6.80511487e-01 -1.20675045e-02
 -1.17042057e-03  1.65029859e-01  1.67024966e-01 -7.30543158e-03
  2.42852460e-02  1.97222166e-01  7.98898532e-01  2.52716694e-02
 -6.42582684e-03 -2.25812185e-02 -1.07191858e-01 -7.42153608e-03
  5.79753843e-01 -1.81335754e+00  3.79637689e-01 -1.46854579e+00
 -2.71707444e-01 -2.65313623e-01  4.94780264e-01 -2.03967603e+00
  3.83191966e+00]
supnorm grad right now is: 3.831919664898821
Weights right now are: 
[  6.57012244  -3.06824751   2.9240565   -1.73475735  -6.31555373
   2.95955582  -2.52511923   1.01872897  70.61434422  66.87134806
  20.38581902  53.22700349  88.00250655 -12.25785139  11.03129835
   7.44747205   3.80880243  18.9449692    3.23646269 -10.61614377
 160.32321396  76.44038146 150.29595331  58.56470866  10.53021638
  -2.48734852   0.53404348  11.41692002   3.92546562  -0.29695886
  11.01238111 -33.09216054 -13.16075337   3.67512236   9.42326183
 -18.07711873  17.12130129 119.57621852   1.97101357  30.56392275
  14.18885321  -0.39933647   2.25915254  21.33940702  -9.85392994
 -11.37936166  19.42850615   0.17422195 -73.01036017  -1.80483825
   1.23847    -73.30229891  27.06364485  59.27919406   4.02675712
  25.51205639   3.56609289  -4.85484263  -4.24848367  -4.48315812
  -2.65502199  -2.25512112   4.42851169  -4.58940142  31.17618141]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.090754724434
gradient value of function right now is: [-6.67438700e-02 -1.20910905e-01 -6.35421356e-01 -5.44946242e-04
  6.67438700e-02  1.20910905e-01  6.35421356e-01  5.44946242e-04
  1.24366080e-02  3.96544548e-04  4.90690799e-02  1.03877519e-05
 -1.01165767e-02 -4.85213128e-02 -1.35698892e-01 -6.80015274e-06
 -1.34791754e-01  4.90771497e-03  4.32509360e-01  1.73285694e-03
 -6.85570512e-05 -1.62822542e-06 -1.46892427e-04 -1.48998056e-09
 -3.29758014e-02  2.52515018e-02  3.86275651e-01  3.25173473e-03
 -1.58885082e-01 -8.26883558e-02 -2.48948170e-01 -7.83486908e-02
 -4.05900753e-01 -6.95800535e-02 -8.30976605e-01 -1.85789648e-02
  6.07524336e-04  2.32607732e-05  1.64290044e-02  2.70579518e-09
 -3.77343303e-02 -6.87547109e-01 -9.91701925e-01 -2.75449492e-02
  4.38289560e-03  7.31058248e-02  8.58758077e-02  1.60234966e-03
  1.90728561e-02  7.26498832e-01  1.05885725e+00  1.38922188e-02
 -1.40519052e-02 -2.98490500e-02 -1.79205059e-01 -1.18655596e-02
  7.27200187e-01 -1.90921124e+00  4.66465299e-01 -2.09507645e+00
  1.08445669e-01 -8.43431939e-01  5.33637729e-01 -1.57229541e+00
 -9.35971656e+00]
supnorm grad right now is: 9.359716560654954
Weights right now are: 
[ 6.23803232e+00 -3.60379916e+00  2.85677883e+00 -6.89013495e+00
 -5.98346361e+00  3.49510747e+00 -2.45784156e+00  6.17410657e+00
  7.26640258e+01  6.66091043e+01  1.97452020e+01  4.99512174e+01
  9.07088373e+01 -1.42948310e+01  1.03781588e+01  9.18420567e+00
  3.50735134e+00  2.14017154e+01  2.86143978e+00 -1.00787748e+01
  1.51887326e+02  7.64681467e+01  1.57488779e+02  5.84536949e+01
  1.01720995e+01 -2.51641677e+00  5.85520567e-01  1.21338258e+01
  4.02156958e+00 -1.46692566e+00  1.10779326e+01 -3.36941574e+01
 -1.26787550e+01  5.10945907e+00  9.50731957e+00 -1.82307400e+01
  1.81244438e+01  1.23569713e+02  2.90044955e+00  3.13043524e+01
  1.33626816e+01 -5.88456666e-01  2.37373853e+00  2.09982373e+01
 -9.67729871e+00 -1.21458254e+01  1.91117804e+01  8.18760110e-02
 -7.53520602e+01 -6.44146332e-01  1.01917953e+00 -7.56982737e+01
  2.84116873e+01  6.04161128e+01  4.57345711e+00  2.69075038e+01
  3.70797366e+00 -4.49185424e+00 -4.21860948e+00 -4.67831932e+00
 -2.62470035e+00 -2.69143242e+00  4.48636464e+00 -4.58273113e+00
  3.11082408e+01]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.376678141449
gradient value of function right now is: [ 1.99189626e-02  1.45253403e-02  2.00959756e-01  4.47665252e-04
 -1.99189626e-02 -1.45253403e-02 -2.00959756e-01 -4.47665252e-04
 -3.41122471e-03 -5.18602526e-05 -4.41917168e-03  5.42479417e-05
  5.94788103e-04 -2.09141952e-02 -2.16121888e-02 -2.62040979e-05
 -4.97252200e-01  3.35872538e-03  3.42670187e-01 -6.19039647e-03
  3.48523073e-04  1.08881040e-07  4.43346016e-05  6.32823177e-08
  4.12099980e-02  1.11938596e-01  1.37019718e+00  3.60503124e-03
 -4.64852231e-02 -1.53987669e-02 -7.39413060e-02 -1.93291723e-02
 -2.26523684e-01  1.50786858e-02 -4.09239523e-01  1.12757745e-02
 -1.84154790e-03 -5.59492832e-04 -6.79630042e-02 -5.33053345e-09
 -3.14824240e-02 -9.48760610e-01 -1.26104142e+00 -2.65344499e-02
  4.43418836e-02  1.59291297e-01  1.49282105e-01  3.85823460e-02
  5.87325659e-03  9.47315488e-01  1.25362621e+00  4.06040218e-03
 -4.73421940e-04  1.11056168e-03 -1.32094790e-02 -5.83225181e-04
  5.73960820e-01 -5.59843618e-01  2.09362842e-01 -2.35392757e-01
  2.81887327e-02 -4.18915746e-01  4.49640722e-01 -5.36892267e-01
 -9.77226573e-01]
supnorm grad right now is: 1.3701971756961189
Weights right now are: 
[ 6.66668010e+00 -3.37663075e+00  2.94240666e+00 -1.08670201e+01
 -6.41211139e+00  3.26793906e+00 -2.54346939e+00  1.01509917e+01
  7.28681002e+01  7.01458644e+01  2.02590320e+01  4.30688529e+01
  9.52600300e+01 -1.38874436e+01  1.11759618e+01  1.07134304e+01
  3.60234648e+00  2.36765421e+01  3.39306294e+00 -1.05574749e+01
  1.40847675e+02  7.68241232e+01  1.69535711e+02  5.83582877e+01
  1.03623640e+01 -2.21734569e+00  6.18141404e-01  1.14710746e+01
  3.95470201e+00 -4.30021057e-01  1.05873952e+01 -3.41811625e+01
 -1.30212920e+01  3.75425737e+00  9.39049160e+00 -1.77975297e+01
  1.77391791e+01  1.29065886e+02  2.78950930e+00  3.23525957e+01
  1.39035954e+01 -5.25732496e-01  2.19776111e+00  2.23870987e+01
 -9.51066398e+00 -1.21113103e+01  1.97372046e+01  1.25187628e-01
 -7.82208030e+01 -8.30012022e-01  1.21949931e+00 -7.84372050e+01
  2.87902852e+01  6.10731284e+01  3.59560822e+00  2.70951200e+01
  3.69467986e+00 -4.61862929e+00 -5.05083560e+00 -4.69629510e+00
 -3.21934045e+00 -2.56894669e+00  4.34979273e+00 -4.46321296e+00
  3.11678496e+01]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.7303656539648
gradient value of function right now is: [ 3.57514907e-02  1.60272350e-02  2.00782176e+00  1.11775550e-03
 -3.57514907e-02 -1.60272350e-02 -2.00782176e+00 -1.11775550e-03
 -1.63274769e-02 -2.04679687e-05 -4.85944406e-03 -3.26700458e-05
  5.07673043e-03 -2.29839075e-02 -1.55236968e-02  8.43864506e-06
 -1.12669602e+00 -1.46766439e-03 -3.29177867e-01 -2.05762427e-02
  9.13984474e-04 -1.18458433e-08  1.02775678e-04  3.45931330e-07
  3.86468754e-01  1.82512343e-01  3.13547698e+00  3.67295390e-03
 -7.32298296e-03 -1.66604931e-03  9.30259974e-03 -7.73890892e-03
  1.61869175e-01  3.95463223e-02  3.06985620e-01  2.22800667e-02
 -1.46968077e-02 -1.72393779e-03 -2.21856278e-01 -1.26257811e-08
 -6.84935304e-02 -5.93557584e-01 -6.79814519e-01 -5.02744366e-02
  5.79982662e-02  3.08405125e-01  3.00723517e-01  4.46909836e-02
 -6.74433514e-03 -1.47060918e-01 -2.40525769e-01 -4.47590698e-03
  4.04961683e-03  1.60890621e-03  8.69408927e-03  3.38375324e-03
  2.79316983e-01  1.28157530e-01  2.59262066e-01 -3.59009539e-02
 -3.64506570e-01 -7.98231512e-02  2.12041486e-01 -9.59328761e-02
 -7.16528663e+00]
supnorm grad right now is: 7.165286633112613
Weights right now are: 
[  6.01256045  -3.49082827   3.01659577 -11.15799112  -5.75799174
   3.38213657  -2.6176585   10.44196274  75.35781105  71.83325691
  20.27156917  42.11770345  96.2599421  -13.32608282  11.76556388
   9.26344361   3.32203801  24.27941966   2.34353482 -11.45161382
 136.94804169  77.19758596 180.32785818  58.24182967   9.87412769
  -2.5846328    0.68725208  14.12371567   5.13446663   0.90089081
  11.80313032 -33.07351695 -12.28173041   3.85037988   9.43783977
 -18.76422797  17.66888751 129.40303646   2.09270577  33.73573851
  12.96895455  -0.40313303   2.47861349  21.517353   -10.64636825
 -11.9546715   20.26147863  -1.18196697 -80.6385464   -0.9493987
   1.16332707 -81.15888271  29.72714585  63.0019531    4.44779821
  27.75480446   3.40750465  -4.36693514  -3.28620991  -4.80431914
  -1.91994707  -2.71131041   4.18009923  -4.53428462  31.02283088]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -1206.5150299427532
gradient value of function right now is: [ 6.37249750e-02 -4.63072357e-03  2.13566870e+00  3.02930583e-03
 -6.37249750e-02  4.63072357e-03 -2.13566870e+00 -3.02930583e-03
 -2.80784827e-02  1.45623104e-04  3.59448564e-03 -4.02741192e-06
  7.32762247e-03 -5.72774994e-02 -1.06559983e-01  7.14484520e-07
 -1.27456825e+00  5.33127807e-03  1.76617740e-01 -8.90264955e-03
  1.63251729e-03  1.35491127e-06  3.77090303e-04  5.67752672e-08
  6.15454334e-01  3.44441711e-01  4.47635161e+00  1.11494825e-02
 -1.79992205e-01 -1.11076264e-01 -2.72136280e-01 -1.02030969e-01
 -4.99150149e-02 -7.15290422e-02 -9.17734555e-02 -5.85041812e-02
 -5.01654019e-03 -6.57145298e-04 -9.14591358e-02 -1.67431257e-11
 -9.97719102e-02 -1.22302823e+00 -1.35727472e+00 -8.75685813e-02
  1.02801761e-01  3.51562259e-01  3.66799563e-01  9.35529801e-02
  3.46921074e-03 -2.21553025e-01 -1.62554996e-01  4.37126410e-03
 -2.15565415e-02 -4.37559200e-02 -2.35016485e-01 -2.10855087e-02
  5.17563486e-01 -1.81376787e+00  6.44830584e-01 -3.11363553e+00
  7.29527881e-02 -7.50585955e-01  5.13065843e-01 -2.10185309e+00
 -2.14356004e+01]
supnorm grad right now is: 21.43560044310829
Weights right now are: 
[ 6.42838486e+00 -3.38127640e+00  3.05862997e+00 -9.73879793e+00
 -6.17381615e+00  3.27258471e+00 -2.65969270e+00  9.02276955e+00
  7.65193162e+01  7.29239660e+01  1.81559604e+01  4.14368870e+01
  9.94606441e+01 -1.45099144e+01  1.12667736e+01  7.87157708e+00
  3.85239936e+00  2.74426259e+01  3.03416779e+00 -1.07092296e+01
  1.36096953e+02  7.74661906e+01  1.88117795e+02  5.81566413e+01
  9.54354515e+00 -2.56873712e+00  8.28146352e-01  1.33439922e+01
  4.56188199e+00  4.20975964e-01  1.12541185e+01 -3.39804444e+01
 -1.22373541e+01  4.17402788e+00  9.48647617e+00 -1.92635902e+01
  1.54514121e+01  1.34341603e+02  2.96317678e+00  3.44004352e+01
  1.31727641e+01 -4.53329890e-01  2.50092435e+00  2.22122582e+01
 -9.57857389e+00 -1.23201675e+01  2.04864818e+01 -7.18803782e-03
 -8.28929716e+01 -1.16087174e+00  1.17409214e+00 -8.39532604e+01
  2.98149198e+01  6.49606633e+01  4.15810291e+00  2.79951857e+01
  3.61782859e+00 -4.51975154e+00 -4.03228125e+00 -4.81818248e+00
 -2.13854293e+00 -2.88744579e+00  4.11869718e+00 -4.48683884e+00
  3.10342618e+01]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.1199509432006
gradient value of function right now is: [-1.89173454e-02  2.16589603e-02 -1.35397936e+00 -3.05335169e-03
  1.89173454e-02 -2.16589603e-02  1.35397936e+00  3.05335169e-03
  1.04392524e-02 -3.79587488e-05 -3.21789685e-02 -2.95643557e-05
 -8.25020900e-04  1.53502699e-02  6.10922045e-02  2.40449313e-05
  1.61126591e+00 -4.26493871e-04 -2.83206388e-01  2.94225673e-02
 -2.57978362e-03 -1.40241916e-06 -8.31415097e-04 -2.69797494e-06
 -2.96214114e-01 -2.71684838e-01 -4.45864944e+00 -5.93562727e-03
  3.82642894e-02  2.13170734e-02  5.56802489e-02  2.29844562e-02
  3.67698393e-01  6.24566353e-02  7.42690381e-01  1.97433142e-02
  1.38106318e-02  2.42692656e-03  3.38200391e-01 -1.16596337e-07
  1.11418514e-01  1.12189108e+00  1.61473703e+00  8.19345696e-02
 -1.20934272e-01 -5.01517031e-01 -5.18945805e-01 -9.68205026e-02
 -1.11994866e-02 -2.73404169e-01 -5.36800927e-01 -7.75873935e-03
  7.34421914e-03  1.71941194e-02  8.73437183e-02  6.01588428e-03
 -1.07559546e+00  1.97005849e+00 -7.27422647e-01  1.61971381e+00
  4.39587856e-01  3.39567870e-01 -7.09481204e-01  1.80494155e+00
  9.10499864e+00]
supnorm grad right now is: 9.104998638024695
Weights right now are: 
[  6.12278414  -3.86358434   2.91194504 -15.60338857  -5.86821543
   3.75489265  -2.51300777  14.88736019  78.3675248   79.72537264
  18.50954637  35.13340622 102.0833379  -13.44262168  11.64168387
   9.04171939   3.80575252  26.11636093   3.58300515 -11.51943897
 126.17674598  77.76039624 194.47644498  57.61855685  10.25305902
  -2.4310404    0.51010564  15.61875365   5.0391746    0.92660552
  11.47157877 -33.80737815 -12.8327015    2.7168985    9.46371881
 -18.80688073  13.21080304 140.69364689   2.35309799  36.57773963
  13.57965197  -0.26584951   2.26514945  23.08625549 -10.28596048
 -12.36703678  20.49410876  -0.8043616  -85.43378611  -1.24291613
   0.80405325 -86.59637168  29.51340027  66.55951048   4.85856095
  27.33100443   3.06826409  -4.5173583   -4.36506405  -4.65450056
  -2.72775567  -2.60167146   3.94061405  -4.63865308  31.07403457]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.7212936376036
gradient value of function right now is: [ 8.88931727e-03 -4.77245160e-02  1.64966202e+00 -3.70672121e-04
 -8.88931727e-03  4.77245160e-02 -1.64966202e+00  3.70672121e-04
 -1.40840701e-02  2.32406110e-04  1.80603044e-02 -1.67233224e-04
  4.43671711e-03 -3.99898627e-02 -1.02831505e-01  5.03568194e-05
 -1.15461756e+00  3.00024379e-03  1.16118524e-01 -2.90012840e-02
  6.02415340e-04 -1.22768273e-06 -1.25707338e-04  4.42269902e-06
  3.13871690e-01  1.72671504e-01  3.08985237e+00  8.08937810e-03
 -1.02213258e-01 -4.80545647e-02 -1.64719529e-01 -5.91462951e-02
 -7.13685026e-03 -7.17713814e-02 -1.14327278e-02 -7.16499414e-02
 -2.11497163e-02 -1.57313231e-03 -2.91512154e-01 -3.63051224e-08
 -5.19632266e-02 -3.60328937e-01 -4.63163917e-01 -4.60330718e-02
  8.28339533e-02  2.83051396e-01  2.93207523e-01  7.53023259e-02
  2.16866425e-03 -3.64489072e-01 -4.28580861e-01  3.10887397e-03
 -1.89813598e-02 -2.82661880e-02 -2.30329653e-01 -1.77898131e-02
  1.50235320e-01 -1.31413602e+00  3.16223065e-01 -1.96049546e+00
 -2.47680173e-01 -7.23162734e-01  1.25245067e-01 -1.51044371e+00
 -4.46694406e+00]
supnorm grad right now is: 4.466944058548805
Weights right now are: 
[ 6.38130297e+00 -3.92987873e+00  2.99697727e+00 -1.72902604e+01
 -6.12673426e+00  3.82118704e+00 -2.59804000e+00  1.65742321e+01
  7.86241517e+01  7.73134561e+01  1.77159627e+01  3.37930103e+01
  1.05622626e+02 -1.41421365e+01  1.12998958e+01  7.98965267e+00
  3.30558689e+00  2.16720323e+01  3.48503790e+00 -1.10955958e+01
  1.21591550e+02  7.84952462e+01  2.00857066e+02  5.69332422e+01
  1.06380445e+01 -2.06755076e+00  7.79394639e-01  1.55090363e+01
  5.10135005e+00 -1.62269114e-01  1.11031006e+01 -3.48429673e+01
 -1.30999615e+01  2.69382373e+00  9.32770768e+00 -1.73919283e+01
  1.65741841e+01  1.44407162e+02  2.76187596e+00  3.79334681e+01
  1.48482422e+01 -3.29115569e-01  2.09783834e+00  2.50240963e+01
 -9.29889662e+00 -1.25066681e+01  2.09860686e+01 -2.22145394e-01
 -8.76420656e+01 -8.67533318e-01  9.51986527e-01 -8.87121556e+01
  2.96213486e+01  6.67543688e+01  4.81201053e+00  2.74588928e+01
  3.41346588e+00 -4.66845139e+00 -5.05057771e+00 -5.04826222e+00
 -3.05351601e+00 -2.67008909e+00  3.94473350e+00 -4.69484648e+00
  3.10991391e+01]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.011576371384
gradient value of function right now is: [ 9.36944350e-03  3.54076589e-02 -1.97901607e+00 -8.01925466e-04
 -9.36944350e-03 -3.54076589e-02  1.97901607e+00  8.01925466e-04
  9.25651231e-03 -4.35667343e-05 -2.20229220e-02  7.29074045e-05
  1.53545549e-05 -4.40413433e-04  1.57522231e-02 -9.31531244e-06
  1.38480475e+00  4.79202361e-04  1.10243825e-01  2.35468909e-02
 -1.00083656e-03 -1.24521509e-07 -1.03532070e-04 -2.30003152e-06
 -3.83259227e-01 -1.76836732e-01 -4.18184146e+00  4.23605121e-03
  4.71469127e-03  5.74807433e-03  1.17124968e-02  4.81167586e-03
  3.49344246e-02  2.59064918e-02  1.32003124e-01  1.40907110e-02
  1.27911962e-02  1.78537721e-03  2.60531975e-01  1.13011157e-07
  9.21103214e-02  9.45841378e-01  1.22566274e+00  7.21679587e-02
 -9.74046202e-02 -3.96826340e-01 -4.03644642e-01 -7.28517252e-02
 -1.23168955e-03  3.11071097e-02  7.01969647e-02 -2.10867741e-03
  4.50632039e-03  3.51663540e-03  2.06910277e-02  5.08223365e-03
 -6.65360178e-01  8.53997351e-01 -1.41338819e-01  2.43610844e-01
  3.15360552e-01  2.34838121e-01 -4.54491060e-01  1.25199566e+00
  5.25524781e+00]
supnorm grad right now is: 5.255247809630672
Weights right now are: 
[  6.99136139  -2.90864877   2.7838191  -14.17289676  -6.73679268
   2.79995708  -2.38488183  13.45686838  79.6746101   75.56845594
  18.03023134  38.38122772 107.68189056 -13.58549313  11.68951026
   4.07209028   3.81265835  22.49644924   3.06408093 -11.38029375
 124.62052617  79.0297772  208.28721811  57.02904391  10.10454366
  -2.7923559    0.62209989  13.87013724   5.60307733   1.43398803
  11.75524029 -34.80482883 -12.63784456   3.06386651   9.28328657
 -17.26969557  15.77318868 149.63069986   2.73991508  38.91251519
  14.11612707  -0.56483961   2.45278186  24.75756429  -9.85316403
 -13.07032757  20.87569187  -0.61071402 -89.77807677  -1.32963263
   0.91371385 -91.16600008  30.89847433  69.36218129   4.48443058
  28.65523667   3.20544179  -4.72335081  -3.89324555  -4.85005231
  -2.26474304  -2.51949415   4.29918221  -4.55828842  31.09454653]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.3464099945295
gradient value of function right now is: [-1.46119371e-01 -1.35988329e-01 -1.10958060e+00  3.90459419e-04
  1.46119371e-01  1.35988329e-01  1.10958060e+00 -3.90459419e-04
  2.82360948e-02  4.61328033e-05  1.36092990e-01  2.22795867e-04
 -1.40799597e-02  3.37335063e-02 -5.78017143e-02 -5.06543416e-05
 -5.00766826e-01 -6.27506771e-04  8.53852235e-01 -1.26031917e-02
  3.00043356e-04 -7.92525491e-09  3.50156297e-05 -6.78571051e-06
 -2.86617507e-01  1.10454805e-01  6.34045568e-01 -4.33369408e-03
  6.47816226e-02  3.34320396e-02  7.75123453e-02  4.35610649e-02
 -1.04512360e+00 -1.84298262e-01 -2.17352976e+00 -8.46778335e-02
  1.70009949e-03 -9.32849901e-04 -1.53108849e-01  9.00103361e-08
 -5.71483770e-02 -9.67413888e-02 -9.66744446e-01 -4.82125321e-02
  7.70630018e-02  2.27711469e-01  2.54789884e-01  6.94019797e-02
  3.05957518e-02  4.18286216e-01  1.07186525e+00  2.41614047e-02
 -7.92115769e-03 -2.48307104e-02 -8.36277958e-02 -6.71614358e-03
  8.30035223e-01 -3.19229766e+00  4.54905550e-01 -1.82605047e+00
 -1.45972739e-01 -1.03075395e+00  6.01087693e-01 -2.96652395e+00
 -7.36517062e-01]
supnorm grad right now is: 3.192297664603776
Weights right now are: 
[  6.28115216  -3.84158538   2.69860258 -16.26107561  -6.02658345
   3.73289369  -2.29966531  15.54504723  80.05223942  80.25918855
  16.59255074  40.47782903 110.8844606  -13.70366179  11.60655643
   1.77257196   3.61182108  19.37191446   3.38549376 -11.74601992
 122.29058942  79.53730271 212.49932087  57.36036625   9.97094907
  -2.07321545   0.85478436  12.46419864   6.37620465   1.35765021
  11.98463641 -35.27627646 -13.06137678   2.51969147   9.04390991
 -16.74598345  15.91555571 155.42844665   2.47893388  39.78427227
  13.02930218  -0.69092312   2.61052548  23.83223667  -9.28878906
 -12.86863328  21.3966181   -0.41430375 -92.08118744  -1.27557391
   0.81146665 -93.49997781  30.30441843  71.26996812   4.81916709
  27.99589824   3.58220419  -4.9537165   -4.61105554  -4.44281543
  -2.76715714  -2.48463056   4.13811167  -5.09739689  31.17589771]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1205.3538621843095
gradient value of function right now is: [-4.06707821e-02 -8.85017826e-02 -1.81653967e+00  6.05271723e-06
  4.06707821e-02  8.85017826e-02  1.81653967e+00 -6.05271723e-06
  6.25333785e-03  1.60733686e-04  4.56706511e-02  6.24533425e-06
 -3.01965777e-03 -1.05514642e-01 -1.87576606e-01 -1.06323310e-06
  1.48133279e+00  6.81185676e-03  8.15136432e-01  3.89375810e-03
 -9.99168726e-05  4.53152566e-08  8.18261618e-06 -1.31994938e-07
 -2.07321241e-01 -3.60150905e-01 -3.74024498e+00  4.43977057e-04
 -2.31292628e-01 -1.16733359e-01 -3.38065160e-01 -1.30141768e-01
 -5.49822889e-01 -1.87659564e-01 -1.10449736e+00 -1.23699277e-01
  2.61490222e-03  6.03266373e-04  4.11245987e-02  5.78423011e-08
  2.42732458e-02  5.27641958e-01  1.94774045e-01  9.66072123e-03
 -1.25392322e-01 -4.40709725e-01 -3.88971434e-01 -9.67362541e-02
  1.87245189e-02  2.23601423e-01  6.61131697e-01  1.61497298e-02
 -2.44893335e-02 -5.45716230e-02 -4.07110981e-01 -2.24716533e-02
 -2.85112206e-01 -2.60969078e+00  5.63601744e-01 -4.06868869e+00
  8.15457079e-01 -1.61107199e+00 -1.43361537e-02 -2.34205686e+00
  5.16231356e+00]
supnorm grad right now is: 5.162313558752816
Weights right now are: 
[  6.49936038  -3.50237233   2.9478383  -17.91622603  -6.24479167
   3.39368064  -2.54890103  17.20019765  81.85815967  81.79809198
  17.36111303  41.78880122 111.66173276 -14.16343541  11.71326931
  -1.42018606   3.94562256  25.7355265    3.10187022 -11.22129466
 120.68769066  79.73981734 214.22836367  57.07700104   9.95273688
  -2.35635273   0.61389748  12.22304811   5.86836904   0.35478318
  11.40727216 -36.10347703 -12.88725882   3.39285157   9.15638582
 -16.78243714  17.95708831 162.02846035   2.94080425  40.05115333
  14.31566338  -0.61420495   2.67638942  24.94670531  -9.51502777
 -14.31753927  20.37766423  -0.81796484 -94.29184149  -0.72234405
   1.18401388 -95.98595484  31.84110227  72.38105808   5.08073378
  29.79122169   3.26235563  -4.91564775  -3.91805845  -5.06442043
  -2.61692881  -2.81126557   4.0921886   -4.91559717  31.19007985]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1206.8217972612385
gradient value of function right now is: [ 6.76463775e-02  9.87538971e-02  1.54754801e+00  7.38321327e-04
 -6.76463775e-02 -9.87538971e-02 -1.54754801e+00 -7.38321327e-04
 -8.42995155e-03 -7.54198391e-05 -5.73014960e-02  6.19607026e-05
  3.75868697e-03  2.28756073e-02  7.53728430e-02 -7.33020332e-06
 -1.04775292e+00 -3.09906226e-03 -7.06644710e-01 -2.53694370e-02
  7.00276231e-04  1.14688810e-07  1.80700055e-04 -6.66490366e-07
  1.42841777e-01  2.08883836e-01  2.68962654e+00  1.51219405e-02
  6.51061975e-02  2.84678487e-02  1.05917336e-01  3.82888617e-02
  4.83267333e-01  1.27728856e-01  1.00582948e+00  1.29530952e-01
 -9.47807876e-03 -2.08510717e-03 -3.16961440e-01 -1.75104116e-06
 -9.40405441e-03 -5.86995741e-02  2.69864665e-01 -7.25182888e-03
  6.29368334e-02  3.21580179e-01  2.89155661e-01  5.31440111e-02
 -1.40476019e-02  9.19401465e-02 -1.96786803e-01 -1.36998098e-02
  1.66248408e-02  2.74283275e-02  2.62111069e-01  1.63095626e-02
  2.72300928e-02  2.01526782e+00 -9.27391832e-02  1.83853197e+00
 -8.60342824e-01  1.47728286e+00 -1.14992769e-01  2.03481917e+00
 -4.44275222e+00]
supnorm grad right now is: 4.442752219004514
Weights right now are: 
[  6.55432056  -2.78002752   3.01745537 -16.74004392  -6.29975185
   2.67133583  -2.6185181   16.02401554  82.5682201   82.2596911
  18.29703116  43.13841491 113.67516568 -14.13057959  12.23043041
  -2.9804549    3.41825301  26.46434226   2.50258229 -12.21056221
 122.16541568  79.93928155 218.41297998  56.82785148  10.1002752
  -1.87879971   0.76995088  11.0857675    6.78600344   1.17818921
  12.2617549  -36.01333098 -12.84692417   3.94689051   9.18268527
 -16.16313337  17.9045282  164.57006594   2.0247947   40.61302936
  14.39929556  -0.76191578   2.73783639  25.58945878  -9.62846395
 -13.7577788   21.36211599  -0.94430341 -96.74934993  -0.59715045
   1.09909497 -98.588293    34.0452342   73.49559524   5.37455934
  31.96722459   3.61396215  -4.56265447  -4.3884689   -5.09205295
  -2.66659309  -2.50148908   4.23168935  -4.51896584  31.03992656]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.034724761625
gradient value of function right now is: [ 2.87688239e-02  7.09893966e-02 -8.06882400e-01 -1.33467106e-03
 -2.87688239e-02 -7.09893966e-02  8.06882400e-01  1.33467106e-03
  1.79726860e-03 -1.46315313e-05 -5.03839189e-02  1.85443105e-06
  3.96380432e-03  2.21791183e-02  1.04717155e-01  5.52393718e-06
  1.11637880e+00 -1.21034013e-03 -7.51172773e-01  3.17666743e-02
 -1.30211388e-03 -8.88856947e-08 -3.24784829e-04 -1.02792029e-06
 -3.01130798e-01 -9.35931487e-02 -3.30839652e+00 -1.07102186e-02
  6.38965529e-02  3.48032271e-02  9.25609057e-02  4.27586131e-02
  5.88844185e-01  1.10016646e-01  1.21511267e+00  7.28061652e-02
  2.41527948e-02  1.99638126e-03  3.82223616e-01 -3.30248901e-07
  8.48807437e-02  1.29652962e+00  2.03091587e+00  6.37948656e-02
 -3.61947317e-02 -3.54776924e-01 -3.81706083e-01 -3.08480072e-02
 -1.44814828e-02 -2.42016139e-01 -7.23889075e-01 -1.02769776e-02
  1.57943601e-02  2.80405375e-02  2.04736373e-01  1.19104627e-02
 -8.74868617e-01  2.72692546e+00 -7.26719058e-01  2.40075465e+00
 -2.94864089e-01  1.86505456e+00 -7.66331060e-01  2.41628163e+00
  9.99315209e+00]
supnorm grad right now is: 9.993152086432493
Weights right now are: 
[   6.52409295   -4.40083069    2.98959539  -15.59939668   -6.26952424
    4.29213899   -2.59065812   14.8833683    82.51111735   87.20403021
   19.78689175   42.4251772   116.76499329  -14.16650982   11.87677337
   -4.38643977    3.56766446   33.59370502    3.0831321   -12.30874949
  122.744501     80.124122    223.78416679   57.10257429   10.58897349
   -2.78670224    0.44012441   15.56219242    7.33418515    1.57671668
   12.72796022  -36.02132754  -12.65238368    2.65352098    9.09307037
  -18.06439816   18.25750343  166.96515494    2.31767348   40.9283463
   14.97314803   -0.58937826    2.75127517   26.78524223   -9.14145838
  -13.98667338   21.48156908   -0.86226234  -98.99351464   -1.24811829
    0.53926805 -100.96007625   32.69975926   74.99557921    5.53230973
   30.64362079    3.65109261   -4.42696623   -4.39036953   -4.89788175
   -2.71886958   -2.5883886     4.12174048   -4.66669744   31.04924642]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.161607111991
gradient value of function right now is: [-2.89097275e-02 -9.05235182e-02  5.54499592e-01  5.70441269e-04
  2.89097275e-02  9.05235182e-02 -5.54499592e-01 -5.70441269e-04
 -3.29363204e-03  1.52200790e-04  4.92873889e-02 -8.04778736e-07
 -1.63083097e-03 -5.01423011e-02 -1.40000841e-01  1.02770057e-07
 -1.12762665e-01  3.78187677e-03  1.11395189e-01 -8.54015541e-05
  4.65422382e-04  1.37115299e-07  1.23548817e-04  1.72574484e-08
  2.71420279e-01 -1.14948855e-02  9.16807843e-01  9.79324456e-03
 -1.79717493e-01 -1.01281268e-01 -2.72351002e-01 -1.03552723e-01
 -1.64929558e-01 -1.13018285e-01 -4.23674167e-01 -8.07755835e-02
 -6.77004744e-04 -1.11051958e-04 -6.73888285e-04 -1.73669353e-10
 -4.01289926e-02 -7.01582833e-01 -7.69859496e-01 -3.42834610e-02
 -3.28714899e-02  1.58943866e-02  3.54634039e-02 -3.17315305e-02
  9.04545559e-03 -1.82719508e-01 -8.03204281e-02  9.59906369e-03
 -2.00405876e-02 -3.94247932e-02 -2.72393048e-01 -2.04172578e-02
  2.54552590e-01 -1.93860303e+00  3.43530770e-01 -3.03802381e+00
  3.22130371e-01 -1.18066517e+00  3.63410490e-01 -2.22538237e+00
 -8.35382216e+00]
supnorm grad right now is: 8.353822157025242
Weights right now are: 
[   6.497413     -3.60072257    2.93357304  -13.67702308   -6.24284429
    3.49203088   -2.53463577   12.96099469   83.13785087   88.26840284
   18.45586435   38.16693474  118.03264532  -15.12809254   11.01621239
   -3.99257002    3.67985842   33.6478432     2.70631925  -11.94534571
  124.84233652   80.28577429  230.50373218   57.30285531    9.8859603
   -3.34987521    0.55099432   15.82493135    6.43594365    0.3695724
   11.88205407  -37.63440104  -12.52025238    3.6324619     9.10186234
  -16.30406944   16.80183583  168.33122553    2.80514115   41.23919862
   14.78233507   -0.67456755    2.48277488   27.50375992  -10.02910338
  -13.87791448   21.89760287   -1.19911614 -100.74902145   -1.14799981
    0.83438897 -102.93274239   33.05567373   76.26321959    5.3101823
   31.12029963    3.64211623   -4.92644015   -4.61047867   -5.09118364
   -2.4179441    -2.86696428    4.36018015   -4.84404234   31.09606479]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.8403140214803
gradient value of function right now is: [-1.12882785e-01 -8.62889155e-02 -1.86088244e+00 -1.19313157e-03
  1.12882785e-01  8.62889155e-02  1.86088244e+00  1.19313157e-03
  2.42124296e-02  1.69105310e-05  4.80785459e-02  4.81461759e-06
 -8.82911712e-03  1.35033821e-02 -8.83992114e-03 -1.15598131e-06
  1.34232947e+00 -1.06886901e-05  2.16830841e-01  6.57425440e-03
 -1.10125702e-03 -7.39492465e-08 -2.78899322e-04 -1.74883524e-07
 -4.08408642e-01 -3.29623538e-01 -3.58620343e+00 -1.75834971e-02
  3.78465782e-02  2.12365369e-02  4.75047549e-02  2.55357212e-02
 -3.54670968e-01 -9.27061705e-02 -7.95101665e-01 -4.78272440e-02
  1.99833613e-03  7.36744048e-04  8.09013870e-02  2.03847321e-09
  4.30275079e-02  1.79727570e-01  1.81278115e-01  3.51835256e-02
 -1.22684149e-01 -4.21191946e-01 -4.00635986e-01 -1.05571962e-01
  9.78250918e-03  9.11815666e-02  2.61778059e-01  8.00302789e-03
 -2.58842609e-03 -3.13619172e-03 -8.49032908e-03 -2.29596694e-03
 -2.64635627e-01 -6.89956127e-01 -2.62686011e-01 -4.38560544e-02
  7.26612504e-01 -2.37787358e-01 -1.23994238e-01 -4.12459396e-01
  7.33404363e+00]
supnorm grad right now is: 7.334043627384165
Weights right now are: 
[   5.63375312   -3.14224172    2.85735349  -13.44537637   -5.37918441
    3.03355003   -2.45841622   12.72934799   84.76903267   87.80229064
   19.90012318   37.9693451   117.16978246  -14.40377697   12.02767267
   -5.14676113    3.58427541   35.43702862    2.96435314  -12.54377097
  125.86490232   80.41613129  233.99192904   57.1128429    10.12952815
   -2.92310853    0.52683317   12.21369533    7.38877727    1.01882736
   12.46246108  -37.43032519  -12.50176587    3.46885308    9.11372891
  -16.60260127   18.19185062  171.11482816    2.14174788   41.96972187
   14.65986179   -0.73697526    2.42031442   27.71057407   -9.75906178
  -14.39309013   22.03616717   -1.32027884 -102.74325041   -0.90163494
    0.77460666 -104.92525456   34.19183655   77.14126675    5.32261819
   32.70223228    3.39870807   -4.86165213   -4.54977144   -4.9351479
   -2.52582461   -2.71960097    4.01997251   -4.95546093   31.14718035]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.6220542507745
gradient value of function right now is: [-1.21672640e-01 -7.82442819e-02 -9.85016962e-01 -7.45041710e-04
  1.21672640e-01  7.82442819e-02  9.85016962e-01  7.45041710e-04
  2.17696856e-02  3.01395695e-06  4.64574296e-02  2.41111385e-05
 -1.00399692e-02  5.49485705e-02  4.88798464e-02 -9.50840325e-06
  2.10157594e-01 -5.89797381e-04 -1.93912404e-01  8.31015148e-03
 -5.38055132e-04 -2.88612117e-08 -2.75467111e-04 -5.88782522e-07
 -2.46720226e-01 -1.11049939e-01 -9.53081124e-01 -4.39350731e-03
  9.53552447e-02  4.71811040e-02  1.14075673e-01  6.46897300e-02
 -1.15078077e-01 -9.53220440e-03 -4.00426377e-01  5.84680490e-03
  5.89106428e-03  6.08205156e-04  1.01439240e-01 -1.37808012e-08
 -5.59251157e-03  9.36294535e-01  7.25786982e-01 -8.27756927e-03
 -4.05213519e-02 -2.23099467e-01 -2.01676484e-01 -3.42957622e-02
  7.04256798e-03 -3.78865503e-02  2.53035652e-02  5.54026079e-03
  1.53683748e-03  1.10841312e-02  1.14795957e-01  1.27584727e-03
  1.19950050e-02 -5.94670904e-01 -2.64173662e-01  1.16688025e+00
 -9.39940084e-02  6.75412639e-01  6.10860674e-02 -5.65335351e-01
  7.12887848e+00]
supnorm grad right now is: 7.1288784771832825
Weights right now are: 
[   5.57283315   -3.7548126     2.78998354  -14.58119431   -5.31826444
    3.64612091   -2.39104627   13.86516593   84.65562667   89.15872703
   20.51839484   37.9812781   120.2234878   -14.74344809   12.94327995
   -5.74739703    3.82842309   38.56112358    3.6127051   -12.65384627
  125.25844348   80.54627607  238.66610207   57.69987191   10.51467777
   -2.66680987    0.85591006   11.61846549    7.97598536    1.83187028
   12.97884196  -37.58133317  -12.68649196    1.92461783    8.95198506
  -17.79964749   15.39338412  175.86015002    2.4613636    42.7488679
   13.7312779    -0.65850659    2.56420698   27.51206266   -9.26681715
  -14.99311233   21.87658202   -0.65837054 -105.3639896    -1.24497889
    0.59951291 -107.91996522   33.66694877   78.96800771    5.31714565
   32.34272662    3.73692557   -4.97665015   -5.52788954   -4.49209346
   -2.89550416   -2.35911178    4.4325605    -5.05019266   31.14319257]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.0318888761212
gradient value of function right now is: [-1.04576756e-01 -1.24337812e-01 -9.73432635e-01 -5.65590594e-04
  1.04576756e-01  1.24337812e-01  9.73432635e-01  5.65590594e-04
  1.18621676e-02  9.32914563e-06  7.27221301e-02 -1.81581059e-07
 -8.36986224e-03  5.70236195e-03 -6.04372588e-02 -1.15201623e-06
 -1.87206624e-02 -1.28748974e-04  1.07437297e+00 -1.10095689e-04
 -4.06370533e-04 -1.84497909e-08 -1.28281932e-04  2.73488510e-08
 -1.32747964e-02 -5.36409629e-02  1.84578457e-01 -3.31119476e-03
  2.23390873e-02  1.60525995e-02  3.30789731e-02  1.66612440e-02
 -1.01926710e+00 -1.98503218e-01 -1.86462035e+00 -6.19247519e-02
 -2.01551806e-03  5.85878315e-05 -1.37764874e-03  1.49020617e-09
 -4.11177014e-02 -1.05403505e+00 -1.78813363e+00 -3.36355198e-02
 -2.41443404e-02  7.35572275e-03  5.01210504e-02 -1.97055877e-02
  1.80672849e-02  5.29959124e-01  1.05068113e+00  1.52503639e-02
 -4.02373405e-03 -1.57554675e-02 -6.26002263e-02 -4.03724291e-03
  7.96186227e-01 -2.27064010e+00  6.16429251e-01 -1.73334758e+00
  5.00440669e-01 -7.08782967e-01  7.82682061e-01 -2.30425306e+00
 -5.51598777e+00]
supnorm grad right now is: 5.515987773185572
Weights right now are: 
[   5.69488183   -3.33489029    2.66760429  -13.98063762   -5.44031312
    3.2261986    -2.26866702   13.26460924   84.9824149    93.04076572
   20.33799273   32.2104755   120.85409888  -14.73916933   12.42779632
   -6.46704286    3.51515619   29.20081716    3.282764    -12.70347872
  126.40416839   80.65937488  241.66919078   58.23913365   10.33505077
   -2.53778904    0.70773663   12.89156372    7.6174805     1.11539671
   12.86803318  -38.74853049  -12.6565787     3.1227513     8.96894218
  -15.5472672    15.25808086  178.12982178    2.63639021   43.51281636
   12.94186856   -0.57597439    2.37109716   26.69806857  -10.35351375
  -14.6646535    22.26797237   -1.33803763 -107.82657708   -1.35637292
    1.19461792 -110.9665831    35.73857968   79.68822075    5.34930693
   34.59825887    3.25317643   -4.88519664   -4.37725038   -4.84432442
   -2.47609324   -2.79392642    4.28753129   -4.70539341   31.13184101]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.7453187952306
gradient value of function right now is: [ 1.48712855e-01  1.44506464e-01  1.24255356e+00 -3.51092087e-04
 -1.48712855e-01 -1.44506464e-01 -1.24255356e+00  3.51092087e-04
 -2.43721662e-02 -4.58683931e-05 -1.12464769e-01 -8.45550066e-05
  8.80485460e-03  4.87256884e-03  8.57248922e-02  1.48535128e-05
  2.40511042e-01 -1.02198154e-03 -7.69175394e-01  1.59387089e-02
 -3.01581420e-04 -3.16571062e-09  1.29951076e-04  7.84393951e-07
  3.96930848e-01  1.31218844e-03  1.81781069e-01  1.14743203e-02
  3.60675201e-02  2.05314798e-02  5.60820101e-02  2.07666294e-02
  8.72256376e-01  2.43962253e-01  1.76503590e+00  1.31572087e-01
  9.89358574e-03  3.55098478e-04  2.01068363e-01 -1.47726042e-08
  2.45700621e-02  5.60008335e-02  3.56535323e-01  2.21369625e-02
 -3.17414118e-02 -1.10054391e-01 -1.48424576e-01 -2.74314176e-02
 -1.89306133e-02 -3.38544943e-01 -7.93994091e-01 -1.64757292e-02
  1.51875180e-02  3.17290390e-02  1.86393015e-01  1.48524232e-02
 -7.68015945e-01  2.67034916e+00 -8.44867630e-01  3.00083197e+00
  1.70259599e-01  4.13124724e-01 -6.05702989e-01  2.69120068e+00
  3.69281659e+00]
supnorm grad right now is: 3.692816588561626
Weights right now are: 
[   6.54848421   -3.36868794    2.88047425  -17.98855477   -6.2939155
    3.25999625   -2.48153698   17.27252639   86.03737901   93.11609451
   18.24702662   34.65226909  123.63809092  -14.96094221   13.01715246
   -8.64676216    3.82003062   33.87843424    2.81988685  -12.58351494
  124.61741324   80.70337255  240.64803562   58.16828012   10.23349595
   -2.3093264     0.57993265   14.04257588    7.86223095    1.3344979
   13.0453283   -38.62657621  -12.11341645    3.09831545    9.41812163
  -17.64799145   15.30392608  183.18811556    2.80794324   43.76316946
   13.70356869   -1.00955435    2.85277284   27.78736823  -10.32578872
  -14.16104125   22.64616441   -1.74228044 -109.84747684   -1.83504153
    0.68136313 -113.18596509   35.99480349   80.90304196    5.24297648
   34.93843379    3.55982092   -4.73380839   -3.95973398   -5.06757032
   -2.43352657   -2.91035423    4.26512456   -4.67996506   31.05880323]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.1622032833757
gradient value of function right now is: [ 1.07405463e-01  1.07759071e-01  1.57206047e+00  1.58370011e-03
 -1.07405463e-01 -1.07759071e-01 -1.57206047e+00 -1.58370011e-03
 -2.53351859e-02 -8.98802181e-06 -5.17851973e-02 -1.29174212e-04
  5.51999157e-03  6.28701029e-02  1.15106112e-01  5.40561730e-06
 -6.49340146e-01 -1.18036465e-03  3.32550339e-01 -9.73098779e-03
  1.68705163e-03  4.22812015e-08  3.15562431e-04  6.43406278e-06
  4.74008539e-01  1.00788185e-01  2.91819247e+00  5.39140351e-03
  9.13956284e-02  4.44630534e-02  1.14207225e-01  5.86196223e-02
 -1.22507336e-01  1.27082485e-01  5.29171143e-02  9.53234266e-02
 -9.84561631e-03 -5.53235391e-04 -1.17234252e-01  2.69740665e-08
 -4.77054571e-02 -2.96298630e+00 -3.35446620e+00 -3.63702855e-02
  3.50590636e-02  1.85768396e-01  1.55905090e-01  3.16625103e-02
 -6.56824315e-03  9.80047330e-01  1.27557506e+00 -6.72826387e-03
  1.22869024e-02  3.12538986e-02  2.35178527e-01  1.10387155e-02
  6.18658888e-01  9.93880833e-01 -4.07348780e-01  2.76549805e+00
  9.59976038e-01 -5.55763452e-01  6.88419293e-01  8.85901323e-01
  4.19020863e+00]
supnorm grad right now is: 4.190208625029538
Weights right now are: 
[   6.37653479   -3.2817794     2.91090141  -15.32136771   -6.12196607
    3.17308771   -2.51196414   14.60533933   86.06991188   95.39773941
   18.92622423   35.4111613   123.96717046  -14.80122951   13.26359337
  -11.19358011    3.69230729   31.99107387    3.12255597  -12.59398371
  128.75213356   80.77411092  244.20084533   57.99896018   10.3447465
   -2.47338577    0.70527275   12.75967978    7.89662451    1.10810557
   12.85261208  -39.22151076  -12.58728615    2.75496188    9.04108278
  -16.79231392   16.37863513  185.96810302    2.57893177   44.27482267
   13.81558046   -0.8922988     2.3095659    27.87283588   -8.95320431
  -14.53119567   22.72471818   -0.59644689 -111.72565136   -1.08448871
    1.19211709 -115.36263391   36.58932879   81.46323696    5.40938093
   35.66071963    3.88996244   -4.74977846   -4.7451481    -4.85237146
   -2.77137722   -2.61710962    4.31327122   -4.8182154    31.11376901]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.0548373482661
gradient value of function right now is: [ 3.28949718e-02  1.60630635e-02  1.55698254e+00  1.52271273e-03
 -3.28949718e-02 -1.60630635e-02 -1.55698254e+00 -1.52271273e-03
 -1.14249736e-02 -5.07633695e-06 -9.16832226e-03 -3.43781096e-05
  2.50706391e-03 -1.19411999e-02 -1.95232188e-03  5.37656045e-06
 -6.27135635e-01 -8.76072501e-04 -5.25766881e-01 -4.71352033e-03
  1.69382582e-03  5.16035285e-08  3.19435007e-04  9.91651166e-07
  3.03899328e-01  8.60398608e-02  2.24911044e+00  1.39706569e-03
 -2.91297320e-03 -1.81307916e-03  5.40994696e-03 -5.57399156e-03
  2.71648624e-01  5.54355737e-02  4.72943908e-01  3.55223695e-02
 -7.56638093e-03 -5.26181745e-04 -4.63328934e-02 -5.06429791e-08
 -3.85599788e-02 -3.17096767e-01 -3.10613048e-01 -3.03923223e-02
  2.48337123e-02  1.29289777e-01  1.31357238e-01  2.01823801e-02
 -4.43936047e-03 -1.77415494e-01 -3.76232753e-01 -3.27376976e-03
  3.42206759e-03  6.81994733e-03  3.55403469e-02  2.87632136e-03
  4.88750661e-02  3.25745057e-01 -1.20878704e-02  5.22924641e-01
 -2.77251818e-01  2.48198431e-01  1.20452850e-01  6.72370472e-02
  5.71514029e+00]
supnorm grad right now is: 5.715140289937027
Weights right now are: 
[   6.27194236   -3.41863477    2.99346403  -17.54815073   -6.01737365
    3.30994308   -2.59452676   16.83212235   87.3299488    95.7051571
   19.24605532   37.93022855  123.20151154  -16.36677699   12.56684019
  -17.14923251    3.97685662   40.43323873    2.63581367  -11.93275378
  129.29341421   80.8127416   243.2457489    58.84329229    9.88753436
   -2.63597666    0.82147411   11.79562879    8.0454349     0.78874721
   12.6380318   -39.49237226  -11.97832162    2.67010275    9.0164547
  -17.13370925   16.19133297  189.98318589    2.69855164   45.30294179
   13.26773697   -0.84973298    2.94178241   28.17060853   -9.6563223
  -14.54151497   22.4869278    -0.95980763 -113.16463886   -1.35840472
    0.72354434 -117.1497537    36.62840128   82.83389954    5.89237424
   35.53799524    3.98181706   -4.88553635   -3.50534779   -4.98966972
   -2.35927982   -2.82715982    4.67994871   -5.01879734   31.20194872]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1207.9343177801995
gradient value of function right now is: [ 8.05061112e-04  2.49258480e-02 -6.09639264e-01 -5.80701662e-04
 -8.05061112e-04 -2.49258480e-02  6.09639264e-01  5.80701662e-04
  6.28356261e-03 -5.26314413e-07 -1.16728180e-02  1.61872863e-04
 -7.67384540e-04  1.40405073e-02  3.56927335e-02 -3.29821775e-05
  4.91767253e-02 -2.03488763e-04  5.57972858e-01 -4.46620088e-02
 -5.15920840e-04 -6.53200936e-09 -1.38251315e-04 -2.37892071e-06
 -1.93225947e-01 -1.13145569e-01 -2.27258803e-01 -4.56864362e-03
  4.35101326e-02  2.82057440e-02  5.92144600e-02  3.18044866e-02
 -3.91978081e-01  3.65184971e-02 -6.20554468e-01  2.71352907e-02
 -1.18130673e-02 -1.19840984e-03 -5.50786833e-01  1.86816958e-07
  2.27520733e-02 -3.02944614e-01 -7.12680949e-01  1.89587516e-02
 -2.49074148e-02  1.98594312e-01  1.55285898e-01 -2.84575426e-02
  5.77954204e-03  5.30155960e-01  1.04241290e+00  2.54606005e-03
  8.92693055e-03  7.62002705e-03  7.19591699e-02  6.12920929e-03
  6.87642271e-01  1.54413085e-01  2.39768512e-01  5.16981314e-01
  6.82258580e-02 -5.85907623e-01  3.31159588e-01  4.16910770e-01
 -3.86194264e+00]
supnorm grad right now is: 3.8619426443935763
Weights right now are: 
[   6.37141641   -3.62383461    2.82965824  -15.22568418   -6.1168477
    3.51514292   -2.43072097   14.50965579   87.01073932   94.84218471
   19.77706625   37.53893852  124.46776624  -16.28630921   12.84542056
  -19.22039208    4.32340605   38.58221646    3.85761243  -12.45657205
  133.63664784   80.86761975  246.46123828   58.80159272   10.19166116
   -3.13432173    0.83865247   12.27846192    9.06200316    0.93067558
   13.61481827  -39.45431821  -12.44285928    3.00226323    8.70398662
  -18.11186361   15.48035078  194.91754867    2.15827049   45.92206105
   13.58780159   -0.44225075    2.44210563   28.65703458  -10.31763889
  -14.44323205   22.91191256   -1.56359063 -115.48289636   -1.09260977
    1.25881804 -119.63773593   38.06683748   83.94483612    6.1290644
   37.00223337    3.72411504   -4.47016718   -4.25650987   -4.91183293
   -2.71295986   -2.74177669    4.36293497   -4.79182538   31.07181863]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.4666444227926
gradient value of function right now is: [-3.12862165e-02 -4.90035549e-02 -1.81121810e-01 -7.69475192e-04
  3.12862165e-02  4.90035549e-02  1.81121810e-01  7.69475192e-04
  4.58608933e-03  3.33546198e-05  1.74118290e-02  1.60084301e-06
 -1.10983991e-03 -2.72225837e-02 -6.49819716e-02  2.43130288e-08
 -2.82582089e-02  1.31911849e-03  1.21999257e-02 -1.62235417e-02
 -8.74672623e-04 -4.43307389e-08 -1.29336772e-04 -2.71102718e-07
 -4.53218416e-02 -3.63913256e-02 -1.17797347e-01  1.97893715e-03
 -7.78543907e-02 -4.17784777e-02 -1.19734415e-01 -4.71513733e-02
  1.73580325e-02 -6.22498724e-02 -5.74520444e-02 -6.40584064e-02
 -7.13268463e-03 -3.91107842e-04 -1.95352476e-01 -2.04743104e-10
  1.12670360e-02  4.09191847e-01  4.74708589e-01  7.18416771e-03
 -5.13226006e-03  5.30572221e-02  5.39303156e-02 -8.11351785e-03
  2.29174289e-03 -1.77304148e-01 -2.14752563e-01  3.10013489e-03
 -1.10772221e-02 -1.73258120e-02 -1.51069107e-01 -1.16171442e-02
 -1.00352111e-01 -6.59046073e-01  8.16589260e-02 -1.46481614e+00
 -2.61753613e-01 -3.51307618e-01 -1.65679725e-01 -7.82961947e-01
  5.61294893e-01]
supnorm grad right now is: 1.464816143039563
Weights right now are: 
[ 6.50214433e+00 -3.77587103e+00  2.82368097e+00 -1.59294955e+01
 -6.24757562e+00  3.66717934e+00 -2.42474370e+00  1.52134671e+01
  8.78314165e+01  9.80666366e+01  1.94495560e+01  3.34125591e+01
  1.26355567e+02 -1.56270194e+01  1.18501801e+01 -1.80955844e+01
  3.90991084e+00  4.09221019e+01  3.23786160e+00 -1.26160884e+01
  1.33619205e+02  8.09076833e+01  2.47937376e+02  6.01018114e+01
  9.50027748e+00 -2.89755272e+00  8.94315960e-01  1.33765894e+01
  7.95792730e+00  1.84260281e-01  1.24501053e+01 -4.10260334e+01
 -1.21574689e+01  2.17129684e+00  9.20127539e+00 -1.73331201e+01
  1.56579675e+01  1.98157073e+02  2.21674636e+00  4.65040980e+01
  1.37414752e+01 -7.67856045e-01  2.87993817e+00  2.89070102e+01
 -9.82763709e+00 -1.45946265e+01  2.32418696e+01 -9.86144629e-01
 -1.17246002e+02 -1.10450644e+00  7.47202412e-01 -1.21910711e+02
  3.76045430e+01  8.47052339e+01  5.10759890e+00  3.68922861e+01
  3.50476092e+00 -4.94405166e+00 -4.71510353e+00 -5.24576571e+00
 -2.40483898e+00 -2.85750447e+00  4.21886579e+00 -4.83850056e+00
  3.10981798e+01]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.472156162679
gradient value of function right now is: [ 6.64338970e-02  4.62814714e-02  9.70877371e-01  1.56617631e-03
 -6.64338970e-02 -4.62814714e-02 -9.70877371e-01 -1.56617631e-03
 -1.72711169e-02 -2.21031100e-06 -2.32707276e-02 -2.49433825e-05
  4.64415461e-03  1.07578789e-03  2.02102412e-02  2.42319916e-06
 -2.31601553e-01 -1.39052071e-04  4.38827562e-02 -4.66853663e-03
  1.28302568e-03  2.19709649e-08  2.85450898e-04  8.34988333e-07
  3.15292590e-01 -2.24262581e-02  1.61527146e+00  2.93626223e-03
  1.08949695e-02  6.60613779e-03  1.72293321e-02  7.24064066e-03
  5.15153687e-02  2.78780841e-02  1.90980205e-01  1.29575578e-02
 -3.78433696e-03 -2.84335070e-04 -5.32890390e-02  4.17753930e-09
 -3.19772087e-02 -6.37176274e-01 -8.36242513e-01 -2.55775016e-02
 -3.11709260e-02  2.20685363e-02  2.71465026e-02 -2.99428385e-02
 -3.87286459e-03  2.14871806e-02  5.05659535e-02 -3.41598795e-03
  1.72152421e-03  3.65679020e-03  2.58515872e-02  1.62744467e-03
  5.13785964e-02  1.86259346e-01 -1.72919839e-02  2.87047399e-01
  3.04710624e-01 -3.67415563e-01  1.56512835e-01  2.28032737e-02
 -4.97132701e+00]
supnorm grad right now is: 4.971327009044943
Weights right now are: 
[   6.62699009   -3.81974489    2.92250471  -14.48718453   -6.37242138
    3.7110532    -2.52356744   13.77115615   86.77515816   97.50765356
   20.92553105   32.26552959  129.01614051  -14.35794746   11.99463427
  -19.72201281    4.18403307   40.41974909    3.58226833  -12.01056383
  135.84613844   80.94287304  254.84828702   60.34996168   10.09383286
   -2.9967571     0.81762213   15.22243235    8.80122739    1.01573927
   13.22907343  -40.92767822  -12.13811947    2.18946074    8.97961848
  -16.82948205   16.68168808  202.42903201    2.54275297   46.96969459
   14.23920354   -0.68636337    2.52928963   29.52808899  -10.21522454
  -14.89033871   23.11633578   -1.62722795 -119.53329528   -1.00725753
    0.98319714 -124.33133478   38.06503888   86.17209464    5.23176782
   37.64559939    3.45579032   -4.83313935   -4.60386821   -4.9259135
   -2.66262712   -2.67272407    4.11203965   -4.82994466   31.04137697]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.8324831654204
gradient value of function right now is: [-5.72184597e-03 -9.30755969e-03  1.79315206e-01  1.43325431e-04
  5.72184597e-03  9.30755969e-03 -1.79315206e-01 -1.43325431e-04
  6.44161325e-04  1.13217519e-06  4.65791152e-03  1.42615659e-05
 -2.16410201e-04 -9.86087555e-03 -1.23486022e-02 -1.75483922e-06
 -2.24759293e-01 -4.67683308e-05 -2.68967505e-02  2.41970683e-03
  1.04514833e-04 -1.68086456e-10  2.52626644e-05 -6.58696236e-07
  1.34050972e-02  3.83057351e-02  5.21461061e-01  5.18625235e-04
 -2.72818600e-03  1.83644814e-05  4.03905449e-04 -1.89373562e-03
 -7.19405302e-04 -1.07163618e-02 -2.57723791e-02 -9.86753681e-03
  9.17944823e-04 -3.14303722e-05  2.97454855e-02 -4.13728180e-09
 -9.62126102e-03  7.97032354e-02  6.65370593e-02 -9.19056987e-03
  1.16587959e-02  4.05859161e-02  4.36103156e-02  9.51932686e-03
  6.17260788e-04 -5.16290723e-02 -5.98137791e-02  5.60062881e-04
 -5.79530754e-04 -2.17008914e-03 -1.81209156e-02 -5.20503837e-04
  6.44034432e-02 -1.61999336e-01  9.46115656e-02 -2.57736043e-01
 -1.51426649e-01  3.93279519e-02  5.57946868e-02 -2.31397559e-01
 -1.48627526e+00]
supnorm grad right now is: 1.486275255436793
Weights right now are: 
[   5.72267651   -3.88311388    2.91178751  -16.89382081   -5.4681078
    3.77442219   -2.51285024   16.17779243   89.23340412  101.27091241
   21.77452845   37.33921075  130.01090796  -14.16807835   11.0844899
  -24.69473309    3.84473748   37.2085797     1.86806493  -11.50327387
  133.49820318   80.98973661  257.10533148   59.86686843    9.43217844
   -2.63956678    0.63771078   13.55772147    8.76312152    0.96356033
   13.05281081  -41.29051861  -11.72824191    2.14037543    9.06725751
  -16.36652693   17.04716416  207.76256541    2.95332207   47.36737919
   13.72237772   -0.87694211    2.77953726   29.66614421   -8.99820666
  -14.77539902   23.18993899   -0.77388965 -121.3484102    -1.34725536
    0.88471342 -126.23022496   38.72386691   86.70575372    4.9571567
   38.27587335    3.91069661   -4.84822546   -3.30219752   -5.52687276
   -2.10581044   -3.05265118    4.32483039   -5.06499471   31.19147759]
(65,)
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.834780828603
gradient value of function right now is: [-4.18480025e-03 -7.11672116e-03  1.40295524e-01  1.49272520e-04
  4.18480025e-03  7.11672116e-03 -1.40295524e-01 -1.49272520e-04
  4.16697966e-04  8.58485372e-07  4.01738675e-03  1.24408250e-05
 -1.61526530e-04 -8.37644864e-03 -9.86910419e-03 -1.47275105e-06
 -1.98565908e-01 -1.65635967e-04 -3.66016719e-02  3.05155744e-03
  1.22679920e-04  5.65583087e-10  3.07449654e-05 -6.36992681e-07
  9.24871812e-03  3.80678733e-02  4.46084504e-01  4.09840563e-04
 -6.29010462e-04  7.63889595e-04  3.22226189e-03 -8.88031914e-04
  1.20954839e-03 -7.15980762e-03 -2.06270678e-02 -6.65170408e-03
  1.72420534e-03  1.07882847e-05  3.69519636e-02 -8.48264360e-10
 -8.87391842e-03  1.13594485e-01  8.52593313e-02 -8.46740446e-03
  8.88486699e-03  2.83040934e-02  3.10426687e-02  6.95078195e-03
  4.98679611e-04 -4.15675426e-02 -4.30039024e-02  4.05288239e-04
 -2.78131596e-04 -1.15707829e-03 -1.05546602e-02 -2.27778646e-04
  5.04935523e-02 -1.37282358e-01  7.43578415e-02 -1.69078943e-01
 -1.26587333e-01  3.15331669e-02  4.23247118e-02 -1.97623213e-01
 -1.33797166e+00]
supnorm grad right now is: 1.3379716607544982
Weights right now are: 
[   6.59692138   -3.55619334    2.84610781  -18.0804017    -6.34235267
    3.44750165   -2.44717054   17.36437332   88.59161882   99.79457894
   20.87704534   29.78301119  131.52034046  -14.38879492   11.71541137
  -23.51095877    3.46677723   41.72909325    3.62805415  -11.91606003
  134.26078544   81.03003709  258.78504023   60.91804242    9.70631651
   -2.87117977    0.68272808   12.11581456    9.38077882    1.15266363
   13.08690687  -41.15260205  -12.25175789    1.85477901    9.07245363
  -15.54268404   14.65316659  208.73376105    2.73745949   47.61433037
   13.87423718   -0.86427534    2.33784791   30.48109126  -10.15840565
  -14.90863237   23.29356922   -1.88512852 -123.058226     -0.82893315
    0.96230535 -127.8830853    39.74773739   87.84924582    5.68230238
   39.53338446    3.6880351    -4.78488868   -4.83134014   -4.95218574
   -2.69574537   -2.70534284    4.38499576   -4.96102974   31.1336674 ]
(65,)
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.8296083389826
gradient value of function right now is: [-3.99645709e-03 -7.33325502e-03  1.33153322e-01  1.51288958e-04
  3.99645709e-03  7.33325502e-03 -1.33153322e-01 -1.51288958e-04
  5.66413276e-04  8.13403406e-07  4.08528793e-03  1.59285360e-05
 -1.72259836e-04 -9.28002680e-03 -1.11342822e-02 -2.01506246e-06
 -2.16842839e-01 -1.78433073e-04 -3.42647949e-02  2.67170111e-03
  1.25124526e-04  9.20497182e-10  3.47440828e-05 -7.23944083e-07
  4.52135774e-03  4.24179438e-02  4.71441452e-01  4.97520689e-04
 -2.07193174e-03 -2.92622043e-04  1.06040172e-03 -2.04755049e-03
 -3.48316080e-03 -6.64586248e-03 -3.10849467e-02 -6.18921297e-03
  1.66078543e-03 -1.09176017e-05  3.25549325e-02 -1.77570437e-09
 -9.25692694e-03  1.14994601e-01  8.41295158e-02 -8.70604121e-03
  1.14682393e-02  3.59258114e-02  3.84362788e-02  9.21081644e-03
  6.53063223e-04 -3.29193110e-02 -2.82091205e-02  5.11591836e-04
 -3.41262246e-04 -1.14086665e-03 -1.13454682e-02 -2.86190695e-04
  6.66370791e-02 -1.56187660e-01  7.85263483e-02 -1.75789939e-01
 -1.40061453e-01  3.16375141e-02  5.11574260e-02 -2.14289814e-01
 -1.38951885e+00]
supnorm grad right now is: 1.3895188468542194
Weights right now are: 
[   6.00809645   -3.12736407    2.81584995  -21.66468283   -5.75352774
    3.01867238   -2.41691268   20.94865445   88.49003575  101.20215688
   21.01844197   31.39302282  133.08945049  -13.92155231   12.31375236
  -25.83434365    3.71399171   42.23541232    3.66539918  -12.21984735
  133.01739123   81.06572612  256.79113653   60.31742471   10.64052094
   -2.21943089    0.61365876   12.11795349    9.58633381    0.8524714
   13.17241832  -41.55495244  -12.44548031    2.73315557    9.26214309
  -15.79918531   17.67688123  212.77421552    2.57257829   48.07664022
   14.90269335   -0.8252216     2.38952217   31.53951695   -9.63464078
  -15.4246705    23.09694099   -1.39751057 -124.89475063   -1.36631888
    0.7277788  -130.24997678   39.73962942   89.38335127    5.85363602
   39.65591018    3.62041451   -5.09416508   -5.40553358   -4.63689178
   -3.44853811   -2.3794524     4.112452     -5.14708534   31.0071428 ]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.8390903589002
gradient value of function right now is: [-5.24973302e-03 -6.51563793e-03  1.37906227e-01  1.46299612e-04
  5.24973302e-03  6.51563793e-03 -1.37906227e-01 -1.46299612e-04
  7.51929429e-04  7.88583187e-07  4.40182421e-03  1.75868228e-05
 -2.52372550e-04 -3.13816423e-03 -2.95174112e-03 -2.23734033e-06
 -2.26223558e-01 -1.80189457e-04 -3.40471641e-02  1.50820568e-03
  1.23882306e-04  6.16393146e-11  3.02157097e-05 -8.14252816e-07
  3.43706780e-03  4.11572540e-02  4.82964885e-01  1.57425411e-04
  8.11365065e-03  4.76210767e-03  1.32457258e-02  4.68670069e-03
 -6.99444839e-03 -6.87335222e-03 -3.69227020e-02 -5.99437843e-03
  1.01575744e-03 -5.53042545e-05  1.92259008e-02 -1.99962963e-09
 -8.87410549e-03  1.08645112e-01  7.41022204e-02 -8.30258268e-03
  1.22955397e-02  4.50023721e-02  4.67971168e-02  9.79813905e-03
  6.07118635e-04 -3.45403795e-02 -3.03314000e-02  4.70295278e-04
 -1.06874023e-04 -3.95309368e-05  4.54587045e-04 -8.45923083e-05
  6.92864676e-02 -1.36749801e-01  4.81279591e-02 -4.82108199e-02
 -1.66972604e-01  9.18287247e-02  4.92164239e-02 -1.95178426e-01
 -1.36661902e+00]
supnorm grad right now is: 1.3666190199786332
Weights right now are: 
[   6.36787209   -3.27852077    2.86130468  -19.49019394   -6.11330338
    3.16982908   -2.46236741   18.77416556   88.68753989   99.81467262
   21.84648814   24.28174748  134.55563318  -14.67694124   12.04933097
  -25.35301077    3.8295536    45.22449157    3.7329168   -12.55585437
  134.68873222   81.09121998  262.33126925   61.74357221    9.71882976
   -2.64698885    0.6875624    10.29083224   10.03471072    0.5022181
   13.09556945  -41.74346474  -12.09637702    2.9424216     9.36998496
  -15.38641275   15.03317946  216.48387185    2.17012001   48.57569612
   14.50110428   -0.66608532    2.4980826    31.79976616   -9.61459206
  -15.05469198   23.36459615   -1.58938939 -126.41984662   -0.95056105
    0.97649924 -131.74688298   40.22863773   89.86493301    6.2662199
   40.19491537    3.19292206   -4.91529238   -4.49989498   -5.13489053
   -2.69620773   -2.94788455    4.26763482   -4.93307937   31.04727558]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1208.8352280504146
gradient value of function right now is: [-5.77789117e-03 -6.66171990e-03  1.43921721e-01  1.19866806e-04
  5.77789117e-03  6.66171990e-03 -1.43921721e-01 -1.19866806e-04
  9.28570315e-04  6.81721361e-07  4.37343443e-03  1.90823067e-05
 -2.93482624e-04 -3.79306220e-03 -3.87380900e-03 -2.34027974e-06
 -2.22665555e-01 -1.75352011e-04 -2.95820587e-02  1.40551969e-03
  1.01681476e-04 -5.16426605e-10  2.38456580e-05 -8.29197569e-07
  4.33147735e-03  3.59241399e-02  4.76416196e-01  2.15500302e-05
  6.89086463e-03  4.15434260e-03  1.15953952e-02  3.86648280e-03
 -9.16164356e-03 -7.34521340e-03 -4.09886328e-02 -6.34690510e-03
  7.32007410e-04 -6.77660297e-05  1.81422391e-02 -1.31696528e-09
 -9.16131974e-03  8.17789122e-02  5.19908252e-02 -8.36538033e-03
  8.47465369e-03  3.98802613e-02  4.17553106e-02  6.46552140e-03
  6.62758498e-04 -3.02043943e-02 -2.45748287e-02  5.10407275e-04
 -1.30553964e-04 -1.95636008e-04 -1.17903538e-03 -1.03895071e-04
  6.79789292e-02 -1.49866157e-01  5.77361257e-02 -6.92721697e-02
 -1.57744253e-01  8.48488696e-02  5.69888363e-02 -2.01727575e-01
 -1.41810072e+00]
supnorm grad right now is: 1.418100715367668
Weights right now are: 
[   6.22574033   -3.16767543    3.03018035  -19.21499075   -5.97117162
    3.05898374   -2.63124308   18.49896237   88.04430623  102.07292542
   20.43666439   20.97228391  136.1687082   -13.45931941   12.63425899
  -26.33431396    3.40854519   47.5456555     3.44022451  -12.03212434
  137.12675961   81.11126521  263.48911726   61.90047253    9.72142507
   -2.57119042    0.54188796   11.68894659   10.74815567    0.97105789
   13.64582561  -41.26896325  -12.2890941     2.50253397    9.21196369
  -16.12310647   15.86702241  218.62413149    2.76371985   49.02449887
   14.29321049   -0.78744839    2.24615457   32.51165595  -10.0889648
  -15.04227732   23.46683061   -1.96750766 -127.58615594   -1.19099578
    0.71153443 -133.02546768   40.13375308   91.1905962     6.82308077
   40.2130664     3.68647023   -5.07491132   -4.30598669   -4.97241906
   -2.73353604   -2.76499748    4.20384757   -5.26712576   31.09922905]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1083.1526560241277
W_T_median: 1055.1137301863325
W_T_pctile_5: 967.1305595650562
W_T_CVAR_5_pct: 938.0516580408279
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.25
F value: -1208.8352280504146
-----------------------------------------------
