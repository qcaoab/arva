sleeping 3 hrs
Starting at: 
03-12-22_01:39

 Random seed:  2  



############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = B10_and_VWD
timeseries_basket['basket_desc'] = CRSP data: B10 and VWD
timeseries_basket['basket_columns'] = 
['B10_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
3.3333333333333335% of MC simulations done.
6.666666666666667% of MC simulations done.
10.0% of MC simulations done.
13.333333333333334% of MC simulations done.
16.666666666666664% of MC simulations done.
20.0% of MC simulations done.
23.333333333333332% of MC simulations done.
26.666666666666668% of MC simulations done.
30.0% of MC simulations done.
33.33333333333333% of MC simulations done.
36.666666666666664% of MC simulations done.
40.0% of MC simulations done.
43.333333333333336% of MC simulations done.
46.666666666666664% of MC simulations done.
50.0% of MC simulations done.
53.333333333333336% of MC simulations done.
56.666666666666664% of MC simulations done.
60.0% of MC simulations done.
63.33333333333333% of MC simulations done.
66.66666666666666% of MC simulations done.
70.0% of MC simulations done.
73.33333333333333% of MC simulations done.
76.66666666666667% of MC simulations done.
80.0% of MC simulations done.
83.33333333333334% of MC simulations done.
86.66666666666667% of MC simulations done.
90.0% of MC simulations done.
93.33333333333333% of MC simulations done.
96.66666666666667% of MC simulations done.
100.0% of MC simulations done.
Withdrawal NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       1       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       8  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       8  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       1  logistic_sigmoid   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 8)    False        None  
2       (8, 8)    False        None  
3       (8, 1)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
Allocation NN:
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_Neural_Network.py:344: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  layers_info_df = layers_info_df.append(layer_dict, ignore_index=True)
  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       8  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       8  logistic_sigmoid   
3        obj.layers[3]        3  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 8)    False        None  
2       (8, 8)    False        None  
3       (8, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer        8  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer        8  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        1  logistic_sigmoid   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0       (2, 8)     False        None  
0       (8, 8)     False        None  
0       (8, 1)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
  obj.layers[layer_id]  layer_id   description  n_nodes        activation  \
0        obj.layers[0]         0   input_layer        2              None   
0        obj.layers[1]         1  hidden_layer        8  logistic_sigmoid   
0        obj.layers[2]         2  hidden_layer        8  logistic_sigmoid   
0        obj.layers[3]         3  output_layer        2           softmax   

  x_l(weights)  add_bias b_l(biases)  
0         None     False        None  
0       (2, 8)     False        None  
0       (8, 8)     False        None  
0       (8, 2)     False        None  
Pytorch NN pbject created from original NN class. Change            original NN object to change structure.
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
constant withdrawal:  40.0
constant allocation:  [0.6 0.4]
W_T_mean: 1579.8088921591966
W_T_median: 1137.3149081751399
W_T_pctile_5: -129.57910035187072
W_T_CVAR_5_pct: -296.09225597438984
-----------------------------------------------
2.0% of gradient descent iterations done. Method = Adam
new min fval:  -1697.5484664762378
Current xi:  [2.002407e-07]
objective value function right now is: -1697.5484664762378
4.0% of gradient descent iterations done. Method = Adam
new min fval:  -1701.0405162528107
Current xi:  [-8.46396e-21]
objective value function right now is: -1701.0405162528107
6.0% of gradient descent iterations done. Method = Adam
Current xi:  [8.3729105e-32]
objective value function right now is: -1688.702185931062
8.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.00037254]
objective value function right now is: -1690.2007726778038
10.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.00902466]
objective value function right now is: -1689.8157609030065
12.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.00032144]
objective value function right now is: -1690.255042185241
14.000000000000002% of gradient descent iterations done. Method = Adam
Current xi:  [0.00273292]
objective value function right now is: -1689.843161904753
16.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.00046869]
objective value function right now is: -1690.8492413182341
18.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.00195102]
objective value function right now is: -1688.4098597275654
20.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.00966813]
objective value function right now is: -1691.5907356039793
22.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.00017077]
objective value function right now is: -1691.0784765060587
24.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.00292456]
objective value function right now is: -1687.3294448263277
26.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.00290941]
objective value function right now is: -1689.9496591659658
28.000000000000004% of gradient descent iterations done. Method = Adam
Current xi:  [0.00103746]
objective value function right now is: -1691.3502128808666
30.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.0001106]
objective value function right now is: -1691.5836617685736
32.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.01071764]
objective value function right now is: -1691.155984653502
34.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.00608847]
objective value function right now is: -1689.3527179453813
36.0% of gradient descent iterations done. Method = Adam
Current xi:  [2.8129239e-06]
objective value function right now is: -1691.0725181059793
38.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.0097469]
objective value function right now is: -1691.369873140785
40.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.0026161]
objective value function right now is: -1691.3269749163967
42.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.00120653]
objective value function right now is: -1691.2124765022115
44.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.00119932]
objective value function right now is: -1688.7440374055013
46.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.00141278]
objective value function right now is: -1691.2552327897877
48.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.0020141]
objective value function right now is: -1691.3157338030292
50.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.00261088]
objective value function right now is: -1691.484085331518
52.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.00022162]
objective value function right now is: -1691.9886602397578
54.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.00105516]
objective value function right now is: -1691.7521201080945
56.00000000000001% of gradient descent iterations done. Method = Adam
Current xi:  [0.00027494]
objective value function right now is: -1691.7617510582559
57.99999999999999% of gradient descent iterations done. Method = Adam
Current xi:  [0.00126947]
objective value function right now is: -1691.4119066696835
60.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.00495679]
objective value function right now is: -1689.3058571724832
62.0% of gradient descent iterations done. Method = Adam
Current xi:  [-8.659373e-05]
objective value function right now is: -1690.234044482241
64.0% of gradient descent iterations done. Method = Adam
Current xi:  [5.597882e-05]
objective value function right now is: -1691.5976324814324
66.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.00031388]
objective value function right now is: -1692.0429988379897
68.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.0004718]
objective value function right now is: -1691.5891992005602
70.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.00159287]
objective value function right now is: -1692.6752825955869
72.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.00018465]
objective value function right now is: -1690.431447191358
74.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.0001336]
objective value function right now is: -1689.013730378603
76.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.00354168]
objective value function right now is: -1691.1431156821434
78.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.00221827]
objective value function right now is: -1691.9290647806515
80.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.00214874]
objective value function right now is: -1690.6389479218967
82.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.00176472]
objective value function right now is: -1692.395163682056
84.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.00298672]
objective value function right now is: -1691.289891401066
86.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.0003553]
objective value function right now is: -1691.1452830032379
88.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.00016244]
objective value function right now is: -1692.197839371145
90.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.00018193]
objective value function right now is: -1689.0461455046475
92.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.01427348]
objective value function right now is: -1691.0374904905507
94.0% of gradient descent iterations done. Method = Adam
Current xi:  [0.01122501]
objective value function right now is: -1692.0694925164767
96.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.00115482]
objective value function right now is: -1688.803590707969
98.0% of gradient descent iterations done. Method = Adam
Current xi:  [-0.00033897]
objective value function right now is: -1692.5701635492442
100.0% of gradient descent iterations done. Method = Adam
Current xi:  [-3.192508e-05]
objective value function right now is: -1691.7303544438046
Traceback (most recent call last):
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/decumulation_driver.py", line 862, in <module>
    fun_RUN__wrapper.RUN__wrapper_ONE_stage_optimization(
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/fun_RUN__wrapper.py", line 116, in RUN__wrapper_ONE_stage_optimization
    RUN__wrapper_training_testing_NN(
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/fun_RUN__wrapper.py", line 216, in RUN__wrapper_training_testing_NN
    res_adam = fun_train_NN.train_NN( theta0 = theta0,
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/fun_train_NN.py", line 196, in train_NN
    result_pyt_adam = run_Gradient_Descent_pytorch(NN_list= NN_list,
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/fun_train_NN_SGD_algorithms.py", line 241, in run_Gradient_Descent_pytorch
    min_fval, _ = objfun_pyt(NN_list_min, params, xi_min)
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/fun_eval_objfun_NN_strategy.py", line 31, in eval_obj_NN_strategy_pyt
    params, g, qsum_T_vector = fun_invest_NN_strategy.withdraw_invest_NN_strategy(NN_list, params)
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/fun_invest_NN_strategy.py", line 183, in withdraw_invest_NN_strategy
    a_t_n_output = NN_list[1].forward(phi_2)
  File "/home/marcchen/Documents/pytorch_decumulation_mc/researchcode/class_NN_Pytorch.py", line 83, in forward
    return self.model(input_tensor)
  File "/home/marcchen/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/marcchen/.local/lib/python3.10/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/marcchen/.local/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/marcchen/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA out of memory. Tried to allocate 80.00 MiB (GPU 0; 23.69 GiB total capacity; 18.04 GiB already allocated; 10.75 MiB free; 18.56 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
