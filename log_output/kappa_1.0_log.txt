

############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2103.2229897777083
gradient value of function right now is: [ 3.92151778e+00  8.93190231e-01  1.46450638e-01  4.23143614e-01
 -3.92151778e+00 -8.93190231e-01 -1.46450638e-01 -4.23143614e-01
  7.35202309e+00  3.86533813e-02  1.33666939e-01  1.71613148e+00
 -3.85106270e+00 -1.37351942e-03 -8.26615136e-03 -2.25552951e-01
  5.09531574e-02  6.09733197e-03  8.52936740e-03  1.82506731e-02
 -1.86516775e+00 -8.22217041e-04 -3.85126856e-03 -9.61270038e-02
 -4.62240313e-02  2.46949553e+00  2.71437849e+00  2.23181335e+00
  3.08843090e-02  8.90344083e-04  3.32649874e-02  1.54455248e-02
  7.69266624e-02  8.26718889e-03  9.95332412e-02  5.75388601e-02
  6.44917100e-01  3.39015530e-01  1.06999739e+00  7.66109956e-01
  6.32569763e-02  1.09900897e-01  4.53519109e-02  2.92251650e-01
 -1.61849053e+00 -4.87706074e-01 -1.45663186e+00 -5.32008927e-01
  7.19254269e-01 -3.69310947e-02  7.52878458e-01 -4.50760665e-01
  9.73517871e-01 -3.37435230e-02  1.04935165e+00 -2.84166491e-01
 -8.86308792e-01  2.34306835e+00  2.80932005e+00 -4.56533049e+00
 -1.20211995e+00  3.50301964e+00  1.76450663e+00 -3.24211961e+00
 -8.75434418e+00]
supnorm grad right now is: 8.754344183300764
Weights right now are: 
[ -1.83795967   3.26870909  -1.33035488   2.61503475   2.09252838
  -3.37740078   1.72929215  -3.33106313   1.47222845  -4.33560734
  -2.57270612  -1.67727998   2.97068498   3.77577383   4.58334873
   4.23836866   8.28560702 -14.72631004  -8.63581267   2.67986817
   4.07259334   2.92192476   3.88930577   3.9700614   -2.16498868
   3.34961793  -1.99367979  -2.34201536   2.82597486   5.00452755
   9.28408083   8.41870471   1.13073518   6.15584689   5.99355806
   5.40386052  -4.33092131   4.783642     1.97111634   2.43760585
   5.2832799    1.76190047   6.94572464   3.17417124  -3.23125672
  16.08605695  -5.07670626   9.94685774  -1.08061319   3.92700224
  -1.08347448   0.88284228  -0.02959328   5.0686406   -1.34253709
   2.79520541   5.83500977   1.96289691   2.75557622  -1.12467165
   6.0364001    1.74600023   1.41256703  -1.45342996  27.33111032]
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2113.3863054795875
gradient value of function right now is: [-1.09693070e+01  5.68283133e-01  9.40331675e-01  6.16489330e-01
  1.09693070e+01 -5.68283133e-01 -9.40331675e-01 -6.16489330e-01
 -9.43531478e+00 -3.70400022e-01 -5.06458956e-01 -1.30942928e+00
  4.20165714e+00  9.04447115e-02  1.33702307e-01  4.27275094e-01
  3.04617293e-01 -9.91862775e-02 -1.15414025e-01 -1.70195827e-01
  4.10628453e+00  9.17476965e-02  1.35203816e-01  4.28024452e-01
 -1.73689574e+00  2.26143772e+01 -4.35300933e+00  5.93638336e+00
 -8.89487697e-02 -2.66537109e-04 -3.43160671e-01 -1.01358171e-04
 -3.61739095e-02 -2.24567078e-04 -1.51096883e-01 -8.31022650e-05
  1.22415743e-02 -1.11951662e-03 -1.61484374e-02 -3.84492018e-04
 -1.97345868e-01 -7.15969059e-01 -5.29343184e-03 -6.64235139e-01
  7.93440053e-01  5.27816930e-01 -1.47391275e+00  4.92248994e-01
  2.05194904e+00  4.09289229e+00 -1.08980284e-01  3.93505467e+00
  4.10709518e+01  9.30613838e-01  2.38467447e+01  9.26059667e-01
  1.00967386e+01 -1.23989968e+01 -9.70081845e+00  5.74392468e+01
  9.00280066e+00 -4.93948860e+01 -5.26847666e+00  4.56123361e+01
  3.59277776e+01]
supnorm grad right now is: 57.43924680652392
Weights right now are: 
[ -2.04183149   3.42372432  -2.38393302   3.19707953   2.2964002
  -3.53241601   2.78287029  -3.91310792  -1.50484258  -3.0749198
   0.34406685   1.78075981   4.7386924    2.21892927   2.18317351
   2.72915337  11.94085594 -16.16795561  -8.89525935   3.43123943
   4.85493002   2.60824666   2.03552102   2.3594048   -3.11019938
   2.60527837   0.80888735  -8.63500883   3.1700643   28.189791
  16.58381744  15.78412199   2.39273247  27.22761784  14.5977429
  12.70493799  -1.99859852  21.02171539  10.20373751  10.16541561
  20.11395727   3.69582078   9.75840707   3.22671231  -1.8820857
  21.00581426  -4.4520521   14.69683791  -2.66734735   3.10569286
  -0.12665534   1.51704324   1.36099103  21.88328532  -2.96069259
  18.4855702    5.19653821   2.66032117   1.32207302  -1.43121862
   9.37372246   1.66772711   1.42671271  -1.43565791  27.96285881]
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2122.9698089237654
gradient value of function right now is: [-4.87130564e+00 -3.26862752e+00 -1.41855532e+00 -3.11768556e+00
  4.87130564e+00  3.26862752e+00  1.41855532e+00  3.11768556e+00
 -8.13993173e-01  5.54132948e-02  5.32713858e-02  2.65952338e-01
  2.21008002e+00 -7.32075784e-03 -6.97022448e-03 -5.22023677e-02
 -8.52336856e-01  1.27806358e-02  1.25435980e-02  2.42298318e-02
  2.11592303e+00 -6.23162744e-03 -5.93460524e-03 -4.38444980e-02
  1.54748830e-01 -1.29727114e+01 -1.31321176e+01 -2.55168148e+00
  1.16715113e-02  1.39516690e-07  4.85955229e-02  3.85317280e-08
  4.73012323e-03  6.45061811e-08  2.03273637e-02  1.81324009e-08
 -1.64035269e-02  4.71322396e-06 -4.53339648e-02  1.55473856e-06
  5.47733560e-03  2.49358384e-02  1.22280320e-04  1.97403121e-02
  2.82880176e+00  1.02935763e-01  1.73149623e+00  1.02358132e-01
  1.22913100e+00 -6.41052421e-01  1.01449612e+00 -6.03657925e-01
 -1.92039818e+01 -5.92632670e-01 -1.26651990e+01 -5.88968732e-01
  8.73163265e-03 -1.55934875e+00  4.10059317e+00 -2.61677605e+01
 -2.96771689e+00  1.53404644e+01  3.43018733e+00 -2.32620373e+01
 -6.17698097e+00]
supnorm grad right now is: 26.16776050883743
Weights right now are: 
[ -1.92862294   3.1740226   -2.49247722   2.84014326   2.18319165
  -3.28271429   2.89141448  -3.55617164  -1.40253868  -6.31416635
  -2.03285595   3.10310278   5.26636667   2.64123456   2.47234393
   4.4573337   12.57079249 -18.77605533 -10.96070676   3.99478903
   5.70541159   3.05884077   2.35271498   4.0747621   -3.31118529
   2.05199438   1.20199078  -9.75551285   8.05903352  34.37544714
  23.98281859  18.57830013   8.79386274  32.49454273  24.2240735
  15.15099827  -6.81710566  30.04311369  14.01160933  15.44583617
  34.27067034   3.72707476  16.35489648   3.09146109  -1.36241301
  28.38807257  -3.99847073  23.11451477  -3.34184752   2.75059533
   0.90536251   1.62712393   1.55002558  32.54750599  -3.08124027
  28.65518236   5.90673994   3.07589197   0.97923249  -1.90068353
  10.02778692   2.26455453   1.134229    -1.88460465  27.73892588]
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2126.8879792129374
gradient value of function right now is: [ 1.05994043e+01  3.21680358e+00  6.11058377e-01  1.80850626e+00
 -1.05994043e+01 -3.21680358e+00 -6.11058377e-01 -1.80850626e+00
  5.64604102e+00  7.80465720e-02  6.69032136e-02  6.75120617e-01
 -5.33185461e+00 -6.26823513e-03 -5.02446553e-03 -1.32739746e-01
  4.01542998e-01  1.45547368e-02  1.36270033e-02  2.75151691e-02
 -2.60399963e+00 -1.87701704e-03 -1.51034880e-03 -3.75153622e-02
  3.40945610e-01 -2.41028342e+00  1.73185296e+01 -9.41772816e-01
  1.36109123e-02  5.50400496e-08  4.77582776e-02  1.19775345e-08
  5.23864769e-03  1.44429447e-08  1.91213269e-02  3.12613461e-09
 -3.79778834e-02  1.33888121e-04 -2.74392485e-02  3.34368528e-05
  2.15560104e-02 -7.56054160e-02  5.14721231e-04 -7.52108415e-02
 -2.50712168e+00 -1.95840117e-01 -5.04812455e-01 -1.90174325e-01
 -3.06126448e+00 -1.83823331e+00 -7.11660511e-01 -1.79583692e+00
 -8.32530829e+00 -1.55721915e-01 -7.73770566e+00 -1.58318405e-01
 -4.44869356e+00  7.45012989e+00  3.35758838e+00 -2.00139231e+01
 -1.89453612e+00  1.12821917e+01  2.58875293e+00 -1.73516615e+01
 -1.99415713e+01]
supnorm grad right now is: 20.01392309434964
Weights right now are: 
[ -1.90363074   3.85946544  -1.80796155   3.02896723   2.15819945
  -3.96815713   2.20689882  -3.74499561  -1.4928311   -6.73077662
  -2.76218117   3.12918348   4.33162618   2.49727865   2.32109265
   8.1684364   13.36397665 -20.1898784  -12.63842476   5.09373184
   7.04601034   2.70049974   2.00268024   7.22899575  -2.90882666
   2.14005117   1.25650739 -10.34291557   9.14720109  34.54653165
  29.95099387  18.60031173  11.11191087  32.56536168  31.62542501
  15.15967653 -12.3066278   28.14027331  14.98679129  12.5209913
  45.02727286   3.60860206  20.81796388   3.01957602  -1.75627481
  34.10580792  -4.2823836   29.35119351  -2.8855138    2.82905314
   0.74452613   1.9446715    1.66054733  41.48562398  -3.09086928
  37.39981079   6.32462701   3.24270167   0.93020956  -2.01195627
  10.10403846   2.12058076   1.01239722  -2.0082079   27.74471972]
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2124.8019326879225
gradient value of function right now is: [ 1.51366407e+01  7.00213443e+00  1.58921053e+00  8.07419677e-01
 -1.51366407e+01 -7.00213443e+00 -1.58921053e+00 -8.07419677e-01
  8.14545873e+00  6.02988729e-02  4.82046080e-02  4.61728193e-01
 -1.01715270e+01 -1.87517135e-02 -1.37413238e-02 -3.09858918e-01
  1.17368493e+00  8.91858710e-03  8.04489732e-03  2.15939841e-02
 -1.01486456e+00 -8.89028793e-05 -6.41813637e-05 -1.82619818e-03
  6.42371559e-01 -3.02953068e+00  1.67049361e+01 -9.92205234e-01
  4.65454318e-03  3.77954474e-09  4.13170791e-02  7.85009315e-10
  2.03858012e-03  7.07055087e-10  1.92993306e-02  1.43286279e-10
  4.31032703e-02  2.12133150e-05  1.51547165e-01  4.97804605e-06
  1.70539571e-02  3.10364815e-01  7.28783806e-04  2.87016391e-01
 -1.69683901e+00 -1.29767367e-01 -3.11447233e-01 -1.25509686e-01
 -3.52247907e+00 -3.64696937e+00 -1.07158170e+00 -3.48981009e+00
 -8.80363404e+00 -1.26849620e-01 -6.82856791e+00 -1.30177947e-01
 -4.23608458e+00  6.56568982e+00  4.64970546e+00 -1.84910750e+01
 -1.63015458e+00  1.00337683e+01  3.58255479e+00 -1.64632711e+01
 -2.43419615e+01]
supnorm grad right now is: 24.341961477063585
Weights right now are: 
[ -2.15463332   3.9550159   -2.1721457    4.29746147   2.40920203
  -4.06370759   2.57108297  -5.01348985  -1.42573767  -7.18915978
  -3.86781951   4.30373892   3.15573345   1.38076931   1.89792915
   8.30651764  11.83965051 -20.30296711 -13.14251032   7.34176151
  16.38473852   0.74803507   0.69796349   6.28379105  -1.76991133
   2.33442644   1.8789314  -10.63673857  13.05855585  34.54985075
  35.89878972  18.60045892  16.23351638  32.56617477  38.61106871
  15.15971135 -13.53037562  24.82725515  19.84398954   9.79897129
  52.4782849    4.72098274  25.80628733   4.05478117  -1.65802189
  40.01790025  -3.858122    35.57883522  -3.26952882   2.78672505
   0.43293001   2.12636492   1.48137637  49.2962605   -2.94301519
  45.10490569   6.96850417   3.58418171   0.79244903  -2.13867136
   9.80861473   1.89661947   0.90197819  -2.12864431  27.67952223]
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2132.4126131691833
gradient value of function right now is: [ 9.37750912e-01  1.07162376e+00  5.22676886e-01  2.30708440e-01
 -9.37750912e-01 -1.07162376e+00 -5.22676886e-01 -2.30708440e-01
 -2.28305333e-01 -5.74109457e-02 -4.72472117e-02 -2.82785413e-01
 -2.34902478e-01  8.79177347e-03  6.77779819e-03  1.03124446e-01
  2.48924280e-01 -9.30219594e-03 -8.41522379e-03 -1.67663008e-02
 -2.30053121e-01  2.94220740e-06  2.20199070e-06  5.51350030e-05
 -1.41416128e-01  3.33999736e+00  3.73105257e+00  9.09598629e-01
 -2.17996343e-03 -3.13485104e-12 -2.09779833e-02  3.24849635e-12
 -1.05571719e-03 -7.20052592e-13 -1.04967761e-02  3.45740689e-13
 -3.72392515e-04 -1.05416165e-07  8.34405166e-03  4.31369176e-07
 -3.57985566e-03 -9.79712306e-03 -3.35274294e-04 -6.79517365e-03
 -1.40079539e+00 -3.18484438e-02 -4.96979666e-01 -3.09807024e-02
 -9.25178258e-01  6.59852401e-01 -4.32613579e-01  6.27801669e-01
  7.21662195e+00  7.32320250e-02  2.96263300e+00  7.10957321e-02
  9.81194391e-04  7.23249871e-01 -1.55612334e+00  5.29341073e+00
  1.68454745e+00 -7.72056074e+00 -1.33432160e+00  4.80948024e+00
  2.33628863e+00]
supnorm grad right now is: 7.72056073532744
Weights right now are: 
[ -2.38105757   3.97286167  -2.72007209   4.74321534   2.63562628
  -4.08155336   3.11900936  -5.45924373  -1.52545246  -6.57954619
  -3.70593746   4.89085492   3.42262489  -0.97472673   0.27944935
   8.35613779  14.00028478 -21.24387095 -14.51047229   8.56556794
  22.99288058  -0.62771467  -0.19391252   5.32782578  -2.58344437
   2.72455247   2.42182427 -11.31512143  12.81530397  34.54989349
  42.12798098  18.60045407  17.49562597  32.56618212  46.01974624
  15.15971076 -17.88212098  20.58421413  20.09778103   8.00880638
  57.74858113   4.54020221  31.15953583   3.95480494  -1.58974583
  44.33110168  -3.72313333  39.8928192   -2.76523757   3.10325061
   0.2959051    2.54903296   1.48237714  54.91228323  -3.35438868
  50.80903509   7.57502372   3.82549049   0.71898404  -2.13659047
   9.01730099   1.69510391   0.8611338   -2.12569347  27.91113245]
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -2130.613312370695
gradient value of function right now is: [-1.94775059e+00 -3.16527622e-02  1.11577431e+00  9.12472187e-01
  1.94775059e+00  3.16527622e-02 -1.11577431e+00 -9.12472187e-01
 -2.14455008e+00 -6.73147567e-02 -5.42390346e-02 -3.01763095e-01
  2.17426426e+00  1.00245234e-02  7.26669964e-03  1.26249763e-01
  3.12846429e-03 -6.98778594e-03 -6.31128270e-03 -1.18717000e-02
 -2.70216498e-01  8.21353633e-07  5.76806325e-07  3.32868696e-05
 -2.32200781e-01  9.58776821e+00  4.09003454e+00  1.96267536e+00
 -7.43596378e-04 -1.09144241e-11 -2.09376774e-02 -1.36146489e-12
 -3.36711523e-04 -9.12034420e-13 -1.02424623e-02 -1.06865951e-13
 -3.30049484e-03 -2.15047614e-06  1.44466315e-02 -3.08056546e-07
 -3.23242235e-03 -4.67597963e-02 -2.77306788e-04 -4.16807087e-02
 -2.40666721e+00 -3.48468153e-02 -1.06252729e+00 -3.40625695e-02
 -1.38343743e+00  1.40582058e+00 -1.04765429e+00  1.33433871e+00
  1.76883821e+01  2.22521533e-01  8.90711423e+00  2.16014253e-01
  8.14673706e-01 -6.83357452e-01 -3.91256993e+00  2.16403383e+01
  3.58185006e+00 -1.92155072e+01 -3.35947180e+00  1.95611382e+01
  6.89688680e+00]
supnorm grad right now is: 21.64033827995851
Weights right now are: 
[ -2.46837863   3.77298732  -2.63778103   5.08136845   2.72294734
  -3.88167901   3.0367183   -5.79739684  -1.56874325  -6.1768049
  -3.36505331   5.57308307   3.42111093   0.07569974   1.90062596
   7.60951415  15.87650706 -21.91767178 -15.55567037   9.53458388
  27.1064436   -0.83892238  -0.30769021   4.31339063  -1.40431172
   2.6913959    2.57737137 -11.67369537  11.19419494  34.54989077
  45.77396559  18.60045148  17.4024115   32.56618199  50.7074831
  15.15971049 -19.79314309  15.10303077  21.48234142   5.28332048
  62.58588806   5.29871692  38.9461493    4.84139104  -1.74693901
  48.27241609  -4.29989724  43.80704956  -2.19164892   2.72577889
   0.3128703    2.22752653   1.5886804   61.05765852  -3.4082064
  57.01556222   7.78104102   3.8742391    0.88389259  -2.14712357
   9.55786169   1.69852055   1.02173798  -2.14781203  27.73033477]
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2126.349035606596
gradient value of function right now is: [ 1.33002725e+01  7.32093753e+00  1.89163165e+00  1.02705547e+00
 -1.33002725e+01 -7.32093753e+00 -1.89163165e+00 -1.02705547e+00
  6.31212534e+00  1.34772863e-01  1.07101075e-01  6.94621524e-01
 -6.26252536e+00 -1.12198394e-02 -7.48884525e-03 -2.84957664e-01
  6.34866199e-01  1.22676006e-02  1.12024340e-02  1.90741043e-02
 -5.74396795e-01 -6.02664904e-07 -4.20448610e-07 -5.86927640e-05
  7.89975735e-01 -3.01896061e+00  1.34927158e+01 -1.15116142e+00
  1.68231050e-03  2.05095769e-11  4.68904780e-02  3.09752813e-12
  7.98590384e-04  1.36044180e-12  2.39216706e-02  1.92046845e-13
  2.07622426e-02  5.36078463e-05 -1.50615058e-02  9.57952878e-06
  1.41413554e-02  2.67741922e-01  1.35116954e-03  2.42897443e-01
 -1.75653418e+00 -9.99343048e-02 -3.59119823e-01 -9.56164668e-02
 -4.12649371e+00 -3.48285636e+00 -1.13413900e+00 -3.31772943e+00
 -1.08700179e+01 -1.18947698e-01 -7.04873518e+00 -1.19794444e-01
 -4.11232098e+00  6.63220215e+00  4.68833515e+00 -2.09017115e+01
 -3.02711791e+00  1.54589592e+01  3.90423906e+00 -1.90317487e+01
 -2.44189679e+01]
supnorm grad right now is: 24.418967939403103
Weights right now are: 
[ -2.40150748   3.68050181  -2.23620612   4.76621562   2.65607619
  -3.7891935    2.63514339  -5.48224401  -1.5591655   -6.69473358
  -3.88007071   5.7473571    3.44983663   4.79586159   7.4525475
   7.86856369  19.02897558 -24.29705158 -18.30547139   8.5843277
  28.92257789  -0.81769584  -0.27896049   4.94387639  -1.98215772
   2.23799125   2.82940573 -12.08093228  12.66613365  34.54988696
  47.22323775  18.60045014  19.44229364  32.56618183  52.56344059
  15.1597104  -25.57078177   9.97622876  22.10419606   3.53452881
  62.5899423    5.44217297  48.10325967   5.12895253  -1.81263212
  51.35427833  -4.2452465   46.74491522  -2.80128337   2.70774934
   0.50277345   2.27307269   1.4309294   67.23152668  -3.59593852
  63.28529435   8.27827508   4.4015746    1.11085601  -2.26746192
   9.35894686   1.92354826   1.23087686  -2.26321397  27.90454885]
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2131.0743597683877
gradient value of function right now is: [-4.86886792e+00 -2.05266919e+00  1.70570431e-01  2.16150481e-01
  4.86886792e+00  2.05266919e+00 -1.70570431e-01 -2.16150481e-01
 -3.41087061e+00 -1.12918847e-01 -9.07026799e-02 -5.19446660e-01
  2.96837222e+00  7.39615985e-03  4.91032903e-03  1.60493863e-01
 -9.04022900e-02 -9.90789228e-03 -8.92105413e-03 -1.64437591e-02
 -2.11673228e-02  1.26521347e-07  8.33408041e-08  1.36314546e-05
 -3.16630725e-01  5.14107630e+00 -9.42651694e-01  1.15529959e+00
 -6.08012616e-04 -3.75377392e-12 -3.82017945e-02 -3.61144798e-13
 -3.13097877e-04 -2.97341034e-13 -2.13785626e-02 -2.50288776e-14
 -5.82307100e-03 -2.75247879e-05  5.30261207e-02 -4.84258976e-06
 -6.77448635e-03 -8.30424100e-02 -8.88798007e-04 -7.60045913e-02
 -2.40092953e-01 -1.78729433e-03 -4.19106986e-01 -2.75203905e-03
  1.05116153e-01  1.98675337e+00 -5.80508170e-01  1.90704023e+00
  1.10932925e+01  1.00247647e-01  7.07862046e+00  1.02973199e-01
  2.17028772e+00 -3.61724119e+00 -2.59516672e+00  1.34708977e+01
  2.55557530e+00 -1.38255534e+01 -2.29689761e+00  1.28925305e+01
  1.39258598e+01]
supnorm grad right now is: 13.9258597919544
Weights right now are: 
[ -2.54144983   3.47545849  -2.37597391   4.64759245   2.79601854
  -3.58415018   2.77491118  -5.36362083  -1.52898125  -6.73861348
  -4.25568889   6.38266734   3.19261002   4.54505103   8.09324503
   8.89123185  21.15079362 -27.14602244 -21.46207877   6.8724831
  31.23133571  -0.83471268  -0.28572039   6.41453028  -2.23222595
   2.38271853   2.93783395 -12.07490849  13.36905978  34.54988468
  50.33237131  18.60044952  20.58402086  32.56618172  55.79734746
  15.15971036 -23.44803197   0.73374159  22.13571435  -1.41057383
  59.87750236   6.52436431  58.30157203   6.20539454  -2.00916456
  54.96292602  -4.65093993  50.3045143   -2.21487225   3.0219733
   0.42541844   2.62631291   1.59495062  73.3069417   -3.1252706
  69.42280166   8.65951659   4.21729353   0.89012437  -2.33390421
   9.21273946   1.71406102   1.01107859  -2.31423081  27.96809435]
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2130.3265548385953
gradient value of function right now is: [-8.46566866e+00 -4.45470906e+00 -4.26116934e-01 -1.53692851e-01
  8.46566866e+00  4.45470906e+00  4.26116934e-01  1.53692851e-01
 -5.06115444e+00 -1.50935220e-01 -1.20022401e-01 -7.84255757e-01
  4.43027608e+00  1.07209649e-02  6.98219267e-03  2.73349332e-01
 -2.14236547e-01 -8.94577103e-03 -8.14630569e-03 -1.40723805e-02
  1.88346211e-01  5.10313138e-08  3.20797809e-08  9.83076169e-06
 -4.08572921e-01  6.98416479e+00 -5.48890848e+00  1.63660926e+00
 -1.22843043e-03 -9.34834836e-13 -5.42137255e-02 -7.11264042e-14
 -6.68966900e-04 -6.24828259e-14 -3.16446911e-02 -4.46677143e-15
 -7.29361386e-04  4.95197652e-06  1.08649907e-01 -2.79041073e-07
 -8.55246836e-03 -8.46954712e-02 -1.37913266e-03 -6.87776484e-02
 -1.32167808e-02  4.98770905e-02 -6.89282295e-01  4.55965480e-02
  1.50639271e+00  3.11573901e+00 -5.35109046e-01  2.86693725e+00
  1.55792831e+01  2.01749522e-01  1.04091865e+01  1.99210332e-01
  2.54354476e+00 -4.41671457e+00 -6.34012983e+00  3.16559058e+01
  3.50422903e+00 -1.94097011e+01 -5.52888638e+00  2.90617072e+01
  1.99159842e+01]
supnorm grad right now is: 31.655905808569965
Weights right now are: 
[ -2.5034483    3.42404524  -2.1981206    5.22645474   2.75801701
  -3.53273693   2.59705787  -5.94248312  -1.43812725  -7.47151506
  -5.04942902   6.2789959    3.0004908    6.56368469  11.34925306
   7.54076674  23.91294046 -28.02321219 -22.60200711   7.08351619
  33.77791523  -0.83849666  -0.28651905   7.0867065   -2.08464604
   2.271073     3.00355471 -12.06810393  11.42333407  34.54988388
  52.00687099  18.60044934  19.14738822  32.56618167  57.73091017
  15.15971034 -26.01372261  -4.75460716  22.19474148  -2.81981761
  59.29516826   5.62226029  61.67543004   5.21056342  -1.23535075
  57.7809913   -3.80408142  52.95249863  -2.43046338   2.59443206
   0.30095292   2.2223857    1.61355506  78.16220849  -3.48123002
  74.38700092   8.79514403   4.28481234   0.48608107  -2.30167093
   8.94776164   1.73464994   0.72440803  -2.28744215  27.90695112]
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2127.863049098962
gradient value of function right now is: [-1.10740390e+01 -7.41990759e+00 -1.79144826e+00 -1.31212872e+00
  1.10740390e+01  7.41990759e+00  1.79144826e+00  1.31212872e+00
 -4.48391121e+00 -6.68695315e-02 -5.55548292e-02 -3.54447761e-01
  4.13740414e+00  2.40673687e-03  1.50393980e-03  1.08410236e-01
 -3.83166311e-01 -3.49140557e-03 -3.24896416e-03 -5.05331248e-03
  5.11418107e-01  1.15001920e-08  7.68970364e-09  6.88676814e-06
 -1.94639933e-01 -4.05163638e+00 -1.50656210e+01 -4.76811547e-01
 -1.15324910e-04 -2.25267449e-13 -1.63136439e-02 -1.93160625e-14
 -5.89999269e-05 -1.34619508e-14 -9.13833569e-03 -1.02226368e-15
  2.91545106e-03 -1.96149286e-05  6.69680133e-02 -4.73328312e-06
 -5.16493215e-03 -4.79806065e-02 -1.00149629e-03 -4.17794434e-02
  2.58797257e+00  7.37212634e-02  9.52915101e-01  7.10790003e-02
  5.23754336e+00  1.53429428e+00  2.12475886e+00  1.45671349e+00
 -4.39101022e+00 -1.47721463e-02  7.72644783e-02 -1.10711785e-02
  1.87479998e+00 -3.58596812e+00 -5.98145357e-01  4.86652201e+00
 -1.12134732e+00  3.88015973e+00 -4.46173199e-01  4.53413119e+00
  1.47558800e+01]
supnorm grad right now is: 15.065620991249263
Weights right now are: 
[-2.71862177e+00  3.27952638e+00 -2.27848147e+00  4.96189996e+00
  2.97319048e+00 -3.38821807e+00  2.67741874e+00 -5.67792834e+00
 -1.57079514e+00 -6.55035320e+00 -4.16071394e+00  6.74122850e+00
  3.31246245e+00  5.97796822e+00  1.14369253e+01  8.64203119e+00
  2.75555402e+01 -2.82562017e+01 -2.31545163e+01  8.21285201e+00
  3.54902704e+01 -8.39789257e-01 -2.86985615e-01  4.71099536e+00
 -2.75623297e+00  2.16754559e+00  2.90380437e+00 -1.23261592e+01
  9.04521271e+00  3.45498835e+01  5.46621954e+01  1.86004493e+01
  1.70926241e+01  3.25661817e+01  6.05904488e+01  1.51597103e+01
 -2.81278324e+01 -6.05489298e+00  2.13486909e+01 -7.18968327e-01
  5.89890400e+01  6.44553489e+00  7.07588613e+01  6.08681121e+00
 -1.49372786e+00  6.10184534e+01 -4.62286529e+00  5.59683091e+01
 -2.30392291e+00  2.86811568e+00  3.04822732e-02  2.49185555e+00
  1.63397841e+00  8.23207898e+01 -3.57099895e+00  7.86842687e+01
  8.64419199e+00  4.44193151e+00  9.17853541e-01 -2.34936811e+00
  8.61806667e+00  1.79423660e+00  1.10905188e+00 -2.33357815e+00
  2.80093537e+01]
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2125.7588313491697
gradient value of function right now is: [-7.98002191e+00 -5.40692237e+00 -1.20750879e+00 -8.72401913e-01
  7.98002191e+00  5.40692237e+00  1.20750879e+00  8.72401913e-01
 -2.99017657e+00 -5.50528233e-02 -4.50715058e-02 -2.21430781e-01
  3.09644323e+00  1.43133357e-03  8.64294191e-04  6.86538455e-02
 -2.67127422e-01 -2.40297324e-03 -2.22271496e-03 -3.50236823e-03
  3.19224155e-01  3.74353904e-09  2.65098332e-09  7.63740282e-05
 -2.34875736e-02 -5.61791741e+00 -1.03352205e+01 -9.00453407e-01
  2.20708376e-04  3.24722351e-14 -1.48768745e-02  3.38671470e-14
  9.38326711e-05 -5.60436364e-15 -8.25969550e-03  1.33354016e-15
 -4.61197847e-03 -1.37551236e-04  1.28825065e-02 -2.88102466e-05
 -6.46676860e-04 -3.88367237e-02 -2.89117574e-04 -3.35990987e-02
  1.30953854e+00  4.09365644e-02  8.42251221e-01  3.97211813e-02
  5.03558373e+00  1.25808035e+00  3.16770258e+00  1.20197093e+00
 -8.38840589e+00 -1.03562641e-01 -5.09429246e+00 -1.00346501e-01
  6.37846210e-01 -1.57835130e+00  4.68572487e-01 -9.73393183e+00
 -2.11639862e+00  1.05394093e+01  5.19387606e-01 -9.26083866e+00
  8.30146307e+00]
supnorm grad right now is: 10.539409322113212
Weights right now are: 
[ -2.60808563   3.44904418  -2.57777432   5.32994088   2.86265434
  -3.55773587   2.97671159  -6.04596926  -1.71651028  -7.34393172
  -4.59897957   5.85818384   3.04653365  10.12807314  17.365789
   7.9482905   29.59660055 -29.88549288 -25.09628859   7.95105409
  38.76754895  -0.83961973  -0.2866121    2.5019054   -1.96888145
   2.27534224   2.90290436 -12.17151045   7.55870072  34.5498834
  54.06931013  18.60044924  15.89522658  32.56618165  60.54993483
  15.15971034 -34.10597458  -7.19836667  20.88276884   0.75821235
  56.12362637   6.3074049   73.16601644   5.973088    -1.75445702
  64.82044044  -4.41186896  59.62089718  -2.11195597   3.48696741
   0.28347252   3.07012735   1.68869203  86.3127245   -3.77659335
  82.78641156   9.06502989   4.16392167   0.32380518  -2.42793211
   8.38861838   1.83838333   0.5191996   -2.42228507  27.90598052]
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2132.972932717477
gradient value of function right now is: [ 3.88234820e+00  2.08562876e+00  5.08201097e-02  1.20435384e-02
 -3.88234820e+00 -2.08562876e+00 -5.08201097e-02 -1.20435384e-02
  2.41673770e+00  1.47181249e-02  9.99215083e-03  1.55485793e-01
 -2.18285443e+00 -2.09895716e-03 -1.17538592e-03 -8.31769466e-02
  2.46886167e-02 -5.47515804e-04 -5.00778162e-04 -2.83930102e-03
 -2.50644999e-02 -1.89538446e-08 -1.47663118e-08  4.29500050e-03
  1.28081932e-01 -1.72549624e+00  1.81904564e+00 -4.01167076e-01
  5.36232391e-05  2.40784192e-13  7.10372933e-03  2.55770164e-14
  2.52501469e-05  7.80252202e-15  3.55279260e-03  7.79690364e-16
  9.35117324e-04  4.14686279e-02  2.54071523e-02  3.65930530e-03
  3.95246743e-03  3.47188018e-02  3.34056781e-04  3.15912554e-02
 -5.11928369e-01 -2.16411673e-02  1.74726492e-02 -2.04502404e-02
 -6.58122898e-01 -7.45446514e-01  2.35445558e-01 -6.93095477e-01
 -4.33424690e+00 -4.13567029e-02 -2.64615886e+00 -4.18928282e-02
 -1.19783284e+00  2.09176664e+00  1.82777998e+00 -8.48974663e+00
 -8.31858417e-01  5.22380143e+00  1.56127390e+00 -7.96435040e+00
 -7.60643276e+00]
supnorm grad right now is: 8.48974663142999
Weights right now are: 
[ -2.55677211   3.1729917   -2.42104996   5.78019748   2.81134082
  -3.28168339   2.81998723  -6.49622587  -1.40123632  -6.6544637
  -3.69646231   6.19528009   2.54124522  11.6101799   20.74555349
   6.97263686  31.86680529 -32.91505822 -28.37554638   5.91396098
  40.49717902  -0.83453867  -0.28207134  -9.53074502  -2.32272122
   2.13750432   3.13786891 -12.54997721  10.24946219  34.54988328
  55.5605402   18.60044922  18.59693805  32.56618165  62.88612937
  15.15971034 -33.03186425 -15.38343746  22.92672729   7.29468621
  55.93055279   8.59047682  80.14406613   8.36712592  -1.51807462
  66.82431274  -4.32917763  61.36206326  -2.17632764   2.87596225
   0.33711447   2.463876     1.55504445  90.91795803  -3.59368687
  87.50381162   8.75885483   4.67738782   0.76226304  -2.50904673
   8.95377581   1.65627997   0.89083781  -2.50031469  27.91976485]
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -2132.4174140042633
gradient value of function right now is: [ 1.80916257e+00  5.21212188e-01  1.65952247e-01  1.45589465e-01
 -1.80916257e+00 -5.21212188e-01 -1.65952247e-01 -1.45589465e-01
  1.78427706e+00  1.60211297e-01  1.26725323e-01  5.43276035e-01
 -7.28955985e-01 -2.89664078e-03 -1.72833363e-03 -4.96324062e-02
 -1.90996231e-02  3.78316178e-03  3.42228559e-03 -9.80017872e-03
  3.18222869e-02 -7.60514009e-08 -6.15062332e-08  2.60042065e-02
  4.19824240e-02 -2.00719121e+00 -4.39016205e-01 -5.91888371e-01
  1.49085047e-05  4.11459265e-14  3.51599353e-02  4.93400367e-15
  6.54613046e-06  9.41845730e-16  1.62662118e-02  1.01188694e-16
  1.08205765e-04  3.46871651e-01  1.88461998e-01  4.71645246e-02
  3.73272921e-03  2.09599399e-02  4.90203897e-04  1.99599754e-02
 -9.64181101e-01 -3.40103411e-02 -3.38176908e-01 -3.38856424e-02
 -4.63724010e-01 -9.59411269e-01 -1.32165225e-01 -9.36591045e-01
 -6.44778982e+00 -5.84504892e-02 -4.27066906e+00 -5.97034968e-02
 -1.19486344e+00  2.34431358e+00  2.20067792e+00 -1.19540909e+01
 -1.92007921e+00  1.00039981e+01  2.01394050e+00 -1.15523443e+01
 -8.34670554e+00]
supnorm grad right now is: 11.954090910127354
Weights right now are: 
[ -2.59209324   3.17299427  -2.96065057   4.87391691   2.84666195
  -3.28168596   3.35958784  -5.58994529  -1.48358359  -6.26737654
  -3.27740834   6.91475949   2.84055143  13.09946344  22.62414126
   8.49122664  34.16565519 -34.91022432 -30.5251263    8.03539585
  42.67462735  -0.817821    -0.26824366 -10.17024581  -5.02728802
   2.35721717   3.17203131 -11.93291462   5.62105189  34.54988322
  56.91739353  18.60044921  14.41165186  32.56618164  64.67916616
  15.15971034 -28.03989274 -16.51767039  21.30448627  18.78743662
  48.53849214   9.80613062  80.76273092   9.46750988  -2.93132184
  68.6080733   -4.28885391  63.29192976  -2.56359691   2.75686182
   0.54965899   2.33127216   1.73164594  94.80507543  -3.41435038
  91.34675515   9.08409531   4.36093513   0.55633343  -2.52713404
   8.63405983   1.81318817   0.63260021  -2.50808644  27.89885237]
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2131.51516162135
gradient value of function right now is: [ 2.85406844e+00  2.38309792e+00  9.83328125e-01  9.85201884e-01
 -2.85406844e+00 -2.38309792e+00 -9.83328125e-01 -9.85201884e-01
  5.36953185e-01 -3.57874182e-02 -3.09495476e-02 -6.73562515e-03
 -5.31219750e-01 -1.43944246e-04 -2.08888182e-05 -5.31614305e-02
  1.07330930e-01 -2.71438581e-03 -2.48684473e-03  2.64591881e-02
 -1.42877703e-01  7.16356176e-09  6.25137009e-09 -5.16122457e-02
  6.54578353e-02  3.16000453e-01  2.57253536e+00 -1.56698057e-01
  2.35086627e-05  2.96883788e-13 -4.30739377e-03  3.09937469e-14
  9.71560957e-06  3.67456924e-15 -2.22281244e-03  3.16596290e-16
  1.56581323e-05 -6.00215075e-01 -5.74114162e-01 -1.57282286e-02
  3.84594840e-03  1.68742837e-02  7.32669312e-04  1.51895974e-02
 -1.16820838e+00 -4.49296571e-02 -7.06469903e-01 -4.47369351e-02
 -9.60964471e-02  7.02367156e-02  5.61907681e-02  7.58732683e-02
 -9.45166967e-01  2.48761887e-02  5.83219014e-01  2.56188425e-02
 -6.11626982e-01  1.34390232e+00  6.97296904e-01 -6.88806285e-01
 -1.49724736e+00  5.75304145e+00  6.12484839e-01 -3.33530861e-01
 -4.09562207e+00]
supnorm grad right now is: 5.75304144652861
Weights right now are: 
[ -2.65529472   3.27088521  -2.95409425   4.38029632   2.90986343
  -3.3795769    3.35303152  -5.0963247   -1.67831883  -6.56603118
  -3.04854136   6.5045381    2.95769306  16.37728362  27.01896258
   6.65362784  37.67131144 -35.50668698 -31.27608926  10.08431294
  43.5033688   -0.81352969  -0.26519934  -8.20463467  -4.0197167
   2.122593     3.67608789 -12.15536099   1.90362242  34.54988319
  55.73053926  18.60044919  11.47904214  32.56618164  64.52664569
  15.15971034 -28.52957513 -16.40750445  20.42132971  24.57230642
  48.59665394  10.21905997  84.04142991   9.86129     -3.47184274
  70.47531639  -4.4397833   65.25713197  -2.4846359    3.14435766
   0.44309402   2.77205382   1.65041955  98.91681452  -3.51679548
  95.41473458   9.35137654   4.21773165   0.55054791  -2.45957429
   8.4966864    1.8886997    0.70099497  -2.43305374  27.91343176]
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2132.4646958148433
gradient value of function right now is: [-2.45357254e+00 -7.84793119e-01  3.08685723e-01  5.19038538e-01
  2.45357254e+00  7.84793119e-01 -3.08685723e-01 -5.19038538e-01
 -2.46345813e+00 -1.35568597e-01 -9.90305010e-02 -6.03889844e-01
  1.63756095e+00  6.31032810e-03  2.88795379e-03  8.52643120e-02
  1.40447812e-02 -3.97531196e-03 -3.62704605e-03  7.61593755e-02
 -4.94642900e-02  2.33014563e-09  1.34433614e-09 -1.69514309e-01
 -1.55138143e-01  3.38354138e+00  6.19972690e-01  6.54547788e-01
 -8.72875025e-05 -1.89643685e-12 -4.68630826e-02 -9.55578545e-14
 -3.66351937e-05 -1.31690561e-14 -2.02785653e-02 -4.89562406e-16
  2.71516430e-03 -1.12825645e+00 -8.72754332e-01 -9.59316087e-02
 -9.74876702e-03 -5.29150851e-02 -1.76686049e-03 -4.74720544e-02
 -5.85794235e-01 -8.76434402e-03 -6.97853564e-01 -9.70160193e-03
  1.61648683e+00  1.59321776e+00  8.14616930e-01  1.50826988e+00
  9.03592707e+00  7.94234308e-02  5.14847868e+00  7.98574250e-02
  2.29798091e+00 -4.23531867e+00 -2.76635826e+00  1.29967883e+01
  2.89090866e+00 -1.42449878e+01 -2.50559556e+00  1.24572967e+01
  1.14480684e+01]
supnorm grad right now is: 14.244987809622282
Weights right now are: 
[ -2.75499966   3.33918009  -2.74079195   4.13518366   3.00956838
  -3.44787178   3.13972922  -4.85121204  -1.67382025  -7.56450472
  -3.8668231    6.28731953   2.58550499  17.88549433  29.22838692
   6.59316556  38.78646384 -38.08378577 -33.96631667  11.8918219
  45.80709418  -0.81261008  -0.26460353  -2.52782314  -5.02077783
   1.72734246   3.94336647 -12.39866838  -3.7803259   34.5498831
  54.97080263  18.60044918   7.60765143  32.56618164  64.34575374
  15.15971034 -32.17150194 -16.52382519  19.72148     24.58051138
  43.56892612   9.88329964  87.12998922   9.52988747  -3.22885559
  69.98834667  -3.50436588  64.84873292  -2.27362622   3.15845585
   0.45622671   2.7916646    1.7206726  102.63699318  -3.88537393
  99.07168489   8.97138915   3.83534692   0.45435861  -2.53940431
   8.57811115   1.60754406   0.60908493  -2.52508517  27.99553363]
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2131.836559703375
gradient value of function right now is: [-1.32139178e+00 -1.10309975e+00 -3.02257949e-01 -6.46498928e-01
  1.32139178e+00  1.10309975e+00  3.02257949e-01  6.46498928e-01
 -3.73679120e-01 -1.04585995e-03 -2.85914110e-03 -2.62454020e-01
  3.94937919e-01  4.32994930e-04  8.40179051e-05  2.50308700e-01
  2.39591786e-03 -3.78539325e-03 -3.34163457e-03 -1.29636102e-01
 -1.30923053e-02  1.85875091e-10  3.06511494e-11  2.62881249e-01
 -6.04020587e-02  1.98890798e+00  6.17507406e-01  8.07514402e-01
 -3.82477651e-06 -8.82599424e-13 -1.86989114e-03 -2.93971750e-14
 -1.24273479e-06 -2.87131177e-15 -1.90119358e-03 -7.94829197e-17
  1.07282658e-03  1.04589122e+00  9.84249190e-01  4.70553268e-02
 -3.24305357e-03 -1.56586705e-02 -6.09565603e-04 -1.41441734e-02
  6.35843464e-01  1.36786829e-02  2.46276403e-01  1.31933404e-02
 -2.34329550e+00  5.00096049e-01 -1.69484528e+00  4.67238841e-01
  4.97646593e+00  1.41595506e-02  3.49244798e+00  1.50944465e-02
  9.40227506e-01 -1.57331177e+00 -6.97945387e-01  4.95520075e+00
  1.58615329e+00 -8.95918283e+00 -6.02971148e-01  4.81369334e+00
  2.41148141e+00]
supnorm grad right now is: 8.959182834976877
Weights right now are: 
[ -2.8592221    2.98582614  -2.48657655   3.74560988   3.11379082
  -3.09451783   2.88551382  -4.46163826  -1.34724309  -6.47870748
  -2.52263066   6.65726499   2.2310951   18.77882321  30.6844355
   7.7005023   39.84800794 -44.89376959 -40.95841346  12.65714119
  47.11493512  -0.81255112  -0.26455328   0.91929691  -3.69368764
   2.1664988    4.38519371 -12.04889437  -8.4842284   34.5498834
  55.29246017  18.60044918   5.06024557  32.56618164  65.20855211
  15.15971034 -32.2581178  -16.64832549  19.29628101  27.94669841
  40.83187973   9.57830162  91.74287351   9.31343266  -3.98103474
  69.12660094  -3.13771112  63.94459088  -2.66370025   2.6661248
   0.44025893   2.30309027   1.79729054 107.17181109  -3.72204062
 103.56776577   8.61744705   3.83236272   0.74176962  -2.51407517
   8.49411074   1.65810323   0.89602431  -2.49317628  27.81328371]
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2130.025782123839
gradient value of function right now is: [ 1.08159479e+00  5.95306526e-01  2.32301373e-02 -2.45804181e-01
 -1.08159479e+00 -5.95306526e-01 -2.32301373e-02  2.45804181e-01
  7.26758995e-01  2.52440825e-02  1.52277044e-02  9.25229758e-02
 -3.25705879e-01 -1.44650611e-03 -4.84954363e-04  7.11191652e-02
  1.65994818e-02  3.72853000e-05  3.28238765e-05 -7.46289255e-02
 -7.00296193e-03 -6.92018588e-11 -2.72198641e-11  1.48753276e-01
  8.28522119e-02 -3.99260223e+00 -8.86040773e-01 -1.04052470e+00
  3.14733210e-05  3.35979232e-12  1.09839647e-02  1.08414238e-13
  9.13147916e-06  3.71823825e-15  3.15976575e-03  8.73219021e-17
  1.29099512e-03  7.03404148e-01  5.82481329e-01  7.34914871e-02
  8.34278590e-03  2.68352132e-02  1.04506581e-03  2.03577442e-02
 -1.84997757e-01 -1.91980183e-02  1.77408504e-01 -1.65559065e-02
 -1.00860071e+00 -3.59186606e-01 -2.95748141e-01 -2.94242483e-01
 -1.18152781e+01 -1.13407598e-01 -7.87001664e+00 -1.18673663e-01
 -1.81550666e+00  3.38537616e+00  2.76548816e+00 -2.21853049e+01
 -2.97812964e+00  1.65624083e+01  2.58523696e+00 -2.18796968e+01
 -9.75773090e+00]
supnorm grad right now is: 22.185304885155084
Weights right now are: 
[ -2.89684986   3.13489086  -2.16612347   3.48345911   3.15141857
  -3.24358255   2.56506074  -4.19948749  -1.75247029  -7.30108934
  -2.89109818   6.2766959    2.88517265  18.47222168  31.41421714
   8.32189711  41.6046617  -45.51126861 -41.7372681   14.03377054
  49.51424111  -0.81253018  -0.26453261   0.18125219  -4.02009736
   2.20073458   4.09377412 -12.74772009 -14.85373866  34.54988364
  54.76082517  18.60044916   2.33501558  32.56618164  66.53568943
  15.15971034 -32.85993079 -16.78544059  18.86366341  29.39330984
  35.30309398  10.36250494  92.27106801  10.10606405  -3.38955272
  69.01599579  -2.93879832  63.35470717  -2.72000142   3.15758758
   0.73252296   2.64497466   1.63197285 110.72337606  -3.90645651
 107.28798426   8.55900557   4.0240207    0.33040088  -2.6550364
   8.36195978   1.71727928   0.72362157  -2.59645447  27.93988523]
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2133.5202593379395
gradient value of function right now is: [ 3.07933281e-02  1.13368999e-01  3.86584653e-01  2.96259190e-01
 -3.07933281e-02 -1.13368999e-01 -3.86584653e-01 -2.96259190e-01
 -1.55685393e-01  2.69366401e-03 -4.20383465e-04 -1.44555881e-02
  2.62851896e-01 -5.80687693e-05 -9.04589047e-05  4.36943534e-02
  1.79015774e-02 -3.78325584e-04 -3.28709960e-04 -3.82672952e-03
 -2.88242120e-02  1.94313616e-11 -2.22216221e-12  5.67398749e-02
 -1.03026026e-02 -6.47637865e-02  9.53351283e-02 -4.63646593e-02
  3.72301480e-06 -6.45975674e-14  2.50968765e-03  1.38425182e-13
  9.30086487e-07 -3.18869709e-15  4.32688862e-04 -1.94516017e-17
 -1.21190425e-03  5.77164328e-02  1.61088939e-02  1.27999594e-02
 -1.51484717e-03 -3.72242359e-03 -2.88384027e-04 -2.67618951e-03
 -4.83649185e-01 -1.48830383e-02 -1.73492403e-01 -1.32266106e-02
 -2.79594405e-01  1.57481954e-01 -8.20826920e-02  1.50608033e-01
 -8.83808316e-01 -8.50267434e-03 -5.49829956e-01 -7.82480985e-03
 -1.81604544e-01  6.83309869e-01  6.28182814e-01 -2.91128357e+00
 -3.30106754e-01  2.25545830e+00  5.52647232e-01 -2.50350093e+00
 -1.60960338e+00]
supnorm grad right now is: 2.911283573439413
Weights right now are: 
[ -2.89726669   2.98035361  -1.86118293   3.26030903   3.1518354
  -3.0890453    2.2601202   -3.97633742  -1.58362942  -7.74586674
  -3.23026833   7.02249482   2.65190713  21.01307563  35.31415525
   7.46543803  44.32153705 -51.50548628 -47.87843438  13.73425308
  50.03453855  -0.81254086  -0.2645267    0.15628438  -4.37599463
   2.11929449   4.39903293 -13.24964257 -20.77434389  34.54988963
  53.87375999  18.6004492   -1.0026327   32.56618164  65.04877775
  15.15971034 -29.50977954 -17.06261294  18.81374379  29.63632826
  31.93464847  10.85738243  94.61443985  10.60844339  -3.38140968
  68.1906328   -2.6425965   62.16467381  -2.53018843   2.97809338
   0.63734231   2.39293284   1.79217571 115.13706166  -3.85498507
 111.69118622   8.90057489   4.10434096   0.62115011  -2.58536304
   8.65677489   1.66965795   1.14792054  -2.53395369  27.8735567 ]
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2129.139726764992
gradient value of function right now is: [-4.27485884e+00 -3.38697089e+00 -7.94279654e-01 -6.51236779e-01
  4.27485884e+00  3.38697089e+00  7.94279654e-01  6.51236779e-01
 -1.14856656e+00 -6.68665924e-03 -6.94722275e-03  1.18969839e-03
  1.22719886e+00 -6.67355551e-04 -2.61066423e-04  1.71291090e-02
 -9.64214509e-02 -1.23954114e-03 -1.05842996e-03 -5.35749985e-03
  1.20018333e-01  2.01209266e-11  5.38663561e-13 -5.02310327e-02
 -5.14349440e-03 -3.16322846e+00 -4.47078851e+00 -7.99147393e-01
  2.31410925e-05 -9.46138134e-12  1.12760150e-03  4.70036653e-14
  7.65750632e-06 -5.07469303e-15 -1.06777937e-06  1.12786796e-17
  3.43404774e-04  7.15503363e-02  3.42274579e-02  2.41582767e-02
  3.14944672e-04 -2.35118786e-03 -1.28323403e-04 -1.66750341e-03
 -1.42127340e-04 -3.64003415e-03 -1.17333185e-01 -3.61263827e-03
  2.80200406e+00  6.65998631e-01  1.61553925e+00  5.83234109e-01
 -7.39141289e+00 -5.18709563e-02 -3.36548328e+00 -4.11803438e-02
  1.10605658e+00 -3.16869556e+00  1.84801702e+00 -1.09152417e+01
 -3.04988130e+00  1.37760146e+01  1.36420661e+00 -8.40796209e+00
  3.35059366e-01]
supnorm grad right now is: 13.776014621359705
Weights right now are: 
[ -2.95437107   3.23277217  -2.11277941   3.05737843   3.20893978
  -3.34146386   2.51171668  -3.77340681  -1.83570982  -7.57029626
  -2.72014669   7.24925325   2.99663785  23.09034583  39.64426677
   7.41621088  46.11751467 -53.58604729 -50.03728327  14.30017295
  52.28293106  -0.81254396  -0.26452395  -0.30392377  -5.31919111
   2.07033224   4.29703203 -12.80890453 -22.11744189  34.5498798
  53.43421742  18.60044911  -1.31778473  32.56618165  64.84623639
  15.15971034 -29.91944955 -16.58977161  18.89168568  33.67884182
  30.54247121  10.59143602  97.32458923  10.60967596  -3.452543
  67.30271826  -3.08953494  59.92258968  -2.43254799   3.17410447
   0.85898663   2.70512247   1.66919136 118.67625379  -4.11240101
 115.32231982   9.03825824   3.59275713   0.16401091  -2.52107093
   8.28433071   1.73759823   0.85749475  -2.51175235  27.82908396]
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2130.4703743246905
gradient value of function right now is: [-6.75630478e+00 -5.06622318e+00 -2.08952757e+00 -2.64526599e+00
  6.75630478e+00  5.06622318e+00  2.08952757e+00  2.64526599e+00
 -2.67846291e+00 -1.29008047e-01 -8.33630566e-02 -1.00950203e+00
  1.72044367e+00  3.32018116e-03  9.87626911e-04  4.99872651e-01
 -8.99332021e-02 -1.99649901e-03 -1.66978805e-03 -1.39663982e-01
  1.22121967e-01  4.51968040e-11  9.91998853e-12  3.73172201e-01
 -1.44073323e-01  4.22141051e-01 -3.51403323e+00  5.13176914e-01
 -5.47930370e-05 -1.50124694e-10 -4.90693582e-02 -1.41765476e-12
 -1.26674507e-05 -1.97671490e-14 -1.38118735e-02 -1.23054888e-16
  2.76128730e-03  1.63139856e+00  1.73798269e+00  6.44078761e-02
 -1.11396855e-02 -6.12535597e-02 -1.45281493e-03 -3.97136544e-02
  2.33855867e+00  5.82282521e-02  9.73866319e-01  5.30328691e-02
 -1.46155069e+00  1.89194984e+00 -1.08761159e+00  1.54846242e+00
  2.19030352e+00 -2.51755458e-02  6.71437363e-01 -2.43917938e-02
  1.31867723e+00 -2.29741834e+00 -1.89487789e+00  1.40413444e+00
  1.91712619e+00 -8.55473881e+00 -1.15478242e+00  3.91903681e-01
  1.43314862e+01]
supnorm grad right now is: 14.331486182833913
Weights right now are: 
[ -2.94169543   3.10090749  -2.06199459   2.93295063   3.19626414
  -3.20959918   2.46093186  -3.64897901  -1.43616103  -8.67767239
  -3.24818719   6.61179739   2.54908111  23.87947561  43.50666437
   7.92934695  48.37941467 -55.58310882 -52.18513243  14.63297253
  55.22561984  -0.81254895  -0.2645224   -0.70606666  -4.91749091
   2.1032997    4.19431068 -12.80976465 -25.83597114  34.54988656
  52.24152805  18.60044827  -3.16545924  32.56618165  65.10775518
  15.15971034 -29.82019917 -16.51466865  18.41573121  34.61509805
  32.52606877   9.2806123  101.62663401   9.30056622  -3.15374427
  67.08072336  -3.26580662  59.10192425  -2.68351421   2.96429733
   0.56371168   2.10046152   1.97365657 121.9576235   -3.98527692
 118.80610703   8.54281577   4.09318856   0.24019553  -2.69459292
   8.63835646   1.54989518   0.87549075  -2.62370149  28.18228101]
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2131.9435916513166
gradient value of function right now is: [ 2.56443819e+00  7.56492758e-01 -2.72426884e-01 -2.36275727e-01
 -2.56443819e+00 -7.56492758e-01  2.72426884e-01  2.36275727e-01
  2.94850840e+00  3.51047194e-01  2.37483469e-01  1.17068951e+00
 -1.12884400e+00 -3.64298730e-03 -1.31612418e-03 -1.35150398e-01
 -1.98120078e-03  1.10690023e-02  9.23588159e-03  2.65091140e-02
  3.35509267e-02 -1.38008983e-11 -4.76485605e-12 -2.65390943e-03
  6.74427295e-02 -8.86997518e-01 -9.46199864e-02 -2.33394690e-01
  2.51729131e-05  5.78510158e-11  1.02782598e-01  4.58048477e-13
  5.06121310e-06  8.50683390e-15  2.79659786e-02  7.24453077e-17
 -3.55164126e-04 -8.24001692e-02 -3.62865004e-01  7.09258272e-03
  6.38560150e-03  3.40015418e-02  6.86087076e-04  1.77024291e-02
 -3.57076214e-01 -6.79073496e-03 -7.59733747e-02 -2.58050661e-03
  4.67266149e-01 -3.05918665e+00  3.46031817e-01 -2.68851086e+00
 -2.68431904e+00 -1.26240885e-02 -1.28300744e+00 -9.56437820e-03
 -9.56775742e-01  1.60767223e+00  1.69876758e+00 -3.40841605e+00
 -1.34419868e+00  6.44511800e+00  1.20165158e+00 -2.02554141e+00
 -9.18363865e+00]
supnorm grad right now is: 9.183638651987405
Weights right now are: 
[ -2.84942855   3.1120855   -2.16656313   3.10193746   3.10399726
  -3.22077719   2.5655004   -3.81796584  -1.39546135  -7.97841227
  -2.32104996   7.27511098   2.55928025  25.2934634   46.34821909
   7.64641467  50.37625265 -58.9098038  -55.63221228  15.33491891
  57.7903941   -0.81255101  -0.26452201  -0.23535459  -4.51996976
   2.02201225   4.04851865 -13.48029267 -32.5957978   34.54986935
  52.14966384  18.6004473   -8.52359167  32.56618166  65.13287203
  15.15971034 -27.7621115  -16.78956027  18.35152568  35.44309824
  31.3409803    9.10021352 106.52599748   8.91455296  -3.10453666
  67.53723157  -2.9274531   58.79429416  -2.7374897    2.55982275
   0.90270885   1.8437066    1.89329511 125.47440747  -4.25904966
 122.32319218   8.301336     4.01682337   0.20659236  -2.48023631
   8.42308858   1.71328958   1.02845396  -2.53205093  27.74738519]
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2128.7821458926537
gradient value of function right now is: [ 1.04850190e+01  7.23640601e+00  1.35674401e+00  1.35535460e+00
 -1.04850190e+01 -7.23640601e+00 -1.35674401e+00 -1.35535460e+00
  5.38473712e+00  2.35625492e-01  1.46037600e-01  1.17715807e+00
 -3.75170983e+00 -6.20390990e-03 -1.77413046e-03 -3.66695629e-01
  1.12828800e-01  3.01167726e-03  2.44661413e-03  2.13501813e-02
 -1.38237113e-01 -2.04372973e-11 -2.78909924e-12 -1.16566571e-01
  1.86190347e-01 -1.10991405e+00  5.17075218e+00 -4.68528551e-01
  6.94200523e-05  2.07645969e-09  8.98712103e-02  1.12698848e-11
  1.27206290e-05  1.23732234e-13  1.96869335e-02  5.22921322e-16
 -2.19118850e-04 -3.10870606e-02 -3.88463442e-01  4.11242671e-02
  1.71098062e-02  8.49688673e-02  1.72979129e-03  4.04331117e-02
 -1.93173721e+00 -6.94905952e-02 -5.02126567e-01 -4.65349716e-02
 -1.86522224e+00 -3.07105394e+00 -9.03610131e-01 -2.18265729e+00
 -6.18431195e+00 -6.21336072e-02 -4.57717544e+00 -5.56943346e-02
 -2.99922923e+00  5.35772798e+00  4.61990122e+00 -1.96073441e+01
 -1.93165459e+00  1.13963822e+01  3.23436421e+00 -1.49336571e+01
 -2.18092219e+01]
supnorm grad right now is: 21.80922187375378
Weights right now are: 
[ -2.8381096    3.09672448  -2.12374737   3.22401168   3.09267832
  -3.20541617   2.52268464  -3.94004006  -1.50362031  -8.2006256
  -2.05004924   7.24916194   2.20126941  26.73879644  49.07731318
   7.47427068  53.10886932 -63.33887365 -60.25598913  15.58581854
  59.28750258  -0.81255265  -0.26452188   0.50200378  -4.4734946
   2.1817039    4.08720747 -13.14126696 -39.68088923  34.54850498
  50.89104269  18.60041497 -12.92677943  32.56618167  64.53014105
  15.15971034 -25.66607654 -16.98976956  18.64080745  36.37586388
  29.23975057  10.45284592 109.02799885  10.15168843  -3.71610758
  66.70727662  -2.89497483  57.58542331  -3.00941647   2.79410306
   0.55033027   2.33584943   1.95375273 129.26690684  -4.39081214
 126.09828611   8.48743528   4.23650725   0.30146131  -2.60017501
   8.56721768   1.64860194   1.24249254  -2.61794219  27.72852284]
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2132.5719945831092
gradient value of function right now is: [-2.21317666e+00 -1.33462443e+00  3.22791774e-02 -6.16816908e-02
  2.21317666e+00  1.33462443e+00 -3.22791774e-02  6.16816908e-02
 -1.53341434e+00 -1.08371632e-01 -6.85804610e-02 -5.00200479e-01
  1.01337179e+00  2.86158043e-03  5.56491218e-04  1.77763373e-01
 -5.67334588e-03 -3.57622862e-03 -2.85869435e-03 -1.72547796e-02
 -2.72005991e-03  1.18136356e-11  4.12289628e-13  5.42108024e-02
 -9.56717859e-02  2.65402818e+00 -1.98956681e-02  7.36991848e-01
 -8.26822535e-05 -9.44836188e-09 -3.92793440e-02  2.08766920e-11
 -1.24923939e-05 -7.07279061e-14 -8.08013374e-03 -1.33711127e-16
  1.06768584e-03  1.40208736e-01  2.48103894e-01 -6.10259952e-03
 -4.43791805e-03 -2.34830868e-02 -8.74537844e-04 -1.53879298e-02
  3.98101370e-01  1.38942106e-02 -3.93804517e-02  1.00358681e-02
 -4.93695768e-01  1.33500609e+00 -4.04573687e-01  1.09868347e+00
  7.48747513e+00  3.71574364e-02  4.25881535e+00  3.61281066e-02
  1.33103385e+00 -2.48502024e+00 -2.17906428e+00  1.05608268e+01
  2.68285160e+00 -1.42025076e+01 -1.71147014e+00  9.30075185e+00
  7.16321201e+00]
supnorm grad right now is: 14.202507568789898
Weights right now are: 
[ -2.84512844   3.04468204  -1.96122274   3.31252436   3.09969715
  -3.15337373   2.36016001  -4.02855275  -1.3252748   -8.66739097
  -1.59322044   7.22153224   2.38013313  25.88953791  50.21246217
   7.98833234  55.08482645 -63.32432255 -60.35251266  16.12747137
  62.23218108  -0.81255077  -0.26452181  -0.33031222  -2.87212204
   2.2545138    4.17055182 -13.46512044 -45.36248452  34.54481952
  50.12706595  18.60046795 -15.77145134  32.56618168  66.26997203
  15.15971034 -28.66476261 -16.38412764  18.70947492  38.16671877
  31.65114916   8.81070508 114.62258785   8.77907514  -3.20003773
  67.23707079  -2.56759988  56.54601206  -2.70233436   2.84979546
   0.88252583   2.30576277   1.96056752 132.76296824  -4.10804477
 129.8930556    8.92255464   3.82549264   0.24015213  -2.6163528
   8.49569235   1.57886574   0.8419242   -2.59065804  27.88346014]
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2131.0030135361826
gradient value of function right now is: [ 5.83108329e+00  3.64585866e+00  3.45973660e-01  6.14928334e-01
 -5.83108329e+00 -3.64585866e+00 -3.45973660e-01 -6.14928334e-01
  3.39924508e+00  9.90588984e-02  5.26793310e-02  6.83452042e-01
 -2.52084501e+00 -2.51596415e-03 -6.45244031e-04 -2.82091897e-01
  1.88454025e-02  4.69875475e-04  3.68156451e-04  3.76151968e-02
 -3.05021283e-02 -4.58775818e-12 -2.92430202e-13 -2.29040654e-01
  1.47509595e-01 -5.26261591e-02  2.94364253e+00 -1.47894772e-01
  1.19028717e-04  6.96688031e-07  4.49042744e-02  7.14425004e-09
  1.10338883e-05  2.30950351e-13  8.15494419e-03  1.84580352e-15
 -1.66347153e-02 -3.12311464e-01 -4.97844261e-01  6.68783875e-03
  6.93061970e-03  7.68935929e-02  9.90351851e-04  4.47040679e-02
 -1.59839376e+00 -5.18993751e-02 -5.67556500e-01 -4.13299735e-02
 -3.22376449e-01 -1.59540640e+00 -1.64244915e-01 -1.11474951e+00
 -2.08318272e+00 -5.91410331e-04 -3.99971224e-01 -1.97175759e-04
 -1.13696576e+00  2.16942354e+00  2.94729745e+00 -5.40964067e+00
 -1.05540065e+00  4.62054010e+00  1.87951228e+00 -3.45224081e+00
 -1.20659829e+01]
supnorm grad right now is: 12.065982861236762
Weights right now are: 
[-2.79473322e+00  3.16542745e+00 -2.14363689e+00  3.25715922e+00
  3.04930193e+00 -3.27411914e+00  2.54257416e+00 -3.97318760e+00
 -1.41203380e+00 -9.04118206e+00 -2.41452045e+00  7.31923034e+00
  2.33268171e+00  2.72872787e+01  5.32346856e+01  8.51176762e+00
  5.88425988e+01 -6.96715705e+01 -6.68113845e+01  1.63924778e+01
  6.24050819e+01 -8.12549068e-01 -2.64521780e-01 -5.35784127e-03
 -4.80055122e+00  1.90505278e+00  3.96434155e+00 -1.38537439e+01
 -5.24908887e+01  3.45615871e+01  5.01646161e+01  1.86000559e+01
 -1.84359994e+01  3.25661817e+01  6.56903876e+01  1.51597103e+01
 -2.70725044e+01 -1.73098954e+01  1.85587592e+01  3.83628786e+01
  3.06951891e+01  9.61432507e+00  1.18312794e+02  9.62931683e+00
 -3.48551189e+00  6.78161997e+01 -2.94055839e+00  5.64856719e+01
 -2.51364479e+00  2.92089369e+00  6.57999799e-01  2.36884849e+00
  1.90170870e+00  1.36070049e+02 -4.15411519e+00  1.33438705e+02
  8.74026991e+00  4.09647112e+00  8.08125343e-01 -2.57582718e+00
  8.74011699e+00  1.60962932e+00  1.57651941e+00 -2.53619149e+00
  2.77367889e+01]
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2129.8678397528274
gradient value of function right now is: [ 8.78174335e-01  1.49147938e-01 -1.91025979e-01 -4.93142710e-01
 -8.78174335e-01 -1.49147938e-01  1.91025979e-01  4.93142710e-01
  1.07185706e+00  6.56075905e-02  3.29911547e-02  2.09436011e-01
 -4.65939507e-01 -1.31941196e-03 -2.58397536e-04  7.26012629e-02
 -7.09043827e-03  5.86639121e-04  4.61698689e-04 -5.40154382e-02
  2.52078578e-02 -3.96682756e-12 -1.43162620e-13  1.56536674e-01
  9.47100706e-02 -5.23964391e+00 -1.83564617e+00 -1.05094349e+00
  2.57896911e-04  2.99933225e-06  3.02398772e-02  4.00081395e-08
  1.76995835e-05  2.42453835e-13  4.79806965e-03  2.42976251e-15
 -2.12585758e-02  5.53129118e-01  3.91464897e-01  3.85351915e-02
 -2.36974473e-04  3.59540576e-02  5.06175835e-04  2.25095637e-02
  3.38514879e-01 -8.23566348e-03  1.55895961e-01 -6.85617175e-03
 -5.72573920e-01 -1.12366254e+00 -6.10402861e-01 -8.42073894e-01
 -1.10678262e+01 -9.50688533e-02 -6.04372439e+00 -7.92427938e-02
  8.98606511e-01 -2.51621608e+00  4.57742016e+00 -2.24869561e+01
 -3.29824947e+00  1.64365327e+01  3.16760389e+00 -1.79698507e+01
 -7.53552802e+00]
supnorm grad right now is: 22.486956145714828
Weights right now are: 
[ -2.78872003   3.26903523  -2.04957046   3.1583107    3.04328874
  -3.37772692   2.44850773  -3.87433908  -1.57744924  -9.40950289
  -2.56954008   7.34976015   2.91115106  26.96241497  53.76581244
   9.10710479  63.53355601 -70.00535551 -67.16985194  16.44034838
  63.18531469  -0.81250864  -0.26452176  -0.39311671  -4.07933672
   1.67582201   4.11338933 -13.49244659 -54.88434358  34.48037096
  50.20112807  18.59840385 -22.68627558  32.56618159  67.38279682
  15.15971034 -26.04617133 -16.91698308  18.99649906  41.28276982
  29.84833058   8.40973502 123.62206248   8.05135891  -3.24847807
  68.11715097  -2.49408008  56.22688578  -2.58938506   2.94290685
   0.60085121   2.17926292   1.86829482 138.71453635  -4.28544995
 136.24779695   9.62034724   3.92029117   0.33719316  -2.71619742
   8.38098224   1.7424328    1.07782281  -2.71934774  28.08907954]
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2133.547955794321
gradient value of function right now is: [-8.25069272e-01 -9.26351128e-01 -3.35914280e-01 -4.87378797e-01
  8.25069272e-01  9.26351128e-01  3.35914280e-01  4.87378797e-01
  1.21150121e-01  7.12824587e-02  3.98189382e-02  6.76383928e-02
  2.13215550e-01  9.19471308e-05 -6.28425350e-05  8.95154809e-02
 -1.67878460e-02  3.31360149e-03  2.55323454e-03  4.61598211e-04
  4.07565656e-02  9.33105691e-12 -6.55558484e-15  1.56162624e-01
 -6.78217626e-02 -5.91320996e-01 -1.26364205e+00  5.28076489e-02
 -1.33988758e-04 -1.84794997e-06  2.28596988e-02 -5.59155323e-09
  2.91276170e-07 -1.24028575e-13  4.52730623e-03 -2.45992990e-16
  2.05298761e-03  1.06783768e-01  6.49957169e-02  6.71523798e-03
 -2.81902395e-03 -1.53221003e-02 -6.14832087e-04 -6.82312913e-03
  1.93636310e-01  4.48072789e-03 -3.41774573e-02  2.29306274e-03
  6.59968328e-02 -5.26920559e-01 -3.05715549e-02 -5.36431298e-01
  1.12819409e-01 -5.91166098e-03  1.30466495e-01 -4.16082383e-03
  3.90916416e-01 -6.90286753e-01  1.28241740e-01 -6.57159450e-01
  5.07266691e-01 -1.73639835e+00  1.63956075e-01 -5.65623826e-01
  6.66183048e-01]
supnorm grad right now is: 1.7363983464273027
Weights right now are: 
[ -2.87880891   3.06044923  -2.22524131   3.35759675   3.13337762
  -3.16914092   2.62417858  -4.07362514  -1.39957944  -9.41132552
  -1.57743103   7.36810111   2.42561381  26.30485597  54.38147506
   8.72526414  65.37805699 -73.93707383 -71.22202527  18.03958402
  65.94302326  -0.81249667  -0.26452176  -0.25195238  -3.37294385
   1.536341     4.13017872 -13.78831552 -56.66623814  34.04227855
  49.01907099  18.59095471 -22.718344    32.56618162  68.25918474
  15.15971033 -25.24543237 -17.11334264  18.83613161  42.10064167
  27.83540328   7.99074735 130.84462182   7.84299401  -2.96933407
  68.77090678  -3.35529663  55.64072931  -2.50236486   2.61072683
   0.55725953   1.64989261   2.04058578 141.6537603   -4.40840779
 139.57165485   9.21171289   4.51508235   0.30342492  -2.6950482
   8.40340337   1.51140601   1.44556261  -2.66265088  28.05302247]
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -2130.833892435857
gradient value of function right now is: [ 2.01085178e+00  1.03225544e+00  3.86396756e-01  3.03444353e-01
 -2.01085178e+00 -1.03225544e+00 -3.86396756e-01 -3.03444353e-01
  1.59415992e+00  1.75931335e-01  9.35503429e-02  6.06972410e-01
 -4.49352115e-01 -3.17622633e-03 -4.46421275e-04 -5.69170200e-02
  1.45591766e-02  2.41107302e-03  1.83238038e-03 -9.26276819e-03
 -1.63496668e-02 -8.23409216e-12 -6.89506599e-14  2.42332603e-02
  1.14820336e-01 -2.58283740e+00 -1.30322766e-01 -6.75803186e-01
  5.74007248e-04  1.42217293e-07  6.93888544e-02  1.92585435e-10
  4.86573237e-05  9.29809446e-14  7.20895838e-03  1.50214621e-16
 -3.05608577e-03  2.29762103e-01 -2.20639558e-02  2.93982558e-02
  6.78673252e-03  3.18047370e-02  1.22760259e-03  1.98451503e-02
 -8.99456374e-01 -3.40250752e-02 -2.52488525e-01 -2.81831563e-02
 -4.36009005e-03 -1.11326391e+00  4.04110535e-01 -9.28741414e-01
 -8.55900271e+00 -6.13066284e-02 -5.50218827e+00 -6.08880436e-02
 -1.66072247e+00  3.23979683e+00  3.06890137e+00 -1.80986077e+01
 -3.19416006e+00  1.55086603e+01  2.47068180e+00 -1.64660144e+01
 -1.23005200e+01]
supnorm grad right now is: 18.09860767022602
Weights right now are: 
[-3.02746329e+00  2.93424502e+00 -1.77699177e+00  3.45865132e+00
  3.28203200e+00 -3.04293671e+00  2.17592904e+00 -4.17467971e+00
 -1.55096200e+00 -9.58859323e+00 -1.08658465e+00  7.60183346e+00
  2.67250864e+00  2.46835670e+01  5.63308091e+01  9.07564463e+00
  6.91692909e+01 -7.79221432e+01 -7.53253834e+01  1.73372588e+01
  6.68344787e+01 -8.12474544e-01 -2.64521758e-01 -6.82256996e-01
 -3.60039968e+00  1.79390714e+00  4.29152549e+00 -1.38301416e+01
 -5.51044402e+01  3.56770087e+01  4.91594370e+01  1.85538343e+01
 -2.36328400e+01  3.25661818e+01  6.87317795e+01  1.51597103e+01
 -2.45723296e+01 -1.65997334e+01  1.91824923e+01  4.40398407e+01
  2.89963538e+01  7.06387559e+00  1.34654449e+02  7.12067979e+00
 -2.72261263e+00  6.85107432e+01 -2.82836323e+00  5.47674366e+01
 -2.32626668e+00  2.92057906e+00  6.86897832e-01  1.92726794e+00
  2.06103402e+00  1.45338991e+02 -4.31971951e+00  1.43286618e+02
  9.05243769e+00  4.26851372e+00  8.79432113e-02 -2.68343142e+00
  8.25006612e+00  1.80047832e+00  7.33788028e-01 -2.63401916e+00
  2.77863619e+01]
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -2132.280422813522
gradient value of function right now is: [ 1.22436211e+00  5.93728681e-01 -3.88892402e-01 -6.71730813e-01
 -1.22436211e+00 -5.93728681e-01  3.88892402e-01  6.71730813e-01
  1.06738455e+00 -4.31785216e-02 -2.80136817e-02 -1.27476842e-01
 -9.56065992e-01 -1.13920058e-03 -6.89807257e-05  6.61033499e-02
 -1.96661969e-02 -1.20613415e-03 -9.09945072e-04 -2.71673367e-02
  3.45897122e-02 -4.97653315e-12 -1.78758352e-16  2.46273163e-01
  5.78182996e-02  3.11444328e-01  3.58746075e-01  3.25087546e-01
  8.03233507e-04  3.53450069e-06 -5.17342268e-03  1.67635488e-08
  3.92165749e-05  2.87277778e-13 -2.09934789e-03  1.14748098e-15
 -2.05745549e-03  3.60659691e-01  3.18351429e-01  1.66221133e-02
  3.63492282e-03  1.39975030e-02  4.00905491e-04  1.09345686e-02
  4.99107042e-01  5.26848922e-03  1.04268878e-01  5.02922987e-03
 -1.00689820e+00  2.24052676e-01 -3.68680090e-01  2.24799157e-01
  2.26910827e+00  2.10732264e-03  1.55780836e+00  2.86889182e-03
 -3.30997790e-02 -1.03104036e-01  6.00879055e-02  1.19354141e+00
  9.84193495e-01 -5.51416889e+00  3.38370292e-02  1.31422827e+00
 -1.91963393e+00]
supnorm grad right now is: 5.5141688894508745
Weights right now are: 
[-2.84706722e+00  3.07119986e+00 -2.26271143e+00  3.20340157e+00
  3.10163593e+00 -3.17989155e+00  2.66164870e+00 -3.91942996e+00
 -1.37459131e+00 -1.07055385e+01 -2.41980622e+00  7.86993633e+00
  2.21597178e+00  2.37444976e+01  5.52568913e+01  9.02004893e+00
  7.19902494e+01 -7.93484470e+01 -7.67855584e+01  1.76220852e+01
  6.91344839e+01 -8.12375353e-01 -2.64521766e-01 -7.85894075e-02
 -3.30347546e+00  1.78753235e+00  4.25202834e+00 -1.37527977e+01
 -5.59720184e+01  3.47143725e+01  4.92934277e+01  1.84833318e+01
 -2.65711661e+01  3.25661819e+01  7.03909374e+01  1.51597103e+01
 -2.27919419e+01 -1.64287507e+01  1.92816058e+01  4.58410697e+01
  2.99198620e+01  7.37322283e+00  1.38389421e+02  7.09817874e+00
 -2.80342501e+00  6.91272533e+01 -2.52354485e+00  5.54728102e+01
 -2.08724067e+00  3.23542924e+00  7.44383154e-01  2.48836533e+00
  2.17223206e+00  1.48785015e+02 -4.04594390e+00  1.46606694e+02
  9.16708980e+00  4.07466707e+00  4.83128204e-01 -2.69446099e+00
  8.56243261e+00  1.58970252e+00  8.37496984e-01 -2.64652980e+00
  2.77479145e+01]
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2126.976274369436
gradient value of function right now is: [ 8.73143154e+00  6.62750062e+00  7.26201768e-01  7.97638999e-01
 -8.73143154e+00 -6.62750062e+00 -7.26201768e-01 -7.97638999e-01
  3.19992520e+00  3.16884592e-02  6.13443793e-03  3.35545672e-01
 -2.71305285e+00 -4.95923763e-03 -5.25077155e-04 -1.05939689e-01
  7.05897529e-02 -2.04963316e-04 -1.50751607e-04 -1.95393605e-02
 -1.14802046e-01 -3.94774045e-12 -6.37522159e-15 -5.37403731e-02
  1.75130970e-01  1.26276875e+00  5.80376463e+00  2.67770438e-01
  1.09972596e-03  1.24238043e-05  3.83107816e-02  4.62583583e-08
  4.31347759e-05  1.05058888e-12  3.35961782e-03  2.64192277e-15
  5.61469570e-03  2.44614080e-01  1.06181814e-01  3.31558706e-02
  1.62184300e-02  7.27222133e-02  1.98513509e-03  5.88010588e-02
 -1.20095768e+00 -3.98575542e-02 -4.40166646e-01 -3.76830013e-02
 -3.38971124e+00 -1.30234466e+00 -1.75225219e+00 -1.16867295e+00
  8.39985901e-01 -1.64799697e-02 -4.23120697e-01 -1.75265602e-02
 -1.75988592e+00  3.66541266e+00  1.79991567e+00 -8.12320266e+00
  5.70452983e-01 -2.46899487e+00  1.32710608e+00 -7.16906862e+00
 -1.55073447e+01]
supnorm grad right now is: 15.50734465388193
Weights right now are: 
[ -2.72956101   3.24818881  -2.16371229   3.08490499   2.98412972
  -3.3568805    2.56264956  -3.80093337  -1.39366371 -11.13383935
  -1.90774929   7.28610805   2.30908541  24.02318921  57.56515737
   9.46991086  75.6061247  -81.31428077 -78.86181363  17.83688274
  70.66582456  -0.8123442   -0.26452177  -0.24257966  -3.80324154
   2.0343133    4.2383244  -13.92225761 -55.63766011  31.98875067
  48.21255105  18.45092267 -32.12129131  32.56618177  71.69589908
  15.15971033 -21.54886403 -16.83096301  19.04365741  45.65519276
  22.13498273   8.1925422  135.83605414   7.62134323  -3.20163971
  68.46820652  -3.28227198  54.91595612  -2.42894969   2.97772587
   0.24943868   2.3503576    2.27406757 151.73925011  -4.10181932
 149.39913301   9.73440191   4.35852786   0.21823093  -2.69720849
   8.88079744   1.62778111   0.53170556  -2.66001918  27.45683145]
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2130.5161455622433
gradient value of function right now is: [ 7.83102120e+00  5.28320182e+00  4.01350416e-01  3.77365795e-01
 -7.83102120e+00 -5.28320182e+00 -4.01350416e-01 -3.77365795e-01
  4.36582940e+00  1.41896047e-01  5.57607312e-02  7.08082767e-01
 -3.27938568e+00 -6.64721187e-03 -5.46433896e-04 -2.24039512e-01
  3.80051591e-02  1.31460891e-03  9.58992784e-04 -2.18791428e-02
 -6.57427741e-02 -3.67905963e-11 -1.63083862e-14  3.30544447e-02
  2.49138282e-01 -2.07774862e+00  3.60984053e+00 -3.92215402e-01
  1.43179450e-03  3.26991168e-05  8.29303100e-02  1.64490016e-07
  1.33515761e-05  1.95007731e-12  4.40305744e-03  5.78094744e-15
  4.67457151e-03  3.53037377e-01  1.75482209e-01  3.47191580e-02
  9.25469882e-03  1.02409471e-01  3.25210671e-03  8.11123847e-02
 -3.81961715e-01 -2.34689209e-02 -1.98261148e-01 -2.22929870e-02
 -2.45230972e+00 -2.80776157e+00 -1.56551272e+00 -2.49282199e+00
 -5.93398581e+00 -4.09258430e-02 -3.28481169e+00 -4.03595708e-02
 -6.69765059e-01  1.20238583e+00  3.75585613e+00 -1.32123077e+01
 -2.04515960e+00  9.60068637e+00  3.01027431e+00 -1.21348402e+01
 -1.67180855e+01]
supnorm grad right now is: 16.718085505931022
Weights right now are: 
[-2.86252139e+00  3.15149209e+00 -2.17974534e+00  3.51146454e+00
  3.11709011e+00 -3.26018378e+00  2.57868261e+00 -4.22749293e+00
 -1.39502036e+00 -1.08727500e+01 -3.79878003e-01  7.48566016e+00
  2.01227765e+00  2.32276895e+01  6.02483971e+01  9.03883961e+00
  8.00754136e+01 -8.26013676e+01 -8.02734606e+01  1.69059931e+01
  7.14176805e+01 -8.12332522e-01 -2.64521766e-01 -8.83035646e-01
 -3.65351640e+00  1.69380273e+00  4.45403781e+00 -1.43746117e+01
 -5.71522050e+01  2.85063253e+01  4.79574686e+01  1.83450914e+01
 -3.73029761e+01  3.25661815e+01  7.38753689e+01  1.51597103e+01
 -2.17344241e+01 -1.71825944e+01  1.90256165e+01  4.61873701e+01
  2.15845659e+01  8.30204951e+00  1.42220716e+02  7.67899035e+00
 -2.67890752e+00  6.80733617e+01 -2.80203337e+00  5.46848595e+01
 -2.28594437e+00  2.65962787e+00 -5.35016670e-03  2.12625628e+00
  2.09899487e+00  1.54392469e+02 -4.08501522e+00  1.51994055e+02
  1.01969099e+01  4.40554513e+00  3.30326616e-01 -2.71439402e+00
  8.26671929e+00  1.58223705e+00  6.68415206e-01 -2.67938119e+00
  2.77268196e+01]
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2128.9492678995953
gradient value of function right now is: [ 2.00377553e-01 -4.66902873e-01 -5.60705551e-01 -8.83546135e-01
 -2.00377553e-01  4.66902873e-01  5.60705551e-01  8.83546135e-01
  1.16003436e+00  6.79519315e-02  1.97391548e-02  3.43207352e-01
 -3.29865573e-01 -4.93418030e-03 -2.96588432e-04 -3.44751286e-03
 -1.57264289e-02  2.80869950e-04  2.03726941e-04 -5.45908923e-02
  2.95559723e-02 -3.57821428e-11 -2.44776209e-15  1.32573899e-01
  1.57221439e-01 -3.66903560e+00 -1.46199465e+00 -8.15237369e-01
  2.49130165e-03  2.54142860e-06  5.05700463e-02  5.25835675e-09
  8.35509281e-05  2.90157307e-13  1.54352730e-03  3.59733637e-16
 -7.25832775e-03  7.52410082e-01  5.08261461e-01  5.47514842e-02
  7.47871225e-03  3.35930414e-02  2.27425941e-03  1.74311149e-02
  4.90122849e-02 -8.67134776e-03  3.46263038e-01 -3.77272175e-03
 -5.61835053e-01 -5.81077649e-01 -4.06219131e-01 -3.89693183e-01
 -1.08646811e+01 -9.30637873e-02 -6.94864942e+00 -8.35889237e-02
 -1.00649144e+00  1.95734280e+00  3.46873659e+00 -2.47603849e+01
 -3.79978094e+00  1.91210716e+01  2.70536154e+00 -2.11361262e+01
 -9.97744800e+00]
supnorm grad right now is: 24.7603849043435
Weights right now are: 
[-2.98371548e+00  2.98811733e+00 -2.15258965e+00  3.17623569e+00
  3.23828419e+00 -3.09680902e+00  2.55152692e+00 -3.89226407e+00
 -1.47304912e+00 -1.08838812e+01  6.04435095e-01  7.30286661e+00
  2.43437012e+00  2.06513934e+01  6.43631063e+01  9.87907679e+00
  8.36289051e+01 -8.32935525e+01 -8.11827862e+01  1.76149463e+01
  7.34148047e+01 -8.12323594e-01 -2.64521765e-01 -1.67075293e-01
 -3.28913922e+00  1.81468833e+00  4.67472703e+00 -1.37168501e+01
 -5.30725110e+01  2.91410727e+01  4.82170869e+01  1.83396036e+01
 -3.62655289e+01  3.25661815e+01  7.66321087e+01  1.51597103e+01
 -2.39393233e+01 -1.64608186e+01  1.88498780e+01  4.82812541e+01
  1.85944158e+01  6.65137335e+00  1.46846157e+02  6.27741218e+00
 -2.76317608e+00  6.90155911e+01 -2.82312378e+00  5.56453277e+01
 -2.14411158e+00  2.98195767e+00  8.19538826e-02  2.45212925e+00
  2.02043780e+00  1.57047523e+02 -4.78245095e+00  1.54604063e+02
  1.03772329e+01  4.84875270e+00  3.92884798e-02 -2.73762735e+00
  7.85997694e+00  1.65088563e+00  8.67694022e-01 -2.72773514e+00
  2.79035476e+01]
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2129.3739100584285
gradient value of function right now is: [-3.14494655e+00 -2.68478890e+00 -3.58368399e-01 -5.27858175e-01
  3.14494655e+00  2.68478890e+00  3.58368399e-01  5.27858175e-01
 -6.68205652e-01 -2.45592169e-02 -1.51552995e-02 -7.57678866e-02
  7.29238181e-01 -1.00326764e-03 -8.97754342e-05  6.44117364e-02
 -3.61697008e-02 -7.08154147e-04 -5.12733871e-04 -1.79588620e-02
  7.34155329e-02 -1.36558228e-11  2.92552911e-16  2.55981545e-02
  8.64844317e-02 -3.99664164e+00 -3.90017044e+00 -7.66326447e-01
  2.02976068e-03  8.25428971e-06  6.25677776e-04  4.47626516e-08
  6.35522718e-05  1.40572388e-12  3.14336587e-04  3.68917467e-15
 -2.27985643e-03  2.27108681e-01  1.61955938e-01  2.60711837e-02
  3.93132780e-03  2.36702218e-02  1.70578280e-03  1.48045650e-02
  2.10965445e-01 -3.71588622e-03 -3.46940879e-02 -4.19320290e-03
  2.83454341e+00  3.84725696e-01  1.47636876e+00  3.83926095e-01
 -8.75471124e+00 -6.06234799e-02 -4.70880921e+00 -5.81625283e-02
  5.29530904e-01 -1.54857746e+00  2.07074750e+00 -1.62632387e+01
 -3.19492651e+00  1.56512309e+01  1.80144819e+00 -1.52619182e+01
 -1.02279843e+00]
supnorm grad right now is: 16.263238729516516
Weights right now are: 
[-2.92545675e+00  3.15378765e+00 -2.23329069e+00  3.37897066e+00
  3.18002546e+00 -3.26247934e+00  2.63222796e+00 -4.09499904e+00
 -1.57057271e+00 -1.07728439e+01  8.68085693e-01  7.24514159e+00
  2.57048905e+00  2.04916377e+01  6.78467309e+01  9.36390916e+00
  8.47731171e+01 -8.57030999e+01 -8.36602814e+01  1.84938082e+01
  7.62867527e+01 -8.10626618e-01 -2.64521766e-01 -1.17529647e+00
 -3.20833924e+00  1.71233724e+00  4.54545630e+00 -1.35113092e+01
 -5.55845793e+01  2.01095364e+01  4.77229395e+01  1.81514068e+01
 -4.24999885e+01  3.25661809e+01  7.61633827e+01  1.51597103e+01
 -2.22794558e+01 -1.64187726e+01  1.90290457e+01  4.77076541e+01
  1.42470647e+01  6.08921527e+00  1.50198801e+02  6.34090126e+00
 -2.18047486e+00  6.83019965e+01 -3.71811403e+00  5.45397952e+01
 -1.70857858e+00  3.21384014e+00  2.17196802e-01  2.48698941e+00
  1.99716098e+00  1.60072629e+02 -4.71798076e+00  1.57741509e+02
  1.07075104e+01  4.56329433e+00  1.31035333e-02 -2.73984006e+00
  7.68886584e+00  1.57678477e+00  6.57805470e-01 -2.67596208e+00
  2.79528660e+01]
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2129.3541639008545
gradient value of function right now is: [ 7.39658257e+00  5.90142681e+00  1.26921991e+00  1.80547769e+00
 -7.39658257e+00 -5.90142681e+00 -1.26921991e+00 -1.80547769e+00
  2.12242359e+00  2.43841711e-01  1.30068862e-01  7.22449056e-01
 -1.19681231e+00 -1.13908532e-03 -1.58889554e-04 -1.58986143e-01
  7.66909430e-02  7.79779971e-03  5.98229966e-03  4.86477712e-02
 -1.48733864e-01 -1.06813164e-11 -7.18784544e-16 -2.17562420e-01
  3.85737609e-02  3.25453712e+00  6.51853791e+00  4.50908927e-01
  1.97240432e-04  1.41457785e-05  7.28515498e-02  1.97666285e-07
  9.91616317e-06  1.97955216e-12  4.54062409e-03  6.86227321e-14
 -4.26529782e-03 -4.00189158e-01 -5.37108745e-01 -1.33208486e-02
  3.24795534e-03  3.41033874e-02  3.54562301e-04  1.62515491e-02
 -1.97930231e+00 -5.21083013e-02 -7.32005912e-01 -3.94741854e-02
 -3.88314214e+00 -2.29306503e+00 -1.81550624e+00 -1.93843419e+00
  5.07442943e+00  2.71491333e-02  2.13428608e+00  2.12091918e-02
 -1.18793341e+00  2.66917998e+00  4.80523653e-01  2.78254156e+00
  1.49028826e+00 -7.09865587e+00  1.57458714e-01  3.12504178e+00
 -9.58537752e+00]
supnorm grad right now is: 9.585377518902508
Weights right now are: 
[ -2.82635024   3.15514407  -1.84584836   3.16812854   3.08091895
  -3.26383576   2.24478563  -3.88415692  -1.36636771 -10.25460913
   0.562637     7.65476339   2.73710698  23.61790882  75.95929239
   9.94013041  89.70447833 -87.21133111 -85.29236433  19.98593243
  76.92278891  -0.81041124  -0.26452177  -0.18375583  -3.10855645
   2.00320059   4.60803199 -13.61478905 -54.34992349  15.65082443
  49.02707129  17.68896508 -48.36436366  32.56617599  75.50193105
  15.15971028 -21.05261646 -16.93248517  18.6476906   47.52628789
  15.87891259   6.08402467 154.28535064   6.13100531  -2.48447856
  68.66743181  -3.43705704  54.37648271  -1.89857548   2.72642202
   0.25106038   1.80752436   2.18156199 163.56297358  -4.67883262
 161.32802952  10.60929608   5.15662494   0.40645187  -2.71468068
   8.08620566   1.54204033   1.5398205   -2.66390294  27.84333418]
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2132.381536043699
gradient value of function right now is: [-3.57050942e+00 -2.44564413e+00 -7.98929270e-02  2.81298804e-01
  3.57050942e+00  2.44564413e+00  7.98929270e-02 -2.81298804e-01
 -1.85335119e+00 -1.14447126e-01 -5.43783650e-02 -1.66195429e-01
  1.30675467e+00  2.83783952e-03  2.52674276e-04 -1.60094625e-01
 -1.46311992e-02 -1.23355001e-03 -9.26418894e-04  2.47361487e-02
  2.51619588e-03  1.56730822e-12  6.81394777e-16 -9.44170674e-02
 -5.78279511e-02  2.55125836e+00 -4.52460336e-01  3.19698413e-01
 -1.38545981e-04  6.78975790e-08 -4.88251297e-02  1.61232540e-10
 -9.35575412e-06 -6.53672202e-13 -3.47643607e-03  3.18504242e-15
  5.16349915e-05 -3.43816872e-01 -1.84033006e-01 -1.95885806e-02
 -1.88127059e-03 -2.70056070e-02 -1.32504286e-03 -9.46975805e-03
 -3.62457021e-01 -1.98269638e-03 -3.06460376e-01 -3.42046130e-03
  6.11825316e-01  1.63942165e+00  2.50612338e-02  1.07530222e+00
  4.33300943e+00  4.40262512e-02  3.04005956e+00  2.99535751e-02
  7.12421787e-01 -1.45631233e+00 -2.66977811e+00  1.30181277e+01
  1.26459828e+00 -6.58813113e+00 -1.65023346e+00  8.32993691e+00
  6.89414504e+00]
supnorm grad right now is: 13.018127666441584
Weights right now are: 
[-2.85369014e+00  3.14411676e+00 -2.22113458e+00  3.16082351e+00
  3.10825885e+00 -3.25280845e+00  2.62007185e+00 -3.87685189e+00
 -1.52229765e+00 -1.10262139e+01 -4.78741138e-01  7.72126388e+00
  2.50354987e+00  2.37532873e+01  7.91513643e+01  8.68250919e+00
  9.09240370e+01 -9.25103840e+01 -9.06152873e+01  2.00339353e+01
  7.95465311e+01 -8.10259422e-01 -2.64521764e-01 -4.82658790e-02
 -3.47669133e+00  1.67671331e+00  4.58069550e+00 -1.30857495e+01
 -5.41411085e+01  9.05527631e+00  4.95867903e+01  1.71765498e+01
 -5.32941797e+01  3.25659851e+01  7.50110644e+01  1.51597093e+01
 -2.08986805e+01 -1.62720208e+01  1.88108771e+01  4.90367343e+01
  1.22560209e+01  7.59589953e+00  1.56035683e+02  7.86416976e+00
 -2.73040836e+00  6.89977328e+01 -3.48174552e+00  5.34844228e+01
 -1.54543222e+00  2.68424890e+00  3.00391174e-01  2.45819530e+00
  2.32538767e+00  1.66385575e+02 -4.64947553e+00  1.64121826e+02
  1.09060721e+01  4.68047270e+00 -2.28350403e-01 -2.63309816e+00
  7.86857760e+00  1.62802608e+00  1.21270353e+00 -2.69363000e+00
  2.77953150e+01]
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2126.05042527334
gradient value of function right now is: [ 1.19985709e+01  7.80288857e+00  2.57216394e-01  6.42585533e-01
 -1.19985709e+01 -7.80288857e+00 -2.57216394e-01 -6.42585533e-01
  7.43241935e+00  3.79018818e-01  1.66311722e-01  1.93608197e+00
 -5.08930791e+00 -1.57470343e-02 -1.48075723e-03 -7.26767512e-01
  2.70571497e-02  2.30653108e-03  1.66973538e-03  4.50027351e-02
 -4.75657925e-02 -1.34512884e-10 -5.12673256e-15 -2.11906649e-01
  4.01063483e-01  2.94633213e-01  5.10918582e+00 -1.67343734e-01
  2.47479255e-03  2.83748713e-06  1.87681743e-01  1.43710865e-09
  1.63754114e-04  1.03480854e-10  9.58518196e-03  2.13180343e-14
 -4.20408825e-03 -5.16764258e-01 -1.01420263e+00 -3.80796891e-03
  1.37301647e-02  8.73038183e-02  3.18735510e-03  4.64620665e-02
 -2.48803154e+00 -5.03912125e-02 -5.63386126e-01 -3.84420069e-02
 -5.94070487e-01 -3.73129606e+00 -4.60451310e-01 -2.73367219e+00
 -1.70058264e+00 -3.63821080e-03 -9.82680499e-01 -5.87253207e-03
 -1.56507278e+00  2.82757060e+00  4.57945207e+00 -7.18741912e+00
 -1.57649395e+00  6.23150368e+00  2.77575208e+00 -4.98150090e+00
 -2.03335341e+01]
supnorm grad right now is: 20.333534091161958
Weights right now are: 
[ -2.71766232   3.16118767  -2.8238242    3.1128893    2.97223103
  -3.26987936   3.22276147  -3.82891768  -1.09124826 -10.57257121
   0.54057599   8.20211095   2.28111219  21.50837984  78.01709254
   8.23613943  92.30286189 -98.28531883 -96.46563435  19.19265722
  81.73445557  -0.81028379  -0.26452176  -0.49177345  -2.07773437
   1.71988411   4.54021475 -13.79589049 -55.2062964   10.66422721
  49.80483786  16.57124118 -55.91755908  32.56623027  74.73483873
  15.15970994 -21.93307823 -16.60229458  18.8201231   46.76948267
  14.46802943   7.08961362 158.83559535   7.51932529  -2.41642134
  67.23527899  -2.58785344  52.09938126  -1.57323717   2.98526406
   0.53241465   2.18306482   2.00378909 170.13220123  -4.69815204
 167.78246077   9.97247743   5.23055936   0.18824634  -2.70301604
   7.72137848   1.45615918   1.09670817  -2.60068512  27.65719221]
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2127.4264510989715
gradient value of function right now is: [-1.17508061e+01 -7.74564559e+00 -8.54803752e-01 -2.78594148e-01
  1.17508061e+01  7.74564559e+00  8.54803752e-01  2.78594148e-01
 -6.36517989e+00 -3.40321712e-01 -1.40012778e-01 -1.27082148e+00
  3.80341068e+00  1.24552958e-02  1.21094251e-03  5.65832130e-02
 -5.47823009e-02 -3.21091726e-03 -2.28485550e-03  8.47223890e-02
  7.84051226e-02  8.09561705e-12  1.68124016e-15 -4.31394684e-01
 -3.71373569e-01  3.57245303e+00 -5.21201826e+00  6.35037012e-01
 -4.28460588e-03 -6.39298642e-06 -1.81643201e-01 -4.40113306e-09
 -2.40493835e-04 -1.10144827e-09 -7.68656916e-03 -2.04265135e-13
  2.81652915e-03 -1.53246162e+00 -9.14410805e-01 -9.28994972e-02
 -1.54045846e-02 -1.80313092e-01 -8.10030147e-03 -1.35285895e-01
  9.69691613e-02  5.47453105e-02 -5.47378046e-01  4.81279613e-02
  6.02790426e+00  3.82896932e+00  3.17389363e+00  3.30998298e+00
  1.13418332e+01  1.18710258e-01  7.96991303e+00  1.13589733e-01
  1.80488125e+00 -3.52216876e+00 -9.20665591e+00  4.17824315e+01
  4.17587096e+00 -1.90961363e+01 -7.02817090e+00  3.72318837e+01
  3.05844388e+01]
supnorm grad right now is: 41.782431529238394
Weights right now are: 
[-3.03245928e+00  3.03906596e+00 -2.44499573e+00  3.62426522e+00
  3.28702799e+00 -3.14775765e+00  2.84393300e+00 -4.34029361e+00
 -1.75503874e+00 -1.09050740e+01  9.22804434e-01  7.49221101e+00
  2.46064116e+00  2.08669595e+01  7.85590606e+01  9.66307972e+00
  9.44562206e+01 -1.02299339e+02 -1.00559302e+02  1.86298378e+01
  8.28589610e+01 -8.10198703e-01 -2.64521763e-01 -9.93095843e-01
 -3.93939794e+00  1.81188734e+00  4.55542617e+00 -1.41430771e+01
 -5.91272299e+01  4.32124079e+00  4.89046762e+01  1.70806035e+01
 -6.75168412e+01  3.25639088e+01  7.40427029e+01  1.51597128e+01
 -2.04693542e+01 -1.65175820e+01  1.88644299e+01  4.74288949e+01
  1.11949244e+01  6.51410872e+00  1.61108284e+02  6.43768388e+00
 -2.18445859e+00  6.82680863e+01 -2.48944338e+00  5.25332143e+01
 -1.73604156e+00  3.14673081e+00  9.77949820e-02  2.27251784e+00
  2.05967555e+00  1.72960218e+02 -4.85048656e+00  1.70624032e+02
  1.06410243e+01  4.76432354e+00  1.96133372e-01 -2.57404523e+00
  7.72222402e+00  1.65873058e+00  6.28351577e-01 -2.54824392e+00
  2.79424565e+01]
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2129.8827100383937
gradient value of function right now is: [ 1.03181865e+00  1.85393319e+00  5.93763869e-01  5.24265842e-01
 -1.03181865e+00 -1.85393319e+00 -5.93763869e-01 -5.24265842e-01
 -1.15860243e+00 -1.11560059e-01 -4.03235009e-02 -5.38940647e-01
  4.29191274e-01  2.08887059e-03  1.91966165e-04  1.42967646e-01
  4.04703200e-02 -6.47848672e-04 -4.65446527e-04 -3.64033175e-02
 -8.91576652e-02 -1.35529041e-11  7.29815784e-16  8.71579136e-02
 -3.98196006e-02  9.64264053e-01  2.74801498e+00  1.12602776e-01
 -2.35489045e-03  3.24973820e-06 -6.02073851e-02  8.11873925e-09
 -6.37453399e-05  9.00615528e-10 -2.24268163e-03  8.91907740e-13
  3.14922801e-03  4.49814815e-01  5.16450496e-01  1.91672762e-02
  2.17317376e-03 -6.36752954e-02 -6.77186989e-04 -4.07231076e-02
 -1.74053584e-01 -1.30945063e-02 -2.72208320e-02 -1.16892233e-02
 -3.27929493e+00  8.88503467e-01 -1.75511913e+00  6.33420079e-01
  4.03400065e-01 -1.01375453e-02 -6.77704815e-01 -1.20555416e-02
 -4.31865947e-01  1.37716477e+00 -1.35603950e+00 -3.10756291e+00
  7.10978059e-01 -1.11372385e+00 -7.54349361e-01 -3.49862230e+00
  1.99398816e+00]
supnorm grad right now is: 3.49862229724886
Weights right now are: 
[-2.94874633e+00  3.21501835e+00 -1.91651581e+00  3.56672192e+00
  3.20331504e+00 -3.32371004e+00  2.31545308e+00 -4.28275031e+00
 -1.81171559e+00 -1.16396765e+01 -1.97034695e-01  7.11231907e+00
  2.74794197e+00  1.91081888e+01  8.23808758e+01  1.04061063e+01
  9.71416593e+01 -1.02768622e+02 -1.01053456e+02  1.92795778e+01
  8.46628832e+01 -8.09924792e-01 -2.64521706e-01 -5.37067294e-01
 -3.20360419e+00  1.78690806e+00  4.76702440e+00 -1.35740920e+01
 -6.01385205e+01  2.37692367e-01  4.95465977e+01  1.38802855e+01
 -7.73553799e+01  3.25054464e+01  7.57847635e+01  1.51597410e+01
 -1.92381470e+01 -1.61174625e+01  1.88250573e+01  4.81096627e+01
  1.21646815e+01  6.15489793e+00  1.65454945e+02  5.78427791e+00
 -2.20519301e+00  6.66165860e+01 -3.13942480e+00  5.04678848e+01
 -2.07427419e+00  3.44534084e+00 -1.55707290e-01  2.54073947e+00
  2.19502325e+00  1.76184294e+02 -4.95533496e+00  1.73877319e+02
  1.03633556e+01  4.61550053e+00 -2.67635900e-01 -2.82298388e+00
  7.76411988e+00  1.56060552e+00  4.89425078e-01 -2.79783082e+00
  2.79220423e+01]
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2130.9579527554197
gradient value of function right now is: [-6.19510294e+00 -4.73518193e+00 -4.99447101e-01 -9.70354822e-01
  6.19510294e+00  4.73518193e+00  4.99447101e-01  9.70354822e-01
 -2.20347341e+00 -9.17867645e-02 -3.77632659e-02 -5.75704345e-01
  1.53193757e+00  3.03485736e-03  2.76592712e-04  1.79026701e-01
 -4.87102344e-02 -7.04759894e-04 -5.10125174e-04 -1.77937438e-02
  9.30254790e-02 -2.43416380e-11  1.06539689e-13  6.95342965e-01
 -8.53552765e-02 -2.39174451e+00 -4.75365724e+00 -2.11337356e-01
 -1.43421494e-03  2.34422971e-06 -4.93132968e-02  7.29195785e-08
 -7.33231825e-05 -1.25395183e-07 -1.83831394e-03  9.55408279e-11
 -5.37421346e-03  3.21716228e-01  3.77134175e-01  8.56933818e-03
 -4.14039027e-03 -3.72386004e-02 -1.44638721e-03 -2.28573780e-02
  1.20956763e+00  3.03345230e-02  4.09569952e-01  2.45893483e-02
  2.65215521e+00  1.51637845e+00  1.41485074e+00  1.24620734e+00
 -2.37082020e+00 -1.92122812e-02 -1.17652528e+00 -1.63135049e-02
  9.58262879e-01 -2.20560161e+00 -6.82094881e-01 -2.41923716e+00
 -3.40949732e-01  3.09987427e+00 -2.32069865e-01 -2.76933777e+00
  1.00815306e+01]
supnorm grad right now is: 10.081530621380853
Weights right now are: 
[  -2.92325221    3.18655129   -2.59031808    3.20052911    3.17782092
   -3.29524298    2.98925535   -3.9165575    -1.67466828  -11.45359304
    0.8835996     6.93874604    2.37347891   18.57474809   86.30753229
    9.7259012    99.66672816 -106.05049607 -104.42657412   18.70880526
   86.54961519   -0.80977313   -0.26452166   -0.20483589   -2.14996483
    1.68657746    4.52427032  -13.00064161  -55.62643473    6.07817961
   50.1295738    14.72944132  -79.99132689   33.15492868   75.45714658
   15.16063118  -21.49794306  -16.22639032   18.40492549   49.82541202
   10.11571635    5.90585573  168.31712494    5.19212773   -2.28400069
   66.2653127    -3.39266819   50.88517694   -1.75517094    2.89463375
    0.49382586    1.93172791    2.13226592  179.09659864   -5.04964694
  176.49959707   10.34263566    4.53931257    0.22083247   -2.77736849
    8.02514351    1.52808048    0.96907492   -2.75051343   28.10719129]
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2131.4846089818025
gradient value of function right now is: [ 4.16162697e+00  1.77682446e+00  5.74562788e-02  2.57814603e-01
 -4.16162697e+00 -1.77682446e+00 -5.74562788e-02 -2.57814603e-01
  4.06502309e+00  4.94482774e-01  2.52085805e-01  1.64174268e+00
 -1.87510300e+00 -6.32606214e-03 -7.35790667e-04 -3.76134509e-01
  2.29516190e-02  1.75212722e-02  1.25909379e-02  4.27971373e-02
  1.06196635e-03 -3.30685330e-10 -4.57412100e-13 -2.86239729e-01
  2.48169572e-01  5.12325006e-01  1.40275764e+00 -1.14084305e-01
  1.82135137e-03  2.54901127e-05  1.86453081e-01  5.61376902e-08
  5.03931382e-05  1.34242114e-07  1.16316186e-02  4.96470903e-11
  4.36510509e-03 -2.99853349e-01 -5.66592793e-01 -8.83665679e-03
  6.59188610e-03  9.53029085e-02  2.09855557e-03  5.85726563e-02
 -9.91620037e-01 -1.49997534e-02 -5.00672803e-01 -1.30085033e-02
  9.66767851e-01 -5.43624055e+00  3.87867370e-01 -4.88636935e+00
 -6.00347560e-01  9.05984945e-03  9.15973489e-02  9.08586427e-03
 -3.87740216e-01  7.11300372e-01  1.73871351e+00  1.29593278e+00
 -1.13516703e+00  3.84921390e+00  8.97413140e-01  1.83287064e+00
 -8.28972533e+00]
supnorm grad right now is: 8.289725329246226
Weights right now are: 
[  -2.83372203    3.07627062   -1.97180944    3.47071149    3.08829074
   -3.18496231    2.37074671   -4.18673987   -1.1042397   -11.46875768
    1.79490535    7.78715962    2.2627183    14.75954915   88.48133402
    9.15104858  103.44148634 -107.17499902 -105.64787619   17.08158663
   87.02352513   -0.80939412   -0.26452123   -0.70813192   -2.30372037
    1.73519429    4.73874174  -12.80939744  -54.95035299   -3.9712437
   49.84516784   14.08454723  -80.53110083   32.85112803   76.7989837
   15.16002581  -19.73520564  -16.32559429   18.091695     49.05914028
   11.85609963    6.1121427   173.16285635    5.67816712   -1.94419753
   66.25325841   -2.68097366   51.10304978   -1.54814815    2.61697168
    0.36697229    1.58153746    2.04231676  182.33670811   -5.07029336
  179.55305086   10.3630211     4.95505778    0.35999665   -2.72164895
    7.92339633    1.60853943    1.0833681    -2.64223092   27.94337591]
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2130.916292711395
gradient value of function right now is: [-1.26370516e+00 -1.40991240e+00 -3.24948096e-02  4.26875913e-01
  1.26370516e+00  1.40991240e+00  3.24948096e-02 -4.26875913e-01
  1.68041143e-01  2.26287028e-02  5.52502198e-03  3.85477027e-01
  2.04846253e-01 -1.07929515e-03 -1.07653895e-04 -1.97331242e-01
 -1.02929121e-02  2.82136023e-04  2.05630439e-04  1.80314510e-02
  1.12205250e-02 -4.66680311e-11 -1.17470184e-14 -7.14892220e-01
  1.66769178e-01 -8.58144589e-01 -9.17774323e-01 -5.00564132e-01
  1.26711150e-03  2.11897247e-05  1.89683351e-02  2.38681482e-07
  6.84292183e-05  8.35765548e-08  9.31389537e-04  4.61370185e-11
 -3.95969475e-03 -5.23052645e-01 -5.74572659e-01 -3.53305523e-04
  4.67972831e-03  3.10345254e-02  1.78900523e-03  1.75950310e-02
 -1.75832687e+00 -4.12585067e-02 -7.65060768e-01 -3.21452188e-02
  3.41150286e+00  2.28845926e-02  1.88324040e+00  9.84077440e-02
 -4.90135504e+00 -1.55115391e-02 -2.22891505e+00 -1.27355620e-02
 -2.29409547e-01  4.45035038e-01  1.95694842e+00 -8.87586612e+00
 -2.91366182e+00  1.24918264e+01  1.28720642e+00 -6.29985382e+00
 -3.59722546e+00]
supnorm grad right now is: 12.491826388945745
Weights right now are: 
[  -2.99626905    3.03890392   -2.25682621    3.37766381    3.25083776
   -3.14759561    2.65576348   -4.09369219   -1.62530806  -12.15728597
    0.73308579    7.65264535    2.71038379   14.64858466   94.37868859
    9.48292017  105.78427582 -109.49859853 -108.08364362   18.33710322
   89.05846014   -0.8091173    -0.2645208    -0.73856273   -2.64353559
    1.6504927     4.51217877  -13.11898226  -52.76827384  -12.03372053
   50.46580634   10.70395404  -77.84982159   33.56022156   75.94355429
   15.15812355  -18.21446471  -16.24466555   18.09854852   47.47276308
    8.81761618    6.13399943  175.63913103    6.10371224   -2.54650891
   66.58457064   -2.74124482   50.97573787   -1.59121261    2.91785071
    0.32514242    2.25672875    2.1867474   185.02110698   -4.87671975
  182.05886278   10.78693615    4.81477779    0.35114023   -2.75210685
    7.77731932    1.61176869    1.10715696   -2.74428444   27.9200542 ]
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2132.9685043896893
gradient value of function right now is: [ 4.15063315e+00  2.90282436e+00  1.94735683e-01  2.18336955e-01
 -4.15063315e+00 -2.90282436e+00 -1.94735683e-01 -2.18336955e-01
  1.88105463e+00  1.56132096e-01  9.07006239e-02  4.14494670e-01
 -1.29288286e+00 -1.04704566e-03 -1.52228416e-04 -6.90489653e-02
  2.52571610e-02  7.16467752e-03  5.31671823e-03  2.45801780e-02
 -2.88440154e-02 -1.38237770e-11  4.40981014e-15  8.90663527e-02
  4.42617470e-02  5.59370445e-01  2.23604459e+00  1.37661899e-01
  3.22721695e-04  6.82240352e-05  5.85206292e-02  1.24379504e-06
 -7.78388221e-05 -2.33792423e-06  5.30855033e-03  6.55881348e-10
 -6.48528693e-03 -9.22241315e-02 -1.79302512e-01  3.64463425e-04
 -4.01515525e-04  7.65791784e-02  2.54782957e-04  6.05025909e-02
 -6.36572859e-01 -1.57153967e-02 -3.01613372e-01 -1.43602809e-02
 -1.45123152e+00 -2.51025051e+00 -7.94588834e-01 -2.36079533e+00
  1.22878844e+00  2.25553109e-03  4.70477744e-01  2.04435493e-03
 -1.96187456e-01  4.76399037e-01  9.28302529e-01 -6.43677645e-01
  6.65816165e-01 -2.83518003e+00  5.02214307e-01 -2.35822555e-01
 -5.99231513e+00]
supnorm grad right now is: 5.992315133988511
Weights right now are: 
[-2.87204200e+00  3.10602992e+00 -2.45329279e+00  3.48746187e+00
  3.12661071e+00 -3.21472161e+00  2.85223006e+00 -4.20349025e+00
 -1.54730523e+00 -1.14641039e+01  1.96172773e+00  7.35186052e+00
  2.09532141e+00  1.72763311e+01  1.01776337e+02  9.35925935e+00
  1.07425033e+02 -1.13890857e+02 -1.12501360e+02  1.85218877e+01
  8.99369267e+01 -8.09092819e-01 -2.64520662e-01 -1.51514704e-01
 -3.39947688e+00  1.78866038e+00  4.66562723e+00 -1.31886636e+01
 -5.08638840e+01 -1.25419876e+01  4.93213094e+01  1.03301830e+01
 -7.55904114e+01  3.32838204e+01  7.15922843e+01  1.51584946e+01
 -1.95268198e+01 -1.64924290e+01  1.86086151e+01  4.81223157e+01
  8.51897911e+00  4.82525303e+00  1.79154814e+02  4.79349922e+00
 -2.32290669e+00  6.61502890e+01 -2.53731441e+00  5.11127198e+01
 -1.74657479e+00  2.51933350e+00  3.73687555e-01  1.67231239e+00
  2.08575871e+00  1.87854072e+02 -4.89994330e+00  1.84657703e+02
  1.02752938e+01  4.81288558e+00  5.42672591e-01 -2.77115769e+00
  7.98719041e+00  1.43444707e+00  9.38708116e-01 -2.75498301e+00
  2.79600058e+01]
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2130.9946568271516
gradient value of function right now is: [-8.06092341e+00 -5.35525061e+00 -4.80918276e-01  1.40987922e-02
  8.06092341e+00  5.35525061e+00  4.80918276e-01 -1.40987922e-02
 -4.09344069e+00 -1.85987492e-01 -8.86334726e-02 -7.47098319e-01
  2.41976876e+00  4.62276573e-03  5.67650491e-04  4.87944260e-02
 -3.02791491e-02 -1.11462922e-03 -8.38663220e-04  1.63066537e-02
  3.18887770e-02 -9.69927344e-10  6.21456452e-13 -7.59832759e-01
 -4.00636343e-01  4.89547062e+00 -2.28832170e+00  8.42165145e-01
 -6.03022572e-03 -1.38215544e-05 -1.06210045e-01 -1.11477722e-07
 -8.20234038e-04 -1.03625359e-06 -7.06289771e-03 -1.25702471e-10
  2.26985717e-02 -8.13974967e-01 -3.43387707e-01 -4.98755356e-02
 -8.52637474e-03 -5.46526919e-02 -3.92462937e-03 -4.30574241e-02
 -4.64232555e-02  2.69697936e-02 -8.27712829e-01  2.25237680e-02
  2.68067180e+00  2.62628043e+00  1.38365847e+00  2.32632089e+00
  1.07316241e+01  7.38019346e-02  6.99229770e+00  7.18148930e-02
  1.26889341e+00 -2.54127443e+00 -5.50963100e+00  2.73007336e+01
  3.95774965e+00 -2.00621791e+01 -4.36191839e+00  2.49255943e+01
  1.92896464e+01]
supnorm grad right now is: 27.300733603538475
Weights right now are: 
[  -2.94935503    3.08815579   -2.17093561    3.46063928    3.20392374
   -3.19684748    2.56987288   -4.17666767   -1.6493658   -12.49474004
    0.27484588    7.66827571    2.89572399   18.94026125  105.43426168
    9.96227481  110.18240034 -115.47748388 -114.13725058   17.62005356
   91.44286103   -0.80886713   -0.26451988   -0.83534755   -2.25015458
    1.70707423    4.67695694  -12.65222037  -49.2429167   -19.5462966
   50.28574223    9.89038851  -75.65202072   36.64060206   71.63637868
   15.1588558   -19.16305124  -16.48754132   18.40951637   48.66443233
    8.37641001    5.16420502  184.24752057    4.92617275   -1.80811966
   65.72640159   -2.76507642   50.98309619   -1.69225032    2.9325181
    0.3561649     2.22994178    2.44030329  190.50563268   -4.84026814
  187.201431     10.58588988    4.90948394    0.50809686   -2.69705256
    7.71261537    1.49785202    0.90020846   -2.67238301   27.802904  ]
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2128.7482240752765
gradient value of function right now is: [ 6.17676281e+00  3.27421334e+00  2.33504685e-02 -1.84500126e-02
 -6.17676281e+00 -3.27421334e+00 -2.33504685e-02  1.84500126e-02
  5.03924502e+00  4.51657057e-01  2.40018208e-01  1.78503988e+00
 -2.12078884e+00 -6.44853954e-03 -9.60338235e-04 -3.06017185e-01
  1.42031846e-02  4.33126616e-03  3.26733030e-03 -1.01422302e-02
 -1.65811000e-02 -4.15242520e-10 -7.71561009e-14  1.76460857e-02
  4.47672463e-01 -2.74480829e+00  1.69971444e+00 -7.40926376e-01
  7.38934457e-03  6.90598355e-05  1.98687862e-01  1.28195957e-06
  8.57726648e-04  1.61634317e-06  3.62026306e-04  2.81831569e-10
 -2.59082675e-02  3.15321417e-01 -2.15861204e-01  3.62143521e-02
  2.34968591e-02  1.34766546e-01  4.76494972e-03  7.27456443e-02
 -7.25539716e-01 -3.07760052e-02 -1.86537884e-02 -1.93024233e-02
 -1.06803755e+00 -3.70045382e+00 -6.08851235e-01 -2.92583280e+00
 -8.74961816e+00 -6.20544064e-02 -4.95619935e+00 -4.98803889e-02
 -1.26831894e+00  2.53626337e+00  4.80858639e+00 -2.31020531e+01
 -4.09551083e+00  1.92651299e+01  3.30156150e+00 -1.68529377e+01
 -2.10411699e+01]
supnorm grad right now is: 23.10205308969525
Weights right now are: 
[-2.94605786e+00  2.98074024e+00 -2.36373868e+00  3.47174287e+00
  3.20062657e+00 -3.08943193e+00  2.76267595e+00 -4.18777125e+00
 -1.28819891e+00 -1.15732045e+01  2.16016343e+00  7.63128033e+00
  2.41732294e+00  1.64752101e+01  1.06798290e+02  9.84035345e+00
  1.12025990e+02 -1.20249254e+02 -1.19184593e+02  1.88752082e+01
  9.30543586e+01 -8.49323549e-01 -2.64518280e-01 -2.12840819e-01
 -2.80087134e+00  1.77481030e+00  4.68275086e+00 -1.28172254e+01
 -5.04349680e+01 -2.23903400e+01  5.06619777e+01  1.19591622e+01
 -7.43863203e+01  4.07192865e+01  7.10686056e+01  1.51632820e+01
 -1.86641688e+01 -1.61485189e+01  1.84632675e+01  4.93131790e+01
  3.65355170e+00  4.89487095e+00  1.85388547e+02  5.10702508e+00
 -2.30480929e+00  6.48673838e+01 -2.88422582e+00  5.05205254e+01
 -1.94789445e+00  2.60736624e+00 -7.57354084e-02  2.04945486e+00
  1.97187872e+00  1.93547720e+02 -5.24162622e+00  1.89941659e+02
  1.03683604e+01  4.93935475e+00  2.49102958e-01 -2.65576536e+00
  7.76857141e+00  1.42284085e+00  1.19875157e+00 -2.69177581e+00
  2.75798295e+01]
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2133.3219592873297
gradient value of function right now is: [-1.29367112e+00 -9.27496388e-01 -7.40902730e-02  1.70739062e-02
  1.29367112e+00  9.27496388e-01  7.40902730e-02 -1.70739062e-02
 -5.46870791e-01  3.83168034e-02  2.12008618e-02  1.18310178e-01
  6.26222201e-01  6.89868574e-04  4.47267206e-05 -6.17914787e-02
 -8.97018922e-03 -6.78601736e-04 -5.02834372e-04  1.91670953e-02
  7.65261538e-03 -1.09085706e-09  7.41922632e-17  6.46337860e-03
 -3.48903461e-02 -8.61348530e-02 -7.86215725e-01 -1.76927087e-01
  1.13889196e-04  1.68607496e-05  8.99648491e-03  1.19574132e-06
 -3.66909389e-07 -1.08525735e-08 -3.05033147e-03  1.22955713e-12
 -3.44763133e-04 -1.56710553e-01 -1.43743320e-01 -7.20385847e-03
  9.76361186e-03 -2.11177948e-02 -3.01771794e-04 -1.00463924e-02
 -2.79747891e-01 -1.99119543e-03 -1.76722947e-01 -1.85298736e-03
  8.22001318e-01  3.05589591e-01  1.29768821e-01  1.96128474e-01
 -1.04319833e+00  6.63975767e-03 -6.43175196e-02  4.98559735e-03
  7.23981157e-02 -1.27120061e-01 -5.66105815e-01  1.72917673e+00
 -7.33653696e-01  3.17307613e+00 -3.33377775e-01  1.32019469e+00
  1.60858578e+00]
supnorm grad right now is: 3.17307612988584
Weights right now are: 
[-2.80522386e+00  3.18909665e+00 -2.47467105e+00  3.33303389e+00
  3.05979257e+00 -3.29778834e+00  2.87360832e+00 -4.04906227e+00
 -1.74895777e+00 -1.17315408e+01  3.17766306e+00  8.01252024e+00
  2.87242832e+00  1.61511474e+01  1.06841593e+02  9.22928522e+00
  1.13837962e+02 -1.20744325e+02 -1.19912215e+02  1.84775175e+01
  9.51976276e+01 -2.52221334e+00 -2.64517910e-01 -5.91210828e-01
 -4.29042775e+00  1.37338961e+00  4.88813020e+00 -1.21484822e+01
 -5.03837424e+01 -2.41312712e+01  4.99704161e+01  1.11799067e+01
 -7.46005095e+01  3.96016522e+01  7.30944835e+01  1.51627581e+01
 -1.73155304e+01 -1.57253158e+01  1.83396173e+01  5.04427016e+01
  1.22622578e+00  5.69464728e+00  1.86586934e+02  6.17707665e+00
 -2.44554502e+00  6.51385313e+01 -2.69855363e+00  5.04476809e+01
 -1.36923552e+00  2.58104899e+00  8.21143449e-02  2.07964006e+00
  1.79045164e+00  1.96421973e+02 -5.16820098e+00  1.92759226e+02
  1.05434827e+01  4.87327561e+00 -8.40575840e-02 -2.74777531e+00
  7.87121624e+00  1.59588757e+00  8.87951604e-01 -2.79536940e+00
  2.79920845e+01]
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2133.9536548454967
gradient value of function right now is: [ 5.90761755e-01  4.38334888e-01  5.72989808e-02  5.72151334e-02
 -5.90761755e-01 -4.38334888e-01 -5.72989808e-02 -5.72151334e-02
  1.93064086e-01 -9.66993744e-03 -8.48902413e-03  3.48503507e-02
 -3.37311266e-02 -7.08361555e-04 -7.67979160e-05 -1.34098310e-02
  2.14896144e-03 -2.94952807e-04 -2.18816491e-04  6.14424585e-03
 -5.74728862e-03  4.29945541e-10 -3.88330653e-17  3.48791352e-02
  3.51170485e-02 -1.33898235e-01  1.75394310e-01 -7.93984729e-02
  1.33101620e-03  4.07368643e-05  4.18618483e-03  2.14885117e-06
  1.52595010e-04  1.80593751e-08  8.67058385e-04  2.98143583e-11
 -5.96865819e-03 -2.07708072e-02 -7.12933304e-02  3.81294929e-03
  1.25651989e-02  4.59172677e-03  8.04700876e-04  2.12639896e-03
 -3.98576205e-01 -1.22538188e-02 -2.37335319e-01 -9.16282775e-03
 -1.21328996e-01  1.42239014e-01 -3.12611545e-02  1.40133409e-01
 -8.65735944e-01 -3.21193929e-03 -3.79930130e-01 -2.26059659e-03
 -1.88986375e-01  4.62893085e-01  2.82417841e-01 -2.18150733e+00
 -6.74194183e-01  3.14752099e+00  2.05631479e-01 -1.38805054e+00
 -1.99633883e+00]
supnorm grad right now is: 3.1475209924104384
Weights right now are: 
[  -2.8855884     3.09244196   -1.53572278    3.33842571    3.14015711
   -3.20113365    1.93466005   -4.05445409   -1.73252828  -13.32704773
    1.53145986    7.21809741    2.36185512   18.53280486  112.53154007
    9.87982728  116.91245639 -121.2718223  -120.71410953   19.23101841
   97.03036798   -3.69507064   -0.26451796   -0.28335806   -2.02064893
    1.43429714    4.64289045  -12.26930084  -47.94195144  -18.35452453
   50.63291664   16.03125076  -73.85112854   40.97194351   73.58105978
   15.16281725  -18.18642137  -16.21227249   17.78395645   46.95863169
   -1.4849484     5.22728929  188.7548398     5.95186562   -1.83983085
   63.96186982   -2.82170517   49.8276592    -1.7886032     2.79708705
    0.61763047    2.3481061     2.11305716  199.74916639   -5.32498602
  195.55462628   11.15408309    4.63703175   -0.30830559   -2.6398064
    7.54507655    2.02620222    1.07839121   -2.83101771   28.09576567]
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2133.852941151322
gradient value of function right now is: [ 9.64923325e-01  6.78858173e-01  5.10661700e-02  2.49177586e-02
 -9.64923325e-01 -6.78858173e-01 -5.10661700e-02 -2.49177586e-02
  3.95013933e-01 -2.98099165e-03 -5.95816419e-03  6.57540383e-02
 -1.78107953e-01 -7.29570592e-04 -8.61980411e-05 -1.64413976e-02
  3.22461866e-03  1.59822576e-04  1.16492078e-04  3.62335994e-03
 -6.10790149e-03 -9.81807733e-12 -1.32278284e-16  5.61045602e-02
  7.17818866e-02 -3.74787235e-01  3.09287223e-01 -1.22809800e-01
  8.34043856e-04  1.71891680e-05  7.99910538e-03  7.21622705e-07
  9.11124751e-05  3.54073813e-08  1.23235409e-03  1.81695295e-11
 -2.32909341e-03  3.22122703e-02 -2.95421582e-02  6.91005060e-03
  1.73688923e-02  1.96996406e-02  1.45196094e-03  7.21985664e-03
 -3.40196223e-01 -1.28013219e-02 -2.13958229e-01 -9.52201378e-03
 -3.13579746e-01 -5.12172239e-02 -1.10214015e-01  6.07146047e-03
 -1.40072806e+00 -7.75862907e-03 -7.35917249e-01 -5.58654020e-03
 -2.51992592e-01  5.95878035e-01  5.62735361e-01 -3.72778233e+00
 -9.54534348e-01  4.27529408e+00  3.87902862e-01 -2.46851305e+00
 -3.03984959e+00]
supnorm grad right now is: 4.27529407573401
Weights right now are: 
[-2.88358727e+00  3.11505859e+00 -2.26687444e+00  3.08959780e+00
  3.13815598e+00 -3.22375028e+00  2.66581171e+00 -3.80562619e+00
 -1.73864710e+00 -1.23698435e+01  3.19293316e+00  7.52208116e+00
  2.76332644e+00  2.06306751e+01  1.16699509e+02  9.77518347e+00
  1.18809942e+02 -1.22770690e+02 -1.22578710e+02  1.90069811e+01
  9.90588509e+01 -2.03528111e+00 -2.64517902e-01 -5.02616940e-01
 -2.87254188e+00  1.60106578e+00  4.50231611e+00 -1.17094080e+01
 -4.81561996e+01 -1.71835549e+01  5.06738383e+01  1.80595223e+01
 -7.71819777e+01  4.08541017e+01  7.13796194e+01  1.51623090e+01
 -1.54468033e+01 -1.62715666e+01  1.79444485e+01  4.84337759e+01
 -1.79057160e+00  5.70610021e+00  1.91739562e+02  7.25833948e+00
 -2.16238856e+00  6.22461118e+01 -2.58319539e+00  4.99049495e+01
 -1.80417120e+00  2.66138280e+00  8.11495502e-02  2.46685615e+00
  1.95045953e+00  2.03195420e+02 -5.00129024e+00  1.98764987e+02
  9.82324394e+00  4.93768918e+00 -6.07925758e-01 -2.85780293e+00
  7.70536117e+00  1.47580408e+00  1.52056944e+00 -2.70420075e+00
  2.81133232e+01]
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2133.838330247304
gradient value of function right now is: [ 8.25313542e-01  5.91225498e-01  5.08211357e-02  2.56301828e-02
 -8.25313542e-01 -5.91225498e-01 -5.08211357e-02 -2.56301828e-02
  3.23757952e-01 -1.20582005e-02 -1.13277780e-02  4.24181397e-02
 -1.36696192e-01 -6.94101401e-04 -8.49368866e-05 -1.57370289e-02
  2.13762661e-03 -3.41689041e-04 -2.53817862e-04  3.71909413e-03
 -5.62344338e-03 -3.05956491e-11 -2.43548878e-16  5.98538146e-02
  6.78584937e-02 -3.02189388e-01  2.65079537e-01 -1.01978824e-01
  9.27306342e-04  2.02915148e-05  4.35634510e-03  8.21942830e-07
  1.17280914e-04  7.39356268e-08  9.62948930e-04  3.09586474e-11
 -2.77428996e-03  3.04937183e-02 -2.67276420e-02  6.40818986e-03
  1.87661617e-02  1.61592038e-02  1.33281283e-03  5.81186812e-03
 -3.41317148e-01 -1.25252090e-02 -2.12901709e-01 -9.31500065e-03
 -2.86285164e-01  9.32574601e-02 -9.78405238e-02  1.13651132e-01
 -1.20970976e+00 -6.64961267e-03 -6.15146067e-01 -4.69364470e-03
 -2.28349349e-01  5.54348481e-01  4.68343332e-01 -3.34463909e+00
 -8.61484409e-01  3.86009070e+00  3.06203441e-01 -2.19646201e+00
 -2.74648605e+00]
supnorm grad right now is: 3.8600906968222763
Weights right now are: 
[-2.75050195e+00  3.15485002e+00 -2.36844169e+00  3.38588930e+00
  3.00507066e+00 -3.26354171e+00  2.76737896e+00 -4.10191768e+00
 -1.27319439e+00 -1.13482001e+01  4.54252131e+00  8.03122223e+00
  2.44496225e+00  1.90142675e+01  1.18459070e+02  9.53804608e+00
  1.22084541e+02 -1.25968558e+02 -1.26168790e+02  1.86705594e+01
  9.86705556e+01 -2.63325588e+00 -2.64517831e-01 -6.42664872e-01
 -3.32867216e+00  1.67196989e+00  4.81082585e+00 -1.15253963e+01
 -4.96018138e+01 -1.73309615e+01  5.15291387e+01  1.63429781e+01
 -7.71867975e+01  4.50632769e+01  6.96842301e+01  1.51662304e+01
 -1.29950723e+01 -1.60790598e+01  1.78808971e+01  4.99980843e+01
 -7.75444711e-01  4.97130591e+00  1.93363673e+02  7.08074221e+00
 -2.11891290e+00  6.20218360e+01 -2.85604801e+00  4.94716201e+01
 -1.96875003e+00  2.92432728e+00  2.28229997e-01  2.75026807e+00
  2.22766085e+00  2.06462326e+02 -5.31566875e+00  2.01740435e+02
  9.80762168e+00  4.91518213e+00  8.24801605e-02 -2.69444289e+00
  7.83522903e+00  1.72134792e+00  1.07125232e+00 -2.84168260e+00
  2.78185677e+01]
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2133.851083058187
gradient value of function right now is: [ 7.95067089e-01  5.79709051e-01  4.92521863e-02  3.53902951e-02
 -7.95067089e-01 -5.79709051e-01 -4.92521863e-02 -3.53902951e-02
  2.94599750e-01 -1.52611051e-02 -1.28708390e-02  3.08787007e-02
 -1.33066059e-01 -7.09558940e-04 -9.11798950e-05 -1.56455028e-02
  1.45504456e-03 -7.52603926e-04 -5.67680677e-04  3.42506761e-03
 -5.90706037e-03 -2.94920750e-11 -3.34223740e-16  4.76009992e-02
  6.91935691e-02 -2.31686035e-01  2.96584570e-01 -8.54667601e-02
  1.06624843e-03  2.97671160e-05  2.29255414e-03  1.13823736e-06
  1.65103853e-04  1.69193991e-07  7.65406086e-04  6.49854669e-11
 -3.55247428e-03  1.13962174e-02 -3.98934128e-02  5.49823002e-03
  1.99703453e-02  1.75004187e-02  1.26938706e-03  7.51573899e-03
 -3.58387911e-01 -1.26345593e-02 -2.29862546e-01 -9.72087080e-03
 -2.59328551e-01  1.57513449e-01 -6.36733797e-02  1.66657095e-01
 -1.03722748e+00 -5.35720554e-03 -5.07744832e-01 -3.87107592e-03
 -2.19323444e-01  5.36011219e-01  4.06776279e-01 -2.95369239e+00
 -7.76437843e-01  3.47442627e+00  2.60147297e-01 -1.99388005e+00
 -2.60330194e+00]
supnorm grad right now is: 3.474426273423528
Weights right now are: 
[  -2.9913293     3.14599963   -2.34794865    3.53665856    3.24589801
   -3.25469132    2.74688592   -4.25268694   -1.37819661  -12.61836821
    3.01933417    7.77728116    1.90180785   18.42499099  119.71056555
    7.29044076  122.39972791 -130.95704641 -131.1712032    18.85369987
  101.07886091   -2.63297423   -0.26451781   -0.44320465   -3.15389252
    1.47955142    4.79101768  -12.01389984  -47.07224345  -12.12615205
   51.11103388   17.39957356  -72.9925956    49.31564783   71.13292577
   15.17612802  -10.85334191  -15.62577286   18.10325507   50.73815241
   -1.60775878    4.78312456  195.87851503    6.21034275   -1.93155009
   62.49725185   -2.322072     50.43511431   -1.64911122    2.5698945
    0.3388235     2.45995094    2.23629064  209.42357721   -5.57864998
  204.68209066    9.95346372    4.64674446    0.6692329    -2.86282182
    7.84326141    1.49934433    0.90208206   -2.8671254    27.85786641]
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2133.859227727214
gradient value of function right now is: [ 8.62602125e-01  6.54340510e-01  6.70386914e-02  5.76847022e-02
 -8.62602125e-01 -6.54340510e-01 -6.70386914e-02 -5.76847022e-02
  2.81303890e-01 -1.48945713e-02 -1.21874457e-02  2.15556890e-02
 -1.38967410e-01 -5.61018753e-04 -7.20426046e-05 -1.29849163e-02
  2.34233860e-03 -6.86460633e-04 -5.20006146e-04  4.00919304e-03
 -7.46632214e-03 -2.04310659e-11 -2.11220880e-16  4.68426542e-02
  7.48245781e-02 -2.03459814e-01  3.63991798e-01 -8.75216347e-02
  9.20625626e-04  2.48254057e-05  1.35891564e-03  8.76421618e-07
  1.41359476e-04  1.42668663e-07  6.13290545e-04  4.54592288e-11
 -2.90111319e-03 -1.05730841e-03 -4.68857810e-02  4.86579170e-03
  2.54508696e-02  1.85804591e-02  1.42197716e-03  8.85733500e-03
 -3.98274870e-01 -1.32959052e-02 -2.40580306e-01 -1.04325714e-02
 -2.81866500e-01  1.35312008e-01 -7.48482635e-02  1.48172461e-01
 -1.01917394e+00 -4.78671360e-03 -4.88015831e-01 -3.59420752e-03
 -2.39936831e-01  5.80675317e-01  4.10264552e-01 -2.83944104e+00
 -8.25003823e-01  3.60059867e+00  2.67610778e-01 -1.96925019e+00
 -2.72142767e+00]
supnorm grad right now is: 3.600598670083466
Weights right now are: 
[-2.99087860e+00  3.12511766e+00 -1.94362827e+00  3.50441887e+00
  3.24544731e+00 -3.23380935e+00  2.34256554e+00 -4.22044725e+00
 -1.80984955e+00 -1.35906866e+01  1.59496220e+00  6.73565515e+00
  2.85150650e+00  1.93183640e+01  1.20653731e+02  9.73808853e+00
  1.24890929e+02 -1.28885577e+02 -1.29768695e+02  2.30672054e+01
  1.04209981e+02 -3.16768026e+00 -2.58983347e-01 -1.03196488e+00
 -3.45662008e+00  1.92761403e+00  4.29680302e+00 -1.05198990e+01
 -4.32994996e+01 -1.10862961e+01  5.18497411e+01  1.82995488e+01
 -6.90156390e+01  5.23661262e+01  7.61562336e+01  1.51768581e+01
 -1.37237166e+01 -1.57696206e+01  1.74447108e+01  5.06616920e+01
 -4.87974534e+00  6.97132032e+00  1.96951483e+02  8.44338432e+00
 -1.17228411e+00  6.11313267e+01 -4.01516703e+00  4.96949197e+01
 -2.09373935e+00  2.14556855e+00 -2.86543381e-03  2.51993515e+00
  2.55998766e+00  2.12006589e+02 -5.81855804e+00  2.07103832e+02
  9.69953104e+00  4.78857516e+00  9.11348009e-02 -2.80040370e+00
  8.18253704e+00  1.77887740e+00  1.04070616e+00 -2.83247575e+00
  2.79511633e+01]
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1448.953647461455
W_T_median: 1227.979666287103
W_T_pctile_5: 778.4951453252003
W_T_CVAR_5_pct: 684.9461662217342
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.0
F value: -2133.859227727214
-----------------------------------------------
