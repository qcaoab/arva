tracing parameter entered from terminal:  1.5


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2814.7635454260967
gradient value of function right now is: [ 5.61351619e-06  7.35733129e-07  5.61743428e-06  5.61859608e-06
 -5.61351714e-06 -7.35733253e-07 -5.61743523e-06 -5.61859704e-06
  9.30916760e-08  2.60679763e-08  1.40164626e-07  1.13100642e-07
  5.04332182e-07  9.75644793e-08  5.49181558e-07  5.57934088e-07
  4.64218155e-08  1.53711336e-08  8.12387143e-08  5.93650083e-08
  4.46540804e-08  1.33087075e-08  7.10871340e-08  5.52586266e-08
 -1.10397072e-08 -3.22872677e-08 -4.04913796e-08 -4.12698206e-09
  7.58105956e-09 -5.14099059e-09  1.42424182e-09  1.55601822e-09
  8.29803370e-08 -1.08442511e-07 -3.59379101e-08  1.46564384e-08
  1.00798836e-08 -4.77631141e-08 -3.85054006e-08  2.13045992e-10
 -1.02377552e-08  3.68597746e-08 -2.41293917e-08 -1.13687886e-08
  8.83332258e-09 -1.77123243e-08  1.72426087e-08  1.03225047e-08
 -6.12651458e-09  1.43472716e-08 -1.18014944e-08 -7.74469760e-09
 -4.40635843e-09  1.40852901e-08 -9.15050488e-09 -5.74443541e-09
  2.25070571e-10  4.78127203e-09  1.38314418e-08  2.61357948e-09
 -9.37215663e-09 -3.24176652e-09 -5.17768157e-09 -6.46853409e-09
 -3.91229255e+00]
supnorm grad right now is: 3.9122925468040055
Weights right now are: 
[-3.60617649e+00 -5.03619512e-01 -2.35450849e+00 -3.15819040e+00
  3.86074520e+00  3.94927822e-01  2.75344576e+00  2.44216202e+00
 -2.04389739e+00 -7.69179437e-01 -2.10409521e+00 -1.78860136e+00
  1.42895310e+00  3.46455078e-01 -1.24276495e-01  7.23175990e-01
 -1.45363456e+00 -4.95813260e-01 -2.46844920e+00 -2.15136608e+00
 -2.27277839e+00 -8.39139108e-01 -2.22965578e+00 -1.83925413e+00
 -8.59338552e-01 -4.92448806e-01 -1.47810102e+00 -7.18991343e-01
  4.15203734e-01  1.47322405e+00  1.52712809e+00  4.75394166e-01
 -1.65790265e+00  1.47633961e+00 -8.88871478e-01 -8.89795704e-01
 -2.62882940e+00 -5.09619815e-01 -9.46360188e-01 -7.48081860e-01
  1.51582680e-01 -1.74904778e+00  1.44300928e+00  1.02524241e+00
  1.96490721e-01  2.49386093e+00 -2.07905058e+00  2.00946080e-02
 -1.37601208e+00 -6.95571129e-01 -3.52591861e-01 -1.50439684e+00
  7.63746090e-01  1.13522597e+00  6.27149079e-01  1.78811696e+00
  1.32151631e+00  6.63383330e-01 -5.40558429e-01 -2.37767189e+00
  2.13642383e+00  2.24072818e+00 -9.06181979e-02  1.35584779e+00
  2.46894817e+01]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.3376711252363
gradient value of function right now is: [ 8.93616954e-08  1.60431536e-08  8.94305859e-08  8.94141388e-08
 -8.93616083e-08 -1.60431377e-08 -8.94304988e-08 -8.94140516e-08
  9.85338449e-10  4.42009889e-10  2.29761563e-09  1.41055546e-09
  1.28820079e-08  2.60433546e-09  1.45761888e-08  1.44091879e-08
  3.40290299e-10  2.74826372e-10  1.38715828e-09  6.42103988e-10
  4.50551805e-10  2.41009677e-10  1.23971094e-09  6.94337058e-10
 -6.58280427e-10 -9.17068983e-10 -1.44143314e-09 -2.01189589e-10
  1.61509588e-11 -1.70031381e-10 -1.50136157e-10 -4.70594661e-12
  1.80085197e-09 -3.30411236e-09 -1.75132790e-09  2.69224622e-10
  1.09627925e-10 -1.38991355e-09 -1.28604740e-09 -3.95256330e-11
 -4.15535066e-10  7.28022781e-10 -7.96494754e-10 -5.32181263e-10
  3.25999647e-10 -3.90768449e-10  5.78308706e-10  4.20784405e-10
 -2.15211089e-10  2.28399625e-10 -3.63645182e-10 -2.85760548e-10
 -1.55919685e-10  2.75186775e-10 -2.83075684e-10 -2.12469491e-10
 -8.56874714e-12  1.17781431e-10  2.61414503e-10  1.34395569e-10
 -1.53573460e-10 -1.85666738e-10 -9.48415820e-11 -1.91268635e-10
  8.19849075e-01]
supnorm grad right now is: 0.8198490753224255
Weights right now are: 
[-4.26474602e+00 -6.12372508e-01 -2.99994982e+00 -3.83280675e+00
  4.51931486e+00  5.03680840e-01  3.39888722e+00  3.11677851e+00
 -2.05779020e+00 -7.74142941e-01 -2.13327544e+00 -1.80543764e+00
  1.30645526e+00  3.23128595e-01 -2.69431524e-01  5.97624386e-01
 -1.46051693e+00 -4.99440804e-01 -2.48713815e+00 -2.16177783e+00
 -2.28045438e+00 -8.42335255e-01 -2.24633264e+00 -1.84983055e+00
 -8.54327306e-01 -4.82246681e-01 -1.46381862e+00 -7.17254619e-01
  4.14076455e-01  1.47504905e+00  1.52791409e+00  4.75201727e-01
 -1.67961919e+00  1.51388186e+00 -8.70144037e-01 -8.93156503e-01
 -2.63072346e+00 -4.93694770e-01 -9.32193006e-01 -7.47780926e-01
  1.56083255e-01 -1.75838616e+00  1.45201545e+00  1.03093017e+00
  1.92937603e-01  2.49854744e+00 -2.08546943e+00  1.55498578e-02
 -1.37364485e+00 -6.98924216e-01 -3.48419866e-01 -1.50124903e+00
  7.65463235e-01  1.13164173e+00  6.30379943e-01  1.79045791e+00
  1.32157660e+00  6.61904372e-01 -5.43880161e-01 -2.37912361e+00
  2.13839474e+00  2.24273676e+00 -8.94016900e-02  1.35804404e+00
  2.50405913e+01]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.2440658226583
gradient value of function right now is: [ 4.10874146e-08  7.73158629e-09  4.11202317e-08  4.11090438e-08
 -4.10870858e-08 -7.73152418e-09 -4.11199028e-08 -4.11087146e-08
  3.89337939e-10  2.05330153e-10  1.05761931e-09  5.96544361e-10
  6.38996271e-09  1.30524954e-09  7.29521571e-09  7.16578490e-09
  1.00001277e-10  1.28330808e-10  6.39381982e-10  2.49220936e-10
  1.68724688e-10  1.12812818e-10  5.74308502e-10  2.88791069e-10
 -3.52724303e-10 -4.65817516e-10 -7.47643263e-10 -1.06750190e-10
 -3.33473292e-12 -8.80746357e-11 -8.76275041e-11 -5.25776364e-12
  8.75517437e-10 -1.70955694e-09 -9.57084223e-10  1.25483823e-10
  4.51330997e-11 -7.12391766e-10 -6.69284783e-10 -2.30974772e-11
 -2.22442432e-10  3.49320881e-10 -4.16845543e-10 -2.88983384e-10
  1.73397657e-10 -1.89840346e-10  3.03660709e-10  2.26558286e-10
 -1.12886047e-10  1.05734222e-10 -1.88222126e-10 -1.50920314e-10
 -8.20681820e-11  1.32146761e-10 -1.46722686e-10 -1.12524666e-10
 -5.39817535e-12  5.93026482e-11  1.22932282e-10  7.43959078e-11
 -6.88852778e-11 -1.03610684e-10 -4.42789509e-11 -9.86910598e-11
  1.82368784e+00]
supnorm grad right now is: 1.8236878408416923
Weights right now are: 
[-4.38727814e+00 -6.34885783e-01 -3.12257353e+00 -3.95541424e+00
  4.64184698e+00  5.26194114e-01  3.52151092e+00  3.23938599e+00
 -2.05928605e+00 -7.74759025e-01 -2.13650585e+00 -1.80751148e+00
  1.28811785e+00  3.19457378e-01 -2.90029868e-01  5.77152424e-01
 -1.46110081e+00 -4.99828196e-01 -2.48911628e+00 -2.16277440e+00
 -2.28116298e+00 -8.42673546e-01 -2.24808981e+00 -1.85087211e+00
 -8.53390132e-01 -4.81021694e-01 -1.46184673e+00 -7.16972838e-01
  4.14065816e-01  1.47527394e+00  1.52812049e+00  4.75210421e-01
 -1.68216637e+00  1.51824382e+00 -8.67988196e-01 -8.93554105e-01
 -2.63088475e+00 -4.91843732e-01 -9.30496100e-01 -7.47732829e-01
  1.56609985e-01 -1.75940780e+00  1.45304777e+00  1.03158909e+00
  1.92519230e-01  2.49910237e+00 -2.08622298e+00  1.50207351e-02
 -1.37336410e+00 -6.99238194e-01 -3.47943100e-01 -1.50088150e+00
  7.65665560e-01  1.13126023e+00  6.30751465e-01  1.79073010e+00
  1.32158546e+00  6.61749283e-01 -5.44263466e-01 -2.37928234e+00
  2.13863560e+00  2.24295117e+00 -8.92617720e-02  1.35829617e+00
  2.51335364e+01]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.3611585956537
gradient value of function right now is: [ 2.79185056e-08  5.40139993e-09  2.79397091e-08  2.79345863e-08
 -2.79188104e-08 -5.40145900e-09 -2.79400140e-08 -2.79348915e-08
  3.19454650e-10  1.42593484e-10  7.44552958e-10  4.57231246e-10
  4.53379610e-09  9.12345014e-10  5.11621620e-09  5.06869013e-09
  1.13368951e-10  9.04810007e-11  4.59306355e-10  2.13153903e-10
  1.49115022e-10  7.90273556e-11  4.08568117e-10  2.29342636e-10
 -2.47697657e-10 -3.00469828e-10 -4.98448765e-10 -7.34855070e-11
 -5.48476801e-12 -5.60741982e-11 -5.82359224e-11 -4.12991536e-12
  6.16489664e-10 -1.08389249e-09 -5.51250339e-10  9.46653513e-11
  3.46016540e-11 -4.56934257e-10 -4.23664157e-10 -1.32182668e-11
 -1.33668707e-10  2.43249489e-10 -2.58406407e-10 -1.69692644e-10
  1.05990173e-10 -1.34089869e-10  1.89647496e-10  1.35760113e-10
 -7.03864025e-11  7.18699970e-11 -1.18388085e-10 -9.28394683e-11
 -5.07654691e-11  9.06407530e-11 -9.23614306e-11 -6.88053920e-11
 -2.81881694e-12  3.76219649e-11  9.00896076e-11  4.20947150e-11
 -5.42856107e-11 -5.80932757e-11 -3.27711534e-11 -6.27826511e-11
  2.19149081e-01]
supnorm grad right now is: 0.21914908122889157
Weights right now are: 
[-4.45611644e+00 -6.48016888e-01 -3.19146374e+00 -4.02429303e+00
  4.71068528e+00  5.39325218e-01  3.59040113e+00  3.30826478e+00
 -2.06009318e+00 -7.75109178e-01 -2.13833686e+00 -1.80865358e+00
  1.27718197e+00  3.17260569e-01 -3.02351558e-01  5.64932035e-01
 -1.46139829e+00 -5.00049914e-01 -2.49024414e+00 -2.16331351e+00
 -2.28154226e+00 -8.42867151e-01 -2.24909240e+00 -1.85144587e+00
 -8.52802837e-01 -4.80298158e-01 -1.46065388e+00 -7.16798090e-01
  4.14073905e-01  1.47540851e+00  1.52825606e+00  4.75219137e-01
 -1.68365996e+00  1.52084477e+00 -8.66678047e-01 -8.93784120e-01
 -2.63097123e+00 -4.90745926e-01 -9.29481161e-01 -7.47701747e-01
  1.56928306e-01 -1.75999951e+00  1.45366749e+00  1.03199553e+00
  1.92266508e-01  2.49942693e+00 -2.08667723e+00  1.46952203e-02
 -1.37319576e+00 -6.99414874e-01 -3.47658510e-01 -1.50065843e+00
  7.65786773e-01  1.13103956e+00  6.30973247e-01  1.79089521e+00
  1.32159251e+00  6.61657935e-01 -5.44479764e-01 -2.37938469e+00
  2.13876319e+00  2.24309393e+00 -8.91829079e-02  1.35844773e+00
  2.50258032e+01]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.3260657265155
gradient value of function right now is: [ 2.03326524e-08  4.01455066e-09  2.03485305e-08  2.03435804e-08
 -2.03324492e-08 -4.01451043e-09 -2.03483273e-08 -2.03433770e-08
  2.09194273e-10  1.03919017e-10  5.38992587e-10  3.12871980e-10
  3.40648266e-09  6.90772315e-10  3.86898329e-09  3.81526907e-09
  6.19917988e-11  6.59064795e-11  3.31438642e-10  1.37520200e-10
  9.41437388e-11  5.77069850e-11  2.96092325e-10  1.54766299e-10
 -1.93170170e-10 -2.32050702e-10 -3.86629341e-10 -5.72709629e-11
 -6.70395936e-12 -4.38410993e-11 -4.76214308e-11 -3.81524137e-12
  4.59460944e-10 -8.48302689e-10 -4.52323146e-10  6.84419567e-11
  2.33840409e-11 -3.55084309e-10 -3.32512510e-10 -1.11905882e-11
 -1.07522979e-10  1.80398975e-10 -2.04219980e-10 -1.38157231e-10
  8.47348088e-11 -9.98250347e-11  1.49967115e-10  1.09645773e-10
 -5.56168758e-11  5.25103062e-11 -9.27731724e-11 -7.38025153e-11
 -4.02547396e-11  6.74172127e-11 -7.24292057e-11 -5.48535425e-11
 -2.52472150e-12  2.90275276e-11  6.55881473e-11  3.48927347e-11
 -3.82960117e-11 -4.83976049e-11 -2.37466589e-11 -4.90342049e-11
  1.00585285e+00]
supnorm grad right now is: 1.0058528476764972
Weights right now are: 
[-4.50446110e+00 -6.57463559e-01 -3.23984488e+00 -4.07266574e+00
  4.75902993e+00  5.48771890e-01  3.63878228e+00  3.35663748e+00
 -2.06065806e+00 -7.75357402e-01 -2.13963528e+00 -1.80945733e+00
  1.26921034e+00  3.15659637e-01 -3.11333932e-01  5.56023219e-01
 -1.46160387e+00 -5.00207941e-01 -2.49104823e+00 -2.16369250e+00
 -2.28180801e+00 -8.43005035e-01 -2.24980669e+00 -1.85185097e+00
 -8.52365734e-01 -4.79778172e-01 -1.45978449e+00 -7.16668957e-01
  4.14085727e-01  1.47550540e+00  1.52835850e+00  4.75226819e-01
 -1.68474123e+00  1.52271625e+00 -8.65741878e-01 -8.93951952e-01
 -2.63103218e+00 -4.89955490e-01 -9.28749519e-01 -7.47679270e-01
  1.57157646e-01 -1.76042485e+00  1.45411212e+00  1.03228337e+00
  1.92084153e-01  2.49966242e+00 -2.08700413e+00  1.44639897e-02
 -1.37307439e+00 -6.99539533e-01 -3.47454505e-01 -1.50049946e+00
  7.65874260e-01  1.13088161e+00  6.31132526e-01  1.79101296e+00
  1.32159696e+00  6.61593336e-01 -5.44641106e-01 -2.37945482e+00
  2.13886297e+00  2.24319007e+00 -8.91242856e-02  1.35855575e+00
  2.50747304e+01]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2814.7988156041415
gradient value of function right now is: [ 1.80855567e-08  3.62351087e-09  1.80975415e-08  1.80983234e-08
 -1.80853772e-08 -3.62347494e-09 -1.80973619e-08 -1.80981437e-08
  2.96678944e-10  9.61759035e-11  5.17557809e-10  3.79159908e-10
  3.09878847e-09  6.01465266e-10  3.39855559e-09  3.43852449e-09
  1.49620873e-10  6.27629907e-11  3.31656654e-10  2.09616565e-10
  1.53194265e-10  5.40583891e-11  2.89054869e-10  2.01461517e-10
 -1.59759913e-10 -1.62857530e-10 -2.90531874e-10 -4.56138274e-11
 -5.35661116e-12 -2.89653236e-11 -3.16577784e-11 -2.69997373e-12
  4.18165392e-10 -5.50043079e-10 -1.84442161e-10  7.38852961e-11
  2.90502717e-11 -2.41446221e-10 -2.13346657e-10 -4.02840091e-12
 -5.53779057e-11  1.62265453e-10 -1.21797523e-10 -6.30948004e-11
  4.67656282e-11 -9.14847122e-11  9.10021943e-11  5.49870768e-11
 -3.37336757e-11  4.65026319e-11 -5.89084661e-11 -4.23777271e-11
 -2.36062714e-11  5.86300602e-11 -4.59667493e-11 -3.06299036e-11
 -3.47320276e-13  1.95530077e-11  6.69862490e-11  1.28118254e-11
 -4.59962331e-11 -1.67308373e-11 -2.48164985e-11 -3.23398614e-11
 -3.79452580e+00]
supnorm grad right now is: 3.7945258035279026
Weights right now are: 
[-4.54144431e+00 -6.64821470e-01 -3.27685604e+00 -4.10967016e+00
  4.79601314e+00  5.56129800e-01  3.67579343e+00  3.39364190e+00
 -2.06108803e+00 -7.75548390e-01 -2.14063506e+00 -1.81007207e+00
  1.26294223e+00  3.14401490e-01 -3.18397782e-01  5.49017737e-01
 -1.46175836e+00 -5.00329972e-01 -2.49166962e+00 -2.16398174e+00
 -2.28201028e+00 -8.43111470e-01 -2.25035849e+00 -1.85216141e+00
 -8.52016982e-01 -4.79373274e-01 -1.45910050e+00 -7.16566430e-01
  4.14098380e-01  1.47558102e+00  1.52844122e+00  4.75233639e-01
 -1.68558716e+00  1.52417519e+00 -8.65015740e-01 -8.94083303e-01
 -2.63107882e+00 -4.89339223e-01 -9.28178508e-01 -7.47661504e-01
  1.57334834e-01 -1.76075703e+00  1.45445723e+00  1.03250685e+00
  1.91942793e-01  2.49984752e+00 -2.08725862e+00  1.42839702e-02
 -1.37297998e+00 -6.99635364e-01 -3.47295827e-01 -1.50037547e+00
  7.65942228e-01  1.13075898e+00  6.31256452e-01  1.79110474e+00
  1.32160056e+00  6.61543307e-01 -5.44766605e-01 -2.37950961e+00
  2.13893970e+00  2.24326623e+00 -8.90787849e-02  1.35864023e+00
  2.47187016e+01]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.306544711644
gradient value of function right now is: [ 1.41401725e-08  2.87219607e-09  1.41504354e-08  1.41487861e-08
 -1.41402113e-08 -2.87220374e-09 -1.41504742e-08 -1.41488249e-08
  1.85343969e-10  7.41585317e-11  3.91675397e-10  2.54749177e-10
  2.47289579e-09  4.91295047e-10  2.76392110e-09  2.75795372e-09
  7.67986521e-11  4.78839074e-11  2.46806020e-10  1.27588426e-10
  9.06692880e-11  4.15747606e-11  2.17717497e-10  1.31427012e-10
 -1.36709254e-10 -1.48262137e-10 -2.57701984e-10 -3.96244351e-11
 -6.16749742e-12 -2.74360748e-11 -3.12017058e-11 -2.84262731e-12
  3.31351111e-10 -5.26237969e-10 -2.38637797e-10  5.38288063e-11
  1.92439315e-11 -2.24373185e-10 -2.05707587e-10 -5.82989892e-12
 -6.11966048e-11  1.28635064e-10 -1.22459374e-10 -7.55807280e-11
  4.95122295e-11 -7.22849393e-11  9.07942392e-11  6.19669995e-11
 -3.36339500e-11  3.65585379e-11 -5.69612523e-11 -4.37042123e-11
 -2.40237611e-11  4.71602079e-11 -4.44926561e-11 -3.21425617e-11
 -1.11402142e-12  1.81221944e-11  4.99811712e-11  1.78743126e-11
 -3.18044789e-11 -2.44325135e-11 -1.83071928e-11 -3.06083500e-11
 -1.23107347e+00]
supnorm grad right now is: 1.2310734705140993
Weights right now are: 
[-4.57168232e+00 -6.70924951e-01 -3.30711690e+00 -4.13992537e+00
  4.82625116e+00  5.62233282e-01  3.70605429e+00  3.42389712e+00
 -2.06143879e+00 -7.75705343e-01 -2.14145636e+00 -1.81057515e+00
  1.25770439e+00  3.13349645e-01 -3.24301680e-01  5.43162859e-01
 -1.46188354e+00 -5.00430552e-01 -2.49218157e+00 -2.16421837e+00
 -2.28217541e+00 -8.43199160e-01 -2.25081294e+00 -1.85241594e+00
 -8.51721560e-01 -4.79038760e-01 -1.45852955e+00 -7.16480005e-01
  4.14111356e-01  1.47564364e+00  1.52851180e+00  4.75239870e-01
 -1.68629004e+00  1.52538242e+00 -8.64416079e-01 -8.94193129e-01
 -2.63111678e+00 -4.88829229e-01 -9.27705237e-01 -7.47646781e-01
  1.57481849e-01 -1.76103067e+00  1.45474220e+00  1.03269177e+00
  1.91825469e-01  2.50000056e+00 -2.08746910e+00  1.41349435e-02
 -1.37290181e+00 -6.99713684e-01 -3.47164901e-01 -1.50027304e+00
  7.65998507e-01  1.13065769e+00  6.31358768e-01  1.79118056e+00
  1.32160360e+00  6.61502014e-01 -5.44870149e-01 -2.37955352e+00
  2.13900387e+00  2.24332653e+00 -8.90410913e-02  1.35870950e+00
  2.48919531e+01]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.3593857200694
gradient value of function right now is: [ 1.18311978e-08  2.43088398e-09  1.18400646e-08  1.18379545e-08
 -1.18312165e-08 -2.43088784e-09 -1.18400833e-08 -1.18379733e-08
  1.40226980e-10  6.18404808e-11  3.24266463e-10  2.00046049e-10
  2.10445229e-09  4.21683561e-10  2.36867386e-09  2.35155342e-09
  5.13292710e-11  3.98108904e-11  2.03183160e-10  9.52571642e-11
  6.66021580e-11  3.46690311e-11  1.80088198e-10  1.01811586e-10
 -1.19878238e-10 -1.31255043e-10 -2.27291424e-10 -3.48584005e-11
 -6.24437329e-12 -2.46094879e-11 -2.86531117e-11 -2.72696669e-12
  2.80644709e-10 -4.73351401e-10 -2.30469059e-10  4.41463612e-11
  1.49720024e-11 -2.00025889e-10 -1.85474159e-10 -5.78212612e-12
 -5.72099706e-11  1.08715724e-10 -1.11707579e-10 -7.19775198e-11
  4.58289731e-11 -6.11187105e-11  8.27263070e-11  5.82404817e-11
 -3.06169189e-11  3.06574758e-11 -5.13740571e-11 -4.01389148e-11
 -2.19882781e-11  4.00564579e-11 -4.01512659e-11 -2.96539493e-11
 -1.21132101e-12  1.60993008e-11  4.12631493e-11  1.75990180e-11
 -2.54211251e-11 -2.42071747e-11 -1.50519225e-11 -2.74767691e-11
 -3.22154240e-01]
supnorm grad right now is: 0.32215424031531026
Weights right now are: 
[-4.59701090e+00 -6.76100676e-01 -3.33246481e+00 -4.16526797e+00
  4.85157974e+00  5.67409008e-01  3.73140221e+00  3.44923973e+00
 -2.06172169e+00 -7.75836999e-01 -2.14214399e+00 -1.81098746e+00
  1.25323591e+00  3.12450232e-01 -3.29349863e-01  5.38164869e-01
 -1.46197859e+00 -5.00514974e-01 -2.49261008e+00 -2.16440840e+00
 -2.28230702e+00 -8.43272823e-01 -2.25119388e+00 -1.85262366e+00
 -8.51465570e-01 -4.78751321e-01 -1.45803703e+00 -7.16405215e-01
  4.14124175e-01  1.47569773e+00  1.52857411e+00  4.75245645e-01
 -1.68688736e+00  1.52642548e+00 -8.63889581e-01 -8.94285368e-01
 -2.63114777e+00 -4.88389942e-01 -9.27296098e-01 -7.47633609e-01
  1.57610016e-01 -1.76126288e+00  1.45498967e+00  1.03285374e+00
  1.91723311e-01  2.50013077e+00 -2.08765207e+00  1.40047046e-02
 -1.37283404e+00 -6.99779440e-01 -3.47051603e-01 -1.50018400e+00
  7.66047325e-01  1.13057191e+00  6.31447312e-01  1.79124649e+00
  1.32160642e+00  6.61466542e-01 -5.44958004e-01 -2.37959291e+00
  2.13905794e+00  2.24338084e+00 -8.90091954e-02  1.35876952e+00
  2.49759484e+01]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.3324579564064
gradient value of function right now is: [ 1.04654687e-08  2.17108419e-09  1.04731602e-08  1.04716347e-08
 -1.04650820e-08 -2.17100418e-09 -1.04727734e-08 -1.04712475e-08
  1.31842399e-10  5.51055829e-11  2.90327009e-10  1.84281572e-10
  1.88829930e-09  3.76338884e-10  2.11650766e-09  2.10771589e-09
  5.20204750e-11  3.56537175e-11  1.83132800e-10  9.05900396e-11
  6.38842324e-11  3.09796032e-11  1.61783163e-10  9.47943390e-11
 -1.06988004e-10 -1.13726047e-10 -1.99453087e-10 -3.09166685e-11
 -5.94931497e-12 -2.12096644e-11 -2.51144754e-11 -2.48191232e-12
  2.51264724e-10 -4.06759145e-10 -1.88883829e-10  4.04204005e-11
  1.38533494e-11 -1.72782805e-10 -1.59297901e-10 -4.73564331e-12
 -4.79568665e-11  9.70117155e-11 -9.50483846e-11 -5.96187581e-11
  3.87087740e-11 -5.47902694e-11  7.05913572e-11  4.86993768e-11
 -2.61254294e-11  2.71516731e-11 -4.40136835e-11 -3.40394511e-11
 -1.86901454e-11  3.55530407e-11 -3.44042669e-11 -2.50686030e-11
 -9.44278821e-13  1.38478650e-11  3.75174315e-11  1.42492578e-11
 -2.36481592e-11 -1.95310020e-11 -1.37217861e-11 -2.36387411e-11
 -9.15730368e-01]
supnorm grad right now is: 0.9157303676671671
Weights right now are: 
[-4.61905405e+00 -6.80651915e-01 -3.35452455e+00 -4.18732356e+00
  4.87362290e+00  5.71960248e-01  3.75346195e+00  3.47129532e+00
 -2.06197833e+00 -7.75952221e-01 -2.14274731e+00 -1.81135618e+00
  1.24928647e+00  3.11657561e-01 -3.33800859e-01  5.33750049e-01
 -1.46207022e+00 -5.00589152e-01 -2.49298795e+00 -2.16458241e+00
 -2.28242828e+00 -8.43337449e-01 -2.25152905e+00 -1.85281094e+00
 -8.51238598e-01 -4.78504523e-01 -1.45760833e+00 -7.16339270e-01
  4.14136646e-01  1.47574419e+00  1.52862881e+00  4.75250962e-01
 -1.68741234e+00  1.52731903e+00 -8.63449585e-01 -8.94367434e-01
 -2.63117506e+00 -4.88013308e-01 -9.26945919e-01 -7.47622465e-01
  1.57719103e-01 -1.76146556e+00  1.45520149e+00  1.03299198e+00
  1.91636085e-01  2.50024473e+00 -2.08780893e+00  1.38931973e-02
 -1.37277606e+00 -6.99836411e-01 -3.46954553e-01 -1.50010777e+00
  7.66088993e-01  1.13049704e+00  6.31523185e-01  1.79130287e+00
  1.32160881e+00  6.61436266e-01 -5.45033271e-01 -2.37962771e+00
  2.13910395e+00  2.24342801e+00 -8.89816538e-02  1.35882173e+00
  2.49122104e+01]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.3449793722
gradient value of function right now is: [ 8.93354715e-09  1.87078835e-09  8.94049832e-09  8.93823125e-09
 -8.93348287e-09 -1.87077498e-09 -8.94043402e-09 -8.93816690e-09
  9.22211923e-11  4.65687561e-11  2.42105739e-10  1.39107243e-10
  1.63386629e-09  3.30633999e-10  1.85422885e-09  1.82988961e-09
  2.67370221e-11  2.98948930e-11  1.50764466e-10  6.13473666e-11
  4.17527884e-11  2.61277358e-11  1.34414241e-10  6.94484873e-11
 -9.66424374e-11 -1.06089247e-10 -1.83576782e-10 -2.81585048e-11
 -6.00858415e-12 -2.01777390e-11 -2.42863402e-11 -2.45382394e-12
  2.16422646e-10 -3.89415821e-10 -2.02697416e-10  3.27763003e-11
  1.02903213e-11 -1.63023984e-10 -1.52971079e-10 -5.21994351e-12
 -4.87902013e-11  8.35236120e-11 -9.30924863e-11 -6.24558947e-11
  3.87516160e-11 -4.70627121e-11  6.89296697e-11  4.99708571e-11
 -2.54765075e-11  2.32415776e-11 -4.23497275e-11 -3.36986325e-11
 -1.83922922e-11  3.09217708e-11 -3.31223642e-11 -2.50038538e-11
 -1.18170901e-12  1.30577125e-11  3.09088018e-11  1.56359061e-11
 -1.83107934e-11 -2.17099521e-11 -1.12056555e-11 -2.25257830e-11
  6.98266199e-01]
supnorm grad right now is: 0.6982661992733216
Weights right now are: 
[-4.63840471e+00 -6.84684696e-01 -3.37388980e+00 -4.20668505e+00
  4.89297356e+00  5.75993030e-01  3.77282720e+00  3.49065681e+00
 -2.06220218e+00 -7.76053657e-01 -2.14327826e+00 -1.81167902e+00
  1.24577162e+00  3.10951824e-01 -3.37763475e-01  5.29820519e-01
 -1.46214918e+00 -5.00654554e-01 -2.49332095e+00 -2.16473430e+00
 -2.28253391e+00 -8.43394425e-01 -2.25182443e+00 -1.85297497e+00
 -8.51035023e-01 -4.78285799e-01 -1.45722648e+00 -7.16280240e-01
  4.14148694e-01  1.47578542e+00  1.52867815e+00  4.75255913e-01
 -1.68787825e+00  1.52811203e+00 -8.63059147e-01 -8.94440349e-01
 -2.63119895e+00 -4.87679185e-01 -9.26635039e-01 -7.47612511e-01
  1.57816256e-01 -1.76164477e+00  1.45538971e+00  1.03311433e+00
  1.91558434e-01  2.50034575e+00 -2.08794841e+00  1.37944866e-02
 -1.37272453e+00 -6.99886490e-01 -3.46868375e-01 -1.50004019e+00
  7.66126047e-01  1.13043084e+00  6.31590579e-01  1.79135284e+00
  1.32161091e+00  6.61409550e-01 -5.45101223e-01 -2.37965786e+00
  2.13914583e+00  2.24346933e+00 -8.89568528e-02  1.35886787e+00
  2.50807866e+01]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.3499260876374
gradient value of function right now is: [ 8.27959894e-09  1.74658932e-09  8.28576036e-09  8.28432499e-09
 -8.27948397e-09 -1.74656512e-09 -8.28564536e-09 -8.28420986e-09
  1.00075042e-10  4.36980333e-11  2.29643939e-10  1.42306381e-10
  1.53084307e-09  3.06056439e-10  1.72060376e-09  1.71008867e-09
  3.73468407e-11  2.83022014e-11  1.44858024e-10  6.85307197e-11
  4.79467306e-11  2.46143213e-11  1.28176564e-10  7.29116379e-11
 -8.84946575e-11 -9.28026574e-11 -1.63762571e-10 -2.55258958e-11
 -5.61989548e-12 -1.74261404e-11 -2.12540258e-11 -2.21605363e-12
  2.02603644e-10 -3.34357732e-10 -1.58855380e-10  3.22555710e-11
  1.06501729e-11 -1.41509206e-10 -1.31112596e-10 -4.05958084e-12
 -3.99404429e-11  7.78988784e-11 -7.84706604e-11 -4.99885046e-11
  3.21651757e-11 -4.41515283e-11  5.83519992e-11  4.06908012e-11
 -2.15693172e-11  2.15421225e-11 -3.61789661e-11 -2.81877335e-11
 -1.54557911e-11  2.85548235e-11 -2.82968460e-11 -2.07885946e-11
 -8.40481806e-13  1.12789317e-11  2.99166958e-11  1.21097786e-11
 -1.86406971e-11 -1.66306568e-11 -1.09278831e-11 -1.94290439e-11
 -6.08324253e-01]
supnorm grad right now is: 0.6083242530820486
Weights right now are: 
[-4.65562593e+00 -6.88303970e-01 -3.39112409e+00 -4.22391573e+00
  4.91019478e+00  5.79612304e-01  3.79006150e+00  3.50788749e+00
 -2.06239654e+00 -7.76144014e-01 -2.14375077e+00 -1.81196234e+00
  1.24260504e+00  3.10315191e-01 -3.41338406e-01  5.26278965e-01
 -1.46221502e+00 -5.00712838e-01 -2.49361727e+00 -2.16486581e+00
 -2.28262490e+00 -8.43445227e-01 -2.25208752e+00 -1.85311853e+00
 -8.50849997e-01 -4.78087774e-01 -1.45688004e+00 -7.16226653e-01
  4.14160323e-01  1.47582284e+00  1.52872352e+00  4.75260571e-01
 -1.68829733e+00  1.52883201e+00 -8.62701228e-01 -8.94505620e-01
 -2.63122000e+00 -4.87376050e-01 -9.26352391e-01 -7.47603352e-01
  1.57904436e-01 -1.76180597e+00  1.45556014e+00  1.03322594e+00
  1.91487893e-01  2.50043679e+00 -2.08807488e+00  1.37044102e-02
 -1.37267778e+00 -6.99931242e-01 -3.46790372e-01 -1.49997875e+00
  7.66159676e-01  1.13037140e+00  6.31651604e-01  1.79139830e+00
  1.32161289e+00  6.61385363e-01 -5.45161760e-01 -2.37968525e+00
  2.13918263e+00  2.24350694e+00 -8.89347388e-02  1.35890958e+00
  2.49239625e+01]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.24818684488
gradient value of function right now is: [ 7.71273552e-09  1.63796380e-09  7.71825318e-09  7.71743969e-09
 -7.71276641e-09 -1.63797017e-09 -7.71828409e-09 -7.71747058e-09
  1.04808520e-10  4.11411285e-11  2.18137039e-10  1.43191014e-10
  1.44031430e-09  2.84991706e-10  1.60555942e-09  1.60545126e-09
  4.47800144e-11  2.68456986e-11  1.39059506e-10  7.31306770e-11
  5.20185327e-11  2.32524803e-11  1.22296309e-10  7.47239784e-11
 -8.16461085e-11 -8.21215754e-11 -1.47587885e-10 -2.33426348e-11
 -5.29157049e-12 -1.52295955e-11 -1.88233404e-11 -2.02210447e-12
  1.90468502e-10 -2.90434314e-10 -1.24874358e-10  3.15737584e-11
  1.08175270e-11 -1.24272672e-10 -1.13712208e-10 -3.16249199e-12
 -3.29635345e-11  7.29992348e-11 -6.68639663e-11 -4.02609749e-11
  2.69400797e-11 -4.15926132e-11  4.99296821e-11  3.34002166e-11
 -1.84682878e-11  2.00809665e-11 -3.12752302e-11 -2.38530927e-11
 -1.31282856e-11  2.65351225e-11 -2.44566908e-11 -1.74756688e-11
 -5.89134333e-13  9.86986135e-12  2.89104904e-11  9.30867213e-12
 -1.87230131e-11 -1.26835208e-11 -1.06129980e-11 -1.69325791e-11
 -1.73826107e+00]
supnorm grad right now is: 1.7382610686569089
Weights right now are: 
[-4.67131720e+00 -6.91626799e-01 -3.40682728e+00 -4.23961562e+00
  4.92588607e+00  5.82935136e-01  3.80576470e+00  3.52358739e+00
 -2.06257416e+00 -7.76226607e-01 -2.14418293e+00 -1.81222135e+00
  1.23968806e+00  3.09729032e-01 -3.44630282e-01  5.23016775e-01
 -1.46227522e+00 -5.00766200e-01 -2.49388876e+00 -2.16498620e+00
 -2.28270816e+00 -8.43491725e-01 -2.25232847e+00 -1.85324995e+00
 -8.50679079e-01 -4.77906177e-01 -1.45656146e+00 -7.16177178e-01
  4.14171550e-01  1.47585712e+00  1.52876551e+00  4.75264976e-01
 -1.68868330e+00  1.52949135e+00 -8.62375827e-01 -8.94566048e-01
 -2.63123946e+00 -4.87098014e-01 -9.26093415e-01 -7.47595003e-01
  1.57984310e-01 -1.76195458e+00  1.45571537e+00  1.03332685e+00
  1.91423874e-01  2.50052109e+00 -2.08819024e+00  1.36227589e-02
 -1.37263508e+00 -6.99972258e-01 -3.46719008e-01 -1.49992261e+00
  7.66190371e-01  1.13031680e+00  6.31707419e-01  1.79143979e+00
  1.32161475e+00  6.61363155e-01 -5.45218472e-01 -2.37970934e+00
  2.13921718e+00  2.24354090e+00 -8.89141373e-02  1.35894746e+00
  2.48424557e+01]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.1789601865585
gradient value of function right now is: [ 7.14031556e-09  1.52602401e-09  7.14534524e-09  7.14476948e-09
 -7.14034695e-09 -1.52603067e-09 -7.14537664e-09 -7.14480093e-09
  1.01131957e-10  3.82866687e-11  2.03702109e-10  1.36395842e-10
  1.34579450e-09  2.65214803e-10  1.49546580e-09  1.49886531e-09
  4.49756780e-11  2.50703963e-11  1.30457692e-10  7.10461378e-11
  5.07830865e-11  2.16795869e-11  1.14461900e-10  7.16616845e-11
 -7.58986478e-11 -7.47255183e-11 -1.35588397e-10 -2.16079934e-11
 -5.07434805e-12 -1.37926652e-11 -1.72533770e-11 -1.89659430e-12
  1.77747181e-10 -2.62235240e-10 -1.07507176e-10  2.99264715e-11
  1.03472865e-11 -1.12738574e-10 -1.02627466e-10 -2.72077837e-12
 -2.90595543e-11  6.79902360e-11 -5.98349331e-11 -3.50793595e-11
  2.39178909e-11 -3.88599257e-11  4.47813591e-11  2.93730828e-11
 -1.65709501e-11  1.86164867e-11 -2.81752653e-11 -2.12899664e-11
 -1.17353690e-11  2.46184404e-11 -2.20314672e-11 -1.55484257e-11
 -4.79677038e-13  8.92956263e-12  2.72775620e-11  7.90532793e-12
 -1.79306913e-11 -1.07422632e-11 -1.00282560e-11 -1.53069445e-11
 -2.19302059e+00]
supnorm grad right now is: 2.193020592621221
Weights right now are: 
[-4.68543419e+00 -6.94637193e-01 -3.42095506e+00 -4.25374023e+00
  4.94000305e+00  5.85945529e-01  3.81989247e+00  3.53771200e+00
 -2.06272993e+00 -7.76300914e-01 -2.14457125e+00 -1.81245092e+00
  1.23703707e+00  3.09195537e-01 -3.47626537e-01  5.20050856e-01
 -1.46232579e+00 -5.00814211e-01 -2.49413258e+00 -2.16509144e+00
 -2.28278058e+00 -8.43533585e-01 -2.25254508e+00 -1.85336608e+00
 -8.50522299e-01 -4.77740527e-01 -1.45627003e+00 -7.16131867e-01
  4.14182356e-01  1.47588850e+00  1.52880442e+00  4.75269133e-01
 -1.68903307e+00  1.53009544e+00 -8.62074212e-01 -8.94620356e-01
 -2.63125659e+00 -4.86843936e-01 -9.25856125e-01 -7.47587193e-01
  1.58058362e-01 -1.76208893e+00  1.45585831e+00  1.03342044e+00
  1.91364608e-01  2.50059733e+00 -2.08829650e+00  1.35472084e-02
 -1.37259580e+00 -7.00009126e-01 -3.46653607e-01 -1.49987107e+00
  7.66218638e-01  1.13026743e+00  6.31758616e-01  1.79147795e+00
  1.32161641e+00  6.61343027e-01 -5.45269323e-01 -2.37973232e+00
  2.13924842e+00  2.24357253e+00 -8.88956303e-02  1.35898242e+00
  2.47746250e+01]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.3557677280387
gradient value of function right now is: [ 6.18421995e-09  1.33154346e-09  6.18900849e-09  6.18744986e-09
 -6.18394342e-09 -1.33148430e-09 -6.18873189e-09 -6.18717299e-09
  6.47671857e-11  3.25396432e-11  1.69503532e-10  9.75599968e-11
  1.17740470e-09  2.37816204e-10  1.33474255e-09  1.31839759e-09
  1.90719606e-11  2.10105271e-11  1.06226504e-10  4.34152222e-11
  2.95506681e-11  1.83423513e-11  9.45710148e-11  4.90064210e-11
 -7.07041473e-11 -7.43848329e-11 -1.31124843e-10 -2.04384668e-11
 -5.18970078e-12 -1.41789164e-11 -1.78468735e-11 -1.95492578e-12
  1.54780091e-10 -2.73206914e-10 -1.39572757e-10  2.37159928e-11
  7.22023206e-12 -1.14467261e-10 -1.07380624e-10 -3.65523623e-12
 -3.39295661e-11  5.92682035e-11 -6.50233575e-11 -4.32793053e-11
  2.70803755e-11 -3.36637533e-11  4.83485033e-11  3.48103598e-11
 -1.78345119e-11  1.61618964e-11 -2.96238116e-11 -2.35331826e-11
 -1.28533385e-11  2.18369505e-11 -2.31894128e-11 -1.74398907e-11
 -8.23428409e-13  9.08036722e-12  2.21631302e-11  1.07862689e-11
 -1.32656914e-11 -1.49556207e-11 -8.04839740e-12 -1.58249277e-11
  4.51478288e-01]
supnorm grad right now is: 0.4514782876457858
Weights right now are: 
[-4.69849943e+00 -6.97441077e-01 -3.43403028e+00 -4.26681252e+00
  4.95306830e+00  5.88749413e-01  3.83296770e+00  3.55078429e+00
 -2.06287465e+00 -7.76369863e-01 -2.14493174e+00 -1.81266413e+00
  1.23456114e+00  3.08697494e-01 -3.50424001e-01  5.17280985e-01
 -1.46237293e+00 -5.00858822e-01 -2.49435927e+00 -2.16518937e+00
 -2.28284798e+00 -8.43572469e-01 -2.25274639e+00 -1.85347409e+00
 -8.50375495e-01 -4.77586624e-01 -1.45599839e+00 -7.16089485e-01
  4.14192822e-01  1.47591765e+00  1.52884089e+00  4.75273097e-01
 -1.68935944e+00  1.53065631e+00 -8.61795876e-01 -8.94671237e-01
 -2.63127258e+00 -4.86607832e-01 -9.25635791e-01 -7.47579964e-01
  1.58126869e-01 -1.76221409e+00  1.45599089e+00  1.03350646e+00
  1.91309768e-01  2.50066853e+00 -2.08839507e+00  1.34776823e-02
 -1.37255934e+00 -7.00043340e-01 -3.46592819e-01 -1.49982334e+00
  7.66244865e-01  1.13022149e+00  6.31806191e-01  1.79151324e+00
  1.32161792e+00  6.61324353e-01 -5.45317861e-01 -2.37975285e+00
  2.13927863e+00  2.24360115e+00 -8.88780427e-02  1.35901474e+00
  2.50198069e+01]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.2406864574828
gradient value of function right now is: [ 6.05286790e-09  1.30912681e-09  6.05719636e-09  6.05652947e-09
 -6.05337530e-09 -1.30923591e-09 -6.05770390e-09 -6.05703750e-09
  8.22306758e-11  3.24662218e-11  1.72221695e-10  1.12629612e-10
  1.16049205e-09  2.29557466e-10  1.29367018e-09  1.29363896e-09
  3.50224106e-11  2.12541870e-11  1.10152773e-10  5.75601704e-11
  4.08775545e-11  1.84014913e-11  9.68320197e-11  5.89119397e-11
 -6.65923935e-11 -6.53342364e-11 -1.18764876e-10 -1.89598330e-11
 -4.81660798e-12 -1.21495205e-11 -1.55023603e-11 -1.75524663e-12
  1.52691199e-10 -2.31315798e-10 -9.85693027e-11  2.53901871e-11
  8.51869965e-12 -9.89747205e-11 -9.06366724e-11 -2.53827097e-12
 -2.61652046e-11  5.82446248e-11 -5.31539094e-11 -3.19180077e-11
  2.14340495e-11 -3.33477375e-11  3.97909884e-11  2.65431663e-11
 -1.47050528e-11  1.58198333e-11 -2.48723604e-11 -1.89769027e-11
 -1.04432056e-11  2.11206025e-11 -1.94592618e-11 -1.38928153e-11
 -4.76776946e-13  7.81015738e-12  2.31624814e-11  7.35868975e-12
 -1.50342155e-11 -1.00299787e-11 -8.50421018e-12 -1.34936545e-11
 -1.79698383e+00]
supnorm grad right now is: 1.7969838297945222
Weights right now are: 
[-4.71049358e+00 -7.00030472e-01 -3.44603362e+00 -4.27881304e+00
  4.96506244e+00  5.91338808e-01  3.84497104e+00  3.56278481e+00
 -2.06300477e+00 -7.76433149e-01 -2.14526220e+00 -1.81285749e+00
  1.23226866e+00  3.08235694e-01 -3.53017586e-01  5.14715403e-01
 -1.46241381e+00 -5.00899769e-01 -2.49456698e+00 -2.16527721e+00
 -2.28290816e+00 -8.43608179e-01 -2.25293100e+00 -1.85357180e+00
 -8.50238402e-01 -4.77443985e-01 -1.45574567e+00 -7.16049958e-01
  4.14202976e-01  1.47594479e+00  1.52887521e+00  4.75276890e-01
 -1.68966059e+00  1.53117843e+00 -8.61534056e-01 -8.94717817e-01
 -2.63128691e+00 -4.86388697e-01 -9.25430705e-01 -7.47573096e-01
  1.58191208e-01 -1.76232929e+00  1.45611493e+00  1.03358812e+00
  1.91258240e-01  2.50073402e+00 -2.08848743e+00  1.34117201e-02
 -1.37252535e+00 -7.00074675e-01 -3.46536239e-01 -1.49977859e+00
  7.66269320e-01  1.13017916e+00  6.31850480e-01  1.79154636e+00
  1.32161946e+00  6.61306987e-01 -5.45361510e-01 -2.37977324e+00
  2.13930487e+00  2.24362946e+00 -8.88621806e-02  1.35904504e+00
  2.47896094e+01]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.3507630301965
gradient value of function right now is: [ 5.33660455e-09  1.16186497e-09  5.34076149e-09  5.33934211e-09
 -5.33647153e-09 -1.16183625e-09 -5.34062842e-09 -5.33920894e-09
  5.45098557e-11  2.81306907e-11  1.46378300e-10  8.30823569e-11
  1.03220206e-09  2.08766223e-10  1.17160495e-09  1.15624300e-09
  1.51717910e-11  1.81796623e-11  9.17677240e-11  3.64325785e-11
  2.46442063e-11  1.58777428e-11  8.17629967e-11  4.16258692e-11
 -6.26257962e-11 -6.52086203e-11 -1.15482564e-10 -1.80739502e-11
 -4.87755529e-12 -1.24676950e-11 -1.59542707e-11 -1.79455227e-12
  1.35287428e-10 -2.40336122e-10 -1.23574613e-10  2.06505349e-11
  6.14301893e-12 -1.00548968e-10 -9.45052729e-11 -3.26101786e-12
 -2.99591475e-11  5.16663307e-11 -5.72564090e-11 -3.82869696e-11
  2.39111524e-11 -2.94174018e-11  4.26231577e-11  3.07847973e-11
 -1.57082046e-11  1.39802564e-11 -2.60456444e-11 -2.07446687e-11
 -1.13267480e-11  1.90288448e-11 -2.03965501e-11 -1.53809183e-11
 -7.41823192e-13  7.94961548e-12  1.92852255e-11  9.56863789e-12
 -1.14941622e-11 -1.32775839e-11 -6.99846060e-12 -1.39160194e-11
  5.75615875e-01]
supnorm grad right now is: 0.5756158751294008
Weights right now are: 
[-4.72169455e+00 -7.02461821e-01 -3.45724315e+00 -4.29002000e+00
  4.97626343e+00  5.93770161e-01  3.85618059e+00  3.57399179e+00
 -2.06312795e+00 -7.76492405e-01 -2.14557192e+00 -1.81303973e+00
  1.23011106e+00  3.07801513e-01 -3.55456523e-01  5.12301245e-01
 -1.46245334e+00 -5.00938170e-01 -2.49476203e+00 -2.16536064e+00
 -2.28296544e+00 -8.43641650e-01 -2.25310423e+00 -1.85366416e+00
 -8.50109233e-01 -4.77310979e-01 -1.45550897e+00 -7.16012779e-01
  4.14212802e-01  1.47597008e+00  1.52890748e+00  4.75280511e-01
 -1.68994368e+00  1.53166465e+00 -8.61292611e-01 -8.94761853e-01
 -2.63130043e+00 -4.86184417e-01 -9.25239717e-01 -7.47566743e-01
  1.58250806e-01 -1.76243744e+00  1.45623012e+00  1.03366360e+00
  1.91210469e-01  2.50079563e+00 -2.08857322e+00  1.33506876e-02
 -1.37249372e+00 -7.00103974e-01 -3.46483581e-01 -1.49973703e+00
  7.66292068e-01  1.13013949e+00  6.31891708e-01  1.79157710e+00
  1.32162084e+00  6.61290848e-01 -5.45402353e-01 -2.37979217e+00
  2.13932985e+00  2.24365522e+00 -8.88472709e-02  1.35907335e+00
  2.50578790e+01]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.359603964015
gradient value of function right now is: [ 5.10523366e-09  1.11652929e-09  5.10908806e-09  5.10801850e-09
 -5.10520792e-09 -1.11652361e-09 -5.10906232e-09 -5.10799268e-09
  5.85375247e-11  2.71414472e-11  1.42290334e-10  8.53264595e-11
  9.94041935e-10  1.99380955e-10  1.12078013e-09  1.11151250e-09
  2.00554496e-11  1.76476053e-11  9.00044714e-11  3.99899331e-11
  2.76419968e-11  1.53597878e-11  7.97655686e-11  4.35698778e-11
 -5.93501568e-11 -5.99414644e-11 -1.07590096e-10 -1.70179523e-11
 -4.66324610e-12 -1.13644014e-11 -1.46895469e-11 -1.68499447e-12
  1.30220634e-10 -2.18058003e-10 -1.05367344e-10  2.05675101e-11
  6.36881156e-12 -9.19115468e-11 -8.56557690e-11 -2.77428386e-12
 -2.63247824e-11  4.96130030e-11 -5.13128401e-11 -3.31457106e-11
  2.12038186e-11 -2.83538662e-11  3.83055812e-11  2.69545999e-11
 -1.41209966e-11  1.33790122e-11 -2.35548798e-11 -1.85000957e-11
 -1.01294997e-11  1.81531557e-11 -1.84451194e-11 -1.36586069e-11
 -5.98520222e-13  7.24243201e-12  1.89844168e-11  8.10777789e-12
 -1.17061836e-11 -1.11713575e-11 -6.92562903e-12 -1.26694882e-11
 -3.13972507e-01]
supnorm grad right now is: 0.3139725069376692
Weights right now are: 
[-4.73219373e+00 -7.04752757e-01 -3.46775038e+00 -4.30052476e+00
  4.98676263e+00  5.96061100e-01  3.86668783e+00  3.58449656e+00
 -2.06324239e+00 -7.76547998e-01 -2.14586248e+00 -1.81320976e+00
  1.22807363e+00  3.07391425e-01 -3.57760573e-01  5.10021288e-01
 -1.46248942e+00 -5.00974217e-01 -2.49494508e+00 -2.16543808e+00
 -2.28301850e+00 -8.43673072e-01 -2.25326684e+00 -1.85375027e+00
 -8.49986810e-01 -4.77185377e-01 -1.45528503e+00 -7.15977575e-01
  4.14222350e-01  1.47599398e+00  1.52893819e+00  4.75283995e-01
 -1.69021078e+00  1.53212427e+00 -8.61064047e-01 -8.94803348e-01
 -2.63131309e+00 -4.85991364e-01 -9.25059126e-01 -7.47560713e-01
  1.58307108e-01 -1.76253944e+00  1.45633898e+00  1.03373490e+00
  1.91165282e-01  2.50085380e+00 -2.08865441e+00  1.32929719e-02
 -1.37246383e+00 -7.00131501e-01 -3.46433834e-01 -1.49969774e+00
  7.66313552e-01  1.13010212e+00  6.31930657e-01  1.79160615e+00
  1.32162218e+00  6.61275606e-01 -5.45441162e-01 -2.37980990e+00
  2.13935348e+00  2.24367977e+00 -8.88331517e-02  1.35910003e+00
  2.49351463e+01]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.3524162066396
gradient value of function right now is: [ 4.70498221e-09  1.03441463e-09  4.70864661e-09  4.70738509e-09
 -4.70504786e-09 -1.03442903e-09 -4.70871227e-09 -4.70745086e-09
  4.80172645e-11  2.48708706e-11  1.29460548e-10  7.33224844e-11
  9.22738601e-10  1.86578188e-10  1.04729502e-09  1.03364337e-09
  1.32747275e-11  1.60999529e-11  8.13024553e-11  3.21401979e-11
  2.17155283e-11  1.40583993e-11  7.24219538e-11  3.67774174e-11
 -5.62985988e-11 -5.78536559e-11 -1.03061032e-10 -1.62101707e-11
 -4.59080279e-12 -1.10744960e-11 -1.43812312e-11 -1.65571374e-12
  1.20641699e-10 -2.13412043e-10 -1.09277386e-10  1.84617812e-11
  5.42706476e-12 -8.92792022e-11 -8.39311011e-11 -2.90027808e-12
 -2.65549562e-11  4.59550622e-11 -5.07906735e-11 -3.39155637e-11
  2.12236889e-11 -2.62307851e-11  3.78620500e-11  2.73092636e-11
 -1.39423673e-11  1.23513390e-11 -2.31073823e-11 -1.84040435e-11
 -1.00496467e-11  1.69031837e-11 -1.81011717e-11 -1.36420092e-11
 -6.60480042e-13  7.03652777e-12  1.71970255e-11  8.47042982e-12
 -1.02683913e-11 -1.17537159e-11 -6.24278938e-12 -1.23619292e-11
  5.30973679e-01]
supnorm grad right now is: 0.530973679285162
Weights right now are: 
[-4.74205936e+00 -7.06915815e-01 -3.47762352e+00 -4.31039566e+00
  4.99662825e+00  5.98224159e-01  3.87656097e+00  3.59436747e+00
 -2.06335192e+00 -7.76600373e-01 -2.14613653e+00 -1.81337145e+00
  1.22614602e+00  3.07003947e-01 -3.59938116e-01  5.07864788e-01
 -1.46252501e+00 -5.01008233e-01 -2.49511809e+00 -2.16551252e+00
 -2.28306964e+00 -8.43702706e-01 -2.25342040e+00 -1.85383244e+00
 -8.49870971e-01 -4.77067874e-01 -1.45507446e+00 -7.15944325e-01
  4.14231578e-01  1.47601633e+00  1.52896715e+00  4.75287326e-01
 -1.69046311e+00  1.53255362e+00 -8.60852999e-01 -8.94842787e-01
 -2.63132512e+00 -4.85810878e-01 -9.24890468e-01 -7.47555125e-01
  1.58359494e-01 -1.76263565e+00  1.45644054e+00  1.03380110e+00
  1.91123156e-01  2.50090873e+00 -2.08873021e+00  1.32392372e-02
 -1.37243595e+00 -7.00157374e-01 -3.46387392e-01 -1.49966113e+00
  7.66333584e-01  1.13006692e+00  6.31967026e-01  1.79163320e+00
  1.32162342e+00  6.61261378e-01 -5.45477873e-01 -2.37982650e+00
  2.13937571e+00  2.24370259e+00 -8.88197604e-02  1.35912500e+00
  2.49922005e+01]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2814.8450508786837
gradient value of function right now is: [ 4.09003678e-09  9.05251014e-10  4.09362733e-09  4.09154806e-09
 -4.08993148e-09 -9.05227832e-10 -4.09352202e-09 -4.09144258e-09
  2.02415335e-11  2.10005508e-11  1.05843971e-10  4.43080919e-11
  8.08902695e-10  1.69109969e-10  9.43397099e-10  9.12890818e-10
 -7.26486031e-12  1.32952326e-11  6.41028172e-11  1.07522370e-11
  5.21807736e-12  1.17817800e-11  5.84974990e-11  1.95707176e-11
 -5.33659855e-11 -5.92043984e-11 -1.02077729e-10 -1.56505384e-11
 -4.68231864e-12 -1.16964956e-11 -1.51543862e-11 -1.71937357e-12
  1.05190715e-10 -2.28727440e-10 -1.38964484e-10  1.38498046e-11
  3.04796449e-12 -9.32731894e-11 -9.02202082e-11 -3.75140540e-12
 -3.13613100e-11  4.01465798e-11 -5.66328359e-11 -4.17189077e-11
  2.44712200e-11 -2.26859149e-11  4.19691571e-11  3.26469059e-11
 -1.53905632e-11  1.07470304e-11 -2.50059238e-11 -2.08054779e-11
 -1.12659673e-11  1.51311886e-11 -1.96064499e-11 -1.56136826e-11
 -9.64372991e-13  7.37851741e-12  1.34757366e-11  1.11801227e-11
 -6.67855679e-12 -1.57213105e-11 -4.78603974e-12 -1.31872283e-11
  3.87500165e+00]
supnorm grad right now is: 3.8750016475597615
Weights right now are: 
[-4.75130279e+00 -7.08951393e-01 -3.48687391e+00 -4.31964412e+00
  5.00587169e+00  6.00259739e-01  3.88581138e+00  3.60361594e+00
 -2.06345793e+00 -7.76649604e-01 -2.14639455e+00 -1.81352607e+00
  1.22432845e+00  3.06639271e-01 -3.61987656e-01  5.05832288e-01
 -1.46256133e+00 -5.01040281e-01 -2.49528149e+00 -2.16558504e+00
 -2.28311975e+00 -8.43730595e-01 -2.25356519e+00 -1.85391147e+00
 -8.49761776e-01 -4.76959131e-01 -1.45487809e+00 -7.15913066e-01
  4.14240487e-01  1.47603700e+00  1.52899421e+00  4.75290496e-01
 -1.69070032e+00  1.53295000e+00 -8.60661731e-01 -8.94880241e-01
 -2.63133654e+00 -4.85644051e-01 -9.24734881e-01 -7.47550028e-01
  1.58407616e-01 -1.76272554e+00  1.45653425e+00  1.03386179e+00
  1.91084480e-01  2.50096016e+00 -2.08880012e+00  1.31900032e-02
 -1.37241019e+00 -7.00181527e-01 -3.46344429e-01 -1.49962736e+00
  7.66352048e-01  1.13003394e+00  6.32000668e-01  1.79165813e+00
  1.32162452e+00  6.61248254e-01 -5.45512196e-01 -2.37984154e+00
  2.13939688e+00  2.24372321e+00 -8.88072271e-02  1.35914824e+00
  2.52510547e+01]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.360555415622
gradient value of function right now is: [ 4.23158460e-09  9.38364172e-10  4.23485163e-09  4.23377661e-09
 -4.23153334e-09 -9.38352876e-10 -4.23480035e-09 -4.23372529e-09
  4.46287219e-11  2.24666307e-11  1.17219582e-10  6.73374374e-11
  8.40050964e-10  1.69436473e-10  9.51653556e-10  9.40567276e-10
  1.31503173e-11  1.45863296e-11  7.38934852e-11  3.01040926e-11
  2.04607035e-11  1.27225831e-11  6.57135458e-11  3.39933751e-11
 -5.12380478e-11 -5.17108164e-11 -9.28651103e-11 -1.47021067e-11
 -4.32615525e-12 -9.88556315e-12 -1.30160676e-11 -1.53185214e-12
  1.09613598e-10 -1.90210485e-10 -9.55160704e-11  1.69650628e-11
  5.00355145e-12 -7.97265518e-11 -7.47929017e-11 -2.54517269e-12
 -2.34331713e-11  4.16503375e-11 -4.50836190e-11 -2.98055630e-11
  1.87941060e-11 -2.38413015e-11  3.36679465e-11  2.40970032e-11
 -1.23914369e-11  1.11286676e-11 -2.05632601e-11 -1.63185197e-11
 -8.91667367e-12  1.52768269e-11 -1.61115959e-11 -1.20800512e-11
 -5.73131559e-13  6.26353154e-12  1.57133781e-11  7.40241014e-12
 -9.48012294e-12 -1.02550862e-11 -5.71429486e-12 -1.10331427e-11
  2.51988558e-01]
supnorm grad right now is: 0.251988558039012
Weights right now are: 
[-4.76011082e+00 -7.10899547e-01 -3.49568858e+00 -4.32845694e+00
  5.01467972e+00  6.02207892e-01  3.89462605e+00  3.61242876e+00
 -2.06355928e+00 -7.76696596e-01 -2.14664101e+00 -1.81367383e+00
  1.22258587e+00  3.06289865e-01 -3.63951924e-01  5.03883792e-01
 -1.46259612e+00 -5.01070900e-01 -2.49543774e+00 -2.16565444e+00
 -2.28316770e+00 -8.43757235e-01 -2.25370361e+00 -1.85398707e+00
 -8.49657043e-01 -4.76855165e-01 -1.45469007e+00 -7.15883114e-01
  4.14249175e-01  1.47605673e+00  1.52902020e+00  4.75293563e-01
 -1.69092785e+00  1.53332838e+00 -8.60480187e-01 -8.94916352e-01
 -2.63134757e+00 -4.85484509e-01 -9.24586204e-01 -7.47545215e-01
  1.58453160e-01 -1.76281183e+00  1.45662312e+00  1.03391908e+00
  1.91047772e-01  2.50100964e+00 -2.08886652e+00  1.31434128e-02
 -1.37238569e+00 -7.00204647e-01 -3.46303571e-01 -1.49959529e+00
  7.66369612e-01  1.13000235e+00  6.32032672e-01  1.79168180e+00
  1.32162554e+00  6.61235744e-01 -5.45545223e-01 -2.37985535e+00
  2.13941757e+00  2.24374222e+00 -8.87951928e-02  1.35917024e+00
  2.50344973e+01]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2813.965539852461
gradient value of function right now is: [ 4.63489410e-09  1.02815993e-09  4.63774022e-09  4.63831416e-09
 -4.63515781e-09 -1.02821815e-09 -4.63800401e-09 -4.63857820e-09
  8.74202801e-11  2.57909751e-11  1.40742063e-10  1.08678207e-10
  9.22201298e-10  1.76019363e-10  9.99135627e-10  1.02040819e-09
  4.81205624e-11  1.73100899e-11  9.31017146e-11  6.38895916e-11
  4.69453726e-11  1.47865110e-11  8.02887414e-11  5.95858611e-11
 -4.94651324e-11 -4.09197084e-11 -8.06270669e-11 -1.36354313e-11
 -3.83549057e-12 -7.20236072e-12 -9.86041975e-12 -1.26254624e-12
  1.20749244e-10 -1.32157969e-10 -2.60684840e-11  2.27214237e-11
  8.41535082e-12 -5.96437258e-11 -5.14307294e-11 -6.30379843e-13
 -1.11398562e-11  4.54782144e-11 -2.75758454e-11 -1.11573946e-11
  1.00232357e-11 -2.64813506e-11  2.10710620e-11  1.07579973e-11
 -7.83366155e-12  1.21473274e-11 -1.39116412e-11 -9.44034911e-12
 -5.31316613e-12  1.60525302e-11 -1.08687232e-11 -6.62893179e-12
  5.32176372e-14  4.61140328e-12  1.99095680e-11  1.56715035e-12
 -1.43695030e-11 -1.75852911e-12 -7.43275454e-12 -7.89730137e-12
 -5.86767871e+00]
supnorm grad right now is: 5.867678711348103
Weights right now are: 
[-4.76841252e+00 -7.12743740e-01 -3.50399661e+00 -4.33676306e+00
  5.02298143e+00  6.04052087e-01  3.90293408e+00  3.62073488e+00
 -2.06365137e+00 -7.76740845e-01 -2.14687258e+00 -1.81381009e+00
  1.22093356e+00  3.05957757e-01 -3.65818370e-01  5.02035183e-01
 -1.46262587e+00 -5.01099706e-01 -2.49558429e+00 -2.16571717e+00
 -2.28321074e+00 -8.43782321e-01 -2.25383363e+00 -1.85405643e+00
 -8.49556974e-01 -4.76755457e-01 -1.45450999e+00 -7.15854482e-01
  4.14257646e-01  1.47607572e+00  1.52904531e+00  4.75296539e-01
 -1.69114344e+00  1.53369304e+00 -8.60301914e-01 -8.94950284e-01
 -2.63135775e+00 -4.85331146e-01 -9.24442853e-01 -7.47540492e-01
  1.58497699e-01 -1.76289356e+00  1.45670918e+00  1.03397487e+00
  1.91011918e-01  2.50105650e+00 -2.08893088e+00  1.30980681e-02
 -1.37236200e+00 -7.00226471e-01 -3.46264247e-01 -1.49956437e+00
  7.66386643e-01  1.12997243e+00  6.32063505e-01  1.79170466e+00
  1.32162651e+00  6.61223789e-01 -5.45576811e-01 -2.37986890e+00
  2.13943733e+00  2.24376071e+00 -8.87836988e-02  1.35919133e+00
  2.44831705e+01]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.3333973408594
gradient value of function right now is: [ 3.93160107e-09  8.78126724e-10  3.93451600e-09  3.93379916e-09
 -3.93178365e-09 -8.78167096e-10 -3.93469863e-09 -3.93398193e-09
  4.77992580e-11  2.11114965e-11  1.11202517e-10  6.83729726e-11
  7.88681000e-10  1.57382183e-10  8.85859214e-10  8.81046205e-10
  1.77219905e-11  1.38161415e-11  7.09094263e-11  3.30865861e-11
  2.30533741e-11  1.19975466e-11  6.26357516e-11  3.53222950e-11
 -4.71530702e-11 -4.56863570e-11 -8.35661531e-11 -1.34159594e-11
 -4.04448542e-12 -8.63734595e-12 -1.15579868e-11 -1.39860145e-12
  1.02828859e-10 -1.65079631e-10 -7.59291859e-11  1.66134928e-11
  5.15157565e-12 -6.99067091e-11 -6.48355313e-11 -2.02058178e-12
 -1.94428262e-11  3.89544125e-11 -3.84528106e-11 -2.41996734e-11
  1.57948436e-11 -2.24137568e-11  2.88287866e-11  1.98814936e-11
 -1.06193689e-11  1.03575321e-11 -1.77652369e-11 -1.38277391e-11
 -7.58612434e-12  1.41638594e-11 -1.39181065e-11 -1.01745990e-11
 -4.20742273e-13  5.46476990e-12  1.51963298e-11  5.79581318e-12
 -9.58409833e-12 -7.95631809e-12 -5.55926814e-12 -9.60848499e-12
 -8.97079264e-01]
supnorm grad right now is: 0.8970792635025188
Weights right now are: 
[-4.77628964e+00 -7.14500372e-01 -3.51187970e+00 -4.34464440e+00
  5.03085859e+00  6.05808727e-01  3.91081720e+00  3.62861626e+00
 -2.06373996e+00 -7.76782893e-01 -2.14709280e+00 -1.81394050e+00
  1.21935710e+00  3.05641163e-01 -3.67597914e-01  5.00271751e-01
 -1.46265516e+00 -5.01127111e-01 -2.49572386e+00 -2.16577769e+00
 -2.28325236e+00 -8.43806177e-01 -2.25395738e+00 -1.85412299e+00
 -8.49461334e-01 -4.76661321e-01 -1.45433903e+00 -7.15827163e-01
  4.14265895e-01  1.47609367e+00  1.52906924e+00  4.75299414e-01
 -1.69134856e+00  1.53403737e+00 -8.60134904e-01 -8.94982600e-01
 -2.63136740e+00 -4.85186442e-01 -9.24307643e-01 -7.47536015e-01
  1.58539756e-01 -1.76297108e+00  1.45679071e+00  1.03402777e+00
  1.90978068e-01  2.50110095e+00 -2.08899183e+00  1.30551007e-02
 -1.37233960e+00 -7.00247116e-01 -3.46227001e-01 -1.49953506e+00
  7.66402718e-01  1.12994403e+00  6.32092700e-01  1.79172632e+00
  1.32162745e+00  6.61212513e-01 -5.45606574e-01 -2.37988206e+00
  2.13945572e+00  2.24377875e+00 -8.87728537e-02  1.35921150e+00
  2.49140310e+01]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.353373434515
gradient value of function right now is: [ 3.62628393e-09  8.13718991e-10  3.62911443e-09  3.62810921e-09
 -3.62648819e-09 -8.13764448e-10 -3.62931874e-09 -3.62831375e-09
  3.65646112e-11  1.92661983e-11  1.00299981e-10  5.62844293e-11
  7.31865824e-10  1.47999496e-10  8.30998372e-10  8.19978199e-10
  9.73844089e-12  1.25089326e-11  6.31694534e-11  2.44979675e-11
  1.64771525e-11  1.09213077e-11  5.62687599e-11  2.82500911e-11
 -4.52156077e-11 -4.53187756e-11 -8.16474910e-11 -1.29637317e-11
 -4.02233611e-12 -8.70210563e-12 -1.16391625e-11 -1.40029507e-12
  9.52109561e-11 -1.67657542e-10 -8.54682360e-11  1.46098201e-11
  4.17894098e-12 -7.00876708e-11 -6.59553114e-11 -2.29472454e-12
 -2.08267820e-11  3.60858631e-11 -3.98478477e-11 -2.65927738e-11
  1.66855064e-11 -2.06968176e-11  2.97864442e-11  2.14632832e-11
 -1.09489685e-11  9.56707280e-12 -1.81221110e-11 -1.44467188e-11
 -7.88893203e-12  1.32429533e-11 -1.42054893e-11 -1.07064866e-11
 -5.25397054e-13  5.48940193e-12  1.35465659e-11  6.64382846e-12
 -8.09770839e-12 -9.22222434e-12 -4.91892065e-12 -9.71706457e-12
  5.07085587e-01]
supnorm grad right now is: 0.5070855865511765
Weights right now are: 
[-4.78385508e+00 -7.16194039e-01 -3.51945090e+00 -4.35221384e+00
  5.03842401e+00  6.07502391e-01  3.91838839e+00  3.63618568e+00
 -2.06382366e+00 -7.76823292e-01 -2.14730420e+00 -1.81406460e+00
  1.21783492e+00  3.05335139e-01 -3.69317649e-01  4.98568568e-01
 -1.46268202e+00 -5.01153439e-01 -2.49585779e+00 -2.16583474e+00
 -2.28329146e+00 -8.43829105e-01 -2.25407620e+00 -1.85418619e+00
 -8.49368617e-01 -4.76570033e-01 -1.45417329e+00 -7.15800678e-01
  4.14274024e-01  1.47611108e+00  1.52909256e+00  4.75302231e-01
 -1.69154663e+00  1.53437169e+00 -8.59971673e-01 -8.95013809e-01
 -2.63137664e+00 -4.85045909e-01 -9.24176193e-01 -7.47531664e-01
  1.58580480e-01 -1.76304593e+00  1.45686953e+00  1.03407917e+00
  1.90945253e-01  2.50114394e+00 -2.08905083e+00  1.30133166e-02
 -1.37231791e+00 -7.00267015e-01 -3.46190965e-01 -1.49950662e+00
  7.66418296e-01  1.12991660e+00  6.32120947e-01  1.79174734e+00
  1.32162842e+00  6.61201500e-01 -5.45635175e-01 -2.37989454e+00
  2.13947332e+00  2.24379601e+00 -8.87624405e-02  1.35923083e+00
  2.50383820e+01]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.278210791777
gradient value of function right now is: [ 3.63657967e-09  8.17839169e-10  3.63922039e-09  3.63868378e-09
 -3.63673468e-09 -8.17873800e-10 -3.63937544e-09 -3.63883902e-09
  4.71239636e-11  1.96543596e-11  1.04018373e-10  6.59408599e-11
  7.36669969e-10  1.46209939e-10  8.23920386e-10  8.22025846e-10
  1.89147961e-11  1.29196282e-11  6.67322344e-11  3.29779782e-11
  2.31910105e-11  1.11941577e-11  5.87518622e-11  3.44214416e-11
 -4.36810106e-11 -4.12682224e-11 -7.63647843e-11 -1.23667540e-11
 -3.82663048e-12 -7.75820981e-12 -1.05246845e-11 -1.30101328e-12
  9.59362144e-11 -1.47672049e-10 -6.43455166e-11  1.58314836e-11
  5.00486861e-12 -6.28952702e-11 -5.79690683e-11 -1.71515082e-12
 -1.69256701e-11  3.62636590e-11 -3.40431686e-11 -2.07973209e-11
  1.38602028e-11 -2.09361829e-11  2.55892574e-11  1.72600857e-11
 -9.43005825e-12  9.59931834e-12 -1.58485776e-11 -1.22030085e-11
 -6.70657302e-12  1.31228473e-11 -1.24157923e-11 -8.94569788e-12
 -3.41111260e-13  4.90116675e-12  1.43830521e-11  4.85661045e-12
 -9.25945872e-12 -6.63885462e-12 -5.27538050e-12 -8.61046936e-12
 -1.49393828e+00]
supnorm grad right now is: 1.4939382766301834
Weights right now are: 
[-4.79104827e+00 -7.17810459e-01 -3.52664961e+00 -4.35941079e+00
  5.04561720e+00  6.09118810e-01  3.92558709e+00  3.64338264e+00
 -2.06390155e+00 -7.76861683e-01 -2.14750495e+00 -1.81418112e+00
  1.21638009e+00  3.05042388e-01 -3.70963135e-01  4.96940313e-01
 -1.46270602e+00 -5.01178449e-01 -2.49598486e+00 -2.16588765e+00
 -2.28332757e+00 -8.43850897e-01 -2.25418903e+00 -1.85424536e+00
 -8.49279644e-01 -4.76482261e-01 -1.45401398e+00 -7.15775259e-01
  4.14281928e-01  1.47612786e+00  1.52911511e+00  4.75304965e-01
 -1.69173588e+00  1.53469401e+00 -8.59812984e-01 -8.95043388e-01
 -2.63138533e+00 -4.84910651e-01 -9.24049494e-01 -7.47527403e-01
  1.58619903e-01 -1.76311764e+00  1.45694571e+00  1.03412905e+00
  1.90913482e-01  2.50118512e+00 -2.08910789e+00  1.29727621e-02
 -1.37229696e+00 -7.00285990e-01 -3.46156207e-01 -1.49947912e+00
  7.66433350e-01  1.12989041e+00  6.32148201e-01  1.79176767e+00
  1.32162936e+00  6.61190952e-01 -5.45662489e-01 -2.37990707e+00
  2.13948979e+00  2.24381325e+00 -8.87524817e-02  1.35924960e+00
  2.48978476e+01]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.1683209981447
gradient value of function right now is: [ 3.17572138e-09  7.18586795e-10  3.17837206e-09  3.17707412e-09
 -3.17592874e-09 -7.18633241e-10 -3.17857947e-09 -3.17728177e-09
  2.28662860e-11  1.66283019e-11  8.51204141e-11  4.10508881e-11
  6.47994822e-10  1.33417400e-10  7.46694179e-10  7.28941779e-10
  4.67726862e-13  1.06762435e-11  5.26400998e-11  1.41213368e-11
  8.59967777e-12  9.39421311e-12  4.74818637e-11  1.94747845e-11
 -4.18587242e-11 -4.35818808e-11 -7.72234433e-11 -1.21109129e-11
 -3.92300194e-12 -8.52489651e-12 -1.14294808e-11 -1.37205222e-12
  8.39945049e-11 -1.65787175e-10 -9.37128978e-11  1.19469125e-11
  2.95643292e-12 -6.82698235e-11 -6.53191818e-11 -2.54104617e-12
 -2.18091165e-11  3.18323500e-11 -4.03151388e-11 -2.85470639e-11
  1.72329149e-11 -1.81795505e-11  3.00508745e-11  2.26565654e-11
 -1.10109164e-11  8.39306478e-12 -1.80114652e-11 -1.47340635e-11
 -8.00739152e-12  1.18283622e-11 -1.41293403e-11 -1.10020738e-11
 -6.28088098e-13  5.35344876e-12  1.13118088e-11  7.44943347e-12
 -6.18381169e-12 -1.04377225e-11 -4.06233841e-12 -9.58017094e-12
  2.33333132e+00]
supnorm grad right now is: 2.333331321185998
Weights right now are: 
[-4.79793250e+00 -7.19362728e-01 -3.53353909e+00 -4.36629864e+00
  5.05250143e+00  6.10671079e-01  3.93247657e+00  3.65027049e+00
 -2.06397718e+00 -7.76898483e-01 -2.14769758e+00 -1.81429365e+00
  1.21498107e+00  3.04761176e-01 -3.72544238e-01  4.95374849e-01
 -1.46272993e+00 -5.01202452e-01 -2.49610698e+00 -2.16593919e+00
 -2.28336283e+00 -8.43871801e-01 -2.25429740e+00 -1.85430266e+00
 -8.49194088e-01 -4.76398590e-01 -1.45386150e+00 -7.15750852e-01
  4.14289625e-01  1.47614386e+00  1.52913673e+00  4.75307611e-01
 -1.69191761e+00  1.53500100e+00 -8.59663244e-01 -8.95071844e-01
 -2.63139369e+00 -4.84781797e-01 -9.23928909e-01 -7.47523347e-01
  1.58657317e-01 -1.76318641e+00  1.45701836e+00  1.03417642e+00
  1.90883318e-01  2.50122462e+00 -2.08916230e+00  1.29342100e-02
 -1.37227701e+00 -7.00304141e-01 -3.46123017e-01 -1.49945290e+00
  7.66447663e-01  1.12986532e+00  6.32174210e-01  1.79178703e+00
  1.32163027e+00  6.61180878e-01 -5.45688789e-01 -2.37991908e+00
  2.13950554e+00  2.24382988e+00 -8.87428813e-02  1.35926758e+00
  2.51886758e+01]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2814.5801030052394
gradient value of function right now is: [ 2.86475903e-09  6.51664688e-10  2.86737204e-09  2.86566608e-09
 -2.86460710e-09 -6.51630528e-10 -2.86722008e-09 -2.86551394e-09
  8.78226472e-12  1.46535253e-11  7.30810865e-11  2.63201366e-11
  5.88261325e-10  1.24233196e-10  6.92075922e-10  6.65546620e-10
 -9.98401778e-12  9.23894486e-12  4.38351800e-11  3.22267108e-12
  2.05402075e-13  8.22822437e-12  4.03571145e-11  1.07081335e-11
 -4.02562855e-11 -4.41859681e-11 -7.65447239e-11 -1.17979629e-11
 -3.94110136e-12 -8.82592854e-12 -1.17835578e-11 -1.39737336e-12
  7.59460659e-11 -1.73494926e-10 -1.08910007e-10  9.55465904e-12
  1.73590735e-12 -7.02253283e-11 -6.84533264e-11 -2.97507966e-12
 -2.42667630e-11  2.88098247e-11 -4.32982120e-11 -3.25596806e-11
  1.89001614e-11 -1.63227627e-11  3.21571220e-11  2.54134338e-11
 -1.17420987e-11  7.56786863e-12 -1.89706304e-11 -1.59557763e-11
 -8.62427271e-12  1.09093339e-11 -1.48915053e-11 -1.20089977e-11
 -7.84191117e-13  5.52425822e-12  9.35376947e-12  8.88005754e-12
 -4.29901145e-12 -1.25137950e-11 -3.29808670e-12 -1.00070652e-11
  4.78320698e+00]
supnorm grad right now is: 4.7832069771139585
Weights right now are: 
[-4.80453553e+00 -7.20856560e-01 -3.54014715e+00 -4.37290515e+00
  5.05910446e+00  6.12164910e-01  3.93908464e+00  3.65687699e+00
 -2.06404990e+00 -7.76933823e-01 -2.14788263e+00 -1.81440181e+00
  1.21363297e+00  3.04490279e-01 -3.74067458e-01  4.93866424e-01
 -1.46275298e+00 -5.01225517e-01 -2.49622438e+00 -2.16598879e+00
 -2.28339676e+00 -8.43891886e-01 -2.25440156e+00 -1.85435778e+00
 -8.49111557e-01 -4.76318193e-01 -1.45371476e+00 -7.15727314e-01
  4.14297142e-01  1.47615923e+00  1.52915759e+00  4.75310183e-01
 -1.69209268e+00  1.53529582e+00 -8.59519964e-01 -8.95099332e-01
 -2.63140177e+00 -4.84657982e-01 -9.23813090e-01 -7.47519462e-01
  1.58693048e-01 -1.76325266e+00  1.45708794e+00  1.03422174e+00
  1.90854476e-01  2.50126275e+00 -2.08921445e+00  1.28973102e-02
 -1.37225789e+00 -7.00321588e-01 -3.46091166e-01 -1.49942773e+00
  7.66461379e-01  1.12984117e+00  6.32199167e-01  1.79180562e+00
  1.32163116e+00  6.61171202e-01 -5.45714073e-01 -2.37993049e+00
  2.13952079e+00  2.24384582e+00 -8.87336822e-02  1.35928482e+00
  2.53227859e+01]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.267557535773
gradient value of function right now is: [ 3.21969573e-09  7.31197251e-10  3.22202854e-09  3.22155746e-09
 -3.21949462e-09 -7.31151976e-10 -3.22182738e-09 -3.22135609e-09
  4.19500474e-11  1.74541085e-11  9.24375367e-11  5.86604377e-11
  6.61123196e-10  1.31129132e-10  7.39131898e-10  7.37674334e-10
  1.69169917e-11  1.14948943e-11  5.94250933e-11  2.94276995e-11
  2.06956537e-11  9.95598571e-12  5.22935238e-11  3.06826432e-11
 -3.93688430e-11 -3.66739335e-11 -6.83147589e-11 -1.11200529e-11
 -3.58217493e-12 -6.89983211e-12 -9.50503498e-12 -1.19965781e-12
  8.58981070e-11 -1.31193848e-10 -5.65727307e-11  1.42285387e-11
  4.46510696e-12 -5.59056914e-11 -5.15069688e-11 -1.51832135e-12
 -1.49706991e-11  3.23887237e-11 -3.01858477e-11 -1.83607947e-11
  1.22853080e-11 -1.87438931e-11  2.27244878e-11  1.52740519e-11
 -8.36918760e-12  8.52150817e-12 -1.40652180e-11 -1.08192485e-11
 -5.94689440e-12  1.17042930e-11 -1.10216699e-11 -7.92585137e-12
 -3.01416044e-13  4.34208930e-12  1.28820732e-11  4.27439840e-12
 -8.31830469e-12 -5.83711386e-12 -4.72764393e-12 -7.65583768e-12
 -1.58405093e+00]
supnorm grad right now is: 1.584050927099878
Weights right now are: 
[-4.81085868e+00 -7.22291902e-01 -3.54647516e+00 -4.37923158e+00
  5.06542761e+00  6.13600253e-01  3.94541264e+00  3.66320342e+00
 -2.06411777e+00 -7.76967658e-01 -2.14805953e+00 -1.81450386e+00
  1.21233610e+00  3.04229246e-01 -3.75534772e-01  4.92414768e-01
 -1.46277345e+00 -5.01247588e-01 -2.49633650e+00 -2.16603489e+00
 -2.28342814e+00 -8.43911118e-01 -2.25450112e+00 -1.85440959e+00
 -8.49031784e-01 -4.76240243e-01 -1.45357269e+00 -7.15704563e-01
  4.14304506e-01  1.47617414e+00  1.52917790e+00  4.75312691e-01
 -1.69226111e+00  1.53558235e+00 -8.59379138e-01 -8.95125731e-01
 -2.63140944e+00 -4.84537691e-01 -9.23700403e-01 -7.47515675e-01
  1.58728076e-01 -1.76331628e+00  1.45715556e+00  1.03426572e+00
  1.90826260e-01  2.50129939e+00 -2.08926512e+00  1.28615480e-02
 -1.37223925e+00 -7.00338335e-01 -3.46060278e-01 -1.49940338e+00
  7.66474775e-01  1.12981794e+00  6.32223396e-01  1.79182362e+00
  1.32163195e+00  6.61161854e-01 -5.45738756e-01 -2.37994120e+00
  2.13953618e+00  2.24386044e+00 -8.87246998e-02  1.35930140e+00
  2.48320049e+01]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.2794270857485
gradient value of function right now is: [ 2.87623056e-09  6.56691225e-10  2.87856527e-09  2.87754250e-09
 -2.87640074e-09 -6.56729648e-10 -2.87873548e-09 -2.87771294e-09
  2.41741171e-11  1.52045635e-11  7.84376816e-11  4.03808717e-11
  5.94354916e-10  1.21403679e-10  6.80568048e-10  6.67472948e-10
  3.41596688e-12  9.82877783e-12  4.89962461e-11  1.55963435e-11
  1.00013726e-11  8.61757834e-12  4.39426224e-11  1.97037816e-11
 -3.79106208e-11 -3.82580604e-11 -6.87319317e-11 -1.08975308e-11
 -3.63562348e-12 -7.43795555e-12 -1.01302830e-11 -1.24637262e-12
  7.69531223e-11 -1.44098730e-10 -7.78859342e-11  1.13568155e-11
  2.96372542e-12 -5.96923663e-11 -5.67415827e-11 -2.11531092e-12
 -1.84921390e-11  2.90767024e-11 -3.46762386e-11 -2.39542168e-11
  1.47173562e-11 -1.66845557e-11  2.59219990e-11  1.91702513e-11
 -9.49956476e-12  7.62272195e-12 -1.56036177e-11 -1.26323236e-11
 -6.88072035e-12  1.07299853e-11 -1.22421279e-11 -9.40300325e-12
 -5.08224084e-13  4.66112012e-12  1.06181739e-11  6.14407301e-12
 -6.06813934e-12 -8.57033625e-12 -3.83429885e-12 -8.33830690e-12
  1.51747768e+00]
supnorm grad right now is: 1.5174776812495259
Weights right now are: 
[-4.81695925e+00 -7.23680960e-01 -3.55258041e+00 -4.38533532e+00
  5.07152819e+00  6.14989313e-01  3.95151790e+00  3.66930717e+00
 -2.06418363e+00 -7.77000336e-01 -2.14823041e+00 -1.81460269e+00
  1.21107953e+00  3.03976347e-01 -3.76956160e-01  4.91008252e-01
 -1.46279353e+00 -5.01268921e-01 -2.49644488e+00 -2.16607970e+00
 -2.28345866e+00 -8.43929701e-01 -2.25459735e+00 -1.85445983e+00
 -8.48954321e-01 -4.76165180e-01 -1.45343538e+00 -7.15682493e-01
  4.14311757e-01  1.47618851e+00  1.52919760e+00  4.75315146e-01
 -1.69242401e+00  1.53585840e+00 -8.59243819e-01 -8.95151327e-01
 -2.63141683e+00 -4.84421849e-01 -9.23591849e-01 -7.47512028e-01
  1.58761863e-01 -1.76337765e+00  1.45722073e+00  1.03430829e+00
  1.90799021e-01  2.50133476e+00 -2.08931399e+00  1.28269332e-02
 -1.37222130e+00 -7.00354462e-01 -3.46030549e-01 -1.49937990e+00
  7.66487676e-01  1.12979549e+00  6.32246722e-01  1.79184099e+00
  1.32163274e+00  6.61152864e-01 -5.45762269e-01 -2.37995166e+00
  2.13955074e+00  2.24387475e+00 -8.87161319e-02  1.35931741e+00
  2.50770753e+01]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.3609540515736
gradient value of function right now is: [ 2.86143269e-09  6.54598207e-10  2.86365116e-09  2.86288117e-09
 -2.86134327e-09 -6.54577921e-10 -2.86356171e-09 -2.86279164e-09
  2.95657498e-11  1.53041704e-11  7.98551481e-11  4.51865793e-11
  5.93142139e-10  1.19678092e-10  6.72470180e-10  6.64328496e-10
  8.23372845e-12  9.97858842e-12  5.05429482e-11  1.99646691e-11
  1.34739215e-11  8.70272647e-12  4.49528965e-11  2.28246758e-11
 -3.68601212e-11 -3.58698759e-11 -6.55011838e-11 -1.05125490e-11
 -3.51321202e-12 -6.89104453e-12 -9.47998649e-12 -1.18683072e-12
  7.68406391e-11 -1.32555981e-10 -6.61724546e-11  1.19335064e-11
  3.38180107e-12 -5.54948516e-11 -5.21441912e-11 -1.79397687e-12
 -1.62956012e-11  2.89829246e-11 -3.13581060e-11 -2.07260009e-11
  1.31165071e-11 -1.67061908e-11  2.35155231e-11  1.68142893e-11
 -8.63090729e-12  7.58968123e-12 -1.42928153e-11 -1.13612826e-11
 -6.20759860e-12  1.05969253e-11 -1.12102532e-11 -8.40853555e-12
 -4.08117761e-13  4.31892745e-12  1.09747403e-11  5.15148922e-12
 -6.62843170e-12 -7.13916360e-12 -3.99303260e-12 -7.69541363e-12
  2.33220544e-01]
supnorm grad right now is: 0.23322054384794583
Weights right now are: 
[-4.82275560e+00 -7.25005138e-01 -3.55838128e+00 -4.39113457e+00
  5.07732454e+00  6.16313490e-01  3.95731876e+00  3.67510642e+00
 -2.06424241e+00 -7.77031291e-01 -2.14839184e+00 -1.81469322e+00
  1.20988033e+00  3.03734215e-01 -3.78316865e-01  4.89664867e-01
 -1.46280922e+00 -5.01289084e-01 -2.49654692e+00 -2.16611923e+00
 -2.28348524e+00 -8.43947296e-01 -2.25468817e+00 -1.85450541e+00
 -8.48879782e-01 -4.76091983e-01 -1.45330224e+00 -7.15661213e-01
  4.14318816e-01  1.47620257e+00  1.52921685e+00  4.75317540e-01
 -1.69257965e+00  1.53612903e+00 -8.59107731e-01 -8.95175396e-01
 -2.63142367e+00 -4.84308515e-01 -9.23485298e-01 -7.47508353e-01
  1.58794991e-01 -1.76343657e+00  1.45728453e+00  1.03435061e+00
  1.90772333e-01  2.50136873e+00 -2.08936186e+00  1.27925883e-02
 -1.37220372e+00 -7.00369896e-01 -3.46001424e-01 -1.49935668e+00
  7.66500321e-01  1.12977399e+00  6.32269559e-01  1.79185818e+00
  1.32163361e+00  6.61144016e-01 -5.45784512e-01 -2.37996201e+00
  2.13956397e+00  2.24388940e+00 -8.87080701e-02  1.35933301e+00
  2.50149916e+01]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.2744659036557
gradient value of function right now is: [ 2.88063291e-09  6.60022068e-10  2.88272727e-09  2.88228230e-09
 -2.88071629e-09 -6.60041031e-10 -2.88281067e-09 -2.88236581e-09
  3.71363214e-11  1.56420891e-11  8.28047576e-11  5.21846092e-11
  5.98793369e-10  1.18846424e-10  6.69910535e-10  6.68271696e-10
  1.47604969e-11  1.03103680e-11  5.32663713e-11  2.60461602e-11
  1.82755360e-11  8.93155324e-12  4.68892623e-11  2.72806489e-11
 -3.58903037e-11 -3.31674413e-11 -6.20208571e-11 -1.01257290e-11
 -3.37675709e-12 -6.25410944e-12 -8.72334552e-12 -1.11854852e-12
  7.76452644e-11 -1.18923569e-10 -5.14805114e-11  1.28434955e-11
  3.98196185e-12 -5.06299138e-11 -4.67020377e-11 -1.39061853e-12
 -1.35992219e-11  2.92248059e-11 -2.73754809e-11 -1.67023647e-11
  1.11624264e-11 -1.69419299e-11  2.06293189e-11  1.38935793e-11
 -7.59153732e-12  7.64691041e-12 -1.27436822e-11 -9.81972474e-12
 -5.39572134e-12  1.05549020e-11 -9.98902334e-12 -7.19540421e-12
 -2.79281418e-13  3.92214492e-12  1.16200669e-11  3.89960741e-12
 -7.48831329e-12 -5.33088289e-12 -4.26354234e-12 -6.93976878e-12
 -1.52759764e+00]
supnorm grad right now is: 1.527597636133597
Weights right now are: 
[-4.82842660e+00 -7.26303962e-01 -3.56405661e+00 -4.39680851e+00
  5.08299553e+00  6.17612312e-01  3.96299410e+00  3.68078035e+00
 -2.06430384e+00 -7.77061714e-01 -2.14855098e+00 -1.81478534e+00
  1.20870276e+00  3.03497286e-01 -3.79648658e-01  4.88346803e-01
 -1.46282805e+00 -5.01308965e-01 -2.49664798e+00 -2.16616110e+00
 -2.28351376e+00 -8.43964611e-01 -2.25477787e+00 -1.85455230e+00
 -8.48806965e-01 -4.76022114e-01 -1.45317385e+00 -7.15640487e-01
  4.14325778e-01  1.47621597e+00  1.52923538e+00  4.75319880e-01
 -1.69273199e+00  1.53638614e+00 -8.58982240e-01 -8.95199324e-01
 -2.63143053e+00 -4.84200676e-01 -9.23384239e-01 -7.47504934e-01
  1.58826295e-01 -1.76349390e+00  1.45734522e+00  1.03439045e+00
  1.90747066e-01  2.50140180e+00 -2.08940741e+00  1.27601794e-02
 -1.37218702e+00 -7.00384902e-01 -3.45973693e-01 -1.49933469e+00
  7.66512305e-01  1.12975304e+00  6.32291304e-01  1.79187443e+00
  1.32163439e+00  6.61135626e-01 -5.45806108e-01 -2.37997201e+00
  2.13957700e+00  2.24390331e+00 -8.87001990e-02  1.35934805e+00
  2.48308942e+01]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.2022084764944
gradient value of function right now is: [ 2.81941727e-09  6.47525018e-10  2.82142776e-09  2.82108432e-09
 -2.81953595e-09 -6.47551945e-10 -2.82154647e-09 -2.82120309e-09
  3.84303559e-11  1.53842457e-11  8.17737331e-11  5.29798408e-11
  5.88087616e-10  1.16160277e-10  6.55391671e-10  6.55652716e-10
  1.62718274e-11  1.01745448e-11  5.28548969e-11  2.71824936e-11
  1.92221897e-11  8.79688142e-12  4.63939373e-11  2.79301959e-11
 -3.49094235e-11 -3.16718939e-11 -5.97370906e-11 -9.81410847e-12
 -3.29380381e-12 -5.93748700e-12 -8.34254910e-12 -1.08195763e-12
  7.62443901e-11 -1.12444169e-10 -4.61124050e-11  1.28375091e-11
  4.06391272e-12 -4.81390277e-11 -4.41327336e-11 -1.24630494e-12
 -1.25235382e-11  2.86696035e-11 -2.56384132e-11 -1.51856158e-11
  1.03558907e-11 -1.66554244e-11  1.93573280e-11  1.27556582e-11
 -7.12911957e-12  7.49132556e-12 -1.20250915e-11 -9.16846714e-12
 -5.04520898e-12  1.03153730e-11 -9.42351166e-12 -6.69343869e-12
 -2.38127238e-13  3.72258826e-12  1.15548936e-11  3.45879830e-12
 -7.56952703e-12 -4.70983138e-12 -4.24788531e-12 -6.57570223e-12
 -2.06129935e+00]
supnorm grad right now is: 2.0612993472777603
Weights right now are: 
[-4.83387119e+00 -7.27554578e-01 -3.56950539e+00 -4.40225590e+00
  5.08844012e+00  6.18862927e-01  3.96844287e+00  3.68622773e+00
 -2.06436176e+00 -7.77090911e-01 -2.14870362e+00 -1.81487286e+00
  1.20756770e+00  3.03268745e-01 -3.80933496e-01  4.87076063e-01
 -1.46284515e+00 -5.01328038e-01 -2.49674484e+00 -2.16620045e+00
 -2.28354047e+00 -8.43981231e-01 -2.25486390e+00 -1.85459674e+00
 -8.48736569e-01 -4.75954415e-01 -1.45304954e+00 -7.15620456e-01
  4.14332571e-01  1.47622896e+00  1.52925338e+00  4.75322158e-01
 -1.69287885e+00  1.53663573e+00 -8.58859625e-01 -8.95222289e-01
 -2.63143708e+00 -4.84096071e-01 -9.23286126e-01 -7.47501592e-01
  1.58856820e-01 -1.76354920e+00  1.45740423e+00  1.03442911e+00
  1.90722451e-01  2.50143371e+00 -2.08945168e+00  1.27287428e-02
 -1.37217078e+00 -7.00399338e-01 -3.45946768e-01 -1.49931337e+00
  7.66523968e-01  1.12973286e+00  6.32312424e-01  1.79189019e+00
  1.32163513e+00  6.61127515e-01 -5.45827145e-01 -2.37998175e+00
  2.13958991e+00  2.24391658e+00 -8.86925262e-02  1.35936264e+00
  2.48401690e+01]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.3630713834855
gradient value of function right now is: [ 2.59474861e-09  5.98462212e-10  2.59674807e-09  2.59607415e-09
 -2.59483892e-09 -5.98482855e-10 -2.59683841e-09 -2.59616456e-09
  2.74328027e-11  1.39278959e-11  7.27978732e-11  4.15885071e-11
  5.43976708e-10  1.09563240e-10  6.15919861e-10  6.09064855e-10
  7.98468111e-12  9.10231307e-12  4.62106278e-11  1.86291981e-11
  1.26223093e-11  7.93203434e-12  4.10505505e-11  2.11051403e-11
 -3.38196894e-11 -3.24282147e-11 -5.96214072e-11 -9.61974066e-12
 -3.30835718e-12 -6.22575311e-12 -8.67104785e-12 -1.10405511e-12
  7.03550669e-11 -1.19608871e-10 -5.87922818e-11  1.10174563e-11
  3.12770988e-12 -5.01440143e-11 -4.70440013e-11 -1.60029530e-12
 -1.45933912e-11  2.64817416e-11 -2.82070442e-11 -1.84984908e-11
  1.17801318e-11 -1.52995364e-11  2.11859537e-11  1.50568581e-11
 -7.77155497e-12  6.89972799e-12 -1.28800041e-11 -1.02100603e-11
 -5.58239870e-12  9.66159917e-12 -1.01045576e-11 -7.54893437e-12
 -3.60464748e-13  3.89050272e-12  1.00886765e-11  4.58187119e-12
 -6.14333277e-12 -6.33443403e-12 -3.67579588e-12 -6.95252880e-12
  3.31845516e-02]
supnorm grad right now is: 0.033184551565287254
Weights right now are: 
[-4.83913996e+00 -7.28768079e-01 -3.57477821e+00 -4.40752738e+00
  5.09370888e+00  6.20076426e-01  3.97371568e+00  3.69149920e+00
 -2.06441801e+00 -7.77119202e-01 -2.14885156e+00 -1.81495780e+00
  1.20646525e+00  3.03046825e-01 -3.82181089e-01  4.85841876e-01
 -1.46286186e+00 -5.01346531e-01 -2.49683879e+00 -2.16623872e+00
 -2.28356645e+00 -8.43997342e-01 -2.25494733e+00 -1.85463991e+00
 -8.48668175e-01 -4.75888840e-01 -1.45292898e+00 -7.15601004e-01
  4.14339227e-01  1.47624153e+00  1.52927087e+00  4.75324381e-01
 -1.69302149e+00  1.53687725e+00 -8.58741416e-01 -8.95244704e-01
 -2.63144347e+00 -4.83994724e-01 -9.23191118e-01 -7.47498384e-01
  1.58886234e-01 -1.76360287e+00  1.45746112e+00  1.03446627e+00
  1.90698708e-01  2.50146471e+00 -2.08949439e+00  1.26984951e-02
 -1.37215509e+00 -7.00413339e-01 -3.45920763e-01 -1.49929281e+00
  7.66535234e-01  1.12971327e+00  6.32332825e-01  1.79190539e+00
  1.32163584e+00  6.61119647e-01 -5.45847677e-01 -2.37999087e+00
  2.13960263e+00  2.24392902e+00 -8.86850433e-02  1.35937665e+00
  2.49814649e+01]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2814.411265359414
gradient value of function right now is: [ 2.20372272e-09  5.11929574e-10  2.20577992e-09  2.20434816e-09
 -2.20385296e-09 -5.11959375e-10 -2.20591020e-09 -2.20447850e-09
  4.14716510e-12  1.12545792e-11  5.57778220e-11  1.79851090e-11
  4.65550868e-10  9.88964916e-11  5.50547754e-10  5.27508609e-10
 -1.00834164e-11  7.08056906e-12  3.32642277e-11  3.80549915e-13
 -1.52200399e-12  6.32574466e-12  3.07983914e-11  6.78982164e-12
 -3.25879537e-11 -3.53500366e-11 -6.15535321e-11 -9.53648102e-12
 -3.41839403e-12 -7.10706483e-12 -9.69441170e-12 -1.18491028e-12
  5.98210826e-11 -1.40219624e-10 -8.94477504e-11  7.33541524e-12
  1.15119342e-12 -5.65134029e-11 -5.53177029e-11 -2.46015349e-12
 -1.98047193e-11  2.25890794e-11 -3.51226493e-11 -2.66949843e-11
  1.54250104e-11 -1.28279422e-11  2.61387361e-11  2.08283386e-11
 -9.51403169e-12  5.85166387e-12 -1.53231722e-11 -1.29638369e-11
 -7.00084026e-12  8.57297893e-12 -1.20390805e-11 -9.77345426e-12
 -6.56794194e-13  4.42574185e-12  7.18235680e-12  7.35198191e-12
 -3.13957811e-12 -1.03712368e-11 -2.52305866e-12 -8.09361990e-12
  5.28470389e+00]
supnorm grad right now is: 5.284703889274718
Weights right now are: 
[-4.84428267e+00 -7.29955514e-01 -3.57992484e+00 -4.41267275e+00
  5.09885158e+00  6.21263861e-01  3.97886231e+00  3.69664458e+00
 -2.06447421e+00 -7.77146865e-01 -2.14899643e+00 -1.81504189e+00
  1.20538538e+00  3.02829796e-01 -3.83401617e-01  4.84633364e-01
 -1.46287930e+00 -5.01364640e-01 -2.49693097e+00 -2.16627712e+00
 -2.28359264e+00 -8.44013107e-01 -2.25502909e+00 -1.85468281e+00
 -8.48601286e-01 -4.75825339e-01 -1.45281169e+00 -7.15582014e-01
  4.14345788e-01  1.47625371e+00  1.52928790e+00  4.75326561e-01
 -1.69316104e+00  1.53711076e+00 -8.58628547e-01 -8.95266735e-01
 -2.63144978e+00 -4.83896698e-01 -9.23099321e-01 -7.47495306e-01
  1.58914553e-01 -1.76365532e+00  1.45751608e+00  1.03450210e+00
  1.90675784e-01  2.50149504e+00 -2.08953572e+00  1.26692412e-02
 -1.37213995e+00 -7.00426995e-01 -3.45895650e-01 -1.49927294e+00
  7.66546094e-01  1.12969415e+00  6.32352531e-01  1.79192007e+00
  1.32163653e+00  6.61112059e-01 -5.45867640e-01 -2.37999981e+00
  2.13961477e+00  2.24394137e+00 -8.86777510e-02  1.35939028e+00
  2.52994942e+01]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.0902456139775
gradient value of function right now is: [ 2.27684104e-09  5.29075734e-10  2.27878252e-09  2.27774286e-09
 -2.27642121e-09 -5.28979479e-10 -2.27836257e-09 -2.27732250e-09
  1.41062128e-11  1.19345474e-11  6.08122523e-11  2.74935734e-11
  4.81644247e-10  9.96606783e-11  5.57509080e-10  5.42528246e-10
 -1.78666525e-12  7.66159525e-12  3.75141126e-11  8.31781115e-12
  4.70683233e-12  6.75704177e-12  3.39718783e-11  1.27436942e-11
 -3.18826089e-11 -3.25913429e-11 -5.82291080e-11 -9.20047706e-12
 -3.27512832e-12 -6.42332125e-12 -8.87863177e-12 -1.11097653e-12
  6.20689734e-11 -1.25331436e-10 -7.21508006e-11  8.68101857e-12
  1.97640795e-12 -5.13799384e-11 -4.93899193e-11 -1.97703222e-12
 -1.66650420e-11  2.33885973e-11 -3.05821838e-11 -2.19187857e-11
  1.31694283e-11 -1.34118166e-11  2.28574182e-11  1.73873300e-11
 -8.34769278e-12  6.06276384e-12 -1.36005824e-11 -1.11981353e-11
 -6.08269176e-12  8.69799464e-12 -1.06810114e-11 -8.37684259e-12
 -4.96393761e-13  4.00248221e-12  8.21503076e-12  5.77242488e-12
 -4.39075977e-12 -8.09401147e-12 -2.94343996e-12 -7.24037764e-12
  2.77963539e+00]
supnorm grad right now is: 2.7796353949775954
Weights right now are: 
[-4.84924877e+00 -7.31105296e-01 -3.58489476e+00 -4.41764141e+00
  5.10381767e+00  6.22413641e-01  3.98383222e+00  3.70161322e+00
 -2.06452736e+00 -7.77173573e-01 -2.14913616e+00 -1.81512212e+00
  1.20433883e+00  3.02619231e-01 -3.84585682e-01  4.83461818e-01
 -1.46289512e+00 -5.01382114e-01 -2.49701980e+00 -2.16631332e+00
 -2.28361721e+00 -8.44028329e-01 -2.25510796e+00 -1.85472362e+00
 -8.48536273e-01 -4.75763341e-01 -1.45269741e+00 -7.15563538e-01
  4.14352212e-01  1.47626560e+00  1.52930454e+00  4.75328695e-01
 -1.69329638e+00  1.53733906e+00 -8.58517357e-01 -8.95288030e-01
 -2.63145586e+00 -4.83800881e-01 -9.23009535e-01 -7.47492276e-01
  1.58942220e-01 -1.76370628e+00  1.45756981e+00  1.03453709e+00
  1.90653399e-01  2.50152452e+00 -2.08957612e+00  1.26406880e-02
 -1.37212515e+00 -7.00440235e-01 -3.45871074e-01 -1.49925350e+00
  7.66556717e-01  1.12967560e+00  6.32371805e-01  1.79193442e+00
  1.32163722e+00  6.61104608e-01 -5.45887253e-01 -2.38000842e+00
  2.13962682e+00  2.24395334e+00 -8.86706187e-02  1.35940351e+00
  2.51808850e+01]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.0003328679322
gradient value of function right now is: [ 2.54253623e-09  5.89504201e-10  2.54428331e-09  2.54412320e-09
 -2.54282806e-09 -5.89571285e-10 -2.54457521e-09 -2.54441538e-09
  3.81153501e-11  1.40155950e-11  7.50547435e-11  5.09665718e-11
  5.37496904e-10  1.05225712e-10  5.94782001e-10  5.98145116e-10
  1.77016575e-11  9.33331621e-12  4.89668121e-11  2.73452957e-11
  1.95623146e-11  8.04065463e-12  4.27580929e-11  2.72613350e-11
 -3.14331500e-11 -2.73315718e-11 -5.26111662e-11 -8.76763965e-12
 -3.03679415e-12 -5.07073701e-12 -7.29005068e-12 -9.75661613e-13
  6.95560454e-11 -9.51721323e-11 -3.45008564e-11  1.20951294e-11
  3.94451369e-12 -4.11956476e-11 -3.73135386e-11 -9.38151868e-13
 -1.00399538e-11  2.60604117e-11 -2.12897256e-11 -1.18159202e-11
  8.44097511e-12 -1.52083792e-11  1.61474913e-11  1.01516377e-11
 -5.95251124e-12  6.77322912e-12 -1.01319166e-11 -7.55720795e-12
 -4.17408126e-12  9.31169583e-12 -7.93823740e-12 -5.47331643e-12
 -1.56112913e-13  3.16655566e-12  1.07617006e-11  2.54986186e-12
 -7.25414316e-12 -3.41001353e-12 -3.97528100e-12 -5.59773357e-12
 -3.04635017e+00]
supnorm grad right now is: 3.04635017035397
Weights right now are: 
[-4.85405941e+00 -7.32221910e-01 -3.58970910e+00 -4.42245450e+00
  5.10862832e+00  6.23530256e-01  3.98864657e+00  3.70642632e+00
 -2.06457812e+00 -7.77199423e-01 -2.14927123e+00 -1.81519917e+00
  1.20332147e+00  3.02414251e-01 -3.85737877e-01  4.82322606e-01
 -1.46290983e+00 -5.01399023e-01 -2.49710561e+00 -2.16634782e+00
 -2.28364057e+00 -8.44043063e-01 -2.25518418e+00 -1.85476275e+00
 -8.48472680e-01 -4.75703144e-01 -1.45258606e+00 -7.15545492e-01
  4.14358588e-01  1.47627719e+00  1.52932087e+00  4.75330802e-01
 -1.69342750e+00  1.53756166e+00 -8.58407869e-01 -8.95308570e-01
 -2.63146159e+00 -4.83707706e-01 -9.22922004e-01 -7.47489285e-01
  1.58969591e-01 -1.76375534e+00  1.45762249e+00  1.03457185e+00
  1.90631297e-01  2.50155285e+00 -2.08961572e+00  1.26124016e-02
 -1.37211067e+00 -7.00452980e-01 -3.45847116e-01 -1.49923447e+00
  7.66567120e-01  1.12965764e+00  6.32390609e-01  1.79194850e+00
  1.32163790e+00  6.61097388e-01 -5.45905700e-01 -2.38001718e+00
  2.13963807e+00  2.24396521e+00 -8.86638626e-02  1.35941650e+00
  2.47208432e+01]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.259961909364
gradient value of function right now is: [ 2.20377311e-09  5.14143502e-10  2.20558170e-09  2.20474178e-09
 -2.20356450e-09 -5.14095437e-10 -2.20537305e-09 -2.20453288e-09
  1.74006803e-11  1.16809343e-11  6.01470626e-11  3.00303942e-11
  4.68935459e-10  9.60018000e-11  5.38140562e-10  5.26980400e-10
  1.55186527e-12  7.56042139e-12  3.75798778e-11  1.10826999e-11
  6.95301217e-12  6.63515904e-12  3.37609964e-11  1.45369681e-11
 -3.03923933e-11 -3.01010266e-11 -5.45430635e-11 -8.71100224e-12
 -3.13042627e-12 -5.88080770e-12 -8.22114345e-12 -1.04700393e-12
  6.04404662e-11 -1.14119344e-10 -6.21467548e-11  8.87058350e-12
  2.21466603e-12 -4.71577886e-11 -4.49420327e-11 -1.70324032e-12
 -1.47079517e-11  2.27317613e-11 -2.74882530e-11 -1.91045392e-11
  1.17190414e-11 -1.30938904e-11  2.06004972e-11  1.53002981e-11
 -7.53043776e-12  5.88005623e-12 -1.23404859e-11 -1.00272957e-11
 -5.45894977e-12  8.38339533e-12 -9.68984460e-12 -7.47013602e-12
 -4.14687588e-13  3.66212393e-12  8.26639498e-12  4.92329072e-12
 -4.68220782e-12 -6.87886089e-12 -2.98265234e-12 -6.60399053e-12
  1.69749450e+00]
supnorm grad right now is: 1.6974944977427502
Weights right now are: 
[-4.85873030e+00 -7.33308604e-01 -3.59438357e+00 -4.42712779e+00
  5.11329921e+00  6.24616952e-01  3.99332104e+00  3.71109962e+00
 -2.06462855e+00 -7.77224577e-01 -2.14940289e+00 -1.81527505e+00
  1.20233050e+00  3.02214949e-01 -3.86858663e-01  4.81213370e-01
 -1.46292509e+00 -5.01415499e-01 -2.49718941e+00 -2.16638224e+00
 -2.28366398e+00 -8.44057410e-01 -2.25525855e+00 -1.85480142e+00
 -8.48410944e-01 -4.75644994e-01 -1.45247825e+00 -7.15527982e-01
  4.14364801e-01  1.47628836e+00  1.52933665e+00  4.75332850e-01
 -1.69355527e+00  1.53777601e+00 -8.58303997e-01 -8.95328682e-01
 -2.63146727e+00 -4.83617829e-01 -9.22837773e-01 -7.47486426e-01
  1.58995695e-01 -1.76380324e+00  1.45767310e+00  1.03460486e+00
  1.90610208e-01  2.50158056e+00 -2.08965376e+00  1.25855013e-02
 -1.37209673e+00 -7.00465399e-01 -3.45823993e-01 -1.49921618e+00
  7.66577118e-01  1.12964017e+00  6.32408753e-01  1.79196201e+00
  1.32163853e+00  6.61090456e-01 -5.45924036e-01 -2.38002544e+00
  2.13964923e+00  2.24397661e+00 -8.86571648e-02  1.35942909e+00
  2.50936450e+01]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.179735916518
gradient value of function right now is: [ 2.35222316e-09  5.48316911e-10  2.35389525e-09  2.35361227e-09
 -2.35182984e-09 -5.48226133e-10 -2.35350183e-09 -2.35321846e-09
  3.23010917e-11  1.28915648e-11  6.85948056e-11  4.44958353e-11
  5.00696038e-10  9.88028818e-11  5.57689368e-10  5.58169218e-10
  1.37557066e-11  8.54919798e-12  4.44687645e-11  2.29241190e-11
  1.62104660e-11  7.38774930e-12  3.90067385e-11  2.35239541e-11
 -2.98977324e-11 -2.65816450e-11 -5.06280819e-11 -8.37792412e-12
 -2.96546607e-12 -4.98891569e-12 -7.17001087e-12 -9.56153550e-13
  6.47079658e-11 -9.43130548e-11 -3.79983617e-11  1.09531732e-11
  3.43534574e-12 -4.04137186e-11 -3.70225421e-11 -1.03807201e-12
 -1.04224619e-11  2.42500923e-11 -2.14333486e-11 -1.25975066e-11
  8.64843944e-12 -1.41360415e-11  1.62200967e-11  1.06233118e-11
 -5.96880805e-12  6.28185424e-12 -1.00699163e-11 -7.66448996e-12
 -4.21781907e-12  8.70663236e-12 -7.89418082e-12 -5.58878825e-12
 -1.97747164e-13  3.11008261e-12  9.81675368e-12  2.84813831e-12
 -6.46052547e-12 -3.87526420e-12 -3.61111519e-12 -5.52130731e-12
 -2.18917379e+00]
supnorm grad right now is: 2.1891737949687524
Weights right now are: 
[-4.86326572e+00 -7.34366355e-01 -3.59892247e+00 -4.43166553e+00
  5.11783463e+00  6.25674702e-01  3.99785994e+00  3.71563736e+00
 -2.06467702e+00 -7.77249014e-01 -2.14953069e+00 -1.81534833e+00
  1.20136516e+00  3.02020643e-01 -3.87951030e-01  4.80132619e-01
 -1.46293945e+00 -5.01431505e-01 -2.49727075e+00 -2.16641529e+00
 -2.28368639e+00 -8.44071351e-01 -2.25533075e+00 -1.85483873e+00
 -8.48350662e-01 -4.75588237e-01 -1.45237302e+00 -7.15510883e-01
  4.14370917e-01  1.47629927e+00  1.52935210e+00  4.75334861e-01
 -1.69367975e+00  1.53798543e+00 -8.58202064e-01 -8.95348324e-01
 -2.63147279e+00 -4.83530018e-01 -9.22755404e-01 -7.47483647e-01
  1.59021285e-01 -1.76384988e+00  1.45772244e+00  1.03463710e+00
  1.90589511e-01  2.50160756e+00 -2.08969088e+00  1.25591851e-02
 -1.37208312e+00 -7.00477476e-01 -3.45801506e-01 -1.49919839e+00
  7.66586899e-01  1.12962316e+00  6.32426416e-01  1.79197517e+00
  1.32163913e+00  6.61083698e-01 -5.45941839e-01 -2.38003346e+00
  2.13966018e+00  2.24398743e+00 -8.86506450e-02  1.35944127e+00
  2.48166331e+01]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.1210481795492
gradient value of function right now is: [ 2.03646511e-09  4.77724653e-10  2.03819485e-09  2.03727773e-09
 -2.03647701e-09 -4.77727406e-10 -2.03820675e-09 -2.03728967e-09
  1.29555212e-11  1.07123629e-11  5.46723730e-11  2.49426072e-11
  4.36410831e-10  9.01662032e-11  5.04626784e-10  4.91452892e-10
 -1.33836933e-12  6.89250723e-12  3.38231043e-11  7.72318087e-12
  4.42526981e-12  6.07453622e-12  3.05961975e-11  1.16303577e-11
 -2.89263962e-11 -2.91519187e-11 -5.24178891e-11 -8.32528134e-12
 -3.05078474e-12 -5.74522933e-12 -8.03803674e-12 -1.02256450e-12
  5.61491000e-11 -1.12059499e-10 -6.39198326e-11  7.92073421e-12
  1.80834652e-12 -4.59720728e-11 -4.41495836e-11 -1.75723845e-12
 -1.48235335e-11  2.11139289e-11 -2.72804604e-11 -1.94650515e-11
  1.17418365e-11 -1.21365374e-11  2.04227840e-11  1.54797651e-11
 -7.45078408e-12  5.44127130e-12 -1.21452911e-11 -9.98447839e-12
 -5.42485925e-12  7.83417322e-12 -9.54086575e-12 -7.46473774e-12
 -4.40424004e-13  3.57147558e-12  7.46361753e-12  5.11969997e-12
 -4.02238117e-12 -7.17816428e-12 -2.67743993e-12 -6.47878346e-12
  2.60924804e+00]
supnorm grad right now is: 2.6092480417488035
Weights right now are: 
[-4.86768988e+00 -7.35400731e-01 -3.60335006e+00 -4.43609192e+00
  5.12225879e+00  6.26709078e-01  4.00228752e+00  3.72006374e+00
 -2.06472283e+00 -7.77272812e-01 -2.14965493e+00 -1.81541848e+00
  1.20042037e+00  3.01830096e-01 -3.89022001e-01  4.79074389e-01
 -1.46295216e+00 -5.01447075e-01 -2.49734967e+00 -2.16644635e+00
 -2.28370732e+00 -8.44084924e-01 -2.25540090e+00 -1.85487427e+00
 -8.48291300e-01 -4.75532247e-01 -1.45226926e+00 -7.15494039e-01
  4.14376997e-01  1.47631007e+00  1.52936743e+00  4.75336859e-01
 -1.69380141e+00  1.53819297e+00 -8.58099510e-01 -8.95367320e-01
 -2.63147803e+00 -4.83443247e-01 -9.22673804e-01 -7.47480831e-01
  1.59046860e-01 -1.76389544e+00  1.45777162e+00  1.03466962e+00
  1.90568842e-01  2.50163390e+00 -2.08972790e+00  1.25326939e-02
 -1.37206961e+00 -7.00489249e-01 -3.45779172e-01 -1.49918061e+00
  7.66596611e-01  1.12960652e+00  6.32443950e-01  1.79198832e+00
  1.32163978e+00  6.61076987e-01 -5.45959071e-01 -2.38004174e+00
  2.13967043e+00  2.24399882e+00 -8.86443383e-02  1.35945337e+00
  2.51880291e+01]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.150419431723
gradient value of function right now is: [ 1.99076539e-09  4.67980166e-10  1.99244618e-09  1.99157286e-09
 -1.99115932e-09 -4.68071439e-10 -1.99284021e-09 -1.99196729e-09
  1.32011485e-11  1.04952907e-11  5.36568583e-11  2.48794952e-11
  4.27887654e-10  8.82537492e-11  4.94091719e-10  4.81677922e-10
 -8.44090427e-13  6.76318732e-12  3.32709395e-11  7.98592705e-12
  4.66869676e-12  5.95562962e-12  3.00564761e-11  1.16897800e-11
 -2.82856773e-11 -2.83114042e-11 -5.10625880e-11 -8.12977734e-12
 -2.99708049e-12 -5.57322138e-12 -7.82578168e-12 -1.00073504e-12
  5.50350954e-11 -1.08614847e-10 -6.14047427e-11  7.82758127e-12
  1.81205103e-12 -4.46105783e-11 -4.27861457e-11 -1.68931429e-12
 -1.42986061e-11  2.06790363e-11 -2.63896128e-11 -1.87408620e-11
  1.13421508e-11 -1.18981250e-11  1.97676617e-11  1.49278248e-11
 -7.21127782e-12  5.32319325e-12 -1.17650667e-11 -9.65273294e-12
 -5.24611104e-12  7.66255805e-12 -9.24235854e-12 -7.21206187e-12
 -4.21694672e-13  3.46271819e-12  7.35162411e-12  4.91460288e-12
 -3.99966294e-12 -6.88817660e-12 -2.64036532e-12 -6.28307830e-12
  2.43781383e+00]
supnorm grad right now is: 2.4378138264179863
Weights right now are: 
[-4.87197517e+00 -7.36404783e-01 -3.60763865e+00 -4.44037938e+00
  5.12654408e+00  6.27713129e-01  4.00657611e+00  3.72435120e+00
 -2.06476800e+00 -7.77295898e-01 -2.14977562e+00 -1.81548718e+00
  1.19950251e+00  3.01645252e-01 -3.90061375e-01  4.78046622e-01
 -1.46296516e+00 -5.01462197e-01 -2.49742646e+00 -2.16647708e+00
 -2.28372811e+00 -8.44098099e-01 -2.25546911e+00 -1.85490918e+00
 -8.48233747e-01 -4.75478247e-01 -1.45216894e+00 -7.15477727e-01
  4.14382923e-01  1.47632047e+00  1.52938225e+00  4.75338799e-01
 -1.69391959e+00  1.53839271e+00 -8.58001895e-01 -8.95385846e-01
 -2.63148318e+00 -4.83359627e-01 -9.22595297e-01 -7.47478140e-01
  1.59071305e-01 -1.76393969e+00  1.45781884e+00  1.03470059e+00
  1.90549087e-01  2.50165951e+00 -2.08976342e+00  1.25074474e-02
 -1.37205661e+00 -7.00500669e-01 -3.45757653e-01 -1.49916355e+00
  7.66605943e-01  1.12959038e+00  6.32460842e-01  1.79200094e+00
  1.32164039e+00  6.61070537e-01 -5.45975904e-01 -2.38004958e+00
  2.13968065e+00  2.24400952e+00 -8.86381760e-02  1.35946508e+00
  2.51481236e+01]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2814.7195467123047
gradient value of function right now is: [ 2.26622784e-09  5.30999282e-10  2.26772674e-09  2.26771517e-09
 -2.26624429e-09 -5.31003103e-10 -2.26774320e-09 -2.26773161e-09
  3.70323929e-11  1.26213313e-11  6.80736734e-11  4.82535194e-11
  4.86172451e-10  9.43421640e-11  5.34228060e-10  5.40051965e-10
  1.84638282e-11  8.46257010e-12  4.48179824e-11  2.68910012e-11
  1.94141543e-11  7.26515080e-12  3.89418513e-11  2.61438987e-11
 -2.80242366e-11 -2.32927096e-11 -4.58379439e-11 -7.75440736e-12
 -2.77953337e-12 -4.27240833e-12 -6.30645166e-12 -8.72997277e-13
  6.27840818e-11 -7.93352122e-11 -2.44334608e-11  1.12607921e-11
  3.76905464e-12 -3.47778091e-11 -3.10732962e-11 -6.70644533e-13
 -7.83259031e-12  2.34319650e-11 -1.73499900e-11 -8.85463648e-12
  6.72174078e-12 -1.37391835e-11  1.32274998e-11  7.83770968e-12
 -4.88505440e-12  6.05733330e-12 -8.40290321e-12 -6.10697155e-12
 -3.38788065e-12  8.31689189e-12 -6.58144467e-12 -4.37942404e-12
 -8.68282048e-14  2.65537643e-12  9.91428731e-12  1.74487547e-12
 -6.86744853e-12 -2.27245821e-12 -3.67752297e-12 -4.69305521e-12
 -4.05163429e+00]
supnorm grad right now is: 4.051634290032383
Weights right now are: 
[-4.87614513e+00 -7.37383914e-01 -3.61181181e+00 -4.44455146e+00
  5.13071404e+00  6.28692259e-01  4.01074927e+00  3.72852327e+00
 -2.06481223e+00 -7.77318384e-01 -2.14989321e+00 -1.81555429e+00
  1.19860674e+00  3.01464903e-01 -3.91075429e-01  4.77043636e-01
 -1.46297804e+00 -5.01476935e-01 -2.49750133e+00 -2.16650722e+00
 -2.28374851e+00 -8.44110936e-01 -2.25553558e+00 -1.85494333e+00
 -8.48177547e-01 -4.75425772e-01 -1.45207125e+00 -7.15461808e-01
  4.14388750e-01  1.47633058e+00  1.52939670e+00  4.75340702e-01
 -1.69403485e+00  1.53858672e+00 -8.57907389e-01 -8.95403982e-01
 -2.63148822e+00 -4.83278366e-01 -9.22519012e-01 -7.47475540e-01
  1.59095005e-01 -1.76398279e+00  1.45786461e+00  1.03473066e+00
  1.90529907e-01  2.50168448e+00 -2.08979788e+00  1.24829086e-02
 -1.37204401e+00 -7.00511785e-01 -3.45736796e-01 -1.49914699e+00
  7.66614994e-01  1.12957465e+00  6.32477220e-01  1.79201318e+00
  1.32164097e+00  6.61064278e-01 -5.45992152e-01 -2.38005719e+00
  2.13969049e+00  2.24401987e+00 -8.86322163e-02  1.35947644e+00
  2.46494093e+01]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.3237775673533
gradient value of function right now is: [ 1.95667841e-09  4.61380892e-10  1.95824883e-09  1.95758301e-09
 -1.95638699e-09 -4.61313135e-10 -1.95795734e-09 -1.95729123e-09
  1.73018077e-11  1.04573420e-11  5.41754036e-11  2.83893155e-11
  4.22484840e-10  8.59502887e-11  4.82447152e-10  4.74162743e-10
  2.97677064e-12  6.80762731e-12  3.41279741e-11  1.13547067e-11
  7.36280571e-12  5.95761100e-12  3.05237005e-11  1.40290079e-11
 -2.71497748e-11 -2.61245856e-11 -4.79650192e-11 -7.73755740e-12
 -2.86967183e-12 -5.08138125e-12 -7.22967049e-12 -9.43134551e-13
  5.43675556e-11 -9.82594620e-11 -5.14109097e-11  8.20997577e-12
  2.12769989e-12 -4.08019825e-11 -3.86776505e-11 -1.41410712e-12
 -1.23965810e-11  2.03864217e-11 -2.34572840e-11 -1.59567230e-11
  9.94283969e-12 -1.17921172e-11  1.76295522e-11  1.28771494e-11
 -6.44328552e-12  5.24150647e-12 -1.05936869e-11 -8.53385566e-12
 -4.65451079e-12  7.47601906e-12 -8.32011244e-12 -6.33993292e-12
 -3.35950104e-13  3.15360132e-12  7.56859019e-12  4.05444127e-12
 -4.42626724e-12 -5.64038634e-12 -2.74322865e-12 -5.69704479e-12
  1.04000914e+00]
supnorm grad right now is: 1.0400091365302824
Weights right now are: 
[-4.88022903e+00 -7.38344894e-01 -3.61589885e+00 -4.44863742e+00
  5.13479793e+00  6.29653238e-01  4.01483630e+00  3.73260924e+00
 -2.06485541e+00 -7.77340418e-01 -2.15000845e+00 -1.81561993e+00
  1.19772691e+00  3.01287752e-01 -3.92071496e-01  4.76058465e-01
 -1.46299051e+00 -5.01491380e-01 -2.49757472e+00 -2.16653664e+00
 -2.28376841e+00 -8.44123519e-01 -2.25560074e+00 -1.85497672e+00
 -8.48122296e-01 -4.75374215e-01 -1.45197527e+00 -7.15446160e-01
  4.14394517e-01  1.47634050e+00  1.52941093e+00  4.75342579e-01
 -1.69414808e+00  1.53877727e+00 -8.57814628e-01 -8.95421833e-01
 -2.63149318e+00 -4.83198489e-01 -9.22444050e-01 -7.47472993e-01
  1.59118156e-01 -1.76402514e+00  1.45790939e+00  1.03476007e+00
  1.90511166e-01  2.50170905e+00 -2.08983161e+00  1.24589226e-02
 -1.37203165e+00 -7.00522701e-01 -3.45716336e-01 -1.49913074e+00
  7.66623868e-01  1.12955920e+00  6.32493284e-01  1.79202519e+00
  1.32164156e+00  6.61058117e-01 -5.46008113e-01 -2.38006444e+00
  2.13970026e+00  2.24402985e+00 -8.86263775e-02  1.35948753e+00
  2.50467977e+01]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.2831507157007
gradient value of function right now is: [ 2.02708290e-09  4.77952683e-10  2.02856642e-09  2.02821612e-09
 -2.02727442e-09 -4.77997340e-10 -2.02875798e-09 -2.02840791e-09
  2.55634131e-11  1.10727917e-11  5.85856569e-11  3.63386079e-11
  4.38146408e-10  8.70585640e-11  4.90847051e-10  4.89212875e-10
  9.82521070e-12  7.32260478e-12  3.77963433e-11  1.79485263e-11
  1.25237518e-11  6.34445661e-12  3.32871103e-11  1.89973384e-11
 -2.67288588e-11 -2.39941862e-11 -4.55005069e-11 -7.50844643e-12
 -2.76635341e-12 -4.55109092e-12 -6.60288334e-12 -8.88003709e-13
  5.64669669e-11 -8.65061985e-11 -3.74720549e-11  9.33808996e-12
  2.80195543e-12 -3.67582338e-11 -3.39855418e-11 -1.03120055e-12
 -9.91028132e-12  2.11250851e-11 -1.99103736e-11 -1.21946506e-11
  8.15386548e-12 -1.23128784e-11  1.50576054e-11  1.01627482e-11
 -5.52573660e-12  5.43561455e-12 -9.25203118e-12 -7.15195387e-12
 -3.92745275e-12  7.61401752e-12 -7.25894818e-12 -5.24133861e-12
 -2.12049461e-13  2.82364622e-12  8.40526748e-12  2.86495242e-12
 -5.40454906e-12 -3.91847017e-12 -3.08421127e-12 -5.05374566e-12
 -1.45721326e+00]
supnorm grad right now is: 1.457213261963106
Weights right now are: 
[-4.88420243e+00 -7.39281964e-01 -3.61987533e+00 -4.45261282e+00
  5.13877133e+00  6.30590308e-01  4.01881279e+00  3.73658463e+00
 -2.06489666e+00 -7.77361857e-01 -2.15012049e+00 -1.81568315e+00
  1.19686840e+00  3.01114745e-01 -3.93044193e-01  4.75096961e-01
 -1.46300193e+00 -5.01505430e-01 -2.49764602e+00 -2.16656465e+00
 -2.28378727e+00 -8.44135763e-01 -2.25566410e+00 -1.85500879e+00
 -8.48068294e-01 -4.75323563e-01 -1.45188120e+00 -7.15430855e-01
  4.14400181e-01  1.47635025e+00  1.52942489e+00  4.75344422e-01
 -1.69425873e+00  1.53896459e+00 -8.57722917e-01 -8.95439264e-01
 -2.63149803e+00 -4.83119925e-01 -9.22370297e-01 -7.47470490e-01
  1.59140927e-01 -1.76406657e+00  1.45795333e+00  1.03478879e+00
  1.90492736e-01  2.50173312e+00 -2.08986471e+00  1.24354787e-02
 -1.37201950e+00 -7.00533373e-01 -3.45696249e-01 -1.49911483e+00
  7.66632600e-01  1.12954410e+00  6.32509060e-01  1.79203696e+00
  1.32164211e+00  6.61052067e-01 -5.46024088e-01 -2.38007126e+00
  2.13971014e+00  2.24403936e+00 -8.86205628e-02  1.35949831e+00
  2.48757805e+01]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.2127344994765
gradient value of function right now is: [ 2.00356901e-09  4.73150511e-10  2.00500682e-09  2.00472726e-09
 -2.00335627e-09 -4.73100822e-10 -2.00479403e-09 -2.00451427e-09
  2.67726994e-11  1.09948322e-11  5.84118058e-11  3.72882514e-11
  4.34033803e-10  8.58280775e-11  4.84357987e-10  4.84123233e-10
  1.10389943e-11  7.29487754e-12  3.78620485e-11  1.89647277e-11
  1.33466329e-11  6.30822221e-12  3.32489157e-11  1.96645527e-11
 -2.62149721e-11 -2.31301444e-11 -4.42230120e-11 -7.33988872e-12
 -2.71389858e-12 -4.36217386e-12 -6.37202155e-12 -8.65303314e-13
  5.59353932e-11 -8.25590508e-11 -3.39107822e-11  9.41349150e-12
  2.88993610e-12 -3.52770746e-11 -3.24198830e-11 -9.34768120e-13
 -9.21596365e-12  2.09100836e-11 -1.88239338e-11 -1.12017072e-11
  7.63648334e-12 -1.22111902e-11  1.42607541e-11  9.42223565e-12
 -5.23884391e-12  5.37658499e-12 -8.81317207e-12 -6.74296713e-12
 -3.70751147e-12  7.50942727e-12 -6.91264686e-12 -4.92343531e-12
 -1.83917500e-13  2.70564361e-12  8.42847970e-12  2.56751381e-12
 -5.51036785e-12 -3.49868539e-12 -3.09892222e-12 -4.83337696e-12
 -1.98567240e+00]
supnorm grad right now is: 1.9856723954238973
Weights right now are: 
[-4.88805450e+00 -7.40192363e-01 -3.62373039e+00 -4.45646681e+00
  5.14262340e+00  6.31500706e-01  4.02266784e+00  3.74043861e+00
 -2.06493606e+00 -7.77382629e-01 -2.15022901e+00 -1.81574392e+00
  1.19603374e+00  3.00946482e-01 -3.93990490e-01  4.74162030e-01
 -1.46301247e+00 -5.01519037e-01 -2.49771504e+00 -2.16659133e+00
 -2.28380519e+00 -8.44147626e-01 -2.25572546e+00 -1.85503956e+00
 -8.48015700e-01 -4.75274115e-01 -1.45178943e+00 -7.15415946e-01
  4.14405721e-01  1.47635977e+00  1.52943855e+00  4.75346225e-01
 -1.69436633e+00  1.53914774e+00 -8.57632843e-01 -8.95456124e-01
 -2.63150269e+00 -4.83043191e-01 -9.22298208e-01 -7.47468020e-01
  1.59163190e-01 -1.76410699e+00  1.45799634e+00  1.03481698e+00
  1.90474694e-01  2.50175660e+00 -2.08989714e+00  1.24124462e-02
 -1.37200762e+00 -7.00543748e-01 -3.45676613e-01 -1.49909924e+00
  7.66641135e-01  1.12952942e+00  6.32524482e-01  1.79204849e+00
  1.32164268e+00  6.61046161e-01 -5.46039609e-01 -2.38007814e+00
  2.13971956e+00  2.24404901e+00 -8.86149244e-02  1.35950889e+00
  2.48623506e+01]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.3028939343294
gradient value of function right now is: [ 1.80821489e-09  4.29079703e-10  1.80968084e-09  1.80902863e-09
 -1.80854257e-09 -4.29156372e-10 -1.81000860e-09 -1.80935671e-09
  1.52060379e-11  9.65672995e-12  4.99180917e-11  2.55527884e-11
  3.93775528e-10  8.03047744e-11  4.50601690e-10  4.42201684e-10
  2.03974848e-12  6.28079422e-12  3.13873728e-11  9.86818157e-12
  6.30255345e-12  5.50227225e-12  2.81203065e-11  1.25289377e-11
 -2.55134803e-11 -2.45426472e-11 -4.50689553e-11 -7.27341970e-12
 -2.75006358e-12 -4.78852137e-12 -6.85317442e-12 -9.00101981e-13
  5.06073769e-11 -9.27470551e-11 -4.91700860e-11  7.57465342e-12
  1.91467300e-12 -3.84265609e-11 -3.65102809e-11 -1.35594646e-12
 -1.17866090e-11  1.89556734e-11 -2.22039102e-11 -1.52200492e-11
  9.44236938e-12 -1.09687034e-11  1.66927726e-11  1.22632150e-11
 -6.09401691e-12  4.85566369e-12 -1.00025364e-11 -8.08571677e-12
 -4.40761668e-12  6.95941680e-12 -7.85797569e-12 -6.01321552e-12
 -3.25758755e-13  2.96715365e-12  6.99873621e-12  3.89017448e-12
 -4.05092509e-12 -5.42031117e-12 -2.53277394e-12 -5.37530362e-12
  1.28252632e+00]
supnorm grad right now is: 1.2825263222215975
Weights right now are: 
[-4.89182271e+00 -7.41084724e-01 -3.62750153e+00 -4.46023689e+00
  5.14639160e+00  6.32393067e-01  4.02643898e+00  3.74420869e+00
 -2.06497451e+00 -7.77402952e-01 -2.15033519e+00 -1.81580329e+00
  1.19521504e+00  3.00781413e-01 -3.94918839e-01  4.73244932e-01
 -1.46302269e+00 -5.01532354e-01 -2.49778258e+00 -2.16661736e+00
 -2.28382266e+00 -8.44159235e-01 -2.25578551e+00 -1.85506961e+00
 -8.47964023e-01 -4.75225674e-01 -1.45169941e+00 -7.15401305e-01
  4.14411202e-01  1.47636911e+00  1.52945198e+00  4.75348003e-01
 -1.69447176e+00  1.53932730e+00 -8.57544502e-01 -8.95472624e-01
 -2.63150724e+00 -4.82967996e-01 -9.22227555e-01 -7.47465590e-01
  1.59185034e-01 -1.76414651e+00  1.45803859e+00  1.03484466e+00
  1.90457014e-01  2.50177956e+00 -2.08992898e+00  1.23898570e-02
 -1.37199597e+00 -7.00553887e-01 -3.45657316e-01 -1.49908392e+00
  7.66649503e-01  1.12951505e+00  6.32539629e-01  1.79205981e+00
  1.32164324e+00  6.61040349e-01 -5.46054839e-01 -2.38008490e+00
  2.13972890e+00  2.24405843e+00 -8.86093896e-02  1.35951927e+00
  2.50822094e+01]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.033832930209
gradient value of function right now is: [ 1.68976187e-09  4.02448363e-10  1.69122690e-09  1.69039130e-09
 -1.68968634e-09 -4.02430629e-10 -1.69115135e-09 -1.69031566e-09
  9.12819900e-12  8.87240872e-12  4.50608379e-11  1.92826984e-11
  3.69455101e-10  7.67197637e-11  4.29086450e-10  4.16576359e-10
 -2.59153338e-12  5.69753442e-12  2.77550950e-11  5.10799911e-12
  2.63161325e-12  5.03368504e-12  2.52111144e-11  8.74817897e-12
 -2.49242844e-11 -2.50166001e-11 -4.50679331e-11 -7.17275914e-12
 -2.74995861e-12 -4.95898826e-12 -7.03807199e-12 -9.11148735e-13
  4.73940960e-11 -9.70470491e-11 -5.64782163e-11  6.55787059e-12
  1.39466566e-12 -3.96534380e-11 -3.82377016e-11 -1.55958506e-12
 -1.29827750e-11  1.77727181e-11 -2.37205605e-11 -1.71319333e-11
  1.02718781e-11 -1.02290834e-11  1.77787999e-11  1.36011440e-11
 -6.47171365e-12  4.53910153e-12 -1.05157902e-11 -8.69672080e-12
 -4.72206316e-12  6.60914584e-12 -8.26659975e-12 -6.51393250e-12
 -3.96462826e-13  3.07156818e-12  6.19432232e-12  4.54190657e-12
 -3.25489159e-12 -6.37661781e-12 -2.21575700e-12 -5.60608780e-12
  3.07710414e+00]
supnorm grad right now is: 3.077104139286215
Weights right now are: 
[-4.89550561e+00 -7.41958455e-01 -3.63118728e+00 -4.46392165e+00
  5.15007451e+00  6.33266799e-01  4.03012473e+00  3.74789345e+00
 -2.06501313e+00 -7.77422860e-01 -2.15043934e+00 -1.81586228e+00
  1.19441289e+00  3.00619943e-01 -3.95827150e-01  4.72346694e-01
 -1.46303360e+00 -5.01545417e-01 -2.49784896e+00 -2.16664366e+00
 -2.28384040e+00 -8.44170615e-01 -2.25584446e+00 -1.85509960e+00
 -8.47913532e-01 -4.75178733e-01 -1.45161183e+00 -7.15387021e-01
  4.14416577e-01  1.47637815e+00  1.52946504e+00  4.75349742e-01
 -1.69457502e+00  1.53950087e+00 -8.57460243e-01 -8.95488913e-01
 -2.63151176e+00 -4.82895219e-01 -9.22159270e-01 -7.47463274e-01
  1.59206116e-01 -1.76418518e+00  1.45807936e+00  1.03487119e+00
  1.90439915e-01  2.50180204e+00 -2.08995974e+00  1.23681514e-02
 -1.37198471e+00 -7.00563794e-01 -3.45638708e-01 -1.49906921e+00
  7.66657592e-01  1.12950100e+00  6.32554250e-01  1.79207069e+00
  1.32164373e+00  6.61034774e-01 -5.46069732e-01 -2.38009146e+00
  2.13973817e+00  2.24406731e+00 -8.86039458e-02  1.35952935e+00
  2.51844629e+01]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.3629972137855
gradient value of function right now is: [ 1.79978703e-09  4.27847968e-10  1.80118241e-09  1.80068317e-09
 -1.79978555e-09 -4.27847629e-10 -1.80118092e-09 -1.80068172e-09
  1.85143504e-11  9.72050204e-12  5.07932443e-11  2.85036236e-11
  3.93059894e-10  7.92288579e-11  4.45549710e-10  4.40273597e-10
  5.01192558e-12  6.37477203e-12  3.23430285e-11  1.25640320e-11
  8.44240705e-12  5.55613862e-12  2.87449937e-11  1.44530632e-11
 -2.48508860e-11 -2.30876284e-11 -4.30844872e-11 -7.03345971e-12
 -2.66712477e-12 -4.45514987e-12 -6.45062161e-12 -8.61804611e-13
  5.05317607e-11 -8.56192013e-11 -4.19427224e-11  7.92743743e-12
  2.17242474e-12 -3.58385389e-11 -3.36766531e-11 -1.15837581e-12
 -1.04372960e-11  1.88992657e-11 -2.01663865e-11 -1.32384067e-11
  8.45376681e-12 -1.09814767e-11  1.52068938e-11  1.08093414e-11
 -5.56059417e-12  4.83805637e-12 -9.19786787e-12 -7.30556069e-12
 -3.99357049e-12  6.87827435e-12 -7.22334007e-12 -5.40170138e-12
 -2.64192127e-13  2.75721262e-12  7.21397298e-12  3.28928378e-12
 -4.39018411e-12 -4.54873380e-12 -2.62937442e-12 -4.98230862e-12
  5.62221446e-02]
supnorm grad right now is: 0.056222144618723255
Weights right now are: 
[-4.89911469e+00 -7.42816233e-01 -3.63479914e+00 -4.46753256e+00
  5.15368359e+00  6.34124577e-01  4.03373659e+00  3.75150437e+00
 -2.06505148e+00 -7.77442395e-01 -2.15054162e+00 -1.81592055e+00
  1.19362485e+00  3.00461437e-01 -3.96718833e-01  4.71464419e-01
 -1.46304471e+00 -5.01558246e-01 -2.49791423e+00 -2.16666984e+00
 -2.28385811e+00 -8.44181787e-01 -2.25590239e+00 -1.85512930e+00
 -8.47863974e-01 -4.75132879e-01 -1.45152611e+00 -7.15373005e-01
  4.14421880e-01  1.47638697e+00  1.52947782e+00  4.75351453e-01
 -1.69467643e+00  1.53967013e+00 -8.57378732e-01 -8.95504982e-01
 -2.63151624e+00 -4.82824159e-01 -9.22092675e-01 -7.47461029e-01
  1.59226468e-01 -1.76422313e+00  1.45811898e+00  1.03489691e+00
  1.90423394e-01  2.50182412e+00 -2.08998963e+00  1.23470847e-02
 -1.37197376e+00 -7.00573518e-01 -3.45620545e-01 -1.49905483e+00
  7.66665441e-01  1.12948721e+00  6.32568507e-01  1.79208130e+00
  1.32164425e+00  6.61029286e-01 -5.46084431e-01 -2.38009764e+00
  2.13974715e+00  2.24407599e+00 -8.85986018e-02  1.35953914e+00
  2.49838259e+01]
(65,)
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.3630912016183
gradient value of function right now is: [ 1.78313424e-09  4.24256984e-10  1.78451279e-09  1.78402704e-09
 -1.78327617e-09 -4.24290291e-10 -1.78465476e-09 -1.78416911e-09
  1.85492870e-11  9.63950236e-12  5.04030782e-11  2.84306365e-11
  3.89903451e-10  7.85360841e-11  4.41713740e-10  4.36671415e-10
  5.14565240e-12  6.32553781e-12  3.21225447e-11  1.26166982e-11
  8.49691945e-12  5.51140596e-12  2.85347863e-11  1.44431427e-11
 -2.46230154e-11 -2.28012394e-11 -4.26148506e-11 -6.96473818e-12
 -2.64773083e-12 -4.39721140e-12 -6.37831399e-12 -8.54149388e-13
  5.01172341e-11 -8.44602482e-11 -4.11350963e-11  7.88672783e-12
  2.16916693e-12 -3.53766783e-11 -3.32189811e-11 -1.13648566e-12
 -1.02671732e-11  1.87366580e-11 -1.98709537e-11 -1.30060990e-11
  8.32295313e-12 -1.08912191e-11  1.49886189e-11  1.06302887e-11
 -5.48099214e-12  4.79465046e-12 -9.07026177e-12 -7.19603403e-12
 -3.93449269e-12  6.81605618e-12 -7.12320819e-12 -5.31864230e-12
 -2.58327093e-13  2.72042411e-12  7.16512173e-12  3.22400606e-12
 -4.37380902e-12 -4.45529316e-12 -2.61296713e-12 -4.91623559e-12
 -2.02982860e-02]
supnorm grad right now is: 0.02029828595202838
Weights right now are: 
[-4.90260862e+00 -7.43648497e-01 -3.63829580e+00 -4.47102820e+00
  5.15717752e+00  6.34956840e-01  4.03723325e+00  3.75500001e+00
 -2.06508650e+00 -7.77461251e-01 -2.15064004e+00 -1.81597508e+00
  1.19285981e+00  3.00307046e-01 -3.97587072e-01  4.70607213e-01
 -1.46305361e+00 -5.01570603e-01 -2.49797682e+00 -2.16669349e+00
 -2.28387391e+00 -8.44192564e-01 -2.25595807e+00 -1.85515685e+00
 -8.47815465e-01 -4.75087581e-01 -1.45144175e+00 -7.15359276e-01
  4.14427110e-01  1.47639572e+00  1.52949048e+00  4.75353141e-01
 -1.69477486e+00  1.53983848e+00 -8.57295441e-01 -8.95520376e-01
 -2.63152043e+00 -4.82753737e-01 -9.22026409e-01 -7.47458747e-01
  1.59247148e-01 -1.76425998e+00  1.45815863e+00  1.03492294e+00
  1.90406638e-01  2.50184553e+00 -2.09001956e+00  1.23258083e-02
 -1.37196281e+00 -7.00582936e-01 -3.45602527e-01 -1.49904054e+00
  7.66673319e-01  1.12947382e+00  6.32582675e-01  1.79209189e+00
  1.32164474e+00  6.61023900e-01 -5.46098641e-01 -2.38010406e+00
  2.13975592e+00  2.24408470e+00 -8.85934158e-02  1.35954885e+00
  2.49924087e+01]
(65,)
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.363054531082
gradient value of function right now is: [ 1.76447621e-09  4.20198270e-10  1.76583944e-09  1.76536055e-09
 -1.76416735e-09 -4.20125714e-10 -1.76553051e-09 -1.76505130e-09
  1.83923860e-11  9.54076823e-12  4.98951945e-11  2.81688989e-11
  3.86250972e-10  7.77870601e-11  4.37521795e-10  4.32567880e-10
  5.12386270e-12  6.26215939e-12  3.18078368e-11  1.25166559e-11
  8.43331397e-12  5.45588372e-12  2.82526773e-11  1.43171610e-11
 -2.43940880e-11 -2.25548741e-11 -4.21847186e-11 -6.89812114e-12
 -2.62949830e-12 -4.34950209e-12 -6.31747085e-12 -8.47362738e-13
  4.96391181e-11 -8.35329533e-11 -4.06189656e-11  7.81779919e-12
  2.15060290e-12 -3.49931594e-11 -3.28538912e-11 -1.12272053e-12
 -1.01464077e-11  1.85536422e-11 -1.96461338e-11 -1.28493614e-11
  8.22751117e-12 -1.07872708e-11  1.48214912e-11  1.05056516e-11
 -5.41956411e-12  4.74543739e-12 -8.96938780e-12 -7.11423584e-12
 -3.88985325e-12  6.74820802e-12 -7.04416429e-12 -5.25764509e-12
 -2.55028759e-13  2.69007794e-12  7.09870065e-12  3.18319147e-12
 -4.33656040e-12 -4.39845303e-12 -2.58910144e-12 -4.86286767e-12
 -3.94235002e-02]
supnorm grad right now is: 0.039423500215936665
Weights right now are: 
[-4.90606501e+00 -7.44473199e-01 -3.64175486e+00 -4.47448630e+00
  5.16063390e+00  6.35781541e-01  4.04069231e+00  3.75845810e+00
 -2.06512195e+00 -7.77479937e-01 -2.15073774e+00 -1.81602978e+00
  1.19210122e+00  3.00154203e-01 -3.98446875e-01  4.69757527e-01
 -1.46306310e+00 -5.01582864e-01 -2.49803907e+00 -2.16671754e+00
 -2.28389005e+00 -8.44203250e-01 -2.25601339e+00 -1.85518457e+00
 -8.47767507e-01 -4.75042994e-01 -1.45135858e+00 -7.15345709e-01
  4.14432299e-01  1.47640431e+00  1.52950296e+00  4.75354812e-01
 -1.69487251e+00  1.54000360e+00 -8.57214825e-01 -8.95535740e-01
 -2.63152467e+00 -4.82684492e-01 -9.21961398e-01 -7.47456529e-01
  1.59267059e-01 -1.76429658e+00  1.45819726e+00  1.03494818e+00
  1.90390483e-01  2.50186685e+00 -2.09004872e+00  1.23051647e-02
 -1.37195213e+00 -7.00592288e-01 -3.45584834e-01 -1.49902650e+00
  7.66680988e-01  1.12946054e+00  6.32596567e-01  1.79210227e+00
  1.32164526e+00  6.61018562e-01 -5.46112704e-01 -2.38011012e+00
  2.13976457e+00  2.24409319e+00 -8.85883012e-02  1.35955837e+00
  2.51368705e+01]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.36283273118
gradient value of function right now is: [ 1.74754165e-09  4.16527520e-10  1.74888951e-09  1.74842034e-09
 -1.74768105e-09 -4.16560217e-10 -1.74902893e-09 -1.74855998e-09
  1.83475647e-11  9.45661258e-12  4.94780704e-11  2.80229966e-11
  3.83041493e-10  7.71023169e-11  4.33719829e-10  4.28930215e-10
  5.18755726e-12  6.20968701e-12  3.15613240e-11  1.25047008e-11
  8.43619621e-12  5.40889300e-12  2.80238679e-11  1.42597554e-11
 -2.41739763e-11 -2.23012590e-11 -4.17546739e-11 -6.83292372e-12
 -2.61067089e-12 -4.29880459e-12 -6.25282909e-12 -8.40238688e-13
  4.92226612e-11 -8.25298587e-11 -3.99667676e-11  7.76785933e-12
  2.14240893e-12 -3.45890502e-11 -3.24578322e-11 -1.10514839e-12
 -1.00032291e-11  1.83953877e-11 -1.93942645e-11 -1.26541366e-11
  8.11663820e-12 -1.06985529e-11  1.46350014e-11  1.03544229e-11
 -5.35139161e-12  4.70273999e-12 -8.85976341e-12 -7.02079383e-12
 -3.83958364e-12  6.68709353e-12 -6.95809216e-12 -5.18699567e-12
 -2.50230008e-13  2.65794976e-12  7.05360701e-12  3.12933565e-12
 -4.31840094e-12 -4.32298096e-12 -2.57323174e-12 -4.80505365e-12
 -8.97642230e-02]
supnorm grad right now is: 0.08976422303309164
Weights right now are: 
[-4.90942281e+00 -7.45275903e-01 -3.64511528e+00 -4.47784576e+00
  5.16399170e+00  6.36584244e-01  4.04405272e+00  3.76181755e+00
 -2.06515589e+00 -7.77498081e-01 -2.15083251e+00 -1.81608246e+00
  1.19136243e+00  3.00005196e-01 -3.99284935e-01  4.68929827e-01
 -1.46307188e+00 -5.01594764e-01 -2.49809941e+00 -2.16674051e+00
 -2.28390542e+00 -8.44213626e-01 -2.25606705e+00 -1.85521123e+00
 -8.47720639e-01 -4.74999483e-01 -1.45127734e+00 -7.15332448e-01
  4.14437402e-01  1.47641271e+00  1.52951518e+00  4.75356454e-01
 -1.69496749e+00  1.54016519e+00 -8.57135387e-01 -8.95550608e-01
 -2.63152873e+00 -4.82616869e-01 -9.21897823e-01 -7.47454333e-01
  1.59286738e-01 -1.76433213e+00  1.45823528e+00  1.03497312e+00
  1.90374535e-01  2.50188754e+00 -2.09007740e+00  1.22847892e-02
 -1.37194164e+00 -7.00601359e-01 -3.45567488e-01 -1.49901272e+00
  7.66688525e-01  1.12944762e+00  6.32610191e-01  1.79211245e+00
  1.32164576e+00  6.61013366e-01 -5.46126350e-01 -2.38011626e+00
  2.13977289e+00  2.24410175e+00 -8.85833403e-02  1.35956775e+00
  2.48127647e+01]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -2815.36307149177
gradient value of function right now is: [ 1.72648755e-09  4.11903108e-10  1.72782235e-09  1.72735099e-09
 -1.72633742e-09 -4.11867696e-10 -1.72767217e-09 -1.72720071e-09
  1.79491143e-11  9.33858946e-12  4.88347351e-11  2.75271720e-11
  3.78872660e-10  7.63091846e-11  4.29215639e-10  4.24321228e-10
  4.96691579e-12  6.13042755e-12  3.11353913e-11  1.22119950e-11
  8.22186383e-12  5.34128386e-12  2.76571189e-11  1.39876592e-11
 -2.39536227e-11 -2.21124249e-11 -4.13888035e-11 -6.77190557e-12
 -2.59508437e-12 -4.26568499e-12 -6.20913107e-12 -8.34929224e-13
  4.86757157e-11 -8.19295696e-11 -3.98486625e-11  7.66503885e-12
  2.10389024e-12 -3.43166288e-11 -3.22232356e-11 -1.10227979e-12
 -9.95282918e-12  1.81879250e-11 -1.92687691e-11 -1.26055225e-11
  8.07189877e-12 -1.05778112e-11  1.45401571e-11  1.03078470e-11
 -5.31557148e-12  4.64713931e-12 -8.79601922e-12 -6.97801679e-12
 -3.81533650e-12  6.61422965e-12 -6.90845465e-12 -5.15713769e-12
 -2.50655989e-13  2.63685945e-12  6.95927130e-12  3.12390508e-12
 -4.25018568e-12 -4.31670792e-12 -2.53825277e-12 -4.76953317e-12
 -3.12271387e-02]
supnorm grad right now is: 0.031227138741021468
Weights right now are: 
[-4.91272637e+00 -7.46066998e-01 -3.64842142e+00 -4.48115095e+00
  5.16729526e+00  6.37375338e-01  4.04735886e+00  3.76512275e+00
 -2.06518950e+00 -7.77515941e-01 -2.15092586e+00 -1.81613449e+00
  1.19063388e+00  2.99858349e-01 -4.00111102e-01  4.68113675e-01
 -1.46308070e+00 -5.01606484e-01 -2.49815887e+00 -2.16676328e+00
 -2.28392068e+00 -8.44223842e-01 -2.25611991e+00 -1.85523759e+00
 -8.47674431e-01 -4.74956729e-01 -1.45119738e+00 -7.15319385e-01
  4.14442453e-01  1.47642097e+00  1.52952723e+00  4.75358077e-01
 -1.69506111e+00  1.54032393e+00 -8.57057663e-01 -8.95565269e-01
 -2.63153273e+00 -4.82550441e-01 -9.21835389e-01 -7.47452177e-01
  1.59306020e-01 -1.76436719e+00  1.45827261e+00  1.03499761e+00
  1.90358885e-01  2.50190794e+00 -2.09010560e+00  1.22647541e-02
 -1.37193134e+00 -7.00610286e-01 -3.45550453e-01 -1.49899918e+00
  7.66695916e-01  1.12943490e+00  6.32623572e-01  1.79212246e+00
  1.32164625e+00  6.61008267e-01 -5.46139743e-01 -2.38012239e+00
  2.13978102e+00  2.24411029e+00 -8.85784729e-02  1.35957699e+00
  2.52362853e+01]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1551.6347824792047
W_T_median: 1406.068794458085
W_T_pctile_5: 624.1985510177566
W_T_CVAR_5_pct: 487.9109330091177
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 1.5
F value: -2815.36307149177
-----------------------------------------------
