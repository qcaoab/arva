tracing parameter entered from terminal:  0.8


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1824.7999148596257
gradient value of function right now is: [ 3.15108055e+00  1.84855824e+00  1.48873496e+00  1.56003276e+00
 -3.15108055e+00 -1.84855824e+00 -1.48873496e+00 -1.56003276e+00
  3.63031465e+00  1.91310381e+00  1.08909943e+00  4.05234094e+00
 -1.95233066e-01 -5.56503547e-02 -2.27072708e-02 -2.76548726e-01
 -1.40916414e-01 -7.06303197e-03 -2.77305702e-03 -1.69078740e-01
 -1.67672934e-01 -1.17818699e-02 -4.74625789e-03 -2.02541652e-01
 -1.18680793e+00  1.91984272e-01 -2.86529939e-02  2.88793851e-01
  1.73492966e-01  2.69152263e-03 -8.99395858e-03  6.82468799e-03
  2.39475018e+00 -2.82719436e-03  1.42322210e-01 -1.46056629e-03
 -1.02277493e+00  1.75658889e-01 -2.01304772e-02  2.68892827e-01
 -5.66600922e-01 -6.84097846e+00 -3.77567866e-01 -3.11848025e+00
 -4.26965595e-01 -1.88137597e-01 -7.27183125e-01 -1.85185658e-01
  1.29577805e-02 -6.76684273e-01  1.06038806e-01 -2.59606602e-01
 -3.07662795e-01 -1.19914177e-01 -5.01867010e-01 -1.43041489e-01
 -3.96540272e-01 -2.95902848e-02  5.00781099e-01 -1.44080582e+00
 -4.70919257e-01  9.81746004e-01  2.91489705e+00  4.18371139e+00
 -1.23866852e+01]
supnorm grad right now is: 12.386685150532857
Weights right now are: 
[-2.75345894e+00  1.99660404e+00  1.41351023e+00  9.72922071e-01
  3.00802765e+00 -2.10529573e+00 -1.01457296e+00 -1.68895045e+00
  3.13004731e+00 -1.18147242e-01 -9.27086419e+00  2.82296027e+00
  1.82015748e+00  6.14636852e+00  1.53232014e+01  1.50615616e+00
  5.21926460e+00  3.84073730e+00  7.56467860e+00  3.96319928e+00
  3.93398518e+00  3.90954019e+00  8.84640287e+00  4.01952792e+00
 -5.10281232e-02  4.51925929e+00 -2.31605383e+00  2.25985111e+00
  2.34236968e+00  6.20585811e+00  5.32300216e+00  6.01984040e+00
  4.98084242e+00  9.04319913e+00  3.66761992e+00  8.13273670e+00
 -7.64929069e-01  4.70554960e+00 -1.69224383e+00  2.46767921e+00
 -2.46566997e+00  2.26392939e-03 -5.34138823e-01  2.90415394e+00
 -1.69731423e+00  1.13321468e+01 -3.90570139e+00  1.13971991e+01
  3.71079094e-01  3.64251460e+00  2.06200039e-01  3.73880097e+00
 -1.74899900e+00  7.88183959e+00 -3.50791370e+00  9.06815919e+00
  5.53058966e+00  1.38768049e+00  7.35396738e-01 -1.61162386e+00
  5.03439686e+00  2.97980438e+00  3.73009165e+00 -8.75789571e-01
  2.92447910e+01]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1852.2256679772013
gradient value of function right now is: [ 9.22131610e-01  1.20367786e+00  4.27863839e-01  5.53831702e-01
 -9.22131610e-01 -1.20367786e+00 -4.27863839e-01 -5.53831702e-01
  4.11472519e-01  2.82453652e-01  4.84783302e-02  3.14568199e+00
 -1.03408745e-01 -3.05484011e-02 -3.57324685e-03 -1.76247025e+00
 -1.77823473e-02 -8.26893627e-04 -1.00054659e-04 -5.82916016e-01
  2.94738993e-03 -2.55848263e-03 -3.07326590e-04 -7.24668335e-01
  7.22770637e-01 -1.04855345e+00 -9.49465677e-01 -1.02827601e+00
  2.05854254e-01  8.84520553e-04  7.97530588e-03  2.71354446e-03
  1.10408511e-01  7.58183925e-04  5.26186800e-03  9.45679332e-04
  1.93147662e+00  2.43215274e+00  6.23204408e-01  9.62675387e-01
  9.73742095e-02 -4.25022636e-01 -2.49318832e-01 -4.98188631e-04
 -9.32956192e-01 -4.67423313e-01 -3.22221341e+00 -3.31325957e-01
 -2.67694165e+00  1.17820990e-01 -3.97182311e+00 -6.16577390e-02
 -3.62491284e-01  8.65690553e-02  3.49041097e-01  2.96284465e-02
 -1.80936406e+00  8.47870395e+00  7.29104993e-01 -6.25225451e+00
 -3.12177259e+00  4.34019375e+00  1.67297227e+00 -8.62566722e+00
 -6.33217006e+00]
supnorm grad right now is: 8.625667217414225
Weights right now are: 
[-3.61208241e+00  2.75864047e+00  3.30824536e+00  2.49834673e+00
  3.86665112e+00 -2.86733216e+00 -2.90930809e+00 -3.21437512e+00
 -2.33173191e+00 -1.08908668e-02 -5.39181607e+00  4.07720524e+00
  3.41945590e+00  1.36663035e+01  2.91500403e+01  1.69522148e+00
  7.84652415e+00  1.03495153e+01  2.03134114e+01  5.98028874e+00
  5.91268177e+00  1.09737406e+01  2.24739285e+01  4.85005359e+00
  2.10643719e+00  4.38804748e+00 -8.27029484e+00 -1.96029660e+00
  2.99456457e+00  1.75214700e+01  1.19323990e+01  1.46321122e+01
  7.37514252e+00  1.87370994e+01  6.44900758e+00  1.31609208e+01
 -1.80387831e+00  4.47966487e+00  2.51884275e-01 -2.08472899e+00
  2.58050419e-01 -1.48640308e-01 -4.27605798e+00  2.80347279e+00
 -4.11672303e+00  1.74372133e+01 -4.30164845e+00  2.04717962e+01
 -3.19436877e+00  9.64958766e+00  6.32920053e-01  1.28297552e+01
 -4.22220015e-01  1.63717828e+01 -1.57004397e+00  1.68938403e+01
  7.18139486e+00  1.57882055e+00  9.13398047e-01 -1.69957687e+00
  3.38612357e+00  2.72828551e+00  2.43504878e+00 -1.43070326e+00
  2.91794411e+01]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.4971119694878
gradient value of function right now is: [-9.80745718e-01  5.24488799e-02  4.41494012e-02  6.14629637e-02
  9.80745718e-01 -5.24488799e-02 -4.41494012e-02 -6.14629637e-02
 -2.14563154e+00 -2.53998985e+00 -1.76911025e-01 -5.97334568e+00
 -4.15818042e-02  6.45409299e-02  2.81483958e-05  6.87428604e-01
 -2.37115011e-02  8.51271696e-03  3.71104885e-06 -6.01900999e-02
 -2.40669905e-02  1.20679699e-02  7.28861008e-06 -8.13729823e-02
  5.54410527e-01  5.89313440e+00  2.59295700e+00  3.20849409e+00
 -3.67741770e-02 -9.88889442e-03 -1.02843282e-02 -3.00931943e-03
 -1.57539678e-01 -1.25226236e-06 -4.12284810e-06 -6.49769784e-07
  2.67477025e+00  1.37273336e-01 -3.40830701e-02 -2.16653914e-01
 -1.48319745e-01  7.35335408e+00  5.45853334e-01  3.86768794e+00
 -6.09446848e-01  2.02391596e-01  1.14509238e-01  3.38272356e-02
  8.40719582e+00  5.26342906e-01  1.19251266e+01  5.70036438e-01
  3.18222972e+00  2.05936250e-01  4.19294070e+00  2.32145740e-01
  3.48826865e+00 -1.69894418e+01 -4.30344483e+00  2.18288167e+01
  4.24673108e+00 -1.94320591e+00 -7.37881916e+00  1.64369956e+01
  1.76353570e+01]
supnorm grad right now is: 21.828816663384696
Weights right now are: 
[-4.64809006  3.74506766  5.00411263  3.4330044   4.90265877 -3.85375935
 -4.60517536 -4.14903278 -4.52759618  1.78793885 -6.40137038  4.33267484
  6.59816496 21.39065806 42.73761571  2.06827079 15.62438881 15.13594457
 29.73163203  3.94454647 10.21113247 17.0858283  35.18988926  3.96078038
  3.14558602  4.3195481  -8.75469084 -3.29550203  3.83223826 37.75923429
 22.2333308  20.17684647 20.2856505  24.4815319  10.08898164 16.49879228
 -2.5222459   3.52467219 -0.06105455 -3.81027869  1.51381168  0.21190522
 -5.64884639  2.94399815 -2.39164581 20.61571649 -4.86435023 22.78063755
 -3.83680467 15.32214252  1.28662589 16.54250847 -1.18266444 22.35415693
 -1.60358977 22.52274902  7.51893254  1.83040734  0.5143055  -1.85015048
  4.00215065  2.30471803  2.39808282 -1.65041694 29.36131227]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.0918077019387
gradient value of function right now is: [-2.09322119e-01 -5.65250035e-01 -3.87635906e-01 -1.48189150e-01
  2.09322119e-01  5.65250035e-01  3.87635906e-01  1.48189150e-01
 -5.90762826e-01 -2.55849594e-01 -7.32633458e-02 -1.41732089e+00
  5.67973694e-02 -7.83612918e-03 -5.14613498e-09  2.68512847e+00
  4.20381806e-02 -2.44966904e-03 -9.16408380e-10  2.28671855e+00
  8.04121580e-03 -6.88042970e-04 -1.75780532e-10  4.54770588e-01
 -2.32547359e+00 -3.18219137e+00 -1.14321219e+00 -1.32946644e+00
 -3.98141860e-02  3.66978192e-04  4.47964774e-04  1.61415953e-04
 -3.40989746e-02  5.93672782e-11  4.84992061e-10  1.70293330e-11
 -2.77169396e+00 -2.18642026e+00 -5.23855405e-01 -3.93164736e-01
  2.34870476e-01  5.03389223e-01  2.09974103e-02  7.84460732e-01
  7.50827825e-01  7.14665266e-02  1.02705911e+00  6.98082436e-02
 -5.08623294e+00 -4.48245988e-01 -7.02603908e+00 -3.99170257e-01
 -3.24616400e+00 -3.36662967e-01 -4.47388168e+00 -2.89438405e-01
 -2.18333895e+00  1.25503420e+01  2.65379090e+00 -1.96215290e+01
 -6.88018612e-01 -4.00891680e-01  2.31569790e+00 -1.81018517e+01
  4.19523554e-01]
supnorm grad right now is: 19.621529030317166
Weights right now are: 
[-6.03250061  3.9184704   5.00665004  2.04203458  6.28706932 -4.02716209
 -4.60771277 -2.75806296 -4.83402063  3.20256559 -7.33605674  4.55257352
  9.94251944 27.2180562  44.22054162  2.386626   21.37472668 24.21775931
 29.90169931  2.77160531 13.94737368 23.3190212  35.52801976  4.42068632
  3.67804007  4.18235941 -9.40714803 -4.41424223  4.75666582 55.57187985
 40.56960105 32.39254221 38.08641238 24.52742087 10.20464236 16.5219845
 -2.99599797  4.10650822 -2.24386392 -6.54987599  2.2761341   0.50296589
 -5.2700147   3.47138004 -3.47380765 24.55638513 -4.39685246 24.92179058
 -4.65608493 19.21805599  1.65634674 19.31835278 -2.56978121 27.50009284
 -1.0598187  28.08296822  7.18615395  1.73834154  0.71308387 -1.89504207
  3.91790467  2.35901576  2.28516298 -1.80906949 29.48686125]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.3999790466435
gradient value of function right now is: [-1.98620066e-02  4.26824969e-01  5.68744049e-01  1.96296601e-02
  1.98620066e-02 -4.26824969e-01 -5.68744049e-01 -1.96296601e-02
 -7.96342461e-01 -7.86163438e-01 -4.32569012e-02  3.49393896e-01
 -6.46643686e-02 -6.59411872e-03  1.10572305e-09 -2.49899543e+00
 -9.64311251e-02 -9.54639452e-03  1.35088412e-11 -4.12539431e+00
 -4.48515289e-04 -3.69419538e-05  9.98751909e-11 -3.40777758e-02
  2.61218170e+00  9.11840466e-01  1.59200361e-01  4.27016221e-01
  5.94413356e-01  1.19446310e-03  2.94785404e-04  8.31844519e-05
 -1.91157745e-02  2.65823432e-14  4.15787851e-13  6.42713695e-15
  2.02403569e+00  8.10661056e-01  7.42793358e-02  1.32225804e-01
 -1.78259851e-01  1.01807593e+00 -6.86401106e-01  7.83461017e-01
 -7.53340360e-01 -2.16162260e-01 -1.77350693e+00 -1.69163072e-01
  1.04463303e-01  4.54064019e-02  1.09704809e+00  1.94058121e-02
  2.76772662e-01  7.50793082e-02  1.38537087e+00  4.29107313e-02
  9.50761006e-01 -2.34477460e+00  9.29084506e-02 -1.98948044e+00
 -1.56080625e+00  3.21118805e+00 -2.24659523e-01 -3.44600055e+00
 -2.18910694e+00]
supnorm grad right now is: 4.125394307832169
Weights right now are: 
[-6.59991699  4.14892086  5.61309735  1.20003661  6.8544857  -4.25761255
 -5.21416008 -1.91606499 -5.047238    3.53756825 -6.74081375  4.86213794
 12.05841633 30.32294383 44.22426302  2.9862216  25.03692162 32.94880002
 29.90198775  2.24611949 14.71387423 23.1513912  35.5284775   7.78522511
  4.04758524  4.14049133 -9.50954633 -4.96794663  5.57335145 65.22669641
 49.35754027 34.91038284 50.494153   24.52742505 10.20467951 16.52198564
 -2.56920911  4.52802474 -1.73887127 -9.21209547  2.2461835   0.66487273
 -4.9574893   3.35545268 -3.91212711 29.06953993 -3.84831193 26.87313053
 -5.01167787 21.90428639  2.04803242 21.32768464 -3.24442854 31.39176914
 -0.67616255 32.52615021  7.26561709  1.56941391  0.76121133 -2.01653997
  4.31810384  2.77049904  2.44000029 -1.73894718 29.29525123]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.6507677786317
gradient value of function right now is: [-5.43190174e-01 -2.84770335e-01 -7.44580124e-01 -2.39508402e-03
  5.43190174e-01  2.84770335e-01  7.44580124e-01  2.39508402e-03
 -1.59597833e+00 -1.50306009e+00 -8.03327842e-02 -4.44551831e+00
  1.45868467e-02  5.93301222e-03  2.75592366e-10  1.63804556e+00
  4.44108729e-02  1.08726780e-02  1.37154897e-13  5.28469246e+00
  4.80450800e-05  6.44188886e-06  3.60322255e-11  7.09757854e-03
 -1.87316206e+00  2.71607729e-01  1.72385725e-01  1.63363504e-01
  2.80410366e-02 -2.11195804e-03 -1.03964384e-03 -1.58592798e-04
 -2.48930925e-02 -1.32664536e-16 -3.64568311e-14  3.13750996e-17
 -1.43427377e+00 -1.04758602e+00 -1.08387001e-01 -4.96550810e-02
  1.65097012e-01  2.66573374e+00  4.51243481e-01  2.04043502e+00
  1.73740444e+00  2.63488762e-01  2.51400699e+00  2.92714279e-01
  6.42813118e-01  3.47043903e-02  7.36954436e-01  4.37976639e-02
  2.08570603e-01 -1.75166142e-02  1.37728742e-01 -1.22720854e-02
  3.05440857e-01 -2.46457865e+00 -1.86159803e+00  9.08829110e+00
  7.52414051e-01 -8.93609846e-01 -2.81189350e+00  7.90744266e+00
  1.08911531e+01]
supnorm grad right now is: 10.891153076300355
Weights right now are: 
[ -6.93109882   4.44155394   5.97916191   2.28899685   7.18566753
  -4.55024563  -5.58022464  -3.00502523  -5.11941039   3.701395
  -7.19138567   4.96728246  10.55286081  31.81984925  44.22451922
   3.89553419  25.77112005  43.37476797  29.90199034   2.21185095
  12.40786322  22.23616781  35.52848416  11.85682221   4.50422189
   4.03068767  -9.43566704  -5.9070781    5.13295496  73.60456768
  61.01987259  41.38889107  62.60687489  24.52742505  10.2046797
  16.52198564  -2.67552295   4.57056108  -1.45015893 -11.083034
   1.21053428   0.80062916  -4.57482046   3.43204434  -3.83577096
  32.56510665  -3.40619097  28.7469293   -5.22315389  24.96928518
   1.99640978  22.84743702  -3.94942036  34.46776289  -0.26757509
  35.59382082   6.84771663   1.68467386   1.09866598  -1.99411668
   3.85954097   2.7053831    2.181946    -1.70615053  29.42112774]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.3727631865286
gradient value of function right now is: [ 2.94233926e-01  8.83236591e-02  3.81582005e-01  9.85052484e-05
 -2.94233926e-01 -8.83236591e-02 -3.81582005e-01 -9.85052484e-05
  1.16308264e+00  8.46162253e-01  6.34243273e-03  2.39769120e+00
 -9.87573956e-04  3.31720223e-03 -6.55952734e-10 -4.00156129e-01
 -1.92030899e-02  8.46944328e-03 -1.37071947e-15 -2.46580128e+00
  9.23089270e-09 -2.38496066e-11  1.16779263e-15  2.74180324e-06
  1.64054114e+00  1.76788229e+00  4.21096353e-01  7.63448870e-01
 -6.36283296e-01 -7.64333461e-04 -1.07005378e-03 -1.94537954e-04
  8.21813216e-04  7.00423091e-19  7.04952840e-16  2.13822923e-20
  8.38691113e-01  1.05947105e+00  1.48352547e-01  2.05219454e-01
 -1.56112867e-01 -7.97804021e-01  5.59188202e-02 -5.74434959e-01
 -5.63909999e-01 -5.19994898e-02 -8.76323416e-01 -6.36231110e-02
  1.49463119e+00  8.97718892e-02  2.89857452e+00  9.02062255e-02
  1.99540805e+00  1.50802758e-01  4.12966546e+00  1.36605705e-01
  2.43198336e+00 -1.04985254e+01 -1.89291876e+00  9.45832175e+00
  6.76863326e-01 -1.88348118e-01 -1.02145502e+00  8.59338157e+00
 -3.04521477e+00]
supnorm grad right now is: 10.498525416573377
Weights right now are: 
[ -7.02995178   4.25350371   6.37328735  -0.40442956   7.28452049
  -4.3621954   -5.97435008  -0.31159882  -5.0424363    3.70176514
  -7.82537057   5.35531948   8.15851553  28.1904648   44.22491181
   4.85337017  28.33417678  49.8546843   29.90199036   2.11766956
  13.07979897  22.13584262  35.52848511  21.34843096   4.5053277
   3.72033272  -9.23277751  -6.88623331   4.84662286  82.76807036
  72.34395773  47.41412766  71.43842725  24.52742505  10.20467971
  16.52198564  -2.65324826   4.69341905  -1.28610954 -11.35481018
   1.00325471   0.78353485  -4.23031307   3.49314701  -5.11247293
  36.03808108  -3.36877434  29.78948757  -5.12124833  26.60368432
   2.17250103  23.5262343   -4.38804654  37.39505079   0.14185368
  38.08092818   7.14343546   1.47972199   0.63148114  -2.07375424
   4.38216991   2.62506639   2.52772852  -1.83183818  29.0814048 ]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.3492283667274
gradient value of function right now is: [ 8.74580437e-01  8.28321032e-02  4.40376812e-01  4.67705298e-07
 -8.74580437e-01 -8.28321032e-02 -4.40376812e-01 -4.67705298e-07
  2.96057286e+00  3.00131846e+00  2.44638990e-01  7.03262692e+00
 -3.01603998e-02 -1.45418541e-02 -6.91891343e-08 -6.26683226e-01
 -1.11661568e-01 -2.93131559e-02 -4.29508957e-16 -4.42524657e+00
 -1.10612087e-09 -2.35131766e-11 -5.18629033e-16 -2.40931232e-07
  3.29690263e+00 -1.92584533e+00 -4.85265510e-01 -9.68589636e-01
  3.22451609e-01  2.52688947e-03  1.43880809e-03  2.66978052e-04
  3.60666128e-02  3.15093502e-19  1.39566765e-16  5.98215752e-20
 -1.67112122e+00 -5.04546813e-01 -1.18936749e-01 -1.38422472e-01
 -7.36812736e-01 -6.00073518e+00 -1.97446237e+00 -4.39771081e+00
 -7.21304099e-02 -1.25806348e-01 -7.53491947e-01 -8.28415419e-02
 -2.51692988e+00 -1.08168659e-01 -3.63725847e+00 -1.54104488e-01
 -3.59670133e+00 -1.83769589e-01 -5.10861174e+00 -2.51436942e-01
 -2.43557456e+00  1.45744979e+01  3.60034936e+00 -1.80366576e+01
 -3.30693835e+00  3.23905992e+00  5.24248160e+00 -1.79942782e+01
 -1.95006510e+01]
supnorm grad right now is: 19.500650982437254
Weights right now are: 
[ -7.09335828   4.78277528   6.63835136   0.22459183   7.34792699
  -4.89146697  -6.23941409  -0.94062021  -5.08049272   3.92916865
  -7.21197784   5.29905541   5.16300134  21.52586948  44.23218513
   5.28173106  27.78273934  55.45124287  29.90199036   2.10541042
  14.99994032  22.13584095  35.52848512  28.09500221   4.59739897
   3.62176497  -9.1316759   -7.74203937   5.65427159  90.10110387
  81.61549566  49.92288849  82.60270511  24.52742505  10.20467971
  16.52198564  -2.35324722   4.41132371  -2.3545742  -14.48461768
   0.74354125   0.90247101  -4.3333375    3.1942362   -4.85034343
  38.57779307  -3.1612391   30.67914646  -5.37453236  28.29296563
   2.672275    23.33057086  -4.7738611   40.32037331   0.19020449
  40.66159945   6.94951267   1.5318784    0.83106649  -2.17582743
   4.36131118   2.96416786   2.35508497  -1.83789665  29.26341322]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.5449932413503
gradient value of function right now is: [ 2.51988436e-01 -1.08043805e-01 -6.74204613e-01 -1.65872879e-05
 -2.51988436e-01  1.08043805e-01  6.74204613e-01  1.65872879e-05
  1.86061710e+00  1.53989427e+00  3.13602127e-02  1.61295883e+00
  1.91317439e-02 -5.28437110e-04 -1.27094990e-07  7.30045888e-01
  1.62133364e-01  7.39466861e-03 -8.74142824e-18  6.30741573e+00
 -1.49830077e-06  1.10117098e-09  6.69398789e-14 -1.13083773e-04
 -3.64116802e+00 -2.36850117e+00 -2.43916509e-01 -6.77780149e-01
 -8.38562396e-01 -9.02246060e-04 -4.75711850e-04 -3.54371001e-05
  7.63399011e-03  1.74586215e-20  1.44571885e-15  2.20393247e-21
 -2.46876659e+00 -1.11129991e+00 -9.54938978e-02 -1.87416212e-01
  5.95291329e-01 -1.38267433e+00  1.16565772e+00 -6.04672875e-01
  7.70630036e-01  1.20098026e-01  1.92472834e+00  1.05052594e-01
 -7.59579039e-01 -7.60305850e-02 -1.71665934e+00 -6.80852360e-02
 -2.21426608e+00 -2.16509974e-01 -5.56375936e+00 -2.00570514e-01
 -1.60153410e+00  7.55817435e+00  2.62789709e+00 -8.81203029e+00
  1.76021038e+00 -4.04864126e+00  2.85043541e+00 -7.59416029e+00
 -1.65716134e+00]
supnorm grad right now is: 8.812030289801717
Weights right now are: 
[ -6.92031219   4.68103441   6.82436191  -8.18134181   7.1748809
  -4.7897261   -6.42542464   7.46531342  -4.92534811   4.1641848
  -7.38204142   5.48168037   3.1901564   21.11989382  44.24028031
   5.45859755  29.476008    59.23792797  29.90199036   2.14063332
  15.88793869  22.13579801  35.52848512  22.34659538   4.20454794
   3.17555936  -8.99174938  -8.65904065   5.58825256  94.40852974
  89.80425528  46.792077    89.97861503  24.52742505  10.20467971
  16.52198564  -2.59772997   4.65977348  -1.92417896 -15.08196087
   1.63805679   1.18284554  -4.32572471   3.56417306  -5.03889493
  41.58264827  -2.88826655  31.07643644  -5.37927607  27.21597133
   3.34995386  21.07071522  -4.96278707  43.28592563   0.33750008
  42.82564521   6.60920133   1.30478317   0.79685048  -2.26178805
   4.30006993   2.71268719   2.85862906  -1.8352496   29.24471517]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1852.096446869655
gradient value of function right now is: [ 1.16488105e-01 -4.37279178e-03  1.02301200e-01 -7.54916982e-06
 -1.16488105e-01  4.37279178e-03 -1.02301200e-01  7.54916982e-06
  1.32001375e+00  6.36751505e-01  1.67940581e-01  6.97046379e-01
  4.46511146e-03  3.24425616e-03 -2.33277458e-08  2.14824382e-02
  8.68918232e-03  4.97951427e-03  2.63379687e-19 -8.36192921e-01
 -5.87076910e-08 -2.80513378e-11  5.44292132e-17 -1.47017251e-05
  9.63846821e-01  2.64952615e+00  1.97274313e-01  1.53972709e+00
  1.91345341e-02 -1.15383235e-03 -1.39845448e-03 -1.28568014e-04
  1.97014340e-02 -1.25026221e-22  1.91771347e-17 -8.55697076e-24
  1.14487216e+00  5.59492686e-01  2.95050429e-02  1.27286972e-01
 -3.96796716e-01 -1.22189341e+00  3.21886622e-02 -1.75701514e+00
 -2.65789504e-01  2.18335718e-02 -1.21327784e-01 -1.57738239e-03
  1.07401168e+00  3.96655467e-02  1.59696417e+00  4.29489240e-02
  4.35041415e+00  1.96246666e-01  6.74963738e+00  2.12147591e-01
  2.90680966e+00 -1.53494093e+01 -3.05523622e+00  1.57325176e+01
  1.48373604e+00 -9.11823819e-01 -2.52978892e+00  1.53658756e+01
  2.31601643e+00]
supnorm grad right now is: 15.732517587282622
Weights right now are: 
[-7.00951432e+00  4.61269401e+00  6.83994914e+00 -3.29802539e+00
  7.26408303e+00 -4.72138570e+00 -6.44101187e+00  2.58199701e+00
 -5.15211145e+00  4.08696446e+00 -8.01506691e+00  5.45357419e+00
  2.70114743e+00  2.24424075e+01  4.42600170e+01  6.74573437e+00
  2.94635776e+01  6.32240273e+01  2.99019904e+01  2.08833731e+00
  2.21653926e+01  2.21363521e+01  3.55284851e+01  2.73995519e+01
  4.46717798e+00  3.60954783e+00 -8.47279256e+00 -9.70896662e+00
  5.65518066e+00  9.75983178e+01  9.72990860e+01  4.13400629e+01
  9.77060307e+01  2.45274251e+01  1.02046797e+01  1.65219856e+01
 -2.53307397e+00  4.65998450e+00 -3.84133153e-02 -1.51030177e+01
  9.64266398e-01  1.10048711e+00 -4.45166883e+00  3.16156840e+00
 -5.18427353e+00  4.38958601e+01 -2.89267852e+00  3.14404201e+01
 -5.20370319e+00  2.75909711e+01  4.68099674e+00  2.04548182e+01
 -5.23396953e+00  4.68235859e+01  6.13291988e-01  4.63196050e+01
  6.72993395e+00  1.44433649e+00  7.94174074e-01 -2.14363429e+00
  4.28508485e+00  2.74286086e+00  2.53914676e+00 -1.89972728e+00
  2.91838333e+01]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1851.8983844594438
gradient value of function right now is: [ 5.09304483e-01 -7.50163370e-02 -9.40512691e-01 -9.99640075e-06
 -5.09304483e-01  7.50163370e-02  9.40512691e-01  9.99640075e-06
  2.60493948e+00  2.80283142e+00  1.00025348e-01  3.63059779e+00
 -3.10226556e-03 -4.78475738e-03 -1.98536377e-08  4.15659249e-01
  6.99069244e-02 -3.35887551e-03 -4.59117095e-20  7.64394444e+00
 -4.02937632e-07  2.18942353e-09  1.82122299e-15 -8.46874240e-05
 -1.51732252e+00 -2.62114881e+00 -1.05917230e-01 -1.10178962e+00
 -7.54091797e-01 -4.01588072e-04 -9.48116590e-04  6.88711721e-06
  1.68835072e-02  5.90617694e-22  2.59753462e-11  1.38813987e-23
 -4.79008392e+00 -1.87910581e+00 -1.22605215e-01 -2.09043507e-01
 -2.41320751e-01 -3.89434189e+00 -4.38157249e-01 -2.62770768e+00
  1.45318783e+00  1.60989848e-01  2.33114309e+00  1.56940430e-01
 -6.25851482e-01 -4.98228400e-03 -1.00793014e+00 -3.09939472e-02
 -4.09461448e+00 -2.93295894e-01 -8.05303631e+00 -2.62676923e-01
 -3.31493632e+00  1.43447745e+01  3.30510462e+00 -1.13407758e+01
 -3.73582800e-01 -1.57719850e+00  4.14866154e+00 -9.47193192e+00
 -1.03896493e+01]
supnorm grad right now is: 14.344774522125228
Weights right now are: 
[-7.07286963e+00  4.49388150e+00  6.64316878e+00 -8.87378743e+00
  7.32743834e+00 -4.60257319e+00 -6.24423151e+00  8.15775905e+00
 -5.26003216e+00  4.07775102e+00 -8.20766280e+00  5.45943823e+00
  9.82951033e-02  2.66879193e+01  4.42785726e+01  6.32036737e+00
  2.84904060e+01  6.85323190e+01  2.99019904e+01  2.31602723e+00
  2.26519524e+01  2.21365116e+01  3.55284851e+01  2.31154996e+01
  4.45555299e+00  3.26238655e+00 -7.08748228e+00 -1.10434207e+01
  5.05446149e+00  1.03517637e+02  1.17284151e+02  4.11577041e+01
  1.04823304e+02  2.45274251e+01  1.02046821e+01  1.65219856e+01
 -2.42556156e+00  4.18562330e+00 -2.48371029e+00 -1.70051079e+01
 -1.53803456e-01  1.42907364e+00 -4.59598758e+00  3.16037511e+00
 -5.49075392e+00  4.61743084e+01 -2.79884059e+00  3.16936686e+01
 -5.88404943e+00  1.74868715e+01  5.39876049e+00  1.41578675e+01
 -5.84163114e+00  5.00812865e+01  5.41919075e-01  4.82653508e+01
  6.98606844e+00  1.58621416e+00  1.24877824e+00 -2.09435002e+00
  4.21307886e+00  2.75845936e+00  2.82540995e+00 -1.88813175e+00
  2.92107762e+01]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.7214792895936
gradient value of function right now is: [-2.74639259e-01 -2.73053293e-02 -3.22502139e-01 -4.55452446e-05
  2.74639259e-01  2.73053293e-02  3.22502139e-01  4.55452446e-05
 -1.41986923e+00 -1.39192962e+00 -6.74526882e-02 -1.86977163e+00
 -3.18330113e-03 -8.96795765e-04  3.91914211e-09  1.41874083e-01
  4.07730458e-02  3.64076681e-03  1.36732072e-21  2.97176104e+00
 -1.91203511e-06  1.14857721e-10 -1.40870282e-16 -2.76091436e-04
 -1.26653597e+00 -4.72652617e-01 -2.78592543e-02 -1.84118352e-01
 -8.46418267e-02 -4.86807848e-04 -1.59120767e-03 -7.62873691e-06
 -1.17282679e-02  8.35237610e-25 -5.32430535e-10  1.98102293e-24
 -7.65577944e-01 -3.02890915e-01 -4.28668195e-02 -4.62387732e-02
  3.30943967e-01  1.68818726e+00  4.45906258e-01  1.38932411e+00
  1.30073723e-01  3.49523163e-02  3.98783700e-01  2.24327020e-02
 -1.53681575e-01  2.47665925e-02 -2.19256660e-01  3.20495026e-03
 -9.33593651e-01 -6.34591851e-02 -1.56742546e+00 -5.43184883e-02
 -2.69447293e-01  2.85058933e+00 -1.68538473e-01 -3.12995905e+00
  2.18307786e-01 -4.14732185e-01 -4.24960494e-01 -4.21146176e+00
  5.63053311e+00]
supnorm grad right now is: 5.630533114421608
Weights right now are: 
[ -7.26705938   4.58772802   6.66758221  -9.28161175   7.52162809
  -4.69641971  -6.26864494   8.56558337  -5.79011466   3.43815671
  -7.6846438    5.70431873  -0.98828574  29.78731726  44.28117168
   6.34450751  27.19979082  73.83627771  29.90199036   2.39265529
  26.34974851  22.13661781  35.52848511  23.57190011   4.71457967
   3.37274284  -4.9473528  -11.51223611   5.33889668  96.20737528
 121.68118189  25.84897755 112.14546137  24.52742505  10.20562699
  16.52198564  -2.31742779   4.98959202  -3.94601957 -17.45013312
   0.31101622   1.8229244   -3.82472495   3.32332892  -6.39258017
  49.88610202  -2.43692631  32.60492636  -8.0016097   15.68180516
   6.59270854  12.58408512  -5.93068497  52.64840404   0.76102504
  50.38420744   6.72546505   1.40417681   0.87335378  -2.17624626
   4.48610616   3.00779975   2.94991627  -2.00649092  29.36338225]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1852.3900180593726
gradient value of function right now is: [-4.69927068e-01 -9.13171930e-02 -1.09202886e+00 -4.35863044e-05
  4.69927068e-01  9.13171930e-02  1.09202886e+00  4.35863044e-05
 -1.47244005e+00 -1.56668963e+00 -5.79784115e-02 -3.41896751e+00
  7.22385341e-04  2.54262125e-04  2.45152099e-09  4.94513387e-01
  1.14948127e-01  1.41834842e-02 -1.98741527e-22  9.15118353e+00
 -9.16757276e-07 -2.32443007e-11 -7.20529915e-18 -2.33687475e-04
 -2.62977063e+00 -4.48939705e-01 -4.26246518e-02  1.94834395e-04
 -7.71805594e-01 -2.24364646e-03 -3.61608432e-03 -4.64636416e-05
 -1.16456595e-02 -3.82734305e-24 -1.63431268e-09  7.91217294e-26
 -2.96648063e+00 -1.64584714e+00 -6.56669567e-02 -1.84563203e-01
  4.50028667e-01  2.20057233e+00  9.26082661e-01  1.66259751e+00
  1.27056605e+00  1.99987195e-01  2.64612978e+00  1.57922048e-01
 -9.36454985e-02  2.91545597e-02 -1.21765015e-01  1.57760297e-02
 -1.44602011e+00 -1.60434307e-01 -2.91322054e+00 -1.24483226e-01
  1.06371916e-01  1.00636917e+00 -4.93090076e-01 -6.43609594e-01
  1.38862720e+00 -2.32308700e+00 -6.76324258e-01 -3.83940651e+00
  1.19280826e+01]
supnorm grad right now is: 11.928082577518303
Weights right now are: 
[ -7.17291706   5.2246914    6.75592728  -7.74338482   7.42748577
  -5.33338309  -6.35699001   7.02735644  -5.83701388   3.28068987
  -8.8529764    5.82299446  -1.36680354  30.25068953  44.28184711
   7.19565703  26.08443049  78.48387037  29.90199036   2.59383205
  28.85947945  22.13667935  35.52848511  26.48175129   4.82099774
   3.37466323  -4.39682066 -12.09033988   5.03093108 100.30390198
 125.28041228  20.85791845 120.11742973  24.52742505  10.20979291
  16.52198564  -2.51979234   5.06690787  -5.46343843 -17.99039631
  -0.21426937   1.74480585  -3.75369024   3.40807006  -5.9923574
  51.68586386  -2.49316112  33.30794657  -8.53973719  14.3303676
   7.7797368   12.71543641  -6.35514481  55.91046601   0.81153474
  52.03484564   6.75411241   1.31363433   1.07641988  -2.21408132
   5.15954935   3.19337787   2.98664377  -2.03077523  29.37492868]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.5618526980347
gradient value of function right now is: [ 2.00033267e-02  1.39597843e-02  1.79722154e-01  1.76145346e-04
 -2.00033267e-02 -1.39597843e-02 -1.79722154e-01 -1.76145346e-04
 -3.15657461e-01 -1.74496061e-01 -2.68722077e-02  1.09560076e-01
 -2.81809586e-04 -2.96574906e-04  1.82218036e-10 -5.03915995e-02
 -9.25843330e-03 -6.00995714e-03 -8.62624504e-23 -1.24410488e+00
  4.42246087e-06  1.16157186e-11 -1.61401190e-19  6.88576573e-04
 -1.09719375e-02 -6.03016720e-01 -3.31400660e-02 -3.62599850e-01
  3.56935573e-01  2.76305482e-04  1.00180259e-04  1.26460855e-05
 -4.56837344e-03  1.98176320e-25 -6.22049093e-11  2.07027948e-27
  2.78706985e-01  1.99417777e-01 -6.41076173e-03  1.55532879e-02
 -1.35039627e-01  2.35166126e-01 -3.40867966e-01  3.08243943e-01
 -2.61753316e-01 -3.99642827e-02 -5.92896922e-01 -3.23427601e-02
 -1.63208815e-01  1.29998316e-03 -2.39603392e-01 -1.15635898e-02
 -1.24290168e+00 -3.72977844e-02 -1.61251171e+00 -5.82405423e-02
 -5.18174924e-01  5.19217827e+00  4.40439159e-01 -5.53695297e+00
 -2.56168939e-01  4.91557535e-01  3.95927739e-01 -5.95408087e+00
 -1.01085263e+00]
supnorm grad right now is: 5.954080868956917
Weights right now are: 
[ -6.93894964   5.84468432   6.95753351  -9.12150189   7.19351835
  -5.95337601  -6.55859625   8.40547351  -5.7806118    3.85481877
  -8.21990782   5.67411637  -0.58063536  28.34158443  44.28216414
   8.69443425  27.04109298  81.92146179  29.90199036   2.25514832
  31.24957229  22.13669281  35.52848511  27.34009141   4.60098238
   3.25146625  -5.38400673 -12.02329721   5.45604353 102.54713368
 126.59601186   8.81778347 127.24601411  24.52742505  10.22029729
  16.52198564  -2.29524382   5.30332544  -5.43736385 -17.69255268
  -0.33280193   1.96615247  -3.92456606   2.98544954  -6.73017076
  53.87054174  -2.12966274  32.90952671  -9.56631182  12.66422716
   8.52477693  14.04066149  -6.3778681   58.38569393   0.89659099
  53.97043356   6.19532391   1.18669989   0.73420332  -2.36797641
   4.99993171   3.27468137   2.99507451  -2.04625708  29.37669842]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.6652897996444
gradient value of function right now is: [-2.63908452e-01  6.37112724e-03  4.79976714e-01  1.50308513e-05
  2.63908452e-01 -6.37112724e-03 -4.79976714e-01 -1.50308513e-05
 -1.26004284e+00 -1.43473117e+00 -7.17496248e-02 -1.78296340e+00
  1.24556197e-03  1.74579776e-04  2.76859531e-10 -3.21030675e-02
  1.13538940e-02 -6.82512677e-03  4.78765269e-23 -3.93959542e+00
  2.33891347e-07 -3.90151067e-11 -9.11819032e-19  9.65868619e-05
  1.55950891e-01  1.12633210e+00  2.76084745e-02  5.26530323e-01
  7.90383565e-01  5.94506316e-04  1.02387117e-03  6.96058485e-06
 -1.03304702e-02 -6.14855755e-26 -5.59829723e-10 -1.68302182e-28
  1.91556975e+00  7.39894605e-01  9.73956066e-02  9.22759072e-02
 -1.80877359e-01  2.52301766e+00 -9.63594842e-02  1.37357669e+00
 -4.05303313e-01 -3.28628964e-02 -4.62283461e-01 -4.00717797e-02
  6.27698930e-01 -2.46796818e-02  7.07495080e-01  1.62216277e-02
  2.95560158e+00  1.36819953e-01  4.20452603e+00  1.40671436e-01
  1.47643140e+00 -8.46383052e+00 -2.07120793e+00  9.96237310e+00
  1.31472082e+00 -7.15566196e-01 -2.06488355e+00  8.29220382e+00
  5.83834896e+00]
supnorm grad right now is: 9.962373101962323
Weights right now are: 
[ -6.83035166   6.03419079   6.99250668 -11.33757515   7.08492037
  -6.14288248  -6.59356941  10.62154677  -5.66054989   3.50060928
  -7.86834349   5.8934234   -0.18598289  30.23592093  44.28329173
  10.02413782  26.61773707  85.08964211  29.90199036   2.15736589
  33.47470127  22.13672203  35.52848511  26.74779334   5.13344204
   3.40595863  -5.06201703 -11.76796588   5.37639173 106.02403863
 128.77748324   2.25325605 134.17988372  24.52742505  10.22343699
  16.52198564  -2.26588054   4.71569993  -5.47855314 -18.6040464
  -0.36904291   1.96353383  -3.79117152   3.10116911  -6.90351421
  55.78384425  -2.42388087  33.29907933 -10.67177247  12.46515247
   9.2464317   15.49840882  -6.02676848  61.58798499   0.84006163
  55.72314473   6.34394854   1.56098612   0.79495196  -2.25093632
   5.39382013   3.18726072   3.24330274  -1.95246962  29.35320934]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1851.7903554052714
gradient value of function right now is: [-1.46859405e+00 -3.98321779e-03 -2.29021332e-01 -2.53611303e-04
  1.46859405e+00  3.98321779e-03  2.29021332e-01  2.53611303e-04
 -4.95536800e+00 -4.70333253e+00 -7.26559477e-02 -1.17179195e+01
  1.17150278e-02  2.47660822e-03  5.26333145e-09  3.48086805e-02
  2.18668374e-01  1.77365865e-02  2.48734940e-23  3.70096669e+00
 -5.63097065e-06 -4.35966249e-10 -1.58635072e-18 -1.53966793e-03
 -5.24690622e+00  3.21985161e+00 -1.46912009e-01  1.73431816e+00
  4.07748178e-01 -2.02797046e-03 -3.27311991e-03 -6.33949736e-05
 -1.55676619e-02 -2.83566744e-27 -2.17113510e-10 -7.29822990e-30
  4.65491892e+00  1.30900146e+00  2.09817416e-01  2.29064129e-01
  8.96819097e-01  9.36521425e+00  2.44834702e+00  3.90506155e+00
 -4.17633267e-03  1.24421874e-01  8.41809159e-01  3.86730137e-02
  1.04036725e+00 -9.26841976e-02  1.41873638e+00  6.23731614e-02
  6.54381815e+00  2.91124454e-01  1.23688503e+01  2.76881577e-01
  6.86171473e+00 -3.39746124e+01 -9.84994663e+00  3.48902994e+01
  4.96940500e+00 -4.93629770e+00 -6.65400082e+00  2.14794437e+01
  3.45454619e+01]
supnorm grad right now is: 34.89029937908446
Weights right now are: 
[ -6.88155319   7.07353224   6.88313885 -14.17678382   7.1361219
  -7.18222393  -6.48420158  13.46075544  -5.8187353    3.65792704
 -10.18564613   5.62064629  -2.11970162  27.95215663  44.28354563
   9.88187046  25.24886155  87.25358946  29.90199036   2.39765248
  34.67729121  22.13673939  35.52848511  26.20810233   4.91747466
   3.44859504  -5.37891213 -11.82445073   5.70940857 110.55398236
 133.48975103  -7.61419536 142.43594355  24.52742505  10.22431216
  16.52198564  -2.28316962   4.69639378  -5.56270527 -19.41171205
   0.17322751   1.84441853  -3.46082642   2.89452057  -7.26153258
  58.4167788   -2.40081036  32.67979865 -11.11305313  13.27588767
   9.06547888  15.43269811  -6.30465023  64.03505708   0.71859455
  56.96162123   6.24676823   1.26053134   0.62107886  -2.29062066
   5.45661957   3.16104603   3.35375213  -2.03167477  29.45513785]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.8184461194087
gradient value of function right now is: [-3.98086492e-01 -1.38293983e-02 -1.46254960e-01 -9.76284552e-05
  3.98086492e-01  1.38293983e-02  1.46254960e-01  9.76284552e-05
 -1.34990619e+00 -1.20857300e+00 -1.96651804e-02 -2.79026409e+00
  1.30327521e-03  1.35718876e-04  2.36318616e-10  7.21464608e-02
  3.66869188e-02  4.52815689e-03  3.66994332e-25  6.38266521e-01
 -4.76101101e-06 -5.36110345e-11 -1.92069178e-20 -8.86667431e-04
 -1.09307837e+00  3.45277447e-01 -4.12305913e-02  1.15948602e-01
 -1.05763874e-02 -3.30937381e-04 -1.59115193e-03 -9.94380609e-06
 -4.55042730e-03 -3.36770124e-29 -1.75946731e-11 -1.69798558e-32
  7.47232767e-01  1.23121663e-01  2.16202378e-02  5.23866839e-02
  1.90672938e-01  1.98920485e+00  4.76371970e-01  1.01607279e+00
 -8.44262801e-03  1.49344663e-02  1.66445353e-03  5.90171833e-03
  8.68144678e-02  8.31681983e-03  1.22056486e-01  1.11302004e-02
  6.45378216e-01  3.17229162e-02  1.68708113e+00  2.52917262e-02
  1.11313718e+00 -3.36708146e+00 -1.82209742e+00  4.15092780e+00
  7.42407848e-01 -4.84923567e-01 -1.13964187e+00  1.64775560e+00
  6.32538181e+00]
supnorm grad right now is: 6.325381806781863
Weights right now are: 
[ -6.81260134   8.11065001   7.07667619 -15.12201792   7.06717005
  -8.2193417   -6.67773893  14.40598954  -5.91918009   3.65094026
  -9.99153482   5.53837024  -1.50577085  30.05751309  44.28386293
  10.9314765   25.25760263  90.76871255  29.90199036   2.2499286
  40.81263376  22.1368167   35.52848511  26.61136739   4.92915796
   3.13550219  -4.98625218 -11.54226436   5.26411847 114.80931739
 138.58738672 -12.14943107 149.96686675  24.52742505  10.22549747
  16.52198564  -2.1865102    5.11132874  -4.88857761 -17.57477941
  -0.47522087   1.84834475  -3.40423817   2.95599326  -5.91352275
  60.16821432  -2.19279788  32.43300539 -11.34284733  13.72926204
   9.8608068   16.4070576   -6.32595806  66.26890277   1.02586629
  57.92655936   6.30880985   1.36504715   0.6241218   -2.36307458
   5.33721469   3.20207091   3.34793618  -2.04186137  29.32281884]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.4759267094776
gradient value of function right now is: [ 5.62143970e-01 -7.59968602e-03 -5.47845266e-01 -7.26724108e-05
 -5.62143970e-01  7.59968602e-03  5.47845266e-01  7.26724108e-05
  2.53792553e+00  2.48713162e+00  3.52417367e-02  3.95164359e+00
 -1.41285818e-03 -1.00385685e-04 -5.18736851e-11  3.68743436e-02
  2.09870560e-02 -1.74178664e-03 -4.60458015e-25  4.48414170e+00
 -2.73262966e-06  4.19582153e-11  3.28800814e-20 -7.12231166e-04
 -1.91236952e-01 -1.97166223e+00  2.01556068e-02 -9.13288580e-01
 -5.43592579e-01  2.93227238e-04 -1.64039287e-04  2.56101187e-05
  6.19016016e-03  6.46213854e-28  3.29872808e-10  3.09934908e-31
 -2.82530670e+00 -1.20169946e+00 -7.56687378e-02 -2.12452360e-01
 -6.63985336e-02 -3.37797063e+00 -2.12963624e-01 -1.32788119e+00
  3.10584510e-01  4.99294782e-03  6.12012198e-01  1.29906689e-02
 -2.00983047e-01  4.54611686e-02 -3.02391708e-01 -8.12814198e-04
 -3.92019217e+00 -1.97260580e-01 -7.85258787e+00 -1.69997239e-01
 -3.01062884e+00  1.47414772e+01  4.89254449e+00 -1.66656193e+01
 -4.12554962e-01 -2.30836967e-01  3.32275658e+00 -1.10009419e+01
 -1.04810549e+01]
supnorm grad right now is: 16.665619271975622
Weights right now are: 
[ -6.50648258   7.37949293   6.75960467 -16.23774803   6.76105129
  -7.48818462  -6.3606674   15.52171965  -5.63124544   3.99231775
  -9.31722099   5.80208574  -1.94941343  35.68944701  44.28400369
  11.45959854  25.12974345  92.63184287  29.90199036   2.39787786
  43.36296071  22.13685387  35.52848511  25.81061026   4.94793581
   3.21775806  -5.3029046  -11.41284028   5.36736362 117.61981127
 143.83852483 -22.23675669 155.51478009  24.52742505  10.22688662
  16.52198564  -2.32795612   4.83510695  -3.77507065 -19.62259569
  -0.30875508   2.15036017  -3.434782     2.95239544  -5.91016709
  61.88598357  -2.44705613  32.26229783 -11.57304441  12.81310135
  10.39160042  16.89517739  -6.13017546  69.15726593   0.8976535
  59.3743439    6.62231258   1.37944568   1.0044219   -2.43583536
   5.39308922   3.49261533   3.8522264   -2.07324714  29.33384787]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.1943371648074
gradient value of function right now is: [ 1.07716137e-01  2.20146446e-02  2.58020265e-01  2.63113638e-04
 -1.07716137e-01 -2.20146446e-02 -2.58020265e-01 -2.63113638e-04
  2.60915725e-02  9.85151580e-02 -1.02471091e-02  2.92435660e-01
 -4.73880614e-04  6.05722201e-05 -3.65981815e-11 -1.18990340e-01
  3.75326504e-02  2.19094924e-03 -3.03195105e-27 -3.70117799e-01
  1.75034786e-05 -3.23746334e-11  2.22298997e-22  2.39340656e-03
 -5.95730778e-01  6.86147685e-02  3.17973604e-02 -1.33871497e-01
 -2.10503266e-01 -1.99443163e-04 -1.01472567e-03 -1.49201747e-07
 -1.79420196e-03  4.44182170e-31  1.38374967e-11  5.80354663e-34
  6.93008618e-01  7.03675326e-01  8.94871701e-02  6.48530783e-02
  6.44430506e-02  1.93414622e-01  3.92844722e-01  2.20549100e-01
 -3.89819541e-01 -2.09680168e-02 -3.83130072e-01 -2.69175760e-02
  6.14881910e-01  2.98106698e-02  7.43678616e-01  4.08330413e-02
  1.42959292e+00  7.25241893e-02  9.28926749e-01  8.71397671e-02
 -1.06827326e-01 -2.40314785e+00 -2.10795113e-01  5.63328606e+00
  1.07654065e+00 -9.77855900e-01 -5.19563212e-01  6.55245723e+00
  2.01066275e+00]
supnorm grad right now is: 6.552457234520339
Weights right now are: 
[ -6.5059125    8.67188476   6.80965629 -17.38569999   6.76048121
  -8.78057645  -6.41071902  16.66967161  -5.88667919   3.68669345
  -9.26591423   5.7882514   -1.82641395  29.72860932  44.28420061
  10.76287692  25.64563341  95.14685589  29.90199036   2.22087805
  47.0239144   22.13700688  35.52848511  25.74999119   4.82289338
   2.68963591  -5.82571133 -11.51300772   5.29785683 116.4909386
 146.92579374 -31.11524777 161.18900342  24.52742505  10.22787672
  16.52198564  -2.28939455   5.22565706  -4.864018   -19.25648585
  -0.54142386   1.97686711  -3.48389169   3.06962424  -6.18385567
  63.73749221  -2.39644827  31.08669112 -12.60598304  12.17197665
  10.61062536  18.18440667  -6.0348135   71.89474184   0.91911846
  60.15994141   6.36148837   1.49057674   0.94601086  -2.31114453
   5.33549928   3.27135544   3.737474    -1.98588515  29.3258634 ]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.486809772622
gradient value of function right now is: [-1.47687204e-01 -2.08128494e-02 -5.56838956e-01 -2.33931267e-04
  1.47687204e-01  2.08128494e-02  5.56838956e-01  2.33931267e-04
 -5.98102803e-01 -1.67239800e-01 -1.05180088e-02 -9.73511423e-01
  3.17088704e-04 -2.12126593e-04  8.17756848e-11  1.16719695e-01
  2.22119638e-02  4.53276161e-03  1.57943227e-27  3.99440788e+00
 -1.48632583e-05 -8.58293735e-11 -2.24746096e-22 -2.57820962e-03
 -1.56968383e+00 -2.09869782e+00 -6.00307437e-02 -1.14228419e+00
 -4.97144164e-01 -2.01479055e-04 -1.55251555e-03  9.58393954e-06
 -2.24086535e-03 -3.61069652e-31 -6.35784847e-13  3.24899548e-35
 -1.92468935e+00 -9.86904123e-01 -1.05716029e-01 -1.19433847e-01
  4.12980200e-01 -2.82975160e-01  4.68867243e-01  4.69866957e-01
  3.78355813e-01  2.52375863e-02  6.29786485e-01  2.64291015e-02
 -5.41372357e-01  5.62813952e-02 -6.85368457e-01 -1.19127006e-02
 -3.71204050e+00 -1.41932453e-01 -6.44903523e+00 -1.31245595e-01
 -3.30038247e+00  1.51141070e+01  2.60089668e+00 -1.25469969e+01
 -3.54287719e-01 -3.07218694e-01  1.82694523e+00 -1.02003587e+01
  5.47571225e-01]
supnorm grad right now is: 15.11410695505495
Weights right now are: 
[-6.80325829e+00  8.87640546e+00  6.92830357e+00 -1.93190558e+01
  7.05782701e+00 -8.98509715e+00 -6.52936630e+00  1.86030274e+01
 -5.79283513e+00  3.52754531e+00 -1.09534538e+01  5.66859690e+00
 -2.79685705e+00  3.15654031e+01  4.42842839e+01  1.09595794e+01
  2.62250432e+01  9.74491659e+01  2.99019904e+01  2.43460571e+00
  4.96192346e+01  2.21370632e+01  3.55284851e+01  2.56191503e+01
  5.17634201e+00  2.82521729e+00 -5.08465872e+00 -1.10380580e+01
  5.42899219e+00  1.18501938e+02  1.53220300e+02 -3.71874769e+01
  1.69940127e+02  2.45274251e+01  1.02280539e+01  1.65219856e+01
 -2.14538221e+00  4.69306008e+00 -3.97106526e+00 -2.01077765e+01
  4.02097705e-02  1.91996067e+00 -3.62562189e+00  2.92553082e+00
 -6.10562748e+00  6.56124298e+01 -2.21011338e+00  3.04439213e+01
 -1.27085055e+01  1.38715861e+01  1.07761510e+01  1.89717354e+01
 -5.99823054e+00  7.43026720e+01  9.79102587e-01  6.15312272e+01
  6.70634614e+00  1.72062928e+00  6.87038471e-01 -2.51097253e+00
  5.31418689e+00  3.33313039e+00  3.58935489e+00 -2.04989889e+00
  2.93994109e+01]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.6528089319174
gradient value of function right now is: [ 4.52778278e-01  5.80269090e-03 -6.55605943e-02  1.04486291e-04
 -4.52778278e-01 -5.80269090e-03  6.55605943e-02 -1.04486291e-04
  1.23328074e+00  1.24566641e+00 -6.36349207e-03  3.48790513e+00
 -3.77439392e-03 -2.93908152e-04 -8.20321010e-11 -3.86377849e-02
 -5.21416131e-02 -8.70135484e-03 -5.52885117e-27  7.06914610e-01
  4.45253782e-06  5.17675450e-10  7.52644479e-22  1.37768688e-03
  8.50540807e-01 -1.73867978e+00 -2.08196592e-01 -8.13236433e-01
  2.01246087e-01  8.78464526e-04  2.09846197e-03  2.99919505e-05
 -3.30830788e-04  1.75044985e-30  2.46959948e-11  1.14219488e-34
 -2.01774104e+00 -9.53496000e-01 -2.35854140e-01 -1.75089804e-01
 -1.58801167e-01 -2.53714158e+00 -7.81626201e-01 -5.87568357e-01
  4.22448460e-02 -3.52317846e-02 -1.74908916e-01 -1.42133373e-02
 -1.29164808e+00 -3.00704288e-02 -1.69833041e+00 -6.61671642e-02
 -4.61323916e+00 -1.67436855e-01 -6.77178883e+00 -1.92412075e-01
 -2.36737767e+00  1.67902997e+01  4.93017013e+00 -1.93700518e+01
 -1.18379107e+00  4.91772122e-01  3.05033728e+00 -1.68028136e+01
 -1.13613608e+01]
supnorm grad right now is: 19.37005183428991
Weights right now are: 
[-6.58444068e+00  8.37444579e+00  7.22820465e+00 -2.19713868e+01
  6.83900939e+00 -8.48313748e+00 -6.82926738e+00  2.12553584e+01
 -5.69946255e+00  3.71993190e+00 -9.49686512e+00  5.75465971e+00
 -3.26750141e+00  3.38542384e+01  4.42844448e+01  1.08348815e+01
  2.50895959e+01  9.92801545e+01  2.99019904e+01  2.42216206e+00
  5.18070815e+01  2.21372393e+01  3.55284851e+01  2.33318000e+01
  5.27437449e+00  3.08240097e+00 -5.01696999e+00 -1.11726425e+01
  5.79072321e+00  1.15840275e+02  1.58929302e+02 -4.58315255e+01
  1.75708827e+02  2.45274251e+01  1.02281423e+01  1.65219856e+01
 -2.58763834e+00  5.15295082e+00 -3.47165795e+00 -2.01759677e+01
  8.50725108e-03  2.14620155e+00 -3.64098819e+00  3.09216654e+00
 -5.60350763e+00  6.85190902e+01 -2.45524189e+00  3.10383777e+01
 -1.38608347e+01  1.29466136e+01  1.09281964e+01  1.95256152e+01
 -5.94236823e+00  7.67509999e+01  1.04213999e+00  6.30703919e+01
  6.99644121e+00  1.54548181e+00  1.06000625e+00 -2.63128864e+00
  5.28064428e+00  3.49309270e+00  3.76614279e+00 -2.24062720e+00
  2.93782740e+01]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.338507712974
gradient value of function right now is: [ 5.85466071e-01 -2.22892615e-03 -2.13623158e-01 -4.58542483e-06
 -5.85466071e-01  2.22892615e-03  2.13623158e-01  4.58542483e-06
  2.92415650e+00  2.79943566e+00  1.83274254e-01  3.84399788e+00
 -3.02930562e-04 -7.10435461e-05 -3.06142503e-11  1.89320960e-02
  1.13969361e-02  3.04931891e-03 -2.85270263e-27  1.89656053e+00
 -4.39445995e-07 -1.12647052e-11  1.57021342e-22 -9.16229054e-05
  1.92242113e-01 -5.26772668e-01  3.65110782e-02 -2.69630790e-01
 -7.31886386e-01 -5.24552219e-04 -1.53622724e-03  8.23033575e-06
  1.65447342e-02  1.02910014e-31  1.89560812e-11  4.12396749e-36
 -1.42895359e+00 -3.44680706e-01 -2.70988122e-02 -3.15953270e-02
 -1.78989286e-01 -4.46231801e+00 -1.34531717e-01 -3.26954726e+00
  3.19538403e-01  1.85789174e-02  3.32204502e-01  2.78029361e-02
  2.29916168e-02  5.92941892e-02  5.03336329e-02  1.24310119e-02
 -7.74850776e-01 -2.47865585e-02 -1.84063758e+00 -2.43105745e-02
 -8.28056615e-01  3.48067331e+00  1.01969136e+00 -9.21217531e-01
 -7.62182444e-01  6.06776146e-01  1.18199583e+00  5.22473144e-01
 -7.53869460e+00]
supnorm grad right now is: 7.538694596544455
Weights right now are: 
[-6.59378130e+00  9.31793282e+00  7.34324051e+00 -2.27430565e+01
  6.84835001e+00 -9.42662451e+00 -6.94430324e+00  2.20270281e+01
 -5.65642516e+00  4.15654254e+00 -9.13328096e+00  5.96127233e+00
 -5.71702103e-01  3.66678730e+01  4.42844790e+01  1.10678911e+01
  2.59074622e+01  9.98936630e+01  2.99019904e+01  2.26971642e+00
  5.65093510e+01  2.21375093e+01  3.55284851e+01  2.45696987e+01
  4.75782006e+00  2.98316397e+00 -4.91827634e+00 -1.11378697e+01
  5.29103419e+00  1.14290982e+02  1.64247741e+02 -5.37673992e+01
  1.81519670e+02  2.45274251e+01  1.02283876e+01  1.65219856e+01
 -2.75345234e+00  4.67425642e+00 -3.51622100e+00 -1.86501529e+01
  1.67815337e-01  2.26019602e+00 -4.12416394e+00  2.61610858e+00
 -4.88552476e+00  7.06495385e+01 -2.77868911e+00  3.15586619e+01
 -1.37228612e+01  1.25036381e+01  1.16177596e+01  2.02497729e+01
 -5.75003053e+00  7.98500124e+01  7.03192677e-01  6.42650480e+01
  6.71412204e+00  1.47414739e+00  7.77327702e-01 -2.44747699e+00
  5.21293727e+00  3.57865921e+00  3.31613907e+00 -2.14673835e+00
  2.92589760e+01]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1852.8329328277948
gradient value of function right now is: [-7.58423256e-01 -4.77013755e-02 -6.07865412e-01 -4.21219615e-03
  7.58423256e-01  4.77013755e-02  6.07865412e-01  4.21219615e-03
 -2.63097214e+00 -2.60164951e+00 -7.66853649e-02 -5.14871112e+00
  2.53348646e-03  1.23340243e-04  1.91500419e-11  1.92359217e-01
  1.19255522e-01  1.36941391e-02  4.91385842e-28  5.17785086e+00
 -3.89167846e-04 -2.78515693e-09 -1.65967001e-22 -5.58780470e-02
 -2.79911081e+00  7.22994357e-01  6.69771399e-03  4.54304705e-01
 -6.75212083e-01 -2.41647009e-03 -2.79874783e-03 -3.95079049e-05
 -1.09645646e-02 -9.36411324e-30 -5.06262976e-12 -2.03434858e-35
  6.83535298e-01  3.42447604e-01  8.11003063e-02  6.87816604e-02
  6.22795978e-01  3.82102092e+00  1.42112999e+00  2.19530839e+00
  2.44884767e-01  8.34168898e-02  7.84124420e-01  4.53534200e-02
  4.33967951e-01  2.85758600e-02  5.78688237e-01  3.20578596e-02
  1.90923402e+00  6.26951291e-02  3.01523830e+00  6.06588160e-02
  1.99727480e+00 -9.18661394e+00 -4.66858271e+00  1.36095525e+01
  1.98900533e+00 -2.35892331e+00 -3.10713261e+00  5.95378083e+00
  1.70173761e+01]
supnorm grad right now is: 17.01737606528979
Weights right now are: 
[-6.90971591e+00  8.92497721e+00  6.91440982e+00 -2.88136906e+01
  7.16428462e+00 -9.03366890e+00 -6.51547255e+00  2.80976622e+01
 -5.93932845e+00  3.83218180e+00 -1.01170680e+01  5.83393600e+00
 -1.28492940e+00  3.70680871e+01  4.42844861e+01  1.11005831e+01
  2.60743947e+01  1.02240431e+02  2.99019904e+01  2.54094181e+00
  5.91309196e+01  2.21375918e+01  3.55284851e+01  2.11908960e+01
  4.63171573e+00  3.29667999e+00 -5.74590506e+00 -1.07906786e+01
  5.34805812e+00  1.14935978e+02  1.67180351e+02 -6.32106279e+01
  1.87034966e+02  2.45274251e+01  1.02285000e+01  1.65219856e+01
 -2.82715461e+00  5.20375240e+00 -2.48601558e+00 -1.82101761e+01
  1.18764318e-01  2.37640328e+00 -3.86943986e+00  3.32343970e+00
 -5.66648830e+00  7.17247479e+01 -2.95830126e+00  3.15250210e+01
 -1.44601029e+01  1.55249469e+01  1.18636261e+01  2.30197368e+01
 -5.69628618e+00  8.28168272e+01  7.87820590e-01  6.50729024e+01
  6.77931668e+00  1.51598231e+00  6.17263689e-01 -2.42738716e+00
  5.75457516e+00  3.04366467e+00  2.96317804e+00 -2.20348156e+00
  2.91887140e+01]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.5007400084673
gradient value of function right now is: [ 3.27933941e-01  5.84086500e-03  1.23167794e-01  6.33504387e-05
 -3.27933941e-01 -5.84086500e-03 -1.23167794e-01 -6.33504387e-05
  2.12082327e+00  1.62968735e+00  2.51328916e-02  2.16924823e+00
  1.59194157e-03  2.56047525e-04 -1.14653552e-11 -3.94538516e-02
  3.90706234e-02  4.65087689e-03 -5.42904096e-28 -1.45194446e-01
  4.86310954e-06 -2.97191956e-10  7.81471652e-24  1.27590575e-03
  2.84183426e-01  1.32768645e+00  1.46828718e-02  7.17883603e-01
 -5.29309223e-01 -7.21011380e-04 -1.07189203e-03 -1.53177130e-05
  4.81347012e-03  1.47515208e-33  8.99780184e-12 -2.73036137e-40
  7.30952408e-01  7.41812670e-01  8.20134684e-02  8.67234637e-02
 -1.05277320e-01 -8.61363227e-01  2.41808308e-01 -9.27680480e-01
 -3.09155676e-01 -5.01285800e-03 -3.42280913e-01 -1.59558456e-02
  4.71974100e-01 -1.22310145e-02  6.21245405e-01  2.54842546e-02
  2.43428946e+00  8.85166442e-02  4.02808026e+00  8.90985467e-02
  1.88363280e+00 -9.98537654e+00 -2.09923332e+00  1.04906131e+01
  7.62511912e-01 -4.24880243e-01 -4.31736350e-01  8.96951369e+00
  2.17463326e-01]
supnorm grad right now is: 10.490613143073672
Weights right now are: 
[ -6.79803643   9.76734986   7.4596809  -28.55653774   7.05260514
  -9.87604155  -7.06074363  27.84050935  -5.46801892   4.12371134
 -10.87599651   5.95607431  -2.14852362  40.45350153  44.28448903
  10.56709049  25.77712935 103.33309097  29.90199036   2.30537305
  65.09642825  22.1379193   35.52848511  22.68899862   4.89146037
   2.93594753  -5.68168682 -10.98766192   5.58200071 121.09035097
 173.78077843 -70.02284226 192.58014813  24.52742505  10.22850305
  16.52198564  -2.56821911   4.66708882  -3.75239458 -17.34739736
   0.41422116   2.0679372   -4.03142746   3.08252312  -5.70816879
  72.76756157  -2.67290556  30.21936515 -14.70150734  12.5926431
  12.5460303   21.66757421  -6.08513722  84.69270066   0.81565318
  64.88036871   6.71656135   1.45053185   0.71326968  -2.49952049
   5.17285761   3.21729605   3.98753006  -2.11351193  29.2877888 ]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.048898608981
gradient value of function right now is: [-5.67713425e-02 -1.88791416e-03 -3.15181490e-02 -1.01529819e-05
  5.67713425e-02  1.88791416e-03  3.15181490e-02  1.01529819e-05
 -4.90747018e-01 -7.28761262e-01 -3.93802152e-02  1.67842300e-01
 -4.14523521e-04 -4.80786701e-05  1.31513831e-12  1.65131166e-02
 -4.41788208e-02 -1.84276316e-03  4.16418403e-29 -7.34772005e-01
 -8.78224054e-07  1.85502183e-11 -1.93362800e-25 -2.53503811e-04
  1.47358462e+00  5.91601166e-01  3.74095178e-02  3.56982669e-01
  9.21961711e-02  7.07423905e-04  1.41186904e-04  2.10650036e-05
 -5.93178591e-03 -1.26900104e-31 -1.19711146e-11  1.70475615e-37
 -6.39415889e-01 -4.05799858e-01 -3.31135821e-02 -4.89392886e-02
 -5.89535418e-02  6.21535687e-01 -4.00890663e-01  8.18861900e-01
 -1.90530403e-02 -1.52753912e-02 -7.93674080e-02 -6.97363364e-03
 -3.26137886e-02  2.91508693e-02 -5.73909806e-02 -3.41399314e-05
 -4.72484018e-02 -1.51254939e-02  6.11682951e-01 -1.62543807e-02
  6.98138505e-01 -1.81171546e+00  5.92011434e-01 -2.63515216e+00
 -6.54471088e-01  9.06316026e-01 -1.20585397e-01 -2.54540763e+00
 -1.14153095e+00]
supnorm grad right now is: 2.6351521559706126
Weights right now are: 
[ -7.3032737    9.99000769   6.94333057 -28.97904895   7.55784241
 -10.09869938  -6.5443933   28.26302056  -5.88515844   3.75009394
 -11.06924535   5.78482801  -0.76480188  40.07984341  44.28448997
  11.70887918  26.59695824 105.25627787  29.90199036   2.12138169
  69.75791837  22.13807303  35.52848511  23.28718874   5.04765559
   3.1349096   -5.5033731  -10.64504149   5.53045032 124.19164936
 179.51990316 -76.83543655 197.55148813  24.52742505  10.22851411
  16.52198564  -2.90466155   4.58164726  -2.75969781 -17.34692272
   0.69446939   2.33975413  -4.0677176    3.42320856  -5.53354734
  75.49737409  -2.65974718  29.58967864 -14.9092147   13.36715447
  12.54474031  22.16968089  -5.986693    86.38845091   0.96582485
  65.65518186   6.56314688   1.40066613   0.86475191  -2.42823926
   5.18772571   3.10627574   3.58913336  -2.31808204  29.27113665]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.0369303196085
gradient value of function right now is: [ 4.80105802e-01  2.54078534e-03 -1.39324526e-01  3.39788122e-05
 -4.80105802e-01 -2.54078534e-03  1.39324526e-01 -3.39788122e-05
  2.01267813e+00  2.30087544e+00  9.14540604e-02  3.12091244e+00
 -9.93968414e-04 -7.94187882e-05 -5.66529164e-12 -1.86764835e-02
  6.09204342e-02 -4.97034458e-03 -6.98688768e-29  2.05440437e+00
  2.51477879e-06  8.14821154e-11  7.99633369e-26  7.18221605e-04
 -1.77030667e+00 -3.08564297e+00 -9.04011189e-02 -1.56544933e+00
 -5.50915246e-02  4.66046395e-04  2.76303738e-04  3.92733306e-06
  7.37379952e-03  6.94777018e-33  4.31477348e-12  1.42127017e-38
 -1.40786180e+00 -4.84484954e-01 -4.22340343e-02 -1.00934855e-01
 -1.77591467e-01 -3.36070499e+00  1.72874924e-02 -1.88010281e+00
 -9.01280351e-02 -1.29237790e-02  1.84356543e-01 -2.16319411e-02
 -2.95016498e-01  1.33057255e-02 -4.55551067e-01 -1.45859733e-02
 -3.44598752e+00 -1.28351947e-01 -7.51463892e+00 -1.21296219e-01
 -4.05671277e+00  1.69026959e+01  5.16919541e+00 -1.56044606e+01
  1.56737870e+00 -3.39764191e+00  3.41437541e+00 -1.05403580e+01
 -7.98026891e+00]
supnorm grad right now is: 16.902695859156317
Weights right now are: 
[ -7.04644235   9.78168617   7.40770724 -30.2977585    7.30101106
  -9.89037786  -7.00876997  29.58173012  -5.74318183   4.1228789
  -8.75819957   5.91460358  -0.43649093  39.01704333  44.28449352
  11.53588594  27.771508   105.75596236  29.90199036   2.20059619
  73.78118554  22.13821072  35.52848511  23.26303414   4.8904226
   2.7998798   -5.00264192 -10.91879214   5.91237396 130.38737904
 184.21083799 -76.54123595 202.61822523  24.52742505  10.22853024
  16.52198564  -2.75859188   4.42323519  -3.58694729 -18.9459395
   0.59462482   2.35176035  -4.06752638   2.75408245  -5.81313724
  76.21429066  -2.7620817   29.13739057 -15.10149249  12.90186746
  12.81485702  22.86480795  -6.07379422  88.16350815   0.81651508
  66.58426216   6.54315705   1.50569783   0.98569088  -2.65224171
   6.01571915   3.08403926   3.36008629  -2.14686182  29.40175349]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.15962183634
gradient value of function right now is: [ 2.82895172e-01  3.99237503e-03 -8.86829041e-02  5.14218501e-05
 -2.82895172e-01 -3.99237503e-03  8.86829041e-02 -5.14218501e-05
  9.19478608e-01  7.86357336e-01 -4.53803673e-02  2.42973847e+00
 -2.74886867e-03 -1.31423072e-04 -4.43148776e-12 -3.24083676e-02
 -7.50600565e-03 -4.41267456e-03 -9.14572250e-30  1.41938532e+00
  3.07914224e-06  1.51910903e-10  2.57571062e-27  1.15551972e-03
  3.12075799e-01 -1.24261120e+00 -2.70520656e-02 -5.46288542e-01
  4.83283994e-02  6.26290215e-04  3.91029687e-04  1.60577313e-05
 -3.65701135e-03  1.26221008e-31  6.55330930e-11  8.61194686e-37
 -1.41115615e+00 -6.89325285e-01 -9.21779389e-02 -1.40798148e-01
 -6.04211440e-02 -1.20325592e+00 -3.65137966e-01  1.80192166e-01
 -1.67302147e-01 -3.25638915e-02 -2.85801698e-01 -2.04716568e-02
 -4.13023025e-01  3.52160671e-02 -5.57939655e-01 -1.18407178e-02
 -2.80725725e+00 -1.12714212e-01 -4.67731316e+00 -9.40109039e-02
 -1.62145398e+00  9.72744379e+00  4.42127216e+00 -1.56027355e+01
 -4.63122347e-01  1.11431955e-01  1.64364289e+00 -9.35142667e+00
 -5.72161671e+00]
supnorm grad right now is: 15.602735461186887
Weights right now are: 
[ -7.0592292    9.62265924   7.65354678 -32.11280286   7.31379791
  -9.73135093  -7.25460951  31.39677448  -5.94152788   3.91728042
  -9.07895113   6.17682062  -2.24199541  36.68226453  44.28450215
  11.30519623  26.9888233  108.10353556  29.90199036   2.45253818
  78.05612762  22.13831285  35.52848511  22.84934305   5.24394033
   2.68725989  -5.50515225 -10.74467536   5.58501405 132.21049738
 189.89139396 -82.41246212 207.18407307  24.52742505  10.22857675
  16.52198564  -2.92113594   4.51853042  -3.22670899 -18.5344564
   0.47979382   2.69597408  -4.27554619   3.39669613  -5.4205572
  78.43189735  -3.07124076  28.82520251 -15.64112623  13.17902532
  13.23792355  23.14068367  -5.72927603  90.01871279   0.84962783
  67.35782126   7.04982242   1.54609228   0.9598846   -2.61515316
   5.66608411   3.41001808   4.14506308  -2.3035571   29.45553559]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.3325811206828
gradient value of function right now is: [-5.70715084e-03 -2.44270719e-03 -5.32914153e-02 -7.31216391e-05
  5.70715084e-03  2.44270719e-03  5.32914153e-02  7.31216391e-05
 -4.35776403e-01 -4.95462118e-01 -3.04128656e-02  3.40364521e-01
 -7.85776564e-04 -1.30832910e-04  2.91971863e-12  1.19429822e-02
 -1.41281924e-02 -7.75595570e-04  1.03142800e-30  4.46442979e-01
 -9.35375025e-06  5.18897459e-11 -2.06673462e-28 -1.56194570e-03
  2.39965444e-01 -8.02712645e-01  6.05452423e-02 -4.53771830e-01
 -2.19539566e-02  2.51633162e-04 -9.92454509e-04  1.21656865e-05
 -3.62807267e-03 -1.21410771e-33 -5.88828949e-13  3.36168890e-39
 -6.43713374e-01 -2.21317220e-01 -1.66527751e-02 -5.61013764e-02
  2.67725272e-03  9.89021762e-02 -1.89556548e-01  5.50282253e-01
 -1.01065834e-01 -2.28283883e-02 -2.08628925e-01 -1.52163235e-02
  3.70523319e-02  7.91937361e-02  3.35793960e-02  1.37404058e-02
 -1.17170463e+00 -3.41207871e-02 -2.61172070e+00 -3.03015258e-02
 -1.50789298e+00  6.18732331e+00  1.92510990e+00 -6.54294979e+00
 -7.82241146e-01  8.27504262e-01  6.39054473e-01 -3.77134986e+00
 -3.34950686e+00]
supnorm grad right now is: 6.542949786701805
Weights right now are: 
[-7.47160465e+00  9.37641435e+00  7.38256013e+00 -3.30610555e+01
  7.72617336e+00 -9.48510604e+00 -6.98362286e+00  3.23450271e+01
 -5.95101631e+00  3.68023627e+00 -9.90717150e+00  5.93396010e+00
 -3.20069746e+00  3.91355651e+01  4.42845096e+01  1.19239400e+01
  2.81851873e+01  1.09885568e+02  2.99019904e+01  2.34739920e+00
  8.36550469e+01  2.21384060e+01  3.55284851e+01  2.24604953e+01
  4.89206491e+00  2.87803461e+00 -4.93881652e+00 -1.04215517e+01
  5.64446026e+00  1.30870317e+02  1.95377544e+02 -8.16401595e+01
  2.13292091e+02  2.45274251e+01  1.02285774e+01  1.65219856e+01
 -2.44020990e+00  4.42951488e+00 -2.08534933e+00 -1.86774971e+01
  3.52300909e-02  2.56431891e+00 -3.74586285e+00  2.93544714e+00
 -5.28267570e+00  7.99971794e+01 -2.71769613e+00  2.75934420e+01
 -1.57982428e+01  1.41305550e+01  1.32598291e+01  2.36196053e+01
 -5.82877117e+00  9.16433871e+01  8.63735965e-01  6.77134122e+01
  6.93609153e+00  1.65496725e+00  8.29695133e-01 -2.55002558e+00
  5.48331000e+00  3.32582399e+00  3.36787636e+00 -2.11592107e+00
  2.92418055e+01]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.2198881802972
gradient value of function right now is: [-5.99968972e-02  1.07646435e-03  1.69079727e-02  3.78422537e-05
  5.99968972e-02 -1.07646435e-03 -1.69079727e-02 -3.78422537e-05
 -5.31639208e-01 -6.05643855e-01 -4.32167190e-02 -3.40898698e-01
 -2.95992795e-04 -1.35958918e-05  5.83540690e-13 -9.63343219e-03
  3.28893256e-02 -3.14063594e-04  1.16109521e-30  5.89631730e-01
 -1.40780964e-06  2.11927058e-12 -1.57157402e-29  5.78466953e-04
 -5.06073748e-01 -1.91640772e-01  9.46528166e-02 -1.11276544e-01
  5.90770843e-02  1.25560169e-05 -2.45639925e-04  6.29825992e-07
 -3.69449187e-03 -4.49633053e-33 -1.38815885e-12  1.80560191e-39
  1.60290782e-01  2.06161521e-01  7.72433412e-02 -1.18715988e-02
  3.78806778e-02  7.09939595e-01  1.95930699e-01  6.96562113e-01
 -2.01098601e-01 -1.05973512e-02 -7.34524444e-02 -1.72053791e-02
  4.43146263e-01  2.47248504e-02  4.96100165e-01  2.09647323e-02
  7.19795140e-01  1.06218944e-02 -3.20900982e-01  3.67498768e-02
 -6.72054732e-01 -1.28308891e-01  1.03222303e+00  5.97698625e-01
  1.08424061e+00 -1.39492943e+00 -1.49186968e-01  2.88216733e+00
  3.78486322e-01]
supnorm grad right now is: 2.8821673343903025
Weights right now are: 
[ -7.36611684   9.80260174   7.38002722 -33.38676942   7.62068555
  -9.91129343  -6.98108995  32.67074103  -6.10062889   4.08162276
  -8.26496601   6.01646745  -1.47624585  39.62090112  44.28451324
  12.25801386  27.90580877 110.15216628  29.90199036   2.36039092
  87.42532659  22.13846203  35.52848511  23.4015958    4.9474769
   2.8406614   -4.37085661 -10.88620954   5.93983413 130.64851301
 204.8417202  -83.78237787 217.44650937  24.52742505  10.22859502
  16.52198564  -2.78062785   4.63891765  -3.16688354 -18.81127734
   0.81913487   2.68201251  -3.8847157    2.88852891  -5.81172354
  81.37081999  -2.85022577  27.9708379  -15.84330869  13.4073906
  13.06449623  23.08479294  -5.63429987  94.14170504   0.92358514
  68.80582915   6.68247959   1.59803646   0.94527223  -2.48298338
   5.99091557   3.2389242    3.65084722  -2.11408818  29.15641798]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.1330211765212
gradient value of function right now is: [-8.77410628e-01 -9.52649853e-03 -1.25933132e-02 -3.52471467e-04
  8.77410628e-01  9.52649853e-03  1.25933132e-02  3.52471467e-04
 -3.90130872e+00 -3.91737365e+00 -7.67411182e-02 -6.71323978e+00
  1.16873843e-03  6.68820436e-05  5.84814901e-13  4.95500804e-02
  4.87627526e-02  5.40393521e-03  3.45036403e-30  2.61891216e-01
 -2.67149379e-05 -4.06410245e-11 -1.68696764e-30 -6.56869136e-03
 -1.15085158e+00  2.42704082e+00  4.27090574e-02  1.35881981e+00
  3.08522757e-01 -1.32993474e-03  6.57010583e-04 -2.18369482e-05
 -9.88983188e-03 -8.99784936e-34 -2.72060873e-11 -1.14437065e-39
  2.73476973e+00  1.01069820e+00  1.41513558e-01  1.58551792e-01
  1.43773657e-01  6.09268191e+00  5.65469101e-01  2.47928469e+00
 -1.06059859e-01  2.67775216e-02 -7.56497019e-02  8.04544123e-03
  7.15307428e-01 -1.96491281e-01  9.42129860e-01  6.96073146e-03
  4.15347803e+00  1.53211133e-01  7.47348396e+00  1.09079429e-01
  3.68536962e+00 -1.83153170e+01 -7.49854560e+00  2.30157339e+01
  1.50077069e+00 -7.10979828e-01 -3.09729414e+00  9.54010660e+00
  1.73899688e+01]
supnorm grad right now is: 23.015733889295056
Weights right now are: 
[ -7.52047375  10.03614233   7.32865136 -33.43617599   7.77504247
 -10.14483402  -6.92971409  32.7201476   -5.94587766   3.78019635
 -10.32973504   6.08099121  -1.50483165  43.21771225  44.28451782
  12.6236613   27.37273863 111.07818772  29.90199036   2.4038146
  95.25917942  22.13849022  35.52848511  24.28028079   5.06305065
   3.03991364  -5.61796631 -10.56861278   5.66429282 129.19875436
 213.12074704 -89.10678083 223.70485971  24.52742505  10.22860118
  16.52198564  -2.63171252   4.77923102  -2.89361506 -19.55361555
   0.64224608   2.72621082  -4.56351974   2.55222134  -5.02470445
  82.23475097  -3.2043631   28.14164467 -15.73221638  12.6124474
  13.18858088  24.20969072  -5.77497899  96.23578793   0.73213371
  68.45851059   6.76941344   1.52117965   0.46260361  -2.46866597
   6.0734161    3.49227469   3.4457489   -2.25369741  29.18629801]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.9239262936462
gradient value of function right now is: [ 4.94703932e-01  5.85876128e-03  5.13458011e-01  6.16360421e-05
 -4.94703932e-01 -5.85876128e-03 -5.13458011e-01 -6.16360421e-05
  1.59341011e+00  1.28402575e+00 -3.07548180e-03  4.56408307e+00
 -4.06543914e-03 -2.23254275e-04 -2.68579724e-13 -5.73287157e-02
 -1.10759073e-01 -1.28476653e-02 -2.25968454e-30 -5.47673755e+00
  5.87032983e-06  1.72593289e-11  3.32146593e-32  1.26381096e-03
  2.77911901e+00 -1.25327285e+00  7.78398516e-03 -7.46278136e-01
  7.11357510e-01  8.21950374e-04  5.09015381e-04  1.38921567e-05
  1.81221294e-04  4.03042200e-35  3.21631511e-12  2.80801271e-41
 -8.30006886e-01  6.76966405e-02 -6.47812329e-02 -3.57284439e-02
 -6.93947803e-01 -3.03093885e+00 -1.66689825e+00 -6.92606639e-01
 -3.45132686e-01 -5.92323240e-02 -8.07710171e-01 -3.56952886e-02
 -3.55225187e-01  7.35887382e-02 -4.92216027e-01 -1.15122647e-02
 -2.05114162e+00 -4.93455178e-02 -3.57499493e+00 -5.36116695e-02
 -1.88540086e+00  1.00234464e+01  4.57748861e+00 -1.25532131e+01
 -1.92416708e+00  2.30572833e+00  1.81814661e+00 -6.43562176e+00
 -1.57757192e+01]
supnorm grad right now is: 15.775719164239865
Weights right now are: 
[ -7.48609343  11.74791632   7.5186075  -33.83025902   7.74066214
 -11.85660801  -7.11967023  33.11423063  -5.90529507   3.92020733
 -10.74030637   5.97725982  -3.16897907  45.69621571  44.28451856
  11.5561277   27.21589478 111.26321791  29.90199036   2.17984809
 100.1927167   22.13849423  35.52848511  24.95243655   4.89233813
   2.85957359  -5.09661476 -10.25182227   6.41086658 134.98636552
 217.01114719 -92.98081151 228.02128978  24.52742505  10.22861465
  16.52198564  -3.06611045   5.10633352  -2.12067041 -19.09461365
   0.42788799   2.57574614  -3.87344475   3.01577514  -5.47771349
  83.55041167  -2.77133261  27.07322436 -16.44618437  13.2331674
  13.4084145   25.81114296  -5.76322208  97.70871358   0.76997949
  68.06873856   6.84019962   1.47757732   0.83901823  -2.53102402
   5.80456202   3.56127008   3.92323249  -2.16314696  29.14240888]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1850.6759068279757
gradient value of function right now is: [-7.89131565e-01 -2.94105097e-03 -2.87248219e-01 -6.69021893e-06
  7.89131565e-01  2.94105097e-03  2.87248219e-01  6.69021893e-06
 -3.57992307e+00 -2.80784672e+00 -5.30243273e-02 -6.77014310e+00
  2.50874909e-03  1.37495684e-04  6.16396438e-14  3.62847455e-02
  9.03994560e-02  1.18190125e-03  1.16558187e-30  2.56598557e+00
 -1.51832020e-06 -1.48902323e-11 -2.34621207e-32 -2.10395102e-04
 -3.60292368e+00 -9.47246429e-01 -2.53977316e-01 -4.13054950e-01
  4.67214309e-01 -1.44279678e-04  1.44696369e-03 -3.26549481e-06
 -6.42665528e-03 -3.99195286e-33 -2.69518272e-11 -2.33455832e-41
  1.39941599e+00 -3.31414633e-01  2.47888113e-03 -2.24600788e-02
  4.78723724e-01  4.11667016e+00  9.19045248e-01  1.63152474e+00
  5.52528695e-02  1.47247346e-02  2.31919573e-01  2.40141224e-03
 -4.84628060e-01 -1.97434154e-01 -6.32095033e-01 -3.32845211e-02
 -1.15798237e+00 -4.65530678e-02 -1.81576624e+00 -3.55824277e-02
 -5.36968386e-01  4.73121516e+00 -1.13979190e+00 -5.15898190e+00
  1.97538588e+00 -2.55396191e+00 -8.14704417e-01 -4.93571944e+00
  1.52656586e+01]
supnorm grad right now is: 15.26565859852338
Weights right now are: 
[-7.56009323e+00  1.15853175e+01  7.52053888e+00 -3.58497097e+01
  7.81466194e+00 -1.16940092e+01 -7.12160161e+00  3.51336813e+01
 -5.93116464e+00  3.79280532e+00 -1.01152951e+01  5.82558561e+00
 -1.71315694e+00  4.86880824e+01  4.42845188e+01  1.16431404e+01
  2.72051445e+01  1.12527178e+02  2.99019904e+01  2.22823025e+00
  1.03780304e+02  2.21385368e+01  3.55284851e+01  2.38498993e+01
  4.91649278e+00  2.46636330e+00 -5.04819399e+00 -1.05074434e+01
  5.78090977e+00  1.35758293e+02  2.23582441e+02 -9.90357136e+01
  2.32721907e+02  2.45274251e+01  1.02286204e+01  1.65219856e+01
 -2.45904528e+00  4.15095283e+00 -3.38495398e+00 -1.92743764e+01
  2.10386434e-01  2.67155220e+00 -3.54528007e+00  3.30738235e+00
 -4.94586697e+00  8.29622893e+01 -3.05567464e+00  2.76223694e+01
 -1.66549408e+01  1.30950793e+01  1.36487973e+01  2.44534201e+01
 -5.54783515e+00  1.00439937e+02  7.30012515e-01  6.79675977e+01
  6.70549488e+00  1.57347106e+00  6.20428951e-01 -2.59848837e+00
  6.49548679e+00  3.47071912e+00  4.04896089e+00 -2.38204617e+00
  2.94202210e+01]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.2615120707453
gradient value of function right now is: [-5.53894497e-01 -4.96545052e-03 -1.87128981e-01 -1.11724282e-05
  5.53894497e-01  4.96545052e-03  1.87128981e-01  1.11724282e-05
 -2.23065428e+00 -1.96397814e+00 -4.36104748e-02 -4.57308571e+00
  8.12562935e-03  4.58952798e-04  3.33668114e-13  6.49787765e-02
  7.70253089e-02  3.90837321e-03  5.46608130e-31  2.14956452e+00
 -2.61752972e-06 -9.78165391e-12 -2.52152824e-34 -2.78267184e-04
 -1.71680706e+00  1.05686395e+00 -4.66311988e-02  4.45170962e-01
  1.13864305e-01 -5.87082931e-04 -3.55857085e-04 -1.00952792e-05
 -4.39733025e-03 -5.38852493e-35 -1.08932866e-12 -7.44999890e-44
  1.25582353e+00  3.23208587e-01  1.26961230e-01  6.31897757e-02
  1.73646749e-01  3.48032119e+00  6.55497142e-01  1.33633203e+00
 -1.47124437e-02  3.35758322e-02  3.66115612e-01  9.25581051e-03
  3.99841369e-01 -6.46319763e-02  4.91668354e-01  1.07191078e-02
  2.16744605e+00  6.06303108e-02  3.74331116e+00  5.59088813e-02
  2.11202148e+00 -9.93859663e+00 -3.89546276e+00  1.15437795e+01
  1.91542450e+00 -1.91068970e+00 -1.49307480e+00  4.81815821e+00
  1.33751500e+01]
supnorm grad right now is: 13.37514997502112
Weights right now are: 
[  -7.27474019   12.94664558    7.43686384  -34.86867212    7.5293089
  -13.05533727   -7.03792657   34.15264374   -5.88400429    3.94834599
   -9.16220846    5.88618215   -4.401234     47.79490941   44.28451885
   10.76276      25.32300322  114.90216784   29.90199036    2.29920261
  110.45002174   22.13854918   35.52848511   25.63217397    5.22083653
    2.25284416   -4.84376666  -11.03633687    5.92111173  139.61778774
  229.72403093 -102.20325246  238.71312334   24.52742505   10.22862275
   16.52198564   -2.57622322    4.62343092   -2.69627941  -19.28625781
    0.26394037    2.55836234   -3.47377613    2.81757303   -5.29150354
   83.63333117   -2.2585294    25.61814396  -17.04849074   13.41304253
   13.81797263   25.53017519   -5.68371914  102.63077368    0.97746821
   68.65103532    7.01868395    1.57685379    0.85241653   -2.57104535
    6.00489218    3.52429197    4.28456043   -2.26133847   29.40383997]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1852.6857004105277
gradient value of function right now is: [ 3.02020791e-01  2.43749372e-02  8.04688028e-01  2.41757042e-03
 -3.02020791e-01 -2.43749372e-02 -8.04688028e-01 -2.41757042e-03
  8.32869014e-01  1.83212113e-01 -3.89998524e-02  2.59843538e+00
 -1.89065628e-03 -2.51264741e-05  2.54916936e-14 -1.33137508e-01
 -8.02163793e-02 -5.25147645e-03 -3.15301825e-32 -6.68656651e+00
  1.33825044e-04  1.42823413e-10  1.82974595e-35  3.77115150e-02
  2.82045866e+00  1.57648273e+00  1.13305898e-01  8.74991752e-01
  3.55702578e-01  1.35350661e-03  5.88980142e-04  1.18668306e-05
 -3.57946708e-03 -7.16235603e-34  9.31041108e-13  3.73119337e-42
  8.92842244e-01  6.11283161e-01  3.53768286e-02  5.80157318e-02
 -3.51699415e-01 -1.51062239e-01 -8.36244793e-01  4.17066453e-01
 -4.40973626e-01 -7.40615113e-02 -1.16106196e+00 -3.80553379e-02
  2.92042442e-01  1.03428754e-02  3.33001555e-01  7.08865307e-03
  1.93902572e+00  5.64980628e-02  3.81200561e+00  4.27220989e-02
  1.32164559e+00 -7.33432251e+00  1.37196337e+00  2.20944259e+00
 -6.48114603e-01  1.28399195e+00 -1.33633818e-01  2.76903441e+00
 -5.84692408e+00]
supnorm grad right now is: 7.334322513017279
Weights right now are: 
[  -7.12658456   11.09710338    7.46486559  -38.82083694    7.38115327
  -11.20579507   -7.06592832   38.10480856   -5.88682753    3.77407167
  -10.56604755    6.1678901    -3.54171005   45.65733179   44.28451905
   12.19261551   25.88233104  115.91549041   29.90199036    2.26365122
  115.57539233   22.13856648   35.52848511   22.46721162    5.37583329
    2.64916828   -4.17377005  -10.65961821    5.77808177  140.02995196
  234.34646068 -104.83868109  242.3116385    24.52742505   10.22863438
   16.52198564   -3.05253873    5.21462044   -1.72638289  -19.08404338
    0.26134343    2.89666588   -3.46267936    2.97249866   -5.53246034
   84.28645659   -2.92998086   25.81976073  -17.05870919   14.63253109
   14.14901319   26.14031213   -5.68180364  105.42365673    0.93082895
   68.81539898    6.68694739    1.51836943    1.04487661   -2.62067267
    6.49367761    3.99409137    4.45018007   -2.32154278   29.28662603]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.618689681813
gradient value of function right now is: [-4.00081853e-01 -4.63522773e-03 -1.35172196e-02 -2.00480496e-04
  4.00081853e-01  4.63522773e-03  1.35172196e-02  2.00480496e-04
 -2.17426960e+00 -1.90150719e+00 -6.16200088e-02 -2.93671948e+00
  8.16970656e-04  2.14527330e-05  2.83498305e-13  3.27732909e-02
  1.57598952e-02  4.89818228e-03  2.80645739e-31 -1.31524807e-02
 -5.64378735e-05 -1.38483945e-09 -2.36414517e-35 -5.35560045e-03
 -9.97413380e-01 -2.37215728e-01 -1.96867904e-01 -2.08043184e-01
 -2.07308370e-01 -4.50694190e-04 -1.02419947e-03 -5.86486807e-06
 -5.77532278e-03 -1.00472858e-32 -9.14436093e-12 -6.63517826e-42
  7.93008496e-01  6.25466292e-01 -6.16655965e-02  1.14243810e-01
  7.13542793e-01  2.31003011e+00  1.01758716e+00  1.30624039e+00
 -4.97428088e-02  1.72761285e-03 -3.35754594e-01  5.35928998e-03
 -4.98670127e-01  2.30127063e-02 -5.61728728e-01 -1.38156373e-02
 -1.78999135e-01  3.07819637e-02  1.05697220e+00 -9.44571141e-03
  7.31198907e-01  8.84429472e-01 -3.39643204e+00  3.77636811e+00
 -2.10381753e-01  5.22663065e-01 -1.05729663e+00 -2.35027874e+00
  8.20116317e+00]
supnorm grad right now is: 8.201163168291489
Weights right now are: 
[  -7.38399077   10.39562265    7.41350551  -39.70400425    7.63855948
  -10.50431434   -7.01456824   38.98797586   -6.25655693    3.91056407
   -9.08670162    6.06916695   -3.88350139   46.73182323   44.28451915
   12.15889139   25.28341474  116.95856174   29.90199036    2.31281898
  123.03885675   22.13855057   35.52848511   19.85058023    5.40827165
    2.40065532   -4.14777837  -11.10599197    6.14481621  139.70360969
  241.43192162 -106.08237965  247.26383568   24.52742505   10.22863688
   16.52198564   -2.89458387    4.96526743   -2.71207421  -18.53401971
    0.72192133    3.15884512   -3.22178371    2.96838885   -5.09183151
   85.49975216   -2.89871185   26.52160492  -17.43175737   14.85982561
   13.65878511   28.31219494   -6.00467079  107.78341391    0.96751287
   68.36856147    6.65139173    1.57328847    0.47794757   -2.50248051
    6.09682152    3.51152505    4.14621447   -2.30701236   29.28687148]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1852.9122913726233
gradient value of function right now is: [-1.22120227e-01  8.77267875e-03  7.50994059e-01  5.27798178e-05
  1.22120227e-01 -8.77267875e-03 -7.50994059e-01 -5.27798178e-05
 -7.96609520e-01 -1.09880147e+00 -5.92311141e-02 -8.61461981e-01
 -3.59551150e-04  1.69283274e-04  7.87350740e-15 -1.04170254e-01
 -5.29510952e-02  1.68113677e-02  8.98415252e-33 -6.27490962e+00
  4.74996149e-06 -6.86793321e-10 -1.05146926e-37  1.51352687e-03
  1.37403489e+00  1.74189555e+00  9.11408439e-02  6.32656818e-01
 -1.38221904e+00 -7.63972683e-04 -1.11087819e-03  2.94763077e-05
 -4.75596755e-03 -3.24856347e-37 -2.43653245e-13 -1.91330952e-45
  3.24859931e+00  2.24593179e+00  8.99286720e-02  2.24294010e-01
  6.16140698e-02  2.30808581e+00  6.12848519e-01  9.97070178e-01
 -5.65482174e-01 -4.50159513e-02 -1.55454447e+00 -1.93386952e-02
  3.39388227e-01  4.03978777e-02  4.97140176e-01  1.50489083e-02
  3.03219529e+00  1.55617143e-01  7.00361603e+00  6.40294756e-02
  2.91289205e+00 -1.13662538e+01 -5.95888719e+00  1.85382124e+01
 -2.54621865e-01  6.47955732e-01 -1.57230828e+00  4.73079749e+00
  8.51993384e+00]
supnorm grad right now is: 18.53821243879572
Weights right now are: 
[  -7.2529073    12.78983583    7.63961205  -38.02611863    7.50747601
  -12.89852752   -7.24067478   37.31009025   -5.78462702    3.89949805
   -9.46153924    6.20773734   -1.87906175   50.25535605   44.28451925
   10.73515868   26.39394518  118.20726351   29.90199036    2.28742718
  127.57665348   22.13858001   35.52848511   22.70915838    5.42626718
    2.16994496   -4.17529571  -10.72459332    5.11188687  136.97969961
  244.88410783 -110.45857664  252.11447389   24.52742505   10.22863663
   16.52198564   -2.83845695    4.45662087   -2.21649308  -19.65580041
   -0.27342559    2.84670383   -3.82314085    2.73816188   -5.06399678
   87.03399476   -2.97628578   26.83259642  -17.36216821   15.07992493
   14.37237979   29.38978977   -5.71074417  109.76472834    0.83310631
   68.26131213    7.03806943    1.73025084    0.32711865   -2.59499166
    5.19924197    4.12117753    4.12647149   -2.45006795   29.39518382]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1851.0760499301828
gradient value of function right now is: [-5.13778778e-01 -1.66636146e-02 -6.12667811e-01 -1.02836535e-03
  5.13778778e-01  1.66636146e-02  6.12667811e-01  1.02836535e-03
 -1.28832627e+00 -1.95556346e+00 -7.76831097e-02 -3.61747474e+00
  3.33762062e-03  1.37716499e-04  5.94036399e-14  1.58555995e-01
  5.26134062e-02  6.81263481e-03  4.87616044e-32  4.65123782e+00
 -8.73155970e-05 -3.81959794e-09 -2.62556015e-38 -2.97384804e-02
  3.83898884e-01  3.23376131e+00  2.01116152e-01  1.93040207e+00
 -2.37240285e-01 -1.24426441e-03 -3.31619093e-04 -6.77810693e-06
 -7.86304140e-03 -1.96857375e-34 -3.59762212e-12 -6.10592193e-44
  2.24197436e-01 -3.25156693e-02  1.73601542e-01  5.54158138e-02
 -3.26133989e-02  4.13106175e+00  2.60932191e-01  1.84752354e+00
  4.81431241e-01  7.65090688e-02  1.23840878e+00  4.86625406e-02
  8.63158651e-01 -5.18640663e-02  1.09285539e+00  1.84269915e-02
  5.18679943e+00  8.77782179e-02  7.84915903e+00  9.37788680e-02
  3.76718940e+00 -2.13227058e+01 -5.85402058e+00  2.09160045e+01
  1.31879922e+00 -1.05579055e+00 -2.22311702e+00  9.65296410e+00
  1.64323219e+01]
supnorm grad right now is: 21.32270578243047
Weights right now are: 
[  -7.49922344   12.99928581    6.86230086  -42.71951099    7.75379215
  -13.1079775    -6.46336359   42.00348261   -5.71002321    4.08486892
  -11.14063718    6.09956581   -2.71603675   49.24123182   44.28451933
   11.63982115   27.38002438  117.33014336   29.90199036    2.53538087
  137.78584981   22.1385354    35.52848511   19.23729394    5.38531213
    2.25556209   -3.38874805  -10.20843884    6.08018034  140.33750223
  253.05521593 -116.27925818  256.10875753   24.52742505   10.22863772
   16.52198564   -2.92810643    4.25869397   -2.53871713  -18.99648891
    0.5088228     2.94194087   -3.95594582    2.69180661   -5.07215306
   86.84728074   -2.6348383    25.15874973  -17.16121722   13.6077328
   14.50965777   27.56107685   -5.44146451  111.82274997    1.40964165
   67.87854144    6.98850362    1.59662387    1.24904838   -2.6085182
    5.76138644    3.9050663     4.25598063   -2.28882306   29.37956373]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1852.4081601353028
gradient value of function right now is: [ 8.18013145e-01  4.82997860e-04  7.03702794e-02  2.25673517e-06
 -8.18013145e-01 -4.82997860e-04 -7.03702794e-02 -2.25673517e-06
  3.76634651e+00  3.93726458e+00  5.61394787e-02  6.15427460e+00
 -8.64704969e-04 -1.07923503e-04 -1.91456448e-13 -8.06250309e-03
 -1.49825731e-02 -1.29623511e-02 -1.82833337e-31 -9.54315417e-01
  2.53867975e-07  5.75486864e-10  2.77637352e-40  9.20992734e-05
  3.89909328e-01 -2.49977878e+00 -2.18098870e-01 -1.15641893e+00
  4.07770146e-01  7.77423217e-04  8.73896346e-04  5.35134557e-06
  6.21293395e-03  2.81473405e-36  4.51162361e-13  7.60283796e-46
 -1.89646970e+00 -6.37368635e-01 -1.15344546e-01 -9.58586506e-02
 -6.42815856e-01 -4.82889067e+00 -1.00892048e+00 -1.76977927e+00
 -5.25952203e-02 -2.06881382e-02 -2.14545418e-02 -1.22134628e-02
 -9.79448609e-01  3.78400436e-02 -1.28617756e+00 -3.82002768e-02
 -4.29837782e+00 -1.40877627e-01 -6.70148908e+00 -8.92120414e-02
 -2.99144110e+00  1.67624847e+01  5.61613723e+00 -2.34344135e+01
  1.14507894e-01 -1.41272833e+00  2.44693549e+00 -7.50329785e+00
 -1.80334318e+01]
supnorm grad right now is: 23.434413461442283
Weights right now are: 
[  -7.1227819    13.82739857    7.55186998  -42.22212142    7.37735061
  -13.93609026   -7.15293271   41.50609303   -5.72906569    4.36824583
   -9.5938312     6.01878043   -0.3804979    46.98710069   44.28451939
   11.84345915   27.42598112  117.18719185   29.90199036    2.18571423
  147.27271107   22.13859655   35.52848511   21.34791958    5.13926832
    2.43199978   -5.26905452  -10.97083771    5.91297666  139.72424855
  254.91278273 -117.21045834  260.01320022   24.52742505   10.22864203
   16.52198564   -2.88481599    4.00892909   -1.42825475  -19.83058685
    0.30257598    2.85871617   -4.23656744    2.90341468   -4.99249654
   88.1778285    -2.73202723   26.11833229  -17.35970176   16.19608223
   14.72806558   28.39790797   -5.73029094  114.28607578    1.08444845
   66.94219223    6.87241123    1.61254617    0.73809419   -2.60631225
    6.37851742    3.24285119    4.68992903   -2.45277076   29.29110769]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.576650372358
gradient value of function right now is: [-2.52073489e-02  7.60390731e-04 -9.79352412e-02  4.34428215e-05
  2.52073489e-02 -7.60390731e-04  9.79352412e-02 -4.34428215e-05
 -4.11511189e-01 -4.50549676e-01 -5.00624865e-02  6.66953955e-02
 -6.36459813e-04 -2.69692887e-05  1.27663993e-13 -5.27296749e-03
 -2.90861362e-02 -5.43675138e-03  9.37895935e-33  6.90406731e-01
  3.12000730e-06  2.37296934e-10 -1.93578263e-42  1.13974046e-03
  4.21199764e-01 -6.77833820e-01 -3.39461907e-02 -2.40263719e-01
  4.70458318e-01  5.38960511e-04  5.76644895e-04  3.53609410e-06
 -4.45481538e-03 -1.32548189e-33 -1.67937003e-12  1.28812256e-43
 -7.75756968e-01 -8.88934279e-01 -1.27149637e-01 -1.26065045e-01
 -1.17222614e-01  5.12793669e-01 -5.57814005e-01  7.01094244e-01
 -5.07656753e-02 -2.32807503e-02 -1.89622453e-01 -1.05493381e-02
 -4.63905848e-01 -1.26705769e-02 -6.14176784e-01 -1.88890591e-02
 -2.56106393e+00 -9.22655086e-02 -3.40109871e+00 -7.53170500e-02
 -7.61934521e-01  7.05906566e+00  2.94432960e+00 -1.64178081e+01
 -5.08793234e-01  5.14691767e-01  5.89033714e-01 -7.98613500e+00
 -1.87380834e+00]
supnorm grad right now is: 16.417808057653538
Weights right now are: 
[  -7.43226495   13.49148265    7.2780797   -42.29288503    7.68683366
  -13.60017434   -6.87914243   41.57685664   -5.91655245    4.17082466
  -10.25901775    5.94742663   -2.06687772   44.60654629   44.28451982
   12.57438      27.23978695  118.68770107   29.90199036    2.38171702
  152.4917299    22.13850554   35.52848511   22.10522766    5.43106067
    2.39438353   -3.64693458  -10.64294267    6.16827198  148.29405233
  263.28785653 -119.46918465  264.61749837   24.52742505   10.2286426
   16.52198564   -2.71681229    4.47664823   -3.23443898  -20.45789409
    0.52465506    3.23362673   -3.95979883    2.96567395   -4.7309177
   87.5460103    -2.97117625   24.0936105   -17.13496274   14.64743349
   14.31338474   27.26879585   -5.69897911  116.66512656    1.13465118
   66.72330967    7.04607216    1.51278172    0.91062724   -2.67154074
    6.28352925    3.62316868    4.1944112    -2.48386256   29.38836159]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.8334375235806
gradient value of function right now is: [-1.46496277e-01  3.71115641e-04 -1.35818035e-02 -7.08123511e-05
  1.46496277e-01 -3.71115641e-04  1.35818035e-02  7.08123511e-05
 -6.01159455e-01 -8.54245241e-01 -7.76332591e-02 -1.12493862e+00
 -3.19195182e-04  7.77928268e-05  2.72893599e-12 -1.57949834e-02
  4.64726701e-02  1.11774388e-02  2.61709394e-33  1.41071249e+00
 -2.07728200e-05 -1.76031355e-10 -4.89590531e-44 -1.60869240e-03
 -3.30356532e-01  1.67991918e+00  2.04630867e-01  5.71917886e-01
 -8.48360602e-01 -1.26966973e-03 -1.36125066e-03 -9.65766116e-06
 -6.29585072e-03 -7.87677729e-35 -1.30229659e-13 -7.65498174e-46
  7.32548434e-01  7.58770219e-01  1.26626787e-01  1.01274836e-01
  3.64072255e-01  2.44962456e+00  1.15677035e+00  1.52929530e+00
 -9.32606077e-02  2.74903589e-02  1.20814709e-01  1.03668272e-02
  7.00580750e-01  3.76287969e-02  9.12395557e-01  3.51495752e-02
  2.98178683e+00  1.00231749e-01  4.72879496e+00  8.69169177e-02
  2.34605283e+00 -1.20925738e+01 -4.91321257e+00  1.90331141e+01
  8.59476654e-01 -7.39140460e-01 -2.09571811e+00  8.18404553e+00
  1.04069520e+01]
supnorm grad right now is: 19.033114051026427
Weights right now are: 
[  -7.2073444    14.42199423    7.16971683  -42.78283466    7.46191311
  -14.53068592   -6.77077956   42.06680627   -5.80221949    4.19840045
  -10.47009409    6.17250035   -3.90319139   39.6043178    44.28452341
   11.8068934    27.14729354  120.09850191   29.90199036    2.14250425
  158.93680574   22.1384771    35.52848511   21.41302183    5.08575886
    2.16977485   -4.52878041  -10.62603423    5.99106642  145.04291663
  265.8537427  -122.51136899  268.19275271   24.52742505   10.22864645
   16.52198564   -3.32946641    4.95872246   -0.7331879   -19.90950501
    0.44356914    3.09624904   -3.18527961    2.68284332   -5.31949285
   89.37274931   -2.42005679   23.68090886  -17.78916524   16.31867188
   14.36623152   27.1053967    -5.70510988  118.46038434    0.95119965
   67.40094047    7.02713242    1.63950024    0.92119551   -2.5412071
    5.71116075    3.51457778    3.56676234   -2.26250486   29.29869644]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.6768691299267
gradient value of function right now is: [-3.21340081e-01  8.82235608e-04  4.33735442e-01 -1.78198618e-05
  3.21340081e-01 -8.82235608e-04 -4.33735442e-01  1.78198618e-05
 -1.89792009e+00 -2.16686606e+00 -7.60811313e-02 -1.90811069e+00
 -2.19329349e-03  9.63643400e-06  2.37489704e-11 -2.40914430e-02
 -6.43284306e-02  2.86886406e-03  1.04370858e-32 -4.21073553e+00
 -3.18331719e-06 -4.83946110e-10 -7.26882398e-44 -4.59035688e-04
  1.69039669e+00  1.72295946e+00  1.41028882e-01  7.16678357e-01
  1.10888995e-02  4.28753851e-04 -3.62156010e-04  5.17855384e-06
 -5.98680527e-03 -1.85768827e-34 -3.90309357e-13 -5.27353157e-46
  1.35688932e+00  6.60954212e-01  5.22316814e-02  6.48407053e-02
  2.48036158e-02  2.49845251e+00 -1.30203230e-01  1.52978388e+00
 -3.21298961e-01 -3.11515934e-02 -6.65580901e-01 -1.72256350e-02
  3.71763621e-01  2.64915124e-02  4.70405644e-01  1.36570759e-02
  2.58300316e+00  7.95180604e-02  4.54568056e+00  5.75404483e-02
  1.80502777e+00 -9.10201257e+00 -2.42621964e+00  1.00453133e+01
 -6.03284697e-01  1.22792664e+00 -1.38999464e+00  4.03736423e+00
  4.67519078e+00]
supnorm grad right now is: 10.045313344339585
Weights right now are: 
[  -7.19787533   15.42237215    7.03090599  -45.84000428    7.45244404
  -15.53106384   -6.63196872   45.1239759    -5.99114123    3.9278191
   -8.79975176    6.01253583   -3.92701759   39.40777272   44.28453108
   10.8638449    26.33255089  121.54717948   29.90199036    2.1675179
  164.8548742    22.13833368   35.52848511   19.52875817    5.2495696
    2.14852633   -3.7236537   -10.70092689    5.85502331  144.29570513
  272.6860364  -124.21500934  272.43152462   24.52742505   10.22864988
   16.52198564   -2.95972576    4.42234269   -2.38032263  -20.06285737
    0.59060715    3.15793884   -3.49375599    2.58620082   -4.43405299
   89.60125883   -2.90219463   23.21966769  -17.38775393   16.43528901
   14.94215592   28.61326118   -5.68547515  120.68985268    1.11716391
   66.59617571    6.95760977    1.60293681    0.92441378   -2.54892356
    6.05485872    3.69340521    3.97308166   -2.35399801   29.24745405]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.8009370576176
gradient value of function right now is: [-2.45766315e-02 -1.03294564e-03 -3.13121693e-02 -1.00879782e-05
  2.45766315e-02  1.03294564e-03  3.13121693e-02  1.00879782e-05
  5.06129043e-02 -7.49791556e-02 -2.81892213e-02 -1.07629271e-01
  5.61686565e-04  1.24842205e-05 -6.02352276e-13  1.62259847e-02
  1.70539950e-02 -8.15219112e-04 -2.29197610e-33 -6.24956610e-02
 -3.86800488e-06  1.61742566e-10  3.60082716e-46 -4.40987987e-04
  1.99030415e-01  6.60115963e-01 -3.78613364e-02  3.61937297e-01
  1.02863726e-01 -6.71618631e-05 -3.37546244e-04 -9.53409706e-07
 -2.28161073e-03 -2.50645690e-37 -1.99097958e-15  1.63516737e-48
  3.62631883e-02 -1.18069120e-01 -2.57654093e-02 -6.28224046e-03
 -1.49387430e-01  6.93476641e-01 -7.94456378e-02  4.62196099e-01
 -8.54830077e-02 -4.09840255e-03 -1.19831880e-01 -5.05263746e-03
 -6.27677738e-02 -3.05244293e-03 -7.10738487e-02 -3.65622440e-03
  5.23051362e-01  4.94136046e-03  1.59600750e+00 -7.73773820e-04
  1.20494440e+00 -3.88618598e+00 -8.34471732e-01  9.24576607e-01
  5.10657647e-01 -4.32203637e-01 -2.60744112e-01 -5.10870549e-01
  1.05276636e+00]
supnorm grad right now is: 3.8861859751749543
Weights right now are: 
[-7.30293350e+00  1.52103889e+01  7.19680365e+00 -4.61167519e+01
  7.55750221e+00 -1.53190806e+01 -6.79786639e+00  4.54007235e+01
 -5.85020162e+00  4.22790502e+00 -1.04820562e+01  5.96324175e+00
 -4.05039524e-02  3.97679652e+01  4.42845410e+01  1.17340436e+01
  2.72173350e+01  1.20998663e+02  2.99019904e+01  2.14865629e+00
  1.71508970e+02  2.21379215e+01  3.55284851e+01  1.96642974e+01
  4.67194727e+00  2.38884320e+00 -3.87636447e+00 -1.05498839e+01
  5.96074166e+00  1.40924662e+02  2.76212041e+02 -1.29518507e+02
  2.76155534e+02  2.45274251e+01  1.02286505e+01  1.65219856e+01
 -3.06252806e+00  4.51993021e+00 -2.21180560e+00 -2.10334492e+01
 -1.33769304e-02  2.99644989e+00 -3.57309782e+00  2.49739989e+00
 -4.72330549e+00  9.08958758e+01 -2.77428802e+00  2.31431153e+01
 -1.81041610e+01  1.75514619e+01  1.45860975e+01  2.65021217e+01
 -5.73140314e+00  1.22638282e+02  1.12858869e+00  6.66592632e+01
  6.86364251e+00  1.46810935e+00  9.11290135e-01 -2.61372038e+00
  5.92108960e+00  3.52068940e+00  3.73966157e+00 -2.42637318e+00
  2.93013001e+01]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1853.0177423760476
gradient value of function right now is: [-1.34395719e-01  3.46815082e-04  1.67970856e-01 -2.65788302e-06
  1.34395719e-01 -3.46815082e-04 -1.67970856e-01  2.65788302e-06
 -5.04446788e-01 -1.04669998e+00 -5.61649667e-02 -6.47330963e-01
 -2.31433459e-04  1.02985922e-04  3.76936468e-12 -6.73346530e-03
 -5.35927386e-02  5.26434943e-03  1.83990828e-33 -1.77719357e+00
  3.42731234e-07 -2.05710699e-10 -1.38907333e-47 -5.56304205e-05
  1.97720680e+00  2.02839555e+00  1.73020795e-01  1.07483735e+00
 -3.06245510e-01  1.22926434e-04 -1.17787629e-04  1.89905532e-05
 -4.33762037e-03 -2.90359063e-36 -4.22309989e-13 -6.98160266e-48
  7.23144528e-01  2.92225097e-01  6.52550912e-02  4.15378024e-02
 -5.19713664e-02  1.90089869e+00 -1.66652003e-01  9.08464021e-01
 -1.89882151e-03  4.55132253e-03  3.67547049e-02  6.46245647e-03
  5.48413906e-01 -5.53218751e-03  7.07612744e-01  2.02467013e-02
  3.14776223e+00  7.08678477e-02  4.62577968e+00  8.50093880e-02
  1.86168628e+00 -1.13452244e+01 -2.28427103e+00  1.30013533e+01
 -6.35490694e-01  9.91588114e-01 -1.28646102e+00  7.77057659e+00
  3.26270305e+00]
supnorm grad right now is: 13.001353328302885
Weights right now are: 
[  -7.40946294   15.81289737    7.36776938  -45.5140026     7.66403165
  -15.92158906   -6.96883211   44.79797421   -5.8438617     4.15911394
  -10.16291869    6.10017829   -2.44417204   38.23975531   44.28454329
   11.61303285   27.62911262  120.06632926   29.90199036    2.12025883
  178.01003709   22.13774977   35.52848511   20.89131568    5.05273254
    2.20181044   -4.52971065   -9.93873183    5.64081082  138.05244326
  282.62666189 -134.45505072  279.42132093   24.52742505   10.22865116
   16.52198564   -2.90539682    4.51001984   -1.4536328   -21.66087699
    0.67822195    3.11907689   -3.93797985    2.99991886   -4.81204346
   93.19746844   -2.1523928    24.11435558  -17.59947714   16.38161427
   15.11954409   26.74261123   -5.60179006  124.25394763    1.07885745
   66.55502416    6.7383039     1.53596984    0.76094742   -2.61653034
    5.41118473    3.90086897    4.52737349   -2.08201621   29.21275284]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1849.4757406731487
gradient value of function right now is: [ 1.10136586e+00 -9.21947537e-04 -1.55833766e-01 -7.10582199e-06
 -1.10136586e+00  9.21947537e-04  1.55833766e-01  7.10582199e-06
  5.52981320e+00  5.59085622e+00  1.03456878e-01  8.72003999e+00
 -3.00118419e-03 -4.34278073e-04 -1.80928747e-11  1.02007071e-02
 -6.45557478e-03 -7.40824170e-03 -3.04553193e-32  8.10276835e-01
 -5.95256649e-06  9.45919249e-10  2.09248933e-47 -3.34262310e-04
  3.43227920e-01 -3.15487932e+00 -5.47023378e-01 -1.25359882e+00
 -3.53693776e-01  5.94908878e-04 -3.84819507e-04  4.42479361e-06
  9.81731119e-03  5.85149008e-38  6.27652932e-13  6.39605534e-50
 -3.11161960e+00 -8.07805528e-01 -2.76547907e-01 -7.20434189e-02
 -4.18488314e-01 -7.21932809e+00 -8.30023776e-01 -2.79109010e+00
  2.07726909e-01 -7.70121925e-03  1.85131627e-01  6.56305628e-03
 -1.80593698e+00  8.86521742e-02 -2.22928070e+00 -7.80676748e-02
 -4.01662954e+00 -1.17568301e-01 -6.54684534e+00 -1.08465491e-01
 -3.37858456e+00  2.07111125e+01  6.01097289e+00 -2.14227317e+01
 -1.12891094e+00 -1.36032084e-02  3.05973442e+00 -8.81236994e+00
 -2.43749769e+01]
supnorm grad right now is: 24.37497690522526
Weights right now are: 
[  -7.29597132   16.34945513    6.8996264   -47.70114584    7.55054004
  -16.45814682   -6.50068913   46.98511746   -5.62847685    4.2449023
   -9.88994121    6.08528963   -2.30556392   40.25962464   44.28454991
   11.48601919   27.48166898  119.8517479    29.90199036    2.16394237
  183.88468725   22.13753953   35.52848511   18.99113888    4.84370056
    2.25940554   -5.01445127  -10.00806944    5.71106043  141.07811193
  287.71131142 -136.60970165  283.78154441   24.52742505   10.22865076
   16.52198564   -3.22401122    4.54642031   -1.43098538  -21.55352502
    0.34996757    2.87405949   -3.9491476     2.80734689   -5.1056752
   93.49360023   -2.85647007   23.02977803  -18.37660627   16.36202013
   14.50295017   26.53741435   -5.85983863  126.44532913    0.8897473
   65.9104931     7.05885657    1.65853777    0.82765757   -2.56460758
    6.14625493    3.44139265    4.85585964   -2.12981973   29.06046711]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1854.2625064477434
gradient value of function right now is: [-3.01356363e-02  7.16782611e-03  3.35644945e-01  1.99849911e-04
  3.01356363e-02 -7.16782611e-03 -3.35644945e-01 -1.99849911e-04
  2.09169572e-01  2.59871700e-01 -2.70891568e-02 -6.02833049e-01
  6.60633937e-03  5.94058250e-04 -3.05794495e-11 -8.46202546e-02
  1.41415481e-02 -5.43215987e-03 -1.78584516e-32 -2.33130762e+00
  6.44533304e-05  1.58336126e-09  4.35807760e-49  7.51312699e-03
  6.91354649e-03  1.08439751e+00  6.40571200e-02  3.97328026e-01
  7.50908926e-01  3.31971196e-05  8.90492741e-04 -1.31154557e-06
 -7.69699448e-04 -2.13629427e-38  2.04360728e-13 -2.02187336e-50
  1.93725108e+00  8.33663009e-01  1.24690299e-01  5.89155277e-02
 -4.13003666e-01  1.09525618e+00 -3.48003043e-01  2.14333853e-01
 -3.80144110e-01 -1.33454215e-02 -3.66444338e-01 -1.90170104e-02
  5.13555001e-01 -1.07108988e-01  5.73260165e-01  5.54623323e-03
  2.45427956e+00  7.03333690e-02  2.96011977e+00  6.67640394e-02
  7.85817214e-01 -6.24127319e+00 -2.06993226e+00  1.13054232e+01
  1.31786287e+00 -8.39177044e-01 -4.71773852e-01  5.79151492e+00
  2.25744069e+00]
supnorm grad right now is: 11.305423193790254
Weights right now are: 
[  -7.39639122   16.83334715    7.16015276  -49.64183898    7.65095993
  -16.94203884   -6.76121549   48.92581059   -5.63417227    4.53250406
  -10.13205193    5.96689393   -1.97606874   38.00742403   44.28457901
   10.36442505   26.53353332  120.54084722   29.90199036    2.0752966
  190.06365964   22.13636154   35.52848511   18.16254006    4.67553642
    1.98588232   -4.40603022   -9.79319119    6.47137787  140.87779237
  293.7308146  -138.24476364  287.70950164   24.52742505   10.22865419
   16.52198564   -2.74017239    4.40418908   -1.41103954  -21.92926588
    0.77570049    2.94609342   -4.39071768    2.92798179   -4.81074356
   94.71601205   -2.85075428   22.91470697  -17.41650117   15.82506135
   15.25892925   27.60650644   -5.56498773  128.1573567     1.09205718
   65.0492538     6.89113876    1.68656105    0.71677744   -2.59059365
    6.0214305     3.3146888     4.2101274    -2.29085649   29.19384948]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.9417529888601
gradient value of function right now is: [ 6.72609293e-02 -2.46299885e-03 -2.13205631e-03 -1.06176729e-04
 -6.72609293e-02  2.46299885e-03  2.13205631e-03  1.06176729e-04
  2.04102812e-01  1.60017816e-01 -2.48261780e-02  7.77688344e-01
 -6.75564043e-04 -1.61937699e-04 -1.09518779e-12  2.14313911e-02
 -1.11581627e-02 -9.37134175e-04 -1.15660858e-33 -1.03252586e-01
 -5.28351693e-05  7.25986382e-10  1.73932449e-50 -3.56075926e-03
  4.05746399e-01 -1.44132648e-01  5.42769032e-02 -1.24351184e-01
 -2.93162893e-02  1.22506102e-04 -3.09920507e-04  1.55388941e-06
 -1.72815672e-03 -3.82602475e-38  5.50941614e-14  1.74012740e-51
 -3.98760662e-01 -9.00199883e-02  1.65613597e-04 -1.39970161e-02
 -7.04703478e-02 -1.26760453e-01 -1.84885436e-01  3.21988374e-01
 -1.09212705e-01 -1.03603937e-02 -1.54694630e-01 -8.09669634e-03
  9.62738720e-02  3.95969203e-02  1.01932215e-01  6.09146087e-03
 -2.91777952e-01 -6.17955423e-03 -6.40418947e-01 -1.91109772e-03
 -3.56982474e-01  1.57721400e+00  7.61592450e-01 -2.11282848e+00
 -2.96639455e-01  4.17693060e-01  2.10403903e-01 -4.55431121e-01
 -2.13664476e+00]
supnorm grad right now is: 2.136644763811119
Weights right now are: 
[  -7.59042114   17.19451649    7.17986951  -49.85888135    7.84498985
  -17.30320818   -6.78093224   49.14285297   -5.96250106    3.76543136
   -9.30538816    5.87523096   -0.88897335   41.88190308   44.28459529
   10.74906728   26.84988568  121.62459984   29.90199036    2.22041972
  197.59831054   22.13522917   35.52848511   18.94241395    4.95236749
    2.02543597   -3.74315122   -9.95213655    5.6606156   143.39572201
  300.25083075 -140.19278269  290.91244156   24.52742505   10.22865465
   16.52198564   -3.36584621    4.73505088   -1.15595109  -21.52066195
    0.33602909    3.02066548   -4.5553991     3.21026696   -4.8735403
   94.89286829   -2.99977808   21.07192979  -17.70535281   15.6687719
   15.20264605   26.3741126    -5.3852488   130.38384577    1.18813622
   65.29984192    7.22017701    1.87684825    0.73261204   -2.492584
    5.93320056    3.45909842    4.38419524   -2.37278473   29.09993705]
(65,)
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.964171090915
gradient value of function right now is: [ 7.61896309e-02 -1.89573002e-03  1.12968332e-02 -8.52507809e-05
 -7.61896309e-02  1.89573002e-03 -1.12968332e-02  8.52507809e-05
  2.54756919e-01  2.06448449e-01 -2.14230115e-02  8.24920080e-01
 -3.47101626e-04 -9.08392609e-05 -3.65313379e-13  1.60945148e-02
 -1.06408480e-02 -1.11564671e-03 -1.29916430e-33 -1.71621358e-01
 -4.36705707e-05  7.69236017e-10  3.30443867e-51 -2.78428082e-03
  3.91730447e-01 -1.44417283e-01  5.32212502e-02 -1.14918874e-01
 -6.54300757e-03  1.35097324e-04 -2.38993481e-04  1.56125471e-06
 -1.39562075e-03 -2.60357615e-38  4.77782789e-14  4.89965755e-52
 -3.34405814e-01 -5.72893509e-02  2.23811258e-03 -1.37743278e-02
 -7.69107591e-02 -2.02783527e-01 -1.86433247e-01  2.64543132e-01
 -1.25750448e-01 -1.12196569e-02 -1.67113008e-01 -9.05251001e-03
  7.74498329e-02  3.54119508e-02  7.80177313e-02  4.43749757e-03
 -2.67627052e-01 -6.43554835e-03 -6.00625148e-01 -1.62347516e-03
 -3.14000847e-01  1.47870382e+00  7.79498717e-01 -2.24582242e+00
 -2.27073990e-01  3.17433823e-01  2.42014496e-01 -3.87711726e-01
 -2.23938144e+00]
supnorm grad right now is: 2.2458224190491443
Weights right now are: 
[-7.45887235e+00  1.65252514e+01  7.08539154e+00 -5.05526496e+01
  7.71344106e+00 -1.66339431e+01 -6.68645427e+00  4.98366212e+01
 -5.71376576e+00  4.14359245e+00 -9.35433641e+00  6.07053357e+00
 -3.08104677e-01  4.57158243e+01  4.42845958e+01  1.23370780e+01
  2.65653380e+01  1.21311877e+02  2.99019904e+01  2.14266054e+00
  2.05632316e+02  2.21345350e+01  3.55284851e+01  1.87444598e+01
  5.22495255e+00  1.72508935e+00 -4.46435126e+00 -1.02729163e+01
  5.86732798e+00  1.42437144e+02  3.03341931e+02 -1.42238985e+02
  2.94750968e+02  2.45274251e+01  1.02286547e+01  1.65219856e+01
 -2.74497447e+00  4.75504232e+00 -1.46051327e+00 -2.17715146e+01
  2.80676840e-01  2.80024489e+00 -4.09085198e+00  3.28246889e+00
 -4.79977542e+00  9.56332790e+01 -2.98624445e+00  2.12592733e+01
 -1.81204631e+01  1.79666564e+01  1.52568022e+01  2.79736872e+01
 -5.41527819e+00  1.32326902e+02  9.32190049e-01  6.49653013e+01
  6.99275479e+00  1.72524584e+00  9.16731249e-01 -2.77772066e+00
  5.67266372e+00  3.59031539e+00  4.75564303e+00 -2.23778504e+00
  2.92511486e+01]
(65,)
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.9350804058574
gradient value of function right now is: [ 7.01608495e-02 -1.76817322e-03  9.86896665e-03 -7.90486317e-05
 -7.01608495e-02  1.76817322e-03 -9.86896665e-03  7.90486317e-05
  2.25610946e-01  1.62889908e-01 -2.52395100e-02  7.83711117e-01
 -2.53470514e-04 -7.62957647e-05 -2.45335958e-13  1.60603315e-02
 -1.05289377e-02 -9.13949926e-04 -1.06040229e-33 -1.66747079e-01
 -3.59476601e-05  4.34608059e-10  4.07352537e-52 -2.59866409e-03
  4.14083630e-01 -1.15483352e-01  5.07846966e-02 -9.41684454e-02
 -2.21423784e-02  1.36929522e-04 -3.20943678e-04  1.64424799e-06
 -1.57138692e-03 -4.58510012e-38  4.36921541e-14  1.40028372e-51
 -3.16653899e-01 -5.16363133e-02  4.20075665e-03 -1.32515511e-02
 -6.91136667e-02 -1.16764604e-01 -1.80744730e-01  3.08227524e-01
 -1.22311968e-01 -1.14643410e-02 -1.71088978e-01 -8.68809488e-03
  8.01031870e-02  3.91469908e-02  8.65895174e-02  4.91281346e-03
 -2.34367693e-01 -5.67325723e-03 -5.43134887e-01 -1.31454221e-03
 -2.58634543e-01  1.25676221e+00  7.09545607e-01 -2.15646935e+00
 -2.71046199e-01  3.86051126e-01  1.88356623e-01 -4.09577453e-01
 -2.18502394e+00]
supnorm grad right now is: 2.1850239444513604
Weights right now are: 
[  -7.34732385   17.83012675    7.45710963  -48.09988286    7.60189256
  -17.93881844   -7.05817236   47.38385448   -5.86607201    4.12504874
   -9.86616085    5.99339718   -2.57542643   43.83827831   44.28459647
   11.98788521   28.49063823  121.60914113   29.90199036    2.23025584
  211.12895871   22.13421969   35.52848511   20.65281475    4.89204422
    2.02219955   -3.98975844  -10.41014557    5.54806952  141.84764962
  310.56617339 -144.3514868   298.8224623    24.52742505   10.228655
   16.52198564   -3.02099653    4.80130822   -1.95153215  -21.23732755
    0.48932079    3.19809257   -3.76738401    3.02738174   -5.38608199
   97.13783207   -2.87028039   20.90437151  -18.08104136   17.2950211
   15.00937918   27.79569769   -5.78867258  134.48624128    0.80360411
   64.88609711    6.95385748    1.81570444    0.85409779   -2.49478335
    6.03753165    3.6319169     4.17126385   -2.34720759   29.22402572]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.9483599078678
gradient value of function right now is: [ 6.82691615e-02 -1.58711580e-03  6.55789033e-03 -6.91480368e-05
 -6.82691615e-02  1.58711580e-03 -6.55789033e-03  6.91480368e-05
  2.33508512e-01  1.69303775e-01 -2.61398275e-02  7.50751059e-01
 -2.97328968e-04 -7.41353193e-05 -3.91641611e-13  1.52423619e-02
 -9.91598886e-03 -1.02379301e-03 -9.21178080e-34 -1.55088191e-01
 -2.93137800e-05  3.99647597e-10  1.16327917e-52 -2.34306381e-03
  4.02424749e-01 -1.08522633e-01  4.75936130e-02 -8.72586845e-02
 -4.00554413e-03  1.45867019e-04 -2.85386276e-04  1.73470755e-06
 -1.57945804e-03 -4.97616452e-38  3.73315133e-14  2.20569707e-51
 -2.93998576e-01 -5.05441407e-02  4.85741955e-03 -1.31582639e-02
 -7.23764274e-02 -7.75466639e-02 -1.87237084e-01  3.13985340e-01
 -1.16838436e-01 -1.11932016e-02 -1.63618742e-01 -8.16253561e-03
  7.50140210e-02  3.46756213e-02  8.01243666e-02  4.39951059e-03
 -2.20696316e-01 -5.37609718e-03 -5.15031821e-01 -1.16243890e-03
 -2.48009625e-01  1.21062565e+00  7.07656595e-01 -2.09105111e+00
 -2.61211920e-01  3.81224247e-01  1.74095383e-01 -3.97176498e-01
 -2.09277614e+00]
supnorm grad right now is: 2.092776143160261
Weights right now are: 
[  -7.45858483   16.634608      7.65388281  -51.25133048    7.71315354
  -16.74329969   -7.25494554   50.5353021    -6.24883833    4.00682575
   -9.94494848    5.99662454   -2.76512867   41.21562551   44.28460418
   11.59200453   27.60527605  122.64361879   29.90199036    2.07945168
  213.16284203   22.13376216   35.52848511   17.29689915    5.00749385
    1.83004847   -4.25938636  -10.29472023    5.47206198  144.6790506
  314.93629975 -146.04716052  301.38494695   24.52742505   10.22865634
   16.52198564   -3.12406067    4.59566361   -0.77529369  -20.75370352
    0.51224862    3.88372214   -3.95379469    3.34778294   -5.22528428
   97.33820229   -2.34156862   20.09099176  -18.17489822   18.41731289
   15.21329918   28.22071759   -5.63500537  135.93233185    1.33741457
   63.59989936    6.89914717    1.77004978    0.6645851    -2.62757433
    5.88817793    3.37814769    3.95745184   -2.68352022   29.27817617]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1855.9453661200341
gradient value of function right now is: [ 6.91316362e-02 -1.45768371e-03  8.17688412e-03 -6.39581115e-05
 -6.91316362e-02  1.45768371e-03 -8.17688412e-03  6.39581115e-05
  2.39012043e-01  1.77529679e-01 -2.69574718e-02  7.51417913e-01
 -2.61614090e-04 -6.96082389e-05 -4.38043451e-13  1.44836437e-02
 -9.94750972e-03 -9.78035382e-04 -8.61540070e-34 -1.78874985e-01
 -2.70568480e-05  4.51843484e-10  3.78051190e-53 -2.21190822e-03
  4.02600358e-01 -1.14095230e-01  4.61609869e-02 -8.91979275e-02
 -9.80102529e-03  1.51521252e-04 -3.05588335e-04  1.70330589e-06
 -1.57662717e-03 -5.90850384e-38  3.23887353e-14  3.38992918e-51
 -2.85974969e-01 -4.93191868e-02  4.68803302e-03 -1.30727428e-02
 -7.02171847e-02 -7.12408138e-02 -1.84934238e-01  3.17277596e-01
 -1.16817408e-01 -1.14517239e-02 -1.68946804e-01 -8.05672432e-03
  7.02188197e-02  3.57841054e-02  7.54215127e-02  4.31333850e-03
 -2.28616544e-01 -5.52540289e-03 -5.22758186e-01 -1.45766049e-03
 -2.49289280e-01  1.24117693e+00  7.00622325e-01 -2.15137573e+00
 -2.69368873e-01  3.93461897e-01  1.65635682e-01 -4.19266595e-01
 -2.09721889e+00]
supnorm grad right now is: 2.1513757320269575
Weights right now are: 
[  -7.61293385   17.54712105    7.50033029  -50.03741852    7.86750256
  -17.65581274   -7.10139303   49.32139014   -6.02446038    4.04328233
   -9.89431642    5.80820403   -1.76701815   43.19707424   44.28460654
   11.5476182    27.24162031  122.86456982   29.90199036    2.17736653
  219.77368611   22.13283817   35.52848511   18.77239401    4.97235357
    2.28955051   -4.38761797  -10.0067827     5.80681456  145.73136584
  321.4507206  -146.9887561   306.32508164   24.52742505   10.22865689
   16.52198564   -2.8249187     4.30061812   -1.57683031  -21.14052037
    0.6263763     3.49571632   -3.75635462    2.6624707    -5.04204819
   98.10229434   -2.66864122   20.4791243   -18.13630137   17.55450045
   14.99096203   28.7517345    -5.90162171  138.20398237    1.07101732
   63.51721041    7.15993209    1.57891341    0.92458622   -2.56522054
    6.57030208    3.72119931    4.47652153   -2.24387889   29.26138175]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1339.8539763902143
W_T_median: 1140.9913141876636
W_T_pctile_5: 857.2502602462775
W_T_CVAR_5_pct: 784.0804674838864
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.8
F value: -1855.9453661200341
-----------------------------------------------
