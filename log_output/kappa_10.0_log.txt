tracing parameter entered from terminal:  10.0


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16003.679234832507
gradient value of function right now is: [ 5.07409598e-05  2.35403256e-06  5.06848235e-05  5.06929431e-05
 -5.07409490e-05 -2.35403206e-06 -5.06848127e-05 -5.06929323e-05
  7.00364216e-07  8.82240669e-08  6.77338835e-07  7.26638833e-07
  2.55543855e-06  3.22249567e-07  2.47180833e-06  2.65146747e-06
  7.86163661e-07  9.90401532e-08  7.60325908e-07  8.15660799e-07
  8.06845945e-07  1.01642514e-07  7.80327070e-07  8.37117670e-07
 -2.12958032e-08 -5.16034514e-09 -2.32512730e-08 -3.90228601e-09
  5.50528544e-08  1.64090789e-08  6.33722486e-08  1.07529743e-08
  3.43959066e-07  1.06621645e-07  4.00418137e-07  6.79916144e-08
  4.31571868e-08  1.49315279e-08  5.19036913e-08  8.86395102e-09
  4.46046509e-08  5.54035759e-08  2.85551629e-08  5.14009469e-08
  1.90868473e-08  2.34580117e-08  1.25153553e-08  2.21817903e-08
  3.17046451e-08  3.80524555e-08  1.41109758e-08  2.64441276e-08
  4.10438785e-08  4.78595277e-08  1.53332836e-08  2.83322949e-08
  9.56262576e-09  2.05063639e-09 -6.39993053e-10 -4.47519483e-10
  1.45006770e-10 -5.33805484e-10 -4.38208974e-09 -8.08096951e-10
 -3.83789088e+00]
supnorm grad right now is: 3.837890878172611
Weights right now are: 
[-3.57437724e+00 -6.64618250e-01 -2.48004364e+00 -3.25672682e+00
  3.82894595e+00  5.55926560e-01  2.87898091e+00  2.54069843e+00
 -2.25978322e+00 -9.66477318e-01 -2.27244799e+00 -2.00746738e+00
  1.82125169e+00  5.34344713e-01  2.58950222e-01  1.06525571e+00
 -1.31774323e+00 -6.09017941e-01 -2.64556132e+00 -2.15479066e+00
 -2.01193810e+00 -1.08644932e+00 -2.37320420e+00 -1.73638766e+00
 -1.03052280e+00 -8.96139658e-01 -1.76870816e+00 -9.87390857e-01
  4.49026779e-01  1.45497217e+00  1.50251999e+00  5.13728047e-01
 -1.07202890e+00 -6.56007368e-01 -1.27040278e+00 -1.28116871e+00
 -2.49879502e+00 -1.43730906e+00 -1.25110031e+00 -1.08724105e+00
 -9.99153652e-01 -9.48183283e-01 -7.25021798e-02  1.71319349e-01
  5.02278806e-01  1.31698103e+00  1.59712171e-02  3.78990279e-01
 -1.46745146e+00 -4.31142398e-01 -4.40767260e-01 -1.59149524e+00
  4.67866984e-01  1.22067271e+00  4.95084623e-01  1.64689227e+00
  1.20692218e+00 -2.12671948e+00 -1.90191309e-01 -2.22908873e+00
  2.15792522e+00  1.06025421e+00 -4.14062737e-02  1.38499474e+00
  2.46963107e+01]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.233675051302
gradient value of function right now is: [ 1.24077133e-07  9.30907527e-09  1.24004995e-07  1.24020087e-07
 -1.24077306e-07 -9.30909123e-09 -1.24005168e-07 -1.24020260e-07
  1.90161513e-09  2.39605012e-10  1.85660385e-09  1.97456477e-09
  1.09216657e-08  1.37783139e-09  1.06649415e-08  1.13413737e-08
  1.98983448e-09  2.50730983e-10  1.94274439e-09  2.06617277e-09
  2.03527285e-09  2.56447449e-10  1.98710287e-09  2.11335041e-09
 -3.31863475e-10 -9.54202086e-11 -3.77394411e-10 -6.44592719e-11
 -2.76587865e-11 -4.96224451e-12 -2.83015382e-11 -4.73078051e-12
  9.38987618e-10  2.91349097e-10  1.09060268e-09  1.86808730e-10
  4.89925115e-11  1.83177347e-11  6.02151568e-11  1.04085255e-11
  8.63528206e-11  1.07678318e-10  5.70245390e-11  1.02590387e-10
  4.60635472e-11  5.60512414e-11  2.77776842e-11  4.93779136e-11
  6.47023085e-11  7.76905724e-11  2.89623029e-11  5.42895461e-11
  8.96755612e-11  1.04630050e-10  3.37162836e-11  6.23285878e-11
  1.86334994e-11  3.64244342e-12 -3.33644643e-12 -1.11566198e-12
  6.36279141e-14 -1.05761192e-12 -1.04053624e-11 -2.00820013e-12
  8.12399665e-01]
supnorm grad right now is: 0.8123996648365225
Weights right now are: 
[-4.52091252e+00 -7.34427455e-01 -3.46467805e+00 -4.30965148e+00
  4.77548135e+00  6.25735773e-01  3.86361544e+00  3.59362323e+00
 -2.29349229e+00 -9.70915910e-01 -2.31924308e+00 -2.03686022e+00
  1.64403943e+00  5.13414458e-01  3.97177546e-02  9.13265864e-01
 -1.40198680e+00 -6.21327299e-01 -2.75511665e+00 -2.23421353e+00
 -2.09481984e+00 -1.09986638e+00 -2.48712390e+00 -1.81584842e+00
 -1.02531970e+00 -8.94542452e-01 -1.76221414e+00 -9.86116115e-01
  4.46816974e-01  1.45410124e+00  1.49906290e+00  5.13067058e-01
 -1.12192553e+00 -6.72548825e-01 -1.32832394e+00 -1.29344207e+00
 -2.50283260e+00 -1.43884361e+00 -1.25606155e+00 -1.08838940e+00
 -1.00709095e+00 -9.57638449e-01 -7.76781522e-02  1.62107606e-01
  4.98617593e-01  1.31255532e+00  1.35908874e-02  3.74782458e-01
 -1.47276545e+00 -4.37021749e-01 -4.43189170e-01 -1.59594598e+00
  4.60689035e-01  1.21287703e+00  4.92349519e-01  1.64192021e+00
  1.20510924e+00 -2.12710455e+00 -1.90037338e-01 -2.22899632e+00
  2.15790154e+00  1.06035698e+00 -4.05620691e-02  1.38516306e+00
  2.50401468e+01]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.151422960409
gradient value of function right now is: [ 4.95178764e-08  3.85168614e-09  4.94893436e-08  4.94953280e-08
 -4.95174669e-08 -3.85165564e-09 -4.94889344e-08 -4.94949186e-08
  7.78201630e-10  9.80497724e-11  7.59972338e-10  8.08099493e-10
  4.58230170e-09  5.78065175e-10  4.47572012e-09  4.75865941e-09
  8.20848680e-10  1.03427320e-10  8.01624228e-10  8.52386809e-10
  8.37108626e-10  1.05472366e-10  8.17501474e-10  8.69269864e-10
 -1.40902281e-10 -4.05137363e-11 -1.60228655e-10 -2.73713481e-11
 -1.47735993e-11 -2.98019224e-12 -1.54637383e-11 -2.59816274e-12
  3.89522640e-10  1.20777472e-10  4.52312825e-10  7.74852102e-11
  1.98290408e-11  7.43340777e-12  2.43910918e-11  4.21725477e-12
  3.55620185e-11  4.43423808e-11  2.34568411e-11  4.22080071e-11
  1.92826945e-11  2.34459474e-11  1.15397306e-11  2.05215816e-11
  2.67976971e-11  3.21671159e-11  1.19524764e-11  2.24117696e-11
  3.70428068e-11  4.32151504e-11  1.38997282e-11  2.57015785e-11
  7.67337008e-12  1.50723525e-12 -1.42525414e-12 -4.62667078e-13
  2.75077712e-14 -4.35149179e-13 -4.29061622e-12 -8.31319456e-13
  1.73100882e+00]
supnorm grad right now is: 1.7310088170877191
Weights right now are: 
[-4.67324188e+00 -7.46061493e-01 -3.61691923e+00 -4.46191114e+00
  4.92781072e+00  6.37369812e-01  4.01585663e+00  3.74588290e+00
 -2.29585670e+00 -9.71213780e-01 -2.32155178e+00 -2.03931539e+00
  1.63029540e+00  5.11680831e-01  2.62952985e-02  8.98993362e-01
 -1.40447089e+00 -6.21640258e-01 -2.75754222e+00 -2.23679297e+00
 -2.09735687e+00 -1.10018600e+00 -2.48960115e+00 -1.81848283e+00
 -1.02489995e+00 -8.94421534e-01 -1.76173656e+00 -9.86034541e-01
  4.46856313e-01  1.45410878e+00  1.49910366e+00  5.13073890e-01
 -1.12310055e+00 -6.72914017e-01 -1.32968933e+00 -1.29367595e+00
 -2.50289328e+00 -1.43886637e+00 -1.25613621e+00 -1.08840231e+00
 -1.00719858e+00 -9.57772692e-01 -7.77495629e-02  1.61979207e-01
  4.98559735e-01  1.31248492e+00  1.35559337e-02  3.74720350e-01
 -1.47284627e+00 -4.37118808e-01 -4.43225490e-01 -1.59601402e+00
  4.60577201e-01  1.21274651e+00  4.92307266e-01  1.64184215e+00
  1.20508598e+00 -2.12710906e+00 -1.90033100e-01 -2.22899493e+00
  2.15790145e+00  1.06035830e+00 -4.05490706e-02  1.38516553e+00
  2.51266841e+01]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.258653893305
gradient value of function right now is: [ 3.10526005e-08  2.46214646e-09  3.10347905e-08  3.10385304e-08
 -3.10523717e-08 -2.46212768e-09 -3.10345618e-08 -3.10383017e-08
  4.94140622e-10  6.22513637e-11  4.82624230e-10  5.13137771e-10
  2.95015553e-09  3.72122602e-10  2.88189067e-09  3.06377437e-09
  5.23222371e-10  6.59177482e-11  5.11030652e-10  5.43338711e-10
  5.32829100e-10  6.71256685e-11  5.20412320e-10  5.53313755e-10
 -9.13566407e-11 -2.63081459e-11 -1.03928127e-10 -1.77559762e-11
 -1.06640968e-11 -2.24809857e-12 -1.12641830e-11 -1.89633373e-12
  2.49038534e-10  7.73071131e-11  2.89271576e-10  4.95605707e-11
  1.24676601e-11  4.69017182e-12  1.53530862e-11  2.65523639e-12
  2.26071020e-11  2.81955765e-11  1.49623349e-11  2.69131614e-11
  1.23701279e-11  1.50383815e-11  7.40143990e-12  1.31597375e-11
  1.70816469e-11  2.05061081e-11  7.63678679e-12  1.43132950e-11
  2.35856288e-11  2.75204673e-11  8.87915781e-12  1.64111440e-11
  4.88329680e-12  9.51150252e-13 -9.27170657e-13 -2.93985872e-13
  1.75721102e-14 -2.76674568e-13 -2.73694534e-12 -5.21037436e-13
  5.54410578e-02]
supnorm grad right now is: 0.05544105778609114
Weights right now are: 
[-4.75110678e+00 -7.52175811e-01 -3.69473936e+00 -4.53974067e+00
  5.00567574e+00  6.43484140e-01  4.09367688e+00  3.82371255e+00
 -2.29708809e+00 -9.71368913e-01 -2.32275439e+00 -2.04059410e+00
  1.62299550e+00  5.10760030e-01  1.91648070e-02  8.91412443e-01
 -1.40577226e+00 -6.21804213e-01 -2.75881318e+00 -2.23814435e+00
 -2.09868307e+00 -1.10035308e+00 -2.49089636e+00 -1.81985999e+00
 -1.02467476e+00 -8.94356689e-01 -1.76148038e+00 -9.85990780e-01
  4.46881230e-01  1.45411392e+00  1.49912986e+00  5.13078297e-01
 -1.12371895e+00 -6.73106010e-01 -1.33040768e+00 -1.29379901e+00
 -2.50292452e+00 -1.43887811e+00 -1.25617466e+00 -1.08840896e+00
 -1.00725487e+00 -9.57842903e-01 -7.77868429e-02  1.61912182e-01
  4.98529083e-01  1.31244764e+00  1.35375436e-02  3.74687670e-01
 -1.47288873e+00 -4.37169791e-01 -4.43244496e-01 -1.59604963e+00
  4.60518551e-01  1.21267807e+00  4.92285166e-01  1.64180132e+00
  1.20507382e+00 -2.12711143e+00 -1.90030815e-01 -2.22899420e+00
  2.15790141e+00  1.06035899e+00 -4.05422605e-02  1.38516683e+00
  2.50130432e+01]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.222550730383
gradient value of function right now is: [ 2.25470766e-08  1.81160350e-09  2.25341880e-08  2.25368967e-08
 -2.25483164e-08 -1.81169799e-09 -2.25354271e-08 -2.25381359e-08
  3.61755024e-10  4.55737440e-11  3.53357534e-10  3.75670846e-10
  2.18132762e-09  2.75147261e-10  2.13105615e-09  2.26538658e-09
  3.84009255e-10  4.83792937e-11  3.75096970e-10  3.98781983e-10
  3.90693824e-10  4.92197121e-11  3.81625498e-10  4.05722950e-10
 -6.79317905e-11 -1.95555342e-11 -7.72715587e-11 -1.32023409e-11
 -8.50694469e-12 -1.83814027e-12 -9.03270618e-12 -1.52247419e-12
  1.83223826e-10  5.68359306e-11  2.12778459e-10  3.64559119e-11
  9.04559284e-12  3.40673046e-12  1.11430507e-11  1.92732822e-12
  1.65679620e-11  2.06609286e-11  1.09492859e-11  1.96976215e-11
  9.12676878e-12  1.10907609e-11  5.43790313e-12  9.67077491e-12
  1.25476340e-11  1.50596228e-11  5.59548786e-12  1.04896510e-11
  1.73172969e-11  2.02033913e-11  6.50636846e-12  1.20278460e-11
  3.57611092e-12  6.99575909e-13 -6.90117660e-13 -2.16397322e-13
  1.25786931e-14 -2.02460793e-13 -2.00803278e-12 -3.84885053e-13
  9.94465236e-01]
supnorm grad right now is: 0.9944652364947748
Weights right now are: 
[-4.80397018e+00 -7.56394849e-01 -3.74757249e+00 -4.59258016e+00
  5.05853916e+00  6.47703179e-01  4.14651004e+00  3.87655206e+00
 -2.29793274e+00 -9.71475322e-01 -2.32357939e+00 -2.04147123e+00
  1.61792799e+00  5.10120821e-01  1.42143183e-02  8.86149710e-01
 -1.40666773e+00 -6.21917031e-01 -2.75968783e+00 -2.23907426e+00
 -2.09959456e+00 -1.10046791e+00 -2.49178666e+00 -1.82080654e+00
 -1.02451739e+00 -8.94311383e-01 -1.76130138e+00 -9.85960194e-01
  4.46900262e-01  1.45411798e+00  1.49915002e+00  5.13081692e-01
 -1.12414568e+00 -6.73238428e-01 -1.33090329e+00 -1.29388393e+00
 -2.50294574e+00 -1.43888610e+00 -1.25620080e+00 -1.08841348e+00
 -1.00729352e+00 -9.57891117e-01 -7.78123992e-02  1.61866186e-01
  4.98507858e-01  1.31242184e+00  1.35248767e-02  3.74665135e-01
 -1.47291798e+00 -4.37204900e-01 -4.43257550e-01 -1.59607411e+00
  4.60478174e-01  1.21263096e+00  4.92269989e-01  1.64177325e+00
  1.20506547e+00 -2.12711306e+00 -1.90029217e-01 -2.22899370e+00
  2.15790138e+00  1.06035946e+00 -4.05375763e-02  1.38516772e+00
  2.50736092e+01]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16003.699294085029
gradient value of function right now is: [ 1.78561352e-08  1.44950285e-09  1.78459509e-08  1.78480924e-08
 -1.78567761e-08 -1.44955650e-09 -1.78465913e-08 -1.78487329e-08
  2.88331380e-10  3.63142599e-11  2.81650409e-10  2.99423957e-10
  1.75167026e-09  2.20895673e-10  1.71137631e-09  1.81918036e-09
  3.06632691e-10  3.86208302e-11  2.99529096e-10  3.18430026e-10
  3.11757679e-10  3.92649195e-11  3.04534642e-10  3.23751577e-10
 -5.47383415e-11 -1.58162454e-11 -6.23258457e-11 -1.06504171e-11
 -7.19915060e-12 -1.58520657e-12 -7.67531153e-12 -1.29470964e-12
  1.46494623e-10  4.56081277e-11  1.70298296e-10  2.91826427e-11
  7.16339281e-12  2.71194848e-12  8.83920429e-12  1.52930510e-12
  1.31837040e-11  1.64527679e-11  8.79773822e-12  1.58097315e-11
  7.29740146e-12  8.87212696e-12  4.38257915e-12  7.78679447e-12
  9.99193703e-12  1.19999614e-11  4.49889514e-12  8.42280035e-12
  1.37800427e-11  1.60867882e-11  5.23078184e-12  9.65778771e-12
  2.85545417e-12  5.44508350e-13 -5.58053735e-13 -1.70587546e-13
  1.01621291e-14 -1.61525660e-13 -1.60711660e-12 -2.93474312e-13
 -3.77697318e+00]
supnorm grad right now is: 3.7769731808712232
Weights right now are: 
[-4.84388486e+00 -7.59618240e-01 -3.78746437e+00 -4.63247684e+00
  5.09845370e+00  6.50926559e-01  4.18640177e+00  3.91644859e+00
 -2.29857519e+00 -9.71556244e-01 -2.32420694e+00 -2.04213839e+00
  1.61403987e+00  5.09630467e-01  1.04157330e-02  8.82111751e-01
 -1.40735033e+00 -6.22003012e-01 -2.76035459e+00 -2.23978312e+00
 -2.10028881e+00 -1.10055535e+00 -2.49246480e+00 -1.82152749e+00
 -1.02439612e+00 -8.94276393e-01 -1.76116334e+00 -9.85936613e-01
  4.46915821e-01  1.45412138e+00  1.49916658e+00  5.13084484e-01
 -1.12447156e+00 -6.73339736e-01 -1.33128198e+00 -1.29394880e+00
 -2.50296176e+00 -1.43889214e+00 -1.25622055e+00 -1.08841690e+00
 -1.00732293e+00 -9.57927798e-01 -7.78319441e-02  1.61831055e-01
  4.98491625e-01  1.31240211e+00  1.35151551e-02  3.74647859e-01
 -1.47294025e+00 -4.37231631e-01 -4.43267543e-01 -1.59609282e+00
  4.60447462e-01  1.21259511e+00  4.92258368e-01  1.64175179e+00
  1.20505911e+00 -2.12711429e+00 -1.90027983e-01 -2.22899331e+00
  2.15790136e+00  1.06035982e+00 -4.05340028e-02  1.38516839e+00
  2.47205493e+01]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.208545624637
gradient value of function right now is: [ 1.46410263e-08  1.19837346e-09  1.46326941e-08  1.46344471e-08
 -1.46380172e-08 -1.19812703e-09 -1.46296867e-08 -1.46314393e-08
  2.37510894e-10  2.99166568e-11  2.32023849e-10  2.46652959e-10
  1.45237002e-09  1.83170565e-10  1.41906095e-09  1.50837318e-09
  2.52956484e-10  3.18634675e-11  2.47113793e-10  2.62693622e-10
  2.57048085e-10  3.23777354e-11  2.51110305e-10  2.66942231e-10
 -4.55778649e-11 -1.31466177e-11 -5.18711233e-11 -8.86364184e-12
 -6.24616402e-12 -1.39115293e-12 -6.67584926e-12 -1.12680397e-12
  1.21078256e-10  3.76177847e-11  1.40669176e-10  2.41039887e-11
  5.85639913e-12  2.21561102e-12  7.22481123e-12  1.24997060e-12
  1.08724883e-11  1.35629820e-11  7.21864073e-12  1.29794298e-11
  6.04570583e-12  7.34601313e-12  3.60544445e-12  6.40977842e-12
  8.25554477e-12  9.91007163e-12  3.69491458e-12  6.92244803e-12
  1.13852136e-11  1.32861374e-11  4.29720345e-12  7.93922408e-12
  2.35001716e-12  4.54564208e-13 -4.64373620e-13 -1.41842227e-13
  8.04401752e-15 -1.32862631e-13 -1.32438589e-12 -2.48196655e-13
 -1.16558591e+00]
supnorm grad right now is: 1.1655859131965702
Weights right now are: 
[-4.87612519e+00 -7.62245944e-01 -3.81968635e+00 -4.66470267e+00
  5.13069400e+00  6.53554261e-01  4.21862371e+00  3.94867439e+00
 -2.29909690e+00 -9.71621964e-01 -2.32471659e+00 -2.04268019e+00
  1.61085963e+00  5.09229349e-01  7.30848885e-03  8.78808895e-01
 -1.40790557e+00 -6.22072958e-01 -2.76089700e+00 -2.24035973e+00
 -2.10085317e+00 -1.10062645e+00 -2.49301612e+00 -1.82211358e+00
 -1.02429647e+00 -8.94247691e-01 -1.76104998e+00 -9.85917240e-01
  4.46929218e-01  1.45412434e+00  1.49918087e+00  5.13086896e-01
 -1.12473716e+00 -6.73422144e-01 -1.33159043e+00 -1.29400166e+00
 -2.50297466e+00 -1.43889702e+00 -1.25623645e+00 -1.08841965e+00
 -1.00734683e+00 -9.57957595e-01 -7.78477540e-02  1.61802621e-01
  4.98478362e-01  1.31238600e+00  1.35072689e-02  3.74633836e-01
 -1.47295839e+00 -4.37253400e-01 -4.43275634e-01 -1.59610798e+00
  4.60422432e-01  1.21256592e+00  4.92248959e-01  1.64173441e+00
  1.20505396e+00 -2.12711529e+00 -1.90026970e-01 -2.22899300e+00
  2.15790134e+00  1.06036011e+00 -4.05311020e-02  1.38516894e+00
  2.48969228e+01]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.257102863052
gradient value of function right now is: [ 1.24285372e-08  1.02442045e-09  1.24214768e-08  1.24229627e-08
 -1.24299639e-08 -1.02453224e-09 -1.24229028e-08 -1.24243889e-08
  2.02459164e-10  2.55022506e-11  1.97792381e-10  2.10254776e-10
  1.24482631e-09  1.56999695e-10  1.21634172e-09  1.29284340e-09
  2.15885705e-10  2.71945984e-11  2.10910444e-10  2.24198772e-10
  2.19275019e-10  2.76205672e-11  2.14221131e-10  2.27718174e-10
 -3.91962495e-11 -1.12994901e-11 -4.46012448e-11 -7.62154671e-12
 -5.55166566e-12 -1.24802220e-12 -5.94568788e-12 -1.00405277e-12
  1.03485028e-10  3.21258142e-11  1.20200929e-10  2.05968364e-11
  4.96039181e-12  1.87734194e-12  6.12015782e-12  1.05890977e-12
  9.27136264e-12  1.15637627e-11  6.14421003e-12  1.10495441e-11
  5.17515383e-12  6.28616533e-12  3.07566688e-12  5.46912811e-12
  7.04974166e-12  8.46071344e-12  3.14715517e-12  5.89767225e-12
  9.72154998e-12  1.13427817e-11  3.66085852e-12  6.76507605e-12
  2.00211091e-12  3.89094722e-13 -3.99337058e-13 -1.21373347e-13
  6.67190954e-15 -1.13118140e-13 -1.12978077e-12 -2.13466369e-13
 -2.16526151e-01]
supnorm grad right now is: 0.2165261513133689
Weights right now are: 
[-4.90304457e+00 -7.64456848e-01 -3.84659042e+00 -4.69160997e+00
  5.15761330e+00  6.55765158e-01  4.24552771e+00  3.97558161e+00
 -2.29953446e+00 -9.71677084e-01 -2.32514405e+00 -2.04313459e+00
  1.60817652e+00  5.08890922e-01  4.68681458e-03  8.76022290e-01
 -1.40837186e+00 -6.22131700e-01 -2.76135253e+00 -2.24084397e+00
 -2.10132689e+00 -1.10068612e+00 -2.49347891e+00 -1.82260554e+00
 -1.02421210e+00 -8.94223396e-01 -1.76095400e+00 -9.85900840e-01
  4.46940981e-01  1.45412697e+00  1.49919345e+00  5.13089020e-01
 -1.12496057e+00 -6.73491420e-01 -1.33184984e+00 -1.29404611e+00
 -2.50298541e+00 -1.43890108e+00 -1.25624971e+00 -1.08842194e+00
 -1.00736688e+00 -9.57982598e-01 -7.78609938e-02  1.61778791e-01
  4.98467190e-01  1.31237243e+00  1.35006486e-02  3.74622055e-01
 -1.47297363e+00 -4.37271686e-01 -4.43282416e-01 -1.59612070e+00
  4.60401413e-01  1.21254140e+00  4.92241069e-01  1.64171982e+00
  1.20504963e+00 -2.12711614e+00 -1.90026111e-01 -2.22899274e+00
  2.15790132e+00  1.06036036e+00 -4.05286623e-02  1.38516941e+00
  2.49851931e+01]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.227987090006
gradient value of function right now is: [ 1.08162111e-08  8.96989186e-10  1.08100756e-08  1.08113674e-08
 -1.08131415e-08 -8.96734928e-10 -1.08070078e-08 -1.08082991e-08
  1.76779249e-10  2.22662336e-11  1.72710712e-10  1.83587424e-10
  1.09211004e-09  1.37731297e-10  1.06715943e-09  1.13424497e-09
  1.88694457e-10  2.37679798e-11  1.84352574e-10  1.95961926e-10
  1.91588890e-10  2.41317285e-11  1.87179974e-10  1.98967472e-10
 -3.44793157e-11 -9.94705092e-12 -3.92414944e-11 -6.70591494e-12
 -5.01920397e-12 -1.13774436e-12 -5.38534102e-12 -9.09776295e-13
  9.05513050e-11  2.81278019e-11  1.05195688e-10  1.80262304e-11
  4.30747557e-12  1.63307070e-12  5.31756521e-12  9.20133549e-13
  8.09177402e-12  1.00941166e-11  5.37191542e-12  9.65915847e-12
  4.53119895e-12  5.50401961e-12  2.69428429e-12  4.79051176e-12
  6.15790683e-12  7.39117398e-12  2.75306067e-12  5.15818913e-12
  8.49008230e-12  9.90722207e-12  3.20284798e-12  5.91764404e-12
  1.74853628e-12  3.38506363e-13 -3.51642819e-13 -1.05911641e-13
  5.73809016e-15 -9.87280518e-14 -9.88106489e-13 -1.85247768e-13
 -9.17672173e-01]
supnorm grad right now is: 0.9176721732621963
Weights right now are: 
[-4.92625812e+00 -7.66375986e-01 -3.86979079e+00 -4.71481311e+00
  5.18082689e+00  6.57684300e-01  4.26872813e+00  3.99878480e+00
 -2.29991323e+00 -9.71724792e-01 -2.32551410e+00 -2.04352795e+00
  1.60584211e+00  5.08596517e-01  2.40577215e-03  8.73597826e-01
 -1.40877595e+00 -6.22182600e-01 -2.76174732e+00 -2.24126363e+00
 -2.10173726e+00 -1.10073781e+00 -2.49387983e+00 -1.82303170e+00
 -1.02413849e+00 -8.94202175e-01 -1.76087024e+00 -9.85886528e-01
  4.46951552e-01  1.45412936e+00  1.49920479e+00  5.13090934e-01
 -1.12515438e+00 -6.73551591e-01 -1.33207497e+00 -1.29408468e+00
 -2.50299466e+00 -1.43890458e+00 -1.25626113e+00 -1.08842392e+00
 -1.00738422e+00 -9.58004222e-01 -7.78724932e-02  1.61758116e-01
  4.98457493e-01  1.31236066e+00  1.34948866e-02  3.74611810e-01
 -1.47298682e+00 -4.37287516e-01 -4.43288308e-01 -1.59613174e+00
  4.60383216e-01  1.21252017e+00  4.92234214e-01  1.64170716e+00
  1.20504590e+00 -2.12711687e+00 -1.90025362e-01 -2.22899251e+00
  2.15790131e+00  1.06036057e+00 -4.05265504e-02  1.38516980e+00
  2.49120779e+01]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.240507115725
gradient value of function right now is: [ 9.54352663e-09  7.95692294e-10  9.53812074e-09  9.53925921e-09
 -9.54570935e-09 -7.95868718e-10 -9.54030234e-09 -9.54144104e-09
  1.56475468e-10  1.97102146e-11  1.52881219e-10  1.62503715e-10
  9.70840363e-10  1.22445420e-10  9.48703628e-10  1.00830894e-09
  1.67171412e-10  2.10583724e-11  1.63332258e-10  1.73612088e-10
  1.69674078e-10  2.13728637e-11  1.65777043e-10  1.76210842e-10
 -3.07372423e-11 -8.85776473e-12 -3.49719828e-11 -5.97637256e-12
 -4.58441652e-12 -1.04526421e-12 -4.92519920e-12 -8.32322085e-13
  8.03239916e-11  2.49175828e-11  9.32781950e-11  1.59840456e-11
  3.79155981e-12  1.43690967e-12  4.68002057e-12  8.09849927e-13
  7.16632712e-12  8.93753164e-12  4.74147911e-12  8.52916254e-12
  4.02539278e-12  4.88780331e-12  2.38229974e-12  4.23760795e-12
  5.46066275e-12  6.55239104e-12  2.43152277e-12  4.55807970e-12
  7.52910317e-12  8.78371241e-12  2.82943022e-12  5.23013719e-12
  1.54654712e-12  3.01696273e-13 -3.13314300e-13 -9.42296535e-14
  4.91972248e-15 -8.72530729e-14 -8.74776431e-13 -1.66405614e-13
  6.99444687e-01]
supnorm grad right now is: 0.699444687453159
Weights right now are: 
[-4.94659838e+00 -7.68067266e-01 -3.89011953e+00 -4.73514427e+00
  5.20116715e+00  6.59375579e-01  4.28905685e+00  4.01911595e+00
 -2.30024620e+00 -9.71766732e-01 -2.32583941e+00 -2.04387374e+00
  1.60378072e+00  5.08336541e-01  3.91431719e-04  8.71456897e-01
 -1.40913152e+00 -6.22227388e-01 -2.76209471e+00 -2.24163289e+00
 -2.10209821e+00 -1.10078328e+00 -2.49423248e+00 -1.82340656e+00
 -1.02407332e+00 -8.94183385e-01 -1.76079608e+00 -9.85873854e-01
  4.46961156e-01  1.45413154e+00  1.49921510e+00  5.13092676e-01
 -1.12532511e+00 -6.73604593e-01 -1.33227327e+00 -1.29411867e+00
 -2.50300275e+00 -1.43890765e+00 -1.25627112e+00 -1.08842565e+00
 -1.00739946e+00 -9.58023226e-01 -7.78826000e-02  1.61739941e-01
  4.98448944e-01  1.31235028e+00  1.34898128e-02  3.74602788e-01
 -1.47299843e+00 -4.37301446e-01 -4.43293488e-01 -1.59614145e+00
  4.60367206e-01  1.21250150e+00  4.92228188e-01  1.64169602e+00
  1.20504261e+00 -2.12711750e+00 -1.90024699e-01 -2.22899231e+00
  2.15790130e+00  1.06036075e+00 -4.05246906e-02  1.38517015e+00
  2.50813545e+01]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.249195871544
gradient value of function right now is: [ 8.57219922e-09  7.18176779e-10  8.56734896e-09  8.56837066e-09
 -8.57673374e-09 -7.18554461e-10 -8.57188096e-09 -8.57290319e-09
  1.40957301e-10  1.77542191e-11  1.37723048e-10  1.46388389e-10
  8.77842147e-10  1.10708681e-10  8.57848341e-10  9.11725965e-10
  1.50710149e-10  1.89834106e-11  1.47252822e-10  1.56517345e-10
  1.52919034e-10  1.92609451e-11  1.49410674e-10  1.58811040e-10
 -2.78487640e-11 -8.03355313e-12 -3.16940441e-11 -5.41652397e-12
 -4.23896806e-12 -9.72525112e-13 -4.56040047e-12 -7.70898638e-13
  7.24741101e-11  2.25034222e-11  8.41840513e-11  1.44265282e-11
  3.40040396e-12  1.29107167e-12  4.19972440e-12  7.26819729e-13
  6.45122989e-12  8.04776388e-12  4.27924372e-12  7.69600758e-12
  3.63289014e-12  4.41176400e-12  2.15338475e-12  3.82980227e-12
  4.91869015e-12  5.90325651e-12  2.19527532e-12  4.11421059e-12
  6.78057614e-12  7.91204441e-12  2.55471892e-12  4.72125275e-12
  1.39378625e-12  2.70128731e-13 -2.84203862e-13 -8.46688093e-14
  4.39612439e-15 -7.85700858e-14 -7.89271347e-13 -1.48294215e-13
 -5.21165655e-01]
supnorm grad right now is: 0.5211656554837529
Weights right now are: 
[-4.96469579e+00 -7.69579761e-01 -3.90820668e+00 -4.75323359e+00
  5.21926454e+00  6.60888072e-01  4.30714400e+00  4.03720525e+00
 -2.30054330e+00 -9.71804153e-01 -2.32612969e+00 -2.04418228e+00
  1.60193397e+00  5.08103641e-01 -1.41322969e-03  8.69538872e-01
 -1.40944905e+00 -6.22267384e-01 -2.76240495e+00 -2.24196265e+00
 -2.10242045e+00 -1.10082386e+00 -2.49454732e+00 -1.82374122e+00
 -1.02401480e+00 -8.94166507e-01 -1.76072948e+00 -9.85862473e-01
  4.46969974e-01  1.45413356e+00  1.49922458e+00  5.13094279e-01
 -1.12547773e+00 -6.73651977e-01 -1.33245055e+00 -1.29414904e+00
 -2.50300994e+00 -1.43891038e+00 -1.25627999e+00 -1.08842718e+00
 -1.00741306e+00 -9.58040186e-01 -7.78916206e-02  1.61723723e-01
  4.98441296e-01  1.31234099e+00  1.34852771e-02  3.74594724e-01
 -1.47300880e+00 -4.37313883e-01 -4.43298115e-01 -1.59615011e+00
  4.60352916e-01  1.21248483e+00  4.92222804e-01  1.64168607e+00
  1.20503967e+00 -2.12711807e+00 -1.90024102e-01 -2.22899213e+00
  2.15790129e+00  1.06036092e+00 -4.05230294e-02  1.38517047e+00
  2.49303917e+01]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.153628899256
gradient value of function right now is: [ 7.77980343e-09  6.54667682e-10  7.77540598e-09  7.77633249e-09
 -7.78202675e-09 -6.54848335e-10 -7.77762818e-09 -7.77855492e-09
  1.28226042e-10  1.61493939e-11  1.25286919e-10  1.33167077e-10
  8.01326679e-10  1.01051543e-10  7.83094657e-10  8.32260301e-10
  1.37193100e-10  1.72794518e-11  1.34049083e-10  1.42479970e-10
  1.39170215e-10  1.75278510e-11  1.35980552e-10  1.44533008e-10
 -2.54694651e-11 -7.35348632e-12 -2.89928842e-11 -4.95502200e-12
 -3.94850993e-12 -9.10852731e-13 -4.25314085e-12 -7.19137689e-13
  6.60252057e-11  2.05166362e-11  7.67097757e-11  1.31459231e-11
  3.07976309e-12  1.17126215e-12  3.80577107e-12  6.58679821e-13
  5.86505430e-12  7.31655012e-12  3.89942975e-12  7.00956959e-12
  3.31062335e-12  4.02006802e-12  1.96506465e-12  3.49345927e-12
  4.47436521e-12  5.36987156e-12  2.00109598e-12  3.74819380e-12
  6.16740073e-12  7.19670301e-12  2.32903109e-12  4.30193590e-12
  1.26711129e-12  2.44246075e-13 -2.60023098e-13 -7.68360100e-14
  3.94047634e-15 -7.14502632e-14 -7.18613687e-13 -1.33524990e-13
 -1.66447120e+00]
supnorm grad right now is: 1.6644711978865696
Weights right now are: 
[-4.98106339e+00 -7.70953965e-01 -3.92456503e+00 -4.76959389e+00
  5.23563221e+00  6.62262282e-01  4.32350241e+00  4.05356562e+00
 -2.30081266e+00 -9.71838083e-01 -2.32639288e+00 -2.04446202e+00
  1.60025337e+00  5.07891675e-01 -3.05558807e-03  8.67793395e-01
 -1.40973714e+00 -6.22303676e-01 -2.76268645e+00 -2.24226185e+00
 -2.10271274e+00 -1.10086068e+00 -2.49483292e+00 -1.82404477e+00
 -1.02396141e+00 -8.94151123e-01 -1.76066874e+00 -9.85852089e-01
  4.46978182e-01  1.45413544e+00  1.49923341e+00  5.13095772e-01
 -1.12561636e+00 -6.73694969e-01 -1.33261151e+00 -1.29417664e+00
 -2.50301642e+00 -1.43891283e+00 -1.25628799e+00 -1.08842857e+00
 -1.00742539e+00 -9.58055569e-01 -7.78997684e-02  1.61709055e-01
  4.98434340e-01  1.31233255e+00  1.34811744e-02  3.74587420e-01
 -1.47301821e+00 -4.37325176e-01 -4.43302298e-01 -1.59615796e+00
  4.60339938e-01  1.21246969e+00  4.92217936e-01  1.64167707e+00
  1.20503701e+00 -2.12711859e+00 -1.90023558e-01 -2.22899197e+00
  2.15790128e+00  1.06036107e+00 -4.05215219e-02  1.38517075e+00
  2.48481795e+01]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.068881414183
gradient value of function right now is: [ 7.12101905e-09  6.01631895e-10  7.11699778e-09  7.11784520e-09
 -7.12072141e-09 -6.01605128e-10 -7.11670035e-09 -7.11754772e-09
  1.17607417e-10  1.48113401e-11  1.14914302e-10  1.22139832e-10
  7.37304875e-10  9.29739720e-11  7.20546134e-10  7.65770657e-10
  1.25910123e-10  1.58576184e-11  1.23027471e-10  1.30762788e-10
  1.27697424e-10  1.60821593e-11  1.24773558e-10  1.32618730e-10
 -2.34764392e-11 -6.78222815e-12 -2.67285037e-11 -4.56812794e-12
 -3.69987583e-12 -8.57478815e-13 -3.98951437e-12 -6.74703173e-13
  6.06407709e-11  1.88535266e-11  7.04644918e-11  1.20758819e-11
  2.81313601e-12  1.07132643e-12  3.47783425e-12  6.01962249e-13
  5.37667323e-12  6.70836158e-12  3.58017708e-12  6.43477269e-12
  3.04148840e-12  3.69345421e-12  1.80654824e-12  3.21133371e-12
  4.10386427e-12  4.92581915e-12  1.83789900e-12  3.44196658e-12
  5.65609544e-12  6.60091856e-12  2.13934203e-12  3.95095296e-12
  1.16237500e-12  2.23295235e-13 -2.39864032e-13 -7.04097367e-14
  3.56449315e-15 -6.55139592e-14 -6.59907208e-13 -1.21881733e-13
 -2.23156768e+00]
supnorm grad right now is: 2.231567675504366
Weights right now are: 
[-4.99587200e+00 -7.72202536e-01 -3.93936528e+00 -4.78439590e+00
  5.25044082e+00  6.63510854e-01  4.33830266e+00  4.06836763e+00
 -2.30105695e+00 -9.71868851e-01 -2.32663157e+00 -2.04471573e+00
  1.59872424e+00  5.07698834e-01 -4.54995367e-03  8.66205226e-01
 -1.40999860e+00 -6.22336607e-01 -2.76294192e+00 -2.24253338e+00
 -2.10297794e+00 -1.10089408e+00 -2.49509204e+00 -1.82432019e+00
 -1.02391275e+00 -8.94137084e-01 -1.76061336e+00 -9.85842625e-01
  4.46985790e-01  1.45413720e+00  1.49924161e+00  5.13097159e-01
 -1.12574225e+00 -6.73734059e-01 -1.33275775e+00 -1.29420170e+00
 -2.50302227e+00 -1.43891506e+00 -1.25629522e+00 -1.08842982e+00
 -1.00743657e+00 -9.58069513e-01 -7.79071836e-02  1.61695718e-01
  4.98428024e-01  1.31232488e+00  1.34774351e-02  3.74580769e-01
 -1.47302674e+00 -4.37335414e-01 -4.43306104e-01 -1.59616509e+00
  4.60328179e-01  1.21245597e+00  4.92213505e-01  1.64166888e+00
  1.20503460e+00 -2.12711905e+00 -1.90023061e-01 -2.22899183e+00
  2.15790128e+00  1.06036121e+00 -4.05201523e-02  1.38517101e+00
  2.47714523e+01]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.251015653554
gradient value of function right now is: [ 6.53122676e-09  5.53814349e-10  6.52754246e-09  6.52831904e-09
 -6.52922394e-09 -5.53647228e-10 -6.52554071e-09 -6.52631706e-09
  1.08051079e-10  1.36094118e-11  1.05580800e-10  1.12216551e-10
  6.79493495e-10  8.56936154e-11  6.64073892e-10  7.05735606e-10
  1.15745415e-10  1.45791304e-11  1.13099763e-10  1.20207762e-10
  1.17364940e-10  1.47826129e-11  1.14682013e-10  1.21889503e-10
 -2.16850815e-11 -6.25402838e-12 -2.46775576e-11 -4.21746297e-12
 -3.47261469e-12 -8.06871224e-13 -3.74661028e-12 -6.33738957e-13
  5.58051718e-11  1.73172330e-11  6.48103823e-11  1.11063487e-11
  2.57237969e-12  9.78555787e-13  3.17902959e-12  5.50227804e-13
  4.94347109e-12  6.16636210e-12  3.27565444e-12  5.89162110e-12
  2.80283664e-12  3.40246607e-12  1.65501495e-12  2.94397310e-12
  3.77731307e-12  4.53260480e-12  1.68245631e-12  3.15360666e-12
  5.20679879e-12  6.07507722e-12  1.95887233e-12  3.62058852e-12
  1.06734516e-12  2.07817085e-13 -2.21404644e-13 -6.52426263e-14
  3.15743389e-15 -6.00920891e-14 -6.06221769e-13 -1.14741293e-13
  4.61657712e-01]
supnorm grad right now is: 0.46165771200631844
Weights right now are: 
[-5.00950786e+00 -7.73356640e-01 -3.95299344e+00 -4.79802568e+00
  5.26407667e+00  6.64664957e-01  4.35193081e+00  4.08199741e+00
 -2.30128235e+00 -9.71897243e-01 -2.32685182e+00 -2.04494982e+00
  1.59730894e+00  5.07520336e-01 -5.93311896e-03  8.64735270e-01
 -1.41023998e+00 -6.22367013e-01 -2.76317778e+00 -2.24278407e+00
 -2.10322272e+00 -1.10092492e+00 -2.49533122e+00 -1.82457440e+00
 -1.02386762e+00 -8.94124069e-01 -1.76056201e+00 -9.85833846e-01
  4.46992961e-01  1.45413886e+00  1.49924934e+00  5.13098467e-01
 -1.12585859e+00 -6.73770160e-01 -1.33289285e+00 -1.29422485e+00
 -2.50302765e+00 -1.43891710e+00 -1.25630187e+00 -1.08843097e+00
 -1.00744688e+00 -9.58082382e-01 -7.79140071e-02  1.61683429e-01
  4.98422183e-01  1.31231778e+00  1.34739900e-02  3.74574633e-01
 -1.47303462e+00 -4.37344870e-01 -4.43309610e-01 -1.59617167e+00
  4.60317320e-01  1.21244329e+00  4.92209424e-01  1.64166133e+00
  1.20503237e+00 -2.12711949e+00 -1.90022600e-01 -2.22899169e+00
  2.15790127e+00  1.06036133e+00 -4.05188863e-02  1.38517125e+00
  2.50206858e+01]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.131835966902
gradient value of function right now is: [ 6.07562957e-09  5.16965883e-10  6.07220471e-09  6.07292670e-09
 -6.07731751e-09 -5.17108920e-10 -6.07389171e-09 -6.07461390e-09
  1.00738736e-10  1.26870096e-11  9.84368293e-11  1.04622378e-10
  6.35179026e-10  8.00964791e-11  6.20772772e-10  6.59710248e-10
  1.07969222e-10  1.35981714e-11  1.05502601e-10  1.12131848e-10
  1.09454786e-10  1.37847699e-11  1.06953970e-10  1.13674468e-10
 -2.02955204e-11 -5.86267723e-12 -2.31060435e-11 -3.94922798e-12
 -3.29265117e-12 -7.68551388e-13 -3.55612684e-12 -6.01633409e-13
  5.20802770e-11  1.61864073e-11  6.05104018e-11  1.03705185e-11
  2.39072538e-12  9.11445016e-13  2.95659993e-12  5.11820126e-13
  4.60431463e-12  5.74517347e-12  3.06301307e-12  5.50714249e-12
  2.61509360e-12  3.17528632e-12  1.54927552e-12  2.75505181e-12
  3.51894782e-12  4.22376158e-12  1.57367700e-12  2.94825851e-12
  4.84967020e-12  5.65991940e-12  1.83232732e-12  3.38509428e-12
  9.95564319e-13  1.91468270e-13 -2.07489459e-13 -6.04455245e-14
  2.94181474e-15 -5.60147785e-14 -5.66080575e-13 -1.04840046e-13
 -1.82475781e+00]
supnorm grad right now is: 1.8247578140612761
Weights right now are: 
[-5.02207071e+00 -7.74423717e-01 -3.96554921e+00 -4.81058294e+00
  5.27663958e+00  6.65732038e-01  4.36448664e+00  4.09455473e+00
 -2.30149041e+00 -9.71923449e-01 -2.32705512e+00 -2.04516590e+00
  1.59599878e+00  5.07355106e-01 -7.21356489e-03  8.63374502e-01
 -1.41046291e+00 -6.22395094e-01 -2.76339562e+00 -2.24301560e+00
 -2.10344875e+00 -1.10095339e+00 -2.49555209e+00 -1.82480915e+00
 -1.02382578e+00 -8.94111998e-01 -1.76051439e+00 -9.85825708e-01
  4.46999706e-01  1.45414043e+00  1.49925662e+00  5.13099699e-01
 -1.12596611e+00 -6.73803532e-01 -1.33301773e+00 -1.29424625e+00
 -2.50303259e+00 -1.43891899e+00 -1.25630798e+00 -1.08843203e+00
 -1.00745640e+00 -9.58094257e-01 -7.79203160e-02  1.61672080e-01
  4.98416782e-01  1.31231123e+00  1.34708006e-02  3.74568959e-01
 -1.47304189e+00 -4.37353600e-01 -4.43312851e-01 -1.59617775e+00
  4.60307295e-01  1.21243159e+00  4.92205651e-01  1.64165435e+00
  1.20503031e+00 -2.12711989e+00 -1.90022172e-01 -2.22899156e+00
  2.15790126e+00  1.06036145e+00 -4.05177179e-02  1.38517147e+00
  2.47877487e+01]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.245667867792
gradient value of function right now is: [ 5.64060861e-09  4.81463409e-10  5.63743189e-09  5.63810170e-09
 -5.63821335e-09 -4.81264202e-10 -5.63503787e-09 -5.63570742e-09
  9.36391595e-11  1.17939336e-11  9.15024034e-11  9.72500422e-11
  5.92019982e-10  7.46605941e-11  5.78611117e-10  6.14890272e-10
  1.00408167e-10  1.26470068e-11  9.81174114e-11  1.04280291e-10
  1.01775470e-10  1.28187879e-11  9.94533083e-11  1.05700132e-10
 -1.89542419e-11 -5.46739208e-12 -2.15707585e-11 -3.68659653e-12
 -3.11688080e-12 -7.28969787e-13 -3.36779957e-12 -5.69849661e-13
  4.84785961e-11  1.50434482e-11  5.63009795e-11  9.64826396e-12
  2.21264514e-12  8.42907541e-13  2.73571387e-12  4.73538749e-13
  4.28215367e-12  5.34183907e-12  2.83800098e-12  5.10460282e-12
  2.43700429e-12  2.95806314e-12  1.43709850e-12  2.55654131e-12
  3.27571611e-12  3.93074741e-12  1.45860109e-12  2.73417917e-12
  4.51512593e-12  5.26825875e-12  1.69868386e-12  3.13983833e-12
  9.24713193e-13  1.80059109e-13 -1.93632903e-13 -5.66273470e-14
  2.64076257e-15 -5.20118591e-14 -5.26088833e-13 -9.95970268e-14
  5.90896734e-01]
supnorm grad right now is: 0.5908967336707167
Weights right now are: 
[-5.03376384e+00 -7.75420208e-01 -3.97723575e+00 -4.82227087e+00
  5.28833274e+00  6.66728532e-01  4.37617321e+00  4.10624269e+00
 -2.30168441e+00 -9.71947884e-01 -2.32724469e+00 -2.04536738e+00
  1.59477391e+00  5.07200634e-01 -8.41067964e-03  8.62102315e-01
 -1.41067089e+00 -6.22421289e-01 -2.76359885e+00 -2.24323159e+00
 -2.10365957e+00 -1.10097994e+00 -2.49575809e+00 -1.82502810e+00
 -1.02378660e+00 -8.94100693e-01 -1.76046979e+00 -9.85818086e-01
  4.47006106e-01  1.45414193e+00  1.49926354e+00  5.13100868e-01
 -1.12606648e+00 -6.73834687e-01 -1.33313431e+00 -1.29426623e+00
 -2.50303719e+00 -1.43892074e+00 -1.25631366e+00 -1.08843301e+00
 -1.00746527e+00 -9.58105328e-01 -7.79261944e-02  1.61661500e-01
  4.98411738e-01  1.31230510e+00  1.34678257e-02  3.74563663e-01
 -1.47304868e+00 -4.37361743e-01 -4.43315872e-01 -1.59618342e+00
  4.60297944e-01  1.21242068e+00  4.92202132e-01  1.64164785e+00
  1.20502839e+00 -2.12712026e+00 -1.90021771e-01 -2.22899145e+00
  2.15790126e+00  1.06036155e+00 -4.05166274e-02  1.38517167e+00
  2.50590460e+01]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.255583255139
gradient value of function right now is: [ 5.28759241e-09  4.52691999e-10  5.28461655e-09  5.28524409e-09
 -5.28419009e-09 -4.52404014e-10 -5.28121607e-09 -5.28184322e-09
  8.79108229e-11  1.10717873e-11  8.59061268e-11  9.13010154e-11
  5.57144466e-10  7.02584787e-11  5.44534162e-10  5.78668887e-10
  9.43077480e-11  1.18779165e-11  9.21576138e-11  9.79448354e-11
  9.55774212e-11  1.20374267e-11  9.33981372e-11  9.92632995e-11
 -1.78610556e-11 -5.15553795e-12 -2.03303515e-11 -3.47467361e-12
 -2.97130870e-12 -6.97216503e-13 -3.21291881e-12 -5.43725137e-13
  4.55581488e-11  1.41459165e-11  5.29185794e-11  9.06876335e-12
  2.07034232e-12  7.89725271e-13  2.56086941e-12  4.43292981e-13
  4.01797856e-12  5.01243868e-12  2.66781740e-12  4.79687119e-12
  2.29046252e-12  2.78009653e-12  1.35228479e-12  2.40497605e-12
  3.07483685e-12  3.68973563e-12  1.37142910e-12  2.56975552e-12
  4.23798016e-12  4.94507286e-12  1.59731995e-12  2.95140924e-12
  8.67765562e-13  1.68303931e-13 -1.82525354e-13 -5.30623795e-14
  2.44875655e-15 -4.88127154e-14 -4.94235736e-13 -9.27541465e-14
 -2.97604142e-01]
supnorm grad right now is: 0.2976041424330312
Weights right now are: 
[-5.04469276e+00 -7.76354453e-01 -3.98815851e+00 -4.83319493e+00
  5.29926168e+00  6.67662779e-01  4.38709599e+00  4.11716677e+00
 -2.30186602e+00 -9.71970758e-01 -2.32742216e+00 -2.04555599e+00
  1.59362434e+00  5.07055658e-01 -9.53421925e-03  8.60908336e-01
 -1.41086567e+00 -6.22445824e-01 -2.76378919e+00 -2.24343389e+00
 -2.10385698e+00 -1.10100480e+00 -2.49595100e+00 -1.82523312e+00
 -1.02374977e+00 -8.94090068e-01 -1.76042788e+00 -9.85810922e-01
  4.47012197e-01  1.45414336e+00  1.49927012e+00  5.13101982e-01
 -1.12616056e+00 -6.73863878e-01 -1.33324356e+00 -1.29428496e+00
 -2.50304147e+00 -1.43892237e+00 -1.25631895e+00 -1.08843393e+00
 -1.00747358e+00 -9.58115690e-01 -7.79316932e-02  1.61651603e-01
  4.98407007e-01  1.31229936e+00  1.34650398e-02  3.74558703e-01
 -1.47305503e+00 -4.37369369e-01 -4.43318700e-01 -1.59618872e+00
  4.60289187e-01  1.21241046e+00  4.92198839e-01  1.64164175e+00
  1.20502660e+00 -2.12712061e+00 -1.90021395e-01 -2.22899134e+00
  2.15790125e+00  1.06036166e+00 -4.05156056e-02  1.38517187e+00
  2.49362039e+01]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.248500740105
gradient value of function right now is: [ 4.96390078e-09  4.26173494e-10  4.96110915e-09  4.96169793e-09
 -4.96306871e-09 -4.26107074e-10 -4.96027744e-09 -4.96086614e-09
  8.26674299e-11  1.04118326e-11  8.07841621e-11  8.58560074e-11
  5.25124832e-10  6.62231443e-11  5.13251067e-10  5.45415908e-10
  8.87206017e-11  1.11746725e-11  8.66998440e-11  9.21428497e-11
  8.98980895e-11  1.13225860e-11  8.78503239e-11  9.33655848e-11
 -1.68599887e-11 -4.86433496e-12 -1.91883417e-11 -3.27958586e-12
 -2.83605651e-12 -6.66955878e-13 -3.06820809e-12 -5.19308722e-13
  4.28888650e-11  1.33093492e-11  4.98093200e-11  8.53617113e-12
  1.94021922e-12  7.40090665e-13  2.39988111e-12  4.15456512e-13
  3.77863388e-12  4.71409574e-12  2.50478692e-12  4.50558461e-12
  2.15762990e-12  2.61874774e-12  1.27088148e-12  2.26111203e-12
  2.89352958e-12  3.47219224e-12  1.28809553e-12  2.41478099e-12
  3.98815627e-12  4.65356637e-12  1.50047139e-12  2.77367920e-12
  8.16149910e-13  1.58747395e-13 -1.72330111e-13 -5.00190537e-14
  2.25776536e-15 -4.58473095e-14 -4.65006344e-13 -8.78325806e-14
  5.22745540e-01]
supnorm grad right now is: 0.5227455397555258
Weights right now are: 
[-5.05495039e+00 -7.77233877e-01 -3.99841037e+00 -4.84344801e+00
  5.30951932e+00  6.68542204e-01  4.39734786e+00  4.12741985e+00
 -2.30203674e+00 -9.71992260e-01 -2.32758899e+00 -2.04573330e+00
  1.59254118e+00  5.06919060e-01 -1.05928806e-02  8.59783319e-01
 -1.41104885e+00 -6.22468897e-01 -2.76396820e+00 -2.24362414e+00
 -2.10404261e+00 -1.10102818e+00 -2.49613240e+00 -1.82542591e+00
 -1.02371502e+00 -8.94080039e-01 -1.76038833e+00 -9.85804162e-01
  4.47018009e-01  1.45414472e+00  1.49927641e+00  5.13103046e-01
 -1.12624908e+00 -6.73891359e-01 -1.33334638e+00 -1.29430258e+00
 -2.50304549e+00 -1.43892390e+00 -1.25632392e+00 -1.08843479e+00
 -1.00748138e+00 -9.58125427e-01 -7.79368678e-02  1.61642292e-01
  4.98402556e-01  1.31229396e+00  1.34624156e-02  3.74554033e-01
 -1.47306100e+00 -4.37376538e-01 -4.43321360e-01 -1.59619371e+00
  4.60280955e-01  1.21240085e+00  4.92195739e-01  1.64163602e+00
  1.20502491e+00 -2.12712094e+00 -1.90021039e-01 -2.22899123e+00
  2.15790125e+00  1.06036175e+00 -4.05146446e-02  1.38517205e+00
  2.49914011e+01]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16003.743938707474
gradient value of function right now is: [ 4.65980214e-09  4.01107881e-10  4.65718370e-09  4.65773604e-09
 -4.65955400e-09 -4.01086580e-10 -4.65693571e-09 -4.65748801e-09
  7.76995666e-11  9.78751551e-12  7.59321639e-11  8.06974346e-11
  4.94718650e-10  6.23971340e-11  4.83549348e-10  5.13840475e-10
  8.34221411e-11  1.05087892e-11  8.15249548e-11  8.66409823e-11
  8.45162812e-11  1.06462503e-11  8.25940214e-11  8.77771791e-11
 -1.59146548e-11 -4.58101103e-12 -1.81012751e-11 -3.09355627e-12
 -2.70729047e-12 -6.37106991e-13 -2.92933875e-12 -4.95859011e-13
  4.03660771e-11  1.24950321e-11  4.68463421e-11  8.02753878e-12
  1.81607383e-12  6.91427186e-13  2.24496438e-12  3.88587023e-13
  3.55530611e-12  4.43287797e-12  2.34225805e-12  4.21532379e-12
  2.03393606e-12  2.46704980e-12  1.18961558e-12  2.11751089e-12
  2.72575579e-12  3.26891329e-12  1.20495420e-12  2.26045483e-12
  3.75797468e-12  4.38269701e-12  1.40397240e-12  2.59695944e-12
  7.65704435e-13  1.51557959e-13 -1.62354928e-13 -4.74882875e-14
  2.02481889e-15 -4.30352323e-14 -4.36467944e-13 -8.50075964e-14
  3.86342906e+00]
supnorm grad right now is: 3.8634290620672282
Weights right now are: 
[-5.06459199e+00 -7.78062758e-01 -4.00804655e+00 -4.85308533e+00
  5.31916090e+00  6.69371084e-01  4.40698402e+00  4.13705716e+00
 -2.30219744e+00 -9.72012499e-01 -2.32774603e+00 -2.04590020e+00
  1.59151932e+00  5.06790202e-01 -1.15916332e-02  8.58721980e-01
 -1.41122135e+00 -6.22490622e-01 -2.76413677e+00 -2.24380329e+00
 -2.10421738e+00 -1.10105020e+00 -2.49630319e+00 -1.82560743e+00
 -1.02368219e+00 -8.94070563e-01 -1.76035096e+00 -9.85797776e-01
  4.47023557e-01  1.45414603e+00  1.49928241e+00  5.13104062e-01
 -1.12633248e+00 -6.73917256e-01 -1.33344326e+00 -1.29431918e+00
 -2.50304925e+00 -1.43892534e+00 -1.25632858e+00 -1.08843559e+00
 -1.00748872e+00 -9.58134587e-01 -7.79417472e-02  1.61633524e-01
  4.98398361e-01  1.31228886e+00  1.34599387e-02  3.74549631e-01
 -1.47306663e+00 -4.37383286e-01 -4.43323869e-01 -1.59619841e+00
  4.60273206e-01  1.21239181e+00  4.92192817e-01  1.64163063e+00
  1.20502332e+00 -2.12712125e+00 -1.90020704e-01 -2.22899114e+00
  2.15790124e+00  1.06036184e+00 -4.05137404e-02  1.38517222e+00
  2.52501814e+01]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.25673430814
gradient value of function right now is: [ 4.43390961e-09  3.82653752e-10  4.43141917e-09  4.43194455e-09
 -4.43058706e-09 -3.82371970e-10 -4.42809837e-09 -4.42862338e-09
  7.40184456e-11  9.32206265e-12  7.23345633e-11  7.68739302e-11
  4.72193015e-10  5.95453699e-11  4.61531266e-10  4.90442132e-10
  7.94982565e-11  1.00126057e-11  7.76900765e-11  8.25653126e-11
  8.05334214e-11  1.01426457e-11  7.87015340e-11  8.36402678e-11
 -1.51986754e-11 -4.38673474e-12 -1.72994572e-11 -2.95672137e-12
 -2.60784197e-12 -6.16259310e-13 -2.82444049e-12 -4.78155740e-13
  3.84730520e-11  1.19421172e-11  4.46844433e-11  7.65769975e-12
  1.72621584e-12  6.59459327e-13  2.13625748e-12  3.69824947e-13
  3.38128439e-12  4.21824896e-12  2.24387857e-12  4.03501067e-12
  1.93653546e-12  2.35005576e-12  1.14055041e-12  2.02873144e-12
  2.59142047e-12  3.10947651e-12  1.15443363e-12  2.16349690e-12
  3.57168066e-12  4.16755123e-12  1.34508593e-12  2.48569529e-12
  7.30161645e-13  1.41917398e-13 -1.55384458e-13 -4.48102718e-14
  1.95353952e-15 -4.10230436e-14 -4.16740748e-13 -7.85321099e-14
  2.25402385e-01]
supnorm grad right now is: 0.22540238520757447
Weights right now are: 
[-5.07372557e+00 -7.78850017e-01 -4.01717500e+00 -4.86221486e+00
  5.32829447e+00  6.70158341e-01  4.41611246e+00  4.14618667e+00
 -2.30234988e+00 -9.72031697e-01 -2.32789500e+00 -2.04605852e+00
  1.59054794e+00  5.06667712e-01 -1.25410655e-02  8.57713064e-01
 -1.41138505e+00 -6.22511239e-01 -2.76429674e+00 -2.24397330e+00
 -2.10438322e+00 -1.10107108e+00 -2.49646525e+00 -1.82577966e+00
 -1.02365095e+00 -8.94061539e-01 -1.76031540e+00 -9.85791697e-01
  4.47028888e-01  1.45414729e+00  1.49928818e+00  5.13105040e-01
 -1.12641167e+00 -6.73941856e-01 -1.33353525e+00 -1.29433495e+00
 -2.50305282e+00 -1.43892670e+00 -1.25633299e+00 -1.08843636e+00
 -1.00749569e+00 -9.58143274e-01 -7.79463745e-02  1.61625202e-01
  4.98394377e-01  1.31228403e+00  1.34575879e-02  3.74545449e-01
 -1.47307196e+00 -4.37389687e-01 -4.43326249e-01 -1.59620287e+00
  4.60265855e-01  1.21238323e+00  4.92190044e-01  1.64162550e+00
  1.20502182e+00 -2.12712154e+00 -1.90020384e-01 -2.22899104e+00
  2.15790124e+00  1.06036192e+00 -4.05128816e-02  1.38517238e+00
  2.50322257e+01]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16002.862697856894
gradient value of function right now is: [ 4.24883265e-09  3.67606476e-10  4.24644668e-09  4.24695004e-09
 -4.24586149e-09 -3.67353622e-10 -4.24347711e-09 -4.24398013e-09
  7.10430238e-11  8.94461110e-12  6.94256695e-11  7.37829455e-11
  4.53974602e-10  5.72311749e-11  4.43717159e-10  4.71514899e-10
  7.63285036e-11  9.61046951e-12  7.45911755e-11  7.92724392e-11
  7.73125098e-11  9.73401521e-12  7.55526179e-11  8.02942441e-11
 -1.46119323e-11 -4.23662011e-12 -1.66519115e-11 -2.84652882e-12
 -2.52517968e-12 -5.99979168e-13 -2.73836085e-12 -4.63648982e-13
  3.69319185e-11  1.15175036e-11  4.29510508e-11  7.36220549e-12
  1.65474590e-12  6.35425961e-13  2.05123019e-12  3.55225142e-13
  3.23668160e-12  4.04172457e-12  2.17376706e-12  3.90427111e-12
  1.85526506e-12  2.25339626e-12  1.10567755e-12  1.96461401e-12
  2.47878371e-12  2.97701840e-12  1.11831063e-12  2.09259347e-12
  3.41472919e-12  3.98773975e-12  1.30282594e-12  2.40413936e-12
  7.02117683e-13  1.31938887e-13 -1.49897507e-13 -4.22183049e-14
  1.94621598e-15 -3.94095276e-14 -4.01313329e-13 -7.09891849e-14
 -5.86620763e+00]
supnorm grad right now is: 5.866207626121277
Weights right now are: 
[-5.08237937e+00 -7.79597756e-01 -4.02582394e+00 -4.87086482e+00
  5.33694825e+00  6.70906079e-01  4.42476139e+00  4.15483663e+00
 -2.30249449e+00 -9.72049909e-01 -2.32803632e+00 -2.04620871e+00
  1.58962456e+00  5.06551273e-01 -1.34436028e-02  8.56753996e-01
 -1.41154040e+00 -6.22530804e-01 -2.76444855e+00 -2.24413464e+00
 -2.10454057e+00 -1.10109090e+00 -2.49661903e+00 -1.82594308e+00
 -1.02362122e+00 -8.94052953e-01 -1.76028155e+00 -9.85785911e-01
  4.47034012e-01  1.45414850e+00  1.49929373e+00  5.13105980e-01
 -1.12648686e+00 -6.73965208e-01 -1.33362259e+00 -1.29434992e+00
 -2.50305618e+00 -1.43892799e+00 -1.25633716e+00 -1.08843708e+00
 -1.00750229e+00 -9.58151512e-01 -7.79507560e-02  1.61617313e-01
  4.98390593e-01  1.31227944e+00  1.34553599e-02  3.74541481e-01
 -1.47307702e+00 -4.37395761e-01 -4.43328505e-01 -1.59620710e+00
  4.60258878e-01  1.21237509e+00  4.92187416e-01  1.64162064e+00
  1.20502039e+00 -2.12712181e+00 -1.90020080e-01 -2.22899096e+00
  2.15790123e+00  1.06036200e+00 -4.05120670e-02  1.38517253e+00
  2.44834268e+01]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.229089013019
gradient value of function right now is: [ 4.01176328e-09  3.47855517e-10  4.00951238e-09  4.00998732e-09
 -4.02035751e-09 -3.48594178e-10 -4.01810193e-09 -4.01857786e-09
  6.72318258e-11  8.46706085e-12  6.57043451e-11  6.98259528e-11
  4.30490699e-10  5.42847052e-11  4.20783347e-10  4.47131023e-10
  7.22603482e-11  9.10071801e-12  7.06189616e-11  7.50486587e-11
  7.31698676e-11  9.21491676e-12  7.15076285e-11  7.59931235e-11
 -1.38856042e-11 -4.00952710e-12 -1.58065058e-11 -2.70190099e-12
 -2.42338981e-12 -5.75144361e-13 -2.62724209e-12 -4.44896785e-13
  3.50024492e-11  1.08674678e-11  4.06554935e-11  6.96819578e-12
  1.55971879e-12  5.96512881e-13  1.93085935e-12  3.34338774e-13
  3.06971898e-12  3.82956025e-12  2.03824381e-12  3.66519689e-12
  1.76293655e-12  2.13909853e-12  1.03768771e-12  1.84583211e-12
  2.35503269e-12  2.82559976e-12  1.04914269e-12  1.96606028e-12
  3.24576718e-12  3.78703202e-12  1.22262004e-12  2.25921556e-12
  6.62703555e-13  1.27927457e-13 -1.41971177e-13 -4.05379621e-14
  1.73779358e-15 -3.72019193e-14 -3.78727556e-13 -7.06089312e-14
 -8.96302176e-01]
supnorm grad right now is: 0.896302176492953
Weights right now are: 
[-5.09058101e+00 -7.80308097e-01 -4.03402098e+00 -4.87906284e+00
  5.34514992e+00  6.71616421e-01  4.43295844e+00  4.16303466e+00
 -2.30263172e+00 -9.72067190e-01 -2.32817043e+00 -2.04635123e+00
  1.58874668e+00  5.06440580e-01 -1.43016768e-02  8.55842185e-01
 -1.41168786e+00 -6.22549374e-01 -2.76459266e+00 -2.24428779e+00
 -2.10468991e+00 -1.10110970e+00 -2.49676498e+00 -1.82609819e+00
 -1.02359292e+00 -8.94044777e-01 -1.76024933e+00 -9.85780405e-01
  4.47038930e-01  1.45414967e+00  1.49929906e+00  5.13106882e-01
 -1.12655827e+00 -6.73987395e-01 -1.33370555e+00 -1.29436413e+00
 -2.50305937e+00 -1.43892921e+00 -1.25634111e+00 -1.08843776e+00
 -1.00750855e+00 -9.58159326e-01 -7.79549270e-02  1.61609819e-01
  4.98386998e-01  1.31227507e+00  1.34532371e-02  3.74537708e-01
 -1.47308182e+00 -4.37401523e-01 -4.43330651e-01 -1.59621112e+00
  4.60252260e-01  1.21236737e+00  4.92184915e-01  1.64161602e+00
  1.20501904e+00 -2.12712207e+00 -1.90019790e-01 -2.22899087e+00
  2.15790123e+00  1.06036208e+00 -4.05112940e-02  1.38517267e+00
  2.49140762e+01]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.249034491206
gradient value of function right now is: [ 3.81801234e-09  3.31772935e-10  3.81587147e-09  3.81632324e-09
 -3.82166513e-09 -3.32080648e-10 -3.81952241e-09 -3.81997457e-09
  6.40109388e-11  8.06178498e-12  6.25580546e-11  6.64811855e-11
  4.10665005e-10  5.17869869e-11  4.01413752e-10  4.26541524e-10
  6.88192756e-11  8.66771806e-12  6.72575791e-11  7.14752308e-11
  6.96826330e-11  8.77613946e-12  6.81011545e-11  7.23717708e-11
 -1.32651716e-11 -3.82643847e-12 -1.50961561e-11 -2.58031520e-12
 -2.33546856e-12 -5.54880019e-13 -2.53255756e-12 -4.28892806e-13
  3.33585366e-11  1.03450467e-11  3.87336380e-11  6.63824274e-12
  1.47975943e-12  5.65602265e-13  1.83154833e-12  3.17113765e-13
  2.92379173e-12  3.64585223e-12  1.93620280e-12  3.48160901e-12
  1.68161145e-12  2.03946672e-12  9.86544963e-13  1.75484864e-12
  2.24461223e-12  2.69193208e-12  9.96906813e-13  1.86816574e-12
  3.09412165e-12  3.60881292e-12  1.16200489e-12  2.14722767e-12
  6.29840968e-13  1.22634710e-13 -1.35447690e-13 -3.87837807e-14
  1.59189568e-15 -3.53873404e-14 -3.60297872e-13 -6.81559647e-14
  5.07085189e-01]
supnorm grad right now is: 0.5070851885177928
Weights right now are: 
[-5.09842279e+00 -7.80988756e-01 -4.04185836e+00 -4.88690115e+00
  5.35299173e+00  6.72297083e-01  4.44079586e+00  4.17087300e+00
 -2.30276305e+00 -9.72083730e-01 -2.32829878e+00 -2.04648763e+00
  1.58790483e+00  5.06334419e-01 -1.51245537e-02  8.54967795e-01
 -1.41182903e+00 -6.22567155e-01 -2.76473063e+00 -2.24443442e+00
 -2.10483288e+00 -1.10112771e+00 -2.49690469e+00 -1.82624666e+00
 -1.02356574e+00 -8.94036938e-01 -1.76021840e+00 -9.85775118e-01
  4.47043697e-01  1.45415080e+00  1.49930423e+00  5.13107757e-01
 -1.12662668e+00 -6.74008611e-01 -1.33378499e+00 -1.29437775e+00
 -2.50306241e+00 -1.43893037e+00 -1.25634487e+00 -1.08843841e+00
 -1.00751455e+00 -9.58166803e-01 -7.79588997e-02  1.61602675e-01
  4.98383551e-01  1.31227089e+00  1.34512136e-02  3.74534109e-01
 -1.47308643e+00 -4.37407045e-01 -4.43332696e-01 -1.59621495e+00
  4.60245912e-01  1.21235997e+00  4.92182532e-01  1.64161162e+00
  1.20501775e+00 -2.12712232e+00 -1.90019513e-01 -2.22899080e+00
  2.15790123e+00  1.06036215e+00 -4.05105553e-02  1.38517281e+00
  2.50383623e+01]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.173832142385
gradient value of function right now is: [ 3.66075484e-09  3.18785767e-10  3.65870296e-09  3.65913599e-09
 -3.65923982e-09 -3.18656919e-10 -3.65718872e-09 -3.65762158e-09
  6.14065633e-11  7.73280465e-12  6.00126815e-11  6.37761500e-11
  3.94609728e-10  4.97564088e-11  3.85719798e-10  4.09864694e-10
  6.60376840e-11  8.31632771e-12  6.45389837e-11  6.85861214e-11
  6.68641134e-11  8.42012007e-12  6.53465185e-11  6.94443206e-11
 -1.27539445e-11 -3.68633497e-12 -1.45222253e-11 -2.48225040e-12
 -2.26132253e-12 -5.38915492e-13 -2.45391351e-12 -4.15594059e-13
  3.20164390e-11  9.94976077e-12  3.71975895e-11  6.37514390e-12
  1.41661006e-12  5.42969015e-13  1.75498331e-12  3.03881985e-13
  2.80103354e-12  3.49517812e-12  1.86507328e-12  3.35261448e-12
  1.61247427e-12  1.95678565e-12  9.50951421e-13  1.69106046e-12
  2.14957392e-12  2.57966445e-12  9.60358692e-13  1.79896027e-12
  2.96231887e-12  3.45715049e-12  1.11938396e-12  2.06769244e-12
  6.05370847e-13  1.16578587e-13 -1.30550092e-13 -3.70367591e-14
  1.54200367e-15 -3.39800120e-14 -3.46526567e-13 -6.42124395e-14
 -1.49393708e+00]
supnorm grad right now is: 1.4939370806905448
Weights right now are: 
[-5.10589733e+00 -7.81638946e-01 -4.04932871e+00 -4.89437238e+00
  5.36046629e+00  6.72947275e-01  4.44826623e+00  4.17834425e+00
 -2.30288838e+00 -9.72099515e-01 -2.32842126e+00 -2.04661779e+00
  1.58710011e+00  5.06232938e-01 -1.59111483e-02  8.54131961e-01
 -1.41196379e+00 -6.22584128e-01 -2.76486233e+00 -2.24457438e+00
 -2.10496933e+00 -1.10114489e+00 -2.49703805e+00 -1.82638838e+00
 -1.02353974e+00 -8.94029433e-01 -1.76018880e+00 -9.85770059e-01
  4.47048292e-01  1.45415189e+00  1.49930922e+00  5.13108602e-01
 -1.12669202e+00 -6.74028883e-01 -1.33386086e+00 -1.29439075e+00
 -2.50306531e+00 -1.43893148e+00 -1.25634845e+00 -1.08843903e+00
 -1.00752027e+00 -9.58173945e-01 -7.79626924e-02  1.61595852e-01
  4.98380258e-01  1.31226690e+00  1.34492806e-02  3.74530668e-01
 -1.47309082e+00 -4.37412316e-01 -4.43334649e-01 -1.59621861e+00
  4.60239858e-01  1.21235290e+00  4.92180255e-01  1.64160741e+00
  1.20501651e+00 -2.12712256e+00 -1.90019247e-01 -2.22899072e+00
  2.15790122e+00  1.06036222e+00 -4.05098483e-02  1.38517294e+00
  2.48978277e+01]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.062960965432
gradient value of function right now is: [ 3.48554505e-09  3.04117709e-10  3.48359275e-09  3.48400482e-09
 -3.48349840e-09 -3.03944444e-10 -3.48154714e-09 -3.48195900e-09
  5.85096392e-11  7.36944795e-12  5.71833900e-11  6.07682440e-11
  3.76684127e-10  4.75050035e-11  3.68209925e-10  3.91251091e-10
  6.29403059e-11  7.92782414e-12  6.15139147e-11  6.53700818e-11
  6.37216030e-11  8.02594246e-12  6.22773739e-11  6.61814116e-11
 -1.21954947e-11 -3.51604832e-12 -1.38767515e-11 -2.37189769e-12
 -2.18033738e-12 -5.19471942e-13 -2.36585752e-12 -4.00713093e-13
  3.05421481e-11  9.46561632e-12  3.54565660e-11  6.07668673e-12
  1.34497742e-12  5.14309937e-13  1.66491816e-12  2.88297913e-13
  2.67214439e-12  3.33365716e-12  1.76569596e-12  3.17841393e-12
  1.54054743e-12  1.86894382e-12  9.00981016e-13  1.60430552e-12
  2.05271447e-12  2.46281215e-12  9.09709058e-13  1.70686198e-12
  2.82947876e-12  3.30129561e-12  1.06062231e-12  1.96209511e-12
  5.76849309e-13  1.13088412e-13 -1.24736770e-13 -3.56927953e-14
  1.40631036e-15 -3.22882956e-14 -3.30054180e-13 -6.32196829e-14
  2.34083887e+00]
supnorm grad right now is: 2.340838872490017
Weights right now are: 
[-5.11305079e+00 -7.82262483e-01 -4.05647816e+00 -4.90152268e+00
  5.36761978e+00  6.73570815e-01  4.45541572e+00  4.18549459e+00
 -2.30300844e+00 -9.72114637e-01 -2.32853861e+00 -2.04674249e+00
  1.58632786e+00  5.06135551e-01 -1.66660203e-02  8.53329843e-01
 -1.41209293e+00 -6.22600393e-01 -2.76498854e+00 -2.24470850e+00
 -2.10510007e+00 -1.10116136e+00 -2.49716583e+00 -1.82652417e+00
 -1.02351476e+00 -8.94022223e-01 -1.76016037e+00 -9.85765199e-01
  4.47052739e-01  1.45415295e+00  1.49931404e+00  5.13109419e-01
 -1.12675466e+00 -6.74048316e-01 -1.33393360e+00 -1.29440322e+00
 -2.50306807e+00 -1.43893253e+00 -1.25635188e+00 -1.08843963e+00
 -1.00752575e+00 -9.58180785e-01 -7.79663258e-02  1.61589317e-01
  4.98377100e-01  1.31226307e+00  1.34474272e-02  3.74527371e-01
 -1.47309503e+00 -4.37417367e-01 -4.43336521e-01 -1.59622212e+00
  4.60234059e-01  1.21234613e+00  4.92178074e-01  1.64160338e+00
  1.20501533e+00 -2.12712280e+00 -1.90018991e-01 -2.22899065e+00
  2.15790122e+00  1.06036229e+00 -4.05091706e-02  1.38517307e+00
  2.51890766e+01]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16003.443727754497
gradient value of function right now is: [ 3.33163880e-09  2.91238063e-10  3.32977383e-09  3.33016752e-09
 -3.33270423e-09 -2.91332212e-10 -3.33083865e-09 -3.33123247e-09
  5.59973555e-11  7.05378080e-12  5.47295156e-11  5.81594657e-11
  3.61118153e-10  4.55466619e-11  3.53003445e-10  3.75086219e-10
  6.02548752e-11  7.59039221e-12  5.88909184e-11  6.25815032e-11
  6.09932320e-11  7.68312163e-12  5.96124236e-11  6.33482466e-11
 -1.17081639e-11 -3.36938132e-12 -1.33157727e-11 -2.27583268e-12
 -2.10916240e-12 -5.02558484e-13 -2.28866766e-12 -3.87659192e-13
  2.92598785e-11  9.05020250e-12  3.39491507e-11  5.81772375e-12
  1.28316935e-12  4.89929774e-13  1.58764330e-12  2.74878540e-13
  2.55947338e-12  3.19154575e-12  1.68327033e-12  3.03086656e-12
  1.47770504e-12  1.79176849e-12  8.59580526e-13  1.53095410e-12
  1.96803729e-12  2.36005146e-12  8.67443441e-13  1.62825648e-12
  2.71339974e-12  3.16447679e-12  1.01153472e-12  1.87201925e-12
  5.51188515e-13  1.09505830e-13 -1.19547612e-13 -3.44263262e-14
  1.29059775e-15 -3.08961759e-14 -3.15491278e-13 -6.20098825e-14
  4.87824044e+00]
supnorm grad right now is: 4.8782404356211595
Weights right now are: 
[-5.11990705e+00 -7.82861300e-01 -4.06333058e+00 -4.90837591e+00
  5.37447604e+00  6.74169631e-01  4.46226813e+00  4.19234781e+00
 -2.30312364e+00 -9.72129144e-01 -2.32865119e+00 -2.04686214e+00
  1.58558574e+00  5.06041969e-01 -1.73914385e-02  8.52559029e-01
 -1.41221687e+00 -6.22616002e-01 -2.76510967e+00 -2.24483722e+00
 -2.10522554e+00 -1.10117716e+00 -2.49728845e+00 -1.82665448e+00
 -1.02349073e+00 -8.94015284e-01 -1.76013302e+00 -9.85760524e-01
  4.47057047e-01  1.45415398e+00  1.49931872e+00  5.13110211e-01
 -1.12681480e+00 -6.74066984e-01 -1.33400345e+00 -1.29441519e+00
 -2.50307072e+00 -1.43893355e+00 -1.25635515e+00 -1.08844019e+00
 -1.00753101e+00 -9.58187346e-01 -7.79698133e-02  1.61583042e-01
  4.98374069e-01  1.31225939e+00  1.34456472e-02  3.74524203e-01
 -1.47309907e+00 -4.37422212e-01 -4.43338317e-01 -1.59622549e+00
  4.60228496e-01  1.21233964e+00  4.92175979e-01  1.64159950e+00
  1.20501419e+00 -2.12712302e+00 -1.90018745e-01 -2.22899058e+00
  2.15790122e+00  1.06036235e+00 -4.05085198e-02  1.38517320e+00
  2.53280487e+01]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.14008446084
gradient value of function right now is: [ 3.23403931e-09  2.83264431e-10  3.23222914e-09  3.23261126e-09
 -3.22970807e-09 -2.82889785e-10 -3.22790023e-09 -3.22828185e-09
  5.43814112e-11  6.84777828e-12  5.31488968e-11  5.64803339e-11
  3.51158792e-10  4.42755341e-11  3.43260177e-10  3.64736854e-10
  5.85295691e-11  7.37041457e-12  5.72033078e-11  6.07887209e-11
  5.92474274e-11  7.46057560e-12  5.79047859e-11  6.15341847e-11
 -1.13819963e-11 -3.29138355e-12 -1.29617570e-11 -2.21552724e-12
 -2.06071360e-12 -4.93491694e-13 -2.23872614e-12 -3.79236774e-13
  2.84127095e-11  8.83285135e-12  3.30139678e-11  5.65804140e-12
  1.24491086e-12  4.78053774e-13  1.54323380e-12  2.67225699e-13
  2.47854983e-12  3.09288252e-12  1.65261866e-12  2.96972208e-12
  1.43171908e-12  1.73724571e-12  8.44359433e-13  1.50111606e-12
  1.90386939e-12  2.28478043e-12  8.51359795e-13  1.59427692e-12
  2.62369478e-12  3.06207311e-12  9.92616049e-13  1.83300711e-12
  5.35699380e-13  1.03052851e-13 -1.16555902e-13 -3.28159215e-14
  1.30550322e-15 -3.00466037e-14 -3.07239911e-13 -5.66982502e-14
 -1.76762360e+00]
supnorm grad right now is: 1.7676235981291473
Weights right now are: 
[-5.12648823e+00 -7.83437176e-01 -4.06990808e+00 -4.91495418e+00
  5.38105722e+00  6.74745508e-01  4.46884563e+00  4.19892609e+00
 -2.30323431e+00 -9.72143084e-01 -2.32875936e+00 -2.04697708e+00
  1.58487161e+00  5.05951910e-01 -1.80895138e-02  8.51817277e-01
 -1.41233597e+00 -6.22631004e-01 -2.76522608e+00 -2.24496092e+00
 -2.10534610e+00 -1.10119235e+00 -2.49740628e+00 -1.82677969e+00
 -1.02346758e+00 -8.94008603e-01 -1.76010667e+00 -9.85756019e-01
  4.47061225e-01  1.45415498e+00  1.49932326e+00  5.13110980e-01
 -1.12687262e+00 -6.74084925e-01 -1.33407060e+00 -1.29442670e+00
 -2.50307325e+00 -1.43893452e+00 -1.25635829e+00 -1.08844074e+00
 -1.00753606e+00 -9.58193650e-01 -7.79731549e-02  1.61577020e-01
  4.98371153e-01  1.31225585e+00  1.34439404e-02  3.74521160e-01
 -1.47310295e+00 -4.37426870e-01 -4.43340040e-01 -1.59622873e+00
  4.60223148e-01  1.21233340e+00  4.92173970e-01  1.64159578e+00
  1.20501310e+00 -2.12712323e+00 -1.90018507e-01 -2.22899051e+00
  2.15790122e+00  1.06036241e+00 -4.05078938e-02  1.38517331e+00
  2.48177282e+01]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.18032893052
gradient value of function right now is: [ 3.09724809e-09  2.71754030e-10  3.09551555e-09  3.09588132e-09
 -3.10366097e-09 -2.72306400e-10 -3.10192506e-09 -3.10229154e-09
  5.22047979e-11  6.57492748e-12  5.10234659e-11  5.42203646e-11
  3.37624217e-10  4.25765744e-11  3.30041638e-10  3.50682993e-10
  5.62032398e-11  7.07879853e-12  5.49316936e-11  5.83733038e-11
  5.68755720e-11  7.16321697e-12  5.55886528e-11  5.90714836e-11
 -1.09603424e-11 -3.16006330e-12 -1.24714774e-11 -2.13175204e-12
 -1.99854614e-12 -4.78203123e-13 -2.17072930e-12 -3.67767815e-13
  2.73055511e-11  8.46094532e-12  3.16977536e-11  5.43242109e-12
  1.19139151e-12  4.56092469e-13  1.47538100e-12  2.55467785e-13
  2.38306252e-12  2.97107335e-12  1.57569970e-12  2.83344769e-12
  1.37872369e-12  1.67140577e-12  8.05644141e-13  1.43320029e-12
  1.83331599e-12  2.19807077e-12  8.12045819e-13  1.52195104e-12
  2.52745765e-12  2.94730100e-12  9.47004958e-13  1.75014996e-12
  5.12754837e-13  1.00269268e-13 -1.11879818e-13 -3.17547731e-14
  1.19219234e-15 -2.87867624e-14 -2.94138077e-13 -5.61071523e-14
  1.45884731e+00]
supnorm grad right now is: 1.4588473101124921
Weights right now are: 
[-5.13282476e+00 -7.83992649e-01 -4.07624106e+00 -4.92128792e+00
  5.38739376e+00  6.75300982e-01  4.47517862e+00  4.20525983e+00
 -2.30334096e+00 -9.72156515e-01 -2.32886359e+00 -2.04708785e+00
  1.58418235e+00  5.05864994e-01 -1.87632763e-02  8.51101369e-01
 -1.41245077e+00 -6.22645463e-01 -2.76533828e+00 -2.24508016e+00
 -2.10546229e+00 -1.10120698e+00 -2.49751984e+00 -1.82690038e+00
 -1.02344522e+00 -8.94002150e-01 -1.76008122e+00 -9.85751669e-01
  4.47065289e-01  1.45415595e+00  1.49932767e+00  5.13111727e-01
 -1.12692838e+00 -6.74102220e-01 -1.33413534e+00 -1.29443780e+00
 -2.50307569e+00 -1.43893545e+00 -1.25636131e+00 -1.08844126e+00
 -1.00754093e+00 -9.58199720e-01 -7.79763777e-02  1.61571220e-01
  4.98368340e-01  1.31225244e+00  1.34422932e-02  3.74518228e-01
 -1.47310669e+00 -4.37431358e-01 -4.43341702e-01 -1.59623184e+00
  4.60217991e-01  1.21232738e+00  4.92172033e-01  1.64159220e+00
  1.20501205e+00 -2.12712343e+00 -1.90018279e-01 -2.22899044e+00
  2.15790121e+00  1.06036247e+00 -4.05072918e-02  1.38517343e+00
  2.50729942e+01]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.256807808182
gradient value of function right now is: [ 2.99139021e-09  2.62923233e-10  2.98971748e-09  2.99007064e-09
 -2.99198798e-09 -2.62980931e-10 -2.99031480e-09 -2.99066807e-09
  5.04227145e-11  6.34997605e-12  4.92816135e-11  5.23694443e-11
  3.26554929e-10  4.11775490e-11  3.19220631e-10  3.39185416e-10
  5.42963064e-11  6.83807234e-12  5.30677919e-11  5.63927060e-11
  5.49468353e-11  6.91975977e-12  5.37034928e-11  5.70682480e-11
 -1.06065189e-11 -3.06312264e-12 -1.20741756e-11 -2.06394977e-12
 -1.94491157e-12 -4.66496519e-13 -2.11366511e-12 -3.58119656e-13
  2.63842830e-11  8.18997079e-12  3.06433936e-11  5.25209735e-12
  1.14861640e-12  4.40765133e-13  1.42349726e-12  2.46520535e-13
  2.29900058e-12  2.86880377e-12  1.52659170e-12  2.74557499e-12
  1.33102480e-12  1.61481626e-12  7.80965278e-13  1.38953159e-12
  1.76793085e-12  2.12145135e-12  7.86816541e-13  1.47493335e-12
  2.43665435e-12  2.84347877e-12  9.17551394e-13  1.69599190e-12
  4.96736063e-13  9.62696067e-14 -1.08595288e-13 -3.05766997e-14
  1.16824381e-15 -2.77950546e-14 -2.84930130e-13 -5.33989511e-14
  2.19149158e-01]
supnorm grad right now is: 0.21914915761532666
Weights right now are: 
[-5.13889309e+00 -7.84525562e-01 -4.08230600e+00 -4.92735357e+00
  5.39346210e+00  6.75833895e-01  4.48124356e+00  4.21132549e+00
 -2.30344320e+00 -9.72169390e-01 -2.32896352e+00 -2.04719404e+00
  1.58352073e+00  5.05781569e-01 -1.94100392e-02  8.50414152e-01
 -1.41256085e+00 -6.22659325e-01 -2.76544587e+00 -2.24519449e+00
 -2.10557370e+00 -1.10122101e+00 -2.49762872e+00 -1.82701608e+00
 -1.02342374e+00 -8.93995944e-01 -1.76005677e+00 -9.85747490e-01
  4.47069214e-01  1.45415689e+00  1.49933194e+00  5.13112450e-01
 -1.12698186e+00 -6.74118827e-01 -1.33419746e+00 -1.29444844e+00
 -2.50307802e+00 -1.43893635e+00 -1.25636420e+00 -1.08844176e+00
 -1.00754559e+00 -9.58205537e-01 -7.79794772e-02  1.61565649e-01
  4.98365642e-01  1.31224916e+00  1.34407081e-02  3.74515409e-01
 -1.47311027e+00 -4.37435657e-01 -4.43343299e-01 -1.59623483e+00
  4.60213054e-01  1.21232162e+00  4.92170169e-01  1.64158876e+00
  1.20501104e+00 -2.12712363e+00 -1.90018059e-01 -2.22899038e+00
  2.15790121e+00  1.06036253e+00 -4.05067143e-02  1.38517354e+00
  2.50130516e+01]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.17650387438
gradient value of function right now is: [ 2.89450621e-09  2.54840948e-10  2.89288816e-09  2.89322980e-09
 -2.89151999e-09 -2.54574706e-10 -2.88990368e-09 -2.89024495e-09
  4.88009180e-11  6.14527266e-12  4.76968445e-11  5.06850163e-11
  3.16502205e-10  3.99070035e-11  3.09395717e-10  3.28743777e-10
  5.25610715e-11  6.61904101e-12  5.13721741e-11  5.45904564e-11
  5.31907674e-11  6.69809633e-12  5.19874928e-11  5.52443578e-11
 -1.02872423e-11 -2.97331557e-12 -1.17132448e-11 -2.00231822e-12
 -1.89724194e-12 -4.55998371e-13 -2.06285249e-12 -3.49531981e-13
  2.55487212e-11  7.93607915e-12  2.96786101e-11  5.08698735e-12
  1.10901438e-12  4.25981811e-13  1.37483388e-12  2.38124719e-13
  2.22402973e-12  2.77469142e-12  1.47908667e-12  2.65928862e-12
  1.28885133e-12  1.56336129e-12  7.57101158e-13  1.34675015e-12
  1.71046181e-12  2.05212235e-12  7.62628024e-13  1.42876512e-12
  2.35740775e-12  2.75071386e-12  8.89520544e-13  1.64329262e-12
  4.80111156e-13  9.24390233e-14 -1.05298232e-13 -2.94660249e-14
  1.10763528e-15 -2.68729523e-14 -2.75801397e-13 -5.09992338e-14
 -1.47772098e+00]
supnorm grad right now is: 1.4777209830223423
Weights right now are: 
[-5.14477789e+00 -7.85043219e-01 -4.08818751e+00 -4.93323577e+00
  5.39934690e+00  6.76351552e-01  4.48712507e+00  4.21720769e+00
 -2.30354242e+00 -9.72181885e-01 -2.32906049e+00 -2.04729708e+00
  1.58287767e+00  5.05700484e-01 -2.00386564e-02  8.49746225e-01
 -1.41266770e+00 -6.22672782e-01 -2.76555030e+00 -2.24530546e+00
 -2.10568182e+00 -1.10123463e+00 -2.49773441e+00 -1.82712838e+00
 -1.02340284e+00 -8.93989912e-01 -1.76003298e+00 -9.85743424e-01
  4.47073059e-01  1.45415781e+00  1.49933611e+00  5.13113158e-01
 -1.12703379e+00 -6.74134940e-01 -1.33425777e+00 -1.29445878e+00
 -2.50308028e+00 -1.43893721e+00 -1.25636700e+00 -1.08844225e+00
 -1.00755011e+00 -9.58211180e-01 -7.79824810e-02  1.61560253e-01
  4.98363021e-01  1.31224598e+00  1.34391709e-02  3.74512677e-01
 -1.47311375e+00 -4.37439831e-01 -4.43344847e-01 -1.59623773e+00
  4.60208255e-01  1.21231602e+00  4.92168364e-01  1.64158543e+00
  1.20501006e+00 -2.12712382e+00 -1.90017846e-01 -2.22899032e+00
  2.15790121e+00  1.06036258e+00 -4.05061550e-02  1.38517364e+00
  2.48345632e+01]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.105061950051
gradient value of function right now is: [ 2.79944405e-09  2.46871385e-10  2.79787971e-09  2.79821003e-09
 -2.80475693e-09 -2.47337142e-10 -2.80318967e-09 -2.80352061e-09
  4.73078488e-11  5.95705810e-12  4.62378968e-11  4.91343391e-11
  3.07180387e-10  3.87304307e-11  3.00285517e-10  3.19061705e-10
  5.09657888e-11  6.41793177e-12  4.98133440e-11  5.29336182e-11
  5.15627084e-11  6.49286430e-12  5.03966392e-11  5.35534847e-11
 -9.98985960e-12 -2.88858502e-12 -1.13759646e-11 -1.94467790e-12
 -1.85176598e-12 -4.45650448e-13 -2.01401517e-12 -3.41283494e-13
  2.47789342e-11  7.70036861e-12  2.87881796e-11  4.93432222e-12
  1.07351055e-12  4.12706475e-13  1.33122913e-12  2.30560553e-13
  2.15500328e-12  2.68898920e-12  1.43567675e-12  2.58023638e-12
  1.25001803e-12  1.51637635e-12  7.35300425e-13  1.30746025e-12
  1.65795287e-12  1.98933962e-12  7.40133301e-13  1.38621946e-12
  2.28492446e-12  2.66634879e-12  8.63226457e-13  1.59426804e-12
  4.65467038e-13  8.92935112e-14 -1.02284522e-13 -2.85110592e-14
  1.07744276e-15 -2.60883937e-14 -2.67451162e-13 -4.93063321e-14
 -2.01270143e+00]
supnorm grad right now is: 2.0127014273323782
Weights right now are: 
[-5.15044364e+00 -7.85542446e-01 -4.09385009e+00 -4.93889903e+00
  5.40501261e+00  6.76850776e-01  4.49278763e+00  4.22287091e+00
 -2.30363803e+00 -9.72193925e-01 -2.32915394e+00 -2.04739639e+00
  1.58225719e+00  5.05622250e-01 -2.06452046e-02  8.49101748e-01
 -1.41277070e+00 -6.22685752e-01 -2.76565097e+00 -2.24541243e+00
 -2.10578604e+00 -1.10124775e+00 -2.49783627e+00 -1.82723662e+00
 -1.02338267e+00 -8.93984080e-01 -1.76001001e+00 -9.85739498e-01
  4.47076789e-01  1.45415871e+00  1.49934017e+00  5.13113845e-01
 -1.12708386e+00 -6.74150495e-01 -1.33431594e+00 -1.29446875e+00
 -2.50308245e+00 -1.43893805e+00 -1.25636969e+00 -1.08844271e+00
 -1.00755447e+00 -9.58216616e-01 -7.79853817e-02  1.61555040e-01
  4.98360495e-01  1.31224292e+00  1.34376856e-02  3.74510036e-01
 -1.47311710e+00 -4.37443852e-01 -4.43346342e-01 -1.59624053e+00
  4.60203637e-01  1.21231063e+00  4.92166620e-01  1.64158221e+00
  1.20500912e+00 -2.12712400e+00 -1.90017639e-01 -2.22899026e+00
  2.15790121e+00  1.06036264e+00 -4.05056145e-02  1.38517374e+00
  2.48435177e+01]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.258757818898
gradient value of function right now is: [ 2.69976381e-09  2.38444977e-10  2.69825592e-09  2.69857435e-09
 -2.70140243e-09 -2.38589883e-10 -2.69989361e-09 -2.70021224e-09
  4.56237077e-11  5.74541285e-12  4.45926961e-11  4.73854752e-11
  2.96675039e-10  3.74085993e-11  2.90021503e-10  3.08151957e-10
  4.91612676e-11  6.19114872e-12  4.80505410e-11  5.10597447e-11
  4.97369213e-11  6.26343020e-12  4.86130770e-11  5.16575366e-11
 -9.65956045e-12 -2.78979816e-12 -1.09963376e-11 -1.87973659e-12
 -1.80143420e-12 -4.33613439e-13 -1.95934176e-12 -3.32039168e-13
  2.39156566e-11  7.42284188e-12  2.77753964e-11  4.76054896e-12
  1.03228411e-12  3.96583287e-13  1.27981959e-12  2.21647910e-13
  2.07913017e-12  2.59372014e-12  1.38080044e-12  2.48257753e-12
  1.20736363e-12  1.46424331e-12  7.07625766e-13  1.25872933e-12
  1.60053724e-12  1.91998978e-12  7.12005797e-13  1.33419177e-12
  2.20614884e-12  2.57389523e-12  8.30544320e-13  1.53463775e-12
  4.48580775e-13  8.69016992e-14 -9.88279960e-14 -2.76571343e-14
  1.00807969e-15 -2.51212042e-14 -2.57819999e-13 -4.82275147e-14
 -3.90373835e-04]
supnorm grad right now is: 0.00039037383526725994
Weights right now are: 
[-5.15592917e+00 -7.86026553e-01 -4.09933256e+00 -4.94438214e+00
  5.41049815e+00  6.77334883e-01  4.49827009e+00  4.22835403e+00
 -2.30373067e+00 -9.72205590e-01 -2.32924448e+00 -2.04749260e+00
  1.58165519e+00  5.05546343e-01 -2.12337025e-02  8.48476458e-01
 -1.41287051e+00 -6.22698321e-01 -2.76574852e+00 -2.24551610e+00
 -2.10588703e+00 -1.10126047e+00 -2.49793497e+00 -1.82734151e+00
 -1.02336308e+00 -8.93978420e-01 -1.75998770e+00 -9.85735685e-01
  4.47080432e-01  1.45415959e+00  1.49934413e+00  5.13114517e-01
 -1.12713241e+00 -6.74165567e-01 -1.33437232e+00 -1.29447841e+00
 -2.50308455e+00 -1.43893885e+00 -1.25637229e+00 -1.08844316e+00
 -1.00755869e+00 -9.58221882e-01 -7.79881868e-02  1.61549996e-01
  4.98358045e-01  1.31223995e+00  1.34362485e-02  3.74507480e-01
 -1.47312035e+00 -4.37447749e-01 -4.43347789e-01 -1.59624324e+00
  4.60199159e-01  1.21230541e+00  4.92164933e-01  1.64157909e+00
  1.20500821e+00 -2.12712417e+00 -1.90017439e-01 -2.22899021e+00
  2.15790121e+00  1.06036269e+00 -4.05050910e-02  1.38517384e+00
  2.49793569e+01]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16003.309705486772
gradient value of function right now is: [ 2.59382359e-09  2.29416249e-10  2.59237581e-09  2.59268159e-09
 -2.58885783e-09 -2.28978795e-10 -2.58741279e-09 -2.58771798e-09
  4.37974754e-11  5.51662596e-12  4.28092021e-11  4.54893210e-11
  2.85261585e-10  3.59769439e-11  2.78873451e-10  2.96300751e-10
  4.72021196e-11  5.94570251e-12  4.61372374e-11  4.90255831e-11
  4.77583999e-11  6.01557980e-12  4.66808701e-11  4.96032679e-11
 -9.30464487e-12 -2.67822805e-12 -1.05828715e-11 -1.80865782e-12
 -1.74718831e-12 -4.19933143e-13 -1.89970167e-12 -3.21902986e-13
  2.29850488e-11  7.10839179e-12  2.66679438e-11  4.56957782e-12
  9.87011616e-13  3.78026956e-13  1.22248375e-12  2.11661265e-13
  1.99920230e-12  2.49226349e-12  1.31557710e-12  2.36770802e-12
  1.16251477e-12  1.40885794e-12  6.74682999e-13  1.20125939e-12
  1.54049785e-12  1.84676051e-12  6.78747720e-13  1.27343124e-12
  2.12420103e-12  2.47688374e-12  7.92049531e-13  1.46517768e-12
  4.29911229e-13  8.57595086e-14 -9.49858285e-14 -2.70530076e-14
  8.91685060e-16 -2.40964769e-14 -2.47152872e-13 -4.87010663e-14
  5.27706759e+00]
supnorm grad right now is: 5.277067589454259
Weights right now are: 
[-5.16125314e+00 -7.86497121e-01 -4.10465355e+00 -4.94970376e+00
  5.41582212e+00  6.77805452e-01  4.50359110e+00  4.23367566e+00
 -2.30382064e+00 -9.72216921e-01 -2.32933243e+00 -2.04758605e+00
  1.58106973e+00  5.05472521e-01 -2.18060409e-02  8.47868344e-01
 -1.41296747e+00 -6.22710532e-01 -2.76584329e+00 -2.24561680e+00
 -2.10598512e+00 -1.10127282e+00 -2.49803085e+00 -1.82744339e+00
 -1.02334401e+00 -8.93972913e-01 -1.75996600e+00 -9.85731974e-01
  4.47083999e-01  1.45416045e+00  1.49934801e+00  5.13115174e-01
 -1.12717958e+00 -6.74180209e-01 -1.33442711e+00 -1.29448780e+00
 -2.50308658e+00 -1.43893963e+00 -1.25637481e+00 -1.08844360e+00
 -1.00756279e+00 -9.58226995e-01 -7.79909092e-02  1.61545101e-01
  4.98355663e-01  1.31223706e+00  1.34348529e-02  3.74504997e-01
 -1.47312351e+00 -4.37451535e-01 -4.43349193e-01 -1.59624587e+00
  4.60194807e-01  1.21230033e+00  4.92163295e-01  1.64157606e+00
  1.20500733e+00 -2.12712435e+00 -1.90017244e-01 -2.22899015e+00
  2.15790120e+00  1.06036274e+00 -4.05045828e-02  1.38517393e+00
  2.52988834e+01]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16003.961141598624
gradient value of function right now is: [ 2.52301701e-09  2.23492103e-10  2.52160908e-09  2.52190645e-09
 -2.52210951e-09 -2.23413674e-10 -2.52070204e-09 -2.52099932e-09
  4.26715285e-11  5.37435296e-12  4.17086333e-11  4.43198233e-11
  2.78223193e-10  3.50863647e-11  2.71992559e-10  2.88989631e-10
  4.59984108e-11  5.79359734e-12  4.49606548e-11  4.77753141e-11
  4.65326101e-11  5.86067455e-12  4.54827021e-11  4.83300593e-11
 -9.07752011e-12 -2.61700554e-12 -1.03287258e-11 -1.76553624e-12
 -1.71172135e-12 -4.12330259e-13 -1.86208388e-12 -3.15583037e-13
  2.24004582e-11  6.93866066e-12  2.60007755e-11  4.45613247e-12
  9.60574757e-13  3.68576947e-13  1.19041922e-12  2.06160456e-13
  1.94589315e-12  2.42711801e-12  1.28546976e-12  2.31308997e-12
  1.13228571e-12  1.37283648e-12  6.59531079e-13  1.17409636e-12
  1.49939333e-12  1.79831503e-12  6.63186423e-13  1.24400208e-12
  2.06710927e-12  2.41126099e-12  7.73829896e-13  1.43121562e-12
  4.19455315e-13  8.24303501e-14 -9.28317576e-14 -2.61169290e-14
  8.88477636e-16 -2.34443684e-14 -2.41151950e-13 -4.63431017e-14
  2.91718309e+00]
supnorm grad right now is: 2.9171830876740694
Weights right now are: 
[-5.16641018e+00 -7.86953617e-01 -4.10980771e+00 -4.95485853e+00
  5.42097913e+00  6.78261945e-01  4.50874523e+00  4.23883040e+00
 -2.30390786e+00 -9.72227904e-01 -2.32941767e+00 -2.04767664e+00
  1.58050149e+00  5.05400869e-01 -2.23615382e-02  8.47278127e-01
 -1.41306147e+00 -6.22722371e-01 -2.76593517e+00 -2.24571444e+00
 -2.10608022e+00 -1.10128480e+00 -2.49812380e+00 -1.82754216e+00
 -1.02332548e+00 -8.93967564e-01 -1.75994491e+00 -9.85728369e-01
  4.47087481e-01  1.45416129e+00  1.49935180e+00  5.13115816e-01
 -1.12722534e+00 -6.74194405e-01 -1.33448025e+00 -1.29449691e+00
 -2.50308855e+00 -1.43894039e+00 -1.25637725e+00 -1.08844402e+00
 -1.00756677e+00 -9.58231953e-01 -7.79935449e-02  1.61540361e-01
  4.98353352e-01  1.31223426e+00  1.34335011e-02  3.74502592e-01
 -1.47312657e+00 -4.37455208e-01 -4.43350552e-01 -1.59624842e+00
  4.60190588e-01  1.21229541e+00  4.92161708e-01  1.64157313e+00
  1.20500647e+00 -2.12712451e+00 -1.90017054e-01 -2.22899010e+00
  2.15790120e+00  1.06036278e+00 -4.05040896e-02  1.38517403e+00
  2.51882126e+01]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16003.886901882237
gradient value of function right now is: [ 2.47063225e-09  2.19188694e-10  2.46925357e-09  2.46954476e-09
 -2.46653492e-09 -2.18831683e-10 -2.46515839e-09 -2.46544912e-09
  4.18018247e-11  5.26308360e-12  4.08575250e-11  4.34159386e-11
  2.72816340e-10  3.43937702e-11  2.66700409e-10  2.83369966e-10
  4.50685014e-11  5.67460323e-12  4.40506126e-11  4.68088496e-11
  4.55923748e-11  5.74038531e-12  4.45625756e-11  4.73528747e-11
 -8.89717257e-12 -2.57676214e-12 -1.01361122e-11 -1.73269413e-12
 -1.68329609e-12 -4.07289501e-13 -1.83309395e-12 -3.10679443e-13
  2.19393023e-11  6.82861450e-12  2.55006592e-11  4.37069308e-12
  9.40549675e-13  3.62837996e-13  1.16768769e-12  2.02245183e-13
  1.90107531e-12  2.37319558e-12  1.27224825e-12  2.28536261e-12
  1.10649906e-12  1.34265644e-12  6.52999804e-13  1.16064496e-12
  1.46325815e-12  1.75645618e-12  6.56166854e-13  1.22830855e-12
  2.01633085e-12  2.35391446e-12  7.65511257e-13  1.41313873e-12
  4.11483348e-13  7.85204891e-14 -9.12743718e-14 -2.51716181e-14
  9.10318791e-16 -2.30162778e-14 -2.36951260e-13 -4.30075598e-14
 -3.08890889e+00]
supnorm grad right now is: 3.0889088916884377
Weights right now are: 
[-5.17140478e+00 -7.87396369e-01 -4.11479952e+00 -4.95985093e+00
  5.42597372e+00  6.78704697e-01  4.51373703e+00  4.24382279e+00
 -2.30399238e+00 -9.72238549e-01 -2.32950029e+00 -2.04776442e+00
  1.57995011e+00  5.05331340e-01 -2.29005785e-02  8.46705403e-01
 -1.41315259e+00 -6.22733846e-01 -2.76602424e+00 -2.24580908e+00
 -2.10617239e+00 -1.10129640e+00 -2.49821389e+00 -1.82763790e+00
 -1.02330749e+00 -8.93962372e-01 -1.75992443e+00 -9.85724868e-01
  4.47090881e-01  1.45416211e+00  1.49935550e+00  5.13116443e-01
 -1.12726972e+00 -6.74208164e-01 -1.33453177e+00 -1.29450574e+00
 -2.50309045e+00 -1.43894112e+00 -1.25637961e+00 -1.08844443e+00
 -1.00757062e+00 -9.58236757e-01 -7.79960954e-02  1.61535773e-01
  4.98351110e-01  1.31223154e+00  1.34321922e-02  3.74500262e-01
 -1.47312954e+00 -4.37458767e-01 -4.43351869e-01 -1.59625089e+00
  4.60186496e-01  1.21229064e+00  4.92160172e-01  1.64157029e+00
  1.20500564e+00 -2.12712467e+00 -1.90016870e-01 -2.22899005e+00
  2.15790120e+00  1.06036283e+00 -4.05036119e-02  1.38517412e+00
  2.47179304e+01]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.155726756937
gradient value of function right now is: [ 2.38168090e-09  2.11573455e-10  2.38035267e-09  2.38063323e-09
 -2.38370698e-09 -2.11755532e-10 -2.38237757e-09 -2.38265839e-09
  4.03634620e-11  5.08339573e-12  3.94531791e-11  4.19227114e-11
  2.63771591e-10  3.32622061e-11  2.57868107e-10  2.73979520e-10
  4.35272968e-11  5.48207366e-12  4.25458631e-11  4.52088607e-11
  4.40233127e-11  5.54433929e-12  4.30305976e-11  4.57239495e-11
 -8.61602787e-12 -2.48614377e-12 -9.80580669e-12 -1.67632692e-12
 -1.63952617e-12 -3.95952412e-13 -1.78460330e-12 -3.02495954e-13
  2.12079294e-11  6.57467531e-12  2.46218784e-11  4.22034135e-12
  9.05482657e-13  3.47964401e-13  1.12267060e-12  1.94471690e-13
  1.83922990e-12  2.29471821e-12  1.21716482e-12  2.19056793e-12
  1.07195180e-12  1.29991119e-12  6.25100474e-13  1.11303542e-12
  1.41774035e-12  1.70075804e-12  6.28196994e-13  1.17845513e-12
  1.95436406e-12  2.28019213e-12  7.33078485e-13  1.35591207e-12
  3.96926330e-13  7.73642966e-14 -8.81945270e-14 -2.45981618e-14
  8.34327295e-16 -2.21578381e-14 -2.28389282e-13 -4.32789047e-14
  1.69474385e+00]
supnorm grad right now is: 1.6947438514123834
Weights right now are: 
[-5.17625541e+00 -7.87826982e-01 -4.11964745e+00 -4.96469943e+00
  5.43082432e+00  6.79135307e-01  4.51858493e+00  4.24867126e+00
 -2.30407453e+00 -9.72248893e-01 -2.32958058e+00 -2.04784975e+00
  1.57941360e+00  5.05263695e-01 -2.34250690e-02  8.46148138e-01
 -1.41324117e+00 -6.22745001e-01 -2.76611082e+00 -2.24590108e+00
 -2.10626199e+00 -1.10130769e+00 -2.49830147e+00 -1.82773096e+00
 -1.02328998e+00 -8.93957312e-01 -1.75990449e+00 -9.85721461e-01
  4.47094204e-01  1.45416291e+00  1.49935912e+00  5.13117056e-01
 -1.12731286e+00 -6.74221559e-01 -1.33458188e+00 -1.29451433e+00
 -2.50309229e+00 -1.43894183e+00 -1.25638190e+00 -1.08844483e+00
 -1.00757436e+00 -9.58241423e-01 -7.79985840e-02  1.61531301e-01
  4.98348931e-01  1.31222890e+00  1.34309145e-02  3.74497990e-01
 -1.47313242e+00 -4.37462223e-01 -4.43353153e-01 -1.59625330e+00
  4.60182524e-01  1.21228600e+00  4.92158674e-01  1.64156752e+00
  1.20500484e+00 -2.12712483e+00 -1.90016691e-01 -2.22899000e+00
  2.15790120e+00  1.06036288e+00 -4.05031472e-02  1.38517420e+00
  2.50935780e+01]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.074757909271
gradient value of function right now is: [ 2.32863952e-09  2.07156514e-10  2.32734101e-09  2.32761530e-09
 -2.33715427e-09 -2.07901933e-10 -2.33585127e-09 -2.33612651e-09
  3.95511304e-11  4.98025122e-12  3.86590764e-11  4.10787542e-11
  2.58701499e-10  3.26175492e-11  2.52910824e-10  2.68711696e-10
  4.26600305e-11  5.37194417e-12  4.16980620e-11  4.43078268e-11
  4.31364830e-11  5.43172407e-12  4.21636309e-11  4.48025905e-11
 -8.45110195e-12 -2.44295274e-12 -9.62284302e-12 -1.64511190e-12
 -1.61395260e-12 -3.90726813e-13 -1.75777469e-12 -2.97973722e-13
  2.07843554e-11  6.45452893e-12  2.41422100e-11  4.13824516e-12
  8.86393691e-13  3.41246921e-13  1.09968014e-12  1.90490006e-13
  1.80050756e-12  2.24571618e-12  1.19780953e-12  2.15236231e-12
  1.05014050e-12  1.27312386e-12  6.15433688e-13  1.09423547e-12
  1.38802759e-12  1.66462901e-12  6.18101528e-13  1.15742939e-12
  1.91324830e-12  2.23177434e-12  7.21306537e-13  1.33189966e-12
  3.87998399e-13  7.44262989e-14 -8.64375939e-14 -2.38380695e-14
  8.17812896e-16 -2.17292285e-14 -2.23641100e-13 -4.12569497e-14
 -2.19263870e+00]
supnorm grad right now is: 2.1926386977093024
Weights right now are: 
[-5.18096948e+00 -7.88246040e-01 -4.12435889e+00 -4.96941142e+00
  5.43553839e+00  6.79554365e-01  4.52329636e+00  4.25338325e+00
 -2.30415442e+00 -9.72258953e-01 -2.32965867e+00 -2.04793272e+00
  1.57889125e+00  5.05197832e-01 -2.39357250e-02  8.45605578e-01
 -1.41332733e+00 -6.22755851e-01 -2.76619503e+00 -2.24599056e+00
 -2.10634913e+00 -1.10131866e+00 -2.49838665e+00 -1.82782146e+00
 -1.02327292e+00 -8.93952384e-01 -1.75988507e+00 -9.85718139e-01
  4.47097458e-01  1.45416370e+00  1.49936266e+00  5.13117657e-01
 -1.12735484e+00 -6.74234585e-01 -1.33463063e+00 -1.29452268e+00
 -2.50309409e+00 -1.43894252e+00 -1.25638412e+00 -1.08844521e+00
 -1.00757800e+00 -9.58245960e-01 -7.80009974e-02  1.61526959e-01
  4.98346810e-01  1.31222633e+00  1.34296747e-02  3.74495783e-01
 -1.47313522e+00 -4.37465587e-01 -4.43354398e-01 -1.59625563e+00
  4.60178658e-01  1.21228149e+00  4.92157221e-01  1.64156484e+00
  1.20500405e+00 -2.12712498e+00 -1.90016517e-01 -2.22898995e+00
  2.15790120e+00  1.06036292e+00 -4.05026955e-02  1.38517429e+00
  2.48163458e+01]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.017240632415
gradient value of function right now is: [ 2.24845289e-09  2.00270829e-10  2.24719983e-09  2.24746455e-09
 -2.24689397e-09 -2.00132801e-10 -2.24564177e-09 -2.24590630e-09
  3.81222335e-11  4.80100573e-12  3.72632722e-11  3.95950204e-11
  2.49719396e-10  3.14895959e-11  2.44135577e-10  2.59384389e-10
  4.11242794e-11  5.17927914e-12  4.01978650e-11  4.27131319e-11
  4.15914180e-11  5.23795327e-12  4.06543942e-11  4.31982508e-11
 -8.16975125e-12 -2.35619221e-12 -9.29687028e-12 -1.58910737e-12
 -1.56939921e-12 -3.79515176e-13 -1.70880422e-12 -2.89660556e-13
  2.00517192e-11  6.21289330e-12  2.32767755e-11  3.98902421e-12
  8.51285980e-13  3.27305538e-13  1.05572068e-12  1.82820712e-13
  1.73683706e-12  2.16566740e-12  1.14940311e-12  2.06658565e-12
  1.01413234e-12  1.22906941e-12  5.90921198e-13  1.05121715e-12
  1.33977515e-12  1.60632613e-12  5.93186847e-13  1.11173405e-12
  1.84726115e-12  2.15429452e-12  6.92343613e-13  1.27950742e-12
  3.73785574e-13  7.34254098e-14 -8.34767448e-14 -2.33277035e-14
  7.48829633e-16 -2.09378569e-14 -2.15447480e-13 -4.12148643e-14
  2.60411347e+00]
supnorm grad right now is: 2.604113469539998
Weights right now are: 
[-5.18555654e+00 -7.88654343e-01 -4.12894340e+00 -4.97399647e+00
  5.44012548e+00  6.79962670e-01  4.52788090e+00  4.25796832e+00
 -2.30423220e+00 -9.72268748e-01 -2.32973469e+00 -2.04801350e+00
  1.57838208e+00  5.05133625e-01 -2.44335058e-02  8.45076703e-01
 -1.41341122e+00 -6.22766417e-01 -2.76627704e+00 -2.24607770e+00
 -2.10643398e+00 -1.10132935e+00 -2.49846958e+00 -1.82790959e+00
 -1.02325626e+00 -8.93947580e-01 -1.75986612e+00 -9.85714900e-01
  4.47100649e-01  1.45416447e+00  1.49936614e+00  5.13118246e-01
 -1.12739574e+00 -6.74247260e-01 -1.33467811e+00 -1.29453082e+00
 -2.50309582e+00 -1.43894319e+00 -1.25638628e+00 -1.08844558e+00
 -1.00758154e+00 -9.58250380e-01 -7.80033415e-02  1.61522741e-01
  4.98344742e-01  1.31222382e+00  1.34284700e-02  3.74493639e-01
 -1.47313796e+00 -4.37468864e-01 -4.43355608e-01 -1.59625790e+00
  4.60174890e-01  1.21227710e+00  4.92155808e-01  1.64156223e+00
  1.20500329e+00 -2.12712513e+00 -1.90016346e-01 -2.22898990e+00
  2.15790119e+00  1.06036296e+00 -4.05022556e-02  1.38517437e+00
  2.51878296e+01]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.061570108146
gradient value of function right now is: [ 2.18957927e-09  1.95278574e-10  2.18835938e-09  2.18861711e-09
 -2.18643205e-09 -1.95000644e-10 -2.18521386e-09 -2.18547122e-09
  3.71336632e-11  4.67638733e-12  3.62971864e-11  3.85682994e-11
  2.43511309e-10  3.07060233e-11  2.38067741e-10  2.52936321e-10
  4.00642846e-11  5.04565014e-12  3.91619746e-11  4.16122278e-11
  4.05186151e-11  5.10271883e-12  3.96059963e-11  4.20840478e-11
 -7.97143628e-12 -2.29979940e-12 -9.07206211e-12 -1.55066801e-12
 -1.53780678e-12 -3.72284604e-13 -1.67483911e-12 -2.83911966e-13
  1.95402611e-11  6.05648575e-12  2.26852986e-11  3.88761281e-12
  8.27651520e-13  3.18458774e-13  1.02666931e-12  1.77790046e-13
  1.69118806e-12  2.10899047e-12  1.12032648e-12  2.01404650e-12
  9.88205498e-13  1.19774089e-12  5.76241350e-13  1.02498950e-12
  1.30467560e-12  1.56441293e-12  5.78227760e-13  1.08356764e-12
  1.79880701e-12  2.09801109e-12  6.74925488e-13  1.24718160e-12
  3.64160464e-13  7.14571276e-14 -8.14894906e-14 -2.27217636e-14
  7.20807944e-16 -2.03889798e-14 -2.09990726e-13 -4.00624991e-14
  2.34914771e+00]
supnorm grad right now is: 2.349147712186809
Weights right now are: 
[-5.19001057e+00 -7.89051341e-01 -4.13339495e+00 -4.97844855e+00
  5.44457951e+00  6.80359668e-01  4.53233244e+00  4.26242039e+00
 -2.30430778e+00 -9.72278266e-01 -2.32980857e+00 -2.04809200e+00
  1.57788682e+00  5.05071178e-01 -2.49176919e-02  8.44562271e-01
 -1.41349276e+00 -6.22776685e-01 -2.76635674e+00 -2.24616239e+00
 -2.10651644e+00 -1.10133973e+00 -2.49855018e+00 -1.82799523e+00
 -1.02324007e+00 -8.93942899e-01 -1.75984767e+00 -9.85711747e-01
  4.47103764e-01  1.45416522e+00  1.49936953e+00  5.13118821e-01
 -1.12743549e+00 -6.74259602e-01 -1.33472428e+00 -1.29453874e+00
 -2.50309751e+00 -1.43894384e+00 -1.25638837e+00 -1.08844595e+00
 -1.00758498e+00 -9.58254672e-01 -7.80056286e-02  1.61518630e-01
  4.98342733e-01  1.31222138e+00  1.34272940e-02  3.74491547e-01
 -1.47314061e+00 -4.37472046e-01 -4.43356789e-01 -1.59626011e+00
  4.60171235e-01  1.21227283e+00  4.92154431e-01  1.64155968e+00
  1.20500254e+00 -2.12712527e+00 -1.90016180e-01 -2.22898986e+00
  2.15790119e+00  1.06036300e+00 -4.05018275e-02  1.38517445e+00
  2.51428041e+01]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16003.6029576463
gradient value of function right now is: [ 2.15426039e-09  1.92391765e-10  2.15306010e-09  2.15331368e-09
 -2.16433599e-09 -1.93281130e-10 -2.16313031e-09 -2.16338503e-09
  3.66800700e-11  4.61824560e-12  3.58533090e-11  3.80968676e-11
  2.40670878e-10  3.03411593e-11  2.35287427e-10  2.49983878e-10
  3.95836831e-11  4.98403650e-12  3.86916660e-11  4.11127235e-11
  4.00157238e-11  5.03822630e-12  3.91138403e-11  4.15613641e-11
 -7.87404223e-12 -2.27973355e-12 -8.96949717e-12 -1.53357387e-12
 -1.52214852e-12 -3.69863615e-13 -1.65922046e-12 -2.81314307e-13
  1.92982327e-11  6.00225704e-12  2.24255035e-11  3.84445664e-12
  8.18094410e-13  3.15769671e-13  1.01578962e-12  1.76000839e-13
  1.66756718e-12  2.08076207e-12  1.11360051e-12  2.00088486e-12
  9.74735879e-13  1.18203548e-12  5.72947751e-13  1.01867274e-12
  1.28606748e-12  1.54288017e-12  5.74879077e-13  1.07626323e-12
  1.77245471e-12  2.06819457e-12  6.70948577e-13  1.23864809e-12
  3.59994024e-13  6.82341867e-14 -8.06498382e-14 -2.19726428e-14
  7.51382951e-16 -2.01393958e-14 -2.07787734e-13 -3.74631404e-14
 -4.08390385e+00]
supnorm grad right now is: 4.083903854727965
Weights right now are: 
[-5.19434456e+00 -7.89438127e-01 -4.13772651e+00 -4.98278062e+00
  5.44891348e+00  6.80746453e-01  4.53666400e+00  4.26675246e+00
 -2.30438136e+00 -9.72287532e-01 -2.32988050e+00 -2.04816843e+00
  1.57740409e+00  5.05010314e-01 -2.53896217e-02  8.44060864e-01
 -1.41357216e+00 -6.22786684e-01 -2.76643435e+00 -2.24624486e+00
 -2.10659673e+00 -1.10134984e+00 -2.49862867e+00 -1.82807863e+00
 -1.02322427e+00 -8.93938333e-01 -1.75982969e+00 -9.85708672e-01
  4.47106816e-01  1.45416596e+00  1.49937285e+00  5.13119385e-01
 -1.12747421e+00 -6.74271623e-01 -1.33476925e+00 -1.29454644e+00
 -2.50309915e+00 -1.43894447e+00 -1.25639041e+00 -1.08844630e+00
 -1.00758833e+00 -9.58258850e-01 -7.80078554e-02  1.61514627e-01
  4.98340776e-01  1.31221901e+00  1.34261484e-02  3.74489509e-01
 -1.47314319e+00 -4.37475144e-01 -4.43357938e-01 -1.59626226e+00
  4.60167675e-01  1.21226868e+00  4.92153089e-01  1.64155720e+00
  1.20500182e+00 -2.12712541e+00 -1.90016019e-01 -2.22898981e+00
  2.15790119e+00  1.06036304e+00 -4.05014109e-02  1.38517453e+00
  2.46464085e+01]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.214722569928
gradient value of function right now is: [ 2.08298030e-09  1.86236642e-10  2.08182042e-09  2.08206549e-09
 -2.07818260e-09 -1.85808953e-10 -2.07702537e-09 -2.07726988e-09
  3.53535417e-11  4.45206173e-12  3.45575885e-11  3.67195298e-11
  2.32324553e-10  2.92943583e-11  2.27133820e-10  2.41317361e-10
  3.81555948e-11  4.80511603e-12  3.72967312e-11  3.96299306e-11
  3.85857384e-11  4.85912317e-12  3.77171101e-11  4.00766229e-11
 -7.61380246e-12 -2.19833627e-12 -8.66674560e-12 -1.48151256e-12
 -1.48054837e-12 -3.59278701e-13 -1.61337753e-12 -2.73520120e-13
  1.86192712e-11  5.77468269e-12  2.16194919e-11  3.70538385e-12
  7.85199526e-13  3.02449535e-13  9.74311129e-13  1.68765959e-13
  1.60921238e-12  2.00736435e-12  1.06695218e-12  1.91878448e-12
  9.41604162e-13  1.14150745e-12  5.49266081e-13  9.77388598e-13
  1.24161818e-12  1.48920076e-12  5.50982276e-13  1.03277036e-12
  1.71168426e-12  1.99690062e-12  6.43266415e-13  1.18892815e-12
  3.46978376e-13  6.76388555e-14 -7.79341296e-14 -2.15666675e-14
  6.69091644e-16 -1.93696168e-14 -2.00240977e-13 -3.78199960e-14
  1.09932870e+00]
supnorm grad right now is: 1.0993287003468868
Weights right now are: 
[-5.19858101e+00 -7.89816667e-01 -4.14196061e+00 -4.98701521e+00
  5.45314996e+00  6.81124995e-01  4.54089812e+00  4.27098707e+00
 -2.30445333e+00 -9.72296595e-01 -2.32995084e+00 -2.04824318e+00
  1.57693146e+00  5.04950718e-01 -2.58516894e-02  8.43569942e-01
 -1.41364983e+00 -6.22796465e-01 -2.76651027e+00 -2.24632552e+00
 -2.10667526e+00 -1.10135973e+00 -2.49870543e+00 -1.82816019e+00
 -1.02320878e+00 -8.93933864e-01 -1.75981206e+00 -9.85705659e-01
  4.47109820e-01  1.45416669e+00  1.49937613e+00  5.13119940e-01
 -1.12751210e+00 -6.74283372e-01 -1.33481325e+00 -1.29455398e+00
 -2.50310075e+00 -1.43894509e+00 -1.25639239e+00 -1.08844664e+00
 -1.00759161e+00 -9.58262938e-01 -7.80100247e-02  1.61510724e-01
  4.98338859e-01  1.31221669e+00  1.34250319e-02  3.74487522e-01
 -1.47314572e+00 -4.37478176e-01 -4.43359059e-01 -1.59626437e+00
  4.60164190e-01  1.21226461e+00  4.92151780e-01  1.64155478e+00
  1.20500111e+00 -2.12712555e+00 -1.90015860e-01 -2.22898977e+00
  2.15790119e+00  1.06036308e+00 -4.05010034e-02  1.38517461e+00
  2.50521594e+01]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.178389943674
gradient value of function right now is: [ 2.03969694e-09  1.82593059e-10  2.03856134e-09  2.03880128e-09
 -2.04406308e-09 -1.82980898e-10 -2.04292511e-09 -2.04316555e-09
  3.47208386e-11  4.37196226e-12  3.39390923e-11  3.60622779e-11
  2.28329907e-10  2.87879411e-11  2.23228190e-10  2.37167452e-10
  3.74802646e-11  4.71961505e-12  3.66365649e-11  3.89283962e-11
  3.78904461e-11  4.77108960e-12  3.70374146e-11  3.93543502e-11
 -7.48312241e-12 -2.16368690e-12 -8.52114463e-12 -1.45684252e-12
 -1.45932937e-12 -3.54758238e-13 -1.59090364e-12 -2.69746944e-13
  1.82886625e-11  5.68035287e-12  2.12439697e-11  3.64165190e-12
  7.70861397e-13  2.97406090e-13  9.57007818e-13  1.65805942e-13
  1.57900373e-12  1.97011879e-12  1.05075935e-12  1.88909571e-12
  9.24494842e-13  1.12094325e-12  5.41128637e-13  9.62651749e-13
  1.21855050e-12  1.46175620e-12  5.42627349e-13  1.01665320e-12
  1.67966894e-12  1.95978433e-12  6.33445531e-13  1.17025721e-12
  3.40745464e-13  6.53954882e-14 -7.66325623e-14 -2.09697420e-14
  6.77851902e-16 -1.90358699e-14 -1.96740445e-13 -3.62239243e-14
 -1.45991755e+00]
supnorm grad right now is: 1.4599175492562584
Weights right now are: 
[-5.20270611e+00 -7.90185705e-01 -4.14608341e+00 -4.99113850e+00
  5.45727497e+00  6.81494026e-01  4.54502084e+00  4.27511028e+00
 -2.30452344e+00 -9.72305425e-01 -2.33001938e+00 -2.04831600e+00
  1.57647053e+00  5.04892595e-01 -2.63023311e-02  8.43091161e-01
 -1.41372551e+00 -6.22805996e-01 -2.76658424e+00 -2.24640413e+00
 -2.10675178e+00 -1.10136937e+00 -2.49878023e+00 -1.82823967e+00
 -1.02319367e+00 -8.93929501e-01 -1.75979486e+00 -9.85702719e-01
  4.47112763e-01  1.45416741e+00  1.49937934e+00  5.13120484e-01
 -1.12754904e+00 -6.74294826e-01 -1.33485613e+00 -1.29456134e+00
 -2.50310231e+00 -1.43894569e+00 -1.25639432e+00 -1.08844698e+00
 -1.00759480e+00 -9.58266919e-01 -7.80121369e-02  1.61506920e-01
  4.98336992e-01  1.31221442e+00  1.34239444e-02  3.74485584e-01
 -1.47314818e+00 -4.37481131e-01 -4.43360150e-01 -1.59626641e+00
  4.60160794e-01  1.21226065e+00  4.92150506e-01  1.64155242e+00
  1.20500043e+00 -2.12712569e+00 -1.90015705e-01 -2.22898973e+00
  2.15790119e+00  1.06036312e+00 -4.05006058e-02  1.38517468e+00
  2.48754981e+01]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.113469844837
gradient value of function right now is: [ 1.99236966e-09  1.78565749e-10  1.99126069e-09  1.99149501e-09
 -1.98753792e-09 -1.78134866e-10 -1.98643158e-09 -1.98666535e-09
  3.38571597e-11  4.26282664e-12  3.30948292e-11  3.51651506e-11
  2.22905988e-10  2.81018120e-11  2.17925416e-10  2.31533175e-10
  3.65515978e-11  4.60225543e-12  3.57287659e-11  3.79637594e-11
  3.69597511e-11  4.65350761e-12  3.61276610e-11  3.83876211e-11
 -7.30947555e-12 -2.11529857e-12 -8.32562319e-12 -1.42311600e-12
 -1.43125523e-12 -3.48435658e-13 -1.56086579e-12 -2.64619763e-13
  1.78400626e-11  5.54612408e-12  2.07291399e-11  3.55252673e-12
  7.49949671e-13  2.89787149e-13  9.31577550e-13  1.61351167e-13
  1.53869602e-12  1.91992631e-12  1.02730136e-12  1.84515291e-12
  9.01399268e-13  1.09302849e-12  5.29293443e-13  9.40755651e-13
  1.18692123e-12  1.42401080e-12  5.30461885e-13  9.92898644e-13
  1.63594629e-12  1.90912778e-12  6.19321320e-13  1.14316458e-12
  3.32218818e-13  6.39535443e-14 -7.49083242e-14 -2.05239830e-14
  6.39373812e-16 -1.85881168e-14 -1.92051649e-13 -3.54482078e-14
 -1.95289071e+00]
supnorm grad right now is: 1.9528907095970918
Weights right now are: 
[-5.20671741e+00 -7.90545001e-01 -4.15009248e+00 -4.99514804e+00
  5.46128635e+00  6.81853329e-01  4.54902998e+00  4.27911990e+00
 -2.30459167e+00 -9.72314016e-01 -2.33008607e+00 -2.04838686e+00
  1.57602159e+00  5.04835992e-01 -2.67412398e-02  8.42624846e-01
 -1.41379916e+00 -6.22815271e-01 -2.76665624e+00 -2.24648063e+00
 -2.10682625e+00 -1.10137874e+00 -2.49885302e+00 -1.82831701e+00
 -1.02317895e+00 -8.93925245e-01 -1.75977810e+00 -9.85699853e-01
  4.47115640e-01  1.45416811e+00  1.49938247e+00  5.13121015e-01
 -1.12758498e+00 -6.74305990e-01 -1.33489788e+00 -1.29456849e+00
 -2.50310382e+00 -1.43894627e+00 -1.25639620e+00 -1.08844730e+00
 -1.00759790e+00 -9.58270792e-01 -7.80142014e-02  1.61503208e-01
  4.98335174e-01  1.31221222e+00  1.34228810e-02  3.74483692e-01
 -1.47315058e+00 -4.37484004e-01 -4.43361217e-01 -1.59626841e+00
  4.60157494e-01  1.21225680e+00  4.92149261e-01  1.64155012e+00
  1.20499976e+00 -2.12712581e+00 -1.90015555e-01 -2.22898969e+00
  2.15790119e+00  1.06036316e+00 -4.05002190e-02  1.38517475e+00
  2.48649371e+01]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.20153558464
gradient value of function right now is: [ 1.93612901e-09  1.73713545e-10  1.93505183e-09  1.93527946e-09
 -1.94074571e-09 -1.74127001e-10 -1.93966598e-09 -1.93989415e-09
  3.29935012e-11  4.15489392e-12  3.22515151e-11  3.42685092e-11
  2.17416117e-10  2.74147228e-11  2.12563986e-10  2.25833230e-10
  3.56264801e-11  4.48664791e-12  3.48254462e-11  3.70033143e-11
  3.60116578e-11  4.53499483e-12  3.52018788e-11  3.74033096e-11
 -7.13688037e-12 -2.06023356e-12 -8.12335179e-12 -1.38874845e-12
 -1.40311426e-12 -3.41118113e-13 -1.52963750e-12 -2.59376319e-13
  1.73983287e-11  5.39451613e-12  2.02000365e-11  3.46237111e-12
  7.29541378e-13  2.81199781e-13  9.05448583e-13  1.56849798e-13
  1.50120358e-12  1.87262705e-12  9.95068397e-13  1.78951679e-12
  8.80409856e-13  1.06716459e-12  5.12921827e-13  9.12716553e-13
  1.15958259e-12  1.39066187e-12  5.13934602e-13  9.63436411e-13
  1.59870852e-12  1.86487790e-12  6.00042958e-13  1.10913865e-12
  3.23562607e-13  6.29166175e-14 -7.30211289e-14 -2.00926891e-14
  6.14037391e-16 -1.80759054e-14 -1.86850728e-13 -3.52638004e-14
  1.25341148e+00]
supnorm grad right now is: 1.2534114757773158
Weights right now are: 
[-5.21064048e+00 -7.90896794e-01 -4.15401336e+00 -4.99906939e+00
  5.46520932e+00  6.82205113e-01  4.55295077e+00  4.28304115e+00
 -2.30465843e+00 -9.72322422e-01 -2.33015133e+00 -2.04845620e+00
  1.57558187e+00  5.04780549e-01 -2.71711405e-02  8.42168104e-01
 -1.41387124e+00 -6.22824348e-01 -2.76672670e+00 -2.24655549e+00
 -2.10689912e+00 -1.10138792e+00 -2.49892425e+00 -1.82839270e+00
 -1.02316453e+00 -8.93921076e-01 -1.75976168e+00 -9.85697045e-01
  4.47118470e-01  1.45416879e+00  1.49938556e+00  5.13121539e-01
 -1.12762018e+00 -6.74316914e-01 -1.33493875e+00 -1.29457550e+00
 -2.50310530e+00 -1.43894684e+00 -1.25639804e+00 -1.08844762e+00
 -1.00760094e+00 -9.58274581e-01 -7.80162174e-02  1.61499581e-01
  4.98333395e-01  1.31221006e+00  1.34218421e-02  3.74481843e-01
 -1.47315292e+00 -4.37486816e-01 -4.43362259e-01 -1.59627037e+00
  4.60154264e-01  1.21225303e+00  4.92148045e-01  1.64154788e+00
  1.20499910e+00 -2.12712594e+00 -1.90015407e-01 -2.22898964e+00
  2.15790119e+00  1.06036320e+00 -4.04998400e-02  1.38517482e+00
  2.50792630e+01]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16003.946974638797
gradient value of function right now is: [ 1.88691453e-09  1.69481826e-10  1.88586511e-09  1.88608689e-09
 -1.89171442e-09 -1.69912045e-10 -1.89066235e-09 -1.89088469e-09
  3.21712131e-11  4.05167689e-12  3.14482301e-11  3.34146438e-11
  2.12213689e-10  2.67608361e-11  2.07480988e-10  2.20430667e-10
  3.47436912e-11  4.37583430e-12  3.39630576e-11  3.60866242e-11
  3.51170496e-11  4.42269724e-12  3.43279439e-11  3.64743459e-11
 -6.97226470e-12 -2.01034523e-12 -7.93346783e-12 -1.35623738e-12
 -1.37625870e-12 -3.34513283e-13 -1.50027551e-12 -2.54403741e-13
  1.69751707e-11  5.25656008e-12  1.97015856e-11  3.37676224e-12
  7.09841176e-13  2.73334167e-13  8.80712748e-13  1.52554672e-13
  1.46453266e-12  1.82658304e-12  9.67660895e-13  1.74079168e-12
  8.59630206e-13  1.04176514e-12  4.99024437e-13  8.88245380e-13
  1.13186243e-12  1.35717551e-12  4.99849524e-13  9.37483206e-13
  1.56068702e-12  1.82022401e-12  5.83669383e-13  1.07935308e-12
  3.15386041e-13  6.18706728e-14 -7.12953962e-14 -1.97028632e-14
  5.78716539e-16 -1.76108898e-14 -1.82117914e-13 -3.49649825e-14
  2.99096743e+00]
supnorm grad right now is: 2.990967427961463
Weights right now are: 
[-5.21447125e+00 -7.91240706e-01 -4.15784201e+00 -5.00289848e+00
  5.46904006e+00  6.82549022e-01  4.55677938e+00  4.28687020e+00
 -2.30472366e+00 -9.72330635e-01 -2.33021509e+00 -2.04852395e+00
  1.57515185e+00  5.04726333e-01 -2.75915609e-02  8.41721436e-01
 -1.41394168e+00 -6.22833217e-01 -2.76679555e+00 -2.24662865e+00
 -2.10697033e+00 -1.10139689e+00 -2.49899385e+00 -1.82846666e+00
 -1.02315041e+00 -8.93916993e-01 -1.75974560e+00 -9.85694297e-01
  4.47121248e-01  1.45416947e+00  1.49938859e+00  5.13122053e-01
 -1.12765457e+00 -6.74327600e-01 -1.33497871e+00 -1.29458235e+00
 -2.50310674e+00 -1.43894740e+00 -1.25639983e+00 -1.08844793e+00
 -1.00760390e+00 -9.58278281e-01 -7.80181916e-02  1.61496031e-01
  4.98331656e-01  1.31220795e+00  1.34208243e-02  3.74480031e-01
 -1.47315521e+00 -4.37489561e-01 -4.43363278e-01 -1.59627228e+00
  4.60151110e-01  1.21224935e+00  4.92146854e-01  1.64154568e+00
  1.20499846e+00 -2.12712606e+00 -1.90015262e-01 -2.22898960e+00
  2.15790119e+00  1.06036323e+00 -4.04994699e-02  1.38517489e+00
  2.51789687e+01]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.258636220362
gradient value of function right now is: [ 1.87380900e-09  1.68405441e-10  1.87276684e-09  1.87298708e-09
 -1.86816173e-09 -1.67902094e-10 -1.86712263e-09 -1.86734222e-09
  3.18716467e-11  4.01325779e-12  3.11549112e-11  3.31032801e-11
  2.10357249e-10  2.65223945e-11  2.05662891e-10  2.18500974e-10
  3.44203557e-11  4.33436244e-12  3.36464607e-11  3.57505540e-11
  3.48011082e-11  4.38216776e-12  3.40185889e-11  3.61459580e-11
 -6.91044758e-12 -1.99745210e-12 -7.86845925e-12 -1.34505164e-12
 -1.36611676e-12 -3.32855253e-13 -1.49010734e-12 -2.52649796e-13
  1.68153454e-11  5.22045444e-12  1.95304283e-11  3.34737746e-12
  7.02586472e-13  2.71321774e-13  8.72526345e-13  1.51159072e-13
  1.44894626e-12  1.80799831e-12  9.63020810e-13  1.73207145e-12
  8.50405911e-13  1.03111453e-12  4.96706379e-13  8.84020524e-13
  1.11856392e-12  1.34197793e-12  4.97681930e-13  9.32824316e-13
  1.54189512e-12  1.79932922e-12  5.81224967e-13  1.07419991e-12
  3.12843418e-13  6.07220048e-14 -7.08302571e-14 -1.94385243e-14
  5.73702703e-16 -1.74486624e-14 -1.80920002e-13 -3.38333623e-14
  5.73939263e-02]
supnorm grad right now is: 0.057393926274915574
Weights right now are: 
[-5.21822204e+00 -7.91577803e-01 -4.16159071e+00 -5.00664762e+00
  5.47279090e+00  6.82886124e-01  4.56052813e+00  4.29061940e+00
 -2.30478755e+00 -9.72338681e-01 -2.33027755e+00 -2.04859032e+00
  1.57473019e+00  5.04673169e-01 -2.80038087e-02  8.41283455e-01
 -1.41401068e+00 -6.22841907e-01 -2.76686301e+00 -2.24670032e+00
 -2.10704009e+00 -1.10140567e+00 -2.49906204e+00 -1.82853911e+00
 -1.02313656e+00 -8.93912990e-01 -1.75972983e+00 -9.85691601e-01
  4.47123985e-01  1.45417014e+00  1.49939157e+00  5.13122559e-01
 -1.12768828e+00 -6.74338066e-01 -1.33501786e+00 -1.29458906e+00
 -2.50310815e+00 -1.43894794e+00 -1.25640158e+00 -1.08844823e+00
 -1.00760681e+00 -9.58281906e-01 -7.80201221e-02  1.61492558e-01
  4.98329951e-01  1.31220588e+00  1.34198287e-02  3.74478259e-01
 -1.47315745e+00 -4.37492252e-01 -4.43364276e-01 -1.59627415e+00
  4.60148017e-01  1.21224574e+00  4.92145689e-01  1.64154352e+00
  1.20499783e+00 -2.12712618e+00 -1.90015120e-01 -2.22898957e+00
  2.15790118e+00  1.06036327e+00 -4.04991073e-02  1.38517496e+00
  2.49843003e+01]
(65,)
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.258747811264
gradient value of function right now is: [ 1.85318314e-09  1.66641905e-10  1.85215259e-09  1.85237038e-09
 -1.84802143e-09 -1.66181707e-10 -1.84699367e-09 -1.84721087e-09
  3.15325384e-11  3.97052375e-12  3.08235266e-11  3.27510833e-11
  2.08212058e-10  2.62517192e-11  2.03566227e-10  2.16272849e-10
  3.40565633e-11  4.28851550e-12  3.32909533e-11  3.53727197e-11
  3.44319229e-11  4.33564398e-12  3.36578116e-11  3.57625240e-11
 -6.84169638e-12 -1.97768705e-12 -7.79030831e-12 -1.33167749e-12
 -1.35482358e-12 -3.30221552e-13 -1.47791539e-12 -2.50584546e-13
  1.66395713e-11  5.16611126e-12  1.93265692e-11  3.31238921e-12
  6.94575236e-13  2.68284728e-13  8.62641554e-13  1.49444422e-13
  1.43338073e-12  1.78854538e-12  9.52893106e-13  1.71371789e-12
  8.41554807e-13  1.02035314e-12  4.91583391e-13  8.74838603e-13
  1.10665992e-12  1.32767095e-12  4.92465633e-13  9.22968623e-13
  1.52549401e-12  1.78016744e-12  5.75148385e-13  1.06288393e-12
  3.09451696e-13  6.00580828e-14 -7.01219047e-14 -1.92334659e-14
  5.63871584e-16 -1.72667291e-14 -1.79005540e-13 -3.34860148e-14
 -1.83467340e-02]
supnorm grad right now is: 0.018346734036924005
Weights right now are: 
[-5.22187414e+00 -7.91906396e-01 -4.16524078e+00 -5.01029812e+00
  5.47644301e+00  6.83214718e-01  4.56417821e+00  4.29426991e+00
 -2.30484980e+00 -9.72346519e-01 -2.33033840e+00 -2.04865497e+00
  1.57431904e+00  5.04621333e-01 -2.84057853e-02  8.40856386e-01
 -1.41407793e+00 -6.22850374e-01 -2.76692873e+00 -2.24677016e+00
 -2.10710806e+00 -1.10141423e+00 -2.49912848e+00 -1.82860971e+00
 -1.02312305e+00 -8.93909080e-01 -1.75971445e+00 -9.85688970e-01
  4.47126663e-01  1.45417079e+00  1.49939449e+00  5.13123054e-01
 -1.12772113e+00 -6.74348276e-01 -1.33505603e+00 -1.29459560e+00
 -2.50310952e+00 -1.43894847e+00 -1.25640328e+00 -1.08844853e+00
 -1.00760963e+00 -9.58285436e-01 -7.80220056e-02  1.61489168e-01
  4.98328290e-01  1.31220387e+00  1.34188569e-02  3.74476528e-01
 -1.47315964e+00 -4.37494873e-01 -4.43365250e-01 -1.59627597e+00
  4.60145008e-01  1.21224223e+00  4.92144552e-01  1.64154142e+00
  1.20499722e+00 -2.12712630e+00 -1.90014981e-01 -2.22898953e+00
  2.15790118e+00  1.06036330e+00 -4.04987534e-02  1.38517502e+00
  2.49924828e+01]
(65,)
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.258708864427
gradient value of function right now is: [ 1.83293071e-09  1.64908609e-10  1.83191155e-09  1.83212694e-09
 -1.83618469e-09 -1.65200612e-10 -1.83516374e-09 -1.83537951e-09
  3.12671627e-11  3.93730556e-12  3.05643835e-11  3.24755535e-11
  2.06515527e-10  2.60389673e-11  2.01909219e-10  2.14511250e-10
  3.37739292e-11  4.25314319e-12  3.30149633e-11  3.50792736e-11
  3.41359020e-11  4.29856184e-12  3.33687186e-11  3.54551657e-11
 -6.78728781e-12 -1.96107718e-12 -7.72723544e-12 -1.32111084e-12
 -1.34583600e-12 -3.28010408e-13 -1.46805207e-12 -2.48960534e-13
  1.65030438e-11  5.12097210e-12  1.91646332e-11  3.28513869e-12
  6.88667224e-13  2.65820673e-13  8.55097508e-13  1.48150852e-13
  1.42160370e-12  1.77392199e-12  9.44022788e-13  1.69763739e-12
  8.35022956e-13  1.01238901e-12  4.87085784e-13  8.66730404e-13
  1.09832778e-12  1.31758560e-12  4.87722094e-13  9.14243600e-13
  1.51409796e-12  1.76665984e-12  5.69535461e-13  1.05267294e-12
  3.06863467e-13  5.92624636e-14 -6.95357041e-14 -1.89788573e-14
  5.67071522e-16 -1.71006451e-14 -1.77337876e-13 -3.31221058e-14
 -3.86429650e-02]
supnorm grad right now is: 0.03864296504650305
Weights right now are: 
[-5.22546535e+00 -7.92229833e-01 -4.16882999e+00 -5.01388776e+00
  5.48003421e+00  6.83538153e-01  4.56776741e+00  4.29785953e+00
 -2.30491104e+00 -9.72354230e-01 -2.33039825e+00 -2.04871857e+00
  1.57391419e+00  5.04570285e-01 -2.88016075e-02  8.40435862e-01
 -1.41414407e+00 -6.22858704e-01 -2.76699340e+00 -2.24683887e+00
 -2.10717492e+00 -1.10142265e+00 -2.49919384e+00 -1.82867915e+00
 -1.02310974e+00 -8.93905235e-01 -1.75969929e+00 -9.85686379e-01
  4.47129313e-01  1.45417144e+00  1.49939739e+00  5.13123545e-01
 -1.12775346e+00 -6.74358304e-01 -1.33509357e+00 -1.29460204e+00
 -2.50311087e+00 -1.43894899e+00 -1.25640495e+00 -1.08844882e+00
 -1.00761242e+00 -9.58288910e-01 -7.80238503e-02  1.61485849e-01
  4.98326653e-01  1.31220189e+00  1.34179047e-02  3.74474833e-01
 -1.47316179e+00 -4.37497453e-01 -4.43366203e-01 -1.59627776e+00
  4.60142042e-01  1.21223877e+00  4.92143438e-01  1.64153936e+00
  1.20499662e+00 -2.12712642e+00 -1.90014845e-01 -2.22898949e+00
  2.15790118e+00  1.06036333e+00 -4.04984061e-02  1.38517509e+00
  2.51302296e+01]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.258486893037
gradient value of function right now is: [ 1.81325584e-09  1.63224389e-10  1.81224774e-09  1.81246080e-09
 -1.81710056e-09 -1.63556844e-10 -1.81609061e-09 -1.81630406e-09
  3.09407596e-11  3.89633413e-12  3.02457461e-11  3.21366326e-11
  2.04469582e-10  2.57817391e-11  1.99911501e-10  2.12386662e-10
  3.34236933e-11  4.20918262e-12  3.26730693e-11  3.47156076e-11
  3.37808685e-11  4.25398138e-12  3.30220974e-11  3.50865091e-11
 -6.72373006e-12 -1.94068494e-12 -7.65270856e-12 -1.30836649e-12
 -1.33602144e-12 -3.25546889e-13 -1.45727630e-12 -2.47131817e-13
  1.63367362e-11  5.06273376e-12  1.89643111e-11  3.25087027e-12
  6.80442698e-13  2.62247333e-13  8.44436712e-13  1.46323254e-13
  1.40787968e-12  1.75511533e-12  9.31116936e-13  1.67490796e-12
  8.27444299e-13  1.00234832e-12  4.80546596e-13  8.55384670e-13
  1.08832102e-12  1.30441716e-12  4.81412731e-13  9.02331971e-13
  1.50065076e-12  1.74969760e-12  5.62359378e-13  1.03930195e-12
  3.02544193e-13  5.86727851e-14 -6.86900428e-14 -1.87985777e-14
  5.32134475e-16 -1.69013497e-14 -1.75126858e-13 -3.29341668e-14
 -8.93740660e-02]
supnorm grad right now is: 0.08937406599708723
Weights right now are: 
[-5.22896745e+00 -7.92545580e-01 -4.17233015e+00 -5.01738832e+00
  5.48353626e+00  6.83853896e-01  4.57126751e+00  4.30136004e+00
 -2.30497078e+00 -9.72361753e-01 -2.33045666e+00 -2.04878063e+00
  1.57351885e+00  5.04520439e-01 -2.91881387e-02  8.40025209e-01
 -1.41420863e+00 -6.22866833e-01 -2.76705650e+00 -2.24690592e+00
 -2.10724016e+00 -1.10143086e+00 -2.49925762e+00 -1.82874692e+00
 -1.02309673e+00 -8.93901475e-01 -1.75968448e+00 -9.85683847e-01
  4.47131910e-01  1.45417207e+00  1.49940022e+00  5.13124025e-01
 -1.12778502e+00 -6.74368101e-01 -1.33513022e+00 -1.29460832e+00
 -2.50311218e+00 -1.43894950e+00 -1.25640658e+00 -1.08844910e+00
 -1.00761513e+00 -9.58292298e-01 -7.80256544e-02  1.61482603e-01
  4.98325057e-01  1.31219995e+00  1.34169732e-02  3.74473174e-01
 -1.47316389e+00 -4.37499970e-01 -4.43367136e-01 -1.59627951e+00
  4.60139150e-01  1.21223539e+00  4.92142349e-01  1.64153735e+00
  1.20499603e+00 -2.12712653e+00 -1.90014712e-01 -2.22898946e+00
  2.15790118e+00  1.06036337e+00 -4.04980668e-02  1.38517515e+00
  2.48148197e+01]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -16004.258725969377
gradient value of function right now is: [ 1.79377144e-09  1.61553987e-10  1.79277431e-09  1.79298505e-09
 -1.79575292e-09 -1.61730809e-10 -1.79475472e-09 -1.79496569e-09
  3.06031674e-11  3.85377360e-12  2.99155690e-11  3.17860022e-11
  2.02318417e-10  2.55102095e-11  1.97807374e-10  2.10152287e-10
  3.30608469e-11  4.16343490e-12  3.23181835e-11  3.43387463e-11
  3.34149164e-11  4.20785027e-12  3.26642117e-11  3.47064256e-11
 -6.65338522e-12 -1.92222133e-12 -7.57453517e-12 -1.29505983e-12
 -1.32381202e-12 -3.22862685e-13 -1.44425669e-12 -2.44934931e-13
  1.61596582e-11  5.01343393e-12  1.87645366e-11  3.21675849e-12
  6.72846821e-13  2.59699507e-13  8.35411322e-13  1.44762445e-13
  1.39143395e-12  1.73641768e-12  9.22946366e-13  1.66055202e-12
  8.17819854e-13  9.91576500e-13  4.76393878e-13  8.48120318e-13
  1.07517920e-12  1.28990268e-12  4.77019560e-13  8.94578102e-13
  1.48217589e-12  1.72952119e-12  5.57123652e-13  1.03013967e-12
  3.00456063e-13  5.80067399e-14 -6.81923807e-14 -1.85802863e-14
  5.43592538e-16 -1.67117042e-14 -1.73676137e-13 -3.24570379e-14
 -2.81045539e-02]
supnorm grad right now is: 0.02810455394123335
Weights right now are: 
[-5.23240021e+00 -7.92855392e-01 -4.17576099e+00 -5.02081958e+00
  5.48696899e+00  6.84163706e-01  4.57469834e+00  4.30479127e+00
 -2.30502938e+00 -9.72369131e-01 -2.33051394e+00 -2.04884148e+00
  1.57313081e+00  5.04471515e-01 -2.95675278e-02  8.39622145e-01
 -1.41427194e+00 -6.22874805e-01 -2.76711839e+00 -2.24697168e+00
 -2.10730415e+00 -1.10143892e+00 -2.49932018e+00 -1.82881338e+00
 -1.02308396e+00 -8.93897782e-01 -1.75966994e+00 -9.85681361e-01
  4.47134467e-01  1.45417270e+00  1.49940301e+00  5.13124498e-01
 -1.12781598e+00 -6.74377713e-01 -1.33516618e+00 -1.29461448e+00
 -2.50311346e+00 -1.43894999e+00 -1.25640817e+00 -1.08844938e+00
 -1.00761780e+00 -9.58295622e-01 -7.80274236e-02  1.61479420e-01
  4.98323490e-01  1.31219805e+00  1.34160592e-02  3.74471547e-01
 -1.47316594e+00 -4.37502438e-01 -4.43368051e-01 -1.59628123e+00
  4.60136315e-01  1.21223208e+00  4.92141280e-01  1.64153537e+00
  1.20499546e+00 -2.12712664e+00 -1.90014580e-01 -2.22898942e+00
  2.15790118e+00  1.06036340e+00 -4.04977337e-02  1.38517521e+00
  2.52354538e+01]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1551.6347824818406
W_T_median: 1406.0687944593828
W_T_pctile_5: 624.1985510152161
W_T_CVAR_5_pct: 487.9109330067564
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 10.0
F value: -16004.258725969377
-----------------------------------------------
