tracing parameter entered from terminal:  0.9


############# Defined asset basket #################
timeseries_basket.keys() = 
dict_keys(['basket_type', 'basket_id', 'basket_desc', 'basket_label', 'basket_columns', 'basket_timeseries_names'])
timeseries_basket['basket_type'] = asset
timeseries_basket['basket_id'] = basic_T30_VWD
timeseries_basket['basket_desc'] = CRSP data: T30 and VWD
timeseries_basket['basket_columns'] = 
['T30_real_ret', 'VWD_real_ret']
############# End: defined asset  basket #################
-----------------------------------------------
No need to read market data.
-----------------------------------------------
5.0% of MC simulations done.
10.0% of MC simulations done.
15.0% of MC simulations done.
20.0% of MC simulations done.
25.0% of MC simulations done.
30.0% of MC simulations done.
35.0% of MC simulations done.
40.0% of MC simulations done.
45.0% of MC simulations done.
50.0% of MC simulations done.
55.00000000000001% of MC simulations done.
60.0% of MC simulations done.
65.0% of MC simulations done.
70.0% of MC simulations done.
75.0% of MC simulations done.
80.0% of MC simulations done.
85.0% of MC simulations done.
90.0% of MC simulations done.
95.0% of MC simulations done.
100.0% of MC simulations done.
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes activation x_l(weights)  \
0        obj.layers[0]        0   input_layer       2       None         None   
1        obj.layers[1]        1  hidden_layer    None       None         None   
2        obj.layers[2]        2  hidden_layer    None       None         None   
3        obj.layers[3]        3  hidden_layer    None       None         None   
4        obj.layers[4]        4  hidden_layer    None       None         None   
5        obj.layers[5]        5  output_layer       2       None         None   

  add_bias b_l(biases)  
0    False        None  
1    False        None  
2    False        None  
3    False        None  
4    False        None  
5    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------
Neural_Network object 'obj' has instance attribute obj.layers.
obj.layers is a list of 'Neural_Network_Layer' objects with following attributes:

  obj.layers[layer_id] layer_id   description n_nodes        activation  \
0        obj.layers[0]        0   input_layer       2              None   
1        obj.layers[1]        1  hidden_layer       4  logistic_sigmoid   
2        obj.layers[2]        2  hidden_layer       4  logistic_sigmoid   
3        obj.layers[3]        3  hidden_layer       4  logistic_sigmoid   
4        obj.layers[4]        4  hidden_layer       4  logistic_sigmoid   
5        obj.layers[5]        5  output_layer       2           softmax   

  x_l(weights) add_bias b_l(biases)  
0         None    False        None  
1       (2, 4)    False        None  
2       (4, 4)    False        None  
3       (4, 4)    False        None  
4       (4, 4)    False        None  
5       (4, 2)    False        None  

 Run 'update_layer' method of Neural_Network object to change layer attributes.
--------------------------------------------------------------------------------------------------
[-0.62277812  0.75294104  0.37108154 -0.23457045  0.87734683 -0.86163273
  0.02785573 -0.48145794 -0.54600176  0.39576202 -0.65000431 -0.36885567
  0.66919174 -0.62014212 -0.6576227  -0.09547811  0.44289714 -0.62745997
 -0.69254554 -0.71497204 -0.09160633 -0.70209214 -0.08649162 -0.03995664
  0.43014226  0.54196156 -0.18869499  0.3803182  -0.4213674   0.51582093
  0.719146   -0.41932646  0.60494673  0.54081414  0.80135845 -0.24869297
 -0.78078131  0.14937982  0.57187137  0.48684314 -0.81297698 -0.8032804
 -0.30872557  0.20747554 -0.27489946  0.56429979 -0.5811595  -0.16646221
 -0.44248831  0.58917257  0.54882857 -0.57567892 -0.30430046  0.43734894
 -0.41036775  0.8237008   0.69471977 -0.63290457 -0.75257106 -0.88717124
  0.98028969  0.25945333  0.60467509  0.43128316] (64,)
-----------------------------------------------
Selected results: ConstProp_strategy on TRAINING dataset
W_T_mean: 1261.0877712339752
W_T_median: 1222.733226526609
W_T_pctile_5: 834.028380700438
W_T_CVAR_5_pct: 747.2411321494716
-----------------------------------------------
Running Adam.
2.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1955.50592452235
gradient value of function right now is: [ 9.58295679e+00  8.04071867e+00  5.83567855e+00  7.26262581e+00
 -9.58295679e+00 -8.04071867e+00 -5.83567855e+00 -7.26262581e+00
  7.48724988e+00 -7.13720888e-02  8.00523981e-02  2.08811383e+00
 -3.55164715e+00 -1.06694650e-03 -9.30675516e-02 -1.06016574e+00
 -1.65857183e+00 -1.21268903e-03 -3.96448179e-02 -4.66491292e-01
 -2.62730036e+00 -1.67249002e-03 -6.78723902e-02 -7.71674052e-01
  4.17689221e-01  1.41167068e+00  5.98066688e+00  8.33295071e-01
 -1.83408626e-01 -2.65710304e-03 -7.53925104e-02 -1.20784329e-02
  6.63614359e-03  9.83546350e-02  5.42840299e-01  4.77560556e-02
  4.67609951e-01  8.16380908e-01  4.14041513e+00  4.37363116e-01
  1.03579872e-02  3.44109197e-02  4.11253750e-02  1.39638477e+00
 -1.45614841e+00 -6.89671202e-01 -1.90796126e+00 -7.03869075e+00
 -2.81161644e-01  1.70234029e-02 -4.08307758e-01 -2.85417467e+00
 -1.29828566e+00 -5.20290527e-01 -1.56528585e+00 -4.34066082e+00
 -1.18574230e+00  2.02700766e+00  4.79232036e+00 -6.44466963e+00
 -2.55591532e+00  3.33672264e+00  2.57481906e-02  1.02504560e-02
 -1.24516654e+01]
supnorm grad right now is: 12.451665427031728
Weights right now are: 
[-2.96978339  1.63444589  1.44853831  1.06346515  3.22435211 -1.74313758
 -1.04960104 -1.77949353  1.82490381 -6.5534901  -1.62359655  0.246603
  2.38500199  3.34666963  2.1537282   2.59757888  4.79679829  1.21728861
  1.9034142   3.23996613  2.9863      2.03502679  2.57119231  3.18936373
 -2.09166136  3.99152315  0.16408005  4.34105018 -3.41570776  6.72859949
  9.31113073  6.49647221 -1.88436488  5.43535264  5.2371524   3.7228345
 -3.04670149  4.01559811  2.2363176   4.04073549 15.42079655 -1.29464503
 13.07507725  1.7988823  -1.58008844 11.65189745 -2.66271134  1.45409588
 -0.87192186  2.82477752 -1.03049363 -1.33914261 -2.90222399 10.74093053
 -2.78805289  2.67415511  6.32016006  2.62573937  3.30796308 -1.17973853
  4.48135238  2.25464407 -3.86724888  7.87419475 28.17849756]
(65,)
4.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1958.932679507542
gradient value of function right now is: [ 2.99570343e+00  3.48637319e+00  3.13773943e+00  3.42528011e+00
 -2.99570343e+00 -3.48637319e+00 -3.13773943e+00 -3.42528011e+00
  1.15952362e-01 -5.81162634e-02 -8.23014279e-01 -8.66848914e-01
 -8.46593808e-01  1.24383714e-04 -4.81323931e-04 -7.01237676e-03
 -3.69447359e-01  1.05656452e-04  1.49735020e-03 -5.01457311e-04
 -6.87710824e-01  8.86620376e-05 -6.56777758e-04 -5.73061166e-03
  4.22238083e-02  7.41221369e-01  2.03192742e+00  1.50746929e-01
 -1.04673951e-02 -1.22472176e-03 -1.35070944e-01 -3.34145737e-04
 -7.27054279e-03  1.89070014e-02 -1.17361763e-01 -8.05476599e-04
  1.41028074e-02  4.39048458e-02  2.72489700e-02  1.78163925e-03
  1.75424476e-03  1.69581236e-02  4.91515776e-03  3.30463152e-02
 -3.92893049e-01 -6.72221255e-02 -5.19048392e-01 -1.03770608e+00
  5.32064986e-02  1.13559106e+00  6.31185614e-02 -1.86157457e-02
 -7.74436436e-01 -1.36853585e-01 -9.15919929e-01 -1.25704718e+00
 -5.11920402e-01  1.19045034e+00 -4.72189249e-01 -5.02620381e+00
 -7.25998333e-01  1.52934669e+00  1.01987208e-01  6.30022488e-02
 -4.60565590e-01]
supnorm grad right now is: 5.026203805085605
Weights right now are: 
[ -3.2864028    1.84220054   1.37017135   1.26190549   3.54097151
  -1.95089223  -0.97123408  -1.97793387   3.08939004 -10.52261061
  -1.19866011  -0.7741255    3.26057738   5.76982038   9.72900788
   7.19772278   5.10567077   2.68750523   6.6844071    5.84906566
   3.53961493   4.51240587   9.78896074   7.32884272  -2.45083368
   1.6793147   -0.30273584   9.79658438  -1.80580294   7.34072223
  16.24291146   6.67652754  -2.29609612  10.13539822   3.64407664
   6.21433756  -3.23571617   7.6430329    3.29013558   6.40156333
  21.74661903   9.55820793  16.5051259   -1.58500569  -1.57252639
  17.13988347  -3.13835436   1.38141138  -0.52425347   3.16174664
  -2.2587691   -1.11173937  -4.15691706  21.24134422  -4.06159451
   5.35007085   5.43750987   2.62025609   2.68002087  -1.55096089
   4.15471114   2.70912411  -2.03804829   6.9048305   28.21897184]
(65,)
6.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1959.4216603667035
gradient value of function right now is: [-3.60449477e-01 -7.50958288e-01 -9.13522695e-01 -7.82200571e-01
  3.60449477e-01  7.50958288e-01  9.13522695e-01  7.82200571e-01
  3.26064748e+00  6.49823995e-04  4.45687514e-01  4.84867866e-01
 -9.74394327e-01 -2.49370682e-07 -3.01481757e-02 -4.05601560e-02
 -1.94407787e-01 -2.48386391e-07 -8.67602540e-03 -1.11486886e-02
 -7.45114221e-01 -2.04050952e-07 -2.35329789e-02 -3.16505338e-02
 -3.60397219e-02 -1.78080450e-01 -1.18807524e+00 -5.18738032e-02
  1.13871113e-05  8.51009405e-06 -3.48273661e-03 -5.26881387e-08
  1.30907074e-02  7.85206630e-02  8.89941360e-01  1.15247272e-03
  1.13226500e-02  1.11110301e-01  9.10617729e-01  1.53461513e-03
  1.57804792e-03  1.85699785e-03  3.62670645e-03  2.14656843e-02
 -3.42324607e-01 -1.77330693e-01 -4.56171008e-01 -1.19664791e+00
 -2.86001475e-01 -3.53358049e-01 -3.73197305e-01 -1.06752176e+00
  9.70245785e-02 -6.71752454e-03  1.90907429e-01  3.17399453e-01
  2.52262314e-02 -1.94474253e-01  1.11860512e+00 -1.26126460e+00
 -3.57595021e-01  8.08852959e-02 -8.14828008e-02 -4.89736295e-02
 -3.72402291e+00]
supnorm grad right now is: 3.724022909245115
Weights right now are: 
[-3.71131347e+00  2.05962533e+00  1.29154776e+00  1.44935680e+00
  3.96588218e+00 -2.16831702e+00 -8.92610486e-01 -2.16538519e+00
  3.63827564e+00 -1.24600299e+01 -1.19462627e+00 -7.41402924e-01
  2.85642988e+00  7.37386544e+00  1.43311637e+01  1.18230448e+01
  4.14559831e+00  4.13727113e+00  1.11063522e+01  9.72862261e+00
  3.00537289e+00  5.87887632e+00  1.42041877e+01  1.17713904e+01
 -3.25116472e+00  2.48283230e-02 -1.21925896e+00  1.01874844e+01
  3.37516977e+00  1.42523952e+01  2.40328591e+01  1.33911144e+01
 -5.04293076e+00  1.09511736e+01  3.03711964e+00  1.35109179e+01
 -7.13329999e+00  6.49304406e+00  3.19143015e+00  1.16711535e+01
  2.67897856e+01  1.57668994e+01  1.85617054e+01 -7.64277567e-01
 -3.01808062e+00  1.96942943e+01 -4.25986057e+00  1.87192715e+00
 -4.11555343e-01  3.25383638e+00 -2.51577610e+00 -1.36416680e+00
 -4.95467602e+00  3.15037159e+01 -5.12245633e+00  6.07854288e+00
  5.51863260e+00  2.41896703e+00  3.11812419e+00 -1.70571266e+00
  4.41812995e+00  2.70153475e+00 -7.99427117e-01  6.30104678e+00
  2.84509527e+01]
(65,)
8.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1986.3300373294585
gradient value of function right now is: [ 4.06173298e-01 -9.10119152e-01 -5.89263755e-01 -1.06980061e+00
 -4.06173298e-01  9.10119152e-01  5.89263755e-01  1.06980061e+00
  1.03396355e+01  1.46595774e-01  4.87959539e+00  6.13794488e+00
 -2.29217579e+00 -1.28674082e-07 -1.61315845e-01 -2.99964317e-01
 -1.66915513e-01  1.52715201e-06  1.27489989e-03  2.21057011e-03
 -1.40383379e+00 -8.43049698e-08 -1.05821054e-01 -1.97324955e-01
 -5.82403174e-01  4.28350267e+00  1.75805522e+00  3.00618947e+00
  8.96896439e-06  3.37148692e-06  6.84748788e-02  7.06395906e-08
  8.26050609e-02  1.95483640e-01  5.13499116e+00  5.69050726e-02
  7.27380456e-02  3.01768357e-01  7.26121950e+00  8.81455818e-02
  1.51759554e-02  1.73829995e-01  3.21008526e-02  3.25838909e-01
 -6.67273393e-01 -2.59648795e-01 -1.66656136e+00 -2.33245117e+00
 -7.76836347e-01 -3.96230016e+00 -1.48160124e+00 -3.75485891e+00
 -1.09164302e+01 -5.99869132e-01 -2.28097081e+01 -2.33688924e+01
 -5.68937434e+00  2.61390475e+01  8.20738320e+00 -3.81045233e+01
 -2.97030761e+00  6.51103177e+00 -5.56330143e-01  9.45528503e-02
 -2.16249044e+01]
supnorm grad right now is: 38.104523292856676
Weights right now are: 
[-7.91714623  2.06862167 -0.62029256  1.33158941  8.17171494 -2.17731336
  1.01922983 -2.04761779  5.0794093  -6.89532457 -1.10247777 -0.63426501
  0.21494691  7.48981175 17.83225845 15.8496991   8.19164923  4.15023781
  6.42871656  8.29096321  0.53118592  5.96047729 17.82345984 15.96786441
  1.39444463 -0.15280492 -1.30343585  9.64552899  2.73539935 15.19629249
 34.75818511 13.64915546 -6.65488839  9.11930209  3.15203796  8.9948414
 -9.67086352  6.04031363  2.44084809 16.0084076  31.11549486 20.2482458
 16.82900665  0.79264471 -4.8359924  24.30859593 -2.59453498  4.73766907
 -0.20044322  3.57131599 -2.33430045 -1.19695125 -2.84227865 40.45692783
 -5.04749242  6.35245545  5.66292515  1.05703151  2.2142008  -1.83020381
  6.45030948  3.68952308  3.82558874  5.71779972 28.5014609 ]
(65,)
10.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1986.6710571784795
gradient value of function right now is: [ 1.04724043e+00  3.27092091e+00  1.84389270e-01  3.32338039e+00
 -1.04724043e+00 -3.27092091e+00 -1.84389270e-01 -3.32338039e+00
 -9.18151616e+00 -1.04282795e-01 -5.09896374e+00 -6.72797888e+00
  1.41986185e+00  7.08610405e-09  1.12736646e-01  2.77737900e-01
  1.42797514e-01 -2.38356651e-12  4.13763909e-03  2.78650979e-06
  7.09802060e-01  5.02789669e-09  7.14564486e-02  1.97762149e-01
  6.16163021e-01 -2.12156102e+00 -1.26063657e+01 -7.13483065e+00
 -3.09243124e-06 -2.07820386e-07 -4.59841687e-02 -4.56420781e-10
 -1.16373899e-01  5.77275926e-02 -4.23992382e+00  8.70849452e-01
 -1.21545875e-01 -5.46260396e-02 -8.44248846e+00 -9.30670483e-02
 -2.06058474e-02 -2.38362453e-01 -8.24266751e-02 -1.32521030e+00
  3.31431185e-01  9.85283647e-02  7.49740957e-02  2.14051605e-01
  2.00833834e-01  3.83238774e+00  5.38270764e-01  4.58855315e+00
  1.87257798e+01  8.25433328e-01  4.30537089e+01  4.36753422e+01
  7.64313557e+00 -4.17551146e+01 -1.11429624e+01  5.95721002e+01
  2.57147697e+00 -5.84493400e+00  1.34067635e+00 -4.22219197e-01
  2.32564244e+01]
supnorm grad right now is: 59.572100151336926
Weights right now are: 
[-7.52716371  2.69153084 -3.75156908  1.94280211  7.78173242 -2.80022253
  4.15050635 -2.6588305   4.89447385 -7.00805488 -1.18810627 -0.73616918
  0.92302837  7.49578848 19.86513406 18.29406868 24.10129355  4.16692265
 25.37922318  3.86663083  1.16385737  5.96400245 20.01564505 18.321885
  1.58701234  0.58552388 -1.39319863  8.7130442   2.48888691 15.17475684
 47.11022052 13.64584541 -6.68720688 16.20355504  3.46211339  2.46281155
 -9.85059351  4.40196373  2.74959557 28.72753701 34.92360255 20.16622386
  9.8193445   1.10166153 -6.21511785 26.789473   -1.43368422  6.45000988
  0.38489591  3.99089404 -1.86729858 -1.56537359 -2.55795064 46.5609763
 -5.16454142  6.23906935  6.67555857  1.0905091   1.87307993 -1.95360489
  9.04825483  4.66041063  2.88701729  5.18731825 28.44257172]
(65,)
12.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1990.7774221600428
gradient value of function right now is: [ 4.45140841e-01  4.45488288e-02 -1.83357961e-02  1.42593397e-02
 -4.45140841e-01 -4.45488288e-02  1.83357961e-02 -1.42593397e-02
  5.18741616e+00  3.29242705e-02  1.92180435e+00  2.45607337e+00
 -1.42378210e+00 -5.85131355e-10 -6.10123346e-02 -7.20544984e-02
 -1.73988349e-02  1.45704990e-22 -1.57565064e-04 -1.20834887e-09
 -1.11358103e+00 -4.48319271e-10 -4.88793841e-02 -5.59979371e-02
 -1.30503158e-01  8.16545780e-01 -1.36469776e+00  4.99427354e-01
  2.43376167e-06  1.89714421e-07  7.17685878e-03  6.02089718e-12
  1.46892755e-02  1.69729022e-02  2.16715745e+00  2.67175617e-01
  2.91851084e-02  3.71183059e-02  2.39447664e+00  2.25202274e-02
  2.41804246e-03  8.09961742e-02  5.54599237e-03  1.64462771e-01
 -4.75114478e-01 -3.91435293e-02 -7.44830086e-01 -7.56366535e-01
 -3.55546834e-01 -1.44729337e+00 -8.74955416e-01 -1.84025640e+00
 -3.38527295e+00 -2.19153770e-01 -3.05436240e+00 -3.08184456e+00
 -2.02344580e-01  4.40185969e+00  2.31512669e+00 -1.48046225e+01
 -1.75944733e-01  2.38728163e-01 -5.83548731e-01  3.42814767e-01
 -8.68296115e+00]
supnorm grad right now is: 14.804622518053534
Weights right now are: 
[-6.91008     3.10373042 -5.51569394  2.34673583  7.16464871 -3.21242211
  5.91463121 -3.06276421  4.93226495 -7.07514869 -0.55895296 -0.75738514
  1.27798215  7.49617113 20.49578281 20.45113035 44.13347202  4.16692265
 54.00389085  3.90577772  1.41123484  5.96426308 20.65562247 20.42659134
  2.22624558  0.81520948 -1.71766216  8.04949554  3.49977922 15.26372093
 59.11057915 13.64581711 -7.59642992 24.73037407  4.03825287  1.14174576
 -8.9121857  -2.16108007  3.11561669 35.41572617 42.29621377 18.13504449
  8.17923649  2.83960359 -9.40938357 23.552293   -0.48101578  7.44692428
  0.75542074  4.35912502 -1.58838233 -1.922028   -3.02377032 51.80750379
 -5.31861166  6.05175057  7.10256294  1.45399203  1.58496634 -1.96022894
 10.86943279  5.63134304  3.79985397  4.83598352 28.59461912]
(65,)
14.000000000000002% of gradient descent iterations done. Method = Adam
objective value function right now is: -1991.6122427943912
gradient value of function right now is: [ 3.20790832e-01  4.95604614e-01  7.74205934e-04  4.95046240e-01
 -3.20790832e-01 -4.95604614e-01 -7.74205934e-04 -4.95046240e-01
 -5.88439044e-03 -4.38837246e-02 -5.17536594e-01 -4.54951959e-01
 -3.03508623e-02  8.62080771e-11 -4.76311248e-03  4.59512606e-02
 -3.29400218e-03 -2.63088404e-29  1.06554111e-04  2.52480177e-10
 -4.78031254e-02  7.19653255e-11 -4.85175968e-03  3.77950882e-02
 -5.87272462e-02  7.51671095e-03 -1.71928197e+00 -6.89111662e-01
 -1.03006034e-06 -2.95869899e-07 -1.15443480e-02  3.81666400e-14
  4.64977825e-03  4.88227857e-03  2.48702028e-01  3.05269201e-01
  1.69130868e-02  9.27769418e-03 -1.52128615e+00  4.06453359e-03
 -3.88399146e-04  1.74190156e-02  1.49547667e-04  5.50165690e-02
 -7.09635361e-02 -2.72262176e-05 -1.89049940e-01 -1.86858328e-01
  3.63667106e-01  7.69186162e-01  3.19868150e-01  6.38180615e-01
  3.47893820e-01  1.81887561e-02  2.78847230e+00  2.88850617e+00
  8.61749284e-01 -2.19297003e+00 -1.95317710e+00  2.29295308e+00
  2.73061543e-01 -7.51180380e-01 -8.88602066e-02  1.08352321e-01
  2.46608891e+00]
supnorm grad right now is: 2.8885061693670067
Weights right now are: 
[ -7.35411347   3.4849536   -6.36395292   2.71347457   7.60868218
  -3.59364529   6.76289019  -3.42950295   4.93415505  -7.03731171
  -0.26446172  -1.21973325   1.55372963   7.4962148   21.31833634
  22.29381096  59.40849452   4.16692265  70.25824885   3.90710566
   1.62278559   5.96429336  21.46699875  22.28874611   0.3348107
   0.72736194  -1.61467995   7.85329096   4.15357219  15.51983708
  69.14769848  13.64581647 -10.39465455  34.93621743   4.20925459
   2.26423202  -6.85989446  -1.35417185   3.25942061  34.72283994
  51.04611867  18.17719313   4.95602861   2.37223853 -10.20496353
  21.83351609  -0.26238861   7.81019585   0.08938543   4.75845622
  -0.45349758  -2.31520257  -3.59412359  56.02910441  -5.3943183
   5.88335507   7.09770979   1.36272699   1.61383321  -1.8864064
  13.04899649   6.29512421   3.52300225   4.20566937  28.5611989 ]
(65,)
16.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1991.2143051206237
gradient value of function right now is: [-1.25346682e+00 -1.56591103e+00  2.06117259e-02 -1.55265596e+00
  1.25346682e+00  1.56591103e+00 -2.06117259e-02  1.55265596e+00
 -3.78867594e+00 -1.90572557e-02 -7.45392029e-01 -6.79580323e-01
  1.55735500e+00  9.71521329e-12  4.83648852e-02 -7.59478667e-03
  2.18883947e-03  1.99831541e-33 -3.95334825e-05  5.23995402e-12
  1.36296062e+00  7.99350787e-12  4.24734666e-02 -6.36945033e-03
  5.63897792e-02 -1.33794302e-01  5.55051022e+00  1.97111019e+00
 -1.91946219e-08 -5.22781259e-07 -5.19970074e-03  3.71532905e-15
 -1.31229869e-03 -1.07817186e-02 -1.94959425e+00 -1.01751761e+00
 -1.76544107e-02 -6.66463035e-03  1.56666413e-01  7.00530948e-03
 -4.69240942e-03 -5.72405120e-03 -2.62272049e-02 -3.74055749e-02
  3.76264874e-01  2.58870021e-02  6.09996842e-01  6.00275431e-01
  2.24283099e-01  5.09511580e-01  5.23726241e-01  7.21920708e-01
 -1.19388215e+00 -1.13474561e-01 -7.67484687e+00 -7.61673101e+00
 -1.68693722e+00  5.26873940e+00  3.17629127e+00 -1.00759525e+01
 -2.65750489e-01  6.40830038e-01  6.19644664e-01 -1.19731318e+00
 -2.10353647e-01]
supnorm grad right now is: 10.075952514563488
Weights right now are: 
[ -7.90174572   3.67705341  -6.9505997    2.90000656   8.15631443
  -3.7857451    7.34953697  -3.61603495   4.90524894  -6.51332087
   0.3345993   -1.90895495   1.8536466    7.49623152  22.7723224
  23.91737004  72.95338724   4.16692265  86.03091222   3.90706435
   1.91182508   5.96430624  22.94600919  23.92234925   0.44562214
   1.61784201  -1.50518442   7.1479106    4.3873522   15.94438571
  79.28768846  13.64581649 -14.99005555  43.66394181   4.1144906
   2.01890976  -5.6558761   -1.40079373   3.69138533  37.04448583
  58.01503216  20.40911566  -0.26807867   1.41715431 -10.55308494
  19.4109247    0.14365243   8.8747311   -0.14936706   4.81377246
  -0.39260816  -2.70486943  -3.57747748  60.0972363   -5.36424217
   5.67829739   6.94860436   1.29218824   1.72222157  -1.87806044
  13.80897448   7.53411917   4.71095444   3.78275376  28.51616199]
(65,)
18.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1992.503337721778
gradient value of function right now is: [-4.35344881e-01 -6.18276892e-01 -2.46296851e-03 -6.14019987e-01
  4.35344881e-01  6.18276892e-01  2.46296851e-03  6.14019987e-01
 -1.18319543e+00 -1.19507168e-02 -3.63052497e-01 -1.18325846e-01
  8.61184212e-01  7.90549337e-13  2.52864987e-02  1.84707208e-02
 -3.65667741e-03  8.52733450e-36 -1.83198055e-04  3.65250257e-12
  7.55627040e-01  6.71507752e-13  2.22157438e-02  1.58524195e-02
 -6.26903279e-02 -1.64022196e-01  1.91045331e+00  9.84009990e-01
  2.36403924e-09 -1.70362364e-06 -3.22786199e-03  6.86731777e-16
  8.77740654e-03 -3.19190054e-03 -9.90262135e-01 -4.11306593e-01
  2.32289461e-02  1.29504000e-02 -7.19516700e-01  3.90790248e-03
  3.92019583e-03  6.62121740e-03  1.33443441e-01  1.38105147e-01
  2.22009980e-02  2.85166541e-02  8.64346875e-02  8.98882686e-02
  3.96054359e-01  3.00248351e-01  8.27868337e-01  9.28239376e-01
 -6.28709675e-01 -3.69463460e-02 -3.10438437e+00 -3.07849015e+00
 -1.30679321e+00  4.57492679e+00  1.10360159e+00 -3.39300660e+00
 -4.30067768e-02  1.20351059e-01  1.38685055e-01 -4.14598056e-01
  4.46340624e-03]
supnorm grad right now is: 4.574926794602788
Weights right now are: 
[-8.35638402e+00  4.07643294e+00 -7.83828579e+00  3.29836321e+00
  8.61095273e+00 -4.18512463e+00  8.23722306e+00 -4.01439159e+00
  5.21329345e+00 -5.89548430e+00  7.90593579e-01 -2.26895430e+00
  2.15037752e+00  7.49623404e+00  2.41167160e+01  2.64395427e+01
  8.25847359e+01  4.16692265e+00  9.87008507e+01  3.90706921e+00
  2.18555296e+00  5.96430820e+00  2.43120828e+01  2.64493339e+01
 -4.00879359e-01  1.31754280e+00 -1.67653470e+00  7.01166477e+00
  4.45738345e+00  1.89920784e+01  8.78261048e+01  1.36458165e+01
 -1.72778533e+01  5.29537427e+01  3.98860258e+00  1.98117472e+00
 -4.73594670e+00 -1.16845555e+00  3.60859594e+00  3.86521681e+01
  6.19640834e+01  2.61512641e+01 -4.59228551e-01  1.13265369e+00
 -1.12873412e+01  1.71272294e+01 -6.01841485e-01  9.19633278e+00
 -2.22059718e-01  5.02552859e+00 -8.24233676e-02 -2.73647102e+00
 -3.90390658e+00  6.34394298e+01 -5.22398756e+00  5.50120168e+00
  6.73267819e+00  1.39595580e+00  1.79849290e+00 -1.87321892e+00
  1.45926772e+01  7.96985909e+00  4.67639945e+00  3.82690703e+00
  2.85286430e+01]
(65,)
20.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1991.5040327824483
gradient value of function right now is: [ 5.64705753e-01  9.07645058e-01  2.46667866e-02  9.07421086e-01
 -5.64705753e-01 -9.07645058e-01 -2.46667866e-02 -9.07421086e-01
 -9.44988335e-01  7.95665690e-04 -4.50393505e-01 -7.16931102e-01
 -1.19673447e-01  2.77808277e-14  1.17946503e-02  1.05176782e-02
  1.01657461e-02 -6.20389580e-39  3.66109252e-04  6.07413604e-14
 -1.15675846e-01  2.49545432e-14  9.98541480e-03  8.99425289e-03
  3.64479888e-02 -3.42634619e-01 -3.18660296e+00 -2.17902189e+00
 -5.22315329e-11 -2.14994812e-08 -1.31163528e-03 -2.70231958e-17
 -1.32368609e-02  2.19841857e-03 -3.85369928e-01  8.23722836e-02
 -2.41363931e-02 -1.83243388e-02 -7.58190896e-01 -5.90727601e-03
 -8.76200768e-03 -1.33447698e-02 -1.95373729e-02 -2.41549215e-01
  3.62631092e-01 -1.44713530e-02  4.42792782e-01  4.48375484e-01
 -4.44215005e-01  3.12351366e-01 -6.94206309e-01  2.85734931e-01
  4.73769208e+00  2.92704691e-01  7.13414326e+00  7.20192866e+00
  1.94486258e+00 -1.10306942e+01 -4.33355488e+00  2.85725948e+01
  1.81986095e-01 -3.71778635e-01  5.82401827e-01 -7.09649605e-02
  3.53133840e+00]
supnorm grad right now is: 28.572594829916046
Weights right now are: 
[ -8.72557102   4.00211844  -8.60212751   3.22147613   8.98013973
  -4.11081013   9.00106478  -3.93750451   5.38069939  -7.20144861
   0.93294036  -2.19709663   2.03106421   7.49623434  25.16658682
  29.80125192  89.72343612   4.16692265 107.52273773   3.90706878
   2.06305069   5.96430844  25.37740644  29.77533367  -1.42471238
   1.60123637  -1.47221717   6.74514115   4.45813447  21.3275785
  95.52349133  13.64581649 -18.83417196  57.50465146   4.34452397
   2.11657006  -7.06715172  -0.64177641   3.95375145  40.68344666
  64.92549426  30.38090522  -0.96270005   1.41390745 -11.58013014
  18.08303514  -0.36949218  10.43683324  -0.67750197   4.71180869
  -0.58250562  -2.53751736  -4.06967752  66.46924269  -5.13687958
   5.39127126   6.88015148   1.36199097   1.58866085  -1.87997809
  16.04658423   8.04341512   4.67035533   3.96241052  28.54513877]
(65,)
22.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1990.1780805314966
gradient value of function right now is: [-3.61309624e-01 -8.02767497e-01  3.24376429e-02 -7.71971803e-01
  3.61309624e-01  8.02767497e-01 -3.24376429e-02  7.71971803e-01
 -5.57847412e+00 -6.92115187e-02 -4.14483135e-01 -6.50166172e-01
  4.33994796e+00 -1.22783169e-14  1.36541559e-01  4.91554036e-02
  1.18482196e-02 -1.93354165e-38  4.69874464e-04  5.87332256e-15
  3.72964054e+00 -7.40087070e-15  1.17534440e-01  4.17069012e-02
  1.67248901e-02 -3.41693867e-01  8.65002349e-01 -6.42054170e-01
  3.33337394e-10  1.79687785e-07 -7.31812049e-03  2.33511461e-17
  4.86404348e-03 -9.49953064e-03 -5.60612054e+00 -9.61749933e-01
 -8.53924558e-03 -3.31037603e-02 -2.92558246e+00 -1.85715989e-02
  4.43653768e-04 -5.83703302e-03  1.01138716e-01  7.92283679e-02
  9.73175652e-01  1.47365159e-02  1.45384669e+00  1.41230718e+00
  9.03357388e-01  1.15655474e+00  2.63222852e+00  3.40201135e+00
  3.64109914e+00  2.36654573e-01  2.83052940e+00  2.82576031e+00
  5.20482980e-01 -7.24587820e+00 -3.10803278e+00  2.37089876e+01
  8.99294158e-02 -1.88148475e-01  8.61321545e-01 -5.30044475e-01
  7.85208603e+00]
supnorm grad right now is: 23.70898757685714
Weights right now are: 
[ -8.61182461   4.02457114  -8.62402355   3.24379761   8.86639332
  -4.13326283   9.02296082  -3.95982599   5.45340414  -7.30099019
   1.56197917  -2.33609685   2.31356374   7.49623439  26.11193306
  32.46482386  96.62553893   4.16692265 119.43821331   3.90706904
   2.36536221   5.96430847  26.36521949  32.40440009  -1.1593538
   1.88559091  -1.23504955   6.54489177   4.45824071  23.5322304
 101.21259385  13.64581649 -19.56869387  66.00935617   4.08010909
   1.91700104  -9.85326513  -1.8405162    4.14525475  47.35718009
  67.62860575  33.67370807   0.16129423   2.20895998 -11.56412168
  17.70316532  -0.4389023   11.02840172  -0.79043891   5.52502075
  -0.21857282  -2.46510394  -3.81856999  69.63116363  -4.97746432
   5.30236787   7.28508086   1.47302971   1.48784341  -1.92994949
  16.4657323    8.99638862   4.5098989    3.84591119  28.51582463]
(65,)
24.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1988.6807387129497
gradient value of function right now is: [-6.16177509e-01 -2.93052707e-01  8.95133350e-03 -2.85153206e-01
  6.16177509e-01  2.93052707e-01 -8.95133350e-03  2.85153206e-01
 -6.44002023e+00 -6.18920589e-02 -2.88797338e+00 -3.20555131e+00
  2.17968633e+00  2.05330745e-14  3.88510460e-02  6.85085052e-02
  4.23328675e-04 -2.75218566e-43 -1.23419045e-04  8.09486564e-17
  1.89167635e+00  1.71276783e-14  3.36510908e-02  5.93488210e-02
 -1.29638592e-02 -3.53103123e-01  6.09882581e-01 -5.15611680e-01
 -1.12804693e-11 -2.86461405e-06 -1.16182606e-02 -3.26595961e-17
  7.38403661e-03 -5.10352001e-03 -1.32535749e+00 -3.47372627e-02
  3.58341721e-03 -3.56991527e-02 -4.39673634e+00 -1.67175759e-02
  3.83986058e-03  1.32090797e-03  9.53271423e-02  1.44039754e-01
  6.65055737e-01  4.15169595e-02  9.16031869e-01  8.98472602e-01
  2.01621413e+00  2.75855901e+00  3.33626048e+00  4.25599914e+00
  2.35497218e+00  2.11410267e-01  3.18377482e+00  3.18396713e+00
  2.53290497e-01 -3.82163660e+00 -5.94332044e+00  1.98448367e+01
  5.52214210e-02 -1.59675375e-01  4.90412645e-01 -1.63057897e-01
  1.75751115e+01]
supnorm grad right now is: 19.844836695040925
Weights right now are: 
[ -8.9740057    4.19674264  -8.51354782   3.41165539   9.22857441
  -4.30543433   8.91248508  -4.12768377   5.66275319  -7.13398732
   0.69368793  -3.01279385   2.37252972   7.49623441  26.45966046
  34.83545084 102.41957591   4.16692265 130.28927389   3.90706904
   2.40142211   5.96430848  26.72699551  34.75038965  -1.53250421
   1.84587178  -1.56595738   6.31554308   4.45836266  25.44279197
 108.04849402  13.64581649 -20.71906413  74.93514484   4.64544055
   2.24381027 -10.83424215  -0.18220541   3.97928121  51.69776376
  70.33802937  40.85899188  -0.69209521   1.46487612 -12.19972908
  18.83635285  -0.60433536  11.15546775  -0.15624431   5.38981468
   0.32995604  -2.532352    -3.96234033  72.12157925  -4.9861569
   5.09868109   7.00579117   1.55438472   1.53943029  -1.97264539
  18.0521187    9.19403299   4.02813981   4.05031674  28.78637104]
(65,)
26.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1985.6362367953434
gradient value of function right now is: [-2.33867848e+00 -2.76241185e+00 -6.39467191e-03 -2.73824667e+00
  2.33867848e+00  2.76241185e+00  6.39467191e-03  2.73824667e+00
 -8.08926453e+00 -3.17906983e-02 -2.37742186e+00 -2.40623947e+00
  4.76002966e+00  2.14683633e-15  8.84736736e-02  3.34586171e-02
 -7.39602891e-03  1.20904007e-42 -8.02268289e-04  1.04483147e-18
  4.16419542e+00  1.75953677e-15  7.76796780e-02  2.88680722e-02
 -2.49681228e-02 -2.08236946e-01  5.73502381e+00  3.08701130e+00
 -2.03264506e-11 -1.88016862e-06 -5.78572326e-03 -3.77062625e-17
  1.23250890e-03 -9.35001584e-03 -4.03229339e+00 -1.33895838e+00
  5.65432612e-03 -9.91467473e-03 -2.70005698e+00 -1.16900696e-02
 -7.50236537e-04  1.94020272e-03  4.45689155e-02  3.74872852e-02
  6.10879524e-01  4.67644647e-02  1.01957806e+00  1.00039765e+00
  8.82495121e-01  1.67969933e+00  1.62055265e+00  2.23928301e+00
 -1.38859176e+00 -1.10734424e-02 -6.87698234e+00 -6.77858831e+00
 -1.89480163e+00  5.88128352e+00 -5.31274415e-02 -4.56419296e+00
  1.46100602e-02  1.43868413e-02  5.90874572e-01 -7.03628411e-01
  1.32954921e+01]
supnorm grad right now is: 13.295492106293326
Weights right now are: 
[-9.04236383e+00  4.25372366e+00 -8.98352026e+00  3.46866471e+00
  9.29693254e+00 -4.36241535e+00  9.38245753e+00 -4.18469310e+00
  5.78836533e+00 -6.77497117e+00  5.80007261e-01 -3.39100687e+00
  2.75339278e+00  7.49623441e+00  2.75163432e+01  3.68089777e+01
  1.06387208e+02  4.16692265e+00  1.39194467e+02  3.90706904e+00
  2.79261029e+00  5.96430849e+00  2.78312543e+01  3.66962570e+01
 -8.95800780e-01  1.37267080e+00 -1.28016822e+00  6.52028276e+00
  4.45836385e+00  2.57959809e+01  1.13614559e+02  1.36458165e+01
 -2.11683934e+01  8.45420122e+01  4.39491227e+00  1.76740812e+00
 -1.59478769e+01  1.35582927e+00  4.07849538e+00  5.66170319e+01
  7.18157170e+01  4.11052738e+01 -6.96590215e-02  1.43042746e+00
 -1.23449924e+01  1.96194047e+01 -7.20443853e-01  1.14613020e+01
 -2.49472041e-01  5.78369725e+00 -3.22141277e-01 -3.03122811e+00
 -3.76687237e+00  7.49269975e+01 -5.04066140e+00  4.90070298e+00
  7.31144298e+00  1.47666123e+00  1.65244151e+00 -2.01218901e+00
  1.91848706e+01  9.31006345e+00  4.68881061e+00  3.74100767e+00
  2.87160533e+01]
(65,)
28.000000000000004% of gradient descent iterations done. Method = Adam
objective value function right now is: -1989.323353756201
gradient value of function right now is: [-1.12952951e+00 -8.82367876e-01  3.06437728e-03 -8.72439015e-01
  1.12952951e+00  8.82367876e-01 -3.06437728e-03  8.72439015e-01
 -8.37638987e+00 -2.97848234e-02 -2.39793590e+00 -3.11249363e+00
  2.39220108e+00  3.35765861e-16  2.22960483e-02  5.72609581e-02
 -1.85942531e-03 -2.40815961e-45 -1.19882194e-04  5.90757311e-18
  2.09688186e+00  2.77837440e-16  1.94133735e-02  4.97902891e-02
  1.93399721e-02 -6.95316727e-02  5.03441082e+00  6.06652630e-01
 -2.66960592e-13 -1.85677950e-07 -5.90500708e-03 -1.18668830e-19
  2.19279026e-03 -1.93417512e-03 -7.21335712e-01 -5.54628416e-02
 -1.01569350e-02 -6.91871960e-02 -5.07797422e+00 -9.65743854e-03
 -1.64703571e-04 -1.38276978e-02  5.46187723e-02 -4.99491220e-04
  3.72595347e-01 -1.48165607e-02  4.98493624e-01  4.76712902e-01
  1.20789444e+00  2.09144959e+00  1.72112605e+00  2.72092728e+00
 -3.84103494e-01  2.79990268e-02 -9.68833266e-01 -9.15324502e-01
 -5.56405316e-01  2.13185508e+00 -1.93294096e+00  1.52506692e+00
  2.19589053e-02 -6.51824723e-02  9.21526504e-01 -6.81042079e-01
  1.31417756e+01]
supnorm grad right now is: 13.141775616550701
Weights right now are: 
[-9.14211072e+00  4.37961604e+00 -8.13822190e+00  3.59194373e+00
  9.39667943e+00 -4.48830773e+00  8.53715917e+00 -4.30797211e+00
  5.63712127e+00 -7.55092039e+00  1.08229776e+00 -3.29323833e+00
  2.69980246e+00  7.49623441e+00  2.83968665e+01  3.97764025e+01
  1.11561978e+02  4.16692265e+00  1.47469018e+02  3.90706904e+00
  2.73765947e+00  5.96430849e+00  2.87324336e+01  3.96365514e+01
 -4.75400659e-01  1.85566644e+00 -1.00925903e+00  6.14314365e+00
  4.45836549e+00  2.66243712e+01  1.21334098e+02  1.36458165e+01
 -2.12873573e+01  8.94325304e+01  4.72643338e+00  2.35315380e+00
 -1.94448579e+01  1.33763464e+00  3.83744427e+00  6.23849873e+01
  7.51853231e+01  4.25079896e+01 -6.60117002e-01  1.75345834e+00
 -1.27379348e+01  2.02918125e+01 -7.77996779e-01  1.20470420e+01
  3.59829966e-03  4.94641876e+00 -9.59121245e-02 -2.83149712e+00
 -3.81215365e+00  7.68851373e+01 -4.70725853e+00  5.04222294e+00
  7.48282350e+00  1.74507676e+00  1.63319231e+00 -2.00266462e+00
  2.02428034e+01  9.72160332e+00  4.69536798e+00  4.16699926e+00
  2.86600787e+01]
(65,)
30.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1988.3307571799162
gradient value of function right now is: [-1.69116869e+00 -2.07390011e+00 -5.58240429e-02 -2.08553759e+00
  1.69116869e+00  2.07390011e+00  5.58240429e-02  2.08553759e+00
  5.19925258e+00  9.32753098e-03  9.50097833e-01  1.78327545e+00
 -2.88555800e+00 -5.95930855e-17 -5.47643253e-02 -6.69072409e-02
 -2.43877592e-02  2.52420054e-46 -4.76217427e-04 -2.01523269e-18
 -2.48883493e+00 -4.88103739e-17 -4.73389946e-02 -5.82038886e-02
 -1.08097818e-01  7.56679235e-01  6.91717154e+00  5.31059534e+00
  1.31032737e-13  9.62688053e-08  1.04785793e-03  2.67450248e-19
  2.36792939e-02  4.80338184e-04  2.30029151e+00 -2.75786446e-01
  5.48874311e-02  1.39267887e-01  5.59116522e+00  1.88468358e-02
  1.70470220e-02  4.90533417e-02  1.16676364e-01  7.35528764e-01
 -2.08873100e+00 -3.10294759e-03 -2.58861449e+00 -2.54635293e+00
 -6.99864524e-01 -1.63370133e+00 -1.33720565e+00 -3.16747435e+00
 -8.38198383e+00 -4.15826531e-01 -1.39816661e+01 -1.42547222e+01
 -5.07591596e+00  2.52752182e+01  7.87145261e+00 -4.65442245e+01
 -3.12977572e-01  6.14295544e-01 -1.73869254e+00  4.64022957e-01
 -1.57546009e+01]
supnorm grad right now is: 46.544224476000245
Weights right now are: 
[ -9.28045047   4.37234523  -9.0408378    3.58249724   9.53501918
  -4.48103692   9.43977507  -4.29852562   5.75289748  -6.31822008
   1.35546588  -3.55327959   2.58213234   7.49623441  28.87833321
  41.04183985 115.26995194   4.16692265 159.77333549   3.90706904
   2.61537278   5.96430849  29.24737445  40.86968551  -1.36978768
   2.94638259  -1.15049081   6.20301678   4.4583655   26.81894735
 126.58242033  13.64581649 -19.86933564  98.99836467   4.8520704
   1.99496251 -21.92652613   0.947246     4.68073547  69.78717602
  78.19036857  46.34292833  -0.46169962   1.71920802 -13.09160369
  20.52163095  -0.83963472  12.19475785  -0.25976785   5.37847797
  -0.542549    -2.86458265  -3.79385903  78.73017228  -4.68424526
   4.86092667   7.59469355   1.71711377   1.91725541  -2.04204227
  20.5011152   10.36207068   4.50285613   3.80222816  28.66957725]
(65,)
32.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1980.8783643745699
gradient value of function right now is: [ 3.43000355e+00  5.94072688e+00  1.05202738e-01  5.94324065e+00
 -3.43000355e+00 -5.94072688e+00 -1.05202738e-01 -5.94324065e+00
 -1.42750863e+01 -7.98133625e-02 -7.03248411e+00 -9.59032979e+00
  1.40789117e+00  1.14248509e-16  1.52237391e-02  9.88447237e-02
  4.10945396e-02 -1.58309017e-47  1.41148985e-03  4.90690273e-20
  1.15570826e+00  9.52823647e-17  1.16782522e-02  8.63153363e-02
  8.21593952e-02 -1.09070008e+00 -1.55022113e+01 -1.30574231e+01
 -1.53064543e-13 -7.33535577e-07 -1.40043526e-02 -4.19068179e-19
 -1.58747749e-02  9.96804509e-03  9.35272113e-02  2.22044429e+00
 -5.90837232e-02 -1.80832482e-01 -1.13115737e+01 -3.00302039e-02
 -1.94442557e-02 -4.84090411e-02 -3.24783145e-02 -8.92304503e-01
  2.06987188e+00 -1.85928842e-01  2.38930749e+00  2.31948090e+00
  4.81810730e-01  6.91272872e+00  2.14915106e-01  4.25863494e+00
  2.00620619e+01  8.78478760e-01  3.71131631e+01  3.74661123e+01
  1.08927044e+01 -5.46934894e+01 -2.74451732e+01  1.07172680e+02
  4.90581926e-01 -1.07028539e+00  3.48483899e+00 -1.64175386e+00
  4.88656430e+01]
supnorm grad right now is: 107.17268005764008
Weights right now are: 
[-9.26638458e+00  4.42085944e+00 -9.05360536e+00  3.62942593e+00
  9.52095329e+00 -4.52955113e+00  9.45254263e+00 -4.34545431e+00
  5.92780636e+00 -7.50802050e+00  9.46141321e-01 -3.81163448e+00
  2.71546127e+00  7.49623441e+00  2.94535255e+01  4.31086913e+01
  1.19266959e+02  4.16692265e+00  1.70991801e+02  3.90706904e+00
  2.74385400e+00  5.96430849e+00  2.98448454e+01  4.28956082e+01
 -4.08882857e+00  2.25445471e+00 -1.20391898e+00  6.30777628e+00
  4.45836549e+00  2.69206074e+01  1.32403056e+02  1.36458165e+01
 -2.07475986e+01  1.09295125e+02  4.73034577e+00  1.60301878e+00
 -2.43040588e+01 -2.99558358e-01  4.42972824e+00  7.18649677e+01
  7.94163521e+01  4.96841582e+01 -6.42848848e-01  1.53500153e+00
 -1.31481107e+01  2.12799745e+01 -6.75422278e-01  1.25446518e+01
  2.44046215e-01  5.50201863e+00 -6.45219054e-02 -2.65256885e+00
 -3.75196564e+00  8.15695929e+01 -4.54120629e+00  4.90988713e+00
  7.80023654e+00  1.66473636e+00  1.46991275e+00 -2.04031642e+00
  2.14120102e+01  1.03295052e+01  5.09218080e+00  4.20250144e+00
  2.86835639e+01]
(65,)
34.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1991.248545889787
gradient value of function right now is: [ 1.80500156e+00  1.92711677e+00  3.52554269e-02  1.92440791e+00
 -1.80500156e+00 -1.92711677e+00 -3.52554269e-02 -1.92440791e+00
  1.10040680e+00  3.76553525e-02  7.31916676e-01  5.28065948e-01
 -6.38817602e-01 -9.62869948e-18 -1.33498812e-02  9.81522978e-03
  1.80424096e-02 -7.46229719e-52  8.74193121e-04  1.95893218e-19
 -5.75361418e-01 -8.00851614e-18 -1.22101412e-02  8.60834937e-03
  2.47221027e-02 -3.67926954e-02 -4.09238504e+00 -3.41846271e+00
  1.85652072e-16  2.28192845e-08  2.44165382e-03  3.48280937e-22
 -2.16232993e-04  1.39060680e-03  5.21405515e-01  6.03983856e-01
 -1.62698612e-02 -2.49395814e-02 -7.27578828e-01 -3.97965395e-03
 -3.32180071e-03 -1.62578010e-02  8.31449330e-02 -1.12985153e-01
  3.97346276e-02 -2.08669904e-02 -5.30693643e-03  5.58056849e-03
 -2.78133705e-01 -4.04926335e-01 -5.91736866e-01 -8.68946114e-02
  2.95448194e+00  7.16057744e-02  6.84308166e+00  6.97295565e+00
  2.70614498e+00 -1.10666856e+01 -1.93491441e+00  9.97788913e+00
  5.49600140e-02 -1.08035469e-01  3.41116201e-01  2.48002487e-02
  3.04762132e-01]
supnorm grad right now is: 11.066685597554939
Weights right now are: 
[-8.99332827e+00  4.74426244e+00 -1.01808918e+01  3.95060827e+00
  9.24789698e+00 -4.85295413e+00  1.05798290e+01 -4.66663665e+00
  6.20403539e+00 -6.76371509e+00  1.77566422e+00 -3.64439745e+00
  2.77370134e+00  7.49623441e+00  2.97633268e+01  4.45939697e+01
  1.24355980e+02  4.16692265e+00  1.85429170e+02  3.90706904e+00
  2.80191117e+00  5.96430849e+00  3.01888990e+01  4.43728186e+01
 -3.23315834e+00  2.22984258e+00 -1.09982932e+00  6.36810520e+00
  4.45836549e+00  2.71047393e+01  1.37714812e+02  1.36458165e+01
 -1.98056766e+01  1.17257084e+02  4.46318249e+00  2.43245353e+00
 -2.78677058e+01  8.13643164e-01  4.49581101e+00  7.37239561e+01
  8.16740255e+01  5.20294307e+01 -1.03094754e+00  1.92615152e+00
 -1.34533235e+01  2.16149771e+01 -9.63766097e-01  1.25058944e+01
 -2.25815481e-01  5.05399088e+00  9.94032789e-02 -2.96068854e+00
 -3.84014881e+00  8.35793538e+01 -4.54673599e+00  4.80111256e+00
  7.68275411e+00  1.65465631e+00  1.80125631e+00 -2.08001882e+00
  2.18749991e+01  1.06194551e+01  4.80277029e+00  3.63967135e+00
  2.85749832e+01]
(65,)
36.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1982.5464984311618
gradient value of function right now is: [-2.64418949e+00 -3.49732846e+00 -1.63233779e-01 -3.50486018e+00
  2.64418949e+00  3.49732846e+00  1.63233779e-01  3.50486018e+00
  9.36046176e+00  1.17556949e-01  3.23794193e+00  4.48340022e+00
 -2.21761337e+00 -1.74691904e-17 -3.01171024e-02 -5.08995105e-02
 -5.22089867e-02  1.59080184e-51 -2.13171984e-03 -2.39823889e-19
 -1.92696691e+00 -1.48429516e-17 -2.57982001e-02 -4.46089047e-02
 -1.19159416e-01  1.04122304e+00  7.88675712e+00  8.23349417e+00
  6.93213407e-16  1.29636819e-07  9.95238141e-03  6.77380674e-22
  9.37879636e-03 -2.62836540e-03  1.13903790e+00 -5.54018740e-01
  6.04176794e-02  1.69670162e-01  6.23740377e+00  2.22902616e-02
  1.55142641e-02  4.86175544e-02  1.62816452e-01  7.74222005e-01
 -1.75268235e+00  9.05093786e-02 -2.17806664e+00 -2.10517026e+00
 -5.17589172e-01 -3.26713676e+00 -8.75454725e-01 -2.70776541e+00
 -1.14427632e+01 -5.16287481e-01 -2.00460158e+01 -2.03592818e+01
 -6.40445591e+00  3.21354514e+01  1.11776444e+01 -5.99496258e+01
 -2.78880215e-01  5.76659889e-01 -1.85144082e+00  3.97724075e-01
 -2.17708184e+01]
supnorm grad right now is: 59.949625815200505
Weights right now are: 
[-9.18771957e+00  4.66712452e+00 -8.81005211e+00  3.87097053e+00
  9.44228828e+00 -4.77581621e+00  9.20898938e+00 -4.58699892e+00
  5.85686944e+00 -6.18385670e+00  2.05610694e+00 -4.02294825e+00
  2.76991855e+00  7.49623441e+00  2.96730711e+01  4.57881626e+01
  1.28610399e+02  4.16692265e+00  2.00986962e+02  3.90706904e+00
  2.80244550e+00  5.96430849e+00  3.01106957e+01  4.55355566e+01
 -4.19614226e+00  1.99096153e+00 -9.18419029e-01  6.43844944e+00
  4.45836549e+00  2.71796749e+01  1.44810492e+02  1.36458165e+01
 -2.15682051e+01  1.25830285e+02  4.67066567e+00  1.96004303e+00
 -3.24711630e+01 -7.04150965e-02  4.52005985e+00  7.48440264e+01
  8.48253318e+01  5.34691237e+01 -1.95328096e-01  1.58230845e+00
 -1.32024764e+01  2.07908212e+01 -1.14699786e+00  1.25484031e+01
 -2.51645939e-01  5.13771492e+00 -1.14717506e-02 -3.06103834e+00
 -3.94604707e+00  8.60451800e+01 -4.66932567e+00  4.67224525e+00
  7.96181735e+00  1.70918129e+00  1.81270993e+00 -2.15968204e+00
  2.26391856e+01  1.11811959e+01  4.85030672e+00  4.02121852e+00
  2.84722814e+01]
(65,)
38.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1990.931937223102
gradient value of function right now is: [-5.27695682e-02 -3.48125668e-01 -3.09610341e-02 -3.56533015e-01
  5.27695682e-02  3.48125668e-01  3.09610341e-02  3.56533015e-01
  6.05336978e+00  2.05308237e-02  1.82347124e+00  2.45264409e+00
 -2.41645219e+00 -3.27972422e-18 -3.92297157e-02 -3.45477854e-02
 -1.05177599e-02  3.76152010e-53 -2.76126405e-04  1.48473724e-22
 -2.11841581e+00 -2.74783270e-18 -3.42925489e-02 -3.03150426e-02
 -3.73714090e-02 -6.52131368e-02  1.26880432e+00  2.10354545e+00
  5.31338283e-16  1.51990650e-07  3.08460600e-03  7.21148680e-22
  5.90933930e-03  1.10294190e-04  1.54230336e+00 -5.16685196e-02
  1.78870586e-02  9.53553332e-02  3.81592239e+00  9.74150656e-03
  7.51583936e-03  1.90842988e-02  4.30600186e-02  3.04254690e-01
 -4.07472539e-01  6.86494102e-02 -5.97112156e-01 -5.53769180e-01
 -8.36163806e-01 -1.92595844e+00 -1.41939942e+00 -2.56629432e+00
 -2.95035701e+00 -1.55379912e-01 -5.34178400e+00 -5.47878647e+00
 -2.26590289e+00  9.83964781e+00  5.63593925e+00 -1.78032886e+01
 -1.48076287e-01  3.26829582e-01 -1.12192358e+00  3.26434138e-01
 -1.34371152e+01]
supnorm grad right now is: 17.803288582389722
Weights right now are: 
[-8.99046793e+00  4.70400841e+00 -9.60822662e+00  3.90489887e+00
  9.24503664e+00 -4.81270010e+00  1.00071639e+01 -4.62092725e+00
  6.16858593e+00 -7.65310729e+00  1.86076083e+00 -3.95305120e+00
  2.68536192e+00  7.49623441e+00  2.98839154e+01  4.79861328e+01
  1.32176459e+02  4.16692265e+00  2.12088397e+02  3.90706904e+00
  2.71552510e+00  5.96430849e+00  3.03319729e+01  4.76995093e+01
 -3.64561065e+00  2.17851842e+00 -1.09603755e+00  6.38604391e+00
  4.45836549e+00  2.72492146e+01  1.50258634e+02  1.36458165e+01
 -2.31055463e+01  1.33301437e+02  4.71222289e+00  2.25443442e+00
 -3.47915557e+01  7.17694723e-01  4.86954380e+00  8.00754528e+01
  8.78276888e+01  5.50672396e+01 -8.17594413e-01  1.76939848e+00
 -1.32249425e+01  2.03894963e+01 -1.10578420e+00  1.30641799e+01
 -1.89061626e-01  5.39523105e+00 -2.45347176e-01 -2.70873232e+00
 -3.79200233e+00  8.73345857e+01 -4.60224100e+00  4.61713937e+00
  7.62634066e+00  1.71348003e+00  1.78091821e+00 -2.08431506e+00
  2.37088701e+01  1.11127709e+01  4.46152694e+00  3.63382669e+00
  2.85718293e+01]
(65,)
40.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1990.3637502761844
gradient value of function right now is: [-2.04160052e+00 -2.77435818e+00 -3.56988739e-02 -2.76865716e+00
  2.04160052e+00  2.77435818e+00  3.56988739e-02  2.76865716e+00
  1.40835585e+00  1.84204010e-02  1.52944549e+00  2.06086337e+00
  7.75918018e-01 -1.00645846e-18  2.45594351e-02 -7.08776591e-03
 -1.40534259e-02  1.46230320e-53 -5.88921785e-04 -2.01042920e-20
  7.05455065e-01 -8.28754681e-19  2.21560623e-02 -6.12783756e-03
 -3.37843419e-02  6.29176755e-01  7.31427213e+00  4.62535042e+00
  1.95798347e-15  7.96074996e-08  1.92829059e-03  3.10560596e-21
 -5.90653759e-04 -4.79853890e-03 -1.40041778e+00 -8.90271361e-01
  1.30773043e-02  3.82309095e-02  1.42616050e+00  7.13714372e-03
  3.37391579e-03  1.26384325e-02 -6.81010550e-03  1.47288305e-01
 -1.04659430e+00  7.61178243e-02 -1.19490797e+00 -1.16148297e+00
  4.39437695e-01 -9.17773606e-01  1.01583756e+00  4.88546358e-01
 -7.01580941e+00 -3.06665270e-01 -1.35596761e+01 -1.34901028e+01
 -3.34853134e+00  1.83785568e+01  6.38853146e+00 -4.02868851e+01
 -1.19552467e-01  2.80441335e-01 -2.58359331e-01 -1.29551826e+00
 -8.39111969e+00]
supnorm grad right now is: 40.28688505798729
Weights right now are: 
[-9.23658627e+00  4.43868615e+00 -9.21723599e+00  3.63598881e+00
  9.49115498e+00 -4.54737784e+00  9.61617326e+00 -4.35201719e+00
  6.16133450e+00 -5.86926779e+00  1.85399380e+00 -3.75198243e+00
  2.71473122e+00  7.49623441e+00  3.00905379e+01  4.98835447e+01
  1.35030500e+02  4.16692265e+00  2.19348256e+02  3.90706904e+00
  2.76182276e+00  5.96430849e+00  3.05648889e+01  4.95620608e+01
 -2.68249501e+00  2.34737736e+00 -7.86245514e-01  6.30835347e+00
  4.45836550e+00  2.73115095e+01  1.53134924e+02  1.36458165e+01
 -2.67388746e+01  1.40046159e+02  4.67617641e+00  2.04399659e+00
 -3.73819072e+01  7.98015323e-01  4.91044476e+00  8.10556560e+01
  9.00213308e+01  5.62922254e+01 -9.26054513e-01  1.56466498e+00
 -1.34053173e+01  2.27240217e+01 -1.23916389e+00  1.31241583e+01
  1.51115560e-01  5.90198166e+00  2.74714445e-02 -2.80004298e+00
 -3.67731598e+00  8.94906580e+01 -4.43366713e+00  4.69118795e+00
  7.86596779e+00  1.62755794e+00  1.34665355e+00 -2.11582791e+00
  2.45957413e+01  1.15120808e+01  5.11797662e+00  3.58399867e+00
  2.84989905e+01]
(65,)
42.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1991.99004760748
gradient value of function right now is: [-1.57459041e-01 -1.71393098e-01  1.42880515e-02 -1.65004481e-01
  1.57459041e-01  1.71393098e-01 -1.42880515e-02  1.65004481e-01
 -2.92804596e+00 -3.00336465e-02 -9.92091406e-01 -1.09665267e+00
  1.30113077e+00  1.75675964e-19  1.21705961e-02  2.21286237e-02
  3.20916125e-03 -8.14171266e-58  1.58961604e-04  2.01422716e-22
  1.13831659e+00  1.51990855e-19  1.05434694e-02  1.91942575e-02
 -2.87959136e-04 -1.30714451e-01  7.69122258e-01 -1.60568265e-01
 -3.22221949e-18 -1.63094530e-08 -3.63552444e-03 -5.07873725e-24
  2.49422610e-03 -1.34142975e-03 -4.89774123e-01 -1.27096588e-02
  9.22708833e-04 -2.33960078e-02 -2.14651006e+00 -2.69086031e-03
  2.31851671e-03 -2.42605893e-03  3.07722136e-02  1.27553591e-01
  3.09619791e-01  1.04453825e-02  4.14495969e-01  4.03592294e-01
  9.74148190e-01  1.04411632e+00  1.52336201e+00  1.70625133e+00
  5.32959935e-02  5.70443614e-03 -2.43087657e-02 -1.86099338e-02
 -1.82535342e-01  1.06536684e-01 -4.67876156e-01  6.98915674e-01
  3.80869021e-02 -9.00052023e-02  2.50066229e-01 -2.30524427e-01
  6.43359759e+00]
supnorm grad right now is: 6.433597592746555
Weights right now are: 
[-8.97260930e+00  4.66002481e+00 -8.64364749e+00  3.85571097e+00
  9.22717801e+00 -4.76871650e+00  9.04258476e+00 -4.57173935e+00
  6.13525615e+00 -7.11894422e+00  1.84510875e+00 -3.89919225e+00
  2.86205682e+00  7.49623441e+00  3.06849794e+01  5.16797377e+01
  1.39450471e+02  4.16692265e+00  2.28488952e+02  3.90706904e+00
  2.91000592e+00  5.96430849e+00  3.11707343e+01  5.13299658e+01
 -2.12616068e+00  1.96508545e+00 -1.01769609e+00  6.22910242e+00
  4.45836550e+00  2.73406179e+01  1.59081998e+02  1.36458165e+01
 -2.80583125e+01  1.47819619e+02  4.87070545e+00  2.20996055e+00
 -3.78979725e+01  4.77993475e-01  4.60462906e+00  8.18439988e+01
  9.23952403e+01  6.02828802e+01 -1.58692921e+00  2.30442413e+00
 -1.34526686e+01  2.26948249e+01 -1.28171811e+00  1.32693201e+01
  2.06483450e-01  5.29268811e+00  3.34554782e-01 -3.11725243e+00
 -3.85132404e+00  9.13752511e+01 -4.44322723e+00  4.55399574e+00
  7.67894992e+00  1.77267438e+00  1.81519465e+00 -2.14673204e+00
  2.52816728e+01  1.16547047e+01  4.82142193e+00  4.17587834e+00
  2.87331791e+01]
(65,)
44.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1990.1621622383616
gradient value of function right now is: [ 3.86209506e-01 -2.83053579e-01  5.87267936e-03 -2.80979618e-01
 -3.86209506e-01  2.83053579e-01 -5.87267936e-03  2.80979618e-01
  4.98120056e+00  1.99383467e-01  3.56281280e+00  3.78485149e+00
  3.23996205e-01 -5.60240492e-19  5.06857865e-03  6.81038911e-04
  1.28264050e-03  6.80620161e-58  3.31348095e-05  5.19728277e-22
  2.86781496e-01 -4.74260531e-19  4.63030003e-03  6.00832729e-04
 -1.07583248e-02 -1.14023595e-01 -1.45779944e+00  3.11104910e-01
  1.08768039e-17  4.19283679e-08  1.55724938e-02  4.57061684e-24
  3.75968512e-03 -1.55701080e-03 -7.66785669e-01 -2.42003830e-01
  2.77589528e-03  5.68686301e-03  7.32036438e-01 -9.63643701e-04
  2.50231497e-03  3.11379697e-03  9.96052424e-02  1.17791277e-01
  1.43393120e-01  5.48752370e-02  1.93047477e-01  2.03746450e-01
 -2.99342318e-01 -3.08335599e+00 -1.60690411e-01 -4.83190045e-01
  2.71433678e-01  1.34624285e-02 -8.68658240e-01 -8.65205588e-01
 -5.18731558e-01  8.17242104e-01  1.88842780e+00  3.91540094e+00
 -1.93414243e-02  4.48946943e-02 -4.26875407e-01  2.91824332e-01
 -9.19175386e+00]
supnorm grad right now is: 9.191753862795515
Weights right now are: 
[-9.07980278e+00  4.57794255e+00 -9.13943156e+00  3.76773810e+00
  9.33437149e+00 -4.68663424e+00  9.53836883e+00 -4.48376648e+00
  6.26018264e+00 -7.10026071e+00  2.54180530e+00 -3.99421881e+00
  2.79412000e+00  7.49623441e+00  3.06540904e+01  5.26092732e+01
  1.41820351e+02  4.16692265e+00  2.39246521e+02  3.90706904e+00
  2.84568108e+00  5.96430849e+00  3.11864538e+01  5.22422767e+01
 -4.75734630e+00  2.43755388e+00 -1.03599526e+00  6.28207272e+00
  4.45836550e+00  2.73552206e+01  1.64330061e+02  1.36458165e+01
 -2.90023406e+01  1.56073359e+02  4.52795297e+00  2.10203891e+00
 -4.19057081e+01 -2.57929058e-01  4.32670746e+00  8.47240551e+01
  9.38239154e+01  5.92095948e+01 -8.49679783e-01  1.67207138e+00
 -1.36929521e+01  2.28091530e+01 -1.47000381e+00  1.32063754e+01
 -4.89788367e-01  5.21868772e+00 -3.65995578e-02 -3.21389947e+00
 -3.73650385e+00  9.29626073e+01 -4.46444731e+00  4.49320139e+00
  7.66506532e+00  1.67074644e+00  1.63273927e+00 -2.09311873e+00
  2.50519636e+01  1.24242773e+01  4.98202507e+00  4.76571950e+00
  2.84801329e+01]
(65,)
46.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1987.6708109380368
gradient value of function right now is: [-6.52521972e-01 -1.63724281e+00 -7.73452111e-02 -1.65205929e+00
  6.52521972e-01  1.63724281e+00  7.73452111e-02  1.65205929e+00
  1.08656766e+01  8.84241172e-02  5.24262074e+00  6.03130177e+00
 -1.97937508e+00 -2.68982622e-19 -4.04394217e-02 -3.19032805e-02
 -2.58982659e-02  1.09573529e-60 -4.03391530e-04 -5.26460608e-21
 -1.67920681e+00 -2.17671965e-19 -3.43691949e-02 -2.72122849e-02
 -3.65802112e-02  1.35153240e+00  2.69559428e+00  4.59250954e+00
  6.09496885e-17  1.51262887e-08  1.25173359e-02  6.19768771e-23
  7.29809487e-03 -4.10693613e-03  1.10901465e+00  4.44628138e-03
  1.71551845e-02  6.96766599e-02  5.09742038e+00  1.26654379e-02
  1.10809777e-02  1.78327122e-02  7.71861795e-02  3.64640664e-01
 -2.11700792e+00  1.07553142e-01 -2.62403741e+00 -2.56779156e+00
 -7.07278221e-01 -3.95032191e+00 -1.13104893e+00 -2.45953257e+00
 -8.18300788e+00 -3.26130716e-01 -1.18990485e+01 -1.20901360e+01
 -4.01301023e+00  2.22356711e+01  9.15850915e+00 -4.41963849e+01
 -1.45924762e-01  3.18533141e-01 -1.41860742e+00  1.64080478e-01
 -2.41112419e+01]
supnorm grad right now is: 44.19638487560663
Weights right now are: 
[-9.05056170e+00  4.60883285e+00 -9.78242459e+00  3.79409047e+00
  9.30513041e+00 -4.71752454e+00  1.01813619e+01 -4.51011886e+00
  6.51445861e+00 -8.41705945e+00  2.18303535e+00 -4.03846594e+00
  2.69889046e+00  7.49623441e+00  3.12013801e+01  5.37853835e+01
  1.45007505e+02  4.16692265e+00  2.45403535e+02  3.90706904e+00
  2.76483268e+00  5.96430849e+00  3.18083625e+01  5.33847585e+01
 -7.43631207e+00  2.28999944e+00 -9.33295450e-01  6.37420689e+00
  4.45836550e+00  2.73675575e+01  1.68229712e+02  1.36458165e+01
 -3.04975635e+01  1.60231167e+02  4.59851089e+00  2.53032128e+00
 -4.35412534e+01  1.83337719e+00  4.65144873e+00  8.58918876e+01
  9.32881447e+01  6.14887107e+01 -1.32689615e+00  1.60194028e+00
 -1.37713696e+01  2.63967480e+01 -1.58725168e+00  1.33821821e+01
 -7.61447601e-02  5.63676597e+00  1.44457514e-01 -3.09260064e+00
 -3.73713902e+00  9.47597046e+01 -4.32012254e+00  4.48678355e+00
  7.74048819e+00  1.76280714e+00  1.40275301e+00 -2.17212632e+00
  2.62032775e+01  1.21778496e+01  5.37503890e+00  3.70587266e+00
  2.83194050e+01]
(65,)
48.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1984.8550185102451
gradient value of function right now is: [ 4.20335009e+00  5.39950613e+00  9.27387515e-02  5.39721389e+00
 -4.20335009e+00 -5.39950613e+00 -9.27387515e-02 -5.39721389e+00
 -3.26218942e+00 -1.33641752e-01 -2.29704990e+00 -3.44497170e+00
  7.87751052e-02  1.04927646e-19 -1.22131987e-02  3.18096451e-02
  3.04995568e-02 -6.47643832e-60  5.70460212e-04  3.62596565e-24
 -2.18744243e-02  8.92008958e-20 -1.25547001e-02  2.72508749e-02
  2.29312282e-02 -9.26259548e-01 -1.63061371e+01 -1.08044268e+01
 -7.79489008e-18 -1.43943076e-08 -1.11121331e-02 -3.05926014e-24
 -9.07386295e-03  6.70740511e-03  9.78906801e-01  1.77129981e+00
 -2.54999379e-02 -7.37164653e-02 -4.57725958e+00 -1.21501962e-02
 -1.51855423e-02 -2.81706008e-02 -1.11105514e-03 -8.77356481e-01
  1.42186284e+00 -1.42327309e-01  1.60768035e+00  1.57735760e+00
 -6.47902115e-01  3.00058905e+00 -1.34458606e+00  8.22920882e-02
  1.42322803e+01  4.31196346e-01  2.70578927e+01  2.74963018e+01
  8.08011336e+00 -4.13684347e+01 -1.23796889e+01  6.24749626e+01
  2.07317128e-01 -4.59682416e-01  1.69115835e+00 -5.33690883e-01
  1.57628654e+01]
supnorm grad right now is: 62.47496264174578
Weights right now are: 
[ -9.13265359   4.59032724  -9.25632788   3.77392351   9.3872223
  -4.69901893   9.65526514  -4.4899519    6.29769251  -7.07015046
   2.48772771  -4.12883156   2.85501794   7.49623441  32.10744377
  53.26654573 149.25423265   4.16692265 254.5954758    3.90706904
   2.90789953   5.96430849  32.77252088  52.82012177 -10.36475781
   2.18004822  -1.01467568   6.20394163   4.4583655   27.37986204
 174.51109409  13.64581649 -28.30233076 169.67876062   4.67130421
   1.87877331 -47.35530733   1.48686858   4.76841638  86.81360516
  95.02534091  61.81314457  -0.75281745   2.00927566 -13.45734382
  23.85693711  -1.50310677  13.63954259   0.28236285   5.53078742
   0.2612636   -3.30135738  -3.63293427  96.54745379  -4.13531236
   4.5754041    7.82416023   1.57395045   1.59612167  -2.16072075
  26.73416638  12.2679562    4.80517757   4.23762304  28.50267763]
(65,)
50.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1991.23653010952
gradient value of function right now is: [-6.92750275e-01 -1.30768798e+00 -3.04806397e-03 -1.30857232e+00
  6.92750275e-01  1.30768798e+00  3.04806397e-03  1.30857232e+00
  3.32810268e+00 -1.38284189e-02  1.75566831e+00  2.29008479e+00
 -1.17005348e-01 -4.72674154e-20 -1.07738433e-02 -1.46646701e-02
 -2.94450458e-03  7.98144099e-61 -4.74593942e-05 -4.51941528e-26
 -6.20958521e-02 -3.54959454e-20 -8.83055414e-03 -1.23715529e-02
 -1.74692694e-02  5.53768721e-02  2.26960939e+00  2.12857534e+00
  4.87555130e-16  5.74940428e-08  5.66114721e-04  2.39649466e-22
  5.54857576e-03 -4.11762692e-03  1.48913528e-01 -1.52979607e-01
  1.36017030e-02  2.93034231e-02  2.26403710e+00  6.09088644e-03
  8.45137467e-03  1.14285112e-02  6.38242751e-02  3.40361600e-01
 -5.64497149e-02  1.25545719e-01 -3.96939889e-02 -2.65950269e-02
  2.52310023e-02 -9.21893303e-01  1.52300787e-02 -9.11737360e-01
 -4.38680642e+00 -1.69241576e-01 -6.77169448e+00 -6.94057684e+00
 -1.95622724e+00  9.15569266e+00  4.34371585e+00 -2.32103916e+01
 -3.75413339e-02  8.74843921e-02 -9.86502393e-01  5.93596243e-01
 -1.05386835e+01]
supnorm grad right now is: 23.21039164024297
Weights right now are: 
[-9.04572156e+00  4.52926477e+00 -1.03454893e+01  3.70999467e+00
  9.30029027e+00 -4.63795646e+00  1.07444265e+01 -4.42602305e+00
  6.35767684e+00 -6.85775115e+00  2.57637578e+00 -4.27665265e+00
  3.03752478e+00  7.49623441e+00  3.22091998e+01  5.38608673e+01
  1.51509444e+02  4.16692265e+00  2.57631193e+02  3.90706904e+00
  3.11412639e+00  5.96430849e+00  3.29924074e+01  5.33609270e+01
 -1.42053734e+01  1.48576063e+00 -9.32256264e-01  6.32107049e+00
  4.45836550e+00  2.73870814e+01  1.77605382e+02  1.36458165e+01
 -2.50527599e+01  1.76626074e+02  5.09682597e+00  1.83107649e+00
 -4.98192516e+01  8.47104797e-01  4.77351281e+00  8.85585534e+01
  9.51522736e+01  6.16409614e+01 -2.50901417e+00  1.94628724e+00
 -1.30069253e+01  2.48419755e+01 -1.26086678e+00  1.38385183e+01
  6.54346973e-01  6.49110636e+00  1.27432053e-01 -3.25136362e+00
 -3.66340608e+00  9.85128049e+01 -4.13660730e+00  4.49098138e+00
  7.71206894e+00  1.69252245e+00  1.36832549e+00 -2.26317612e+00
  2.75402962e+01  1.21608737e+01  5.13700140e+00  3.83682200e+00
  2.84211311e+01]
(65,)
52.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1990.727931504596
gradient value of function right now is: [-1.82205887e+00 -2.38960391e+00 -6.78344328e-02 -2.39010827e+00
  1.82205887e+00  2.38960391e+00  6.78344328e-02  2.39010827e+00
  2.69304319e+00  3.48755029e-02  2.07486059e+00  2.48675857e+00
 -2.00287979e-01 -3.77141981e-20 -1.86973256e-03 -9.77683160e-03
 -2.00831399e-02  7.81600644e-61 -4.04085112e-04 -1.28353758e-22
 -1.50226024e-01 -2.84421783e-20 -1.21050320e-03 -8.44536473e-03
 -1.35279103e-02  5.98809355e-01  7.54169814e+00  4.83179160e+00
  1.56071418e-17  1.39640277e-08  3.19417274e-03  1.28402118e-24
  9.75647101e-03 -1.30622448e-03 -1.37367456e-01 -3.44562568e-01
  1.14027469e-02  2.88659236e-02  1.74277979e+00  8.34294729e-03
  7.85442187e-03  9.94102360e-03  8.49771264e-02  2.25701501e-01
 -1.23684862e+00  3.23331977e-02 -1.53501432e+00 -1.50511800e+00
 -1.67903162e-01 -1.33084387e+00 -2.73255239e-01 -4.06263348e-01
 -6.84014064e+00 -2.66370955e-01 -1.20649565e+01 -1.18816556e+01
 -3.64655147e+00  1.85456723e+01  6.88134272e+00 -3.72544590e+01
 -7.66180653e-02  1.85737832e-01  5.29357312e-01 -2.69180806e+00
 -7.47245398e+00]
supnorm grad right now is: 37.254458986640486
Weights right now are: 
[-9.17794943e+00  4.68130921e+00 -9.16111256e+00  3.85833152e+00
  9.43251814e+00 -4.79000090e+00  9.56004983e+00 -4.57435991e+00
  6.50613845e+00 -6.62736789e+00  2.31574064e+00 -4.31540947e+00
  2.99474938e+00  7.49623441e+00  3.31940535e+01  5.35985141e+01
  1.53340436e+02  4.16692265e+00  2.62208382e+02  3.90706904e+00
  3.04024144e+00  5.96430849e+00  3.40783188e+01  5.30734837e+01
 -1.51887283e+01  2.69440287e+00 -8.04119759e-01  6.32228802e+00
  4.45836550e+00  2.73971187e+01  1.83167038e+02  1.36458165e+01
 -2.39307992e+01  1.83573334e+02  4.71590473e+00  2.53829603e+00
 -5.30817493e+01 -1.25262939e-01  4.78813029e+00  8.77533312e+01
  9.60544077e+01  6.13458892e+01 -1.82259636e+00  1.64508579e+00
 -1.32432337e+01  2.46403762e+01 -1.50695887e+00  1.35412818e+01
  1.59624103e-01  5.78396586e+00 -1.84361363e-01 -3.36270062e+00
 -3.71272806e+00  9.99464202e+01 -4.31569298e+00  4.38546175e+00
  7.85717183e+00  1.74103619e+00  1.52461848e+00 -2.27212144e+00
  2.77306286e+01  1.29188254e+01  5.78677880e+00  3.51472812e+00
  2.87911658e+01]
(65,)
54.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1991.1595774594673
gradient value of function right now is: [-9.95899516e-01 -1.61567199e+00  2.08194180e-02 -1.58459000e+00
  9.95899516e-01  1.61567199e+00 -2.08194180e-02  1.58459000e+00
 -2.78607264e+00 -3.32065640e-02 -2.76515140e-01 -1.49026264e-01
  3.22230995e+00  7.02381809e-21  4.64588089e-02  6.32346848e-03
  4.77307088e-03  1.38379037e-62  8.69335922e-05  4.39798039e-26
  2.77049638e+00  5.35134654e-21  4.01592778e-02  5.31198797e-03
 -6.80256120e-03 -2.58393552e-01  9.59952524e-01  1.05191280e+00
  2.89330286e-18 -5.85287497e-09 -3.68093242e-03  1.98102838e-25
  2.94451230e-03 -2.66801443e-03 -2.78155524e+00 -8.30983042e-01
  4.82635500e-03  4.65333482e-03 -4.53162193e-01 -2.11414828e-03
  1.37886932e-03  3.34827436e-03  5.54274619e-02  8.45603074e-02
  5.57551190e-01  3.33742823e-02  8.39524854e-01  8.38333890e-01
  3.44211613e-02  4.52927457e-01  2.09188257e-01  5.58375516e-01
  1.35824607e-01  2.49293861e-02 -3.03520342e+00 -2.92466127e+00
 -9.67156235e-01  1.56270056e+00  4.74885965e-01  2.02242258e+00
  6.31724259e-02 -1.29482543e-01  3.21445571e-01 -4.91673733e-01
  2.67466747e+00]
supnorm grad right now is: 3.2223099476417327
Weights right now are: 
[-9.44026258e+00  4.46240392e+00 -9.76268279e+00  3.63663601e+00
  9.69483129e+00 -4.57109561e+00  1.01616201e+01 -4.35266440e+00
  6.33998938e+00 -8.99304489e+00  2.19701037e+00 -4.21538006e+00
  3.05705471e+00  7.49623441e+00  3.43838843e+01  5.29343006e+01
  1.56569946e+02  4.16692265e+00  2.69789189e+02  3.90706904e+00
  3.13159093e+00  5.96430849e+00  3.53964459e+01  5.23444540e+01
 -1.59036469e+01  1.97918609e+00 -9.80004273e-01  6.18589211e+00
  4.45836550e+00  2.74003154e+01  1.89153902e+02  1.36458165e+01
 -2.42099223e+01  1.93770957e+02  4.54180836e+00  1.89352071e+00
 -5.55377618e+01  5.51048119e-01  4.86715135e+00  8.90196013e+01
  9.77651548e+01  6.12480069e+01 -2.12557240e+00  2.36850894e+00
 -1.29696829e+01  2.39854370e+01 -1.36195705e+00  1.34959332e+01
  1.84434906e-01  5.80866092e+00 -3.29802719e-01 -3.38748015e+00
 -3.68911639e+00  1.01316288e+02 -4.22228673e+00  4.45054764e+00
  7.80267028e+00  1.62634514e+00  1.61251975e+00 -2.19006666e+00
  2.83769660e+01  1.30899240e+01  5.27926603e+00  3.56996441e+00
  2.86283736e+01]
(65,)
56.00000000000001% of gradient descent iterations done. Method = Adam
objective value function right now is: -1985.0310769647908
gradient value of function right now is: [-2.10029675e+00 -2.85807274e+00 -8.19791359e-02 -2.86837716e+00
  2.10029675e+00  2.85807274e+00  8.19791359e-02  2.86837716e+00
  7.50664133e+00  2.89031863e-02  2.67799027e+00  3.80731100e+00
 -1.55171295e+00 -1.52709513e-20 -1.22169939e-02 -4.40423329e-02
 -2.61353807e-02  6.30896442e-66 -1.67438577e-03 -2.88418578e-23
 -1.27740405e+00 -1.07776955e-20 -9.04191391e-03 -3.71814313e-02
 -3.84807341e-02  6.07217793e-01  5.55716882e+00  6.37527557e+00
  3.63694103e-18  3.13774081e-09  3.90205434e-03  4.06151783e-26
  3.94589714e-03 -3.71348472e-03  4.69267760e-01 -7.52718289e-01
  2.69068385e-02  5.89913529e-02  6.04382402e+00  1.55349705e-02
  1.54708539e-02  2.91659622e-02  3.11706995e-03  6.14357351e-01
 -8.79982101e-01  1.22007188e-01 -9.95108163e-01 -9.64210413e-01
 -3.47066728e-01 -2.40561416e+00 -9.67041851e-02 -2.58996913e+00
 -9.94640890e+00 -3.53083100e-01 -1.62902384e+01 -1.68678476e+01
 -5.92237863e+00  2.38296029e+01  1.07905480e+01 -5.09994099e+01
 -1.55669661e-01  4.05040330e-01 -1.89410031e+00  1.06884813e+00
 -1.88626651e+01]
supnorm grad right now is: 50.99940988416738
Weights right now are: 
[-9.33663753e+00  4.51752937e+00 -1.01815942e+01  3.68521144e+00
  9.59120624e+00 -4.62622106e+00  1.05805315e+01 -4.40123982e+00
  6.41985268e+00 -8.76157079e+00  1.80040820e+00 -4.25729384e+00
  2.78271958e+00  7.49623441e+00  3.42237245e+01  5.34456284e+01
  1.59162642e+02  4.16692265e+00  2.77984182e+02  3.90706904e+00
  2.85589774e+00  5.96430849e+00  3.53546061e+01  5.27845112e+01
 -1.44189110e+01  1.73675979e+00 -6.69319155e-01  6.34255810e+00
  4.45836550e+00  2.74045353e+01  1.93664041e+02  1.36458165e+01
 -2.48651783e+01  1.99529273e+02  4.85651290e+00  1.42658710e+00
 -5.87465927e+01 -4.48991969e-01  4.59258841e+00  8.89304452e+01
  9.91855839e+01  6.11017638e+01 -2.24694880e+00  1.72485733e+00
 -1.28881573e+01  2.58351229e+01 -1.36698512e+00  1.33335651e+01
 -3.13654367e-01  5.46211200e+00  2.17167945e-01 -2.89983305e+00
 -3.74021857e+00  1.02686169e+02 -4.21611974e+00  4.40575521e+00
  7.57915390e+00  1.89490758e+00  1.44799988e+00 -2.22026098e+00
  2.93824798e+01  1.24029752e+01  4.95203364e+00  4.20217455e+00
  2.85217513e+01]
(65,)
57.99999999999999% of gradient descent iterations done. Method = Adam
objective value function right now is: -1989.499202983504
gradient value of function right now is: [-1.64469119e+00 -2.72444263e+00 -3.12424505e-02 -2.72303263e+00
  1.64469119e+00  2.72444263e+00  3.12424505e-02  2.72303263e+00
  6.66320927e+00  6.15358256e-02  3.08057543e+00  4.14123765e+00
  6.42218628e-02 -1.01052827e-20 -4.11524833e-03 -1.43310446e-02
 -1.17782397e-02  1.60725692e-67 -2.15369110e-04 -2.55087950e-27
  1.08974214e-01 -7.21550907e-21 -2.55323258e-03 -1.20216136e-02
 -3.21320660e-02  1.27570615e-01  3.43300940e+00  4.92958512e+00
  2.22544613e-19  2.03533811e-09  6.22036388e-03  3.20523765e-27
  6.54143688e-03 -2.78445929e-03 -2.87402082e-01 -6.23778875e-01
  2.45758003e-02  7.31938882e-02  3.41803332e+00  8.53328860e-03
  7.43010372e-03  2.42738949e-02  6.44186397e-02  4.49837391e-01
 -4.25594802e-01  9.51061331e-02 -4.45171451e-01 -4.15734865e-01
 -6.06893256e-02 -2.84873915e+00  5.02932738e-02 -1.14582049e+00
 -6.59678063e+00 -2.40107057e-01 -1.17072638e+01 -1.19654567e+01
 -3.31161015e+00  1.56623447e+01  8.62574421e+00 -3.33217609e+01
 -1.52065910e-01  3.12113638e-01 -1.43826173e+00  4.51989079e-01
 -1.77884971e+01]
supnorm grad right now is: 33.321760922724636
Weights right now are: 
[-9.14244605e+00  4.52848458e+00 -9.23076109e+00  3.69497667e+00
  9.39701476e+00 -4.63717627e+00  9.62969835e+00 -4.41100505e+00
  6.36923779e+00 -8.13812198e+00  1.96667512e+00 -4.17770823e+00
  3.07182365e+00  7.49623441e+00  3.44697893e+01  5.45056686e+01
  1.61766245e+02  4.16692265e+00  2.87510797e+02  3.90706904e+00
  3.14540688e+00  5.96430849e+00  3.56769090e+01  5.37664934e+01
 -1.84553020e+01  2.46350455e+00 -9.35100870e-01  6.09931601e+00
  4.45836550e+00  2.74081024e+01  1.99689016e+02  1.36458165e+01
 -2.28041032e+01  2.06956248e+02  4.74316314e+00  2.08985370e+00
 -5.86690474e+01  8.40141370e-01  4.47708128e+00  9.39438847e+01
  1.00305520e+02  6.36857079e+01 -1.14332964e+00  2.22013002e+00
 -1.28492491e+01  2.56501997e+01 -1.35435291e+00  1.36059037e+01
  8.67889766e-04  5.28374398e+00 -7.67368519e-03 -3.14009047e+00
 -3.86301341e+00  1.03786117e+02 -4.21560687e+00  4.29928961e+00
  7.93935539e+00  1.73957395e+00  1.78691963e+00 -2.25612346e+00
  2.79478514e+01  1.37899283e+01  4.71442950e+00  4.03411923e+00
  2.84436818e+01]
(65,)
60.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1991.335998476908
gradient value of function right now is: [ 6.63195759e-01  7.08230726e-01  2.03776540e-02  7.03859795e-01
 -6.63195759e-01 -7.08230726e-01 -2.03776540e-02 -7.03859795e-01
  6.70892927e-01 -3.02515609e-02 -2.81568385e-01 -2.75769877e-01
 -4.87840165e-01  1.94396755e-21 -1.33477988e-02 -5.69739560e-03
  6.10759265e-03 -1.07786982e-68  2.04062398e-04  8.73513603e-28
 -4.22862587e-01  1.36961618e-21 -1.17543289e-02 -4.84686655e-03
  1.83394804e-03  1.31358442e-01 -2.07688193e+00 -1.25655903e+00
 -1.49885568e-18 -4.35665842e-09 -2.70987752e-03 -9.44938341e-27
 -1.94935200e-03  1.87997725e-04  6.48015343e-01  2.87862411e-01
 -1.10555370e-02  6.61880116e-03  6.12650483e-01 -3.14473601e-03
 -8.26518638e-03 -9.76024121e-03 -4.58846359e-02 -4.28950905e-01
 -2.98016901e-01 -6.93925774e-03 -3.91172020e-01 -3.83367132e-01
 -3.49130713e-01  1.17781802e-01 -6.57428822e-01 -8.08624920e-01
 -5.15896757e-01 -4.32047253e-02  1.47304541e+00  1.69927895e+00
  1.81188214e+00 -3.99726071e+00 -2.98036181e-01 -7.57675227e+00
  1.89792531e-02 -4.53490343e-02 -3.67569282e-01  5.26343760e-01
 -3.09367944e+00]
supnorm grad right now is: 7.5767522689201
Weights right now are: 
[-9.10802802e+00  4.69798851e+00 -9.54954010e+00  3.85830579e+00
  9.36259673e+00 -4.80668020e+00  9.94847737e+00 -4.57433417e+00
  6.45258338e+00 -7.71996525e+00  2.12004016e+00 -4.49685840e+00
  2.93302746e+00  7.49623441e+00  3.50181657e+01  5.49760716e+01
  1.64217127e+02  4.16692265e+00  2.87534323e+02  3.90706904e+00
  2.99186668e+00  5.96430849e+00  3.63619006e+01  5.42127698e+01
 -1.61835718e+01  2.27284063e+00 -1.03379150e+00  6.39564031e+00
  4.45836550e+00  2.74089081e+01  2.02858467e+02  1.36458165e+01
 -2.63769005e+01  2.16003862e+02  4.68384969e+00  2.87221045e+00
 -6.19504962e+01  2.00078463e+00  4.56580590e+00  9.38141341e+01
  9.94413216e+01  6.27356168e+01 -2.77373159e+00  1.41279106e+00
 -1.29900397e+01  2.52476485e+01 -1.51827528e+00  1.34772192e+01
  6.70401778e-02  5.99506038e+00  7.01511203e-02 -3.64172599e+00
 -3.80080671e+00  1.04977098e+02 -4.17308743e+00  4.24649958e+00
  8.15188994e+00  1.75546807e+00  1.33968695e+00 -2.24164826e+00
  2.95076402e+01  1.28036038e+01  5.36938615e+00  3.97823788e+00
  2.83336581e+01]
(65,)
62.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1987.7390095474016
gradient value of function right now is: [-1.33530744e+00 -2.29398596e+00 -5.72738376e-02 -2.30946725e+00
  1.33530744e+00  2.29398596e+00  5.72738376e-02  2.30946725e+00
  9.77900795e+00  1.71578283e-01  4.69982185e+00  5.81455072e+00
 -2.09930799e+00 -1.82864556e-20 -3.12145664e-02 -4.12309196e-02
 -1.82525656e-02  2.69508515e-67 -4.07255491e-04 -1.98494290e-26
 -1.74534652e+00 -1.18057316e-20 -2.58124890e-02 -3.48383499e-02
 -3.00546902e-02  3.41143270e-01  5.25692761e+00  5.36336778e+00
  2.08778132e-18  1.68777170e-08  1.02223594e-02  1.08496364e-26
  4.52649318e-03 -3.23327479e-03  1.16592685e+00 -3.40921706e-01
  2.82061148e-02  7.41946718e-02  5.83348388e+00  1.10031153e-02
  1.01459170e-02  3.26607721e-02  4.65598731e-02  5.09489640e-01
 -9.64020686e-01  1.56898558e-01 -1.17562707e+00 -1.14460454e+00
 -8.59981611e-01 -4.17569405e+00 -1.18138121e+00 -2.77315847e+00
 -8.39422524e+00 -2.96977283e-01 -1.31964252e+01 -1.34374320e+01
 -3.72807322e+00  1.98043710e+01  9.06787410e+00 -4.28427794e+01
 -1.00209395e-01  2.36092003e-01 -1.78700665e+00  9.83718169e-01
 -2.39663037e+01]
supnorm grad right now is: 42.84277936171249
Weights right now are: 
[-9.24539727e+00  4.63827296e+00 -9.58694761e+00  3.79480390e+00
  9.49996598e+00 -4.74696465e+00  9.98588488e+00 -4.51083229e+00
  6.64278226e+00 -6.29992398e+00  2.21933817e+00 -4.20665906e+00
  2.92958577e+00  7.49623441e+00  3.54629574e+01  5.41083720e+01
  1.65243536e+02  4.16692265e+00  2.93762505e+02  3.90706904e+00
  2.99459383e+00  5.96430849e+00  3.70117313e+01  5.32693198e+01
 -1.92242296e+01  2.40725029e+00 -8.64649894e-01  6.31144328e+00
  4.45836550e+00  2.74125856e+01  2.08209650e+02  1.36458165e+01
 -2.46924651e+01  2.22252884e+02  4.91455680e+00  1.94756428e+00
 -6.36620121e+01  1.88678653e+00  4.86796832e+00  9.46970357e+01
  9.99335708e+01  6.27886771e+01 -1.72439267e+00  1.98642208e+00
 -1.32324148e+01  2.43373517e+01 -1.20922433e+00  1.38022923e+01
 -6.16662855e-02  5.64980815e+00 -2.25996384e-01 -3.28792282e+00
 -3.86107423e+00  1.05776021e+02 -4.12308292e+00  4.30318668e+00
  8.03515760e+00  1.68401872e+00  1.41132782e+00 -2.29158276e+00
  2.95774703e+01  1.28156962e+01  5.39847730e+00  3.87799549e+00
  2.83462036e+01]
(65,)
64.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1991.2509865644597
gradient value of function right now is: [-9.73063718e-01 -1.00384135e+00 -4.76635364e-02 -1.00444574e+00
  9.73063718e-01  1.00384135e+00  4.76635364e-02  1.00444574e+00
 -7.60281488e-01 -2.38031058e-02 -4.81979061e-01 -3.76746117e-01
 -1.23477132e-01  5.40702471e-22 -4.98180034e-03 -7.31768661e-03
 -1.26060735e-02  7.22066110e-70 -3.58834107e-04  1.82078785e-24
 -9.36588398e-02  3.83618115e-22 -4.14492818e-03 -6.32293521e-03
 -1.46856354e-02  2.60901151e-01  4.37727894e+00  2.42223796e+00
  1.22060205e-19 -6.74418894e-10 -1.85219007e-03  1.65310313e-27
  7.29226582e-03 -2.29174384e-05  4.34129905e-01 -4.81102442e-02
  1.03905062e-02  1.19582063e-02  7.50359123e-01  4.32593933e-03
  8.28808240e-03  9.72010231e-03  9.31360893e-02  3.42988797e-01
 -5.06756393e-01 -1.64092068e-02 -6.28934299e-01 -6.15344963e-01
 -1.21395058e-01  3.16328129e-01 -3.59733963e-01 -3.19576165e-01
 -3.37183372e+00 -1.09474842e-01 -5.47118094e+00 -5.61584111e+00
 -2.61893952e+00  1.10801075e+01  2.10631827e+00 -1.73165580e+01
  1.18614461e-02 -2.72293185e-02 -4.23407787e-02 -1.48646141e-01
 -1.02466480e+00]
supnorm grad right now is: 17.31655797493444
Weights right now are: 
[-9.18265817e+00  4.75139599e+00 -9.75357595e+00  3.90685105e+00
  9.43722688e+00 -4.86008768e+00  1.01525132e+01 -4.62287943e+00
  6.27496025e+00 -7.42862733e+00  2.15694674e+00 -4.35063261e+00
  2.98877285e+00  7.49623441e+00  3.61826503e+01  5.52712241e+01
  1.66515758e+02  4.16692265e+00  2.98046070e+02  3.90706904e+00
  3.03262802e+00  5.96430849e+00  3.77532557e+01  5.43270177e+01
 -1.97902820e+01  2.31868456e+00 -6.22971746e-01  6.29785483e+00
  4.45836550e+00  2.74143833e+01  2.12812744e+02  1.36458165e+01
 -2.75272558e+01  2.29780190e+02  4.82543482e+00  2.31462001e+00
 -6.34513050e+01  2.07247482e+00  4.57768022e+00  9.68914063e+01
  9.95715245e+01  6.52249089e+01 -3.01292326e+00  1.94334749e+00
 -1.31678128e+01  2.55237008e+01 -1.49841899e+00  1.35936219e+01
 -2.23780419e-01  5.94181482e+00 -4.15601875e-01 -3.14534666e+00
 -3.93097737e+00  1.06209210e+02 -4.03456940e+00  4.29626990e+00
  7.97894365e+00  1.92703737e+00  1.40081182e+00 -2.19539024e+00
  2.92535513e+01  1.37882323e+01  5.08485419e+00  3.89531062e+00
  2.86134523e+01]
(65,)
66.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1991.03044808449
gradient value of function right now is: [-7.36269224e-01 -6.51939608e-01  4.72590676e-03 -6.39062875e-01
  7.36269224e-01  6.51939608e-01 -4.72590676e-03  6.39062875e-01
 -6.21291891e+00 -1.94175692e-02 -1.38497537e+00 -2.00903250e+00
  2.37476095e+00  4.70783699e-22  3.98577713e-02  2.76715677e-02
  5.09250646e-04 -1.30502960e-68  6.27930292e-05  5.79289160e-23
  2.05015164e+00  3.06062183e-22  3.42724816e-02  2.37698944e-02
  1.53855085e-02  1.43466516e-01  2.91351480e+00 -2.96732623e-03
 -1.83025980e-20 -2.71899765e-09 -1.97222997e-03 -1.97405622e-28
  9.55339833e-04 -1.69844214e-05 -2.18221097e+00 -1.96479230e-01
 -1.25877310e-02 -7.00601292e-02 -3.73752377e+00 -8.19154499e-03
 -3.52797722e-03 -1.62992942e-02  5.12693161e-02 -1.56341647e-01
  7.28458368e-02 -7.82430517e-02  2.03118947e-01  1.74543279e-01
  5.88061905e-01  1.37780569e+00  1.09342260e+00  2.43802138e+00
  5.29132566e-01  5.54814285e-02  6.42762180e-01  9.06090949e-01
  6.44458649e-01 -1.96452975e+00 -2.99266256e+00  6.41828705e+00
  1.38475887e-01 -3.19105451e-01  1.09001851e+00 -7.55364503e-01
  1.09750578e+01]
supnorm grad right now is: 10.975057764957326
Weights right now are: 
[-9.63565038e+00  4.61031237e+00 -9.08604876e+00  3.76369792e+00
  9.89021909e+00 -4.71900406e+00  9.48498603e+00 -4.47972631e+00
  6.27404103e+00 -7.49116462e+00  2.11264783e+00 -4.32710333e+00
  2.88737849e+00  7.49623441e+00  3.72810401e+01  5.53701924e+01
  1.69127569e+02  4.16692265e+00  3.00961215e+02  3.90706904e+00
  2.92081192e+00  5.96430849e+00  3.90249670e+01  5.43583768e+01
 -2.00613529e+01  2.81532288e+00 -7.26129149e-01  6.26639584e+00
  4.45836550e+00  2.74155293e+01  2.17971128e+02  1.36458165e+01
 -2.62740863e+01  2.37826250e+02  4.69540097e+00  2.07847125e+00
 -6.48956395e+01  6.61610908e-01  4.65210729e+00  9.70373513e+01
  1.00605381e+02  6.65940909e+01 -1.94620059e+00  2.14104619e+00
 -1.34260684e+01  2.36817219e+01 -1.66593199e+00  1.34782802e+01
 -2.26563928e-01  5.54691281e+00 -1.49641233e-01 -2.81096329e+00
 -4.00242551e+00  1.07075369e+02 -3.97745466e+00  4.41235197e+00
  8.08035661e+00  1.74026535e+00  1.72993928e+00 -2.17550389e+00
  3.00567262e+01  1.33646299e+01  4.94301701e+00  3.89568025e+00
  2.86893891e+01]
(65,)
68.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1989.4472063752025
gradient value of function right now is: [ 1.53280545e+00  2.02796857e+00  5.66420868e-02  2.00655684e+00
 -1.53280545e+00 -2.02796857e+00 -5.66420868e-02 -2.00655684e+00
  2.44972935e+00 -5.84638579e-02  4.63096997e-01  3.60531872e-01
 -3.22215015e+00 -2.73290926e-23 -3.74958236e-02 -2.81053697e-02
  1.49143735e-02  2.13865249e-68  2.94178574e-04  2.47954665e-29
 -2.77771271e+00  2.08677107e-23 -3.24105126e-02 -2.40210966e-02
  8.02638602e-03 -9.44150823e-02 -2.94184042e+00 -3.44989622e+00
  3.74614636e-18  1.94225865e-09 -3.47784582e-03  3.51985350e-26
  2.00400443e-03  6.85324251e-04  2.14532602e+00  4.05357007e-01
 -1.21830034e-02 -1.20241614e-02  2.53174718e+00  3.43122486e-05
 -2.91054305e-03 -1.65901331e-02  5.25412379e-02 -2.06604868e-01
  7.03140164e-02 -1.30258087e-02  1.68986526e-02  1.98254014e-02
 -8.87580329e-01  1.00748855e-01 -1.91948556e+00 -2.25424517e+00
  1.39287831e+00 -1.67542972e-02  4.92696638e+00  5.03199183e+00
  2.15702858e+00 -7.92559754e+00  3.68027404e-01 -2.87958160e+00
 -5.56565330e-02  1.21152554e-01 -3.70812801e-01  8.95594655e-01
 -3.49586919e+00]
supnorm grad right now is: 7.925597535692296
Weights right now are: 
[-9.33691425e+00  4.69851151e+00 -9.71622487e+00  3.84733738e+00
  9.59148296e+00 -4.80720320e+00  1.01151621e+01 -4.56336577e+00
  6.65444316e+00 -8.17394659e+00  2.24849336e+00 -4.08510067e+00
  2.83211099e+00  7.49623441e+00  3.71332807e+01  5.59576633e+01
  1.71491403e+02  4.16692265e+00  3.04244910e+02  3.90706904e+00
  2.88403419e+00  5.96430849e+00  3.90168628e+01  5.48700922e+01
 -1.98695534e+01  1.97865089e+00 -9.19150615e-01  6.18060806e+00
  4.45836550e+00  2.74168858e+01  2.20806703e+02  1.36458165e+01
 -2.56991853e+01  2.42536784e+02  5.29167053e+00  2.32580852e+00
 -6.91567674e+01  3.43182452e-01  4.96777672e+00  9.79609838e+01
  1.01164038e+02  6.48937133e+01 -1.87425223e+00  2.15428432e+00
 -1.30187350e+01  2.53658897e+01 -1.22971369e+00  1.38588167e+01
  5.54470664e-01  6.38813400e+00 -1.44492704e-01 -3.35024526e+00
 -3.64616043e+00  1.08424144e+02 -4.12031928e+00  4.16946975e+00
  8.15591315e+00  1.69693876e+00  1.60135308e+00 -2.37750414e+00
  2.96287216e+01  1.40546985e+01  5.49183156e+00  4.07180307e+00
  2.86591352e+01]
(65,)
70.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1991.9080748682127
gradient value of function right now is: [ 9.97911840e-01  1.45695510e+00  8.00964958e-03  1.45382499e+00
 -9.97911840e-01 -1.45695510e+00 -8.00964958e-03 -1.45382499e+00
 -1.41073803e+00 -2.68824513e-02 -1.54776769e+00 -1.71804886e+00
 -1.65125498e-01  4.60238325e-22 -3.08234354e-03  8.32825497e-03
  3.03836194e-03 -1.90601458e-73  7.95017090e-05  1.64497856e-23
 -1.75626486e-01  2.64981051e-22 -3.09921610e-03  7.04587338e-03
  1.52542974e-03 -1.16386001e-01 -4.00542866e+00 -2.26692712e+00
 -1.25295114e-20 -5.48384221e-10 -2.82292182e-03 -2.73126089e-29
 -8.52240021e-04  8.54006597e-04  3.25104173e-01  3.66384274e-01
 -1.90032803e-03 -2.64466477e-03 -1.22534682e+00 -3.12031898e-03
 -2.42486222e-03 -3.94751795e-03  1.58307377e-03 -7.86829899e-02
  1.18680609e-01 -1.99923284e-02  7.90633514e-02  8.61572211e-02
 -2.18480298e-01  1.06569894e+00 -5.52997232e-01 -2.53248521e-02
  3.11871040e+00  1.05798697e-01  6.82689772e+00  7.00510172e+00
  2.46635845e+00 -9.50176186e+00 -5.34959935e+00  1.68453314e+01
  1.65127544e-01 -4.47853687e-01  2.24354000e-01  3.60607844e-01
  5.99256696e+00]
supnorm grad right now is: 16.845331376782514
Weights right now are: 
[-9.35181900e+00  4.71454879e+00 -9.85516185e+00  3.86564193e+00
  9.60638771e+00 -4.82324048e+00  1.02540991e+01 -4.58167031e+00
  6.59574025e+00 -7.62609489e+00  1.60333597e+00 -4.12249121e+00
  2.99577804e+00  7.49623441e+00  3.80590888e+01  5.59046296e+01
  1.71086153e+02  4.16692265e+00  3.04892527e+02  3.90706904e+00
  3.07050623e+00  5.96430849e+00  4.01442510e+01  5.47549878e+01
 -2.12988006e+01  2.64466578e+00 -7.19798091e-01  6.29343538e+00
  4.45836550e+00  2.74246057e+01  2.27519146e+02  1.36458165e+01
 -2.63445679e+01  2.48494221e+02  5.29015933e+00  2.31410299e+00
 -6.99048575e+01  1.97544588e+00  4.94037310e+00  1.00141602e+02
  1.02920632e+02  6.63218091e+01 -1.37162384e+00  1.85180911e+00
 -1.35901931e+01  2.61036994e+01 -1.40657692e+00  1.36853248e+01
  1.70228337e-01  5.44449095e+00  3.55422067e-01 -3.12751995e+00
 -3.92853870e+00  1.09251575e+02 -3.88383960e+00  4.35482604e+00
  7.93419763e+00  1.87678730e+00  1.37682493e+00 -2.21234899e+00
  3.14388388e+01  1.26770743e+01  5.10106102e+00  3.88832138e+00
  2.86054273e+01]
(65,)
72.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1985.7608992947462
gradient value of function right now is: [-1.84158282e+00 -2.55644293e+00 -9.67036465e-02 -2.59473530e+00
  1.84158282e+00  2.55644293e+00  9.67036465e-02  2.59473530e+00
  9.59002980e+00  8.91459889e-02  3.93008342e+00  4.89873646e+00
 -3.19084206e+00 -9.61370854e-22 -4.78690188e-02 -5.86350540e-02
 -2.53281593e-02  2.52812003e-71 -9.19348609e-04 -4.73272235e-27
 -2.57932833e+00 -5.24464648e-22 -3.84963063e-02 -4.83190586e-02
 -7.23597160e-03  3.24098543e-01  6.93823420e+00  6.27284414e+00
  7.25842363e-20  9.28997002e-09  6.33267872e-03  2.37069138e-28
  9.89410405e-03 -1.98392492e-03  2.57852241e+00 -3.05837586e-01
  1.45121683e-02  4.20377198e-02  6.80853789e+00  1.05977364e-02
  1.05468354e-02  2.33532491e-02  9.75264548e-03  7.30193897e-01
 -8.09606384e-01  1.34295646e-01 -9.84867258e-01 -9.85012032e-01
 -9.86101371e-01 -3.68690530e+00 -1.39807892e+00 -4.52290424e+00
 -8.55765054e+00 -3.09459064e-01 -1.51087698e+01 -1.56806192e+01
 -4.55189904e+00  2.04114421e+01  1.16580457e+01 -4.75883224e+01
 -9.82369731e-02  2.31484577e-01 -2.89210626e+00  2.38948918e+00
 -2.39251001e+01]
supnorm grad right now is: 47.58832239956732
Weights right now are: 
[-9.35222418e+00  4.56177495e+00 -9.04433031e+00  3.70985480e+00
  9.60679289e+00 -4.67046664e+00  9.44326758e+00 -4.42588318e+00
  6.70358180e+00 -7.11531638e+00  1.69482992e+00 -3.98807690e+00
  3.13263004e+00  7.49623441e+00  3.88279429e+01  5.57613522e+01
  1.72929001e+02  4.16692265e+00  3.08307187e+02  3.90706904e+00
  3.23814439e+00  5.96430849e+00  4.10886283e+01  5.44922493e+01
 -2.43808801e+01  2.28968609e+00 -6.52188492e-01  6.37639819e+00
  4.45836550e+00  2.74295427e+01  2.32223489e+02  1.36458165e+01
 -2.67834612e+01  2.56504606e+02  5.17301889e+00  2.36536226e+00
 -6.99055265e+01  8.95708658e-01  5.18417256e+00  1.04389971e+02
  1.03714248e+02  6.71055572e+01 -3.29755328e+00  3.07292150e+00
 -1.34113498e+01  2.43462671e+01 -1.25084238e+00  1.41288076e+01
  5.04843740e-01  5.72215309e+00 -6.61810057e-02 -3.10474923e+00
 -3.58333402e+00  1.09882610e+02 -4.15559985e+00  3.93344339e+00
  7.97327866e+00  1.79287563e+00  1.34461598e+00 -2.32689530e+00
  3.12207204e+01  1.38172295e+01  4.77120502e+00  4.12779294e+00
  2.86147265e+01]
(65,)
74.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1990.9814636696708
gradient value of function right now is: [ 1.66393848e-01  6.02298808e-01  9.18326656e-03  6.17006743e-01
 -1.66393848e-01 -6.02298808e-01 -9.18326656e-03 -6.17006743e-01
 -4.98769465e+00 -7.13780964e-02 -2.71838294e+00 -3.17612855e+00
  1.35079052e+00  3.03924314e-22  1.75394139e-02  1.46642402e-02
  2.78643649e-03 -4.23674670e-70 -1.87540225e-05  7.77441899e-26
  1.10861301e+00  1.70000059e-22  1.44307507e-02  1.21814941e-02
  2.60022383e-03 -5.13667644e-01 -2.46178018e+00 -1.47864852e+00
 -1.43590322e-18 -2.75623489e-08 -5.70523773e-03 -2.89339079e-27
  6.42982431e-05  1.04546008e-03 -8.57714576e-01  2.93142882e-02
 -7.61393518e-04 -2.26794791e-02 -2.29216208e+00 -4.27840239e-03
 -8.82367615e-04 -2.61708058e-03  4.45367289e-03  1.45380726e-02
  7.86497090e-01 -6.65843625e-02  9.08288740e-01  9.20305906e-01
  5.50317940e-03  2.07170280e+00 -1.83122685e-01  9.45584761e-01
  4.22116954e+00  1.72234971e-01  5.69487922e+00  5.73630241e+00
  9.87738576e-01 -6.29819932e+00 -6.87047503e+00  2.69261431e+01
  1.37887866e-01 -3.32582166e-01  7.86596999e-01  3.75692683e-02
  1.24628615e+01]
supnorm grad right now is: 26.926143064395877
Weights right now are: 
[-9.25369526e+00  4.62273370e+00 -1.02027583e+01  3.76516505e+00
  9.50826397e+00 -4.73142539e+00  1.06016956e+01 -4.48119343e+00
  6.61137057e+00 -7.53103464e+00  1.77691387e+00 -4.34355475e+00
  3.12199820e+00  7.49623441e+00  3.92559162e+01  5.64691214e+01
  1.74190147e+02  4.16692265e+00  3.13913961e+02  3.90706904e+00
  3.21249530e+00  5.96430849e+00  4.16217489e+01  5.50819369e+01
 -2.37917631e+01  2.13343094e+00 -7.95742446e-01  6.52582084e+00
  4.45836550e+00  2.74330225e+01  2.35737530e+02  1.36458165e+01
 -2.81980845e+01  2.64754215e+02  4.93701912e+00  2.58768023e+00
 -7.26094849e+01  1.53913459e+00  4.81941244e+00  1.04224557e+02
  1.04529088e+02  6.52442874e+01 -1.07309416e+00  1.97107358e+00
 -1.34299687e+01  2.40844390e+01 -1.37264905e+00  1.38867288e+01
  1.17793278e-02  6.20769090e+00 -1.64904355e-01 -3.43135835e+00
 -3.52654463e+00  1.10891485e+02 -3.95338010e+00  4.21192823e+00
  8.11667681e+00  1.92961301e+00  1.22539044e+00 -2.21852491e+00
  3.20547341e+01  1.36866958e+01  5.62892812e+00  3.65409015e+00
  2.86011561e+01]
(65,)
76.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1991.82860004558
gradient value of function right now is: [ 8.73717058e-02  9.58519678e-02 -4.24462668e-03  7.58053147e-02
 -8.73717058e-02 -9.58519678e-02  4.24462668e-03 -7.58053147e-02
  1.83596365e+00  7.22826050e-02  1.21641447e+00  1.11545366e+00
 -1.46130431e+00 -2.23664973e-22 -1.79012601e-02 -1.81060454e-02
 -1.35620620e-03  1.24470635e-72  1.41942826e-04  4.68955433e-29
 -1.19939324e+00 -1.19942819e-22 -1.48863835e-02 -1.47864145e-02
  1.13625811e-02  1.90934806e-01  2.03800536e+00  4.88442449e-01
  3.87418416e-21  2.04133360e-09  2.94560256e-03  3.25650459e-30
 -4.83380747e-04  5.14911673e-04  9.94563444e-01  1.05350788e-01
 -1.45639933e-02 -2.14808995e-02  1.70003279e+00 -2.79040103e-03
 -4.58998027e-03 -2.19598561e-02  4.67661526e-02 -2.05303656e-01
 -4.18943684e-01 -3.03359711e-02 -5.65459477e-01 -5.48356987e-01
 -6.48546208e-01 -1.13256098e+00 -1.18246591e+00 -1.18893876e+00
 -1.88222887e+00 -6.65901672e-02 -2.04273173e+00 -1.84465539e+00
  2.72150739e-01  2.15409943e+00  1.93484432e+00 -1.21283018e+01
  1.50029918e-02 -3.29189841e-02 -5.16923493e-02  1.22558151e-01
 -4.08885893e+00]
supnorm grad right now is: 12.128301846596916
Weights right now are: 
[-9.27961571e+00  4.75097995e+00 -9.63540539e+00  3.88370087e+00
  9.53418442e+00 -4.85967164e+00  1.00343427e+01 -4.59972925e+00
  6.63462780e+00 -6.99188488e+00  2.17790529e+00 -4.40693686e+00
  2.93036626e+00  7.49623441e+00  3.94819819e+01  5.63029937e+01
  1.75655316e+02  4.16692265e+00  3.18269393e+02  3.90706904e+00
  3.05388514e+00  5.96430849e+00  4.19878985e+01  5.48184928e+01
 -2.42341246e+01  2.89556244e+00 -7.51141624e-01  6.48597321e+00
  4.45836550e+00  2.74428049e+01  2.41815351e+02  1.36458165e+01
 -3.16592672e+01  2.70880083e+02  5.13564165e+00  2.25495725e+00
 -7.26379878e+01  5.11528304e-01  4.88381814e+00  1.07416361e+02
  1.04179030e+02  6.65222369e+01 -1.26071780e+00  1.82962612e+00
 -1.32165539e+01  2.41630054e+01 -1.26625681e+00  1.39283501e+01
  4.58287841e-02  5.56469045e+00  9.54015773e-02 -3.59531061e+00
 -3.57542398e+00  1.10742351e+02 -4.04848051e+00  4.14450780e+00
  8.36823476e+00  1.75534004e+00  1.40113803e+00 -2.34676465e+00
  3.17155074e+01  1.40695138e+01  5.82524608e+00  3.75931210e+00
  2.87279824e+01]
(65,)
78.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1988.1940471507028
gradient value of function right now is: [-2.52831016e+00 -2.92343999e+00 -5.40002106e-02 -2.92844603e+00
  2.52831016e+00  2.92343999e+00  5.40002106e-02  2.92844603e+00
  7.17000156e-01  6.09789279e-03 -2.88319090e-01  3.14748756e-01
 -3.25113423e-01  1.58375378e-23 -1.64717909e-02 -1.87708700e-02
 -1.69935967e-02  2.00473532e-73 -1.47828118e-04 -8.92934168e-27
 -1.93568240e-01  7.50242459e-24 -1.30217887e-02 -1.52406261e-02
 -1.68571494e-02  9.29095803e-01  7.47561181e+00  5.36055470e+00
  4.69809450e-22 -2.42292809e-09 -2.60915466e-04  2.25285220e-30
  1.15484791e-02 -4.49487639e-04  1.05698799e+00 -1.45726367e-01
  2.08893368e-02  6.05483789e-02  2.52212968e+00  9.54275850e-03
  9.22849617e-03  2.45650590e-02  8.88166219e-02  8.27135820e-01
 -1.60815608e+00 -3.02550236e-03 -1.91893873e+00 -1.90377899e+00
  5.20182286e-01 -4.22003822e-01  6.23867388e-01 -7.58988309e-01
 -9.05142224e+00 -3.27582856e-01 -1.40422623e+01 -1.45530430e+01
 -3.46569254e+00  2.06189932e+01  6.86046939e+00 -4.95021873e+01
  9.76415985e-03 -2.71023592e-02 -1.37323977e+00  8.43014785e-01
 -5.43225710e+00]
supnorm grad right now is: 49.50218726723885
Weights right now are: 
[-9.26749563e+00  4.59296395e+00 -9.95188226e+00  3.72071611e+00
  9.52206434e+00 -4.70165564e+00  1.03508195e+01 -4.43674449e+00
  6.54697417e+00 -6.17618438e+00  1.92111467e+00 -4.70082447e+00
  2.90433422e+00  7.49623441e+00  4.06228056e+01  5.64458309e+01
  1.78832563e+02  4.16692265e+00  3.19995130e+02  3.90706904e+00
  3.01745733e+00  5.96430849e+00  4.35570743e+01  5.47424191e+01
 -2.84072515e+01  2.35944260e+00 -8.09257506e-01  6.27627162e+00
  4.45836550e+00  2.74458731e+01  2.46855635e+02  1.36458165e+01
 -2.94090264e+01  2.78001399e+02  5.19355499e+00  2.86485517e+00
 -7.21724025e+01  8.96848360e-02  4.74114887e+00  1.11293315e+02
  1.04115330e+02  6.86362255e+01 -2.84320686e+00  2.89935196e+00
 -1.33020308e+01  2.32142685e+01 -1.87572816e+00  1.37186270e+01
  8.56452107e-01  5.61526904e+00  7.28814050e-02 -3.21753173e+00
 -3.64148643e+00  1.10852000e+02 -3.91181635e+00  3.85240826e+00
  8.64281347e+00  1.76536124e+00  1.70664535e+00 -2.36905449e+00
  3.21387029e+01  1.41498299e+01  4.91819066e+00  4.32100294e+00
  2.88807943e+01]
(65,)
80.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1989.4161640285079
gradient value of function right now is: [ 9.37669585e-01  1.07067277e+00  4.14539024e-02  1.09695153e+00
 -9.37669585e-01 -1.07067277e+00 -4.14539024e-02 -1.09695153e+00
 -3.15338135e+00 -6.88683122e-02 -1.11282310e+00 -1.27517069e+00
  2.25618714e+00  6.26577063e-23  4.12838889e-02  4.68028436e-02
  1.02290843e-02 -5.93598975e-77  1.37280342e-04  3.12585523e-29
  1.82031530e+00  3.37118241e-23  3.33036867e-02  3.85000512e-02
  1.63082196e-03 -4.78512292e-01 -4.42836158e+00 -3.24908199e+00
 -7.29283351e-21 -9.31913889e-10 -4.52469775e-03 -1.62918820e-29
 -4.69871243e-04 -1.76196571e-03 -2.28310320e+00  8.09556116e-02
 -1.80605973e-03 -2.50894330e-02 -4.16938828e+00 -8.03240878e-03
 -1.73127367e-03 -4.49209231e-03  8.25379601e-03 -4.74121602e-02
  1.20816523e+00  5.51634605e-02  1.57927065e+00  1.54919203e+00
  2.05674392e+00  1.98066307e+00  3.72240744e+00  5.05295095e+00
  6.17362127e+00  2.50537058e-01  8.86612446e+00  8.91083619e+00
  2.01530589e+00 -1.22613869e+01 -7.82860507e+00  4.21316445e+01
  6.24904055e-02 -1.60250491e-01  9.06433514e-01 -5.49784210e-01
  1.37873884e+01]
supnorm grad right now is: 42.13164448308822
Weights right now are: 
[ -9.14074269   4.54476787  -9.47845916   3.6678833    9.3953114
  -4.65345956   9.87739643  -4.38391168   6.87028053  -8.19724203
   2.12099558  -4.18931147   2.96890019   7.49623441  41.37663091
  56.12723697 179.42265431   4.16692265 324.17945254   3.90706904
   3.06516019   5.96430849  44.5073433   54.14164339 -25.31656318
   2.37633614  -0.90696001   6.21410459   4.4583655   27.44663461
 250.6724443   13.64581649 -32.45968794 281.71931649   5.13260513
   2.70956297 -75.15583653   1.54285441   5.07705858 110.6832372
 105.52746626  68.84371926  -2.10124428   2.25682247 -12.81505755
  25.68016242  -1.57300875  13.94726793   0.65668775   5.82708704
   0.36596404  -2.7804504   -3.76106026 111.89063522  -3.78027502
   3.86549187   8.07351319   1.83983212   1.45676429  -2.20431912
  32.96526459  14.01299773   4.83685884   3.51947242  28.58907152]
(65,)
82.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1991.3914707384347
gradient value of function right now is: [ 5.74133797e-01  1.25636675e+00  3.84474448e-02  1.26040811e+00
 -5.74133797e-01 -1.25636675e+00 -3.84474448e-02 -1.26040811e+00
 -5.34765942e+00 -5.77344842e-02 -2.68672443e+00 -3.76815720e+00
  3.87250879e-01  6.58276784e-23  1.53543056e-02  1.86701992e-02
  9.84057989e-03 -9.87958824e-75  1.11321081e-04  1.60943343e-28
  2.95171771e-01  3.22942293e-23  1.25589849e-02  1.55716419e-02
  5.00388067e-02 -4.41078902e-01 -2.24213688e+00 -2.79504134e+00
 -3.49798107e-20 -3.22822517e-09 -5.21422488e-03 -1.32734360e-28
  2.43695625e-02  1.10820473e-03 -5.97069862e-01  6.09143602e-02
 -5.44746937e-02 -3.12406643e-02 -3.26867274e+00 -1.16481072e-02
 -1.87249492e-02 -5.31043570e-02 -3.64149134e-03 -8.76955258e-01
  1.03338547e+00 -3.43015895e-02  1.21182432e+00  1.15152466e+00
  2.78579402e-01  2.06203257e+00  3.66578419e-01  1.31743006e+00
  5.48218592e+00  1.93640193e-01  7.18719386e+00  7.69450702e+00
  2.94019865e+00 -1.18529065e+01 -5.07746853e+00  2.76352240e+01
  6.16542868e-02 -1.23414397e-01  8.76110685e-01 -9.09525722e-02
  1.26402221e+01]
supnorm grad right now is: 27.635223957216095
Weights right now are: 
[-9.36517174e+00  4.59107012e+00 -9.66867707e+00  3.71182141e+00
  9.61974045e+00 -4.69976181e+00  1.00676143e+01 -4.42784980e+00
  6.60755608e+00 -8.79038925e+00  1.85716802e+00 -4.34274937e+00
  2.91616844e+00  7.49623441e+00  4.20119096e+01  5.64128269e+01
  1.81056504e+02  4.16692265e+00  3.26659734e+02  3.90706904e+00
  2.98888153e+00  5.96430849e+00  4.53863769e+01  5.42922098e+01
 -2.21763047e+01  2.70370649e+00 -6.87478103e-01  6.16129269e+00
  4.45836550e+00  2.74472633e+01  2.53614466e+02  1.36458165e+01
 -3.69549183e+01  2.88485933e+02  4.80842507e+00  2.54672061e+00
 -7.60493087e+01  1.85412631e+00  4.55104185e+00  1.13320886e+02
  1.05142786e+02  6.93213308e+01 -4.96558460e-01  2.71647331e-01
 -1.28027052e+01  2.63215651e+01 -1.61702219e+00  1.40644956e+01
  8.37362930e-01  6.08578369e+00 -2.10775942e-01 -3.37930762e+00
 -3.63499278e+00  1.12301231e+02 -3.64347620e+00  3.94602682e+00
  8.13596847e+00  1.87565391e+00  1.51841303e+00 -2.22800578e+00
  3.18626678e+01  1.50143171e+01  4.95981337e+00  3.75807450e+00
  2.86079484e+01]
(65,)
84.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1991.0530813808457
gradient value of function right now is: [ 4.89493265e-01  2.13211474e-01 -1.87778694e-02  1.97484796e-01
 -4.89493265e-01 -2.13211474e-01  1.87778694e-02 -1.97484796e-01
  5.31650665e+00  3.83310956e-02  2.57892723e+00  2.91008392e+00
 -1.50078580e+00 -1.41367172e-22 -2.23029298e-02 -2.08015944e-02
 -4.76371638e-03  2.22284857e-77 -3.81589375e-06 -1.37925636e-27
 -1.25576491e+00 -6.03262714e-23 -1.86051818e-02 -1.72888829e-02
 -5.45471709e-03  3.13580427e-01 -5.88283616e-01  4.83254482e-01
  2.69200419e-21  3.18408270e-09  3.48791141e-03  3.91888945e-29
  2.70169166e-03 -3.32417202e-04  1.19908494e+00  1.97360082e-01
  3.01698058e-03  1.78808073e-02  2.68284609e+00  1.58196235e-03
  2.83708025e-03  3.05490109e-03  5.43277730e-02  1.11486762e-01
 -1.02058968e+00  3.17011394e-02 -1.26427712e+00 -1.24424736e+00
 -6.75001132e-01 -1.77386177e+00 -1.08216629e+00 -1.69133398e+00
 -1.61049967e+00 -5.72025342e-02 -1.07916019e+00 -1.11704600e+00
 -3.38619728e-01  3.87435708e+00  1.67744814e+00 -9.28050459e+00
 -3.87798300e-03  8.07543500e-03 -8.07354077e-01  7.19940058e-01
 -9.80058228e+00]
supnorm grad right now is: 9.800582275197753
Weights right now are: 
[-9.09145734e+00  4.69341484e+00 -1.03334241e+01  3.80687329e+00
  9.34602605e+00 -4.80210653e+00  1.07323614e+01 -4.52290167e+00
  6.84453446e+00 -7.55774730e+00  2.27943159e+00 -4.18166451e+00
  2.98397422e+00  7.49623441e+00  4.15773192e+01  5.62549623e+01
  1.82585008e+02  4.16692265e+00  3.34265201e+02  3.90706904e+00
  3.05999301e+00  5.96430849e+00  4.53060572e+01  5.40197835e+01
 -2.58864879e+01  3.67405309e+00 -8.53174616e-01  6.20211394e+00
  4.45836550e+00  2.74478308e+01  2.56717403e+02  1.36458165e+01
 -3.38464997e+01  2.96426558e+02  4.92054650e+00  2.55939144e+00
 -7.51244238e+01  1.16318642e+00  4.83301347e+00  1.16327122e+02
  1.06658902e+02  7.31307285e+01 -1.95083849e+00  1.31398044e+00
 -1.30024174e+01  2.61722523e+01 -1.76691048e+00  1.38159418e+01
  2.18207057e-01  5.93824532e+00 -1.18480585e-02 -3.49879282e+00
 -3.74816645e+00  1.12830335e+02 -3.57049417e+00  3.77214968e+00
  7.92248734e+00  1.87895867e+00  1.37818837e+00 -2.28110658e+00
  3.20357798e+01  1.53489545e+01  5.19975814e+00  4.36402199e+00
  2.86438631e+01]
(65,)
86.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1989.356222426219
gradient value of function right now is: [ 1.85709012e+00  3.02406051e+00  8.04083133e-02  3.03059241e+00
 -1.85709012e+00 -3.02406051e+00 -8.04083133e-02 -3.03059241e+00
 -8.55511183e+00 -5.32650928e-02 -4.34343918e+00 -5.30949194e+00
  9.37424930e-01  4.48599018e-23  2.21476394e-02  4.85526429e-02
  2.26733054e-02 -1.42109258e-79  3.68879944e-04  1.96562191e-28
  7.13129227e-01  1.77183184e-23  1.76939186e-02  4.02176120e-02
  6.89972171e-03 -3.69920790e-01 -4.98523814e+00 -5.86589508e+00
 -3.77946916e-22 -3.20467540e-10 -5.14550582e-03 -6.05319207e-31
  7.82398411e-04  1.00931070e-03 -1.06647127e+00  3.38674209e-01
 -3.94049012e-03 -3.70223717e-02 -6.69127315e+00 -7.20420578e-03
 -1.34098399e-03 -4.03247852e-03  4.11195411e-02 -3.24671066e-02
  1.21593425e+00 -7.07986128e-02  1.44917929e+00  1.41858930e+00
  7.47441197e-01  3.24398753e+00  1.26696051e+00  2.64879740e+00
  1.02511803e+01  3.07192691e-01  1.54282547e+01  1.54530316e+01
  3.91818104e+00 -2.15531550e+01 -1.10540440e+01  5.27883995e+01
 -3.17916751e-02  6.33275562e-02  1.68986634e+00 -8.40629008e-01
  1.89078002e+01]
supnorm grad right now is: 52.788399545572936
Weights right now are: 
[-9.21694460e+00  4.80830642e+00 -1.00133213e+01  3.91754059e+00
  9.47151331e+00 -4.91699811e+00  1.04122585e+01 -4.63356897e+00
  6.51726232e+00 -8.39042940e+00  1.67136452e+00 -4.31346121e+00
  3.00143923e+00  7.49623441e+00  4.26831845e+01  5.65960698e+01
  1.83294734e+02  4.16692265e+00  3.32898929e+02  3.90706904e+00
  3.10174059e+00  5.96430849e+00  4.66295206e+01  5.43175564e+01
 -2.83799467e+01  3.18840064e+00 -5.89706406e-01  6.37366643e+00
  4.45836550e+00  2.74488657e+01  2.61420910e+02  1.36458165e+01
 -3.75548787e+01  3.02282611e+02  4.92448898e+00  3.06722529e+00
 -7.71121899e+01  1.19304667e+00  4.42875744e+00  1.15286453e+02
  1.05170645e+02  7.14382569e+01 -3.19564454e-01  1.91321529e+00
 -1.26400715e+01  2.72678783e+01 -1.55558558e+00  1.42398839e+01
 -1.53366653e-01  5.46186376e+00  2.97252964e-01 -3.39934798e+00
 -3.71318117e+00  1.13605157e+02 -3.34429830e+00  3.77998386e+00
  7.95822768e+00  1.80061932e+00  1.45335392e+00 -2.19557274e+00
  3.21680742e+01  1.55474826e+01  4.96234315e+00  3.88253640e+00
  2.85166800e+01]
(65,)
88.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1983.6213999473807
gradient value of function right now is: [-1.56731866e+00 -3.07860065e+00 -6.51545024e-02 -3.07719214e+00
  1.56731866e+00  3.07860065e+00  6.51545024e-02  3.07719214e+00
  1.04824588e+01  3.51106072e-01  6.90287532e+00  8.23720410e+00
  1.62787036e-01 -1.00245626e-22 -3.75830186e-03 -1.12166724e-03
 -1.81653624e-02  1.05614216e-76 -6.23798737e-04 -4.22899259e-28
  2.15232654e-01 -3.70408308e-23 -1.80349311e-03 -7.50667381e-04
 -2.16983723e-02  1.73242136e-01  4.57705104e+00  5.70938976e+00
  1.69079985e-22  1.23943291e-09  2.05722274e-02  3.94578431e-31
  8.36526361e-03 -2.13873926e-03 -1.88315538e-01 -4.63379940e-01
  1.63510487e-02  6.94483720e-02  2.32716000e+00  9.45164951e-03
  1.13891818e-02  2.07684613e-02  1.39933278e-02  4.32275947e-01
 -8.24447209e-01  1.53690470e-01 -9.18153770e-01 -9.10405434e-01
  5.93337755e-01 -6.54988164e+00  1.33175268e+00  1.47923936e-01
 -7.75213263e+00 -2.87052930e-01 -1.42223149e+01 -1.45623770e+01
 -4.83093178e+00  2.07383495e+01  1.17744783e+01 -4.22546545e+01
 -1.19780623e-01  2.90690869e-01 -8.27162920e-01 -5.48974399e-01
 -1.98621251e+01]
supnorm grad right now is: 42.25465447284161
Weights right now are: 
[-9.51397113e+00  4.53794128e+00 -9.62936931e+00  3.63381118e+00
  9.76853984e+00 -4.64663297e+00  1.00283066e+01 -4.34983956e+00
  6.88292295e+00 -7.87067034e+00  2.06321880e+00 -3.87497292e+00
  3.12212013e+00  7.49623441e+00  4.29717905e+01  5.75137670e+01
  1.84642252e+02  4.16692265e+00  3.35131580e+02  3.90706904e+00
  3.23114791e+00  5.96430849e+00  4.71003613e+01  5.51952945e+01
 -2.63280647e+01  3.28790399e+00 -6.49740675e-01  6.33344586e+00
  4.45836550e+00  2.74492948e+01  2.63927003e+02  1.36458165e+01
 -3.95976261e+01  3.09696829e+02  5.17878347e+00  2.55178453e+00
 -7.69613967e+01  3.03239509e-01  4.63076941e+00  1.18542098e+02
  1.03606338e+02  7.28186322e+01 -1.23142393e+00  2.17938750e+00
 -1.29519600e+01  2.64436588e+01 -1.76857632e+00  1.42463037e+01
  4.32210761e-01  5.40307963e+00  4.13930036e-01 -3.18335135e+00
 -3.74876239e+00  1.14043204e+02 -3.62483774e+00  3.54527616e+00
  8.17127297e+00  1.86181392e+00  1.51466254e+00 -2.19235843e+00
  3.35225412e+01  1.45278353e+01  5.83017148e+00  3.83268330e+00
  2.84674411e+01]
(65,)
90.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1989.9122411981314
gradient value of function right now is: [-1.19957293e+00 -1.05367481e+00 -4.46223775e-02 -1.05612288e+00
  1.19957293e+00  1.05367481e+00  4.46223775e-02  1.05612288e+00
 -1.75449288e+00 -2.18795050e-02 -1.10651667e+00 -1.21963219e+00
 -2.30464426e-01  9.51528315e-24 -7.08808306e-03 -1.21799968e-02
 -1.18397401e-02 -1.86156290e-77 -2.47847505e-04  2.04236516e-29
 -1.60848209e-01  3.24275505e-24 -5.48670578e-03 -9.93299234e-03
  1.82140729e-03 -1.60829766e-01  4.05985832e+00  2.46430425e+00
 -8.15225096e-21 -1.39886310e-09 -1.80112320e-03 -3.41059270e-30
  4.02141489e-03  2.66898751e-04  6.77769792e-01 -8.79481031e-02
  2.16976467e-03 -5.09132102e-03  7.78365248e-01  2.41090812e-03
  7.82828684e-03  3.32482375e-04  1.42843913e-02  3.20879733e-01
  3.21687240e-01 -1.36557451e-02  3.39932750e-01  3.39650723e-01
 -2.90919505e-01  5.77969104e-01 -6.17169216e-01 -5.63042914e-01
 -7.97517937e-01 -3.71883628e-03 -4.16124694e+00 -4.33253234e+00
 -2.86176275e+00  8.82399317e+00  1.85376891e+00 -2.49557045e+00
 -1.52457802e-02  4.16299198e-02  1.97627299e-01 -1.18531674e-01
  1.06041667e-01]
supnorm grad right now is: 8.82399317214614
Weights right now are: 
[-9.38015945e+00  4.75493481e+00 -9.42037548e+00  3.84518715e+00
  9.63472816e+00 -4.86362650e+00  9.81931274e+00 -4.56121553e+00
  6.42177773e+00 -8.43717205e+00  2.01621790e+00 -4.58739975e+00
  3.09620832e+00  7.49623441e+00  4.30848530e+01  5.69813680e+01
  1.87140849e+02  4.16692265e+00  3.39954530e+02  3.90706904e+00
  3.20772586e+00  5.96430849e+00  4.75176173e+01  5.45271952e+01
 -2.87253207e+01  2.68306295e+00 -6.15266986e-01  6.33207389e+00
  4.45836550e+00  2.74497100e+01  2.67478805e+02  1.36458165e+01
 -3.62706962e+01  3.18041136e+02  5.24186696e+00  3.49753722e+00
 -8.16936230e+01  2.14049966e-01  4.76585160e+00  1.16286257e+02
  1.03267451e+02  6.78895838e+01 -1.76473629e+00  1.48833510e+00
 -1.29710664e+01  2.57136486e+01 -1.60684717e+00  1.44273411e+01
  3.30197862e-01  6.13607413e+00 -2.60556056e-01 -3.87610969e+00
 -3.63530780e+00  1.15485185e+02 -3.64460540e+00  3.38955625e+00
  8.31191641e+00  1.95061061e+00  1.41259723e+00 -2.14904828e+00
  3.42629338e+01  1.46051836e+01  5.62708947e+00  3.70721599e+00
  2.85288966e+01]
(65,)
92.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1992.6995884487067
gradient value of function right now is: [-2.55622580e-01 -4.36119653e-01 -9.79820597e-03 -4.35559066e-01
  2.55622580e-01  4.36119653e-01  9.79820597e-03  4.35559066e-01
  1.00952230e+00 -1.52628111e-02  3.48590499e-01  5.74453981e-01
  4.32813861e-02 -4.04679965e-25 -2.23888896e-03 -3.45460315e-03
 -2.92719676e-03  3.01696427e-78 -2.21729771e-05  3.49384786e-29
  4.95723326e-02 -6.41799222e-26 -1.71084836e-03 -2.79288170e-03
 -7.94806726e-03 -2.45378789e-02  5.48668581e-01  8.75709774e-01
  2.52316238e-21  2.72009443e-10 -7.98643032e-04  2.27508246e-30
  2.14689641e-03 -3.27573390e-04  6.25698317e-02 -1.32892803e-02
  8.06231055e-03  1.49388700e-02  6.98199274e-01  1.92585056e-03
  3.06677595e-03  1.08859699e-02  4.33432174e-02  1.75046170e-01
 -3.20567234e-02  2.07844845e-02 -5.63844775e-02 -4.32708627e-02
 -1.44648172e-01 -1.39447181e-01 -2.40668243e-01 -3.73101201e-01
 -1.01101581e+00 -3.24655169e-02 -1.90172024e+00 -1.94995565e+00
 -8.92801943e-01  3.71044776e+00  1.06549161e+00 -4.99833228e+00
  7.98113011e-03 -1.86109412e-02 -3.41290719e-01  2.65162645e-01
 -2.67662725e+00]
supnorm grad right now is: 4.998332276828727
Weights right now are: 
[-9.24377016e+00  4.75667413e+00 -9.03531136e+00  3.83419327e+00
  9.49833888e+00 -4.86536582e+00  9.43424863e+00 -4.55022166e+00
  6.72038230e+00 -8.20989638e+00  2.00955382e+00 -4.40403958e+00
  2.94079241e+00  7.49623441e+00  4.34839355e+01  5.83128333e+01
  1.88220120e+02  4.16692265e+00  3.44600736e+02  3.90706904e+00
  3.09822192e+00  5.96430849e+00  4.80437905e+01  5.57430440e+01
 -2.95993025e+01  2.78607185e+00 -8.75337395e-01  6.19226573e+00
  4.45836550e+00  2.74502285e+01  2.69321427e+02  1.36458165e+01
 -3.89446701e+01  3.24737629e+02  5.01042487e+00  2.90572828e+00
 -8.05637512e+01  1.46458110e+00  4.69955934e+00  1.18093193e+02
  1.04371986e+02  7.13526857e+01 -1.66315149e+00  1.56548710e+00
 -1.30933828e+01  2.53786268e+01 -1.62830649e+00  1.43884727e+01
 -2.18169728e-02  6.61550476e+00  1.62749974e-01 -3.46574816e+00
 -3.66301127e+00  1.15553080e+02 -3.25956512e+00  3.61631813e+00
  8.16979394e+00  1.93010679e+00  1.43771489e+00 -2.21347012e+00
  3.44215254e+01  1.49474357e+01  5.07943612e+00  3.76206991e+00
  2.85332162e+01]
(65,)
94.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1992.7320727044284
gradient value of function right now is: [-2.26557126e-01 -3.97697955e-01 -8.87148535e-03 -3.97995456e-01
  2.26557126e-01  3.97697955e-01  8.87148535e-03  3.97995456e-01
  1.01354127e+00 -1.56031080e-02  3.22061691e-01  5.61968304e-01
 -2.12423574e-02 -3.67685623e-25 -2.79647998e-03 -4.32757591e-03
 -2.52675267e-03  6.79700506e-78 -1.53652800e-05  3.72764590e-29
  3.71992077e-04 -5.15788979e-26 -2.10884828e-03 -3.45980259e-03
 -7.97037709e-03 -2.59314770e-02  5.50015305e-01  8.00840435e-01
  1.70394454e-21  2.72823012e-10 -7.75642592e-04  2.14783430e-30
  1.76225020e-03 -3.01110899e-04  1.06234581e-01 -3.09583013e-02
  8.60845459e-03  1.64484260e-02  7.79747425e-01  2.37049443e-03
  3.01597701e-03  1.14326747e-02  4.32058740e-02  1.71936626e-01
 -3.18514808e-02  1.90289162e-02 -5.55861394e-02 -4.27245957e-02
 -1.60535577e-01 -1.43006113e-01 -2.87314505e-01 -4.18582773e-01
 -1.00438504e+00 -3.43494180e-02 -1.88365743e+00 -1.93508898e+00
 -8.49271800e-01  3.55973779e+00  1.17815766e+00 -5.19578078e+00
  7.36173508e-03 -1.73468688e-02 -3.31753113e-01  2.63862509e-01
 -2.84228072e+00]
supnorm grad right now is: 5.195780777791835
Weights right now are: 
[-9.00683307e+00  4.88390227e+00 -9.84541179e+00  3.95141638e+00
  9.26140179e+00 -4.99259396e+00  1.02443491e+01 -4.66744476e+00
  6.74030466e+00 -6.42899939e+00  2.34709506e+00 -4.49866831e+00
  3.11426337e+00  7.49623441e+00  4.31697982e+01  5.84268071e+01
  1.88849833e+02  4.16692265e+00  3.50827003e+02  3.90706904e+00
  3.27805511e+00  5.96430849e+00  4.82170497e+01  5.57770621e+01
 -3.05448932e+01  2.84772128e+00 -5.69221007e-01  6.55234877e+00
  4.45836550e+00  2.74504375e+01  2.73488858e+02  1.36458165e+01
 -3.80064826e+01  3.31310401e+02  5.10875098e+00  3.03323715e+00
 -8.28957294e+01  2.08549905e+00  4.55749076e+00  1.18986073e+02
  1.05985004e+02  7.05609113e+01 -6.12426212e-01  1.75576782e+00
 -1.32018139e+01  2.54695516e+01 -1.59707401e+00  1.44230627e+01
 -1.28973670e-01  5.92823294e+00 -2.21463473e-01 -3.62431227e+00
 -3.80049245e+00  1.16688403e+02 -3.39256939e+00  3.33659834e+00
  8.09778233e+00  2.02044405e+00  1.48167705e+00 -2.22389190e+00
  3.48435939e+01  1.50984299e+01  5.04717372e+00  4.28986917e+00
  2.86353380e+01]
(65,)
96.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1992.7205081643597
gradient value of function right now is: [-2.15361396e-01 -3.73401202e-01 -9.43099180e-03 -3.73810278e-01
  2.15361396e-01  3.73401202e-01  9.43099180e-03  3.73810278e-01
  9.25190373e-01 -1.89010728e-02  2.64924481e-01  5.10521586e-01
 -2.33485196e-02  6.81420161e-26 -2.58143047e-03 -3.76924831e-03
 -2.56857329e-03  1.62212668e-77 -2.01963301e-05  2.62490687e-29
 -1.72454703e-03  8.29607906e-26 -1.93796458e-03 -3.00390333e-03
 -7.66531455e-03 -3.32542644e-02  5.84557711e-01  7.81231335e-01
  1.85160422e-21  3.09871902e-10 -9.21254708e-04  2.53129296e-30
  1.67567267e-03 -3.22439314e-04  1.05881023e-01 -2.85109585e-02
  8.39828795e-03  1.66013963e-02  7.09003427e-01  2.37969635e-03
  2.92464603e-03  1.12830425e-02  4.09469263e-02  1.64530868e-01
 -1.29841335e-02  2.11097432e-02 -3.23931051e-02 -2.02659381e-02
 -1.48550961e-01 -9.49338492e-02 -2.73036994e-01 -3.77989604e-01
 -9.63997164e-01 -3.26937896e-02 -1.83839636e+00 -1.89317994e+00
 -8.33985444e-01  3.45456741e+00  1.12084791e+00 -4.93375849e+00
  2.97884476e-03 -7.61041050e-03 -2.83378233e-01  2.29390574e-01
 -2.64783337e+00]
supnorm grad right now is: 4.933758486306154
Weights right now are: 
[ -9.63125505   4.70646403  -9.39984725   3.76118387   9.88582376
  -4.81515572   9.79878452  -4.47721226   6.75366777  -6.8246733
   1.90084564  -4.24017337   2.93307191   7.49623441  43.56182624
  57.047059   188.96233444   4.16692265 355.12004479   3.90706904
   3.03819445   5.96430849  48.87515104  54.31980403 -28.75571441
   2.8180018   -0.68911976   6.41840711   4.4583655   27.4514155
 278.07538262  13.64581649 -39.91847818 338.45514409   5.11820589
   2.79431157 -84.0745201    0.99786071   4.99326059 123.07644307
 105.36277091  70.53847751  -0.37131171   2.21278703 -13.10034862
  26.0422866   -1.7815572   14.19138629   0.43638249   5.94432414
   0.47492843  -3.41824418  -3.67752004 116.51113665  -3.22848344
   3.37963562   7.84626684   2.02363429   1.45089515  -2.25624205
  36.25267012  14.82115546   5.31817359   3.97474877  28.5131606 ]
(65,)
98.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1992.74634653581
gradient value of function right now is: [-2.11625814e-01 -3.66364338e-01 -8.85998812e-03 -3.66800558e-01
  2.11625814e-01  3.66364338e-01  8.85998812e-03  3.66800558e-01
  8.94168799e-01 -1.51833545e-02  2.35857210e-01  4.86602405e-01
 -2.02667160e-02  1.81276656e-26 -2.69204175e-03 -3.83126014e-03
 -2.43342880e-03  8.56130534e-78 -1.45637561e-05  2.14480227e-29
  6.96880773e-04  5.34573953e-26 -2.02773679e-03 -3.04999907e-03
 -7.44272628e-03 -3.15684833e-02  5.57312765e-01  7.57008158e-01
  1.02137282e-21  2.34792597e-10 -7.88625513e-04  1.16622696e-30
  1.95900658e-03 -2.87417428e-04  1.19335162e-01 -2.58749517e-02
  8.15851392e-03  1.69155188e-02  7.04009259e-01  2.37707757e-03
  3.10081803e-03  1.10114660e-02  4.67251360e-02  1.68880259e-01
 -1.90531627e-02  1.97191934e-02 -4.02559453e-02 -2.84677420e-02
 -1.52501616e-01 -1.17335092e-01 -2.83292378e-01 -3.78715892e-01
 -9.52742475e-01 -3.23402566e-02 -1.80140504e+00 -1.85666405e+00
 -8.28640001e-01  3.42410156e+00  1.14180040e+00 -4.86701801e+00
  5.71451327e-03 -1.35506862e-02 -2.64773618e-01  2.22208791e-01
 -2.63715649e+00]
supnorm grad right now is: 4.8670180136872565
Weights right now are: 
[-9.59510235e+00  4.87670072e+00 -9.90670118e+00  3.92844502e+00
  9.84967106e+00 -4.98539241e+00  1.03056384e+01 -4.64447341e+00
  6.74739408e+00 -8.78514355e+00  1.60440362e+00 -4.32094020e+00
  3.09514890e+00  7.49623441e+00  4.35714987e+01  5.64745542e+01
  1.89970281e+02  4.16692265e+00  3.60241174e+02  3.90706904e+00
  3.20602362e+00  5.96430849e+00  4.93965190e+01  5.36856158e+01
 -3.15467614e+01  3.28780751e+00 -9.38002014e-01  6.52718945e+00
  4.45836550e+00  2.74518872e+01  2.82961950e+02  1.36458165e+01
 -3.97163326e+01  3.45772902e+02  5.09497090e+00  2.73213182e+00
 -8.38691090e+01 -4.03217141e-02  4.81691244e+00  1.24131274e+02
  1.04050386e+02  7.10981143e+01 -2.03875520e+00  1.93281078e+00
 -1.29660013e+01  2.67819757e+01 -1.86810418e+00  1.41405331e+01
  6.76470175e-01  5.84198288e+00  1.62380761e-01 -3.74281103e+00
 -3.91197459e+00  1.16683452e+02 -3.28550015e+00  3.53649852e+00
  8.36110084e+00  1.92431615e+00  1.52161509e+00 -2.39265281e+00
  3.62404066e+01  1.56680149e+01  5.36645539e+00  3.87742138e+00
  2.87791900e+01]
(65,)
100.0% of gradient descent iterations done. Method = Adam
objective value function right now is: -1992.7506965382536
gradient value of function right now is: [-2.21546105e-01 -3.71970815e-01 -8.49310740e-03 -3.72146347e-01
  2.21546105e-01  3.71970815e-01  8.49310740e-03  3.72146347e-01
  8.42593025e-01 -1.47472134e-02  2.23626912e-01  4.68533175e-01
 -1.06164892e-02 -2.32211162e-26 -2.44362817e-03 -3.90472072e-03
 -2.37945062e-03  2.28226553e-78 -1.46949219e-05  1.48437371e-29
  7.77811036e-03  4.13077538e-26 -1.83177963e-03 -3.11476707e-03
 -7.26389709e-03 -3.29476047e-02  5.78820282e-01  7.48968212e-01
  8.32415988e-22  2.12554978e-10 -7.72653767e-04  8.16443009e-31
  1.96661773e-03 -2.80497128e-04  1.05102191e-01 -2.91955711e-02
  8.21560666e-03  1.63904979e-02  6.92203058e-01  2.40960386e-03
  3.07482254e-03  1.12455761e-02  4.84046786e-02  1.67293459e-01
 -1.20963873e-02  1.98365950e-02 -3.20889990e-02 -2.07051717e-02
 -1.49175373e-01 -1.04737486e-01 -2.78014186e-01 -3.70153934e-01
 -9.25073027e-01 -3.16503047e-02 -1.78626373e+00 -1.83709833e+00
 -8.15728077e-01  3.36544740e+00  1.08451453e+00 -4.71587571e+00
  7.46603973e-03 -1.73235302e-02 -2.61354474e-01  2.27266091e-01
 -2.55521714e+00]
supnorm grad right now is: 4.715875710337678
Weights right now are: 
[-9.44780699e+00  4.84911955e+00 -8.89844200e+00  3.89833095e+00
  9.70237570e+00 -4.95781124e+00  9.29737927e+00 -4.61435933e+00
  6.73631083e+00 -7.57151251e+00  2.06588796e+00 -4.18074566e+00
  3.14862561e+00  7.49623441e+00  4.40433156e+01  5.65233491e+01
  1.91690573e+02  4.16692265e+00  3.63152999e+02  3.90706904e+00
  3.26304034e+00  5.96430849e+00  5.01973643e+01  5.32761647e+01
 -3.44086835e+01  3.70513260e+00 -6.83136132e-01  6.13407716e+00
  4.45836550e+00  2.74520877e+01  2.85552336e+02  1.36458165e+01
 -3.60743463e+01  3.52616076e+02  4.82340862e+00  3.09351897e+00
 -8.54381196e+01 -3.08363263e-01  4.75258821e+00  1.23073887e+02
  1.02801233e+02  7.06095574e+01 -5.85617579e-01  2.01608324e+00
 -1.29994561e+01  2.60766051e+01 -1.46057290e+00  1.44833635e+01
  9.71987574e-02  5.98481056e+00  7.53954577e-02 -3.80713756e+00
 -3.61327139e+00  1.17720486e+02 -3.09146726e+00  3.55810422e+00
  8.60330104e+00  1.79704179e+00  1.44577135e+00 -2.33808643e+00
  3.63460756e+01  1.62287115e+01  5.63656272e+00  3.59127312e+00
  2.84508341e+01]
(65,)
-----------------------------------------------
Selected results: NN strategy on TRAINING dataset
W_T_mean: 1399.4334563026916
W_T_median: 1178.34786507722
W_T_pctile_5: 817.8499589329627
W_T_CVAR_5_pct: 733.2904964747993
-----------------------------------------------
-----------------------------------------------
Just FINISHED: 
Asset basket ID: basic_T30_VWD
Objective function: mean_cvar_single_level
Tracing param: 0.9
F value: -1992.7506965382536
-----------------------------------------------
